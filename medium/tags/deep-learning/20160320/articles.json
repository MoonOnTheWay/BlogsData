[
    {
        "url": "https://medium.com/@davidhq/what-is-ethereum-caeb8f99cdff?source=tag_archive---------0----------------", 
        "text": "Computer code runs on physical machines which process it. It has always been like that and it will also always be so in the future.\n\nWe as normal people have code run for us either on our devices or in the cloud. Cloud doesn\u2019t actually exist, what is called cloud are just machines nicely abstracted away so we don\u2019t have to deal with them. This structure has worked more or less ok so far and will also work in the future.\n\nThere is however a new system coming up which won\u2019t outright replace the old one, but at points where it makes sense it will. We are not yet completely sure exactly what these aspects that would work better in the new way are, but there is a strong consensus among forward looking researchers and thinkers that change will come because it is natural. First it will come slowly, then faster and faster. Some won\u2019t notice it, some will, maybe some already have. Building blocks for this new technology are already in place and for the next 50 years there will be a ton of work required to realize its fullest potential.\n\nSo what exactly is the new paradigm shift? The similarity is that code still runs on machines and the difference is that nobody can influence or change the code once it\u2019s inside the New World Virtual (is there any non-virtual?) Computer. This is currently not the case: the code in the cloud is a) hidden b) cannot be trusted in mathematical sense\u200a\u2014\u200aif someone that controls the machines manipulates it in any way, you wouldn\u2019t know.\n\nHow has it started? Vitalik Buterin was 19 at the time he got the seed of the idea. He is 22 now (in 2016) and the seed had become a fast evolving billion dollar (or much more) entity already. Vitalik and the team are just starting, that is for sure a\u0336l\u0336t\u0336h\u0336o\u0336u\u0336g\u0336h\u0336 \u0336t\u0336h\u0336e\u0336 \u0336h\u0336a\u0336r\u0336d\u0336e\u0336s\u0336t\u0336 \u0336a\u0336n\u0336d\u0336 \u0336m\u0336o\u0336s\u0336t\u0336 \u0336r\u0336i\u0336s\u0336k\u0336y\u0336 \u0336w\u0336o\u0336r\u0336k\u0336 \u0336i\u0336s\u0336 \u0336n\u0336o\u0336w\u0336 \u0336b\u0336e\u0336h\u0336i\u0336n\u0336d\u0336 \u0336t\u0336h\u0336e\u0336m\u0336 and they still have to bust through a couple of dimensions (eg. scale to 1m TPS via sharding stacked on top of sharding run on top of a security deposit-based PoS backbone).\n\nBitcoin will probably fade in importance (or it already has when you read this\u200a\u2014\u200avery likely) and people that predicted this might have been right but for all the wrong reasons (except those who predicted it after 2013/14). Bitcoin seeded the crucial innovation that some other projects picked upon and extended much further. While Bitcoin was invented for trustless finance, Ethereum is a general platform for trustless computing.\n\nEthereum is like life or the universe\u200a\u2014\u200ayou cannot fully understand it all at once at the same time. You only see glimpses into it depending on how well you look\u200a\u2014\u200ainto present or future.\n\nAt the end Ethereum is an incredible, never-seen-before computer, but on the other hand it\u2019s just a computer. It is not intelligent in the traditional sense and will never be artificially intelligent. With our help it can be naturally intelligent and in sync with our needs and desires.\n\nWho will develop applications for Ethereum?\n\nThis is not a traditional goldrush anymore, it\u2019s more than that. It\u2019s selfless development of cool stuff that can benefit whoever understands it. Small gold rushes come and go like they have since forever. To build something on Ethereum that just works and can sustain itself is a different task than builing a mobile app that pays for itself somehow or becomes free after some time. There is no free things on Ethereum. Code execution needs gas which is an internal currency for an unit of computation bought with Ether before each code execution request in the blockchain.\n\nOnly things that really deserve to be executed in this manner will be. Most of other things that don\u2019t have to will work fine as they do now. Ethereum is even more interesting because it is not something entirely new separate from current technology and reality but one of the final pieces in computing. I said pieces because \u201ceverything else\u201d is built from these pieces. Now more and more things will be built purely with code that has to make sure it always possesses enough resources to continue executing, if not, it stops for some time or forever.\n\nVirtual reality is a big concept but is also fifty years old, it will explode in current years because the world (processing) around it matured enough so that it can live. Ethereum is not fifty years old, but two or three (in 2016) and is the slowest computer on Earth. By design.", 
        "title": "What is Ethereum \u2013 davidhq \u2013"
    }, 
    {
        "url": "https://medium.com/@Lidinwise/congrats-google-deepmind-c7eab1fd73c3?source=tag_archive---------1----------------", 
        "text": "Congrats Google Deepmind. You did it! Top rank player of Go is no longer a human. Should we rejoice or fear this formidable feat? Is this milestone the start of the end game in the quest for Artificial General Intelligence (AGI)? My short answer is yes and no.\n\nFirst, some context. Go is an ancient Chinese board game with very simple rules: black and white stones, played in alternate moves by two opponents, fight to conquer the most territory on an 19x19 square. Despite it\u2019s simple rules, the game is of an incredible complexity. As chess, Go is a Markov complete game (the information for the next move is completely contained in the present state of pieces on the board).\n\nHowever, contrary to chess, Go is a much more fluid game, where a single move can change drastically the fate of the game. In chess, after some moves the fate of the game is determined (for a good enough player). Go is much harder to predict the outcome (for two top players), only by the very end of the game\u200a\u2014\u200awhich may take 200 or more turns. On the other hand, the number of possible moves is beyond imagination: for example, if we want to predict 50 turns ahead, we get about 3x10\u00b9\u2070\u2070\u00a0, which is a higher number than the number of atoms in the entire universe.\n\nSo, how did AlphaGo did it? How it was able to navigate through this gigantic space of possibilities within seconds? Brute force will not work. The simple answer is that it used algorithms that are close to human level intelligence. What are they? We don\u2019t know for sure, but some sort of high-level heuristics and shortcuts, like the ability to see that certain configurations are more defendable than others. This takes years to master by humans, but AlphaGo learned them from scratch\u200a\u2014\u200ainitially playing against other computer programs and later against experienced go players. It learns from its mistakes and was able to device, what may be called, strategies\u200a\u2014\u200apretty much the same way as human brain uses heuristics.\n\nIn this respect, this is a remarkable feat as it relies on a completely different approach from the one used by Deep Blue to beat Kasparov on chess. The more technically the answer is that AlphaGo is taking advantage of one of the most powerful machine learning algorithms ever built: deep recurrent neural networks (DRNN) trained with Long-Short Term Memory (LSTM)\u200a\u2014\u200aa technique proposed in 1997 by J. Schmidhuber of IDSIA, Switzerland. Behind it are more bizarre techniques used for reinforcement learning, most notable Monte-Carlo tree search. But the core concept is DRNN.\n\nHardly the capability to generate heuristic or neural networks are new concepts. Neural Networks were around for more than 50 years. They never got much respect from the academic and AI community as the way they work and why they work is pretty obscured\u200a\u2014\u200asomehow as our brain. They only become popular, though for a short period, in late 80\u2019s when Hinton and others propose an algorithm, called back-propagation that made possible training of networks with hidden layers (a layer between the input and the output). Those architectures gain some relevance as it allow to extract non-linear relationships between inputs and outputs (like the XOR problem) that previous networks couldn\u2019t. They got some visibility in problems, like OCR (recognition of digits\u200a\u2014\u200atypeset or hand written).\n\nHowever, after the early 90\u2019s enthusiasm decline in favor of more \u201celegant\u201d and mathematical sounded machines like SVM, especially the kernel based learning. ANN research were confined to a few ghettos, most prominently, Geoffrey Hinton in Toronto, Yann LeCunn in New York, Yoshua Bengio in Montreal and Jurgen Schmidhuber in Losano. They worked hard to solve a fundamental problem in ANNs: how to train deep neural networks?\n\nTwo main difficulties seems insurmountable: 1) how to avoid the gradient vanishing and gradient explosion problem? and 2) how to avoid overfitting?\n\nFaster computers, more data and efficient learning tricks come to the rescue. A new wave was initiated in 2006, when Hinton published a landmark work proposing an algorithm to train a class of machines called Restricted Boltzmann Machines (RBM) with several layers. The idea was simple: train the network layer by layer with an algorithm called Contrastive Divergence (CD)\u200a\u2014\u200awhen a layer is trained, its weights are freezed and their hidden states taken as input to the next layer.\n\nThe architecture of these layers stacked in a greedy approach were called a Deep Belief Network (DBN). They have the advantage that, any time we add an extra layer the expression capability of the function they represent grows exponentially. We can consider each layer of these networks as a representation of ever higher complex features abstractions from the data. Pretty much like the human visual cortex.\n\nDBN worked fine achieving top performance on the classical MNIST handwritten character recognition problem. Other types of generative models were proposed, like convolutional neural networks (CNN) and Deep stacked Auto Encoders (DsAE).\n\nNote that, from a statistical point of view, training a deep neural network (i.e. finding the latent parameters describing the posterior probability distribution based on a set of observations) is an intractable problem, i.e., the number of possibilities is far too high to calculate the likelihood integrals\u200a\u2014\u200asorry for all this Bayesian statistical jargon\u2026 There are possibilities to solve this difficulty: sampling and variational inference. In the case of AlphaGo they used a technique called Monte Carlo Tree Search (MCTS) to sample promising moves among zillions of possibilities. DRNN trained in reinforcement learning and using MCTS for exploration did the trick. And it worked!\n\nHowever, bear in mind, that these machines are very wild beasts. They are very complex and time consuming to train and finding the right architecture can become a nightmare as almost no theoretical support was developed so far. These machines could have hundreds of millions of parameters. Finding the right set of parameters is like locating the grand canyon at complete obscurity\u2026\n\nDespite all these difficulties, Deep Learning is the thing. It beats all the other techniques in complex problems, sometimes by orders of magnitude: image recognition, video, speech recognition, translation, NLP. To human race dismay, we reach a point where machines beat humans in recognizing objects in an image. So, no much surprise Google beating humans in Go. Our old brains simply can not cope with this huge and powerful learning algorithms.\n\nSo much for deep learning. No comes the No part.\n\nWhy Deep Learning alone will not lead us to GAI?\n\nWhat is the problem in reaching Artificial General Intelligence (AGI)? Haven\u2019t machines proved powerful enough to solve all hard problems we through them: locomotion, playing games, driving cars, translation, even cooking. So, we are already there, aren\u2019t we? No.\n\nThe problem I see can be stated in one phrase: these machines do not have \u201cfree will\u201d, or in other words, they don\u2019t known what to do unless a human tell them the goal, or, in ML terms, the objective function (or loss function) to be minimized.\n\nWe learn mostly by unsupervised learning, not supervised learning, as in Go. How to reach to a point where a machine will find automatically what goals to reach and optimize is a long shot from where we are today. So, what is the problem?\n\nThe problem is finding what \u201cpseudo-objective function\u201d we should give the machine to learn. Reward optimization, as proposed by schmidhuber is ok when the task is well defined and you have frequent or infrequent rewards. However, for more high-level cognition we don\u2019t have obvious rewards. What is the reward of curiosity, of art, of creativity?\n\nFurthermore, you always need an external observer or teacher to interpret the results of the machine and to choose which reward to pick among an infinite number of possibilities. That\u2019s the problem: the machine is isolated from the world and it needs ALWAYS an outside agent consciousness to tell the meaning of inputs & outputs and the goals.\n\nMy take on that is simple: the pseudo-objective function is \u201cmeaning\u201d. The machine will try to minimize the serendipity or surprise, between what it thinks is the world and and it observes from the world.\n\nGiven its computational capabilities, it will start creating models of the world as he observes data (a model is simply a set of abstractions he learns to represent invariant properties he may find in observations).\n\nBased on these models, the agent will generalize these patterns to other unseen observations. If it founds something as expected, then he confirms. If it sees something unexpected, then it will reconsider its model based on what he observed in the past and what he is seeing.\n\nThe agent tries to create a story, a narrative, that creates a sense of unity, cohesion of all elements he is observing. So, in other words, the objective is to maximize the state of internal coherence\u200a\u2014\u200athe meaning. The observation take only a secondary role and are conditioned by the bias of the model that the system already have. It is conditioned by the world but its learning is completely independent from the world. That\u2019s the challenge.\n\nSo, unless we create curiosity driven machines, capable to incorporate some level of subjectivity of the world, we will not solve the last missing part of the puzzle to achieve AGI. These machines (no, they will not be robots) will certainly be able to evolve self-referencial cognition (third person view) and their own language and symbolic representation of the world. We are not that far\u2026", 
        "title": "Why AlphaGo is a milestone but it still not achieved AGI"
    }, 
    {
        "url": "https://medium.com/pankajmathur/how-to-do-interactive-programming-in-browser-via-jupyter-notebook-a-detail-guide-a7649f0d0af2?source=tag_archive---------2----------------", 
        "text": "In this article, we will be learning \u201cHow to do interactive programming in Browsers via Jupyter Notebook\u201d and will be covering:\n\nWhat are Jupyter Notebooks?\n\nYes, gone are those days, at least for Python based Data Scientists, Machine Learners, Deep Learners or Software Engineers, when for analyzing quick data or creating research project, you will have to work in various terminal, either with the normal Python shell or with IPython, then you will create your visualizations for math equation and graphs in separate windows, and then write an in-depth documentation in a separate document software, along with managing various scripts for functions and classes and just when you thought you were almost done, you end up wasting huge amount of time on finding a not so friendly third-party tools to just to share all of this on web\u2026\n\nwith the emergence of Literate Programming, all these steps have vanished in a breeze and Jupyter Notebooks are the reason behind it.\n\nSo, what is a Jupyter notebook? It is a web-based editor, that allows you to combine explanatory text, math equations, code, and visualizations all in one easily shareable document. For example, here\u2019s is a list of world most popular jupyter notebooks which showcase research project in the field of Psychology & Neuroscience, Physics, Chemistry & Biology, Mathematics, Economics & Finance, Earth Science & Geo-Spatial Data, Social data, Signal, Sound and Image Processing and Natural Language Processing.\n\nJupyter Notebooks are also rendered automatically on GitHub. It\u2019s a great feature that lets you easily share your work. Most commonly people use http://nbviewer.jupyter.org/ that renders notebooks directly from your GitHub repo or from notebooks stored elsewhere.\n\nLiterate Programming\n\nJupyter Notebooks are a form of literate programming, introduced by Donald Knuth, in which a program is given as an explanation of the program logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which a compilable source code can be generated.\n\nThe literate programming paradigm, as conceived by Knuth, represents a move away from writing programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts. Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros are included to hide abstractions and traditional source code.\n\nInstalling & Launching Jupyter Notebook\n\n\n\nBy far the easiest way to install Jupyter is with Anaconda. Jupyter notebooks automatically come with the distribution. (If you haven\u2019t Please look at my other article to learn more about Anaconda & Conda environment)\n\nYou\u2019ll be able to use jupyter notebooks from the default environment. If you haven\u2019t installed standard anaconda package, which comes with the jupyter notebook, you can still install jupyter notebook by using below command, if you have already jupyter notebook and you will type this command then it will just try to update the current version with new one.\n\nIf you are still not using Anaconda (& not convinced by my detail article What is Anaconda and Why should I bother about it?) then you can still install only Jupyter notebooks package via pip instead of whole anaconda environment, by using the command:\n\nin your terminal or console. This will start the jupyter notebook server in the directory where you ran the command in. That means any notebook files will be saved in that same directory. Ideally, you\u2019d want to start the jupyter notebook server in the directory where you are saving your projects notebooks. However, you can navigate through your file system to any directory, where your notebooks are stored. For example, I started jupyter notebook in my root directory of mac but my notebook live in the deep-learning folder, so I will just navigate to the deep-learning folder and open the existing ipython notebook files in the jupyter notebook there.\n\nAlso, look at the web address of this browser window, When you run the command, the jupyter notebook server home by default runs at http://localhost:8888\n\nHere, note that localhost can also be replaced with your machine IP and 8888 is the port of the jupyter notebook server is communicating on you can also type http://your_computer_ip:8888 to access it, for example, my machine IP 127.0.0.1, so I can access Jupyter Notebook directly via http://127.0.0.1:8888.\n\nNow, as long as the jupyter notebook server is still running, you can always go back to its main page by going to http://localhost:8888 in your browser.\n\nAt this point, If you start another jupyter notebook server, without closing the previous server, the new notebook sever will just increment the port number and it will run on port 8889. Then, you\u2019d connect to it at http://localhost:8889. Every additional instance of jupyter notebook server will increment the port number like this.\n\nNow, if you look at your current jupyter notebook page, on the right side, you can see the option to create a new notebook by clicking on \u201cNew\u201d. This will create a new notebook, text file, folder, or terminal.\n\nAlso, here you will see different python kernel available for use in this notebook. Python [default] and If you run a Jupyter notebook server from a conda environment, you\u2019ll also be able to choose a kernel from any of the other environments (see below). To create a new notebook, without any pre-configured conda environment and directly on conda root environment, which is popular way to use jupyter notebook is to use Python [conda root]\n\nQuick Introduction to Notebook Interface\n\nWhen you will create a new notebook by choosing Python [conda root], you should see something like this:\n\nGo ahead and check out what each menu item has to offer to you.\n\nWhen you will see below menu items and toolbar, You\u2019ll see a little box with the name \u201cIn [1]: \u201c outlined in green. This is called a cell. Cells are where you write and run your code. You can also change it to render Markdown, a popular formatting syntax for writing web content. We will cover Markdown in more detail later. In the toolbar, under menu items, click \u201cCode\u201d to change it to Markdown and back. The little play button runs the cell, and the up and down arrows move cells up and down\n\nWhen you run a code cell, the output is displayed below the cell. The cell also gets numbered, you see In [1]: on the left. This lets you know the code was run and the order if you run multiple cells. Running the cell in Markdown mode renders the Markdown as text.\n\nThe toolbar\n\nlet\u2019s go through the toolbar one by one, starting from the left:\n\nThe first symbol which looks like a floppy disk is for \u201csave,\u201d It saves the notebook!\n\nThe + button creates a new cell in the notebook below.\n\nThen, the third button with scissor shape, is to cut cell, fourth symbol with two similar transparent page is for copy cell, and the fifth symbol with one dark page and one transparent page is for paste cells from one place to another.\n\nThe up and down arrows are for moving from up and down from one cell to another\n\nThe next 3 buttons are standard Run, stop, restart buttons which run, stop and restart The next drop-down button is for choosing between cell type: code, Markdown, raw text, and header\n\nThe next button is Command palette, which will bring up a panel with a search bar where you can search for various commands. This is really helpful for speeding up your workflow as you don\u2019t need to search around in the menus with your mouse.\n\nJust open the command palette and type in what you want to do. For instance, if you want to see all the keyboard shortcuts of the jupyter notebook, you can choose keyboard shortcuts in command palette. (on the side note, you can also get keyboard shortcuts pop up by using fn + H hotkeys on Mac OSX)\n\nThe next button is Cell toolbar, gives various options for cells such as using them as slides\n\nThe next cloud looking button is to sign in to your anaconda cloud account\n\nThe next giftbox looking button is dedicated to slideshows controls and it will open a pallet from right side of notebook, with the first option will play slideshow and show slide show play options, second option will open each slide pallet in downside of your notebook, Third option will open change theme settings and fourth option is to get help on nbpresent aka slideshow functionality of jupyter notebooks.\n\nRenaming Notebook\n\nAt the top, you see the title. Click on this to rename the notebook.\n\nCode and Markdown Cells\n\nCode cells\n\nMost of your work in notebooks will be done in code cells. This is where you write your code and it gets executed. In code cells you can write any code, assigning variables, defining functions and classes, importing packages, and more. Any code executed in one cell is available in all other cells.\n\nTo give you some practice, I created a notebook you can work through. Download the notebook Working With Code Cells below then run it from your own notebook server. (In your terminal, change to the directory with the notebook file, then enter jupyter notebook) Your browser might try to open the notebook file without downloading it. If that happens, right-click on the link then choose \u201cSave Link As\u2026\u201d\n\nMarkdown cells\n\nAs mentioned before, cells can also be used for text written in Markdown. Markdown is a formatting syntax that allows you to include links, style text as bold or italicized, and format code. As with code cells, you press Shift + Enter or Control + Enter to run the Markdown cell, where it will render the Markdown to formatted text. Including text allows you to write a narrative alongside your code, as well as documenting your code and the thoughts that went into it.\n\nYou can find the documentation here, but I\u2019ll provide a short primer.\n\nHeaders\n\nYou can write headers using the pound/hash/octothorpe symbol # placed before the text. One # renders as an h1 header, two ## renders an h2, and so on. Looks like this:\n\nLinks\n\nLinking in Markdown is done by enclosing text in square brackets and the URL in parentheses, like this\n\nEmphasis\n\nYou can add emphasis through bold or italics with asterisks or underscores (* or _). For italics, wrap the text in one asterisk or underscore,\n\nEither asterisks or underscores are fine as long as you use the same symbol on both sides of the text.\n\nCode\n\nThere are two different ways to display code, in line with text and as a code block separated from the text. To format inline code, wrap the text in backticks. For example, `request.get()` renders as\n\nTo create a code block, start a new line and wrap the text in three backticks\n\nor indent each line of the code block with four spaces.\n\nMath expressions\n\nYou can create math expressions in Markdown cells using LaTeX symbols. Notebooks use MathJax to render the LaTeX symbols as math symbols. To start math mode, wrap the LaTeX in dollar signs $y = mx + b$ for inline math. For a math block, use double dollar signs,\n\nCheatSheet of Notebook Keyboard Shortcuts\n\nNotebooks come with a bunch of keyboard shortcuts that let you use your keyboard to interact with the cells, instead of using the mouse and toolbars. They take a bit of time to get used to, but when you\u2019re proficient with the shortcuts you\u2019ll be much faster at working in notebooks.\n\nPerform Special Operations using Magic Keywords\n\nMagic keywords\n\nMagic keywords are special commands you can run in cells that let you control the notebook itself or perform system calls such as changing directories. For example, you can set up matplotlib to work interactively in the notebook with %matplotlib.\n\nMagic commands are preceded with one or two percent signs (% or %%) for line magic and cell magics, respectively. Line magics apply only to the line the magic command is written on, while cell magics apply to the whole cell.\n\nNOTE: These magic keywords are specific to the normal Python kernel. If you are using other kernels, these most likely won\u2019t work.\n\nTiming code\n\nAt some point, you\u2019ll probably spend some effort optimizing code to run faster. Timing how quickly your code runs is essential for this optimization. You can use the timeit magic command to time how long it takes for a function to run, like so:\n\nIf you want to time how long it takes for a whole cell to run, you\u2019d use\n\nEmbedding visualizations in notebooks\n\nAs mentioned before, notebooks let you embed images along with text and code. This is most useful when you\u2019re using matplotlib or other plotting packages to create visualizations. You can use\n\nto set up matplotlib for interactive use in the notebook. By default, figures will render in their own window. However, you can pass arguments to the command to select a specific \u201cbackend\u201d, the software that renders the image. To render figures directly in the notebook, you should use the inline backend with the command\n\nTip: On higher resolution screens such as Retina displays, the default images in notebooks can look blurry, so you should use:\n\nso, the final command will be\n\nDebugging in the Notebook\n\nWith the Python kernel, you can turn on the interactive debugger using the magic command\n\nWhen you cause an error, you\u2019ll be able to inspect the variables in the current namespace.\n\nAbove you can see I tried to sum up a string which gives an error. The debugger raises the error and provides a prompt for inspecting your code.\n\nRead more about PDB in the documentation. To quit the debugger, simply enter q in the prompt.\n\nMore Magic\n\nThere are a whole bunch of other magic commands, I just touched on a few of the ones you\u2019ll use the most often. To learn more about them, here\u2019s the list of all available magic commands.\n\nCreating HTML Pages from Notebooks\n\nNotebooks are just big JSON files with the extension\u00a0.ipynb.\n\nSince notebooks are JSON, it is simple to convert them to other formats. Jupyter comes with a utility called nbconvert for converting to HTML, Markdown, slideshows, etc.\n\nFor example, to convert a notebook to an HTML file, in your terminal use\n\nConverting to HTML is useful for sharing your notebooks with others who aren\u2019t using notebooks. Markdown is great for including a notebook in blogs and other text editors that accept Markdown formatting.\n\nCreating Beautiful SlideShows\n\nCreating slideshows from notebooks is one of the awesome hidden features of the jupyter notebook. To create a slideshow, in your terminal use\n\nYou can see an example of a slideshow here\n\nI hope, this detailed article will help you to jumpstart your interactive programming experience in Browsers via Jupyter Notebook.\n\nPlease do let me know your thoughts, questions under the comments section. I would really appreciate getting some feedback on this article & ideas to improve it.\n\nIn the meanwhile, Happy Thinking\u2026", 
        "title": "How to do interactive programming in Browser via Jupyter Notebook? A detail Guide.."
    }, 
    {
        "url": "https://medium.com/@jonathan_kolber/superb-analysis-of-why-deep-learning-will-soon-displace-vast-numbers-of-workers-e9378a20771b?source=tag_archive---------3----------------", 
        "text": "Superb analysis of why deep learning will soon displace vast numbers of workers. I intend to share this article widely.\n\nMy only issue\u200a\u2014\u200aand it\u2019s a big one\u200a\u2014\u200ais HOW to implement a guaranteed income. The commonly discussed approaches all face serious practical challenges.\n\nI am preparing a journal article that explores this further, and look forward to there being a solution, or perhaps more than one solution.\n\nCapitalism is approaching its completion. We need to get ready.", 
        "title": "Superb analysis of why deep learning will soon displace vast numbers of workers."
    }
]