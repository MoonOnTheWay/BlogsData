[
    {
        "url": "https://medium.com/kosate/%E0%B9%80%E0%B8%88%E0%B8%B2%E0%B8%B0%E0%B8%A5%E0%B8%B6%E0%B8%81-alphago-%E0%B8%97%E0%B8%B3%E0%B8%87%E0%B8%B2%E0%B8%99%E0%B8%AD%E0%B8%A2%E0%B9%88%E0%B8%B2%E0%B8%87%E0%B9%84%E0%B8%A3-%E0%B8%89%E0%B8%9A%E0%B8%B1%E0%B8%9A%E0%B9%80%E0%B8%82%E0%B9%89%E0%B8%B2%E0%B9%83%E0%B8%88%E0%B8%87%E0%B9%88%E0%B8%B2%E0%B8%A2-%E0%B9%84%E0%B8%A1%E0%B9%88%E0%B9%80%E0%B8%84%E0%B8%A2%E0%B9%80%E0%B8%82%E0%B8%B5%E0%B8%A2%E0%B8%99%E0%B9%82%E0%B8%9B%E0%B8%A3%E0%B9%81%E0%B8%81%E0%B8%A3%E0%B8%A1%E0%B8%81%E0%B9%87%E0%B8%AD%E0%B9%88%E0%B8%B2%E0%B8%99%E0%B9%84%E0%B8%94%E0%B9%89-3a1cf3631289?source=tag_archive---------0----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "\u0e40\u0e08\u0e32\u0e30\u0e25\u0e36\u0e01 AlphaGo \u0e17\u0e33\u0e07\u0e32\u0e19\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e44\u0e23 ? (\u0e09\u0e1a\u0e31\u0e1a\u0e40\u0e02\u0e35\u0e22\u0e19\u0e42\u0e1b\u0e23\u0e41\u0e01\u0e23\u0e21\u0e44\u0e21\u0e48\u0e40\u0e1b\u0e47\u0e19\u0e01\u0e47\u0e2d\u0e48\u0e32\u0e19\u0e44\u0e14\u0e49)"
    }, 
    {
        "url": "https://medium.com/@shiyan/materials-to-understand-lstm-34387d6454c1?source=tag_archive---------1----------------", 
        "text": "People never judge an academic paper by those user experience standards that they apply to software. If the purpose of a paper were really promoting understanding, then most of them suck. A while ago, I read this article talking about academic pretentiousness and it speaks my heart out. My feeling is, papers are not for better understanding but rather for self-promotion. It\u2019s a way for scholars to declare achievements and make others admire. Therefore the golden standard for an academic paper has always been letting others acknowledge the greatness, but never understand enough to surpass itself.\n\nWhen it comes to LSTM, for example, there aren\u2019t many good materials. Most likely what they would show you is this bullshit image:\n\nThere are many things on this image pisses me off.\n\nFirst of all, they use these f shapes (with a footnote \u201cf\u201d that looks like a \u201ct\u201d)to denote non-linearity and at the same time, they have f_t in their equations. And they are not the same thing!\n\nSecond, they have these dash lines and solid lines to represent time delay. So solid lines are C_t, and dash lines are C_t-1. There are 5 arrows coming out of the \u201cCell\u201d, but only 4 are labelled. One C_t is incorrectly labelled with dash line. One solid line is supposed to be a dash line and C_t-1.\n\nThird, what the hell are black dots? You have to look at the equation to figure out that they are element-wise multiplications of two vectors.\n\nAnd finally, C_t is supposed to be calculated as a summation of f_t * C_t-1 and i_t * tanh(W_xc * x_t + W_hc*h_t-1 +b_c) (the third equation). But the image completely misses the plus sign.\n\nCompared to this shitty image, the following version is slightly better:\n\nThe 3 C_t-1 are correctly represented as dash lines. The plus sign is there too. Sigmoid functions are written with the proper sigma sign, not some freaking f_f.\n\nSee, things don\u2019t have to be so difficult. And understanding shouldn\u2019t be a painful experience. But unfortunately, academic writing makes it so almost all the time.\n\nPerhaps the best learning material is really this excellent blog post:\n\nAnd its diagram is simply beautiful:\n\nI think the most evil thing about the first two versions are that they treat C (the cell, or the memory) not as an input to the LSTM block, but rather a thing that is internal to the block. And they adopt this complex dash line, solid line thing to represent delay. This is really confusing.\n\nBut I do noticed one difference between the first two diagrams and the last one. The first two diagrams sum up the inputs with the outputs from the previous layer to calculate the gates (for example, f_t and i_t). But in the third version, the author concatenate them. I don\u2019t know if it is because the third version is a variation or this doesn\u2019t matter in terms of correctness. (But I don\u2019t think it should be concatenation because the vector size h shouldn\u2019t be changed. If it is really concatenation, the vector size of h will change to the size of x+h?)\n\nI drew a new diagram, which I think is better:", 
        "title": "Materials to understand LSTM \u2013 Shi Yan \u2013"
    }, 
    {
        "url": "https://medium.com/@StephenMartindale/alphago-vs-lee-se-dol-game-three-76f2a88f72b3?source=tag_archive---------2----------------", 
        "text": "This morning, Lee Se-dol lost a third and deciding game in the challenge match against Google DeepMind\u2019s AlphaGo. The fourth and fifth games will be played but the prize goes to the programme and the prize money will be paid to various benevolent causes.\n\nThe game started with a high \u2018Chinese\u2019 fuseki which was soon broken up by a vital battle that affected the whole board, a product of Lee Se-dol\u2019s aggressive style and AlphaGo\u2019s refusal to capitulate. Black fought for his heavy and inefficient stones but white, played by the bot, acquired a huge territory that black simply couldn\u2019t match. In desperation, black invaded and a scuffle lead to a complicated situation with multiple Ko fights. Black resigned when it became clear that his stones were lost and, elsewhere on the board, the cost of the scrap became too great to bear.\n\nOne incontrovertible fact was proven during the match: AlphaGo does not struggle with Ko fights in the slightest. AlphaGo showed that it can handle extremely tricky Ko situations that play havoc with the game-tree and would have completely flummoxed its ancestors, the MCTS engines of yester-year.\n\nLee Se-dol admitted that AlphaGo defeated him, taking ownership of his defeat and lamenting that he did not show us a better game, today. He said that today\u2019s defeat was his defeat, not a defeat of human beings.\n\nMichael Redmond, the 9 dan professional westerner who provided the official English commentary during the match, brazenly declared that AlphaGo \u201cbeat Lee Se-dol at his own game!\u201d In front of a veritable army of reporters, in the ballroom of a hotel in down-town Seoul, he went on to suggest that AlphaGo would herald a \u201cthird revolution\u201d in Go opening theory, mentioning AlphaGo in the same sentence as Honinbo Dosaku and Go Seigen, two legendary human players who sparked extensive, novel innovation in the fuseki in the past.\n\nWhen a member of the audience questioned Redmond\u2019s prophecy, Lee Se-dol answered that he thought AlphaGo is not at the level of the so called \u2018Divine Gods\u2019 and described the bot\u2019s play as \u2018different\u2019 and \u2018superior at times.\u2019\n\nMeanwhile, in the Go community, speculators questioned whether Lee Se-dol (9 dan professional) was, in fact, the best player to champion humanity in this duel against the machine. Some pointed to his aggressive and frequently precarious fighting style and hypothesised that AlphaGo\u2019s cold and heartless play was ideally suited to winning in such situations - situations in which mere mortal, human professionals might become flustered or overwhelmed by the complexity. Some suggested that calmer, more placid players might fare better against the A.I.\n\nLee Se-dol reassured the audience at the post-match conference that AlphaGo is not yet perfect. I believe him. If he does not defeat AlphaGo, another will, but I do hope that he shows us the way over the course of the next two games.", 
        "title": "AlphaGo vs. Lee Se-dol: Game Three \u2013 Stephen Martindale \u2013"
    }, 
    {
        "url": "https://medium.com/@vufindinc/why-every-brand-will-capitalize-on-deep-learning-to-optimize-revenue-margins-bca58012b0c0?source=tag_archive---------3----------------", 
        "text": "Every brand has become an online retailer, some managing their own e-stores, and some relying on hosted solutions such as DemandWare. Similarly, every brand has invested in social presence, social listening, and social campaigns. In mobile, we\u2019re definitely lagging behind the emerging markets, as many still have 2-star apps where a web experience has been shoe-horned onto a mobile screen, while an e-tailer like Flipkart in India has gone mobile-only.\n\nBrands realize that they increasingly need to own the customer journey from intent to purchase, as they know the user experience (UX) is what inspires and retains users. A recent HBR article emphasizes how crucial it is for every brand to eliminate the guesswork in understanding customer\u2019s emotional motivators. For online retailers, the study showed customers who are \u201cFully connected and satisfied and able to perceive brand differentiation\u201d were 52% more valuable than the \u201chighly satisfied\u201d baseline users. The retailer study on the bottom line impact of the \u201cFashion Flourishers\u201d category and its strategy impact on online-to-offline and store locations is well worth a careful look. However, most brands still face several key problems in understanding their customers\u2019 motivators and optimizing their UX to get them to the fully connected stage.\n\nSource: \u201cThe new science of customer emotions\u201d by Magids, Zorfas, Leeman, Nov 2015 Harvard Business Review\n\nFor the vast majority of brands there isn\u2019t much intelligence aggregation across these channels and touch points, nor is there a feedback loop to leverage the relevant analytics to inform the decisions various stake-holders are making every day. It\u2019s decisions like these that need every byte and every pixel of intelligence you can gather:\n\n- Is this the right collection for Thanksgiving week sales?\n\n- Why is this recommendation converting against this SKU for San Francisco users, but not for Boston users?\n\n- Is 20% lift in CTR good, or should we continue to refine to aim for 30% lift?\n\n- Should we discount the handbags by 21% or 29% to meet X revenue goal in Q4?\n\n- Does that Twitter or Tumblr photo featuring our product carry positive sentiment or negative?\n\nViewing excel sheets\u2013or even business intelligence dashboards\u2013that lack the continuous deep-learning behind the scenes on all these activities almost always puts you at a significant disadvantage. It gives you, the decision-maker, a partial, spotty view of your world. Also, because it\u2019s already stale, you lack the most relevant real-time ammunition to make the smartest decision at any given moment. Compound this over time and across functions and you\u2019re essentially flying almost blind, kind of like Wattny in The Martian during the scene where he punctures his astronaut suit and hopes to make it to the rope by free-flying through space. His endeavor was fun to watch, but it could have cost him his life and billions of dollars!\n\nWe call this deep-learning across all touch points to affect a smarter user experience, AI-merchandising. We\u2019ll cover only 2 aspects of this in this article: product design and catalog design. Other elements will follow in subsequent articles.\n\nA deep-learning engine that aggregates all clicks, purchases, save-to-wish-list, cart-abandonment, and returns for every product in your catalog gains internal insights (in the neural network) into what\u2019s appealing and what\u2019s not about your products. The information isn\u2019t captured in some metadata attributes in a row or column in a database, it\u2019s embedded in its \u201cmind\u201d and can be recalled. This intelligence can then be queried for suggestions on what to design. The engine can act as an AI-assistant to your designers, suggesting cuts, styles, patterns, colors, and fabrics for next seasons\u2019s collection, which can even be refined by geography and demographic to meet revenue and margin goals.\n\nCross-category recommendations, often called \u201cStyle it with\u201d, or \u201cComplete the look\u201d recommendations, are a unique discovery mechanism used to inspire shoppers to create ensembles from your catalog. It is one way to encourage shoppers to maximize basket size, and to love your brand even more as they dress head-to-toe from your catalog. A deep-learning aiCommerce engine would garner the intelligence to advise you what\u2019s working well with what for your shoppers (for ex: what handbags and shoes with what shirts, etc) so your catalog collections can indeed deliver that head-to-toe ensemble.\n\nNo brand can afford to ignore #aiCommerce and deep-learning powered user experience. We\u2019re very excited to collaborate with brands of all sizes on deep-learning and AI-merchandising to inspire shoppers with a futuristic and joyful user experience, while maximizing revenue lift.", 
        "title": "Why every brand will capitalize on deep-learning to optimize revenue & margins"
    }
]