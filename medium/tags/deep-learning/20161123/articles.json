[
    {
        "url": "https://medium.com/@apoorv03/deep-learning-101-17d68eb7b121?source=tag_archive---------0----------------", 
        "text": "This is meant to be a quick (under 10 min) read for a non-technical audience. Enjoy!\n\nBLUF (Bottom Line Upfront): The goal/problem/mission is to recreate the human intelligence at a machine level (Artificial Intelligence). Breaks down to broadly three atomic steps Receive input \u2192 Understand \u2192 Act.\n\nWhy is that hard? Consider a simple problem\u200a\u2014\u200asomeone across the room throws a ball at you and you catch it. Sounds simple, but actually, this is one of the most complex processes we\u2019ve ever attempted to comprehend\u200a\u2014\u200alet alone recreate at a machine level. What actually happens in the human circuitry is: the image of the ball passes through your eye and strikes your retina, which does some elementary analysis and sends it along to the brain, where the visual cortex more thoroughly analyzes the image. It then sends it out to the rest of the cortex, which compares it to everything it already knows, classifies the objects and dimensions, and finally decides on something to do: raise your hand and catch the ball (having predicted its path). This takes place in a tiny fraction of a second, with almost no conscious effort, and almost never fails. So recreating human-esque vision in machines, as an example, is a set of interconnected problems each of which relies on the other.\n\nBLUF: Deep Learning refers to a specific kind of Machine Learning technique\u200a\u2014\u200amulti-layer Artificial Neural Networks (ANN) (other synonyms: multilayer perceptrons, deep neural nets, etc.)\u200a\u2014\u200awhich is very good at learning patterns and using that intel to classify or predict outputs given a set of inputs.\n\nANN is actually a pretty old machine learning model that was inspired by the human brain (invented in 1957 by Frank Rosenblatt). A neural network is an interconnected set of nodes (each with an activation function) that are connected by edges, with differing weights, to solve problems like classification, regression, etc. For classification problems, for instance, each node will have a similar classifier but each node\u2019s input is modified by different weights (edges) and biases. If you stack a lot of layers in a neural network (more than 3), that is suddenly considered deep learning. For simple pattern recognition problems, you could use simpler frameworks (Logistic regression or Support Vector Machines), but for anything with medium to high complexity deep learning will outperform other frameworks. Patterns are presented to the network via the \u2018input layer\u2019, which communicates to one or more \u2018hidden layers\u2019 where the actual processing is done via a system of weighted \u2018connections\u2019 as shown in this image to the right. ANNs are able to break down the bigger pattern into smaller patterns. Image recognition, for instance, is performed in small chunks to see if there\u2019s a human face (starting from looking for simple things like vertical and horizontal edges for instance).\n\nThere are three basic characteristics of any ANN\u00a0: data, computational hardware and an algorithm.\n\nThe more data you let the ANN train on, the better the outcome is. To get a sense of scale, Google\u2019s face recognition algorithm trained on about 260M images in 2015.\n\nHowever for most real world problems, you probably need somewhere around 10k to 100k data points. If you don\u2019t have a lot of data you could\n\nNo matter what learning algorithm you use, performance gets better with more data.\n\nValue in AI is driven by empirical testing. Quick iteration speed on various algorithms helps researchers try out more ideas. E.g. How did scientists discover that Recurrent Neural Network (RNNs) is the best architecture for speech recognition? 7 years ago, Andrew Ng and team started out using an audio clip, cut it into steps, feed into a vanilla NN (simplified diagram below) to get the output transcript. This didn\u2019t work and after some experiments they realized they needed to move to a Recurrent NN that led to the creation of Deep Speech\n\nBB#3 Algorithms for Feature Representation: Each node in each layer is a computational units. This means each node performs some computation (normally nonlinear like a sigmoidal function, hyperbolic tangent nonlinearity, or rectifier linear unit) given its inputs from the previous layer. The feature representation / loss-function that works best for a specific problem is a result of teams of 1000s of researchers spending dozens of years. Example\u200a\u2014\u200aimage from SIFT paper for computer vision that took 10 years to come up. Thankfully, this hard-work has now been abstracted out (for vision, audio and text). The growth here is very empirical, hence the need for better computing infra to move the research faster.\n\nBLUF: Since 2012, there has been a huge jump in accuracy of ML techniques (~74% \u2192 84%), because they started using ANNs and realizing the giant leap provided by ANNs, the industry is investing resources (hardware, software, data, money) at an unprecedented rate.\n\nDL became feasible only in recent years because of four broad advancements:\n\nToday, Deep Learning is the state if the art approach in almost every computer vision (ANNs are better than a human for face recognition, for instance), voice recognition (Siri, Alexa) and Natural Language Processing tasks. Application of Deep learning today is easy.\n\nStep 2: Get a GPU or use cloud resources (AWS, IBM Softlayer)\n\nToday it\u2019s used for (non-exhaustive list below, a much more comprehensive one here):\n\nMy take on the next frontiers / next big waves:", 
        "title": "Deep Learning 101 \u2013 Apoorv Agrawal \u2013"
    }, 
    {
        "url": "https://medium.com/@Staqu/ai-advancing-one-pixel-at-a-time-9471de84b207?source=tag_archive---------1----------------", 
        "text": "The things we do for Love\u00a0;) Valar Morghulis. For many AI is just a buzz word or USP but for us, it\u2019s more than the funky marketing stuff. Believe me when I say: we dream in pixels!\n\nParsing out the fine information (in this case clothing style) from the crowded/wild background images is a daunting task for any state of the art deep learning tools. Chalking out detailed semantic relationship within pixels is one of the problem on which some of the top deep learning labs are working on. The difficulty with such images is that they have wild background, are ill posed and have variance in illumination along the surface of clothing. To segment such scattered information in a detailed way is a really difficult task. But happy to share that we have made significant advances towards solving this problem and are planning to make this research (wrapped around some product) live soon.\n\nThe dark purple area in the image (right) shows the segmented clothing region through our developed neural network which can further be used to extract the styling (other than color and pattern) of apparels in real time in a more robust way.\n\nP.S. Science advances in small steps and we should stay humble!", 
        "title": "AI: Advancing one pixel at a time \u2013 Staqu Technologies \u2013"
    }, 
    {
        "url": "https://medium.com/@alexprevoteau/generating-multi-track-music-with-deep-learning-60fdf2a3ab05?source=tag_archive---------2----------------", 
        "text": "At the time of this writing there are now many open-source projects that allow one to produce music with deep learning.\n\nThese projects generally fall into one of two categories:\n\nExamples of audio waveform generation include Google\u2019s WaveNet and Gruv, a Stanford research project. Beyond music, WaveNet shows a lot of promise for generating much more natural text-to-speech (TTS) than existing systems. While these are versatile and robust, they are also very computationally intensive, rendering them impractical for real-time applications\u2013at least for now.\n\nMusical note generation is much more lightweight in contrast. Though these projects are only useful for generating music, they too are versatile in the sense that any number of methods can be used to generate audio from the notation. This allows for synthesizers and audio samples to be triggered by the notation, providing some interesting possibilities.\n\nExamples of musical note generation projects include: Melody RNN, Deep Jazz, Bach Bot, as well as training and generation of abc-notation using character libraries such as Andrej Karpathy\u2019s chr-rnn.\n\nA year ago, a friend of mine produced some examples using chr-rnn and abc notation files here. What is interesting about this application is that within the file is not only the music but also meta-data, such as the title. This means that when abc music is generated, it also generates a name for the song.\n\nThe examples of deep learning generated music I\u2019ve seen so far are interesting, but are mostly a single stream of notes or chords and played by a single instrument. I was curious to hear what multiple instruments playing entirely machine generated music together can sound like using the existing available projects.\n\nAll projects that I am currently aware of do not directly account for higher level musical arrangement. However, Google\u2019s Magenta\u2019s Melody RNN does tackle the problem of long-term structure with two models, Lookback and Attention.\n\nIn brief, the Lookback model captures long-term dependencies using an LSTM (Long short-term memory network) as well as the use of custom inputs and labels for each input vector. These include inputs from the previous two bars, labels for whether previous notes were already in a state of repeating, as well as the measure position. The Attention model accounts for even longer term music structure. It also uses an LSTM and creates an \u201cattention mask\u201d through which it takes multiple previous steps as inputs. Read more about melody_rnn\u2019s Lookback and Attention models here.\n\nBelow are my first attempts at producing multi-track recordings entirely generated by Google Magenta\u2019s Melody RNN. For all of these, I am using the Magenta project\u2019s pre-trained Attention Model available here. I am priming each track with midi that was originally written for that track\u2019s instrument in attempt to make it sound as natural and fitting as possible. Finally, priming for each track is done at the same tempo, time signature, and key as for the arrangement it is intended.\n\nI have heard a lot of melodies produced by machine learning for melodic instruments but not so much for percussive instruments (besides this). Surprisingly, melody_rnn\u2019s Attention model is actually able to generate a consistent long-term beat (without getting too \u201cmelodic\u201d) by priming the model with drum beat midi.\n\nNot all beats using this method work very well. Some tend to go off on melodic tangents and no longer provide a meaningful back-bone for accompanying instruments. Below is an example that was on the verge of falling into that behavior but maintained just enough structure to still be used with other instruments. The result was varied and interesting.\n\nBelow I paired the above with a melody that was primed by a one-bar midi bass line.\n\nAdding some generated keyboard synth to the above produces an interesting result. The coincidental and chaotic four-bar \u201cintro\u201d is a bit rough to listen to, but right after that there is some interesting interplay between the three instruments. Again no instrument is aware of the other, they were just simply primed with the same tempo, time signature and key. To me this sounds similar to \u201cjam band-style\u201d improvisation.\n\nThe following are a few more arrangements that happen to be little more cohesive and demonstrate that, even with the current current state of Melody RNN not being designed for multiple instruments or multi-track audio, compelling music can be generated.\n\nHere is a lower-tempo example with a single drum track, bass, and synthesizer lead.\n\nLastly, above is an arrangement that was trained by Aphex Twin drums and bass (I found some fan-produced midi, here). To keep the drums interesting, there are four layers of drums here all using the same Roland-808 drum kit.\n\nI intend to do a follow up to this article where I will attempt to generate a variety of musical styles of multitrack RNN-generated music. Please suggest musical styles that you would like to hear in the comments and I\u2019ll try to accommodate.\n\nAnalyzing Six Deep Learning Tools for Music Generation by Frank Brinkkemper", 
        "title": "Generating Multi-track Music with Deep Learning \u2013 Alex Prevoteau \u2013"
    }, 
    {
        "url": "https://medium.com/bbm406f16/week-1-eat-count-a13231123ea2?source=tag_archive---------3----------------", 
        "text": "In today\u2019s world, people are often suffering from health problems caused by misfeeding. Misfeeding can cause some important health problems like obesity, diabetes, heart problems etc. In 2014, more than 1.9 billion adults, 18 years and older, were overweight. Of these over 600 million were obese. As a result of this situation, health and fitness tracking applications are in common use. The project we are going to develop is based on this problem.\n\nWe plan to follow the eating habit of users between certain periods with image recognition. We take photos of the weekly meals from the user then we are going to calculate the calories of these foods. In this way, users will be able to keep the amount of they eat under control. To do it, we need to understand the type of food from the photographs and classify them. Then we will be able to count the calories according to food. In order to classify the foods that we have taken from the user, we need to use a large dataset.\n\nAs a result of our dataset decision, we decided to use a large dataset about food photos which is Food-101. This dataset contains 101 kinds of foods with 101000 food photos. Each kind of food has 1000 photos.\u00a0\n\nIn order to calculate the calories, we need to find another data set about food\u2019s calories. We are planning to collect information about food\u2019s calories and create a table that contains the calories of the food as a data set.\n\nWhile searching for the method that we will use for image recognition part, we encountered various approaches. One of the most commonly used methods was using SVMs with various numbers of features. Image recognition is difficult on food objects because there is too much diversity of foods. The same food may be in different forms as it is a deformable object. Because of these reasons, SVMs do not achieve high accuracies as the number of classes increases. In recent years, neural networks have become a powerful approach that is often used to recognize objects from images. We have seen that the accuracy of the previous studies using Convolutional Neural Networks is close to 80% in 100 classes. For these reasons, we chose deep learning approach to use in this project.", 
        "title": "[Week 1 \u2014 Eat & Count] \u2013 bbm406f16 \u2013"
    }
]