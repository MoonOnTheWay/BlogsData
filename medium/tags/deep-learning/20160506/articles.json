[
    {
        "url": "https://medium.com/@MarcelHorstmann/self-driving-cars-and-smart-home-energy-use-what-do-they-have-in-common-1f29514d6480?source=tag_archive---------0----------------", 
        "text": "They are both enabled by a technology called \u2018deep learning\u2019. Deep learning allows computer algorithms to learn very complex rules and patterns, just by giving the algorithm a set of example data to learn from.\n\nThe deep learning technology has made incredible progress in the past couple of years, and is finding ever more applications in the real world. Speech recognition (think Siri, GoogleNow,\u00a0\u2026) is a famous and now established example. Self-driving cars is another very prominent and disruptive one that is just on the verge of becoming mass-market viable. In my work as a data scientist at ONZO (www.onzo.com), we\u2019re using deep learning to bring transparency to utility bills.\n\nWhy is it relevant?\n\nWorldwide, utilities are trying to \u2018go digital\u2019 with the aim of delivering a much better customer experience. Current electricity customers are rightfully upset when receiving an expensive bill, that just states cryptic numbers: 3682kWh, $920.50!\n\n\u201cWhat can I do about it?\u201d\n\nThese are the questions on the minds of millions of utility customers worldwide. Thousands of utility call-center service workers know them all too well. The problem is: Without a detailed insight into where that electricity actually went, the question is very hard to answer, and it is hard to keep the customer happy.\n\nThis is where load disaggregation comes into play: This technology, applied to ever more available smart meter data, breaks the utility bill down into its components (consumption of the fridge, the washing machine, the EV,\u00a0\u2026.), allowing detailed insights into where the electricity (and the money!) actually went. Was it that innocent looking space heater, which has been running for months on end? Or that old inefficient fridge in the garage, that we forgot to turn off after the last BBQ?\n\nOur algorithms deliver these answers. They are based on deep learning allowing these insights to be delivered with both unprecedented accuracy and scale.\n\nFor the self-driving car, think of: \u201cThat pedestrian over there, she\u2019s going to cross the road right in front of us! Brake, now!\u201d\n\nThis is intuitive for human drivers with years of experience. As long as we are paying attention (and are neither drunk nor staring on our iPhone\u2026), we will consistently apply it.\n\nConventional approaches of programming a computer to act in the same way are cumbersome to implement. They require incredible amounts of engineering efforts, as all possible rules, driving scenarios and obstacles have to be precisely written in computer language. A Herculean effort, impossible to execute given the ever changing nature of our roads and cities.\n\nWith deep learning, the computer learns from sets of examples that we provide.\n\nLike a student at driving school, the computer metaphorically looks over our shoulder. The computer can watch what what we do and what is the desired behaviour in any given situation. After a while the computer is allowed to drive, and only corrected when an action taken is not appropriate. These corrections are fed back to the deep learning algorithms, which re-adapt their internal configuration, learning from their mistake. It will not happen again!\n\nCalifornia-based electric car company Tesla Motors is running a very large data collection effort in this space: All their recent cars are equipped with sensors and cameras that monitor a 360\u00b0 view around the car. The self-driving algorithms learn from the collective wisdom of tens of thousands of drivers worldwide.\n\nWe here at ONZO are doing a very similar thing for load disaggregation. Since our inception in 2009, we have been collecting huge amounts of data about different appliances worldwide: How and when they are used. What their power consumption patterns look like.\n\nOur deep learning algorithms are becoming better and better every day at breaking utility bills down into their components. From \u201c3682kWh, $920.50!\u201d, we make \u201c$50 for your washing machine, $100 for the fridge, $80 for cooking\u200a\u2014\u200aand yes, all the rest was due to that smallish space heater!\u201d\n\nThe result is helpful for both the end customer, who gains a much better understanding of their electricity consumption. How they can reduce it, contributing to energy sustainability in their own home. And for the utility, who can now understand the unique needs of their customers:\n\nFirst published on our company website www.onzo.com. We at ONZO are partnering with utilities worldwide to deliver best-in-class customer experience. For a sustainable world, and happy utility customers.", 
        "title": "Self-Driving Cars and Smart Home Energy Use \u2014 What Do They Have in Common?"
    }, 
    {
        "url": "https://medium.com/@memoakten/machine-learning-failure-in-algorithms-data-models-and-context-341d07d504db?source=tag_archive---------1----------------", 
        "text": "But imagine this, imagine that Sarah\u2019s model does work perfectly. She does a great job using Nicole\u2019s training data, Tom\u2019s architecture, Adam\u2019s learning algorithm, and trains a model that correctly finds pedestrians on all of her tests and use cases. She runs the model for many years and it works perfectly. This is a very successful model and everyone is happy!\n\nSo she puts this model online. Not necessarily as a service for others to use, but she\u2019s sharing her research.\n\nYears later Peter also needs a system to find pedestrians in his CCTV footage. He reads Sarah\u2019s paper, looks at her use case and decides that it\u2019s very similar to his. So he downloads Sarah\u2019s code and pre-trained model and tests it with his footage. He tests it for months, and it works perfectly for him too. Great, so he deploys it. But then it fails catastrophically. Why?\n\nThere could be many reasons, but let\u2019s pick one single simple reason why it may fail. Let\u2019s assume it\u2019s because his CCTV footage is interlaced, whereas Sarah\u2019s (and Nicole\u2019s) footage is not (i.e. it\u2019s non-interlaced).\n\nIt turns out that when Peter had tested Sarah\u2019s model for those few months, the pedestrians were always walking slowly, so the interlacing artefacts weren\u2019t significant and Sarah\u2019s model worked for him. But when the model encountered a fast running pedestrian for the first time, many months later, the interlacing artefacts became significant and the detection failed. In Sarah\u2019s use case, she ran the model for many years and it worked fine, even successfully detecting fast running pedestrians. Because her footage is non-interlaced, and that\u2019s what she trained it on\u200a\u2014\u200ai.e. Nicole\u2019s data. But the same model didn\u2019t work for Peter, even though his task is identical and his data is very similar, but not similar enough.\n\nSo the problem is not in Sarah\u2019s model itself. It\u2019s in the context in which Peter deployed the model.\n\nIs Sarah at fault for not having made her model compatible with interlaced footage? If she provided this model as a commercial service, an \u2018end all and be all for pedestrian recognition\u2019 then yes she should have made it compatible with interlaced footage. But if she released the model simply as research which works for her use case, and especially with a typical open-source license: \u2018THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED\u2019 then she should not be expected to cover all use cases\u200a\u2014\u200aand this is how most research is shared these days. However she should probably make a very clear note of \u2018trained with and only tested with non-interlaced footage\u2019. But then, in this day and age who still uses interlaced footage? It\u2019s perhaps not unreasonable to expect that this didn\u2019t cross her mind. [4].\n\nBut I\u2019m only giving the interlaced vs non-interlaced property of the data as an easy to understand hypothetical example. It\u2019s actually very easy to immediately see the difference between interlaced and non-interlaced footage, so if this were the case Sarah or Peter would have noticed it. However, there are many properties of data that are not be so immediately obvious, and can cause similar failures. E.g. continuing on this pedestrian detection example, one can immediately think of real world examples including race, gender, size, shape or even types of clothing (which could be related to culture or economic / social status) to be important factors for failure. And most importantly, failure of the model in the context it\u2019s being deployed. E.g. a model trained for and very successful in New York might not work well in Kabul. Or even a model trained for and very successful in most parts of London might not work in Stamford Hill (an area of London home to Hasidic Jews).\n\nUltimately it\u2019s Peter\u2019s responsibility\u200a\u2014\u200aas the person deploying the model\u200a\u2014\u200ato make sure that the model he decides to use fits his problem and purpose.\n\nBut this is complicated by the fact that he didn\u2019t actually train the model. He might not even have access to the training data. He saw that it successfully worked for Sarah for many years. He also saw that his problem appears to be almost identical to Sarah\u2019s (this is the mistake he ultimately makes). He also saw that it worked successfully for him after months of testing. It is ultimately a \u2018user error\u2019 on Peter\u2019s part. But when he doesn\u2019t even have access to the training data, the architecture, or the learning algorithm used, and he\u2019s so far removed from the creation of the model (he might be the 5th person in the loop, after Nicole, Adam, Tom, Sarah) how could he have predicted this failure?", 
        "title": "Machine Learning failure in algorithms, data, models and context."
    }
]