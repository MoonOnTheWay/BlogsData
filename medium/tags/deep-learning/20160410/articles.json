[
    {
        "url": "https://medium.com/@willjack/deep-learning-the-truth-behind-the-hype-7872d8aa49b9?source=tag_archive---------0----------------", 
        "text": "Deep learning is today\u2019s buzz. It\u2019s a black-magic technology lauded as a cure-all for technical ails at the very least, and in the most extreme, a computational substrate for genuinely intelligent (if not conscious!) machines. Labelling your startup a \u2018deep learning company\u2019 is in vogue (never mind the fact that doing so is often as absurd as calling Domino\u2019s Pizza an oven company), and it seems that every other big tech company is building a research group devoted to it.\n\nIs the buzz merited? Will deep learning totally revolutionize the world? Will companies not investing into this technology be left in the dust of those aboard the hype train? Will deep learning automate all of our jobs?\n\nMany would respond to all of these with an enthusiastic \u201cyes!\u201d, but I want to address the finer points of the matter, and instead deliver a much-needed \u2018sort of\u2026\u2019 With this new clarity we can paint a picture of the road forward for machine intelligence.\n\nDeep learning is the technique of using artificial neural networks that are many layers \u201cdeep\u201d to perform computational tasks. Artificial neural networks are assemblies of simple computational elements assembled in a way loosely resembling human neural tissue. If these networks are carefully tuned, they can perform complex computational tasks. One particularly successful breed of artificial neural networks, Convolutional neural networks, attempt to mirror the structure of the mammalian visual cortex, a part of the brain responsible for object recognition. As one might expect, convolutional networks excel at tasks similar to object recognition.\n\nFor example, a simple convolutional neural network I built was capable of determining a person\u2019s emotion given a picture of their facial expression with an accuracy within 1% of human performance, when it does make errors, the errors are similar to the ones humans make. Truly an amazing system!\n\nDeep learning is exceptionally data hungry. To automate a task with a neural network, one must gather a massive dataset of what information the task requires, and what the task produces as output. The network is trained on this data, attempting to learn how to morph input into a proper output. This works very well, provided one can make the assumption that any future input to the network will be only a small jump away from the space of training data it has already explored. Given this condition it\u2019s not hard to assume that the network will make a good decision.\n\nFor my emotion recognition system, the training dataset consisted of approximately 100,000 images of human faces, each one labelled with one of seven possible emotions. Emotion recognition is a relatively simple task with a very constrained system of outputs, and it still required nearly 100,000 examples to learn properly. Can you imagine if you were trying to build a conversational AI system, and you had to amass a dataset spanning all possible thoughts the system could have, labelled with all possible sentences the system should produce? It\u2019s hardly a tractable problem.\n\nFor each problem one would like to automate with deep learning a large training set of data must be built. Most of the thousands of mundane tasks that people loathe and waste their time on day after day are relatively specific. Specific tasks require large amounts of task specific data to automate. Most specific, mundane tasks in a person\u2019s day to day life aren\u2019t repeated nearly enough to build a dataset big enough for deep learning to be effective. Data-hungriness prevents deep learning technologies from solving specific, but repetitive problems.\n\nDeep learning systems can\u2019t reveal how they make decisions. The decision making processes within a neural network are not interpretable in most neural networks. The neural network I developed for doing emotion recognition cannot tell you what makes a happy face different than an angry face, nor can it tell you why it decided a face was surprised and not angry. For simple tasks like emotion recognition this isn\u2019t much of a problem, but it would be horrible if your deep learning powered AI doctor could not explain to you why it thought you had cancer. There\u2019s work to fix this shortcoming, but little progress has been made. Currently, deep learning cannot make high risk decisions.\n\nDeep learning has issues, and cannot alone bring about the AI-fueled wonderland that many (myself included) dream of. What can be done now? What should be the focus of machine intelligence research?\n\nTwo houses, both alike in dignity\u2026\n\nThe field of AI research is divided into two broad camps: the Symbolists and the Connectionists. They\u2019ve remained divided due to staunchly drawn lines in the academic sand.\n\nThe Connectionists begot deep learning. They believe that the path to developing true computational intelligence is by building computational systems inspired by the neural circuitry of our brain.\n\nThe Symbolists were the prime movers of the field of AI. The paradigm of symbolic AI is to construct massive banks of knowledge and rules about how the world works, often structured as ontologies. Given rules and knowledge, it\u2019s easy to build a system capable of reasoning over them. Symbolic AI systems can make decisions and answer questions deductively and inductively. Furthermore, the decisions and actions a symbolic AI system makes are interpretable! When a symbolic AI system spouts out an answer, one can simply follow the system\u2019s chain of reasoning to figure out why it came to its conclusions. Exemplary work in symbolic AI includes the Cyc project, and the Genesis project.\n\nViewed through the lens of discovering the computational mechanism behind intelligence, the divide between symbolic AI and connectionism is easy to understand\u200a\u2014\u200athe two camps are totally different ideologically. But when developing AI to a practical end, perhaps there\u2019s an opportunity for romance between symbolic and connectionist AI.\n\nSymbolic AI is interpretable, and only needs a set of rules and knowledge to make decisions, seemingly solving two major problems of AI based on deep learning. So why is deep learning all the rage, whereas only academics know of symbolic AI?\n\nSymbolic AI systems are a disaster at learning. The rules and knowledge in a symbolic AI system have to come from somewhere. Often times, the common sense rules and knowledge in a symbolic AI system are hand coded. \u2018Situation specific\u2019 knowledge\u200a\u2014\u200asay the knowledge extracted from a story an AI is trying to understand, is extracted using another set of predefined rules. As one might imagine, it\u2019s intractably hard to hard-code a rule for everything. It\u2019s even harder to define rules that tell a system how to learn new rules and knowledge. Imagine trying to write a set of logical rules that told an AI how to turn the language of a story it was reading into an ontology of all the knowledge and relationships in it\u200a\u2014\u200ait\u2019s dizzying difficult, and perhaps intractable.\n\nHere\u2019s one potential marriage of the two fields we could explore: it seems deep learning excels at recognizing patterns, and symbolic AI is great at making decisions once it has rules and knowledge. What if we used deep learning to build systems to recognize rules and knowledge in data such as raw text, and then given those rules, used symbolic AI to do reasoning? You\u2019d only need to train a system to \u2018read\u2019 once, and it would thereafter be able to learn from all sorts of information at an incredibly rapid rate. What\u2019s more, it would be capable of making decisions backed up by chains of reasoning, and the specific sources of it\u2019s knowledge.\n\nAnother thought experiment: by leveraging a concert of symbolic AI and deep learning, you could create systems that build themselves out of tiny neural networks specialized for a very specific but generalizable subtasks. This doesn\u2019t seem to be too far off from the way humans think. If someone hands me a picture, and commands me to \u2018count all the pink elephants\u2019 I\u2019ll first look for elephants in the picture, identify the pink ones, and count those up.\n\nThe traditional deep learning approach to solving the problem of counting pink elephants would be to train a neural network on a dataset of hundreds of thousands of pictures of multiple elephants, painstakingly hand-labelled with the number of pink elephants in them. Needless to say, this might be a very hard dataset to come by, especially because pink elephants don\u2019t actually exist. Instead, we could use symbolic methods to parse the sentence \u2018count all the pink elephants in this picture\u2019 into a few simple subtasks, and then assemble the necessary networks for those tasks\u200a\u2014\u200asimilar to how humans would think about this.\n\nFor example, we could break the request into the subtasks \u2018select elephants\u2019, \u2018of the selected objects, only select pink objects\u2019, and \u2018count all selected objects\u2019. For each subtask, you could train a neural network using a readily available dataset demonstrating the concept of the task: what the shape of an elephant looks like, what a pink thing is, and what counting is. With a large enough grab-bag, you could recycle neural modules and build highly complex networks to solve specific tasks without amassing any new dataset whatsoever. This significantly reduces the data hungriness problems of current pure deep learning systems. What\u2019s more, the well defined architecture of this system would give us insight into how it carries out everything that it\u2019s tasked with.\n\nWhile the example of pink elephants is a little outrageous, it highlights something amazing. Modular networks would be able to reason about objects and scenarios they\u2019ve never seen before, like pink elephants. It\u2019s not hard to think of how you could use similar methods to count and describe tumors in x-ray images, or identify pedestrians in the field of view of a self-driving car, or read over all the newest medical literature to find novel treatments for lung cancer.\n\nCertain research groups are already hybridizing deep learning with symbolic approaches to AI, often with great success.\n\nA modular network system similar to the one described has already been implemented by Jacob Andreas et al. at Berkeley. Their system achieved state of the art results in question answering, with a high degree of interpretability.\n\nPedro Domingos\u2019 group has made some significant strides in machine reading, often by leveraging a concert of deep and symbolic approaches to intelligence.\n\nJoshua Tenenbaum et al\u2019s system for visual continuation learning has shown unprecedented ability to learn grounded symbolic concepts of objects it \u201csees\u201d. This represents major strides forward in improving the interpretability of deep models.\n\nIt seems to me that neither deep learning nor symbolic AI will bring about a world where humans can focus on human things rather than mundane, repetitive tasks. Hybridizing connectionism and symbolic approaches to AI presents a wealth of opportunities to move forward in pursuit of that goal.", 
        "title": "Deep learning: the truth behind the hype \u2013 Will Jack \u2013"
    }, 
    {
        "url": "https://andrewfung.ca/designing-services-in-the-age-of-chat-bots-55453f90c25b?source=tag_archive---------1----------------", 
        "text": "Beyond understanding where the chat bot sits in relation to all other service interactions\u200a\u2014\u200aa chat bot needs to be intentionally designed in a way to capture the sentiments of the service, specifically in the tone it is using to speak with people. Just as the content across a service is thoughtfully designed (well hopefully, if not, do that first), that same thoughtfulness needs to be extended to the chat bot\u2019s language. More importantly, unlike traditional static information that people consume or interact with, a chat bot is perceived to be able to respond semi-intelligently to people\u2019s requests, as a result, an additional layer needs be considered: A chat bot must not only sound professional, but it needs to display some basic level of empathy that resonates appropriately with the people interacting with it. I know I could get ripped apart for saying this since empathy is meant to be developed between human being. However, if a chat bot does indeed become the first point in contact in a service, trust building needs to begin right at that moment. After all, the foundation for trust is empathy.\n\nWhen developing the language of a chat bot, begin by learning how people are speaking to your business right now. In this case, we can follow the \u201cstart with why\u201d method:\n\nWhy are people reaching out to your service in the first place?\n\nHow are people speaking to you right now? Are they happy, sad, angry or simply just neutral?\n\nWhat words are they using? What device are they reaching out from?\n\nBy understanding how people currently speak with your service, valuable insights can be uncovered in informing how the chat bot should speak. It is of utmost importance that a thorough tone audit happen before a chat bot is shipped. At worst, a chat could just be perceived as an automated message response, which is far from the promise of an intelligent service agent.", 
        "title": "Designing services in the age of chat bots \u2013"
    }, 
    {
        "url": "https://medium.com/@timgrindall/how-ai-will-help-us-ec2bd409aaf6?source=tag_archive---------2----------------", 
        "text": "Artificial Intelligence has always been the darling of storytellers since the idea was first envisioned. In the stories robots either serve us or rise against us. But it has never been within the realm of possibility until now. Great strides have been made in cognitive computing and true artificial intelligence is only a matter of time.\n\nDeep Learning is a technology that interests me greatly and is now on the forefront of technology advances. Deep Learning uses neural networks to simulate how the human brain works and so far has been able to do some amazing stuff. It\u2019s very brain like in the way it works. I think the closer we get to the human brain for AI advances, the closer we\u2019ll get to true AI. Technological innovations in the past have always been most successful when following the design God has put in nature. The human eye came before camera lenses, Birds came before human flight, Bats built in sonar came before human sonar technology. God\u2019s design provided the inspiration for many designs we see today.\n\nPeople have long sought the path to true Artificial Intelligence and have done so using many different methods. Most of these methods are very different from how the human brain works. Most use discrete measurements of the world and are not very good at adapting to noise in the data and are very rigid when it comes to their logic. This makes them very good for a quantified problem but not very good at handling unexpected problems and being flexible in their approach to problems. I believe neural networks are the future of AI. The design of the human brain just can\u2019t be surpassed.\n\nThe human brain is a very complicated and well thought-out design. I think we would do well to copy it. It\u2019s not just a neural network, it\u2019s a complicated feedback and feed forward system that uses invariant representations to recognize patterns and remember them later. The neocortex uses a hierarchal system of memory to remember patterns and to respond to input. I learned about this system in a book called On Intelligence by Jeff Hawkins. The theory for how the brain works that was proposed in this book has stuck with through the years and I think researches should take advantage of it. The only place were going to get true artificial intelligence is in the design of the human brain. Researchers have tried to solve the problem using their own way for decades and have mostly failed. If more people would study this theory of how the brain works progress would come much sooner. If you\u2019re interested in learning more, I\u2019d recommend you read the book Jeff wrote\u200a\u2014\u200aIts a doozer. The era of machine intelligence is on us and neural networks using the principles of the brain will lead the way.", 
        "title": "Why we should follow the design of the human brain \u2013 Timothy Grindall \u2013"
    }
]