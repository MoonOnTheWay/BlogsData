[
    {
        "url": "https://medium.com/deepgram/search-through-sound-finding-phrases-in-audio-49fd62315698?source=tag_archive---------1----------------", 
        "text": "In January 2015 my Co-Founder and I were kicking around the idea of a search engine that would let a person find phrases in a block of audio. We were looking for something that could peer into interviews, podcasts, video lectures\u200a\u2014\u200athings like that. And if it was done right, you would be able to search through many seasons of a certain TV show and find all the crucial moments like, \u201cYou\u2019re fired!\u201d.\n\nWe thought, \u2018This has to exist, right?\u2019. Surprisingly, no. There wasn\u2019t a company out there that really provided the functionality. Certainly not in a way that was useful to us, at least. So we started hacking together a Google-based transcription to see if we can get a barebones prototype going. In a couple days it was running\u200a\u2014\u200asearch for something, and most of the time you got it. Huge pat on the back, right?\n\nReality hit us when we noticed a problem. Sometimes the phrase was definitely spoken\u200a\u2014\u200ayou could hear it plain as day in the audio stream\u200a\u2014\u200abut the search missed it. It turns out this is due to the inaccuracy of automatic speech transcription software.\n\nWe went on a quest to get our hands on some top quality speech recognition bad-assery. What we were met with was another dose of reality; speech recognition is hard. More evidence emerges when you dig into the current audio research scene and notice that this topic is still a very active topic.\n\nThe big tech companies (Google, Microsoft, Apple, etc.) put forth large efforts to get this sort of thing right. Even after that, you generally only get 90% word accuracy. That\u2019s on very clean, well recorded speech. With input sources containing conversational speech of questionable quality\u200a\u2014\u200asay, YouTube videos\u200a\u2014\u200athe word error rate get pretty bad (more than half is wrong sometimes!).\n\nThis got us wondering, \u2018can we improve the audio search situation?\u2019. We landed on something we think is pretty good\u200a\u2014\u200asearch based on how a phrase sounds, not on the precise spelling in text. We were sure this would provide better results but we weren\u2019t sure just how much better it would be.\n\nWe dug into research to see if this technique had been tried in a production form. We turned up quite a few papers\u200a\u2014\u200amost were not totally relevant\u200a\u2014\u200abut a Google academic paper on searching through political speeches from 2008 was striking. \u2018What was their method?\u2019, you might wonder. They used just regular old text transcription with no additional incorporation of the way the audio actually sounded. Bummer, right?\n\nWhat we were stumbling across was what speech researchers call keyword search. There is an existing method for doing this called acoustic keyword spotting, but that requires reprocessing the data every time for each and every search\u200a\u2014\u200athat\u2019s totally impractical. So, yeah, applying this idea is a fairly difficult problem. We didn\u2019t really know just how hard at the time, but we know now (eight months of coding our first search engine and starting a company along the way helps beat that into you).\n\nWe landed on a phonetic representation of the audio. You\u2019ve seen that in a dictionary right? We built software that allows you to upload audio and have the server process that audio into a giant searchable lattice. With a lattice like this, you can fuzzily go through the entire audio file for your search phrase in a fraction of a second. There is a huge improvement using this method when compared to the text-based approach\u200a\u2014\u200asearch recall goes from a tepid 45% to a grin-inducing 90%+. Now we have our secret sauce.\n\nBuilding a web API isn\u2019t what we were trained to do, but we weren\u2019t foreign to hacking all manners of software contraptions into reality for the particle physics experiments we worked on previously. I spent a lot of time getting the pieces of the processing chain into working order and Noah took to building a squeaky clean API and search experience. Now, we have an audio toolbox that allows the user to upload audio/video and search the resulting lattice, all with brutally simple API calls. The API is expanding with custom machine learning efforts to help classify that audio, too. Got a huge pile of call data that you\u2019d love to know what is inside? We can help with that!\n\nThe bulk of the effort was painstakingly completed over the summer with the latter half taking place in a San Mateo startup accelerator: BoostVC. The accelerator culminates with a demo day where we pitch our product to (hopefully very eager) investors that can help Deepgram flourish as an early stage startup.\n\nIf you want to test out Deepgram\u2019s robot ears, you can start by visiting www.deepgram.com. Drop us a line if you think you\u2019ll be able to discover something new with Deepgram.\n\nTest the demo, give feedback, and get early API access at www.deepgram.com.", 
        "title": "Search Through Sound: Finding Phrases in Audio \u2013 Deepgram \u2013"
    }, 
    {
        "url": "https://medium.com/deepgram/deepgram-api-getting-started-504495382ba6?source=tag_archive---------3----------------", 
        "text": "Here we have some instructions on how to work with the Deepgram API. The instructions are given sequentially, so you can easily get your own API key and follow along.\n\nOnce you have generated your key, you can test with a single file (we use a file already hosted on the web for this guide). We run through a few API calls and note their outputs to help demonstrate how the system works.\n\nWe hope that this gives you all the things you need to make testing with your own files a breeze! Let us know if you have any questions or suggestions. We\u2019d love to hear them!\n\nInteracting with the API is as simple as using cURL commands with a JSON body. I am writing this as a supplement to what already exists on api.deepgram.com/doc (so check that out for more terse info!).\n\nThe top level quantity is your userID. This key is important as it gives access uniquely to your data. You manipulate your account by using the userID to check your balance, submit files for processing (you receive a response with a contentID), check the status of the submitted file, query a specific file, and query a group of files. Some of those actions have properties that can be changed like, \u2018how do you want your results sorted?\u2019, but they also have default values and it\u2019s not really necessary to change them for a test.\n\nIncluded you should have in safe keeping a dev key and a starting balance of $20. The key gives you access to the Deepgram API and your starting balance can be used for indexing and searching in your tests. Deductions occur at various rates for indexing and for search (noted below). Further charges may be incurred if utilizing features: full text transcript or keywords, utilizing AI classification techniques like automatic tagging, etc.\n\nI used a test file to generate the commands/text you see below. Here are the details of the file:\n\nNote: The above mp3 could be downloaded and listened to for comparison (e.g. by checking that the search results match with the audio in a media player)\u200a\u2014\u200ait is a ten minute lecture on social epistemology, if you are into that sort of thing.\n\nAlso, you can just straight away test with your own files hosted on a server. That way you wouldn\u2019t have to bother with the test url. You decide what you need!\n\nThere are several types of interactions that you can have with the API. For instance, you can check your balance, submit audio for processing, check the processing status of a file, query a file, searching through a group of files, and tag a file with metadata. If you have add-on AI services, such as automatic tagging and file classification, then your API endpoint will have other commands.\n\nYou can check your account balance very easily with a curl command. In your terminal, do a curl POST with the correct header info to api.deepgram.com like this:\n\nTo submit a file, it must be hosted on a server that is accessible from our API servers. Run the command here with the file URL in place and the file will automatically be downloaded and processed. Right after your submission, the API will return a contentID (keep track of/store that, since it points directly to the file you submitted!).\n\nSince it takes ~real time to process the file, you might want to ping the API to check the file\u2019s status. This can be done with the command below. When the file is processing, you\u2019ll see messages that give the status (like \u201cgen_lattice\u201d), but once the file is finished the command will return a status of \u2018done\u2019.\n\n< -- you'll get something like this when the file is processing\n\n< -- you'll get this once the file is finished and ready to query!\n\nQuerying the file is as simple as running the below command. There are a few properties that are added in to make the querying function with a good all around behavior (sort by time, get rid of results that don\u2019t have a high confidence of being correct, things like that).\n\nThis is the code for a search of \u201csocial epistemology\u201d.\n\nBelow is the return for the query \u201csocial epistemology\u201d.\n\n{\"snippet\": [\"fuller i'm a professor social piz dumas logy at the university\", \"and wise it important epistemology is the branch\", \"terms of this issue of the pista mythology has basically been\", \"of doing business as far as epistemology is concern one\"], \"P\": [0.57404827889915799, 0.69574877064225571, 0.57404827889915799, 0.69574877064225571], \"endTime\": [4.879999999999999, 14.869999999999997, 188.16000000000005, 382.0199999999999], \"startTime\": [3.65, 12.657777777777781, 186.97, 380.81], \"N\": [3, 0, 2, 1]}\n\nThere are other actions you can do such as searching through a group of contentIDs or tagging an object with metadata. You can find examples at http://api.deepgram.com/docs that demonstrate the commands and returns. I hope this helps out!", 
        "title": "Deepgram API: Getting Started \u2013 Deepgram \u2013"
    }
]