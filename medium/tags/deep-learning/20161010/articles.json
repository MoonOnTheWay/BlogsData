[
    {
        "url": "https://medium.com/@Francesco_AI/artificial-intelligence-classification-matrix-77376efe195c?source=tag_archive---------0----------------", 
        "text": "All the problems discussed in the previous posts can create two major cross-sectional problems: the likely event to run out of money before hitting relevant milestones toward the next investment, as well as whether pursuing specific business applications to break even instead of focusing on product development.\n\nIn terms instead of classifying different companies operating in the space, there might be several different ways to think around machine intelligence startups (e.g., the classification proposed by Bloomberg Beta investor Shivon Zilis in 2015 is very accurate and useful for this purpose). I believe though that a too narrow framework might be counterproductive given the flexibility of the sector and the facility of transitioning from one group to another, and so I preferred to create a four-major-clusters categorization:\n\ni) Academic spin-offs: these are the more long-term research-oriented companies, which tackle problems hard to break. The teams are usually really experienced, and they are the real innovators who make breakthroughs that advance the field;\n\nii) Data-as-a-service (DaaS): in this group are included companies which collect specific huge datasets, or create new data sources connecting unrelated silos;\n\niii) Model-as-a-service (MaaS): this seems to be the most widespread class of companies, and it is made of those firms that are commoditizing their models as a stream of revenues. They can appear in three different forms:\n\n1. Narrow AI\u200a\u2014\u200aa company that focus on solving a specific problem through new data, innovative algorithms, or better interfaces;\n\n2. Value extractor\u200a\u2014\u200aa company that uses its models to extract value and insights from data. The solutions usually provided might either integrate with the clients\u2019 stack (through APIs or building specifically on top of customers\u2019 platform) or otherwise full-stacks solutions. All the models offered can be trained (operative models) or to be trained (raw models);\n\n3. Enablers\u200a\u2014\u200aa company that is enabling the final user to do either her own analysis (all-in-one platforms), or allowing companies to make daily workflows more efficient, or eventually unlocking new opportunities through the creation of intermediate products (e.g., applications).\n\niv) Robot-as-a-service (RaaS): this class is made by virtual and physical agents that people can interact with. Virtual agents and chatbots cover the low-cost side of the group, while physical world systems (e.g., self-driving cars, sensors, etc.), drones, and actual robots are the capital and talent-intensive side of the coin.\n\nThe results of this categorization can be summarized into the following matrix, plotting the groups with respect to short-term monetization (STM) and business defensibility.\n\nStarting from the more viable products, the MaaS are the companies with the highest potential to monetize their products in the short term, but also the less defensible. DaaS on the other side is way less replicable, and highly profitable anyway. Academic spin-offs are the long bet, which is based on solid scientific research that makes them unique but not valuable from day one. Finally, RaaS companies are the ones who might face more problems, because of high obsolescence in hardware components and difficulties in creating the right interactive interfaces. This classification is not intended to rank any business based on how good they are, and it does not imply that specific companies belonging to specific classes are not going to be profitable or successful (e.g., X.ai is a high profitable company with a great product into the RaaS area). It is nothing more than a generalization tool useful to look at the sector through the correct lenses.", 
        "title": "Artificial Intelligence Classification Matrix \u2013 Francesco Corea \u2013"
    }, 
    {
        "url": "https://medium.com/@memoakten/retune-2016-part-1-the-dawn-of-deep-learning-672b5490f5a2?source=tag_archive---------1----------------", 
        "text": "(btw, yes I\u2019m going to use tweets as anchors throughout my talk).\n\nFirst, as a slight provocation, I like the metaphor relating the development of artificial intelligence as a means of coping with big data, analogous to the Darwinian evolution of \u2018intelligent\u2019 complex organisms, and eventually consciousness. As simple organisms evolved, some started developing more complex sensorimotor systems. They started acquiring more complex senses and related behaviours, to more optimally react to their environment, evade predators, and find food or mates. They perhaps started needing a higher level of \u2018intelligence\u2019 to manage the higher dimensional data streaming in, so they could make better use of the limited bandwidth in their neural pathways, to make more optimal decisions to feed to the relevant parts of their body, and to take optimal actions. This involves many things, including being very efficient with which sensory input data to process, and elevate to higher levels of cognition, and which sensory input data to suppress, and effectively ignore. In higher organisms still, this may even include learning to model the environment, so as to make more accurate predictions, and thus be more efficient in processing sensory input data. Going even further, to be able to form any kind of social interaction, they may need to learn to model each other. So I can attempt to model and interact with any of you, not as billions of atoms vibrating in a quantum field, not as a huge lump of organic cells moving through space; but as a thinking, feeling individual, as an abstracted high level entity with goals and desires that I can empathise with.\n\nSo intelligence, and big data, go hand in hand. I don\u2019t have more time to go into this today, but I wrote a long post about it if you\u2019re interested. You can find it if you search for this title (here)\u200a\u2014\u200athough I\u2019ll probably write an update for it soon.\n\nBut there\u2019s another, more tangible reason why AI is exploding now, after years of big data.\n\nOne of the reasons is\u00a0\u2026\n\nand data is the new currency. But actually it\u2019s not the data itself which is where the true value lies. It\u2019s what the data says that\u2019s valuable. For many companies like Google, Facebook, Twitter and now countless start-ups, their business models depend on making sense of big data.", 
        "title": "Retune 2016, Part 1: The Dawn of Deep Learning \u2013 Memo Akten \u2013"
    }, 
    {
        "url": "https://medium.com/emergent-future/what-can-ai-actually-do-c61f4150737b?source=tag_archive---------2----------------", 
        "text": "What\u2019s the difference between a forest fire and a hurricane? What\u2019s the difference between bricklaying and architecture?\n\nPredictions of how quickly AI technologies will advance are as plentiful as they are diverse. Often the most extreme predictions garner the most attention, but there are also many experts who are considerably more conservative in their forecasts. Getting a handle on the direction of travel of these technologies would seem to be imperative for the making of both good business decisions and good public policy. How did we get to a position of such uncertainty? How do we figure out what AI can actually do? I\u2019m going to try and sketch some answers to these questions, without resorting to any math, so please bear with me!\n\nBefore turning to the second question I\u2019m going to take a stab at the first. Most public discussion of AI actually refers to a much narrower field: Deep learning or deep neural networks. Neural networks have been studied since the 1950s and for most of their history were considered pretty useless. It\u2019s probably fair to say that interest in them resumed significantly in 2012 in large part thanks to a paper by Krizhevsky, Sutskever and Hinton on image recognition (Hinton now moonlights at Google). Two important things happened here:\n\nSince 2012 huge progress has been made, with neural networks being applied very successfully to a vast and growing set of problems that have stumped AI researchers for decades. Suddenly engineers and researchers were able to solve, with relative ease, problems that a few years earlier were considered unassailable. I think this is source of much of the optimism about the progress of AI in the next few years.\n\nResearchers remained largely ignorant though, as to why these techniques were so effective. There were no known limits on what could be accomplished using this technology. It seemed that all you needed was a big enough neural network and you would have a program capable of learning to perform any task (strong AI). You will notice that I\u2019m using the past tense here, because this question may just have been answered.\n\nIn August two physicists from MIT and Harvard released a paper that goes a long way to explaining why neural networks perform so well at certain tasks. This work hasn\u2019t been peer reviewed yet but hopefully, given its high profile and accessible reasoning, any problems will be uncovered quickly. The main conclusions are that:\n\nSay we want an algorithm that can identify cats in photos. In this case a neural network would be a good choice because:\n\nThese properties of cats make it much easier for a neural network to learn how to recognise them in photos and the same is true for the vast majority of things we usually take photos of. We rarely think about how unusual they are. They\u2019re unusual because of all of the possible combinations of pixels that a photo could consist of, most wouldn\u2019t have these kind of patterns in them. Most possible photos contain no patterns at all, they\u2019re just noise, mess, chaos.\n\nEven of the photos that do contain patterns that can be learned, most don\u2019t have the same properties. Consider another common example of photos that are intensely analysed all of the time, stock prices. Let\u2019s say you want an algorithm that\u2019s going to tell you when the chart of a stock price is from a day when there was some exciting news about the company. Immediately you run into a few problems:\n\nAll of these problems make it difficult to train a neural network to perform this task. When human beings engage in this kind of exercise they combine different sources of knowledge in ways that are difficult to codify simply.\n\nWe\u2019re now ready to attempt an answer to the question that titles this essay. We should expect neural networks to be extraordinarily useful in the natural sciences and those disciplines related to their application (e.g. medicine and mechanical engineering). Even within these disciplines though, there are problems that don\u2019t have these kind of properties. Hurricanes, for example, are famously (and tragically) unpredictable, their future paths depending not just on where the weather system is now, but its entire history.\n\nThe upshot of the this is that neural network powered systems capable of predicting and manipulating the most aspects of physical world apparently face no significant barriers. Even very complicated physical tasks can probably be learned using neural networks small enough to be practical in terms of the computing power they need. A robot that can do the ironing is probably just around the corner!\n\nMoving onto social or intellectual pursuits the picture becomes more complicated. Predicting the monetary value of a building or the success of a military strategy is a problem in which the properties listed above clearly don\u2019t apply. Suggesting that AI would struggle with such tasks isn\u2019t new, but I think we can now begin to understand what makes these cases different.\n\nLearning to physically assemble the Sydney Opera House is a question of learning to adequately manipulate the materials the building is constructed of. It\u2019s a task that can be reduced to a (large) number of simple steps, each of which themselves can be reduced to relatively simple rules governing the behaviour of the materials involved and so on. Predicting that Utzon\u2019s design for the Sydney Opera House would be the winning bid is a qualitatively different kind of task. It requires understanding the history, politics and finance surrounding the bid process and is not reducible to a combination of simpler steps in the same way.\n\nUnderstanding that the effectiveness of neural networks derives from their ability to model the kind of systems common in physics helps us to predict the kind of tasks they will be able to learn successfully. We should expect neural networks to be able to take over a huge variety of tasks where the ability to predict the physical environment is key. Ironing, driving and construction are all fair game. Tasks such as finance, architecture and publishing are likely to be much harder to learn. I don\u2019t think we should expect the robots to be coming for the architects anytime soon.", 
        "title": "What can AI Actually Do? \u2013 Emergent // Future \u2013"
    }, 
    {
        "url": "https://machinelearnings.co/machine-learnings-12-2c0d518a8424?source=tag_archive---------3----------------", 
        "text": "1/ A grieving person used AI to build a bot that talked in her dead friend\u2019s voice. link\n\n2/ Researchers at Google taught robots to acquire new skills through shared experiences with other robots. link\n\n3/ Samsung acquired Viv, an AI assistant built by the creators of Apple\u2019s Siri. link\n\n4/ MIT built a platform to gather a human perspective on moral decisions made by machine intelligence. link\n\n6/ eBay acquires visual search engine, Corrigon, for $30m to build out its machine learning capabilities. link\n\n8/ Machine learning engineer at the University of California argued that \u201cscientists should embrace deep learning without being \u2018too anal\u2019 about the black box\u201d behind an AI\u2019s thoughts. link\n\n9/ Google researchers proposed a methodology for measuring and preventing discrimination in supervised learning. link\n\n10/ The Nature Conservancy launched a campaign to sponsor neural networks that can tell what\u2019s on the end of a fishing line. link\n\nps Thanks to David Woo from Capital One Growth Ventures for recommending a deep learning article this week. It was written before the 10/3 cutoff, but I wanted to include it here.\n\nFollow me on Twitter for the most interesting machine learning news as it breaks during the week.", 
        "title": "AI for a dead friend \u2014 #12 \u2013"
    }, 
    {
        "url": "https://medium.com/@DockerTurtle/how-machine-learning-is-different-than-the-traditional-programming-job-8988bc71e2c0?source=tag_archive---------4----------------", 
        "text": "We are moving to a new World of Problem solving\u00a0!!\n\nTo ->> Programs that learn to solve the problems from Examples, we dont need to write long set of rules and instructions.\n\nAs the Programs learn automatically, they improve with data and time.\n\nIn our programs we have a limited set of instructions and there is a boundary created, to how much a Human written program can do to solve tasks or problems.\n\nBut with ML the programs get more clever.", 
        "title": "How Machine learning is different than the Traditional programming Job?"
    }, 
    {
        "url": "https://medium.com/@reworkyulia/language-understanding-with-memory-networks-85fa49cc8ab3?source=tag_archive---------5----------------", 
        "text": "Despite recent advances in AI, a deep understanding of natural language by machines still remains highly challenging. Antoine Bordes, Research Scientist at Facebook Artificial Intelligence Research (FAIR), is working to change this with \u201cmemory networks\u201d.\n\nMemory Networks is an attention-based neural network architecture that operates an external symbolic memory component to perform reasoning. This can achieve interesting performances on various tasks of question answering and dialogue management, and appears to be a promising avenue towards a better machine comprehension of language.\n\nAt the Machine Intelligence Summit in New York on 2\u20133 November, Antoine will give a presentation on Language Understanding with Memory Networks. I asked him some questions ahead of the summit to learn more about the recent advancements in AI and what we can expect next.\n\nWhat are you working on at Facebook AI Research?\n\nI work at FAIR, the AI research lab of Facebook. Our mission is to advance the development of AI-based technologies. We have the freedom to work on ambitious long-term research programs, much like academic labs do, but with Facebook\u2019s unique infrastructure and scale. For technology transfer, we work closely with Facebook\u2019s Applied Machine Learning group, that is in charge of applying AI at scale within Facebook products. My line of work is built around designing neural networks that can learn to understand language, for building question answering and dialogue systems.\n\nWhat do you feel are the leading factors enabling recent advancements in AI?\n\nMany of the recent breakthroughs are related to Deep Learning and used algorithms that have been known for a while. Their excellent performance has been jointly made possible by the huge increase of computing power (with the development of GPU computing for instance) and by the creation of large labeled datasets (such as ImageNet for image recognition). Both factors made the training of very large deep neural networks possible and successful. Now the time is at the development of new neural networks architectures and training mechanisms to tackle the many remaining challenges such as language understanding or unsupervised learning.\n\nWhat present or potential future applications of machine intelligence excite you most?\n\nThe new frontier of AI right now lies at the understanding of the world and of natural language by machines. We have yet to discover how to teach machines to communicate with humans. This is extremely hard and seems to be only possible if machines can have an understanding of how the surrounding world works. This involves many factors from grasping the laws that drives the motion of objects to feeling why teenagers and baby boomers react differently, for instance.\n\nWhat developments can we expect to see in machine intelligence in the next 5 years?\n\nI think that dialogue systems and more generally language-based interfaces will get much better. I also expect that those interfaces will be personalized for each user and will act as trusted assistants to navigate the digital world.\n\nAntoine Bordes will be speaking at the Machine Intelligence Summit in New York, on 2\u20133 November. Visit the event website here to book at a discounted rate.\n\nOther speakers at the summit include Kamelia Aryafar, Senior Data Scientist, Etsy; Avneesh Saluja, Machine Learning Scientist, Airbnb; Tara Sainath, Senior Research Scientist,Google; Kathryn Hume, President, Fast Forward Labs; and Siddartha Dalal, Chief Data Scientist, AIG.", 
        "title": "Language Understanding with Memory Networks \u2013 Yulia Ivanova \u2013"
    }
]