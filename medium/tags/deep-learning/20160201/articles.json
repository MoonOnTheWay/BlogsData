[
    {
        "url": "https://medium.com/pankajmathur/linear-regression-with-tensorflow-3b55e21c137f?source=tag_archive---------0----------------", 
        "text": "A simple linear regression model builds with TensorFlow. We are using fake data and using numpy arrays to supply them to TensorFlow.\n\nHere are the hyperparameters we choose to run initial model:\n\nWe achieved 0.079 training loss cost in 1000 epochs with a learning rate of 0.01 by running simple linear regression model build with Tensorflow on fake data.\n\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\n\nAssuming you have conda install on your machine, please run the following commands to have tensorflow-playground ready for you to play.\n\nRun the following commands to setup your environment:\n\nAnd installing on Windows. In your console or Anaconda shell:\n\nAfter creating conda environment, clone this repository on your local machine via Git or GitHub Desktop\n\nunder tensorflow-playground environment on your terminal or shell window, cd to the cloned directory and then run following command:\n\nPlease do let me know your thoughts, questions under the comments section. I would really appreciate getting some feedback on this article & ideas to improve it.\n\nIn the meanwhile, Happy Thinking\u2026", 
        "title": "Linear Regression with TensorFlow \u2013 Pankaj Mathur \u2013"
    }, 
    {
        "url": "https://blog.ment.at/the-rise-of-overconfident-machines-bbd5023394ff?source=tag_archive---------1----------------", 
        "text": "At the time of writing, a number of eminent scientists have raised concerns about the potential adverse consequences of the belated rise of Artificial Intelligence. Belated because it has been anticipated since the 1960s, but, until a few years ago, it had not materialised except in toy (albeit challenging) worlds, such as, for example, chess. The last few years have, however, been game changing. Amazon\u2019s robotic warehouses, Google\u2019s visual search, Skype\u2019s automatic voice translation all hint towards what is known in academic circles as \u2018strong AI\u2019, i.e., the ability of a machine to respond to real-world stimuli in ways indistinguishable, or superior, to human behaviour. Put simply, machines can increasingly beat us. And this is significant.\n\nIt is important for two reasons. First, because whenever a piece of technology beats humans in something vital, this usually causes a revolution. When fire beat human saliva in making food safe and digestible, the modern human evolved. When stone tools beat human hands in warfare and hunting, the Stone Age began. Then iron beat stone. Steam. Electricity. The Digital Age. And now Artificial Intelligence.\n\nIt is hard for us to envisage the \u2018next day\u2019 where thinking machines routinely outperform humans. Massive unemployment, the potential for asymmetric warfare and a deepening rich-poor divide have all featured as potential elements of a dystopian AI future. Equally, eradication of disease, poverty and social injustice have also been put forward as a utopic alternative.\n\nHard to tell. Even harder to tell is whether machines will eventually dominate the human race, which some thinkers see as theoretically inevitable\u2026geeky end-of-the-world enthusiasm aside, this is not as extreme as it sounds.\n\nBut there is a more practical, immediate concern, with real implications about the choice of methodology that AI companies like us are building right now. Our worry is that our immediate future will be plagued by overconfident machines. Put differently, if true wisdom is to know what you don\u2019t know, machines are still pretty stupid.\n\nMachine translation will always translate the input text, even if it has to clutch at straws and output junk. A bit like an overeager translation intern, it lacks the wisdom to say \u201cI am not quite sure what this means, sorry\u201d.\n\nThis carries risks that are all-too-real. Our foremost experience of AI will not be in the form of a charming golden robot with a British accent and a lovable sidekick, but rather in the form of hidden automation. And just like a human, an unsupervised machine that thinks too highly of itself can prove catastrophic.\n\nSo is it within our ability to code up \u201cmodesty\u201d and \u201cself-criticism\u201d? Yes, and no.\n\nYes, because, to the relief of statistically-minded machine learning researchers most ML is now probabilistic, which simply means that answers are given in the form of a probability, rather than a straight yes/no. A picture might be a picture of a cat with 90% probability, or with 50% probability. It is then a matter of deciding how best to use this estimated uncertainty on a case-by-case basis, and, when it matters, one can always choose not to report the 50/50s.\n\nUnfortunately, honest reporting of uncertainty remains challenging. Lets briefly examine why that is the case in the two flavours of AI that are \u2018hottest\u2019 right now: Bayesian AI, and Neural Networks (of which Deep Learning is the latest branch).\n\nBayesians are proud in relying on a coherent, all encompassing mathematical framework for expressing uncertainty, and they follow best practices in always reporting probability distributions, rather than point estimates. A Bayesian who is worried about a certain assumption will invariably express that assumption in a \u201cfuzzier\u201d manner, by introducing uncertainty about it in the form of yet another probability distribution\u200a\u2014\u200aassumptions about assumptions. Unfortunately, even the most carefully stacked Bayesian model might still be betrayed by the real world, especially since the computational burden of the Bayesian calculus often force over-simplistic assumptions for the sake of faster computations. Now, assumptions are violated al the time\u200a\u2014\u200athis is not a problem in itself, and to over-engineer the assumption set is not always the right decision. What is problematic, though, is that, if the model assumptions are wrong, it is really hard to know whether the answers are still somewhat valid. Ironically, for more complex models, the problem gets worse, because complex models fail in complicated ways. This results in the following well-kept secret: 40-year old tools such as linear and logistic regression are still the workhorses of business intelligence and advanced analytics. Users will call them \u201creliable\u201d. The correct technical term is \u201crobust\u201d, which, in statistics parlour, means, roughly speaking, a model that tends to remain pretty accurate even when its assumptions somewhat break down. Not all is lost of course\u200a\u2014\u200aBayesians are aware of this problem, and are working on it. But to this day off-the-shelf AI will not generally come with strong robustness guarantees, these have to be engineered into the system separately.\n\nWhat about deep learning? Such methods are often referred to as \u2018black-boxes\u2019\u00a0, and typically involve a highly parameterised input-output relationship fitted to the data via optimisation using a training dataset. These algorithms are fascinatingly complex and correspondingly powerful (indeed at Mentat we are building our own deep learning library for IoT cybersecurity right now). However, their complexity, and the fact that parameters of deep learning models are not really meaningful in themselves (technically speaking, they are not generally viewed as random variables or population parameters), makes it incredibly difficult for them to report their own uncertainty. Deep learning is in many ways similar to deep thinkers, or our lizard brains: it knows the answer instinctively, but cannot explain why.\n\nThat this should be a challenge is not surprising. Self-criticism, or, more broadly, self-reflection is one of the most elusive, and important, aspects of intelligence. Indeed, a certain school of thought in the philosophy of mind lists the ability to self-reflect as the defining characteristic of consciousness. Needless to say, humans do not always exhibit such intelligence themselves: cognitive biases, racism, fanaticism are all in many ways consequences of the inability to question one\u2019s assumptions. However, the human race as a whole has historically demonstrated exquisite abilities to self-reflect, and reason about assumptions about assumptions, a little like the nested Bayesian model above.\n\nThe former consists in introducing failsafes into models that allow them to decrease their confidence when they feel overstretched (shrinkage in classical machine learning is a wonderful example of a simple solution to a difficult problem, and analogous techniques are applicable in almost all AI/ML algorithms, albeit with much greater care and technical difficulty at times). Failsafes against the possibility that the data-generating process changes over time is in fact a core innovation in our Machine Learning In Motion toolbox, and an unrecognised performance bottleneck in many competing offerings. Model diagnostics complement robustness and stem from an approach that was all-the-craze in the golden era of classical statistics, consisting in tracking performance indicators of the model, and taking suitable action when they take unreasonable values. This may sound mundane (who doesn\u2019t keep track of their model\u2019s performance?) but the art of diagnostics is in constructing the right statistic, and understanding the range of values it should be allowed to take without raising an alarm\u200a\u2014\u200aa challenging mathematical problem, when done correctly. Thankfully, recent methodological developments can allow us to do both tasks with generality.\n\nThere is, of course, a lot more to \u201cself-reflection\u201d than what was explored here, but self-diagnostic, robust model-based ML is an excellent starting point.\n\nSome time ago, a member of our university study group, after a long period of intense, silent thinking aimed at solving an infamous maths past paper question, announced: \u201cAm I talking cr@p? That is the question.\u201d Simply put we should not fully trust Thinking Machines until we can witness them spontaneously make a similar claim.", 
        "title": "The Rise of Overconfident Machines \u2013"
    }, 
    {
        "url": "https://medium.com/deepgram/create-a-deepgram-account-fb00257c2beb?source=tag_archive---------2----------------", 
        "text": "Hey! With Deepgram you can easily create an account that let\u2019s you index, fuzzy search, and transcribe speech from audio and video. When you sign up you get 40 hours free to use all the features of Deepgram\u2019s API.\n\nSo, you want an account? It\u2019s really simple. Go to www.deepgram.com and you\u2019ll see this.\n\nYou see that awesome pink rectangle at the bottom? That\u2019s where you sign up and dispense an amazingly luxurious API key.\n\nClick it and get whisked away to a sign up form.\n\nDrop in your name, email, pick a password, and you\u2019ll be on your way to a land of happy speech transcribers and fuzzy searching gurus.\n\nIt really is that easy. You are now the proud owner of a Deepgram account with a freshly minted 40 hours of credit sitting in there.\n\nNow that you have all this power, what will you do with it? Well, silly, you should drop some files into the Deepgram console to start that processing!\n\nSee that upload button? You can select files (one or more) and drop \u2019em right in there. They will upload from your computer straight to your Deepgram account and start indexing.\n\nDon\u2019t have any files on your computer but want to upload a YouTube video? No problem! Just drop in the YouTube URL and hit submit.\n\nAfter you\u2019ve uploaded some files then you can check out the \u201cmy files\u201d section of the Deepgram console. In there you\u2019ll find your files and their status. If you have just uploaded the files then they will take a bit to index. They\u2019ll finish up and then you\u2019ll be able to search through them.\n\nYou can search through all files at once to find the best result\u200a\u2014\u200awhere did they say \u2018give me the potato!\u2019 again? Or, you can search in a specific video by clicking on the video and going to the viewer.\n\nThe file takes a couple minutes to index, so you\u2019ll see this next screen if you click on the file.\n\nAfter indexing you can search and navigate through the results to find where the phrase was spoken. There are cute red markers on the timeline to indicate where the results are located and you can click NEXT or BACK to go between the most likely results. There\u2019s also a full transcript available below the player (just click the transcript button).\n\nIf you have content with fairly good audio quality then you\u2019ll see a readable transcript. If the audio quality isn\u2019t that great then the transcript might not be amazing, but don\u2019t fret! The transcript doesn\u2019t have to be perfect to effectively search through video and audio because Deepgram\u2019s awesome fuzzy search can still figure out where the phrases are mentioned.\n\nHey developers! Deepgram is based on an API and you get a free API key with your account. If you are a programmer with a wee little bit of cURL or Python skills, then all you need to do is scroll to the bottom of your dashboard page to reveal the key, then check out our Getting Started with the Deepgram API blog post to try out our RESTful API.", 
        "title": "Create a Deepgram Account \u2013 Deepgram \u2013"
    }
]