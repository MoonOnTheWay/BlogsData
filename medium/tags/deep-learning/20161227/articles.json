[
    {
        "url": "https://towardsdatascience.com/deep-learning-basic-mathematics-for-deep-learning-a82981e95e3b?source=tag_archive---------0----------------", 
        "text": "Before getting started with neural networks and deep learning, lets discuss about the basic mathematics required to understand them. I will try to cover some important mathematics topic that would be required to understand further topics of deep learning. This article contains short notes from Deep Learning Book.\n\nLinear algebra is a form of continuous rather than discrete mathematics, many computer scientists have little experience with it. A good understanding of linear algebra is essential for understanding and working with many machine learning algorithms, especially deep learning algorithms.\n\nThe study of linear algebra involves several types of mathematical objects they are as follows:\n\nOne important operation on matrices is the transpose. The transpose of a matrix is the mirror image of the matrix across a diagonal line, called the main diagonal, running down and to the right, starting from its upper left corner. We denote the transpose of a matrix A as A\u00b4, and it is de\ufb01ned such that A\u00b4(i,j) = A(j,i).\n\nIn the context of deep learning, we also use some less conventional notation.We allow the addition of matrix and a vector, yielding another matrix: C = A+b, where C(i,j) = A(i,j) + b(j). In other words, the vector b is added to each row of the matrix. This shorthand eliminates the need to de\ufb01ne a matrix with b copied into each row before doing the addition. This implicit copying of b to many locations is called broadcasting.\n\nThe transpose of a matrix product has a simple form: (AB)\u00b4= B\u00b4A\u00b4. The matrix inverse of A is denoted as A^-1\u00a0, and it is de\ufb01ned as the matrix such that A^-1A = I (I is Identity matrix). However, A^\u22121 is primarily useful as a theoretical tool, and should not actually be used in practice for most software applications.Because A^\u22121 can be represented with only limited precision on a digital computer, algorithms that make use of the value of b can usually obtain more accurate estimates of x.\n\nSome topics that need to be understand.\n\nSometimes we need to measure the size of a vector. In machine learning, we usually measure the size of vectors using a function called a norm. Given by:\n\nNorms, including the L^p norm, are functions mapping vectors to non-negative values. On an intuitive level, the norm of a vector x measures the distance from the origin to the point x. More rigorously, a norm is any function f that satis\ufb01es the following properties:\n\nSo we can say that The L\u00b2 norm, with p= 2, is known as the Euclidean norm as it is simply Euclidean distance from origin.\n\nMany mathematical objects can be understood better by breaking them into constituent parts, or \ufb01nding some properties of them that are universal, not caused by the way we choose to represent them. For example, integers can be decomposed into prime factors. The way we represent the number 12 will change depending on whether we write it in base ten or in binary, but it will always be true that 12 = 2\u00d72\u00d73. From this representation we can conclude useful properties, such as that 12 is not divisible by 5, or that any integer multiple of 12 will be divisible by 3.\n\nIn the same way we can also decompose matrices in ways that show us information about their functional properties. One of the most widely used kinds of matrix decomposition is called eigen-decomposition, in which we decompose a matrix into a set of eigenvectors and eigenvalues.\n\nAn eigenvector of a square matrix A is a non-zero vector v such that multiplication by A alters only the scale of v:\n\nThe scalar \u03bb is known as the eigenvalue corresponding to this eigenvector. A visual representation of eigenvalue and eigenvector is show in Fig 1.\n\nThe eigen decomposition of a matrix tells us many useful facts about the matrix.\n\nThe singular value decomposition(SVD) provides another way to factorize a matrix, into singular vectors and singular values. The SVD allows us to discover some of the same kind of information as the eigen decomposition. However the SVD is more generally applicable. Every real matrix has a singular value decomposition, but the same is not true of the eigenvalue decomposition. For example, if a matrix is not square, the eigen decomposition is not de\ufb01ned, and we must use a singular value decomposition instead.\n\nThe singular value decomposition is similar, except this time we will write A as a product of three matrices:\n\nSuppose that A is an m \u00d7 n matrix. Then U is de\ufb01ned to be an m \u00d7m matrix, D to be an m \u00d7 n matrix, and V to be an n \u00d7 n matrix. Each of these matrices is de\ufb01ned to have a special structure. The matrices U and V are both de\ufb01ned to be orthogonal matrices. The matrix D is de\ufb01ned to be a diagonal matrix. Note that D is not necessarily square. The elements along the diagonal of D are known as the singular values of the matrix A. The columns of U are known as the left-singular vectors. The columns of V are known as as the right-singular vectors.\n\nMatrix inversion is not de\ufb01ned for matrices that are not square. Suppose we want to make a left-inverse B of a matrix A, so that we can solve a linear equation:\n\nAx = y\n\nby left-multiplying each side to obtain x = By.\n\nIf A is taller than it is wide, then it is possible for this equation to have no solution. If A is wider than it is tall, then there could be multiple possible solutions.\n\nThe Moore-Penrose pseudoinverse allows us to make some headway in these cases. The pseudoinverse of A is de\ufb01ned as a matrix\n\nPractical algorithms for computing the pseudoinverse are not based on this de\ufb01nition, but rather the formula\n\nHow it is significant\u00a0?\n\nWhen A has more columns than rows, then solving a linear equation using the pseudoinverse provides one of the many possible solutions. Speci\ufb01cally, it provides the solution x = (A+)y with minimal Euclidean norm ||x||\u00b2 among all possible solutions.\n\nWhen A has more rows than columns, it is possible for there to be no solution. In this case, using the pseudoinverse gives us the x for which Ax is as close as possible to y in terms of Euclidean norm ||Ax \u2212 y||\u00b2.\n\nsuppose s and t are two vectors of the same dimension. Then we use s\u2299t to denote the elementwise product of the two vectors. Thus the components of s\u2299t are just (s\u2299t)j=sjtj. As an example,\n\nPlease provide your feedbacks, so that I can improve in further articles.", 
        "title": "Deep Learning: Basic Mathematics for Deep Learning \u2013"
    }, 
    {
        "url": "https://chatbotslife.com/check-out-this-new-video-a-friendly-introduction-to-neural-networks-and-deep-learning-50a1375585fd?source=tag_archive---------1----------------", 
        "text": "In it, we introduce a pictorial way to understand the main concepts of deep learning: Gradient descent, activation functions, logistic regression, and neural networks. No heavy math background required.\n\nComments, suggestions, questions are welcome. And if you liked it, please help me share it!", 
        "title": "A friendly introduction to Neural Networks and Deep Learning"
    }, 
    {
        "url": "https://chatbotslife.com/deep-learning-publication-collections-de51e8b6ab9a?source=tag_archive---------2----------------", 
        "text": "For the last couple of months I\u2019ve been creating collections of recent academic publications in various subfields of Deep Learning on my blog https://amundtveit.com\u200a\u2014\u200aThis posting gives an overview of 25 collections.\n\nThis posting is recent papers related to residual networks (i.e. very deep networks). Check out Microsoft Research\u2019s paper Deep Residual Learning for Image Recognition and Kaiming He\u2019s ICML 2016 Tutorial Deep Residual Learning, Deep Learning Gets Way Deeper\n\nTraffic Sign Detection and Recognition is key functionality for self-driving cars. This posting has recent papers in this area. Check also out related posting: Deep Learning for Vehicle Detection and Classification\n\nThis posting has recent papers about vehicle (e.g. car) detection and classification, e.g. for selv-driving/autonomous cars. Related: check also out Nvidia\u2018s End-to-End Deep Learning for Self-driving Cars and Udacity\u2018s Self-Driving Car Engineer (Nanodegree).\n\nThis blog post has some recent papers about Deep Learning with Long-Short Term Memory (LSTM). To get started I recommend checking out Christopher Olah\u2019s Understanding LSTM Networks and Andrej Karpathy\u2019s The Unreasonable Effectiveness of Recurrent Neural Networks. This blog post is complemented by Deep Learning with Recurrent/Recursive Neural Networks (RNN)\u200a\u2014\u200aICLR 2017 Discoveries.\n\nThis posting has recent publications about Deep Learning in Finance (e.g. stock market prediction)\n\nThis posting is about Deep Learning for Information Retrieval and Learning to Rank (i.e. of interest if developing search engines). The posting is complemented by the posting Deep Learning for Question Answering. To get started I recommend checking out Jianfeng Gao\u2018s (Deep Learning Technology Center at Microsoft Research) presentation Deep Learning for Web Search and Natural Language Processing.\n\nOf partial relevance is the posting Deep Learning for Sentiment Analysis, the posting about Embedding for NLP with Deep Learning, the posting about Deep Learning for Natural Language Processing (ICLR 2017 discoveries), and the posting about Deep Learning for Recommender Systems\n\nThis posting presents recent publications related to Deep Learning for Question Answering. Question Answering is described as \u201ca computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language\u201d. I\u2019ll also publish postings about Deep Learning for Information Retrieval and Learning to Rank today.\n\nEnsemble Based Machine Learning has been used with success in several Kaggle competitions, and this year also the Imagenet competition was dominated by ensembles in Deep Learning, e.g. Trimps-Soushen team from 3rd Research Institute of the Ministry of Public Security (China) used a combination of Inception, Inception-Resnet, Resnet and Wide Residual Network to win the Object Classification/localization challenge. This blog post has recent papers related to Ensembles in Deep Learning.\n\nRecently I published Embedding for NLP with Deep Learning (e.g. word2vec and follow-ups) and Deep Learning for Natural Language Processing\u200a\u2014\u200aICLR 2017 Discoveries\u200a\u2014\u200athis posting is also mostly NLP-related since it provides recent papers related to Deep Learning for Sentiment Analysis, but also has examples of other types of sentiment (e.g. image sentiment).\n\nGaussian Process is a statistical model where observations are in the continuous domain, to learn more check out a tutorial on gaussian process (by Univ.of Cambridge\u2019s Zoubin G.). Gaussian Process is an infinite-dimensional generalization of multivariate normal distributions.\n\nResearchers from University of Sheffield\u200a\u2014\u200aAndreas C. Damanianou and Neil D. Lawrence\u200a\u2014\u200astarted using Gaussian Process with Deep Belief Networks (in 2013). This Blog post contains recent papers related to combining Deep Learning with Gaussian Process.\n\nEEG (Electroencephalography) is the measurement of electrical signals in the brain. It has long been used for medical purposes (e.g. diagnosis of epilepsy), and has in more recent years also been used in Brain Computer Interfaces (BCI)\u200a\u2014\u200anote: if BCI is new to you don\u2019t get overly excited about it, since these interfaces are still in my opinion quite premature. But they are definitely interesting in a longer term perspective\u00a0.\n\nThis blog post gives an overview of recent research on Deep Learning in combination with EEG, e.g. r for classification, feature representation, diagnosis, safety (cognitive state of drivers) and hybrid methods (Computer Vision or Speech Recognition together with EEG and Deep Learning).\n\nWord Embedding was introduced by Bengio in early 2000s, and interest in it really accelerated when Google presented Word2Vec in 2013.\n\nThis blog post has recent papers related to embedding for Natural Language Processing with Deep Learning. Example application areas embedding is used for in the papers include finance (stock market prediction), biomedical text analysis, part-of-speech tagging, sentiment analysis, pharmacology (drug adverse effects).\n\nI recommend you to start with the paper: In Defense of Word Embedding for Generic Text Representation\n\nZero-Shot Learning is making decisions after seing only one or few examples (as opposed to other types of learning that typically requires large amount of training examples). Recommend having a look at An embarrassingly simple approach to zero-shot learning first.\n\nAlzheimer\u2019s Disease is the cause of 60\u201370% of cases of Dementia, costs associated to diagnosis, treatment and care of patients with it is estimated to be in the range of a hundred billion dollars in USA. This blog post have some recent papers related to using Deep Learning for diagnostics and decision support related to Alzheimer\u2019s disease.\n\nThis blog post presents recent research in Recommender Systems (/collaborative filtering) with Deep Learning. To get started I recommend having a look at A Survey and Critique of Deep Learning in Recommender Systems.\n\nUltrasound (also called Sonography) are sound waves with higher frequency than humans can hear, they frequently used in medical settings, e.g. for checking that pregnancy is going well with fetal ultrasound. For more about Ultrasound data formats check out Ultrasound Research Interface. This blog post has recent publications about applying Deep Learning for analyzing Ultrasound data.\n\nDeep Learning (creative AI) might potentially be used for music analysis and music creation. Deepmind\u2019s Wavenet is a step in that direction. This blog post presents recent papers in Deep Learning for Music.\n\nThis blog post gives an overview of papers related to using Regularization in Deep Learning submitted to ICLR 2017, see underneath for the list of papers. If you want to learn about Regularization in Deep Learning check out: www.deeplearningbook.org/contents/regularization.html\n\nThis blog post gives an overview of papers related to Unsupervised Deep Learning submitted to ICLR 2017, see underneath for the list of papers. If you want to learn about Unsupervised Deep Learning check out: Ruslan Salkhutdinov\u2019s video Foundations of Unsupervised Deep Learning.\n\nThis blog post gives an overview of papers related to autoencoders submitted to ICLR 2017, see underneath for the list of papers. If you want to learn about autoencoders check out the Stanford (UFLDL) tutorial about Autoencoders, Carl Doersch\u2019 Tutorial on Variational Autoencoders, DeepLearning.TV\u2019s Video tutorial on Autoencoders, or Goodfellow, Bengio and Courville\u2019s Deep Learning book\u2019s chapter on Autencoders.\n\nThis blog post gives an overview of papers related to stochastic/policy gradient submitted to ICLR 2017, see underneath for the list of papers.\n\nThis blog post gives an overview of Deep Learning with Recurrent/Recursive Neural Networks (RNN) related papers submitted to ICLR 2017, see underneath for the list of papers. If you want to learn more about RNN check out Andrej Karpathy\u2019s The Unreasonable Effectiveness of Recurrent Neural Networks and Pascanu, Gulcehre, Cho and Bengio\u2019s How to Construct Deep Recurrent Neural Networks.\n\nThis blog post gives an overview of Deep Learning with Generative and Adverserial Networks related papers submitted to ICLR 2017, see underneath for the list of papers. Want to learn about these topics? See OpenAI\u2019s article about Generative Models and Ian Goodfellow et.al\u2019s paper about Generative Adversarial Networks.\n\nThis blog post gives an overview of Natural Language Processing related papers submitted to ICLR 2017, see underneath for the list of papers. If you want to learn about Deep Learning with NLP check out Stanford\u2019s CS224d: Deep Learning for Natural Language Processing", 
        "title": "Deep Learning Publication Collections \u2013"
    }, 
    {
        "url": "https://chatbotslife.com/quantum-deep-learner-95499aa5335c?source=tag_archive---------3----------------", 
        "text": "I am huge fan of mix-n-matches and especially using things in places you least expect it to be used, the Indian in me calls this jugaad. Needless to say, this naturally extends to mashing one of my passions, deep learning and one of my long time curiosities, Quantum Mechanics.\n\nThere has been some work in using Quantum Computing in Classical Machine Learning algorithms, you can checkout videos from Seth Lloyd and his books to see how this works (Highly recommended!). The natural extension was how to use Quantum Computing and Quantum Mechanics in general to Deep Learning.\n\nI see two obvious approaches here, the first is to use the mathematical machinery of Quantum Mechanics to create energy based models of Deep Neural Nets, this ties nicely with the notions of entropy from Information Theory and can rope in topics from Solid-State Mechanics and Statistical Physics. Checkout the theory of Boltzmann machines to get a flavor of this intersection. As far as I know, there seems to be very little action on this front (please correct me if I am wrong). The second is to use a Quantum Computer to run backpropagation and compute the minima. This, again, is definitely not straightforward and is not as easy as from quantum_computer import NN\n\nA third, more engineering like approach, that I have been thinking about is directly exploiting the quantum properties of physical systems to mimic a deep neural net. This needs a bit more explanation.\n\nLet\u2019s take a neuron, let it be a perceptron, sigmoid, ReLU, doesn\u2019t matter. Let\u2019s define its free state as its state when not connected to any input and not giving out any output. Let the \u201cenergy\u201d associated with this state be Infinity. This assignment is not arbitrary and will become obvious later on.\n\nNow, let\u2019s take this neuron and link it with a data source (inputs) and a data sink (outputs). We can define the energy of the neuron simply as the difference between the neuron\u2019s output and the actual label. Of course, one can use (and should) use different energy definitions like cross-entropy or other suitable metrics as may be needed.\n\nCoupling more neurons together into a neural net, we can generalize the definition of energy of each neuron as a function of the expected output and the actual output computed by the neuron. This is notion is similar to the one used in backpropagation.\n\nWe can further define the state of the neuron as the weight vector associated with it and also consider the activation function as the way by which a neuron transfers data from the source to the sink.\n\nGoing back to high-school thermodynamics, consider an iron rod between a heat source and a heat sink, in some ambient temperature T (this will be very important going forward). Being a good conductor of heat, the rod transfers heat from the source to the sink and in the process is heated up as well. Since there is an ambient temperature T, that will play a role in the rod\u2019s energy as well. Keep this picture in mind.\n\nFinally, let\u2019s replace the heat source by the data source and the sink by the data sink. The iron rod is to replaced by a Quantum System that can mimic the neural net, multiple quantum particles (atoms, electrons, molecules) each with its own state and coupled together and transferring energy between them.\n\nA quantum system always tries to reach a stable state, which is usually lower in energy and we use this property by having an error function that closely mimics the energy states of the particles and hence the total error is a function of the system\u2019s energy. The lowest energy possible is zero, this corresponds to reaching the global minima of our error function, this is not favorable because this means that we have overfit the data, this is where the ambient energy parameter comes in. If the system (or the iron rod) is able to transfer energy with the environment, then at equilibrium, it cannot be at zero energy because then heat from the environment can flow in and increase its temperature / energy level. So, we can see that the ambient temperature parameter acts as a regularizer and helps prevent overfitting.\n\nSo in summary,\n\nHeat Source ->Data Source (Dataset)\n\nHeat Sink -> Data Sink (Labels)\n\nIron Rod -> Quantum System that mimics a neural net\n\nEnergy -> Error\n\nAmbient Temperature -> Regularizer\n\nChallenges\n\nIt\u2019s definitely not simple to go from this analogy to using the idea in real-life, I see that there are the following implementation issues that need to be fixed.\n\n1. How to create a source and sink from the dataset (usually multiple datapoints) and labels\n\n2. How do we construct an \u201cIron Rod\u201d and can we reuse it for other problems?\n\n3. Can any error metric be used or some better than others?\n\n4. How long would the system take to converge?\n\n5. How would we freeze the trained system to be used on the test dataset?\n\nI believe that this intersection of Quantum Mechanics and Deep Learning would be interesting to watch in the near future and would love to hear your thoughts on this!", 
        "title": "Quantum Deep Learner \u2013"
    }, 
    {
        "url": "https://medium.den.ai/lets-face-it-90b5c1ba4398?source=tag_archive---------4----------------", 
        "text": "Let\u2019s face it. Most newsletters suck. They try to sell something without adding any value so I unsubscribe from them as soon as I discover that they are useless. But today I\u2019ve realised there are few newsletters I really enjoy reading. So I\u2018ve decided to share them. I don\u2019t find them disturbing because I receive them once a week. Such volume is manageable and you can quickly skim through concise descriptions accompanying all links without visiting them.\n\nThese newsletters help to stay informed without reading news sites. Also they often include useful (albeit basic) tutorials on some cutting edge stuff.\n\nSo let\u2019s begin. The main section is about Self-Driving Cars.\n\nAs a student of Self-Driving Car program, I spend a lot of time using Python and ML (Machine Learning) libraries. Since I am not aware of any other specisalised newsletters about Autonomous Vehicles, I\u2019ll move to more general ones. They help me to get more comfortable with Python and Machine Learning and to develop intuition in said topics. Sometimes they include some Self-Driving related links.\n\nThree newsletters above are mostly about Python. Often they include some ML related links.\n\nData Science Weekly newsletter seems less technical than Python newsletter. Often it includes Deep Learning and Machine Learning links.\n\nThis is one of the most interesting newsletters I\u2019ve ever read. It contains links and topics from Hacker News. Once a week you get the most interesting and important stuff from Hacker News. For me it\u2019s perfect balance between wasting too much time on Hacker News and completely ignoring it. The main purpose of this newsletter for me is that it helps to stay informed. It also often include some ML related links an discussions. So it is not complete off-topic in this list.\n\nThere were other newsletters that I tried and later unsubscribed from. I didn\u2019t include them in this publication.\n\nSo it appears that not all newsletters are evil. Some of them really deserve being read. In this article I\u2019ve shared the most useful and interesting newsletters about Self-Driving Cars and related stuff from my perspective.", 
        "title": "Let\u2019s face it. \u2013"
    }, 
    {
        "url": "https://medium.com/bbm406f16/week-4-what-am-i-eating-49bd866b7e56?source=tag_archive---------5----------------", 
        "text": "In the past week, we did some research about the TensorFlow[1] Library. How we can use it, what are it\u2019s concepts\u2026\n\nTensorFlow is an open source library developed by Google Brain Team[2]. Researchers\u2019 main purpose of developing this library is conducting machine learning and deep neural networks research. It can work on one or more CPUs or GPUs in a desktop, a server, or a mobile device.\n\n\u00a0\n\nIn TensorFlow multidimensional arrays like inputs, outputs, weights are called tensors. Tensors flow between operations in our model(Hence the name).\n\n\u00a0\n\nIt is very simple.\u00a0\n\nBuilding our model:\n\nx: input\n\nW: weight\n\nb: bias\n\n(This example uses softmax for activation function.)\n\n\u00a0\n\nDefining cost function:\n\ny: true label\n\nmodel: predicted label from our model\n\n(This is Cross entropy[3] loss function)\n\nTensorFlow has many optimizers[4] other than Gradient Descent. (Adadelta, Adagrad, Momentum, Adam, FTRL, RMSProp etc.)\n\n\u00a0\n\n\u00a0After this steps, we can start training and testing.\n\nWe want to \u201ctransfer learning\u201d. There are many trained deep learning models. We want to use these trained models\u2019 weights as a starting point for our training. We thought that this will decrease the training time and increase the accuracy.\n\nWe may use some data augmentation techniques to increase our dataset and get better accuracy. Some augmentation techniques which we thought we may use:\n\nOur dataset is growing! We used a chrome plugin named \u201cFatkun Batch Download Image\u201d[6]. It can download all images from a webpage. We used it on google search results.\n\n\u00a0\n\n\u00a0See you in next week!", 
        "title": "[Week 4\u2014 What Am I Eating?] \u2013 bbm406f16 \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/apple-leaps-into-ai-research-with-improved-simulated-unsupervised-learning-f7cdf8142ac9?source=tag_archive---------6----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Apple leaps into AI Research with Improved Simulated + Unsupervised Learning"
    }
]