[
    {
        "url": "https://medium.com/@dergigi/what-i-learned-from-uploading-my-soul-to-t%CC%B6h%CC%B6e%CC%B6-%CC%B6d%CC%B6e%CC%B6v%CC%B6i%CC%B6l%CC%B6-google-5d91b9ab5153?source=tag_archive---------0----------------", 
        "text": "Where should I start? Let\u2019s start from the beginning. I am a normal guy with a normal life thinking about normal things. I like to skate, I like to party, I like food. I like technology and computers and figuring out how stuff works. I like people, I like gaming, I like science. I like photography. I like to take pictures. Lots of pictures. I was always on the lookout for a better way to organize my pictures\u200a\u2014\u200afolders, subfolders, categories, dates, you name it. I\u2019m pretty sure you all ran into the same problems and can relate. However, I wanted more. I wanted to sort them by beauty, group them by feelings they invoke in me, crazy stuff like that. I was even thinking about writing software that does that for me. But writing such a piece of software is not easy, and who has the time for that anyway, right? Picasa\u200a\u2014\u200aGoogle\u2019s photo manager\u200a\u2014\u200acame close to fulfilling my needs. Automatic sorting, grouping, face detection, filter by colors, those sweet shenanigans. It almost had it all. Now that Google has killed Picasa I had to look for something new. Damn you, Google! That\u2019s why we can\u2019t have nice things. Google Photos: The new kid on the\u00a0block I used Google Photos for a while now, but I never used it extensively. I mostly used it to backup some pictures I took with my (crappy) phone camera. I got a new phone\u200a\u2014\u200athe camera does not suck that much ass anymore\u200a\u2014\u200aso I started to use Google Photos more and more. Google Photos does a lot of things automagically. It creates albums of your trips/weekends/evenings, a short movie of your holiday, collages of related photos and even gifs. It also auto-creates panoramas and adds style to your pictures if it sees fit. Further, it knows where you have been\u200a\u2014\u200aand whom you have been with\u200a\u2014\u200aand uses all those things to put your images into categories (more on that soon). The editing functionalities are quite nice, the syncing just works, creating and sharing albums is a breeze. It\u2019s quite a nice app. The power of Google Photos does not lie in the app itself, but rather in the brain behind it. This artificial brain is made up of the myriad of Google services that exist today. Well, not really. It is a chicken-or-the-egg problem. The services are partly powered by the \u201cbrain\u201d which in turn enables the creation of new services, which then feed back all the processed information into this \u201cbrain\u201d (consisting of multiple neural networks and other things). Google is not the only player in town. There are plenty of apps floating around today. Some are tiny and useful, some are humongous and not so useful. A few of them have a huge corpus of knowledge behind them. This wizardry requires that, somewhere in the cloud, big number-crunching machines work tirelessly to fulfill our every wish. And to do that they need to wade through every bit of our personal lives. At least that\u2019s how it is today. Is that awesome? Scary? I don\u2019t know, you decide. Google is especially good at this. So is Facebook. But I will focus on Google for now. Google reads every single email you ever wrote or have received. (If you do not have a gmail address and have never exchanged some mails with someone who does, you are the exception.) Officially it does it for targeted advertising, but I\u2019m quite sure they feed everything into their artificial brain as well. It is no secret that Google Translate works as well as it does because it uses a ridiculous amount of human-translated texts to learn. Further, all your activity is stored and used to train the brain. This includes your text searches, voice searches, YouTube watch and search history, and your movement. And these are only the things they are willing to show you. Have an Android phone? All of this is automatically true. Have an iPhone? All of this is automatically true as well since I am pretty sure Apple does it as well. You are working for Google and you don\u2019t even know it. The thing is, if I do work for someone I want to give it my best shot\u2026 \u201cDon\u2019t be evil\u201d was Google\u2019s often repeated mantra. Being not evil in a world driven by capitalism is hard. So please, dear Google, if you read this do not sue me. Equating you with the devil is of metaphorical nature. And after all, the devil might not be too bad, comparatively speaking. Anyhow, I still want all that sweet photo categorization goodness, remember? Sort by colors, shapes, feelings, etc. What to do? I soon realized what I had to do. But, the little, rational, voice in my head whispered: You can\u2019t upload each and every picture you ever took to Google! Nobody would be that crazy, right? What about privacy? What about the future repercussions this might have? Just don\u2019t do it! After 5 days of lengthy and thoughtful discussions (getting drunk) with my friends (some people I met by accident) I decided to do it. Fuck it. I will sell my soul to the devil. I will upload my life to Google. That\u2019s it. All my pictures. My whole life. The oldest digital photos are from 1999 and were shot with a camera that used 3.5\u2019\u2019 floppy disks as a storage medium. (Even older photos do exist since I scanned them all. But they have no EXIF data so it is hard to date them exactly.) Not knowing what to expect I went to sleep after hitting the upload button. I awoke a few hours later to see that my phone was screaming something along the lines of: OMG WHAT THE FUCK HAVE YOU DONE I HAVE A GAZILLION NEW ALBUMS AND GIFS AND COLLAGES AND PANORAMAS AND MOVIES TO SHOW YOU!!!!!11\n\nAt times I got these notifications faster than I was able to save them to my library. Like, literally, two or three new cards per second. This went on for weeks. It is incredible how fast this artificial brain is crunching data. The only limiting factor was my crappy upload. This lead to the birth of a new ritual of mine: Whenever I went to the toilet I sat down and saved as many auto-creations as possible, racing through accumulated memories of the past 17 years. It was so intense I got goosebumps and cried a lot. I was also worried about the dangers that Musk and Hawking are talking about. Then I looked like this. Unfortunately it is very hard to tell what exactly is going on in the background and how powerful the Google apparatus is. I contacted the author of the article linked above and he was kind enough to allow me to quote him: I imagine Google aim to keep growing exponentially though, probably following Moore\u2019s law. So they could have gone through two doublings in the last four years.\u00a0[\u2026] It\u2019s also getting more complicated to define what is meant by \u2018one server\u2019. As mentioned at I/O last month, they\u2019ve started designing and using their own neutral network processors. So they no longer build purely with commodity hardware like they used\u00a0to. Even with traditional hardware and an approximate two doublings, that would be 172 petaflops as of now. That is 172 000 000 000 000 000 FLOPS (floating point operations per second). Although the human brain is neither analog nor digital, we are entering the area where brain simulations become feasible. That\u2019s where we are, right now. Anyhow, back to the topic at hand. How is my upload doing? It was not always smooth sailing. Sometimes the app crashed, sometimes it was unable to save creations to my library. Sometimes the app glitched and it looked weird. Oh dear. Material is not supposed to behave that way! It did not happen often, but it did happen often enough. Also: putting an arbitrary limit of 2000 pictures on the album size? Really? Another arbitrary limit that pops up when you try to add 501 photos to an album? Are you kidding me? Out of all companies you do that to me, Google? All in all, it went well. Actually, it is still going well. I started this experiment almost three weeks ago and it is still going on. Files are still being uploaded and the Google Photos Assistent is still nagging me every damn day that there is some new creation waiting for me. I did not expect anything less of Google. If they are good at something, it is solving problems at a planetary scale. Now let\u2019s suppose the upload is done\u200a\u2014\u200awhich it isn\u2019t\u200a\u2014\u200aand let\u2019s suppose all the processing of all the images is done as well (which again, two weeks after initiating the upload, it isn\u2019t). What can we do with a tool like Google Photos? Short answer: It is Google Image Search for your personal photos. Google Photos does an excellent job in regards to feature discovery. The search field is pre-filled with meaningful suggestions that relate to your pictures. In my case it was \u201cscuba diving\u201d and \u201ccamping\u201d. I went scuba diving once or twice. And I like\u00a0camping. Yay, it works! You just got a first glimpse of the power of this search field. Speaking of the search field: it is the entry point as well as the main feature of the whole application. Click on places, and the search field will say \u201cPlaces\u201d. Click on things and \u201cThings\u201d will be filled in. Neat. I did not remember visiting \u201cWoloara\u201d so I had to look it up. It is in Indonesia, and sure enough, I was there. Thanks for reminding me Google. One can already see that the object and place recognition is quite good. Recognizing places is straightforward if your pictures are geo-tagged. However, most of my pictures are not. So how does Google do it? You guessed right: Witchcraft. All the places I supposedly have been\u00a0to. That\u2019s quite a few places! The only place it listed where I have not been is Illinois. The pictures it tagged were shot in Kematen, Austria. There has to be some object or feature\u200a\u2014\u200amaybe a mountain peak or something\u200a\u2014\u200athat is really similar. Who knows. Let\u2019s move on. What kind of things are hidden in my photos? I am somewhat disappointed by those categories. There are plenty of things in my library that are not listed here. Further, they are very generic and do not represent my life accurately. Where are the LAN parties? Where is the nudity? Where are the nutscapes? There is also a lack of photos of nude people. The reason for this might be that seeing a nipple is a big deal in America, so nudity is filtered. Luckily I\u2019m living in Europe. We like nipples. And boobs. And naked people. I disagree with this Google-imposed censorship for many reasons. For one thing, censorship (and surveillance) always has a chilling effect and thus is manipulative and problematic in one way or another. Secondly, this obsession/taboo in regards to our penises/boobs/vaginas/assholes has to stop. We all came from vaginas, we all have (and are, sometimes) assholes, and I\u2019m pretty sure boobs and penises were involved in creating every single one of us as well. So stop it, Google. Back to things. Things are more interesting than places, since grouping photos by places is an old hat, but grouping them by things was not easily possible until recently. Let\u2019s have another look at the things it found: Camping, Selfies, Bikes, Sky, Cars, Beaches, Boats, Mountains, Skateboards, Sunset, Wedding, Beer\u2026\n\nWhat do we see? Well, cooking, obviously! Pots, plates, people preparing food in various ways (cutting, grilling, searing), food in pans, food above fire, people getting things out of a fridge (not pictured), people sitting around a table full of food, and a frog (I guess it counts as cooking if you are French). Getting this categorization right is hard, but still, these are searches suggested by the system. Queries that I call \u201cobvious\u201d. As you have seen in the listing of \u201cThings\u201d there are a lot of these obvious searches. They are already impressive and quite handy. Searching for things that are suggested by the system is easy. Let\u2019s get creative (whatever that means) and find some queries that were not suggested by Google Photos. One thing that was not immediately obvious to me was that you could also search for dates and spans of time. Type in \u201cJuly\u201d and all the pictures you ever took in July will be shown. Shorthands like \u201cSep\u201d for September also work. Type in \u201c2012\u201d and all the pictures you took in 2012 will be shown. Type in a date like \u201cFeb 25 2006\u201d and it will show all pictures of this day. Remove the year and you will find every picture that was taken on \u201cFeb 25\u201d independent of the year.\n\nUnfortunately it does not work with times, e.g. \u201c13:37\u201d does not show anything (except for photos that have 1337 in their filename). For multiple years, e.g. \u201c2002\u20132004\u201d, which should show all pictures taken in 2002, 2003 and 2004, it fails as well. Not sure what happens but it showed mostly pictures from 2002 and 2003, but none of 2004. Although searching by color is easy (computationally speaking) it is a nice feature to have. It works well for most common colors, and it also works for general terms like \u201ccolorful\u201d. It does not work for PANTONE colors or HEX colors. I\u2019m a computer guy so let\u2019s use the additive primary colors used by computer screens: red, green and blue. Exotic colors and general terms like \u201ccolorful\u201d also work. If you want to get crazy you can try all of these. Your results might vary since some colors are named after things (or the other way around) and those things will show up as well.\n\nColors are already an abstract concept, although sorting and filtering by color is quite easy to do for a computer. After all, pixels have colors and computers are good with pixels. Computers, up until recently, were not good with truly abstract concepts. Remember the \u201cBeer\u201d search? We have seen that Google Photos is good at recognizing beer cans and can differentiate between beer and energy drinks. So let\u2019s see what we get if we search for energy drinks. And while we are at it, let\u2019s search for a particular energy drink. Well, not only are drinks recognized, but also energy drink companies and their logos. Again, Google Photos is dealing with high-level concepts. But enough with the energy drinks. What if we are simply interested in the general concept of energy? It turns out that energy is not an easy\u00a0concept Power lines, windmills, electric bikes, cars, drinks, trucks, a ship, a train. Some pictures of explosions also showed up, and again, energy drinks. Think about that for a minute. Imagine you have to do that manually. Go through all your pictures and find the ones that relate to energy. It is quite a hard task. Not impossible, but hard. I would argue that the machine learning algorithms behind Google Photos are already doing a better job than I could ever do. And it does it in milliseconds. These are quite abstract concepts. Abstract is an abstract concept as well. Holy recursion, Batman! I wonder what we will find if our search is really abstract. Hold your horses, everyone! Shapes of nature, quite an abstract face, aerial views of cities, tunnels and blobs of\u00a0light. Damn. The pictures are quite abstract. I wonder how the neural network does that. I wonder how my own brain decides if something is abstract or not. Lots of things to wonder about. Wonder and awe are beautiful feelings. Beauty, in general, evokes emotion, joy, happiness, even love. That is exactly what I want to search for. Beautiful things, beautiful images. Let\u2019s start with dawns. Beautiful dawns. Dawns are beautiful, no matter where you are in the\u00a0world. You can also search for \u201cbeautiful people\u201d, \u201cbeautiful girls\u201d, \u201cbeautiful women\u201d, beautiful men\u201d. I got many results on all of these searches. I also got plenty results for \u201cbeautiful animals\u201d, \u201cbeautiful flowers\u201d, \u201cbeautiful technology\u201d and \u201cbeautiful cars\u201d (all the Tesla models I ever photographed showed up, just to let you know @ElonMusk). Nothing much turned up for \u201cugly\u201d or \u201chorrendous\u201d searches. It seems like Google forces you into a beautiful filter bubble. I tried plenty of things with a \u201cbeautiful\u201d suffix.\n\nWell, that was disappointing. It seems like Google has its SafeSearch feature activated. So we have to get creative with our queries. As you can see above, explicit searches don\u2019t really work either. I guess that those \u201cnasty\u201d words are simply blocked. It\u2019s a shame. After all, sex invented us, not the other way around. And they were both naked, the man and his wife, and were not\u00a0ashamed. Models and breasts! Way better. We can work with that. As long as your search term is generic enough it seems to circumvent the filter. Let\u2019s find some soulless naked people. What do you see,\u00a0Buzz? Okay. Fair enough. Although the hair color detection is not very accurate\u200a\u2014\u200aI tried searching for blondes and brunettes, but mainly redheads showed up\u200a\u2014\u200aI see a bright future coming where porn sites are using balls-deep learning to automatically create categories. The future will be amazing. There were some funny false positives that showed naked people. I was playing around with the search field, trying different things, and suddenly: boobs. Not that I\u2019m complaining. I just have no idea sometimes what is going on in this damn neural network. I guess nobody really does. Softcore only, since I want to keep this a family show (reference game incredibly on\u00a0point) Today I learned about the other meaning of trunk, that a lot of porn is pink, and that Counter-Strike is pure sex. I tried plenty of other searches and some yielded results, although mostly because the search term was somewhere in the file name. To my surprise searching for \u201cfacial\u201d turned up all pictures with faces in them\u200a\u2014\u200awhich leads me to the next feature I want to discuss: facial recognition. Unfortunately, facial recognition for Google Photos is not enabled in my area. Once again, geo-blocking is the bane of my existence. Oh, the disappointment! Luckily it is easy to be someone else on the Internet. Someone, hm, from the United States maybe. So I put on my robe and stars-and-stripes wizard hat to make it happen anyway. Blurred, because I was too lazy to ask all those people for permission to put this on the Interwebz. Facial recognition is always a little bit scary. If it is better than human-level recognition it starts to get creepy. I will not go into all the nasty things you can do with it. Let\u2019s save that for later. But what can you do with it? Find all pictures of a certain person, obviously. If you give the recognized faces names, you can also do things like \u201cshow me all photos that have a Christoph in them\u201d. This works extremely well and will also include people named Christopher. Since\u200a\u2014\u200aof course\u200a\u2014\u200athis works for last names as well, you can search for whole families. My last name is \u201cFuchs\u201d (translates to \u201cfox\u201d) which is also an animal so you will see my family and foxes. This can be confusing if you are named after a thing (Heel), animal (Fuchs, Wolf) or color (Violet). I found that you can limit your search scope to a single person using the \u201cperson\u201d keyword. So if you want to remove the real animal from the search results just type \u201cFuchs person\u201d. Also works with groups of people if you type \u201cFuchs people\u201d. (Does not work well the other way around though, \u201cFuchs animal\u201d shows a bunch of cats.) Getting more specific search results does work with other keywords as well. You can add \u201cbeer\u201d to a person\u2019s name and you will find all the pictures of this person having a beer. Finding out who of your friends is a raging alcoholic has never been easier! By the way: tagging people with names seems to use a simple label (as advertised), even though your suggestions come from your Google Contacts. Searching by additional contact information like nickname or address or phone number yields no results. I guess it is implemented this way since people have privacy concerns. It would be creepy if you type in a phone number and the matching face pops up. Remember, though, that all the data is there and it can be done easily. Google\u2019s advanced search is awesome. I use it all the time, especially in Gmail. Why not have it in Photos as well? I would be already happy with \u201cin:album keyword\u201d or some boolean operators. Let your imagination run wild my dear Googlers. These are not the balls you are looking\u00a0for. Speaking of fucking, I really want to be able to find naked people. Yeah, if you could give me an option to disable SafeSearch, that would be great.", 
        "title": "What I learned from uploading my soul to t\u0336h\u0336e\u0336 \u0336d\u0336e\u0336v\u0336i\u0336l\u0336 Google"
    }, 
    {
        "url": "https://aiinvestor.com/can-monsanto-feed-the-world-with-ai-450c929f71ff?source=tag_archive---------1----------------", 
        "text": "One of the more surprising companies to show up in the AI Winners portfolio was Monsanto (NYSE: MON). Our models indicate that Monsanto stands out from its peer group in embracing deep learning technologies.\n\nThe research is growing that deep learning platforms in general, and Google\u2019s Tensorflow in particular, could be transformative in computational biology. Computational biology, sometimes referred to as bioinformatics, is the science of using biological data to develop algorithms and relations among various biological systems. Since the dawn of modern agriculture, scientists have been experimenting with the manipulation of species through breeding techniques (which leads to the GMO debate). More recently, direct manipulation of the DNA and RNA have dramatically broadened the possibilities of what can be done to crops. However like all genetic experiments, the possibilities of what can be changed have traditionally far exceeded capacity to test those possible changes. Scientists have made educated guesses or just stumbled upon breakthroughs in nearly random fashion.\n\nWith large enough data sets, deep learning will rewrite the rules of experimentation. In the past year, academics have been pushing the science forward, particularly in RNA splicing and binding. However, these academics lack the data set sophistication that is required for AI to shine.\n\nThe trick to using deep learning models is to think of clever ways to represent the data where each event, such as splicing, RNA-protein binding, or methylation, is a training sample in your data, thus creating a scenario where the number of samples far exceeds the number of variables. Once this crucial step is achieved, TensorFlow provides a powerful and flexible gateway to play with deep learning.(1)\n\nDomination of the agro-industrial complex in the 21st century will require two things: The largest biological data sets, and the engineering talent to apply AI to them. Monsanto appears to be winning by a landslide in both areas.\n\nMonsanto\u2019s business is global, diversified within agriculture, and data driven. Their 30 subsidiaries span all cash crops from asia, to europe, to the americas. Their recent $1B acquisition of The Climate Corporation brought a team of Silicon Valley data science veterans, and a scalable data collection strategy for weather effects on crops.\n\nIn the lab, Monsanto is pushing advanced techniques for RNA interference forward with data science. Spraying RNA on crops affords control over the plant\u2019s genes without altering the genome. This opens the door for much faster development of modifications, and also provides a future revenue line of constantly supplying farmers with the chemical sprays they need to optimize their plants. Monsanto\u2019s acquisition of Beelogics in 2010 brought a competency in RNA production, and today we can see the growth of AI within their research group through the types of roles they are hiring for and the publicly available resumes of their scientists.\n\nFor several currently open deep learning roles in Monsanto\u2019s research headquarters in St. Louis:\n\nI reviewed Monsanto\u2019s competitor data sets to look for similar patterns and came up empty. Archer Daniels Midland (ADM) and Syngenta (SYT) has no identifiable correlation to machine learning, deep learning, or AI. Dow Chemical Corporation (DOW) was only able to muster one active job posting that mentions machine learning. Nothing related to more advanced technologies.\n\nReading between the lines\u200a\u2014\u200aMonsanto has a global, scaling program to apply the most powerful AI technologies to the largest plant breeding and growing data sets. Little appears to stand in the way for Monsanto to dominate agriculture in the 21st century.\n\nSign up for our newsletter: https://tinyletter.com/jonaslamis", 
        "title": "Can Monsanto Feed the World with AI? \u2013"
    }, 
    {
        "url": "https://medium.com/emergent-future/twitters-machine-learning-plans-is-deep-learning-magic-net-neutrality-upheld-and-more-4189942473d8?source=tag_archive---------2----------------", 
        "text": "Issue 14\n\n\u00a0This week we check in on Twitter\u2019s machine learning plans, ask if deep learning is magic or just math, celebrate the latest net neutrality ruling, and share some videos to watch. Plus, what we\u2019re reading and a few things for you to try at home.\n\nNot a subscriber? Join the Emergent // Future newsletter here.\n\nYou Might Have Heard: Twitter announced Monday that it acquired the AI company Magic Pony Technology.\n\nThe London-based company uses machine learning and neural networks to identify features in video, enhance imagery, and create graphics for virtual and augmented reality.\n\nIn other words, Twitter\u2019s big bet is that the algorithms will improve video streaming for Vine and Periscope by automatically filling in patchy video feeds, and increasing the resolution of pixelated video and images.\n\nThe new tech might come in handy this Fall when Twitter begins providing free, live streaming video of the NFL\u2019s Thursday Night Football games to more than 800 Million users worldwide on mobile phones, tablets, PCs and connected TVs.\n\nMagic Pony is the third machine learning acquisition by Twitter, joining Madbits, and Whetlab. Sources say the deal was worth $150M and includes a team of 11 PhDs with expertise in computer vision, machine learning, high-performance computing, and computational neuroscience.\n\nPLUS: Google opened a dedicated machine learning research center in Zurich to focus on machine intelligence, natural language processing, and machine perception.\n\nDeep learning isn\u2019t a dangerous magic genie, and it\u2019s far from magic, Oren Etzioni says, CEO of the Allen Institute for Artificial Intelligence and a computer scientist at the University of Washington.\n\nGoogle, Facebook, Microsoft and others continue to push AI into everyday online services while pundits describe deep learning as an imitation of the human brain. It\u2019s really just simple math, Oren says, executed on an enormous scale.\n\nAnd, amazingly, the artificial intelligence we were promised is finally coming as deep learning algorithms can now recognize images, voice, text, and more.\n\n\u201cThere is almost nothing we can think of that cannot be made new, different, or interesting by infusing it with some extra IQ,\u201d Kevin Kelly writes.\n\nIt\u2019s not all peaches and cream. Oxford philosopher and author Nick Bostrom warns that artificial intelligence is a greater threat to humanity than climate change.\n\nSo, what\u2019s next for AI? The best minds in AI weigh in on what life will look like in the age of the machines.\n\nConfused About AI? This two-part series on the AI revolution and the road to superintelligence is an excellent primer. (Part 1) (Part 2)\n\nPLUS: A guide to staying human in the machine age\n\nA federal appeals court has ruled that high-speed internet can be defined as a utility, putting it on par with other essential services like power and the phone.\n\nThe ruling clears the way for rigorous policing of broadband providers like AT&T, Comcast, and Verizon, limiting their ability to shape the user experience by blocking content, prioritizing paid content, or creating fast and slow lanes on the internet.\n\n\u201cThis is an enormous win for consumers,\u201d said Gene Kimmelman, president of the public interest group Public Knowledge. \u201cIt ensures the right to an open internet with no gatekeepers.\u201d\n\nWith the win, the internet will remain a platform for innovation, free expression, and economic growth, Tom Wheeler, chairman of the F.C.C., said in a statement.\n\nBut, hold the celebration, the fight for net neutrality isn\u2019t over.\n\nAT&T is already vowing to fight the decision, and expects this to ultimately be decided by the Supreme Court. \ud83d\ude48", 
        "title": "Twitter\u2019s Machine Learning Plans, Is Deep Learning Magic?, Net Neutrality Upheld, and More"
    }, 
    {
        "url": "https://medium.com/inspiring-ai/dinosaurs-vs-flowers-7ea9f9e6c433?source=tag_archive---------3----------------", 
        "text": "By combining a deep-learning algorithm, a book of dinosaur pictures, and a book of flower paintings, Australian artist Chris Rodley created some mesmerising images of dinosaurs made out of plants and fruits and went viral on social media.\n\nYou can try out style transfer for yourself using a bunch of different platforms. Chris used a user friendly web app called Deepart.", 
        "title": "Dinosaurs vs Flowers \u2013 Inspiring AI \u2013"
    }
]