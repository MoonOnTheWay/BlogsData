[
    {
        "url": "https://medium.com/@alevitale/notes-from-deep-learning-summit-2015-london-day-2-b76b681bbd2c?source=tag_archive---------0----------------", 
        "text": "This post covers the second and final day of the Deep Learning Summit that took place in London on September 24th-25th 2015. You can find the first post here. Videos are also being posted on youtube.\n\nAfter a welcome from Alison Lowndes of NVDIA, the day started with the startup session.\n\nFirst up were Wally Trenholm, Founder & CEO, and Jason Cassidy, MD & Chief Science Officer, of Sightline Innovation, talking about The Commercialisation of Deep Learning. They started going after military customers (2011), then looked for other markets due to long military order process (5 year to order). They first took what had been developed in image analysis on Geo-Scale (Satellite, UAV) and applied it to agriculture. Then, to serve even more customers, they went from Geo-Scale to Macro-Scale images, addressing industrial problems (automated manufacturing quality control). Next they will go further down and apply their image analysis to Nano-Scale (genomic). There is a MLaaS (Machine Learning as a Service, term for which they hold the copyright) platform which will be released next month, with a server on site to collect and preprocess the data, and also provide reporting and dashboards, while algorithm training and prediction will be done on their cloud. In case you are looking, Clarify is hiring.\n\nNext up was Paul Murphy, CEO of Clarify on Deep Learning & Speech: Adaptation, the Next Frontier, with some funny cartoonish slides. Clarify, started in London and now Texas based, provides an API that analyses audio and video making it searchable. The main issue with speech is adaptation, as also discussed by S\u00e9bastien Brati\u00e8res in the last session of the first summit day. There are different adaptation problems, like speaker adaptation (ex. accents, speaker may not be native, while most of the training data is native and male), noise and tenuation (moving away from the microphone). The bleeding edge in speech recognition research is:\n\nThen came Appu Shaji, Head of R&D at EyeEm, talking about Deep Learning for Real Photography. EyeEm is a social network for photography, one of the goals Appu is to improve content discovery, helping photographers being found and selling more photos. He showed EyeVision, which is currently in early access. The engine assesses aesthetic quality of the photo and also tags them with 20k concepts, using data coming from both community and expertly curated tagging. They are using CNNs with word embeddings, based on these research papers Paper1 Paper2 Paper3.\n\nJohn Overington, Director of Bioinformatics at Stratified Medical, followed with Artificial Intelligence in Drug Discovery. John said that currently drug discovery is extremely expensive and unpredictable, R&D expenses for a single approved drug range from 4 Billion$ to 12 Billion$ (source). He brought his experience on drug discovery to Stratified Medical, which is developing their own drug pipeline. The goal is to use AI to filter down potential molecules, accelerating discovery and reducing costs. They are building a knowledge graph using data from structured sources (molecule databases, vocabularies) and unstructured data (papers, patents, etc.), the latter being extracted with NLP techniques. They will also leverage new public datasets such as UK10K, the genome sequencing data of 10k people which will help uncover rare variants contributing to diseases. They are making progress, they achieved key milestones in a multimillion $ partnered Alzheimer\u2019s program.\n\nThe last talk of the startup session was given by Marius Cobzarenco, Co-Founder & CTO of re:infer on Building Conversational Interfaces with Deep Nets. Marisu said they are building business bots that collect data from different systems (Slack, CRM, wiki, etc.) and are able to answer natural queries. Currently it is hard to understand intent and context, there is active research on embeddings done for example by Geoff Hinton on deep thoughts at Google. They are using CNNs to find embeddings, they found this DNNs to be faster to train compared to RNNs and at the same time gives good results. They also use DL for named entity recognition, you still need to extract entities to translate the intent into actions.", 
        "title": "Notes from Deep Learning Summit 2015 London \u2014 Day 2"
    }, 
    {
        "url": "https://medium.com/@kdoherty6125/bath-time-7155e8ee0e66?source=tag_archive---------1----------------", 
        "text": "In this commercial, Johnson\u2019s is advertising their baby bathing collection, focusing on the shampoo. The commercial is about 30 seconds and is taped from the perspective of whoever would be washing the baby, in this case the mother. Due to the slow motion video, language used, and placement this commercial overwhelmingly appealed to the need to nurture.\n\nThe whole commercial is focused on the baby in the bath and is from the mom\u2019s perspective. It looks like you are the one washing the baby, holding her in your hands. This makes the consumer feel connected to the commercial and may bring out some maternal feelings towards the product. Additionally, throughout the advertisement the narrator, a woman, spoke in a soft voice while describing the tiny details of what was occurring in the video. This made me feel more relaxed and comfortable with the product.\n\nSpecifically during the commercial, the narrator once said \u201cIn just this one moment your baby is getting even more than clean\u201d. This suggests that a shampoo, which has the purpose of cleaning, can do more for you and your baby than just clean. It is saying that if you want to do more for your baby, use Johnson\u2019s baby shampoo. Then, towards the end the baby smiles as the mom is washing the baby\u2019s head which might have been the cutest thing I have ever seen. Looking at that smile during the commercial has a positive impact on the consumer. It leaves an impression that if you want to nurture your baby and have a happy baby, use Johnson\u2019s. Finally, Johnson\u2019s baby product collection slogan is \u201cSo much more\u201d, because clearly using Johnson\u2019s products provides your baby with more than the generic brand\u2019s products. In reality, Johnson\u2019s is probably extremely similar to any other baby shampoo, but the commercials Johnson\u2019s produces makes you feel like you are doing more for your baby by using Johnson\u2019s than just giving her a bath.\n\nOverall, this was a very effective ad. Watching this commercial would lead the consumer to trust Johnson\u2019s with your baby\u2019s care, make you feel good about buying their products for your baby, and leave an overall positive impression with the product and the brand. I found myself smiling throughout the commercial, which was part of their goal.", 
        "title": "Bath Time! \u2013 kdoherty6125 \u2013"
    }
]