[
    {
        "url": "https://medium.com/@yaoyaowd/rnn-spelling-correction-to-crack-a-nut-with-a-sledgehammer-7f5aa442c08c?source=tag_archive---------0----------------", 
        "text": "I learned basic spelling correction by Markov Chain and Noisy Channel two years ago but I haven\u2019t implement anything at that time. One year ago, I wrote a spell correction algorithm because the one used in Pinterest was not perfect. The algorithm is based on Peter Novig\u2019s tutorial and probabilities of unigrams and bigrams. The precision is only 70% to 80% compare with Google\u2019s \u201cground truth\u201d and I don\u2019t know the recall. There are many challenges, for example, how to segment the word, how to understand special usernames and how to prevent over corrections.\n\nI\u2019m not very happy although I shipped it in the end. I changed the algorithm and parameters but there\u2019s no significant improvement. Until recently, I start looking at deep learning and how Google uses it. Google uses RNN for machine translation and there are some new progress. Since RNN works for machine translation for hundred thousands of words and long sentences, why we cannot use it to solve spell correction on 30 characters.\n\nI have to admit that spell correction data complexity and model complexity is more than a hundred times smaller than machine translation. But set up a RNN for spell correction is not over engineering because there are too many deep learning libraries and examples already on the Internet.\n\nI started to try RNN for spell correction last week. There are two parts in the RNN model. The first part is an encoding part that contains a list of cells. Each cell takes two input, one input is the current character and the other one is the output from the previous cell.\n\nThe second part is a decoding part that also contains a list of cells. Each cell takes one input from the previous cell and generates a vector as the output. The vector corresponding to a character in the vocabulary.\n\nHigh quality data is the key for every machine learning problem.\n\nI\u2019m using anonymous search session data to extract training and testing data for the model. When I notice there are two similar queries in one search session and the second one have better result, I guess it probably a good spell correction example.\n\nFor people without good training data, Deep Spelling talked about how to generate training data from Google\u2019s billion word dataset. Although it is different from real typos, it is good enough to train a spell correction model.\n\nHow good is our RNN?\n\nI just play it for fun and there\u2019s no expectation. However, it turns out the model works very well for spell correction. Around 100 iterations, there\u2019s only funny result like \u201cddd hhhh\u201d, \u201csssss iiihhhh\u201d in the output. After 400 iterations, I saw a query \u201cdiy home\u201d.\n\nAbout 4000 iterations, the model can generate trigram queries like \u201cpicnic in house\u201d. About 6000 iterations, the model achieves 90% accuracy on my testing data. It only takes a couple hours to train this model.\n\nI didn\u2019t expect that deep learning solved my problem easily. Compare with other solutions, there are a lot of advantages for RNN:\n\nI will continue train spell correction model with more data. And publish my code on Github later. In the same time, I need to write a Java library to load the model into our query understanding service. In the end, I will also implement some logic to handle long sentences so we can spell correct tweets, descriptions and other long sentences.", 
        "title": "RNN Spelling Correction: To crack a nut with a sledgehammer"
    }, 
    {
        "url": "https://medium.com/@dataaspirant/most-popular-kaggle-competition-solutions-5e5704224637?source=tag_archive---------1----------------", 
        "text": "Every data science enthusiastic dreams to get top in kaggle leader board. But It\u2019s not an easy thing to stay top on kaggle leader board. So let\u2019s learn the most popular kaggle solutions to learn how to stay top on kaggle leader board.\n\nRead more about most popular kaggle competition solutions.", 
        "title": "MOST POPULAR KAGGLE COMPETITION SOLUTIONS \u2013 dataaspirant \u2013"
    }
]