[
    {
        "url": "https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39?source=tag_archive---------0----------------", 
        "text": "Generative Adversarial Networks (GANs) are a class of neural networks which have gained popularity in the past couple years, and for good reason. Put most simply, they allow a network to learn to generate data with the same internal structure as other data. If that description sounds a little general, that is because GANs are powerful and flexible tools. To make things a little more concrete, one of the more common applications of GANs is image generation. Say you have a bunch of images, such as pictures of cats. A GAN can learn to generate pictures of cats like those real ones used for training, but not actually replicate any one of the individual images. If given enough cat pictures, it actually learns about \u201ccat-ness\u201d from the samples, and learns to generate images that meet this standard. Furthermore, it does so without the generator actually having direct access to any of the training images itself. GANs have been applied to more than just images though. Recently they have been used to generate everything from short videos to robot behavior.\n\nIn this tutorial, I am going to walk through the theory behind the GAN algorithm in a somewhat unconventional way. I am going to explain it using an episode of Spongebob Squarepants. Stick with me, the metaphor works much better than you would think! After that, I will show how to implement a GAN for image generation using Tensorflow and Python.\n\nA Generative Adversarial Network works through the interplay between two semi-separate networks: a generator and a discriminator. The goal of the discriminator is to tell the difference between the data generated by the generator and the real-world data we are trying to model. We can think of the discriminator as being like the bouncer at a club. I don\u2019t have just any bouncer in mind though. Discriminator networks are like the bouncer outside the Salty Spitoon, as seen in the Spongebob Squarepants episode: No Weenies Allowed.\n\nIn the world of Spongebob Squarepants, one must be tough in order to get into the Salty Spitoon. The job of the bouncer (discriminator) is to tell the difference between the real tough guys (the real data), and the weenies (the generated data).\n\nThen we have Spongebob Squarepants (the generator). He certainly isn\u2019t a real tough guy. He is an imitator, and needs to learn to look like a tough guy in order to get into to see his friend.\n\nThrough training, the discriminator network learns a function to tell the difference between the real and generated data. The first features the discriminator learns to look for may be relatively obvious aspects of the data which easily separate the real from the fake.\n\nIn Spongebob\u2019s world, the bouncer outside the Salty Spitoon learns to look for a show of brute strength to tell the tough guys from the weenies.\n\nAny real data should be able to pass this test easily.\n\nOnce the discriminator has learned something about what to use to tell the two apart, the generator can take advantage of what the discriminator has learned in order to learn for itself.\n\nSpongebob can use the fact that the bouncer is checking for strength in order to appear more like an actual tough guy. At the beginning of training however, it still may not appear convincing.\n\nIf the generator hasn\u2019t learned a convincing enough way to generate data, the discriminator will still be able to tell the real from the fake.\n\nWhile Spongebob is able to demonstrate some features of toughness, he is ultimately called out as a weenie, and sent to Weenie Hut Jr for further training.\n\nThis process doesn\u2019t end after a single round however. There can be thousands (or millions) of iterations before the generator produces data similar to the real thing. As the process continues, the discriminator and generator are trained in an alternating fashion. Over time the discriminator will begin to learn more subtle ways of distinguishing the real data from the generated data. This is exactly what we want to happen, as it makes the generator better too, since the generator is only as good at making up data as the discriminator is at telling the real thing apart from the imitation.\n\nChecking back in on Spongebob, the bouncer has learned a new feature to use for distinguishing the tough from the weenies: fighting.\n\nOur generator, Spongebob, uses this new information, and decides to pick a fight with someone in order to appear tough himself.\n\n\u2026and although things don\u2019t go exactly a planned (see episode for more details), it works well enough to fool the bouncer into believing that he is a tough guy.\n\nPutting aside the question of whether or not Spongebob is still a weenie at heart, he has learned to imitate the true tough guys enough to be let into the Salty Spitoon. With enough training, we hope our generator can eventually do the same, and generate data samples that are not only indistinguishable from the real thing to the discriminator, but also to us humans, who are often much more discerning.\n\nOur Spongebob metaphor only goes so far in helping actually build a GAN. To actually implement one, we need to get a little more formal. The generator (G) and discriminator (D) are both feedforward neural networks which play a min-max game between one another. The generator takes as input a vector of random numbers (z), and transforms it into the form of the data we are interested in imitating. The discriminator takes as input a set of data, either real (x) or generated (G(z)), and produces a probability of that data being real (P(x)).\n\nThe discriminator is optimized in order to increase the likelihood of giving a high probability to the real data and a low probability to the generated data.\n\nThe generator is then optimized in order to increase the probability of the generated data being rated highly.\n\nBy alternating gradient optimization between the two networks using these expressions on new batches of real and generated data each time, the GAN will slowly converge to producing data that is as realistic as the network is capable of modeling. If you are interested, you can read the original paper introducing GANs here for more information.\n\nAs mentioned in the introduction, the most popular application of GANs right now is for image generation using convolutional neural networks. Below is an example of an image-producing GAN. The generator which takes a vector input (z), and produces a 64x64x3 color image. The discriminator then takes both real images (x) and generated images (G(z)), and produces a probability P(x) for them. Once the network is trained and we would like to generate new images from it, we simply call G(z) on a new batch of randomized z vectors.", 
        "title": "Generative Adversarial Networks Explained with a Classic Spongebob Squarepants Episode"
    }, 
    {
        "url": "https://medium.com/emergent-future/recognising-beer-with-tensorflow-9dedfee3c3c0?source=tag_archive---------1----------------", 
        "text": "This guide is by-and-large a retread of Google\u2019s own material on the subject with some personal commentary and notes about my experiences.\n\nI initially thought I was going to train the model from scratch, so I pulled out one of our Mac Pro workstations and set to work. One and a half weeks later, the training was still running. Fortunately I had since aborted this plan.\n\nThere are actually some very smart people in Accenture Labs who understand this subject quite well (unfortunately I\u2019m still trying to encourage them to write blogs). Our Systems & Platforms research group has a rig packed with Nvidia\u2019s Titan GPUs that they use exclusively for neural network training. Because I enjoy fumbling through new technologies so much, though, I ignored the large body of research we already had in this area and set out to learn everything the hard way.\n\nIt turns out that training a model like this requires a lot more maths than the Mac Pro\u2019s CPU could get to in any reasonable time. CPUs are super flexible and have lots of neat instructions for doing stuff on usually around four to sixteen cores. GPUs, on the other hand, excel at doing floating point calculations on thousands of cores simultaneously.\n\nFurthermore, neural networks just take a really long time to train, and even with a GPU rig (which I did not borrow) I was still looking at potentially weeks of training time. That\u2019s not agile.\n\nIf academic papers are your thing, read this one. Simply speaking, instead of training an entire neural network it is possible to retrain just the final layer and still get pretty good results. This can be done on a standard laptop, without a GPU (I ran it in a Docker container on my MacBook Pro), in about half an hour.\n\nStep one is to acquire and structure the data. Over an hour or so, Allison and I took around 150 photos of Lagunitas IPA and Crazy Mountain Pale Ale in various lighting conditions, at different levels of zoom, held by people, not held by people\u2026\n\nOnce we had all the data in a central location, I docker cped it over to my TensorFlow container in the following directory structure.\n\nThen it was just a matter of using Google\u2019s provided example code:\n\nOur initial results were lacklustre. We found that, because all the images were taken in the Labs environment, the model was over-indexing on features of our d\u00e9cor that were over-represented in one set or the other. I fixed this in a rather hacky way: by creating a new class called nothing_interesting and filling it with garbage photos of the Lab, containing no beer. For good measure, I chucked in the flowers data from Google\u2019s tutorial to provide more negative examples. The final training data directory looked like this:\n\nAfter retraining the algorithm, it performed incredibly well\u200a\u2014\u200amuch more so than our existing SURF classifier. The model is in the form of two files: a Protocol Buffer serialisation of the model graph, and a simple ordered text file providing the human-readable names of the class labels (e.g. lagunitas_ipa, crazy_mountain_pale_ale). The model can be easily transported between machines, and is small enough to check in to source control.\n\nNow that we had a trained model, it was time to put it to use.", 
        "title": "Recognising Beer with TensorFlow \u2013 Emergent // Future \u2013"
    }, 
    {
        "url": "https://gab41.lab41.org/across-the-network-ai-week-in-review-sept-23-fe4b243a6c2d?source=tag_archive---------2----------------", 
        "text": "Across the Network\u200a\u2014\u200aAI Week in Review Sept\u00a023\n\nWelcome back to Across the Network\u200a\u2014\u200aLab41\u2019s weekly look at what is going on in the world of AI. As always these are all links that I pulled from the Lab41 Slack channels.\n\nExtraordinary Link Between Deep Learning and the Nature of the Universe\u200a\u2014\u200aThis is an \u201cextraordinarily\u201d exciting title. Physics \u2192 meet Deep Learning. The article describes a paper recently written by some professors at MIT and Harvard. They were seeking to explain how a neural network with just thousands or millions of parameters can generalize tasks (like object recognition) that have a seemingly infinite number of possibilities. Mathematicians have struggled to explain it. But the authors of the paper described in this article claim to have discovered the connection\u200a\u2014\u200ain the laws of our universe. Are you hooked yet?\n\nThe answer is somewhat anti-climatic. The authors believe that the universe is not one with infinite possibilities. If you look at physics formulas, you find polynomial functions with just a different integers as the exponent (2. 3. 4). You don\u2019t see physical phenomena described with formulas where the exponent is 19. And because the universe doesn\u2019t have infinite possibilities, it makes it possible for \u201csmall\u201d networks to describe large data.\n\nMachine Learning with Weak Supervision\u200a\u2014\u200aThis blog post describes a new open source project called Snorkel that enables researchers with the task that everyone hates\u200a\u2014\u200afinding and creating datasets\u200a\u2014\u200ato create labeled data rapidly and in an automated way. The problem, as described by the authors, is that there isn\u2019t enough labeled data for data scientists to create meaningful products. Sure, there are giant sets of labeled images of dog breeds or faces, but these don\u2019t help people in the fields of finance, healthcare, or government whose data requires deep expertise to curate and label. Snorkel is all about combining a set of heuristics or rules of thumb created by experts (this is called weak supervision) into a single model that is able to accurately label data. The labeled data created via this approach is remarkably effective, and is definitely worth checking out!\n\nHow Hillary\u2019s Campaign is (Almost Certainly) Using Big Data\u200a\u2014\u200aWe try to stay away from politics and religion here at Gab41, but this was just too interesting to not mention. The linked article on Scientific American discusses how campaigns use terms like \u201cuplift\u201d and \u201cpersuasion modeling\u201d when thinking about voters. Those are the same terms that you\u2019ll see advertisers talking about. The last few political campaign seasons have seen a marked increase in the use of analytics, both from the campaigns and from the news sources that cover them (including my favorite\u200a\u2014\u200afivethirtyeight).\n\nStealing Machine Learning Models via Prediction APIs- Say that you\u2019re a researcher and you\u2019ve spent the last 5 years developing the world\u2019s best model to identify different types of cars. You\u2019re the world\u2019s best at telling the difference between the Aston Martin Vanquish and Vantage (without resorting to reading the back of the car\u200a\u2014\u200awhich is what I do).\n\nYou decide that this is a commercially interesting product and so you start a company. You choose to make your product available via an API so that anyone who wants images of cars labeled can use your service. You should reconsider, according to the authors of this paper. They describe some pretty generic attacks that enable an API user to very quickly extract relevant information about the underlying models that provide answers to their queries. It is pretty interesting work about the leakiness of machine learning models.\n\nAs an aside, if you have been working on classifying vehicles, let me know.\n\nUnsupervised Monocular Depth Estimation\u200a\u2014\u200aThis paper is outside the typical interests at Lab41, but I still found it to be really interesting. The problem the authors of this paper are contending with is that of depth estimation. A lot of ink has been spilled in describing different methods to do depth estimation of objects within images when you have multiple images (which provide perspective\u200a\u2014\u200aand therefore aid in depth estimation). New research is focused on doing the same thing\u200a\u2014\u200abut with a single image.\n\nThe authors contend that most of the current approaches to monocular depth estimation use tables of ground-truth depth data that is previously learned. They don\u2019t need to because they can learn the depth in an unsupervised fashion. What\u2019s their trick you might ask? They use binocular cameras. Huh? I could have sworn that the title of the paper had the word monocular in it. Still, the technique they developed is novel. They train a CNN to predict or reconstruct what the right-side camera photographed using just the left-side image. This trained network has therefore learned the depth in the scene. Pretty cool.\n\n15 Favorite Data Science Resources \u2014The folks over at Kaggle have put together a list of their favorite Data Science resources on the Internet. It\u2019s a pretty good list\u200a\u2014\u200aone that we\u2019re happy to recommend to you. It includes everything from personal blogs to article aggregators to newsletters. There\u2019s only one problem with the list. Where is Gab41?!\n\nUnofficial Self-Organizing Conference on Machine Learning\u200a\u2014\u200aEveryone\u2019s favorite group of AI specialists over at OpenAI are having their own conference. And because they are ML celebrities, their official conference got overbooked. So they are supporting an unofficial conference as well. So if you want to see if a \u201cself-organizing\u201d conference can work and happen to be in the bay area on Oct 1, you should attend.\n\nMy shameless plug this week is for our fearless leader\u200a\u2014\u200aBob. A few months ago, Bob wrote what is still the most popular article of all time at Gab41\u200a\u2014\u200aI need an AI BS Meter. Yes, the title was a bit \u201cclick-baity\u201d (but at least it wasn\u2019t\u200a\u2014\u200a4 reasons you should be worried about AI, you\u2019ll never believe #3!), but the article discussed results provenance. This concept of trusting the results from your model is something that resonated with our audience. And so, Bob is back with a new article\u200a\u2014\u200aA Chatbot? Are you Sirious?\n\nBob appears to have traded click-bait in his title for puns, but the important takeaway is that he presents a serious option for how you might build a system to helps analysts and data scientists with results provenance. I suggest you take a look.\n\nThat\u2019s all I\u2019ve got but I hope to see you again next week on Across the Network!", 
        "title": "Across the Network \u2014 AI Week in Review Sept 23 \u2013"
    }, 
    {
        "url": "https://medium.com/self-driving-cars/behavioral-cloning-25d6c8b88f37?source=tag_archive---------3----------------", 
        "text": "One of the first modules in our Self-Driving Car Nanodegree program will be Deep Learning. This is such a fun topic!\n\nWe\u2019ll be covering behavioral cloning, which is a technique whereby you drive the car (or the simulated car, in this case) yourself and then pass the data to a neural network. The neural network trains on your driving data and auto-magically learns how to drive the car, without any other information. You don\u2019t have to tell it about the color of the road or which way to turn or where the horizon is. You just pass in data of your own driving and it learns.\n\nBy the end, students will be building their own neural networks to drive cars, just like in this video.", 
        "title": "Behavioral Cloning \u2013 Self-Driving Cars \u2013"
    }, 
    {
        "url": "https://medium.com/@train_ugly/death-of-the-zoo-tiger-dfff67dd667b?source=tag_archive---------4----------------", 
        "text": "Back in the day the recipe for a comfortable, stable life was fairly straight forward: pick something, do that something a lot, get good at that something, get paid to do that something for the next few decades.\n\nAnd the way that we taught and approached learning reflected that time and that environment.\n\nShow up, fit in, obey the rules, sit at your station, memorize, tick the boxes, repeat.\n\nOur approach to learning aligned with what we were looking for in the workplace.\n\nLet\u2019s call this the era of the zoo tiger\u200a\u2014\u200awhere sitting in your cage and doing your job was exchanged for:\n\ncomfort (basic needs are met)\n\nsafety (no surprises, no mix ups, no danger, no struggle)\n\nconstancy (steady paychecks and steady meals\u200a\u2014\u200apredictability)\n\nThis approach worked for decades. But now it doesn\u2019t.\n\nThe zoos are gone. Society and the workplace have been turned on their heads\u200a\u2014\u200aconsistency, stability, and specialization are dead.\n\nAnd in this new world\u200a\u2014\u200athe well trained and obedient zoo tigers are screwed.\n\nWhile the learners, the jungle tigers, the ones who have been living in the wild, learning to adapt, to struggle, deal with adversity, to solve problems\u200a\u2014\u200aare thriving.\n\nToday, as people and organizations, we need to be jungle tigers. To thrive we must be able to adapt, identify and solve problems, connect, and learn on the fly.\n\nThe way that we teach and learn must reflect that. Unfortunately, it does not\u200a\u2014\u200aWe\u2019re stuck in the past raising zoo tigers.\n\nWe\u2019re developing rule followers, station sitters, and box tickers, then throwing them out into the wild\u200a\u2014\u200aan environment where NONE of that matters anymore.\n\nThe skills that matter now, simply CANNOT be developed in the zoo.\n\nIt is impossible to learn to adapt in an environment where there is no change.\n\nIt is impossible to grow in and environment absent of struggle.\n\nIt is impossible to learn to deal with adversity when there are no failures.\n\nIt is impossible to learn how to identify and solve problems when there are none to work through.\n\nThe skills that matter now are forged IN THE WILD.\n\nThe hungry nights, the dangerous encounters, the struggle, the adversity, the unpredictability are where the growth comes from.\n\nWe all have the capacity to become our own version of a jungle tiger\u200a\u2014\u200awe just need enough time in the proper environment to build our skills.\n\nI promise you\u2019re going to fall on your face\u200a\u2014\u200amany times\u200a\u2014\u200awhile you\u2019re out in the wild. Which is exactly why you need to go there.", 
        "title": "Death of the Zoo Tiger \u2013 Trevor-Train Ugly \u2013"
    }
]