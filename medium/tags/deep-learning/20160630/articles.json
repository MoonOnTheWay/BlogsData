[
    {
        "url": "https://artplusmarketing.com/painting-with-ais-6bcff75d57e7?source=tag_archive---------0----------------", 
        "text": "A year or two ago, if you\u2019d asked, I would have suggested that yes, eventually, software and robots will take all our jobs. The only jobs that were potentially safe were the purely creative ones: writers, painters, musicians, artists of one kind or another. But this year I started painting, and recently I began collaborating with deep neural networks as part of my artistic process. Now I can see that the future seldom runs in a straight line from the present; it usually ends up being far more nuanced, with twists and turns that are only apparent and obvious in hindsight. Integrating an AI into my artistic process has enhanced my work and made me a better painter too.\n\nPart of my current artistic process is to work with photos. So far I\u2019ve used family photos or found photos with compositions that I find appealing. I\u2019m especially drawn to scenes with anonymous figures who have their backs turned or their faces fully or partially obscured, and those are the types of things that I\u2019ve painted. Here are a couple of example paintings from early this year:\n\n\u201cWildwood 66\u201d is based on a photo taken of my Aunt and Uncle at the beach in Wildwood, New Jersey in 1966, before I was born. In the photo my Aunt and Uncle stand prominently in the foreground, and in the background there are numerous figures heading into and coming out of the waves.\n\nWhen I started working with this image I removed my Aunt and Uncle entirely, and in that way removed any personal connection I had to it; it\u2019s those background figures that I love. They\u2019re uninhibited because they aren\u2019t the subject of the photo or even aware it\u2019s being taken; they\u2019re anonymous and many of them are likely dead; each one had or has a life that\u2019s probably just beyond our ability to know anything about. All we have is the photograph that gives us a tiny slice of them in that one moment. After a couple of test paintings I took the background figures that I loved the most and composed them into an idealistic, nostalgic and ultimately weird landscape where even when they\u2019re together, they\u2019re separate.\n\nThis is a self-portrait, based on a photo taken by my wife. \u201cHaver\u201d is my internal art-persona. He is a honey-badger who doesn\u2019t stop and who only thinks in 100 painting increments. He\u2019s also a way for me to anonymize the idea of myself as a subject (Haver\u2019s beard is much fuller than my own). Again there\u2019s a disconnect between the subject and the background or landscape; in this case I was exploring the idea of personal acceptance.\n\nPart way through the year I bought a brown bag full of photos for $5. I didn\u2019t pick and choose the photos, I just shovelled them into the bag from a giant bin in a junk store, happy with the idea that they would provide me with many new subjects and compositions. I was right; they were mostly vacation photos from the late 90s and early 2000s. Here\u2019s a painting based on one of the compositions that really appealed to me:\n\nI removed, simplified and flattened almost everything from the original photo. I only kept a small number of figures that I liked, again totally anonymous people, and put them in water that enhances their separation from each other, even when they\u2019re together.\n\nEarly in June I discovered style-transfer and neural-style. They\u2019re both applications of a neural algorithm that analyzes an artistic style and then applies it to a photograph. I immediately wanted to use them to apply the style of some of my own paintings to the found photos that I\u2019d planned to paint. Of the two, I\u2019ve found neural-style to be more feature rich; it allows you to blend multiple style images and to produce photos at various points in the processing. Given that processing an image can take many hours, this is a big advantage because you can see relatively early whether something is going to work or not. Sometimes the earlier iterations of the process end up being more interesting as well. Here\u2019s neural-style, doing it\u2019s thing to a selfie based on the style of one of my paintings:\n\nOnce I got the algorithm software installed and tested, I took a beautiful found photo of two anonymous figures heading towards a bus in northern Canada and applied the style of \u201cHaver in a pink lawn chair\u201d to it.", 
        "title": "Painting with AIs \u2013"
    }, 
    {
        "url": "https://medium.com/@ODSC/amazon-enters-the-open-source-deep-learning-fray-464ad8dd812b?source=tag_archive---------1----------------", 
        "text": "The Synergy Research Group\u2019s last report of 2015 attributed 31% of the cloud computing market to Amazon\u2019s Amazon Web Services (AWS), nearly four times as much as its nearest competitor, Microsoft. This would come as no surprise to any programmer, Data Engineer, or Data Scientist, AWS is a mainstay when it comes to working at scale. It is integral to the internet\u2019s infrastructure. In light of this, Amazon\u2019s recent analytics offering is surprisingly banausic. Competitors like Microsoft and IBM released dedicated analytics platforms to support Data Scientists and have open-sourced deep learning frameworks such as CNTK and TensorFlow. Comparatively, Amazon has been resting on its laurels. Yes, there is AWS IOT, AWS EMR, AWS Kinesis, and AWS Machine Learning, but these seem to cater more to engineering rather than Data Science. Outside of pre-built instances like the Data Science Toolbox\u200a\u2014\u200aPython, Apache Jupyter, and Apache Spark\u200a\u2014\u200aData Scientists using AWS tools have to go through the process of setting up every component they need from scratch. This may be about to change with the recent open-sourcing of Amazon\u2019s Deep Scalable Sparse Tensor Network Engine. It\u2019s quite a mouthful and the abbreviation isn\u2019t much better, ADSSTNE. Amazon says you can just call it\u2026 Destiny.\n\nLike other frameworks of its ilk, Amazon Destiny facilitates the training and deploying of deep learning models on GPUs, and can be run locally, on a Docker container, or on AWS on a GPU instance. Unlike similar frameworks, Amazon Destiny is orientated towards search and recommendations\u200a\u2014\u200ano surprise given its parent company. The release notes claim that Destiny is the fastest deep learning library available, and that it\u2019s the best at using multiple GPUs on a single server. At the other hand, Destiny is a bit bare-bones. The documentation is sparse, the library only works with data in the NetCDF format, and it has no support for Convolutional or Recurrent Neural Networks. (The addition of CNN\u2019s and RNN\u2019s is apparently next in the pipeline.)\n\nTime and will tell if this release is a token open-source offering or thoughtful gift to the wider analytics community.", 
        "title": "Amazon Enters The Open-Source Deep Learning Fray \u2013 #ODSC \u2013"
    }, 
    {
        "url": "https://medium.com/@DollyEFisher/the-next-big-thing-for-artificial-intelligence-d91a257ea1fc?source=tag_archive---------2----------------", 
        "text": "The Dartmouth Conference of 1956 is considered by many to the be the birth of artificial intelligence. AI researches went forward from there confident that machines that could think like humans were just around the corner. That was 60 years ago; and while artificial intelligence has come a long way since then, we\u2019re still not seeing machines that can truly think like humans do. Today researchers are once again hopeful that true artificial intelligence (an oxymoron if ever there was one) is within reach. But are we any closer than researchers were in the 50s? Here\u2019s a look at some of the recent accomplishments, and setbacks that AI researchers are experiencing.\n\nWhere we\u2019re seeing the biggest advancements in AI is computers that can do one thing extremely well. In the near future, we could see some jobs completely disappear as they are outsourced to machines that can do those same jobs much more efficiently and safely. We could be facing a labor displacement of a magnitude that hasn\u2019t been seen since the industrial revolution.\n\nWhile AI can be programmed to do certain tasks very well, a major hang up that researchers face is that they can\u2019t teach AI to learn to do other things. All \u201clearning\u201d requires some kind of input from researchers. But humans could be placed in a room by themselves and can learn all on their own. This is called predictive learning or unsupervised learning and it\u2019s an important key to solving the riddle of true artificial intelligence. For now, the big hurdle standing in the way of truly intelligent machines is the ability to teach them common sense, something humans are simply born with.\n\nArtificial Intelligence News brought to you by artificialbrilliance\u00a0.com", 
        "title": "The next big thing for artificial intelligence \u2013 Dolly E. Fisher \u2013"
    }
]