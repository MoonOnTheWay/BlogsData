[
    {
        "url": "https://medium.com/@farshchi/the-next-renaissance-is-upon-us-458240dc0ee7?source=tag_archive---------0----------------", 
        "text": "I worry about Peter Thiel\u2019s observation of a slowdown in technology progress over the past 50 years. During a recent trip to Florence, I was surrounded by expressions of Renaissance-era artists whose inspiration catalyzed experiments which yielded results that were quickly accelerated to the mainstream.\n\nGalileo\u2019s observation of pendulum motion was swiftly followed by timepieces becoming commonplace. His observations of basic motion were mathematically modeled by Newton, whose famous laws were thought to describe all physics until the introduction of quantum physics a century ago. Shortly after Newton, Bernoulli, Carnot, Gibbs, Thomson, and others developed the laws of thermodynamics, yielding heat engines that quickly gave birth to the industrial age. The Wright Brothers soon coupled these engines to their unique \u201cstable\u201d aircraft design to catalyze general aviation less than a decade later. Shortly after World War II, integrated circuits took compute, sensing and communications systems from warehouses to rooms to pockets over the course of 20 years. Finally, advances in chemistry, materials, and processes have made compute and communications affordable. With the Internet, billions of people are now connected, with access to the vast corpus of human knowledge.\n\nWhere do we go from here? What series of events will catalyze the next Renaissance to shepherd the next major advances in technology and culture?\n\nThe practice of science has become ever more narrow, cumbersome, and unapproachable. The complexity of science has made its practice very narrow in scope. An \u201cexpert\u201d undergoes many years of training, only to be on the cutting-edge in a very specific field. Experiments are very complex, take many years to accomplish and are difficult to replicate. The arduous nature of doing science makes its practice less attractive for talented youth, prompting them to go to trading desks rather than lab benches.\n\nWith information becoming largely ubiquitous, engineers are redirecting their attention toward intelligence machines. There has been plenty of discussion around how \u201cdiscovery\u201d is different from \u201csearch,\u201d with the latter being about seeking and the former more akin to invention\u200a\u2014\u200awhich we do as humans. Conventional \u201cstate machine\u201d representations of compute are not conducive to machines that are expected to \u201cthink.\u201d Recent work on deep neural nets have yielded algorithms that can train themselves to identify characters, objects and people in images, process speech and do natural language processing. These algorithms establish patterns in data as they train on many thousands of samples, and like the human brain, recognize those patterns and make distinctions.\n\nThe art, science, literature and culture that blossomed during the Renaissance was a self-reinforcing phenomenon that catalyzed modern technology and culture. Ruling aristocrats further heightened their stature by embracing and funding the very best talent\u200a\u2014\u200asimilar to how billionaires fund startups and research today. This collaboration generated fabulous works of art and advanced the cutting edge of science which served as the basis of new industries\u200a\u2014\u200afurther empowering their nations and people. The advent of neural nets and intelligent machines will liberate aspiring inventors from spending time learning specifics, building code to test hypothesis and taking arduous measurements, and instead spending their efforts on advancing science and advancing humanity. By leveraging \u201cactive\u201d vs. \u201cpassive\u201d tools, I expect amazing new discoveries to be made, turning science fiction into science fact.\n\nShahin is a partner at Lux Capital. Based in Silicon Valley, he invests in space, robotic, AI, transportation, VR and brain-tech companies; follow him on Twitter@farshchi", 
        "title": "The Next Renaissance is Upon Us \u2013 Shahin Farshchi \u2013"
    }, 
    {
        "url": "https://medium.com/@helen_97703/is-ai-unfair-840da314790b?source=tag_archive---------1----------------", 
        "text": "There\u2019s been a lot of discussion recently about unfairness and bias in AI. The word \u201calgorithm\u201d now seems lodged in our collective consciousness as if it\u2019s some mysterious entity, operating outside of our control and being used by unseen others who have an agenda of manipulating our on-line lives.\n\nAlgorithms are simply sets of rules and we\u2019ve had them for a long time. Before big data and machine learning algorithms, algorithms were hand-coded by programmers, with any bias handled with policy. Policy was informed by statistics. People made decisions on policies, which determined such things as who would get a loan approved. Embedded in any insurance company\u2019s actuarial tables are data on whether men or women are safer drivers or what should be the difference in relative premiums for low income versus high income households. We didn\u2019t refer to the algorithms as having bias. We referred to statistics, risk and fair-treatment policies or laws preventing discrimination.\n\nMachine learning algorithms are \u201cknowledge levers\u201d. We can use machine learning AI to create a lot of new knowledge from a relatively small amount of prior knowledge. This makes them very powerful engines of discovery. But it can also result in propagation of any bias when they are scaled up and used across many problems, computers or social networks.\n\nSo what new sources of unfairness should we be worried about with the diffusion of machine learning algorithms?\n\nInequality is bad for society, globally as well as within nations. Developed economies, with sophisticated technology infrastructure and well-developed data systems, will be able to access the benefits of machine learning AI at a much faster rate and to much greater effect than developing countries.\n\nIn this report (funded by Facebook) AI diffusion across the global economy was compared with the uptake of broadband and mobile. Broadband is an infrastructure technology that makes information easier, cheaper, and faster to access so in many respects offers perhaps the most intuitive analogy to AI. Mobile, on the other hand, is general purpose and distributed, offering users more ways to interact and connect, transact and communicate. Broadband had the biggest positive impact on GDP in developed economies while mobile adoption had a greater positive impact on GDP in lower income countries.\n\nSophisticated stores of digitally structured data abound in wealthy countries. On the other hand, with breakthroughs in machine processing of unstructured data as well as computer vision and natural language processing, developing economies may have a chance to \u201cleap frog\u201d a lot of traditional and costly data infrastructure.\n\nBut it\u2019s impossible to ignore the head start that developed economies have in the AI age and the risk of further economic inequality between nations.\n\nThe increase in inequality within the USA over the last 30 years is now widely recognized. The situation is complex and it\u2019s difficult to pull apart the threads of cause and effect. There\u2019s no denying the sense of insecurity pervading much of society. Mass unemployment, inequities in educational opportunity, a world of haves and have-nots, super-wealth and corrupted power have undermined both peace and democracy before.\n\nGoogle offensively labeling black people as gorillas? Staples discriminating against poor people? Gender stereotyping in search results based on what job is queried? Discriminatory on-line advertising that associates low paying work with women? All happened.\n\nProgrammers routinely incorporate user data into complex algorithms, heuristics, and applications. Most of the time what we get is beneficial, giving us more finely grained information. But it can have unintended consequences such as discrimination, especially if information on minorities is underrepresented in the data that was used to train the algorithm.\n\nWe should think of these unwarranted associations as bugs. And do what we used to do with policy (check we had it right) with a new form of debugging software. If it\u2019s possible to automate the recommendation, it\u2019s possible to automate the policy. There\u2019s no excuse for discrimination, it\u2019s against the law. Discrimination in this context is machine bias. And machine bias is a bug. No one should hide behind an algorithm. Period.\n\nThe gurus of machine learning agree on one aspect of the technology: we don\u2019t know quite how it works but it does. Just consider that for a moment. When the output of an algorithm is no longer traceable, when the answer is instead bound in complex, multidimensional probability, and the person who is accountable can\u2019t explain why a particular decision was made, what are we to think?\n\nMuch of what we consider fairness relies on trust as much as it does on an explicit demonstration of right over wrong. Decisions and actions aren\u2019t always black and white. Our sense of justice having been done or a decision been made fairly is as much based on how we were treated and whether someone acted in good faith as it is on a categorical boundary. If people defer to an algorithm, shrug their shoulders and say \u201cwell I don\u2019t understand it either\u201d trust will be mortally wounded.\n\nName any thorny ethical issue and chances are there\u2019s no known, much less simple, solution. The law is a hazy code of a society\u2019s ethics, based on context and prior cases. Intuition fails us when we are presented with a dilemma. We can hold two competing views in our head but a machine cannot.\n\nThe scope and depth of discussion in the ethics of wide adoption of machine learning algorithms and intelligent robots is intriguing. From expanding the \u201ctrolley problem\u201d in debating the ethics of self-driving cars to figuring out how robots employed in medical care should handle a person who refuses to take their medicine, there is a burgeoning discipline in the ethics of modern AI systems. Some AI experts have even argued that, if machine learning algorithms are so adept at pulling insights from data, the best solution is to turn them loose on to our actions and have the machines learn the rules of our (actual) ethics. Essentially, to solve ethical dilemmas with real data.\n\nThere will be years of work in big picture, machine learning AI ethics, but let\u2019s not overlook there are also hidden ethical issues which are just as interesting, much more near term and far more likely to affect our daily lives. In any algorithm design there is necessarily a certain number of false positives and false negatives. The designer of the algorithm has to make tradeoffs between these two. If this is an algorithm for identifying pictures of cats the tradeoff may not be especially critical but, if it\u2019s an algorithm for medical imagining for a dangerous condition, the design of this tradeoff has profound consequences. Such an algorithm embeds ethical considerations for the diagnosing doctor. The designer of the algorithm, not the doctor, makes the tradeoff between the risk of missing cancer in a small number of cases versus the risk of unnecessarily alarming a group of people who are, in fact, not sick.\n\nFiltering and recommendation are a kind of \u201cbias by choice.\u201d Algorithms are value-laden and the algorithms we use everyday for selecting our newsfeed or products we might like are laden with our own biases as much as they are with those of the algorithm\u2019s designer. Recently there\u2019s been an almost indignant realization that these algorithms tend to feed us what they know we like, based on what we have chosen in the past. There\u2019s been a sense of backlash, a kind of \u201chow dare they\u201d vibe. But that\u2019s what we wanted wasn\u2019t it? For this problem, there are some options.\n\nOne would be some kind of regulation of these algorithms by some\u200a\u2014\u200aso called\u200a\u2014\u200aunbiased party. The trouble with that is, who is unbiased? We are all biased so looking to humans for unbiased filtering won\u2019t solve the problem of bias. We will simply trade one bias for another. The big American technology companies are hitting the threshold to invite regulation in some parts of the world, but it\u2019s a stretch to see that in the USA. The deeper issue here is the power of the free algorithm over willingness to pay for trusted content from established publishers.\n\nAnother option would be to have algorithms with settings and preferences we could configure. Great! Toggle the \u201cuncomfortable but should know\u201d switch. But seriously, it would be useful to be able to tune recommendations and feeds more transparently and deliberately. Consumers shouldn\u2019t have to train their algorithms with haphazard selections accumulated over time.\n\nAnother, low tech and available-now option for those worried they don\u2019t have enough alternative commentary fed directly to them, is to read comments on stories. It\u2019s almost guaranteed there will be comments from people who present an alternate view. It\u2019s a good challenge to remain skeptical and open minded in the face of a conflicting opinion, much less maintain respect for the person who holds it. But isn\u2019t that what the internet is all about? Maybe what we are really worried about is people who we feel should share our views not being algorithmically fed our views.\n\nAbsolving responsibility to an algorithm was never acceptable and it is unlikely to be in future. Accountability is a uniquely human attribute. Accountability and automation will evolve iteratively. In an age of machines that learn and act autonomously in the physical world, innovation within society\u2019s current institutions will be vital in order to maintain safe and fair AI.", 
        "title": "Is AI Unfair? \u2013 Helen Edwards \u2013"
    }, 
    {
        "url": "https://medium.com/@brucerobbins/eating-my-words-2c9b71406d5e?source=tag_archive---------2----------------", 
        "text": "Neural Networks and Art have not sat well at the same table, until now it appears.\n\nI worked as a visiting lecturer on the Post Grad MA course (run by Micheal Craig Martin and Jon Thomson) in the early 80\u2019s and around then had spent some time playing with the ideas that machine learning opens up. Access to the technology was difficult in those days and I moved on to other things.\n\nI also had an interest in film and prior to that took a shine to Philip K Dicks novel. So when Blade Runner was released I went to see it for two reasons. Ridley Scott went to the Royal College of Art at the same time as my then boss, Roy Grayson, at Brighton (film was a part of the syllabus for the fine art course I worked on there) was there. So coincidences!\n\nI visited the film again recently, and really enjoyed a radio version of \u201cDo Androids Dream of Electric Sheep\u201d on the BBC 4 last year. I referred to the film in a recent blog post last year (DO DATA SCIENTISTS DREAM OF ELECTRIC SHEEP) and an recent update of it. Here I looked down on the idea of a use for AI in art \u201cThe generation of surreal and, quite frankly unattractive images may make \u2018DeepDream\u2019 generated images look a bit artistic, it does have a sort of mad Max Ernst\u2019s \u2018Robing of the Bride\u2019 quality about it.\u201d \u201cAs attractive as Surrealism is, it lacks the beauty and poise of Dada. It certainly lacks the insights. The significance for students of ML is that while it can work much quicker and process much more information it is a still a very crude dumb machine compared to the slow old human intelligence box. I suspect this will always be the case and while I would never want to underestimate machine based data processing it is still a bit pre-historic, and, like Surrealism, it lacks the beauty and poise of Dada.\u201d\n\nYour post has me eating my words somewhat. It appears your work does have the \u201cbeauty and poise of Dada\u201d and I enjoyed your article very much. Please feel free to let me (via XCiPI) know what you are doing in this area in the future. I am really interested and would find it interesting to follow your work.", 
        "title": "Eating my words. \u2013 Bruce Robbins \u2013"
    }
]