[
    {
        "url": "https://machinelearnings.co/tensorflow-text-classification-615198df9231?source=tag_archive---------0----------------", 
        "text": "On Nov 9, it\u2019s been an official 1 year since TensorFlow released. Looking back there has been a lot of progress done towards making TensorFlow the most used machine learning framework.\n\nAnd as this milestone passed, I realized that still haven\u2019t published long promised blog about text classification. Even though examples has been there in TensorFlow repository, they didn\u2019t have very good description.\n\nText classification is one of the most important parts of machine learning, as most of people\u2019s communication is done via text. We write blog articles, email, tweet, leave notes and comments. All this information is there but is really hard to use compared to a form or data collected from some sensor.\n\nThere been classic NLP techniques dealing with this, by mostly using words as symbols and running linear models. This techniques worked but were very brittle. Recent adoption of embeddings and deep learning opened up a new ways of handling text.\n\nDifference between words as symbols and words as embeddings is similar to described in Part 3 of tutorial\u200a\u2014\u200aamong other things, allowing to compress similar categories (words) into a smaller space, thus allowing next layers of neural network using this similarity to do job better.\n\nNow, simplest model that everybody should start solving their problem with (or baseline in ML community) is a bag-of-words model. Something that takes words independent of their order and uses it to predict your goal.\n\nFor example, we will take a DBPedia dataset described in this paper. The dataset contains first paragraph of the wikipedia page for ~0.5M entities and the label is on of 15 categories (like People, Company, etc). This is usually called \u201cTopic classification\u201d and can be used in variety of cases, from analyzing comments on your website to sorting incoming emails.\n\nNote, that exactly same techniques would work for sentiment analysis (categorizing if the text is positive or negative sentiment) and even for Question Answering.\n\nFull example can be found in TensorFlow examples: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py (note, that code there will be updated with new APIs so it\u2019s better to check out there).\n\nFirst, we need to retrieve and prepare data:\n\nTensorFlow has a handy learn.datasets module that contains few of example datasets, like DBPedia. By accessing it, it will download it and load it in memory. Note, load_dataset has a size argument, that by default for DBPedia loads a small subset. To load full dataset, pass an empty string.\n\nGoing from sentences (strings) to matrices (what TensorFlow or any ML can work with), requires to find all words in the text and remap them into IDs\u200a\u2014\u200aa number per each unique word. This is exactly the same as for categorical variables in previous section of this tutorial, but now instead of one value per example, we get a list of values per each word in sentence. For example \u201cmy work is cool!\u201d would map into [23, 500, 5, 1402, 17] (where 17 is \u201c!\u201d).\n\nWe also want to make sure that each sentence is the same length, so we provide MAX_DOCUMENT_LENGTH to identify how long each sentence will be (longer sentences will be truncated, and shorter ones padded).\n\nNow resulting x_train and x_test contain just a matrices that we can pass to our learning algorithm.\n\nWe create a simple TensorFlow model function, that takes features (list of word IDs) and target (one of 15 classes). We use simple bow_encoder which combines creation of embedding matrix, lookup for each ID in the input and then averaging them. Then we just add a fully connected layer on top and the use it to compute loss and classification results tf.argmax(logits, 1). Adding training regime (Adam with 0.01 learning rate) and that\u2019s our function.\n\nNow by simply invoking it with training data we prepared we can see how well bag of words work for this problem:\n\nNote, you can play with training steps and training regime (different learning rate and other parameters optimize_loss has).\n\nBut as we all know the bag of words is not really modeling how languages work\u200a\u2014\u200aorder of words matter (even though less then you would think in practice) and we want to handle that as well.\n\nThere are few ways how one can do\u200a\u2014\u200aadd bi-grams, use convolution to learn n-grams over text or Recurrent Neural Network to handle long term dependencies in text. For various problems any of this methods can work better. You can see examples of all of them implemented here (including characters): https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/learn#text-classification\n\nIn this post let\u2019s review the Recurrent Neural Network implementation:\n\nHopefully comments inlined with code give a good description what is done on each step. As you can see the code is not very different from bag of words model, replacing just \u201cencoding\u201d part with rnn function call.\n\nThe same Estimator call with different model function will allow to run this model on the data and see improvements from understanding the sequence in which words appear.\n\nYou now know how to apply some of the basic architectures for text / document classification. Other things to consider is to to load pre-trained embeddings (like GloVe) and doing semi-supervised training, which allows model spend more time training for your problem instead of learning about language from scratch. I\u2019ll try to talk about this in some of the next posts.\n\nAdditionally, I\u2019ll talk more about how to make this models to converge / perform better with some of the tricks implemented in optimize_loss and tf.layers.", 
        "title": "TensorFlow \u2014 Text Classification \u2013"
    }, 
    {
        "url": "https://medium.com/@erikhallstrm/using-the-tensorflow-multilayered-lstm-api-f6e7da7bbe40?source=tag_archive---------1----------------", 
        "text": "In the previous article we learned how to use the TensorFlow API to create a Recurrent neural network with Long short-term memory. In this post we will make that architecture deep, introducing a LSTM with multiple layers.\n\nOne thing to notice is that for every layer of the network we will need a hidden state and a cell state. Typically the input to the next LSTM-layer will be the previous state for that particular layer as well as the hidden activations of the \u201clower\u201d or previous layer. There is a good diagram in this article.\n\nWe could continue to store the states for each layer in many , but that would require a lot of overhead. You can only input data to the placeholders trough the as Python lists or Numpy arrays anyways (not as ) so we still would have to convert between the datatypes. Why not save the whole state for the network in a big tensor? In order to do this the first thing we want to do is to replace and on line 81\u201382 with the more generic:\n\nYou also have to declare the new setting in the beginning of the file, but you may choose any number of layers. The \u201c2\u201d refers to the two states, cell- and hidden-state. So for each layer and each sample in a batch, we have both a cell state and a hidden state vector with the size .\n\nNow modify lines 93 to 103 (the run function and the separation of the state tuple) back to the original statement, since the state is now stored in a single tensor.\n\nYou can change these lines 28 to 30 in the previous post:\n\nTo a single placeholder containing the whole state.\n\nSince the TensorFlow Multilayer-LSTM-API accepts the state as a tuple of LSTMTuples, we need to unpack the state state into this structure. For each layer in the state we then create a stated, and put these in a tuple, as shown below. Add this just after the placeholder.\n\nThe forward pass on lines 40 and 41 should be changed to this:\n\nThe multi-layered LSTM is created by first making a single , and then duplicating this cell in an array, supplying it to the API call. The forward pass uses the usual , let\u2019s print the output of this function, the and variables.\n\nTake a look at the tensor names between single quotes, we see that the RNN is unrolled 15 times. In the all outputs have the name \u201cCell2\u201d, it means that we get the output of the last LSTM layer\u2019s hidden state in the list. Furthermore the LSTMStateTuple in the gives the whole state of all layers in the network. \u201cCell0\u201d refers to the first layer, \u201cCell1\u201d to the second and \u201cCell2\u201d to the third and final layer, \u201ch\u201d and \u201cc\u201d refers to hidden- and cell state.\n\nThis is the whole self-contained script, just copy and run.\n\nIn the next article we will speed up the graph creation by not splitting up our inputs and labels into a Python list.", 
        "title": "Using the Multilayered LSTM API in TensorFlow (4/7)"
    }, 
    {
        "url": "https://medium.com/@erikhallstrm/using-the-dropout-api-in-tensorflow-2b2e6561dfeb?source=tag_archive---------2----------------", 
        "text": "In the previous part we built a multi-layered LSTM RNN. In this post we will make it less prone to overfitting (called regularizing) by adding a something called dropout. It\u2019s a weird trick to randomly turn off activations of neurons during training, and was pioneered by Geoffrey Hinton among others, you can read their initial article here.\n\nFortunately this is very simple to do in TensorFlow, between the lines 41\u201342 you simply add a with the probability to not drop out, called . Change lines 41\u201342 to the code below.\n\nDon\u2019t drop out too much or you will need a large state to be sure to keep some of the information (in our toy example at least). As you can read in this article dropout is implemented between RNN layers in TensorFlow, not on recurrent connections.\n\nThis is the whole self-contained script, just copy and run.\n\nIn the next part we will further regularize it by using something called batch normalization. Stay tuned, it will be coming soon\u00a0:)", 
        "title": "Using the Dropout API in TensorFlow (6/7) \u2013 Erik Hallstr\u00f6m \u2013"
    }, 
    {
        "url": "https://medium.com/@KunfengChen/build-a-machine-learning-dev-box-with-nvidia-titan-x-pascal-de18c0625dc2?source=tag_archive---------3----------------", 
        "text": "It\u2019 been a long while since I built a desktop for a home entertainment system. I thought I won\u2019t using another PC since I have moved to Mac machines. Well, things keep changing and they repeat themselves in different flavors and levels. The PC is back again for me.\n\nI have been helping a machine learning startup company to grow my career path. As a software engineer, machine learning is the next field to pursue. In order to save time on developing the algorithms and training the models, people are starting to use GPUs. The company has the new Titan X, so the CEO and me headed to Fry\u2019s and started a litter journey to build the box.\n\nI was a bit nervous. The hardware specs have been improved a lot so I needed to catch up. LGA2011, SATA III, DDR4\u00a0, PCI express gen3 x 16, M2, X99, SSD,\u00a0\u2026 Oh my. Spent some time researching and refreshing my memory on the internet and found some helpful links.\n\nSince we want to maximise the efficiency on a PC, we planed the spec to have two GPUs, one can occupy 16 PCI lanes. Therefore, 40 PCI lanes are essential, which nail it down to the X99 platforms. The platform cost a lot more but has room to grow to increase the computing power and speed. You would think how time can you really save to have additional performance? Trust me it will save more and more time down the road when data is growing and the model networks are deeper and deeper.\n\nAfter carefully reading the manuals several times, and turning the figures upside down again and again, made sure we were anti-static, and no fingers on the chips, we finally put together the box. The moment of the truth had come, we were ready to turn on the power. Wait, did you check this, that, and that? Yes.\n\n\u201cDid you turn on the power\u00a0\u2026.\u00a0?\u201d \u201c Yeah. Let me turn it off and on again\u201d Then why the fan goes up and down right away? There was no POST on the screen. Is the power connected and secured? Did we put the CPU on the right orientation? Let\u2019s try to swap the memory. Let\u2019s pull a component out one at a time and see\u2026", 
        "title": "Build a Machine Learning Dev Box with Nvidia Titan X Pascal"
    }, 
    {
        "url": "https://chatbotslife.com/from-sorting-cucumbers-to-curing-cancer-machine-learning-algorithms-will-do-everything-689161cbd4fb?source=tag_archive---------4----------------", 
        "text": "From Sorting Cucumbers to Curing Cancer: Machine Learning Algorithms Will Do Everything\n\nWe already know that algorithms are ruling the world. Consider it kind of God or Ghost from the machine powering them all, for good or evil\u200a\u2014\u200ayou decide.\n\nSoon Machine Learning Algorithms will be able to accurately guide forward-looking business decisions and reveal behaviors never before seen.\n\nGartner says that Automation and Machine Learning will shape the future of governments. Artificial Intelligence and Machine Learning is the Trend no 1 in Garner\u2019s Top 10 Strategic Technology Trends for 2017\n\nCan computers really learn mom\u2019s art of cucumber sorting? Makato\u2019s story will tell you How a Japanese cucumber farmer is using deep learning and Google\u2019s TensorFlow to sort cucumbers? In Japan, each farm has its own classification standard and there\u2019s no industry standard. At Makoto\u2019s farm, they sort them into nine different classes, and his mother sorts them all herself\u200a\u2014\u200aspending up to eight hours per day at peak harvesting times.\n\nAlgorithms can be used for the greater good. Algorithms are used for optimizing and individualizing cancer treatment. Boston-based Berg has spent the last six years perfecting an artificial intelligence platform that may soon crack the cancer code.\n\nMachine Learning based algorithms could accelerate the approval of powerful treatments for many cancers, improve clinical outcomes, and reduce costs for treating cancer.\n\nFor treating Cancer, Google DeepMind is launching a project to reduce the time it takes doctors to prepare treatment for head and neck cancers. DeepMind said that in addition to freeing up doctors, it hopes the radiotherapy algorithm developed through this research could eventually be used in other parts of the body.\n\nNot good for marketers, politicians, and salespeople, no more phony sales pitch or matchmaking. Today we use spell-checks, language translator plug-ins for your email\u200a\u2014\u200asoon you will have an algorithmic lie detector. These algorithms are much better at detecting lies than the average human. People manage to spot a lie 54% of the time, according to the researchers, whereas the computer lie detector detects it 70% of the time.\n\nYou just can\u2019t beat it. Algorithm that rewards the dog at exactly the right time, every time. Using sensors tied to the dog and algorithms to communicate back to the dog can be made totally autonomous. It\u2019s good for the dog too, as it gets the reward every time it follows the instruction.\n\nAlgorithms are a much better judge of measuring and tracking your vocal pitch, they can analyze acoustic features to sense any distress in the relationship.\n\nThe general theory is that 55 % of what you communicate is through body language, 38 % is through tone of voice, and 7 percent is through your actual words.\n\nSoon there will be an app that will give you rating to your relationship with your spouse\u200a\u2014\u200ajust swipe when you are getting into any argument.\n\nThis app works so well that it\u2019s been shown to help women avoid pregnancy with 99.5 percent reliability.After ovulation, women see a spike in progesterone, which makes their bodies up to 0.45 degrees Celsius warmer.\n\nYou need to enter your temperature in the app daily, and comparing the results with a broader dataset, the app lets you know when you can have unprotected sex (a green day) and when to use contraception, such as condoms (a red day). This app can also help women plan pregnancies, by taking the guesswork out of finding the best day to have sex.\n\nYou are watching your favorite TV show and you can almost certainly predict what happens next: a handshake, a hug, or maybe even a kiss -whenever two people meet.\n\nAn MIT machine-learning system analyzed television shows including \u201cThe Office\u201d and \u201cDesperate Housewives\u201d in order to predict human interactions such as hugging, kissing, shaking hands, or slapping five. This will be really helpful for the next generation of robots and they will be able to come close to humans\n\nThe kind of image you chose, color, filters etc. tells a lot about your mental health, and researchers have created a machine-learning algorithm to spot correlations between depression and image properties. So next time you blur that image or put a grayscale filter, make sure you smile a little to beat that algorithm\n\nIt\u2019s simple Machine Learning process. Create a large data sets that algorithms can be trained at. A large number of pictures and how people judge them, honest, clever, dumb, manipulative, confident etc. Recent advancements in machine vision and facial recognition have made algorithms to recognize a wide range of human facial expressions and even to rate faces by attractiveness. So is it possible for a machine to look at a face and get the same first impressions that humans make?\n\nBook covers communicate information to potential readers, but can the same information be learned by computers? Method of using a Convolutional Neural Network (CNN) cab be used to predict the genre of a book based on the visual clues provided by its cover\n\nAlgorithm will help predict what kind of help a person needs before they actually need to go to prison and use predictive software to help determine how likely people are to \u00adreoffend. Judges Can also Consider Predictive Algorithms in Sentencing.\n\nComputer Visions and Visual Recognition algorithms can identify trees and information about their health, and help in the creation of long-term plans for future street-tree investments. This work in Pasadena was supported by the Office of Naval Research, NASA, and Google.\n\n\u201cHuman closeness\u201d, that\u2019s what it is. These algorithms look for certain repetitions, word usage patterns, thematic emphases and allusions\n\nData-driven publisher Inkitt announced today that it is partnering with Tor Books to, according to a press release, \u201crelease the first novel selected by an algorithm for publishing.\u201d\n\nSony CSL Research Laboratory has released pop music composed by AI, and the results are impressive. The AI algorithm, called FlowMachines, works by first analyzing a database of songs and then following a particular musical style to create similar compositions. The final result does have a human touch\n\nCall it Algorithm Overload or Algocracy, but you just can\u2019t ignore the influence that algorithms will have on our future. In 2014 a Hong Kong based venture capital firm has appointed a computer algorithm to its board of directors, and with more and more use of algorithms in government agencies -a master algorithm will come into play that will control the economy as all judgments will be automated. But owners of these algorithm codes could be biased and guess, there will be no \u201cOFF\u201d switch once a code becomes very complex it becomes some kind ghost, you can call it a black box -and when they go wrong you can\u2019t ask Why?\n\nYoshua Bengio, computer scientist specializing in AI, said that", 
        "title": "From Sorting Cucumbers to Curing Cancer: Machine Learning Algorithms Will Do Everything"
    }, 
    {
        "url": "https://deephunt.in/deep-hunt-issue-16-6be9db0fc746?source=tag_archive---------5----------------", 
        "text": "An approach to neural sequence modeling that alternates convolutional layers, which apply in parallel across timesteps, and a minimalist recurrent pooling function that applies in parallel across channels. Despite lacking trainable recurrent layers, stacked QRNNs have better predictive accuracy than stacked LSTMs of the same hidden size.\n\nJust append target language token to source sentence to use a single Neural Machine Translation (NMT) model to translate between multiple languages.", 
        "title": "\u2014 Issue #16 \u2013"
    }
]