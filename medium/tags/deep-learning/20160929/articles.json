[
    {
        "url": "https://medium.com/from-the-macroscope/the-science-behind-the-signal-tracking-unknown-oil-tanks-around-the-world-9fc917e25795?source=tag_archive---------0----------------", 
        "text": "Today, we announced the availability of our China Oil product, which is the culmination of months of meticulous engineering, data science, and quality assurance. Here\u2019s how we did it.\n\nThe price of oil is driven by many political, technological, and economic factors, but much of this volatility is due to a lack of transparency in the market. We might know how much oil is stored in Rotterdam, and we have reliable numbers for the United States. But other sources of oil can easily flood or drain the market without warning, since their storage capacity is unreliably reported. We wanted to build a tool that could independently measure how much oil is stored in the world to protect the market from volatility.\n\nWe had already been counting millions of cars in US retail parking lots when we began building the US Oil product. We applied the same technology\u200a\u2014\u200aof identifying objects from satellite images\u200a\u2014\u200ato oil tanks. We trained our algorithms to detect crude oil tanks with floating roofs across the US, from Cushing, Oklahoma, to Houston, Texas. By measuring the size of each tank, we could count the total capacity for oil storage, but we didn\u2019t quite have an accurate measure of current supply. Understanding the volume of oil in each tank took a bit of imagination and trigonometry.\n\nFloating roofs sit on top of crude oil tanks for a variety of reasons\u200a\u2014\u200afor example, to minimize breathing and evaporative losses. As the reservoirs are filled and emptied, the roofs rise and fall, reflected in the crescent moon-like shadows from the walls of the reservoir. The size and shape of the shadow is a sensitive metric of the volume of oil held in the tank, which we analyzed across approximately 6,000 tanks in the US, creating a holistic, near real-time view of the country\u2019s current supply of crude oil.\n\nData on oil inventories in the US is relatively well-known, which made verifying the accuracy of our new product straightforward. We began testing the US Oil product in 2015, and backtesting on satellite images from as far back as 2010, and we have closely matched (within +/- 8%) the amount of oil reported to be stored in the US over the last 300 weeks. What\u2019s more, we have been able to share that data ahead of industry reports. In August, our US Oil product reported a decrease in US crude oil inventory two trading days ahead of the International Energy Agency\u2019s report.\n\nWith the success of the US Oil product, we set our sights abroad. Seeing a near real-time count of oil supply in the world\u2019s largest economy can help regulate market drops and spikes, but we aim to provide a macroscopic view of the world, not a single country. As we continue to expand the coverage of the Oil product, we focused our lens on the second largest economy: China.\n\nOur algorithms don\u2019t care whether they see pictures of the United States or China; we simply feed them new images to analyze. From approximately 10,000 images, we tracked commercial and strategic petroleum reserves across the country\u2019s 3.7 million square miles.\n\nWe found more than 1,500 crude oil storage tanks that were not cataloged in the industry standard database of tank farms. At first, we didn\u2019t believe there would be so many \u201cunknown\u201d tanks, but as we started to check the tanks manually, we knew the algorithm had indeed found them.\n\nAfter that, we performed quality assurance for the China Oil product. Our quality control processes involve a mix of algorithms and manual verification. Algorithms are good at producing statistics and finding anomalies, while human verification and image labeling are useful for calibrating machine vision algorithms.\n\nOur most recent estimate counts approximately 600 million barrels of crude oil supply in China in May 2016. Though there may be additional storage underground, these findings have already dramatically changed our understanding of the amount of oil that can be stored in China, which gives investors the opportunity to price oil based on a more realistic estimate of supply.", 
        "title": "The Science Behind the Signal: Tracking Unknown Oil Tanks Around the World"
    }, 
    {
        "url": "https://medium.com/boldr/re-works-deep-learning-and-chatbot-summit-my-key-takeaways-fcb3a672401d?source=tag_archive---------1----------------", 
        "text": "As part of the development of BOLDR (our new professional AI powered coach in private alpha now), last week, I attended RE\u2022WORK\u2019s most recent event\u200a\u2014\u200athe Deep Learning Summit. The event brought together cutting-edge science and entrepreneurship to showcase how Deep Learning Tech can positively disrupt markets and our lives. It was a fantastic event, which not only introduced me to some incredible brains (entrepreneurs and academics) but also gave plenty of tips on how deep learning can enhance our product. Here are a few of the highlights.\n\nRaia Hadsell, a senior research scientist at Google Deepmind, spoke about how complex problem solving (involving long sequences of tasks) remains a key obstacle in achieving human-level intelligence. Previous methods for continual learning, Raia argued, are not applicable to deep neural networks; however, progressive neural networks (which are immune to forgetting and are able to leverage prior knowledge via lateral connections to previously learned features) are a step in the right direction.\n\nRaia then illustrated how such a progressive approach to deep learning can be used to transfer knowledge from simulated tasks to a real robot domain. This was not a talk for the faint-hearted.\n\nMurray Shanahan, professor of Cogntive Robotics at Imperial College London, talked about how, despite certain dramatic successes, contemporary deep reinforcement learning methods have particular shortcomings. One of these is the slow learning they support due to their reliance on statistics from large datasets. By introducing a symbolic component, that allows for rapid generalisation at a high level of abstraction, Murray argued that deep learning processes could become faster and more accurate.\n\nI also attended the Chatbots breakout track. This looked at how AI and deep learning can be used to create chatbots and conversational interfaces that enable deeper, more personalised one-to-one customer experiences.\n\nChris Bauer, senior lecturer at Goldsmiths, spoke about how he has discovered that people trust robots more than humans because there is no fear of judgement. Which is fascinating, as it implies that users will be more open with a chatbot than they will be with their friends.\n\nArtem Rodichev, a machine learning engineer, spoke about how the company Luka is developing chatbots capable of mimicking certain personalities\u200a\u2014\u200asuch as celebrities and fictional characters. Luka have done a good job of taking a huge amount of data and apply it to create a personality of a chatbot. Still an area with lots of room for development.\n\nPeter Gasston, creative technologist at +rehabstudio (a creative technology company) humorously spoke about his experience of developing a chatbot, TRex, aimed specifically at children. The character is the extinct T Rex species which can answer questions about himself. This was no small feat. By \u2018training\u2019 the bot with lots of input, TRex can answer questions such as \u2018When did you live?\u2019.\n\nPeter\u2019s learnings were that the technology is still catching up, but new tools are being created all the time. He urged developers to create better documentation, to narrow the domain of the bot and set expectations to users upfront in an effort to help build more robust and user-friendly bots.\n\nHe also talked the perils of training the chatbot and the kind of abuse to expect from the users. Even children (who were the target audience of the chatbot) got very creative with how to abuse the poor bot. So be prepared, Peter said.\n\nThe event was a great gathering of minds, and illustrated how deep learning is able to use massive amounts of data to create new \u201cintelligent\u201d systems and processes. I certainly learnt a lot, and very much look forward to next year\u2019s event\u200a\u2014\u200awhich will no doubt be as well put together as this year\u2019s.\n\nDid you attend the Deep Learning Summit? If so, what fascinated you? And do you think that events like this are important for furthering great technology and ideas?\n\nLet me know your thoughts below.", 
        "title": "RE\u2022WORK\u2019s Deep Learning and Chatbot Summit: My Key Takeaways"
    }, 
    {
        "url": "https://insights.untapt.com/deep-learning-study-group-session-3-how-to-improve-neural-networks-82e1a5fc2de5?source=tag_archive---------2----------------", 
        "text": "Last night, in the third installment of our series of Deep Learning study sessions, we examined a range of techniques for improving the way neural networks learn.\n\nFollowing the third-chapter material of Michael Nielsen\u2019s interactive text on the topic, below is a summary of our discussion.\n\nIn addition to the theoretical work above, we applied our knowledge to software applications:\n\nIn our upcoming session, we\u2019ll be diving into the mathematical proof of how neural nets can compute any function and discussing why deep neural nets are difficult to train. In an exciting development, we\u2019ll also begin work on novel, real-world applications of the techniques we\u2019ve been developing thus far.", 
        "title": "Deep Learning Study Group Session #3: How to Improve Neural Networks"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/skymind-raises-3m-to-bring-its-java-deep-learning-library-to-the-masses-2549da3e1020?source=tag_archive---------3----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Skymind Raises $3M to Bring Its Java Deep-Learning Library to The Masses"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/tech-titans-join-forces-to-stop-ai-from-behaving-badly-60f7ace7fb79?source=tag_archive---------4----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Tech Titans Join Forces to Stop AI from Behaving Badly"
    }
]