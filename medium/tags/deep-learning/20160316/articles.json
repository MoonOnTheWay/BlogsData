[
    {
        "url": "https://medium.com/@Lidinwise/why-alphago-is-a-milestone-but-it-still-not-achieved-agi-e37ac02a11bd?source=tag_archive---------0----------------", 
        "text": "Congrats Google Deepmind. You did it! Top rank player of Go is no longer a human. Should we rejoice or fear this formidable feat? Is this milestone the start of the end game in the quest for Artificial General Intelligence (AGI)? My short answer is yes and no.\n\nFirst, some context. Go is an ancient Chinese board game with very simple rules: black and white stones, played in alternate moves by two opponents, fight to conquer the most territory on an 19x19 square. Despite it\u2019s simple rules, the game is of an incredible complexity. As chess, Go is a Markov complete game (the information for the next move is completely contained in the present state of pieces on the board).\n\nHowever, contrary to chess, Go is a much more fluid game, where a single move can change drastically the fate of the game. In chess, after some moves the fate of the game is determined (for a good enough player). Go is much harder to predict the outcome (for two top players), only by the very end of the game\u200a\u2014\u200awhich may take 200 or more turns. On the other hand, the number of possible moves is beyond imagination: for example, if we want to predict 50 turns ahead, we get about 3x10\u00b9\u2070\u2070\u00a0, which is a higher number than the number of atoms in the entire universe.\n\nSo, how did AlphaGo did it? How it was able to navigate through this gigantic space of possibilities within seconds? Brute force will not work. The simple answer is that it used algorithms that are close to human level intelligence. What are they? We don\u2019t know for sure, but some sort of high-level heuristics and shortcuts, like the ability to see that certain configurations are more defendable than others. This takes years to master by humans, but AlphaGo learned them from scratch\u200a\u2014\u200ainitially playing against other computer programs and later against experienced go players. It learns from its mistakes and was able to device, what may be called, strategies\u200a\u2014\u200apretty much the same way as human brain uses heuristics.\n\nIn this respect, this is a remarkable feat as it relies on a completely different approach from the one used by Deep Blue to beat Kasparov on chess. The more technically the answer is that AlphaGo is taking advantage of one of the most powerful machine learning algorithms ever built: deep recurrent neural networks (DRNN) trained with Long-Short Term Memory (LSTM)\u200a\u2014\u200aa technique proposed in 1997 by J. Schmithuber of IDSIA, Switzerland. Behind it are more bizarre techniques used for reinforcement learning, most notable Monte-Carlo tree search. But the core concept is DRNN.\n\nHardly the capability to generate heuristic or neural networks are new concepts. Neural Networks were around for more than 50 years. They never got much respect from the academic and AI community as the way they work and why they work is pretty obscured\u200a\u2014\u200asomehow as our brain. They only become popular, though for a short period, in late 80\u2019s when Hinton and others propose an algorithm, called back-propagation that made possible training of networks with hidden layers (a layer between the input and the output). Those architectures gain some relevance as it allow to extract non-linear relationships between inputs and outputs (like the XOR problem) that previous networks couldn\u2019t. They got some visibility in problems, like OCR (recognition of digits\u200a\u2014\u200atypeset or hand written). However, after the 90\u2019s enthusiasm decline in favor of more \u201celegant\u201d and mathematical sounded machines like SVM, especially the kernel based learning.", 
        "title": "Why AlphaGo is a milestone but it still not achieved AGI"
    }, 
    {
        "url": "https://techstory.shma.so/deep-learning-flappy-bird-ded48be7fa4?source=tag_archive---------1----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Deep Learning Flappy Bird \u2013"
    }, 
    {
        "url": "https://medium.com/@phronk/could-what-you-do-without-thinking-be-the-key-to-artificial-intelligence-898d442ad826?source=tag_archive---------2----------------", 
        "text": "My Master\u2019s thesis explored the links between intuition and intelligence. I found that measures of intuition were closely related with intelligence: people who tend to rely on quick, unconscious decision making also tended to be more intelligent. When poking at the implications, I wrote:\n\nThat was back in 2007, just a decade after Deep Blue beat Kasparov at chess. Here we are another decade later, and Google\u2019s AlphaGo has beat a champion at the more complex game of Go.\n\nI\u2019m no expert on machine learning, but my understanding is that AlphaGo does not play in the same way as Deep Blue, which brute-forces the calculation of 200 000 000 positions per second. That\u2019s the equivalent of conscious deliberation: considering every possibility, then choosing the best one. Intuition, however, relies on non-conscious calculations. Most possibilities have already been ruled out when an intuitive decisions enters consciousness, which is why intuition can seem like magic to the conscious minds experiencing it.\n\nIntuition seems closer to how AlphaGo works. By studying millions of human Go moves, then playing against itself to become better than human (creepy), it learns patterns. When playing a game, instead of flipping through every possible move, it has already narrowed down the possibilities based on its vast, learning-fueled \u201cunconscious\u201d mind. AI has been improved by making it more human.\n\nWhich is to say: hah! I was right! I called this ten years ago! Pay me a million dollars, Google.", 
        "title": "Could What You Do Without Thinking Be the Key to Artificial Intelligence?"
    }, 
    {
        "url": "https://medium.com/@niland/new-public-demo-launched-a08434f9eb28?source=tag_archive---------3----------------", 
        "text": "See it in action here\u00a0:demo.niland.io\n\nThe Niland core technology consists of two functions: automatic tagging and suggestions of acoustically similar tracks.\n\nThis technology is meant to build better recommendation engines for music app users. The rapid growth of digital media delivery in recent years has led to an increase in the demand for tools and techniques for managing huge music catalogues. B2B (Distributors, Publishers and Libraries) and B2C (Music Streaming services) actors are facing the same issues. Music content is exploding which can make searching for specific tracks challenging.\n\nUp until now, media file search queries have been performed textually, which is effective to an extent, but what if you want to find music that is similar to one you have in your possession? Or what if you want alternative tracks based on voice, mood, or instrumentation? This is where niland\u2019s audio search enters into the picture.\n\nThis demo is based on deep learning algorithms applied to machine listening. Machine Listening is essentially an arm of AI that lets machines analyze and understand music by processing it (aka the music signal), rather than by meta data (such as keywords and descriptions that rely not only on human actions, but on human subjectivity too).\n\n.. you get an estimate of its percentage belonging to different tags (genres, instrument, mood, vocals\u2026).\n\nYou also get a list of other tracks showing the highest acoustically similarity to your track.\n\nGive it a try here.\n\nNiland is a music technology company that provides music search & discovery engine based on Deep Learning algorithms. To know more, visit www.niland.io", 
        "title": "New public demo launched! \u2013 niland.io \u2013"
    }
]