[
    {
        "url": "https://medium.com/@awjuliani/pornography-and-the-limits-of-artificial-intelligence-76f00fe6bca4?source=tag_archive---------0----------------", 
        "text": "I have been spending a lot of time recently thinking about the possible applications of deep learning to real world use-cases. In the domain of image classification, something that came to mind a few weeks ago was a pornography filter. On the surface, such a problem seems perfectly suited to deep neural networks. Similar networks have been used to distinguish differences as subtle as breeds of dog, or human faces from one another, so why not distinguish between pornographic, and non-pornographic content? Thinking most generally, it seemed like a classical, straightforward classification problem. Give the computer enough images and video of pornography and non-pornography, and it would inevitably learn to tell the difference between the two. The more I thought about this approach however, the more problematic it began to appear.\n\nWhen thinking about deep neural network, representation is key. What exactly would a neural network trained on a set of pornographic images learn about pornography? While I haven\u2019t trained such a system myself, it seems that the kinds of features it would learn to care about are those associated with human nudity. Exposed bodies in and of themselves don\u2019t constitute porn however. Here is where the issue arises. A technology like this would not just be acting as a neutral filter of images, it would in fact be acting on the boundaries of human sexuality. Any such system would be acting to reinforce certain cultural definitions in the strictest and most unyielding of ways. By reinforcing the taboo of nudity, and equating it with pornography, a neural network would be exercising a kind of editorialization that is removed from the human experience in a dangerous way. Furthermore, cultural context comes into play almost immediately. An obvious extreme example is the number of aboriginal cultures in which exposed bodies is a completely normal and public aspect of societal life. There is no inherent reason that an exposed body of a westerner should be any different. After coming to this realization, it seemed that building such a naive and unitary system might do more harm than good.\n\nAll this begged the greater question: How do we make such distinctions? And if we can\u2019t equate nudity and pornography, then is it possible for a deep learning system to truly distinguish between pornography and non-pornography in a human-like way? My answers is no, at least not given the current state of machine learning. All this comes down to one of the fundamental epistemological assumptions built into image classification systems, and indeed most AIs generally: any such system works on the principle of identity. Either something is this or that. Probabilistic systems introduce the possibility of things being a little this or that, but the fundamental assumption is that the world can be broken into discreet, real things like this and that, and they can be defined intrinsically.\n\nNeural networks take up these assumptions at the most basic level of their design. Classification is always into discreet categories. The system couldn\u2019t be trained if there was not an exact mathematical way to measure how wrong it\u2019s prediction was from the supposed \u2018absolute truth.\u2019 In terms of representation, the architecture of deep networks supposes a priori that the objects being classified can be broken into discreet features that are represented at each layer of the network, and progressively build on one another. Here we find a positivist atomistic concept of meaning wired directly into the system.\n\nWhile this assumption can hold for simple things like \u201cIs there a dog in this photo?\u201d Or even \u201cIs there nudity in this photo?\u201d It completely breaks down for concepts which cannot be constituted on the grounds of identity. Pornography seems to me to be a paradigmatic example of a concept grounded in difference, not identity. It is something that comes about not because of any series of inherent properties, but rather exists in a relational matrix with the content around it and the viewer, extending in both space and time. What makes something pornography isn\u2019t that it contains nude bodies, or sexual intercourse (something found in most films released in theaters today), but rather the relationship between those bodies on display, and critically, the viewer who brings their subjectivity to the experience. The importance of subjective intentionality comes to light in the french film Blue is the Warmest Color. The film contains extended scenes of sex, but few would call it pornographic. Indeed, many viewers expecting pornography were disappointed to find a serious drama with unflinching portrayals of human relationships. On the other hand, some may have found pornographic the depictions of sexuality who were not expecting it. The existence or lack of pornography comes about dynamically between the subject and object. It cannot be objectively determined, least of all by a machine.\n\nConcepts which exist as pure difference, rather than identity pose a problem for deep learning systems, which can only learn sets of innate probabilistic features which correspond to pre-defined identities. Ironically, it is exactly such a system of meaning that we handle as human beings on a daily basis with ease. I have discussed pornography but think about bullying, friendship, love, facade, deception, leading, following, etc. All these and countless more can only be thought with difference. This becomes an issue for deep learning and the field of Artificial Intelligence when we realize, as postmodern theorists such as Deleuze (in Difference and Repetition) and Derrida (in Of Grammatology) have that these concepts are not just some sub-category that can be easily ignored, but comprise everything of meaning in our world. If we believe them, then AI still has a long way to go.", 
        "title": "Pornography and the limits of Artificial Intelligence"
    }, 
    {
        "url": "https://medium.com/self-driving-cars/deep-learning-frameworks-db2ebb698566?source=tag_archive---------1----------------", 
        "text": "I\u2019ve finished NVIDIA\u2019s introductory Deep Learning course, and I\u2019m now starting Udacity\u2019s.\n\nThese courses outline the construction and use of Deep Neural Networks (DNNs) for image processing and text recognition. They\u2019re great!\n\nHere are some of the highights:\n\nDIGITS: This is NVIDIA\u2019s Deep Learning visualization program. It presents a GUI for both building and reviewing DNNs.\n\nCaffe: There are several frameworks for building DNNs, but Caffe seems the most straightforward. Although it is written in C++ and provides a Python interface, no coding is required to get started. This is because Caffe can be configured with Google Protobuf, a JSON-like text format.\n\nTheano: NVIDIA\u2019s course advises that the various Deep Learning frameworks are \u201cmore similar than they are different\u201d, but Theano is at least syntactically different than Caffe. Theano is a Python symbolic math library, on top of which various packages offer DNN capability.\n\nTorch: Torch is Facebook\u2019s tool of choice for DNN research, and it gets support from Google, NVIDIA, and other major Deep Learning companies, as well. It uses the Lua programming language (yay, Brazil!).\n\nTensorFlow: In the same way that Torch is Facebook\u2019s go-to DNN tool, TensorFlow fills that role for Google. Like many Google projects, it is Python-based. I am just diving into TensorFlow now, via Udacity\u2019s course, so I may have more to say later.\n\ncuDNN: This is NVIDIA\u2019s library for parallelizing DNN training on the GPU. It is the key to building large neural networks, and all of the DNN frameworks integrate with it. As Google\u2019s Vincent Vanhoucke relates, neural networks went through a period of popularity in the eighties and nineties, and then slumped in the 2000s, as CPUs weren\u2019t able to provide enough power to train large networks. The publication of AlexNet (2012), showed that the use of GPU parallelization could provide massive training acceleration. This revolutionized the field.\n\nConvolutional Neural Networks (CNNs): Convolutional Neural Networks are a building block of DNNs that involve learning on small parts of an image and then tiling the neighboring small parts to learn over the entire image. This blocking and tiling reduces the learning complexity, which is especially important for large images.", 
        "title": "Deep Learning Frameworks \u2013 Self-Driving Cars \u2013"
    }, 
    {
        "url": "https://humanizing.tech/a-working-worm-s-brain-body-using-ai-robotics-8695f972b52d?source=tag_archive---------2----------------", 
        "text": "Last week I wrote up what I thought was the first steps towards a new architectural framework for a self-learning intelligence:\n\nIt requires much much more work, but really did it to get some thoughts down on paper and get some reaction from other folks interested in the area (mainly to see if I\u2019m as cuckoo as I think I am).\n\nI got a lot of great feedback, but one in particular stuck out. And it centered on a book I read about 3 years ago called the Connectome, which I recommend:\n\nSee also their research project.\n\nMuch like sequencing the human DNA genome (which you can now get your own done through an app for $999), this attempts to map the billions of neurons and trillions of connections in the human brain. You have to start somewhere, though, and this started with a worm\u2019s because there are only about 300 neurons that connect not just its brain but also its body. Sensory input > neural calculations > body movement. It\u2019s the simplest living organism that we can make a 100% accurate reproduction:\n\nSo what can you do with this data? Well, you can create a \u201cconnectome engine\u201d, write some software to accurately reproduce it, then run it on a functioning robot to see if relevant action becomes emergent.\n\nA group of folks actually did this about a year ago, as shown in the Wall Street Journal video below.\n\nIn speaking with one of the leaders, Timothy Busbice, one of the fundamental insights that they believe that others have not yet seemed to stumble upon yet is as follows:\n\nI love this insight because it again takes a set of simple math equations (for example, 302 neurons) and connects them together. With continued data flowing through it, we can create emergent and incredibly complex behavior.\n\nLike a worm searching for food, moving around until it finds some, and allowing life to develop as a result.\n\nThe most surprising thing about this discovery is that we are already there. We copied a worm\u2019s \u201cengineering\u201d and \u201clife\u201d developed from it. This didn\u2019t happen today. It happened a year ago.\n\nI\u2019m slowly but surely figuring out where the edges of human understanding and research exists in the field of AI. I\u2019m going to keep searching. Once we know where the collective consciousness is, we can determine where we\u2019re headed and what we have left to uncover.\n\nAnd what we might actually need is a new way for us to begin to bring all this work together instead of all of us working in silos. Maybe that\u2019s something we can aspire towards as a community in 2016.", 
        "title": "A Working Worm\u2019s Brain & Body Using AI + Robotics \u2013"
    }
]