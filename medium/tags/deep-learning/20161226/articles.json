[
    {
        "url": "https://blog.coast.ai/continuous-online-video-classification-with-tensorflow-inception-and-a-raspberry-pi-785c8b1e13e1?source=tag_archive---------0----------------", 
        "text": "Much has been written about using deep learning to classify prerecorded video clips. These papers and projects impressive tag, classify and even caption each clip, with each comprising a single action or subject.\n\nToday, we\u2019re going to explore a way to continuously classify video as it\u2019s captured, in an online system. Continuous classification allows us to solve all sorts of interesting problems in real-time, like understanding what\u2019s in front of a car for autonomous driving applications to understanding what\u2019s streaming on a TV. We\u2019ll attempt to do the latter using only open source software and uber-cheap hardware. Specifically, TensorFlow on a Raspberry Pi with a PiCamera.\n\nWe\u2019ll use a \u201cnaive\u201d classification approach in this post (see next section), which will give us a relatively straightforward path to solving our problem and will form the basis for more advanced systems to explore later.\n\nBy the time we\u2019re done today, we should be able to classify what we see on our TV as either a football game or an advertisement, running on our Raspberry Pi.\n\nLet\u2019s get to it!\n\nVideo is an interesting classification problem because it includes both temporal and spatial features. That is, at each frame within a video, the frame itself holds important information (spatial), as does the context of that frame relative to the frames before it in time (temporal).\n\nWe hypothesize that for many applications, using only spatial features is sufficient for achieving high accuracy. This approach has the benefit of being relatively simple, or at least minimal. It\u2019s naive because it ignores the information encoded between multiple frames of the video.\n\nSince football games have rather distinct spatial features, we believe this method should work wonderfully for the task at hand.\n\nWe\u2019re going to collect data for offline training with a Raspberry Pi and a PiCamera. We\u2019ll point the camera at a TV and record 10 frames per second, or more specifically, save 10 jpegs every second, which will comprise our \u201cvideo\u201d.\n\nHere\u2019s the code for capturing our images:\n\nOnce we have our data, we\u2019ll use a convolutional neural network (CNN) to classify each frame with one of our labels: ad or football.\n\nCNNs are the state-of-the-art for image classification. And in 2016, it\u2019s essentially a solved problem. It feels crazy to say that, but it really is: Thanks in large part to Google\u2192TensorFlow\u2192Inception and the many researchers who came before it, there\u2019s very little low-level coding required for us when it comes to training a CNN for our continuous video classification problem.\n\nPete Warden at Google wrote an awesome blog post called TensorFlow for Poets that shows how to retrain the last layer of Inception with new images and classes. This is called transfer learning, and it lets us take advantage of weeks of previous training without having to train a complex CNN from scratch. Put another way, it lets us train an image classifier with a relatively small training set.\n\nWe collected 20 minutes of footage at 10 jpegs per second, which amounted to 4,146 ad frames and 7,899 football frames. The next step is to sort each frame into two folders: football and ad. The name of the folders represent the labels of each frame, which will be the classes our network will learn to predict on when we retrain the top layer of the Inception v3 CNN.\n\nThis is essentially using the flowers method described in TensorFlow for Poets, applied to video frames.\n\nTo retrain the final layer of the CNN on our new data, we checkout the r0.11 tag from the TensorFlow repo and run the following command:\n\nRetraining the final layer of the network on this data takes about 30 minutes on my laptop with a GeForce GTX 960m GPU. At the completion of 4,000 training steps, our model reports an incredible 98.8% accuracy on the held out validation set! I\u2019m not sure I could do much better using my eyes on the same data. As a point of reference, if the network had classified each frame as football, it would have achieved about 66% accuracy. So it seems to be working!\n\nIt\u2019s always a good idea to run some known data through a trained network to sanity check the results, so we\u2019ll do that here.\n\nHere\u2019s the code we use to classify a single image manually through our retrained model:\n\nAnd here are the results of spot checking individual frames:\n\nBefore we transfer everything to our Pi and do this in real-time, let\u2019s use a different batch of recorded data and see how well we do on that set.\n\nTo get this dataset, and to make sure we don\u2019t have any data leakage into our training set, we separately record another 19 minutes of the football broadcast. This dataset amounted to 2,639 ad frames and 8,524 football frames.\n\nWe run each frame of this set through our classifier and achieve a true holdout accuracy score of 93.3%. Awesome!\n\nLooks like we\u2019ve validated our hypothesis that we can achieve high levels of accuracy while only considering spatial features. Impressive results, considering that we only used 20 minutes of training data! Thank you, Google, Pete, TensorFlow and all the folks who have developed CNNs over the years for your incredible work and contributions.\n\nGreat, so now we have our CNN trained and we know that we can classify each frame of our video with relatively high accuracy. How does it do on live TV, with always changing context?\n\nFor this, we load up our Raspberry Pi 3 with our newly trained model weights, turn on the PiCamera at 10 fps, and instead of saving the image, send it through our CNN to be classified.\n\nWe have to make some modifications to the code to classify in real time. The final result looks like this:\n\nWe also have to get TensorFlow running on the Pi. Sam Abrahams wrote up excellent instructions for doing this, so I won\u2019t cover them again here.\n\nAfter we install our dependencies, we run the program and\u2026 crap! Inception on the Raspberry Pi 3 can only classify one image every four seconds.\n\nOkay, so we don\u2019t quite have the hardware yet to do 10fps, but this still feels like magic, so let\u2019s see how we do.\n\nFlipping on Sunday Night Football and pointing our camera at the TV shows a remarkable job at classifying each moment as football or ad, once every few seconds. For the vast majority of the broadcast, we see our prediction come out true to life. So cool.\n\nIn all, our naive method worked remarkably well at continuous online video classification for this particular use case. But we know that we\u2019re only considering part of the information provided to us inherently in video, and so there must be room for improvement, especially as our datasets become more complex.\n\nFor that, we\u2019ll have to dive deeper. So in the next post, we\u2019ll explore feeding the output of our CNN (both the final softmax layer and the pool layer, which gives us a 2,048-d feature vector of each image) to an LSTM RNN to see if we can increase our accuracy.", 
        "title": "Continuous online video classification with TensorFlow, Inception and a Raspberry Pi"
    }, 
    {
        "url": "https://medium.com/@anujsharma_1/hi-i-have-retrained-inceptions-final-layer-using-flower-dataset-with-fine-tuning-turned-on-aa438ede5904?source=tag_archive---------1----------------", 
        "text": "Hi I have retrained inceptions final layer using flower dataset with fine tuning turned on.\n\nI have managed to generate\u00a0.pb\u00a0,.pbtxt\u00a0, chkpoint files successfully after getting an accuracy of 93%\u00a0.\n\nBut I am stuck at making this model usable for predictions.\n\nI don\u2019t know what should be my output node while freezing graph.\n\nI tried couple of node names like tower_0/logits/predictions and softmax but got my frozen graph generated. But when I invoke label_image.py script on it. It fails saying \u201cfinal_result\u201d cannot be found in graph.\n\nSo I tried changing tensor name to \u201csoftmax:0\" inside label_image.py. still error.\n\nCan you help me out here\u00a0? I ll share more details if u need. Thanks.", 
        "title": "Hi I have retrained inceptions final layer using flower dataset with fine tuning turned on."
    }, 
    {
        "url": "https://medium.com/@freddgreat/what-have-you-done-with-it-3123c4ebe824?source=tag_archive---------2----------------", 
        "text": "WHAT HAVE YOU DONE WITH IT\n\nThis world was given to us about 2 billions of years ago, what have we done with.\n\nMy name is Oladipupo O. Fredrick, this world was given to me 25 years ago, what have I done with? What have you also done with yours irrespective of when it was given to you? This is my question of the year. Let\u2019s move away from the time a little bit, what of the talent, passion, beauty, grace, creativity that has been given unto us, what have we also done with them.\n\nThis question has been in my head for months, and I figured as humans, we have a lot we can show for the billions of years we have spent: health solutions, computers, advanced war arms, luxurious lifestyle, these are few of the things we have accomplished over the years\n\nHowever, I still believe we have never lived to our potential. In this thought I figured a lot of things that has in one way or the other inhibits us from been more than what we are now.\n\nOf all, I believed our major dilemma is that most of the times we are not ready to accept responsibility for what we want and those that accept responsibility do not have enough grit to stick to their plans when the going gets tougher.\n\nAccording to the 20\u201380 percent rule, only 20% of our population have the sense of responsibility and enough grit to achieve success.\n\nOn thinking deeper, I came across these scenarios which shows how much we are confused as humans.\n\nWe want to be rich and financially stable, but we never stop spending\n\nWe want to be a business tycoon but we are too scared to put our ideas out there\n\nWe want the world green, but all of us want to explore our oils\u00a0\n\nWe want to be great; yet, we never want to sacrifice. Don\u2019t you know greatness is all about tremendous sacrifice\n\nWhy hate trial, if you truly want to grow. Don\u2019t you know that trial precedes all growths?\n\nWe want to experience love; yet, we refuse to be vulnerable. Don\u2019t you know love is all about vulnerability?\n\nWe want to be become a leader, but we hate to serve, do you have to be told that real leadership is a form of service?\n\nWe long for peace; yet we all want to have our say and make our stand. Don\u2019t you know peace in itself is a form of compromise?\n\nWe want more, but we never give out, then, where is the room to keep the more we are longing for?\n\nYou adore promotion; then, why frown at tests? Don\u2019t you know there\u2019s no promotion without one\n\nOh men of earth what do you really want\n\n\u00a0We want to be peaceful, but we also want to repay or enemies. Don\u2019t you know true peace can only come from forgiveness?\n\nWe want to be a top, but we loathe the base. Have you forgotten that\u2019s as with everything the route to the top of the ladder is through the base?\n\nWe want to be masters, but we never truly want to spend time on anything serious. Don\u2019t you know true mastery is not attained overnight?\n\nWe don\u2019t want to be fat, yet, we never stop eating junks\n\nWe all want to change the world in our own little way, but we never really spend time to understand the world itself. How can you change what you don\u2019t even understand?\n\nLooking at what we actually have\n\nWe have smiles, but majorly, they are fake\n\nWe have friends but few of them even know what we actually represent.\n\nWhat\u2019s our compassion like, if our neighbors don\u2019t even feel it?\n\nWhy have love if it can\u2019t be shared?\n\nWhy run, without a specific destination in mind?\n\nWhy has beauty if it cannot be appreciated?\n\nWhy have brains if we think not?\n\nWhy have leaders and still end up in constant entropy\n\nWhy long for tomorrow when we have jeopardized it by the way we are living today\n\nWhy do we lament on things we don\u2019t have; thou we don\u2019t really need them?\n\nWhere\u2019s the love?\n\nWhere\u2019s the grace?\n\nWhere\u2019s the future?\n\nWhere\u2019s the compassion?\n\nWhat do we really need?\n\nWhat do we really want?\n\nDo we even know?\u00a0\n\nIf yes; how sure are we?\n\nPersonally, I think it\u2019s about time we answer these questions.\u00a0\n\nThis post is not aimed at exposing human failure or to cause more confusion to human existence. It was written out of deep thought to source for the problem so we can know where to direct our energy to moving forward.\n\nThis is my first post here. So, if you know how this article can be improved or have any comments; kindly drop them.", 
        "title": "WHAT HAVE YOU DONE WITH IT \u2013 Oladipupo O. Fredrick \u2013"
    }, 
    {
        "url": "https://medium.com/@LevelLabs/why-healthcare-needs-quantum-machine-learning-3008396fc1b8?source=tag_archive---------3----------------", 
        "text": "Artificial intelligence (AI) systems can help physicians make clinical decisions and diagnoses. In the 1950s, Lipkin, Hardy, and Engle were the first to apply statistical methods to diagnose hematologic diseases (Engle et al., 1976). Then, with the refinement of studies and advancement in computer technology, artificial intelligence was created (Fashoto, 2015). Computer programs, known as clinical decision support systems (CDSSs) (Garg et al.), can analyze enormous volumes of complicated medical information to assist in clinical decision-making (Berner, 2007; Garg et al., 2005). A recent example demonstrating the power of applied AI in CDSS in medicine relates to the story of a 60-year-old Japanese woman whose illness stumped doctors for months. A computer system, by the name of \u201cWatson\u201d, diagnosed the women\u2019s illness as a rare form of leukemia in only 10 minutes after it examined millions of cancer research papers (Ng, 2016). Contrary to popular belief, AI has been capable of telling physicians what to do for a long time. Built in the 1970\u2019s, MYCIN was the first computer system providing clinical decision support to physicians that emulated human expert decision-making ability using artificial intelligence. Watson\u2019s decrease in processing time is a significant change from that of MYCIN.\n\nIt is now hoped that with more powerful computing, quantum computing, that these CDSSs will increase efficiency and improve patient outcomes using less invasive diagnostic techniques and more directed treatments.\n\nClassical Machine Learning (CML) is a subfield of artificial intelligence in which computer science derives patterns (that are learned) without being explicitly programmed. Computers can then make predictions by modeling raw input data that is stored and manipulated as small bits of information that exist as 0 or 1. For instance, with classical computing, information is stored and manipulated as small bits, whereas with quantum computing, information is stored and manipulated as quantum bits (qubits) that can exist in many states, known as superposition. This superposition (referred to as the quantum state) results in a substantial increase in the speed of complex computations by having the ability to compute in many states at once. Classical methods of machine learning are currently being adapted to quantum information processing in healthcare systems.\n\nThe healthcare reform act was passed in 2010 with the goals of improving the quality of medical care, reducing costs, and improving access to care, while broadening insurance coverage (Buntin, Jain, & Blumenthal, 2010). Quantum machine learning can benefit health care and assist in the implementation of healthcare reform with the improvement of patient care and reduction of costs for medical diagnostics and treatment. Arguments in support of using these machines in hospitals and laboratories include rapid diagnostic results, superior biomedical imaging capabilities, more precise cancer treatment or surgical procedures, and reminders/interventions for patient diagnostic tests or treatment schedules. Arguments against include the cost of hardware, the difficulty in deciphering diagnostic reasoning, and the potential for privacy or ethical issues.\n\nThe benefit to using quantum sensors and quantum imaging has far-reaching possibilities for the advancement of medicine. This technology could create novel techniques to evaluate the heart through magnetic fields and through more powerful imaging techniques. And, quantum computers will be able to process data much more quickly than traditional computers, which is especially useful for large images created by computed tomography (CT) or magnetic resonance imaging. Cancer research would be another area to benefit from the power of quantum computing. An increase in data transferring speed from lab to bedside would significantly improve the clinician\u2019s ability to treat patients in an appropriate and timely manner (Jain & Chaturvedi, 2014).\n\nSeveral research and internet articles have been published supporting the benefits of quantum computing in healthcare. CDSSs and quantum learning have shown great promise is in biomedical imaging. Enhanced imaging would allow for earlier detection of molecular changes in the body, resulting in more treatment options for patients afflicted with diseases such as cancer or dementia, and subsequently improved outcomes.\n\nNeural networks in classical machine learning have proved to be an accurate diagnostic technique, optimized by changes in the parameters of the network\u2019s architecture. These optimization methods are best suited for quantum computing, where the ability of \u201cquantum tunneling\u201d allows for optimization problems to be solved quickly. One study used a quantum-based binary neural network for the diagnosis of liver disease. This quantum-based algorithm was more accurate and precise in diagnosing liver disease when compared to a classical neural network (O. Patel & Tiawari, 2015).\n\nEmmanuel Candes, an applied mathematician at Stanford University, realized the real need for quantum computers when he worked in collaboration with other radiologists to develop dynamic magnetic resonance imaging (MRI) to record a patient\u2019s heartbeat in real-time. This system required the use of advanced algorithms to create high-resolution videos from only a few MRI images. However, he realized that there was not enough memory in his computer to perform the analysis (Ouelette, 2013). Quantum computing\u2019s distributed optimization approach handles problems such as what Candes encountered, and does so in a fraction of the time, that is, assuming you have enough Q-RAM. It was once thought that one could only store and process this much information by using massive parallel computing. Compared to random access memory (RAM), which uses n bits to randomly address N=2^n distinct memory cells, quantum random access memory (qRAM) uses n qubits to address any quantum superposition of N memory cells, resulting in a more robust qRAM algorithm (Gioovannetti, Lloyd, & Maccone, 2008). For example, by using a quantum algorithm that has Q-RAM and a small 70-qubit quantum processor the genome of every person on Earth could be searched for common patterns among different genes, all while protecting people\u2019s privacy. The quantum-computing technician would only have access to a very small fraction of the total data and the analysis would be done quickly. These large databases may someday exist, as human genome sequencing becomes less expensive and businesses that sell genotyping services become more prevalent (Rebentrost, Mohseni, & Lloyd, 2013).\n\nPharmacists could also benefit from CDSSs and quantum learning in that there are over 100,000 different types of drug interactions. These systems alert pharmacists to drug interactions. Although one group found no difference between pharmacists receiving computerized alerts and those not receiving alerts, an overall potential to reduce patient risk is still present (Miller, Steinmetz Pater, & Corman, 2015). In a similar study, computers used to evaluate adverse drug interactions or overdoses in patients did help to decrease adverse events (Rommers, Teepe-Twiss, & Guchelaar, 2011). On the issue of drug development, the Andrew Furman, the co-founder and CEO of 1QBit, states, \u201cAmong the likely applications (using quantum computing) is drug development\u200a\u2014\u200aif you have a completely new molecule and want to predict what effect it will have on the body, one way to do so is to compare it to a database of molecules with known effects. Is it more similar to a molecule that\u2019s known to cure cancer or to cause heart disease?\u201d (Fursman, 2015).\n\nHowever, some reports are less enthusiastic about CDSSs and quantum learning. The main obstacle with using these machines is the cost. D-wave, a very powerful quantum computer, sells for about $10 million, which is a hefty price for medical research laboratories. Yet, cost in relation to the possibility of a cure for cancer or other disease process should not be an issue, and will likely not be much of an issue as quantum computing becomes more mainstream. In fact, it was recently reported that Europe is planning to spend \u20ac1 Billion to develop quantum technology as part of research and development in many areas including medicine(Hellemans, 2016). Many concerns regarding quantum machine learning are the same as those raised regarding CDSS and classical machine learning. Some of these problems include; acceptance by all users, integration into working environments, compatibility with current data management systems, and the ability to upgrade the system as needed (Garg et al., 2005). And, although these systems should reduce medical errors, there are ethical and legal issues to consider before they should be implemented in hospital or laboratory settings. It is also important to understand that this highly sophisticated technology can produce unexpected errors that should be addressed promptly. And, it is also possible that clinicians may become dependent on reminders generated by CDSSs, which could become problematic if a reminder is missed or not given (Mendez Boo et al., 2016; Wang & Summers, 2012). When medical errors occur, it may be difficult to distinguish between a system failure and negligence (Bonney, 2013). Systems that are unable to explain their diagnostic reasoning have primarily been the barrier to implementation within a clinical setting, a problem that quantum computing is unable to solve and may worsen due to the increasing amount of uncertainty.\n\nFinally, given the valid concerns regarding privacy and Healthcare Information Technology, it is imperative that protections be put in place to create an environment that benefits the vendors, patients, and clinicians. Constant breaches of privacy in healthcare have had a significant effect on health care research, significantly slowing the ability to acquire data that allows for rapid and great advances in medicine; advances that help lower healthcare costs and allow the system to pay for itself. Quantum computing does differ slightly when compared to classical learning in that the memory capability of quantum computers can preserve superpositions, which allows the computers to comb through data and find patterns without having to look at individual records.\n\nAlthough development of smaller and more precise quantum computers are possibly years away from being used, research funding should be allocated to make these computing systems a reality for improvement in healthcare. Integrating the abundance of electronic medical data and quantum machine learning is transforming healthcare, from powering personalized treatments for patients based on their genetic profile to identifying rare disorders that were missed by clinicians through the ability to analyze massive amounts of medical literature and clinical databases that no human is capable of doing. Knowing the sheer power of quantum learning machines makes failing to support their development a detriment to patients, doctors and hospital administrative costs.", 
        "title": "Why Healthcare Needs Quantum Machine Learning \u2013 Level Labs \u2013"
    }
]