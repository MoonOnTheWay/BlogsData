[
    {
        "url": "https://medium.com/@nicorichter/re-embarking-on-a-connectionist-adventure-480c4309c8d?source=tag_archive---------0----------------", 
        "text": "When I graduated in Psychology in the late 1990s, my master thesis about artificial neural networks and their possible applicability towards statistics still raised some eyebrows in the department. It even got me a speaker slot at a statistician conference where I was the only speaker who wasn\u2019t at least a post-doc. Neural networks\u2019 appeal back then was mostly exploratory, a fascination with the ability of something that is wired in a similar fashion to the human brain to at least approximate results of the classical, Von Neumann approach to computation.\n\nIt\u2019s probably no news to anyone that this has changed dramatically. When I re-created one of my networks from back then in Python a few weeks back, running it on my GPU with the excellent Theano library, the differences in computation time were quite shocking. I was very aware of the technological progress, but I didn\u2019t expect the order of magnitude I was about to experience.\n\nWhat ran for several hours on the department\u2019s fastest PC in the late 1990s completed so fast that I initially thought I must have done something wrong. But I hadn\u2019t. It had worked just fine\u200a\u2014\u200athe result checked out. It was just that computation time had been reduced from about 200 minutes when I last saw it to about 1/5th of a second. That\u2019s about a factor of 60.000!\n\nThis is possible not because current i7 CPUs are 1000x faster than their 1990s predecessors, but because modern graphics cards are not made of a couple very fast and smart processors, but instead of hundreds or thousands of comparatively dumb units. Their strength lies in the ability to do huge amounts of calculations in parallel. Just like the human brain. The chart to the left shows graphics card processing power (green) charted against CPU power in blue over the last ~10 years.\n\nI was instantly hooked. Going back to my research in the area over 20 years ago, I immediately had an idea of how revolutionary an order of magnitude change like this could be. Many applications for neural computation were imagined in the 1980s and 1990s\u200a\u2014\u200abut they were far out of reach, impossible to practically achieve with the computational power of single-processor machines at the time.\n\nJeremy Howard has given some excellent speeches about what has happened with this technology, which has started to appear everywhere in our lives, without most of us noticing. Here\u2019s his wonderful TED talk on the subject:\n\nGiven that I had a good amount of time on my hands in the coming weeks, it propelled me deep into a rabbit hole of exciting discoveries in a discipline, which, I quickly learned, had come from theoretical, exploratory experimentation in the 1990s to productive, everyday usage right on your smartphone today!\n\nSince then, I have been able to leverage my 20 year old knowledge to become a somewhat competent user of those new technologies. I\u2019ll write about some of my adventures into this new, exciting sector of brain-like computing in the coming posts.\n\nFor those of you who speak German, this post shows a little preview of my initial application\u200a\u2014\u200acomputer generated poetry. It will also be the subject of my first post on a concrete application.", 
        "title": "Computers that think like humans \u2014 my rediscovery of artificial neural networks"
    }
]