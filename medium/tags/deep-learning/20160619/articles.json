[
    {
        "url": "https://becominghuman.ai/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow-1907a5bbb1fa?source=tag_archive---------0----------------", 
        "text": "The purpose of this tutorial is to help anybody write their first RNN LSTM model without much background in Artificial Neural Networks or Machine Learning. The discussion is not centered on the theory or working of such networks but on writing code for solving a particular problem. We will understand how neural networks let us solve some problems effortlessly, and how they can be applied to a multitude of other problems.\n\nSimple multi-layered neural networks are classifiers which when given a certain input, tag the input as belonging to one of the many classes. They are trained using the existing backpropagation algorithms. These networks are great at what they do but they are not capable of handling inputs which come in a sequence. For example, for a neural net to identify the nouns in a sentence, having just the word as input is not helpful at all. A lot of information is present in the context of the word which can only be determined by looking at the words near the given word. The entire sequence is to be studied to determine the output. This is where Recurrent Neural Networks (RNNs) find their use. As the RNN traverses the input sequence, output for every input also becomes a part of the input for the next item of the sequence. You can read more about the utility of RNNs in Andrej Karpathy\u2019s brilliant blog post. It is helpful to note the \u2018recurrent\u2019 property of the network, where the previous output for an input item becomes a part of the current input which comprises the current item in the sequence and the last output. When done over and over, the last output would be the result of all the previous inputs and the last input.\n\nRNNs are very apt for sequence classification problems and the reason they\u2019re so good at this is that they\u2019re able to retain important data from the previous inputs and use that information to modify the current output. If the sequences are quite long, the gradients (values calculated to tune the network) computed during their training (backpropagation) either vanish (multiplication of many 0< values < 1) or explode (multiplication of many large values) causing it to train very slowly.\n\nLong Short Term Memory is a RNN architecture which addresses the problem of training over long sequences and retaining memory. LSTMs solve the gradient problem by introducing a few more gates that control access to the cell state. You could refer to Colah\u2019s blog post which is a great place to understand the working of LSTMs. If you didn\u2019t get what is being discussed, that\u2019s fine and you can safely move to the next part.\n\nGiven a binary string (a string with just 0s and 1s) of length 20, we need to determine the count of 1s in a binary string. For example, \u201c01010010011011100110\u201d has 11 ones. So the input for our program will be a string of length twenty that contains 0s and 1s and the output must be a single number between 0 and 20 which represents the number of ones in the string. Here is a link to the complete gist, in case you just want to jump at the code.\n\nEven an amateur programmer can\u2019t help but giggle at the task definition. It won\u2019t take anybody more than a minute to execute this program and get the correct output on every input (0% error).\n\nAnybody in their right mind would wonder, if it is so easy, why the hell can\u2019t a computer figure it out by itself? Computers aren\u2019t that smart without a human instructor. Computers need to be given precise instructions and the \u2018thinking\u2019 has to be done by the human issuing the commands. Machines can repeat the most complicated calculations a gazillion times over but they still fail miserably at things humans do painlessly, like recognizing cats in a picture.\n\nWhat we plan to do is to feed neural network enough input data and tell it the correct output values for those inputs. Post that, we will give it input that it has not seen before and we will see how many of those does the program get right.\n\nEach input is a binary string of length twenty. The way we will represent it will be as a python list of 0s and 1s. The test input to be used for training will contain many such lists.\n\nThere can be a total of 220 ~ 106 combinations of 1s and 0s in a string of length 20. We generate a list of all the 220 numbers, convert it to their binary string and shuffle the entire list. Each binary string is then converted to a list of 0s and 1s. Tensorflow requires input as a tensor (a Tensorflow variable) of the dimensions [batch_size, sequence_length, input_dimension] (a 3d variable). In our case, batch_size is something we\u2019ll determine later but sequence_length is fixed at 20 and input_dimension is 1 (i.e each individual bit of the string). Each bit will actually be represented as a list containing just that bit. A list of 20 such lists will form a sequence which we convert to a numpy array. A list of all such sequences is the value of train_input that we\u2019re trying to compute. If you print the first few values of train_input, it would look like\n\nDon\u2019t worry about the values if they don\u2019t match yours because they will be different as they are in random order.\n\nFor every sequence, the result can be anything between 0 and 20. So we have 21 choices per sequence. Very clearly, our task is a sequence classification problem. Each sequence belongs to the class number which is the same as the count of ones in the sequence. The representation of the output would be a list of the length of 21 with zeros at all positions except a one at the index of the class to which the sequence belongs.\n\nMore formally, this is called the one hot encoded representation.\n\nFor every training input sequence, we generate an equivalent one hot encoded output representation.\n\nFor any supervised machine learning task, we need some data as training data to teach our program to identify the correct outputs and some data as test data to check how our program performs on inputs that it hasn\u2019t seen before. Letting test and training data overlap is self-defeating because, if you had already practiced the questions that were to come in your exam, you would most definitely ace it. Currently in our train_input and train_output, we have 220 (1,048,576) unique examples. We will split those into two sets, one for training and the other for testing. We will take 10,000 examples (0.9% of the entire data) from the dataset and use it as training data and use the rest of the 1,038,576 examples as test data.\n\nThis is the most important part of the tutorial. Tensorflow and various other libraries (Theano, Torch, PyBrain) provide tools for users to design the model without getting into the nitty-gritty of implementing the neural network, the optimization or the backpropagation algorithm.\n\nDanijar outlines a great way to organize Tensorflow models which you might want to use later to organize tidy up your code. For the purpose of this tutorial, we will skip that and focus on writing code that just works.\n\nImport the required packages to begin with. If you haven\u2019t already installed Tensorflow, follow the instructions on this page and then continue.\n\nAfter importing the tensorflow, we will define two variables which will hold the input data and the target data.\n\nThe dimensions for data are [Batch Size, Sequence Length, Input Dimension]. We let the batch size be unknown and to be determined at runtime. Target will hold the training output data which are the correct results that we desire. We\u2019ve made Tensorflow placeholders which are basically just what they are, placeholders that will be supplied with data later.\n\nNow we will create the RNN cell. Tensorflow provides support for LSTM, GRU (slightly different architecture than LSTM) and simple RNN cells. We\u2019re going to use LSTM for this task.\n\nFor each LSTM cell that we initialise, we need to supply a value for the hidden dimension, or as some people like to call it, the number of units in the LSTM cell. The value of it is it up to you, too high a value may lead to overfitting or a very low value may yield extremely poor results. As many experts have put it, selecting the right parameters is more of an art than science.\n\nBefore we write any more code, it is imperative to understand how Tensorflow computation graphs work. From a hacker perspective, it is enough to think of it as having two phases. The first phase is building the computation graph where you define all the calculations and functions that you will execute during runtime. The second phase is the execution phase where a Tensorflow session is created and the graph that was defined earlier is executed with the data we supply.\n\nWe unroll the network and pass the data to it and store the output in val. We also get the state at the end of the dynamic run as a return value but we discard it because every time we look at a new sequence, the state becomes irrelevant for us. Please note, writing this line of code doesn\u2019t mean it is executed. We\u2019re still in the first phase of designing the model. Think of these as functions that are stored in variables which will be invoked when we start a session.\n\nWe transpose the output to switch batch size with sequence size. After that we take the values of outputs only at sequence\u2019s last input, which means in a string of 20 we\u2019re only interested in the output we got at the 20th character and the rest of the output for previous characters is irrelevant here.\n\nWhat we want to do is apply the final transformation to the outputs of the LSTM and map it to the 21 output classes. We define weights and biases, and multiply the output with the weights and add the bias values to it. The dimension of the weights will be num_hidden X number_of_classes. Thus on multiplication with the output (val), the resulting dimension will be batch_size X number_of_classes which is what we are looking for.\n\nAfter multiplying the output with the weights and adding the bias, we will have a matrix with a variety of different values for each class. What we are interested in is the probability score for each class i.e the chance that the sequence belongs to a particular class. We then calculate the softmax activation to give us the probability scores.\n\nWhat is this function and why are we using it?\n\nThis function takes in a vector of values and returns a probability distribution for each index depending upon its value. This function returns a probability scores (sum of all the values equate to one) which is the final output that we need. If you want to learn more about softmax, head over to this link.\n\nThe next step is to calculate the loss or in less technical words, our degree of incorrectness. We calculate the cross entropy loss (more details here) and use that as our cost function. The cost function will help us determine how poorly or how well our predictions stack against the actual results. This is the function that we are trying to minimize. If you don\u2019t want to delve into the technical details, it is okay to just understand what cross entropy loss is calculating. The log term helps us measure the degree to which the network got it right or wrong. Say for example, if the target was 1 and the prediction is close to one, our loss would not be much because the values of -log(x) where x nears 1 is almost 0. For the same target, if the prediction was 0, the cost would increase by a huge amount because -log(x) is very high when x is close to zero. Adding the log term helps in penalizing the model more if it is terribly wrong and very little when the prediction is close to the target. The last step in model design is to prepare the optimization function.\n\nTensorflow has a few optimization functions like RMSPropOptimizer, AdaGradOptimizer, etc. We choose AdamOptimzer and we set minimize to the function that shall minimize the cross_entropy loss that we calculated previously.\n\nThis error is a count of how many sequences in the test dataset were classified incorrectly. This gives us an idea of the correctness of the model on the test dataset.\n\nWe\u2019re done with designing the model. Now the model is to be executed!\n\nWe start a session and initialize all the variables that we\u2019ve defined. After that, we begin our training process.\n\nWe decide the batch size and divide the training data accordingly. I\u2019ve fixed the batch size at 1000 but you would want to experiment by changing it to see how it impacts your results and training time.\n\nIf you are familiar with stochastic gradient descent, this idea would seem fairly simple. Instead of updating the values after running it through all the training samples, we break the training set into smaller batches and run it for those. After processing each batch, the values of the network are tuned. So every few steps, the network weights are adjusted. Stochastic optimization methods are known to perform better than their counterparts for certain functions. This is because the stochastic methods converge much faster but this may not always be the case.\n\nFor every batch, we get the input and output data and we run minimize, the optimizer function to minimize the cost. All the calculation of prediction, cost and backpropagation is done by tensorflow. We pass the feed_dict in sess.run along with the function. The feed_dict is a way of assigning data to tensorflow variables in that frame. So we pass the input data along with target (correct) outputs. The functions that we wrote above, are now being executed.\n\nThat\u2019s all. We\u2019ve made our toy LSTM-RNN that learns to count just by looking at correct examples! This wasn\u2019t very intuitive to me when I trained it for the first time, so I added this line of code below the error calculation that would print the result for a particular example.\n\nSo as the model trains, you will notice how the probability score at the correct index in the list gradually increases. Here\u2019s a link to the complete gist of the code.\n\nMany would ask, why use a training data set which is just 1% of the all the data. Well, to be able to train it on a CPU with a single core, a higher number would increase the time exponentially. You could of course adjust the batch size to still keep the number of updates same but the final decision is always up to the model designer. Despite everything, you will be surprised with the results when you realize that 1% of the data was enough to let the network achieve stellar results!\n\nYou can try changing the parameter values to see how it affects the performance and training time. You can also try adding multiple layers to the RNN to make your model more complex and enable it to learn more features. An important feature you can implement is to add the ability to save the model values after every few iterations and retrieve those values to perform predictions in future. You could also change the cell from LSTM to GRU or a simple RNN cell and compare the performance.\n\nTraining the model with 10,000 sequences, batch size of 1,000 and 5000 epochs on a MacbookPro/8GB/2.4Ghz/i5 and no GPU took me about 3\u20134 hours. And now the answer to the question, everybody is waiting for. How well did it perform?\n\nFor the final epoch, the error rate is 0.1% across the entire (almost so because our test data is 99% of all possible combinations) dataset! This is pretty close to what somebody with the least programming skills would have been able to achieve (0% error). But, our neural network figured that out by itself! We did not instruct it to perform any of the counting operations.\n\nIf you want to speed up the process, you could try reducing the length of the binary string and adjusting the values elsewhere in the code to make it work.\n\nNow that you\u2019ve implemented your LSTM model, what else is there that you can do? Sequence classification can be applied to a lot of different problems, like handwritten digit recognition or even autonomous car driving! Think of the rows of the image as individual steps or inputs and the entire image to be the sequence. You must classify the image as belonging to one of the classes which could be to halt, accelerate, turn left, turn right or continue at same speed. Training data could be a stopper but hell, you could even generate it yourself. There is so much more waiting to be done!", 
        "title": "A noob\u2019s guide to implementing RNN-LSTM using Tensorflow"
    }, 
    {
        "url": "https://medium.com/@edouardcolas/voir-linvisible-f737ed5d7b47?source=tag_archive---------1----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Voir l\u2019invisible \u2013 Edouard Colas \u2013"
    }, 
    {
        "url": "https://medium.com/@cankut_durgun/artificial-intelligence-and-deep-learning-primer-47c064ed4203?source=tag_archive---------2----------------", 
        "text": "Artificial intelligence is a hot topic these days. Computer programs are beating humans at complex games like Go, cars are learning to drive themselves, and more and more startups are claiming that they use artificial intelligence in their products. With this much hype, it\u2019s easy to overlook the fundamentals of the subject.\n\nWhat is artificial intelligence, what are its potential use cases, what does its history look like, what\u2019s the difference between artificial intelligence, machine learning, and deep learning, and what is the current state of affairs in the space?\n\nHere\u2019s a great primer by Andreessen Horowitz which answers these questions.", 
        "title": "Artificial intelligence and deep learning primer \u2013 Cankut Durgun \u2013"
    }
]