[
    {
        "url": "https://medium.com/@olivercameron/meet-alvin-the-self-driving-car-from-1989-f0e40492a354?source=tag_archive---------0----------------", 
        "text": "As the Udacity community continues to make amazing progress on our open source self-driving car, I couldn\u2019t help but Tweet an exciting video a team of Udacity students shared with me. The video demos a student-created deep learning model, which aims to steer a car autonomously using only a camera.\n\nHow does it work? After training the model on tons of human-generated driving data, you feed the model a camera image frame (in this case, a series of frames from a trip from Mountain View to Half Moon Bay, a route it\u2019s never seen before) and the model outputs a value it believes would steer the car correctly on its route. You can read more about this very fun problem here. This deep learning focussed approach has gained a lot of traction with those working on self-driving cars as of late. A huge benefit is that you don\u2019t define rules (lane markings, etc.), meaning that given enough (good) training data, the car aims to handle environments it\u2019s never seen before, just like a human would (using past experience).\n\nHowever, this approach is not necessarily new, which I was reminded of when Dean Pomerleau replied to my Tweet. Dean led a project at CMU called ALVINN (Autonomous Land Vehicle In a Neural Network), a groundbreaking project from the late 80s to build an autonomous vehicle powered by a neural network. I highly recommend checking out the below video, shared by Dean from 1992.\n\nThe neural network powering ALVINN was beautifully implemented, but constrained very much so by the hardware. ALVINNs original top speed was 3.5mph, which was limited by the amount of computing power they could fit in the vehicle. In the Udacity Self-Driving Car, we are lucky to have a machine with an NVIDIA Titan X Pascal GPU (>$1000), powering many of our intensive calculations. ALVINN however\u2026\n\nHowever, after much iteration, ALVINN (read more on NAVLAB) was able to hit 70mph in the early 90s. Watch the below news video from the time for more info, or read this paper for performance, system and hardware details (highly recommended).\n\nI also highly recommend reading this paper on ALVINN, and reading Dean\u2019s thesis he published in 1993. Dean and his team solved many of the problems neural network powered self-driving cars are facing today. Dean also shared a chapter from his thesis on Twitter, about how important it is to generate training data that demonstrates the car recovering from perilous situations.\n\nDean\u2019s conclusion in the paper is especially prescient.\n\nThe Udacity Self-Driving Car team hopes we can bring to production, with the help of our amazing students, what ALVINN pioneered in the early 80s. Thank you Dean and team!", 
        "title": "Meet ALVINN, the Self-Driving Car From 1989 \u2013 Oliver Cameron \u2013"
    }, 
    {
        "url": "https://hackernoon.com/the-ai-singularity-is-not-nigh-35ce2d67d6ee?source=tag_archive---------1----------------", 
        "text": "It has become common to hear now that the \u2018AI Singularity\u2019 is soon upon us. Soon Artificial Intelligence will reach such an advanced state that it will update itself, leading to an exponential explosion of self-augmenting sophistication. When algorithms reach such a state, they will be so advanced and self-editing that humans will no longer be able to understand them. They will effectively exit our control.\n\nEven a modestly intelligent AI could spend nearly endless computer cycles to improve itself, and thereby achieve stupendous results in very little \u2018human\u2019 time. Imagine a mediocre programmer given 10,000 years to improve a piece of code. Surely even the slowest dullard could accomplish something. Once an algorithm has the sophistication of even the most modestly gifted humans, it could commit time to bootstrapping itself in \u2018computer clock time\u2019. A single human day would be eons in such time, more than enough to upgrade. At such a rate, a self-augmenting AI could quickly surpass even the brightest person. From there it would diverge into territory yet unexplored by human minds.\n\nThe key necessity is an AI that can design itself analytically, i.e., it can inspect its own source code with intuition and reason the way a human would. The singularity will not occur as a result of naive optimization. Modern machine learning algorithms are trained via optimization techniques. These vary. But they generally boil down to a) brute force approaches and b) blind analytical optimizations. Backpropagation in a neural network can improve results. It is a straightforward analytical technique. But it is not a reasoned, intuited conclusion. This is the sort of dumb, mechanical operation suited to computers. It is not how humans design systems. When an algorithim can design in the human way, however badly it may do so, it may achieve the exponential growth mentioned in the singularity.\n\nIt is precisely this sort of human reasoning that is nowhere on the radar in AI research. We will not attain it for 50 years.\n\nWhere machine learning has achieved its greatest successes, it has eschewed higher-order reasoning and focused on narrowly tailored, supervised learning problems. This is not to take away from its success. Modern algorithms can accomplish incredible feats in image processing, NLP, and many other areas. But generally these solutions boil down to fitting models to known data with effective but limited methods, like backpropagation.\n\nThis is not the kind of learning necessary for an algorithm to bootstrap itself. We have not remotely approached it.\n\nThe AI singularity is massively overhyped in part because we have underestimated the sophistication of systems designed by nature. The complexity of biological systems is a very easy thing to overlook. There is a long history of this. But in truth, very few human systems compete with biological ones in those areas for which evolution has selected. In all sorts of areas, the more we delve, the more we discover how difficult it is to match what nature accomplishes.\n\nBiological systems should not be thought of as simply \u2018natural\u2019. They should be thought of as highly advanced \u2018technology\u2019 that just happens to have arisen due to selective processes over billions of years. There is no effective difference between biological components and alien artifacts possessing technical capabilities and design motifs dramatically different and often superior to our own. It just so happens that they were created in a stochastic environment, which is not to lessen their sophistication.\n\nComputer scientists and other technologists often underestimate the complex depth of biological systems, so they are more prone to the hubris that they can equal them without much effort. Of all the biological technology ever found, the human brain is by far the most advanced ever discovered. So to think that we could construct something equal to that, when we struggle to replicate even the most basic natural processes, is exceedingly optimistic. It is to dramatically discount the inestimable engineering endowed in us by evolution.\n\nEven the simplest distinctly human tasks are beyond the reach of algorithms, and will remain so for the foreseeable. It is generally those tasks for which humans were never well suited, such as intensive mathematical operations, where algorithms excel. The most recent accomplishments in ML, while impressive in isolation, only demonstrate the utter inability of algorithms to reason, generalize, or intuit: precisely the skills necessary for the AI singularity.\n\nWhile the AI Singularity is not an impossibility, it is dramatically farther off than is commonly imagined. This is largely because we focus on the technologically impressive advancements that have just arrived (deep learning) and ignore the mundane but wildly more sophisticated \u2018biological technologies\u2019 we have lived with our whole lives. Equalling nature is not strictly impossible, but it is an extremely tall order.\n\nFollow me on Twitter at Andrew Barisser", 
        "title": "The AI Singularity is Not Nigh \u2013"
    }, 
    {
        "url": "https://medium.com/@petervanderputten/teaching-and-old-dog-new-tricks-transfer-learning-in-deep-neural-networks-ca85992119ec?source=tag_archive---------2----------------", 
        "text": "When you need to learn a new task, it can help if you already have experience in a different but similar task. The same holds for deep neural networks, a class of machine learning methods that recently became famous for beating the best human Go players, producing hallucinating paintings, recognizing doodles or generating Trump-style Tweets. In machine learning, this idea of transferring knowledge from one domain to another is called transfer learning.\n\nNow surely, if you have enough time to learn (and thus seen sufficient examples), the value of transfer learning should diminish\u200a\u2014\u200ayou could just as well have learned from scratch. In our recent research we have investigated whether this actually holds for deep learning [Soekhoe et al, 2016]. Building on some prior work we also investigated whether it would be best to let the entire network adapt, or perhaps lock down the lower layers [Yosinski et, 2014].\n\nWe tested this as follows. We used two different data sets, one with different categories of objects (a, b, c in the image below, taken from the Tiny-Imagenet data set). Networks were first fully trained and tested on one set of objects. For example after training networks on examples of lighthouses, butterflies etc. (in total 100 different image classes with 500 examples each), the networks were then tested by letting these classify new test images out of these categories. Next, the networks were given another task: they had to learn to recognize new classes of objects with more limited number of examples (e.g. testing for different conditions, for example only 50, 100, 200 etc umbrellas; in total 100 new image classes). This experiment was repeated with images depicting certain scenes or settings (d, e, f\u200a\u2014\u200aMini-Places2).\n\nFollowing Yosinski et al [2014], we also wanted to know whether all elements of the network would be updated or just the higher level layers. Despite the recent deep learning hype, neural networks already exist for decades, and are remotely inspired by how the brain is organized. Information feeds in at the lowest level (left in the image below), and the activation of the various \u2018neurons\u2019 feeds forward through the network, relative to how strongly the neurons in the various layers are connected. Based on the training feedback the weights of the network will be adapted from the top layer back down again, to tune the network towards a better outcome. As a result, the various layers will learn to detect features of increasing granularity, layer by layer. You could think that when the network needs to learn a new task, for instance recognizing umbrellas, the optimal approach would be to adapt all layers of the network. But it could also be that actually by fixing the weights of the lower layers (i.e. keeping lower level features the same) you will make it easier for the higher level layers of the network to adapt itself; because the lower level features are generally more reusable.\n\nBelow you can see some of the results for the Tiny-Imagenet data set. The baseline (\u2018base\u2019 on the x-axis) indicates networks that were learned completely from scratch, i.e. no transfer learning resue of what was learned from the other tasks. FTall stands for reusing the network that was learned on the old task, and fine tune all layers in the network. Finally, SxT stands for reusing the network from the old task, but fixing subsequent layers in the network (layer 1, layer and 2 etc). The number stands for the overall number of images that were available. Accuracy rates are plotted on the y-axis (percentage test images correctly classified).\n\nWhat do these results show? Firstly, the less data for the new task is available, the higher the benefit of reusing the networks learned on the other tasks is as a starting point (i.e. \u2018base\u2019 gets beaten more often for the lower data set sizes). We also see a pattern that when transfer learning makes sense, i.e. when less than 500 examples for the new classes are available, the results are best if we fix the first two or three layers of the network.\n\nFor detailed results see the paper, but what these experiments have demonstrated that indeed you can teach an old dog some new tricks\u200a\u2014\u200aas long as there is not much data available for the new classes it makes sense to start with what you have learned from the other tasks. And also that it makes sense to adapt some of the deeper, higher level structures in your old dog brain, and leave the more fundamental levels alone.\n\nThis post was also published as a LinkedIn article.\n\nDeepak Soekhoe, Peter van der Putten and Aske Plaat. On the Impact of Data Set Size in Transfer Learning using Deep Neural Networks. In: Fifteenth International Symposium on Intelligent Data Analysis (IDA), 2016.\n\nNote: Deepak Soekhoe was the principal researcher for this work\n\nYosinski, J., Clune, J., Bengio, Y., Lipson, H.: How transferable are features in deep neural networks? In: Advances in Neural Information Processing Systems, pp. 3320\u20133328, 2014", 
        "title": "Teaching an old dog new tricks: Transfer learning in deep neural networks"
    }, 
    {
        "url": "https://medium.com/@NataliaDiazRodr/things-i-learnt-in-thanksgiving-in-san-francisco-5c2d71942a11?source=tag_archive---------3----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Things I learnt in Thanksgiving in San Francisco \u2013 Natalia D\u00edaz Rodr\u00edguez \u2013"
    }, 
    {
        "url": "https://medium.com/@DrAndyPardoe/neurons-ai-launches-the-network-for-ai-professionals-9cb36bd42145?source=tag_archive---------4----------------", 
        "text": "A new social network for artificial intelligence professionals called Neurons.AI is launching today that will both operate online and host real world meet-ups.\n\nNeurons will be the Facebook for AI experts and also provide members with the chance to socialise at regular events, to learn more about the subject and share ideas with others in the field.\n\nNeurons is the brainchild of UK-based Dr Andy Pardoe, a PhD in Artificial Intelligence and Founder of Informed.AI, a group of community websites supporting those interested in AI, machine learning and data science.\n\nThe network will officially launch in beta mode on the 27th November but is open today for early registrations with a limited membership for the first six months, to be followed later by open paid subscriptions. Beta members will not pay membership for the first year. All membership fees will be used to directly for activities of the Informed.AI group to help promote and support the wider AI community.\n\nFounder, Andy Pardoe, said: \u2018I want to build a place where people can talk and share their ideas and experiences about AI and machine learning and allow collaborations between researchers and those working in a commercial setting.\u2019\n\nHe added that members would be able to learn more about the latest developments in the AI field, often before anyone else does, given that this will be a forum for experts from industry and academia.\n\nThe social dimension will also be front and centre with an objective to build new connections and make friends in the AI and machine learning world. There will also be opportunities for members and their organisations to make presentations to members at meet-ups.\n\nNaturally there will be significant networking opportunities; the ability to share and contribute to online forums and articles connected to Neurons; and to participate and also present new ideas at meet-ups.\n\nIf you would like to become a member please visit http://Neurons.AI to find out more.", 
        "title": "Neurons.AI Launches \u2014 The Network for AI Professionals"
    }, 
    {
        "url": "https://medium.com/@DrAndyPardoe/celebrating-eighteen-months-of-homeai-info-87306d0e6511?source=tag_archive---------5----------------", 
        "text": "Another six months, and a lot of progress to report on.\n\nOur main site homeAI.info still remains at the heart of our group. A growing directory of information resources, with an additional category added for fintech during the last period and still more to come. The news area is still very popular and we continue to see more user submitted stories. We have also continued to add more to our spotlight area and are always looking for more companies, startups and people to profile in our spotlight section.\n\nWe have just launched a new dedicate area for Students of AI accessed via the link http://Study.AI which we see as a major part to our educational offering going forward, and will over the coming months add more resources to this area.\n\nWe have launched the 2nd Annual Global AI Achievement Awards which has an amazing 21 categories, making it the biggest and best Awards for AI. This is the original AI Awards and we hope you all support this initiative by voting at http://Awards.AI. The Awards are a core part of us delivering our manifesto obligation of supporting the AI community and celebrating the achievements of those working in the field.\n\nTo mark the Eighteen month anniversary we are launching our most ambition website yet. We are calling it Neurons.AI and its a Professional Network for AI Practitioners and Researchers. The focus on this site is to provide a bridge between commercial and academic endeavours in the field of AI. We strongly believe that bringing the two groups together will produce even more amazing developments in the field of AI, Machine Learning and Data Science. The network is like a social media network, but with a significant emphasis on forums and discussions. Neurons.AI also includes an offline element in the form of regular meet-ups. We have an official Press Release for this launch which you can read here.\n\nWe are also preparing to launch our AI Showcase Quarterly meet up from Q1 2017, the details can be seen at http://Showcase.AI. The desire is to inform students of AI and Machine Learning about the inner workings of a commercial development of Machine Learning applications and systems. This meetup will also be an opportunity for startups to showcase their products.\n\nWe continue to develop the careers portal and jobs board at http://Vocation.AI and are actively looking for more companies or agencies wanting to list their job opportunities on our site for free.\n\nAs always without the support of the AI community we are nothing. We continue to get wonderful feedback, and look forward to develop our platform to further support the AI community. We are very excited to make significant progress in 2017. As part of this we are looking to build out our advisory board to help us shape the direction of our future growth and are exploring ways we can accelerate our growth and rollout in 2017.\n\nThank you for your continued support and encouragement.\n\nDr Andy Pardoe\n\nFounder of the Informed.AI Group of Community Websites\n\nWe have twitter accounts for all of our sites;", 
        "title": "Celebrating Eighteen Months of homeAI.info \u2013 Dr Andy Pardoe \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/new-artificial-intelligence-technology-character-misrecognition-to-less-than-half-of-conventional-f3b120e2ab8e?source=tag_archive---------6----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "New Artificial Intelligence Technology, Character Misrecognition to Less Than Half of Conventional"
    }
]