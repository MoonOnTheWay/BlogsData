[
    {
        "url": "https://chatbotnewsdaily.com/chatbots-the-entry-into-ai-589505d92e44?source=tag_archive---------0----------------", 
        "text": "An Introduction to Chatbots, Messaging Channels and the History of Artificial Intelligence and Robots.\n\nChatbots are not a particularly new phenomenon to this world. They are in essence nothing more than a programmed input-output system. In the most basic form, Chatbots, also known as chatterbots, interact with humans on closed domains via written text. The user may ask simple questions or give simple commands like \u201cGive me a news update\u201d, which the Chatbot scans for keywords and possibly matches these with its dataset. If the Chatbot is able to match one or more keywords with its dataset, the predefined response will show as output. This basic form of Chatbots in turn can be altered and programmed to eventually arrive at more intelligent bots that may converse not only on closed domains but an open domain as well, meaning that the user may also give commends outside the actual context. For instance, when communicating with a news bot it may answer unrelated questions like \u201chow is the weather tomorrow\u201d or \u201cfind me red sneakers\u201d as well.\n\nDuring the last developer conference in April 2016, Facebook announced that it would open up its messenger platform for the commercial use of Chatbots, and so did Microsoft, WeChat, Telegram, Kik and Slack to name a few. Since the announcement the Chatbot market has grown exponentially with developers and user experimenting with celebrity Chatbots like the many Selena Gomez Chatbots and the Shakespeare Chatbots, flirty ones like the Evie Chatbot and other girlfriend Chatbots, as well as the various attempts for adult, +18 and other sex Chatbots.\n\nUndoubtedly, Chatbots have become a hot topic being widely discussed in newspapers and magazines around the world.\n\nEven though the hype has just started now, Chatbots have been around since 1966.\n\nJoseph Weizenbaum\u2019s Eliza can be thought of as the mother of all Chatbots. Similar to basic Chatbots of today, she/it was programmed to match keywords with a dataset on a closed domain. Strangely enough, her/its closed domain lies in the field of the Rogerian psychotherapy. Now, of course, you will not be able to really find the root to all your problems with Eliza\u2019s help but we encourage you to take a quick look and play around with her. She is glibber than one might think a 50 years old program can be.\n\nWith the development of Eliza, a race for human Chatbots has started. Numerous developers challenged each other to create more and more intelligent, \u201chuman-like\u201d Chatbots.\n\nIn 2001, AOL experimented with commercial Chatbots and released a system called SmarterChild on its messenger platform AIM. SmarterChild was able to give information about the weather, the cinema program and the latest news. The system was somewhat more intelligent than Eliza, yet restrictive because of its continuous confusion and default answers.\n\nEven though the developers of Eliza claim that she/it did pass a restricted Turing Test, one quickly observes the limits Eliza is bound to. A few questions are enough to know that Eliza is not human (or has a terrible sense of empathy).\n\nThe Turing Test has been a milestone in the early research of AI. In this test, you chat via a computer with two partners who are sitting in another room. One of the partner, however, is a Chatbot, while the other is a human. It is the task to find out on what end the computer\n\noperates. The Chatbot is supposed to be programmed to convince you that he is a real person.\n\nWhat question would you ask?\n\nAccording to Turing, if it is not possible to detect in the conversation with an invisible opposite whether the opposite is a human or a machine than one needs to assign a spirit to the opposite even if the opposite is a machine.\n\nEven though you probably never heard of this specific test, you constantly use the Turing Test. Every time we get a message that says \u201cCongratulations, you won 1.000.000 Dollar\u201d we evaluate whether the message was generated by a machine or human.\n\nUntil now, no Chatbot has been able to pass the Turing Test without any restrictions in the test setup. That is of course partly due to the technological limitations researchers still face but also due to a rather ethical/ philosophical issues.\n\nThe research of Artificial Intelligence itself is until today still not clear on what intelligence really is or how it is to be defined. And that might be the much greater limitation to developing a Chatbot with spirit.\n\nNevertheless, suppose one day intelligence is somewhat defined and by that day the technological advancements have as well passed the current limitations and researcher are able give birth to bots that answer logically and be able to interact in an open domain. Still, the question for intelligence remains: Are these bots really intelligent or are they just mimicking intelligence?!\n\nSo, Chatbots are not particularly new. Yet, they enjoy a tremendous amount of interest from large companies, developers and pretty much everyone else at the moment.\n\nThe future is expected to be shiny and nobody really knows what is going to happen. It seems the ride could go anywhere. Already now, at the very beginning of simple Chatbots, developers give insights to their visions that the main street might not be ready yet. Sam Mandel, CEO of the company behind the weather forecasting C(h)atbot Poncho dreams of a Chatbot that people use more than just for getting information on whether to take their umbrellas or sun blocker when leaving the house. Mandel can be quoted: \u201cOur goal is to make it the first bot you want to be friends with.\u201d That future version is supposed to react like a human-being. When insulted, Poncho will not answer for a while.\n\nBut why do Chatbots experience an overwhelming hype just now?\n\nIt is quite simple, because Chatbots are the New Apps. This is not only what we think but also what Facebook founder Mark Zuckerberg and Natya Sadella from Mirosoft say.\n\nOn the one hand, the App-Area has come to an end. User are not willing to install a separate app for each service they need anymore nor to create a user account for each app again and again. Messaging-platforms have become more and more important. A few platforms, billions of users with millions of integrated services. Some voices even say that search engines and browser will become redundant as one day we will find all the information on Facebook.\n\nOn the other hand, the most used apps have become the messaging-apps. WhatsApp and Facebook-Messenger alone reach over 1,7 billion active users. Studies show that besides gaming, from all the time we spent on our smartphones 90% of our time is spent on messaging apps and platforms.\n\nAll in all, we are still at the beginning. There are only a few dozen Chatbots available of which most work with defined command buttons only. But as NOBODY who walks the earth is perfect, so is NOTHING on this planet perfect\u200a\u2014\u200aneither are Chatbots. It is rather a question of time and patience. And on the trail to the vision of intelligent robots, Chatbots might be a significant cornerstone in that direction.\n\nAnd then one day, there might be that moment, when you talk with or about your Chatbot and don\u2019t call the Chatbot and undefined \u201cit\u201d anymore but give it a name or say \u201che/she\u201d and you realise her is not far away anymore.\n\nStart your journey now by creating a personalised Chatbot for your brand or personal life with www.e-bot7.com the largest Chatbot provider in Europe.", 
        "title": "Chatbots \u2014 The entry into AI \u2013"
    }, 
    {
        "url": "https://medium.com/the-mission/up-to-speed-on-deep-learning-august-update-part-1-25afc11aea6b?source=tag_archive---------1----------------", 
        "text": "Continuing our series of deep learning updates, we pulled together some of the awesome resources that have emerged since our last post on August 2nd. In case you missed it, here\u2019s the July update (part 2), here\u2019s the July update (part 1), here\u2019s the June update, and here\u2019s the original set of 20+ resources we outlined in April. As always, this list is not comprehensive, so let us know if there\u2019s something we should add, or if you\u2019re interested in discussing this area further.\n\nAn Intuitive Explanation of Convolutional Neural Networks by Ujjwal Karn. An thorough overview of CNNs: what they do, why they\u2019re important, how they work, some history, and their underlying concepts. Inspired by Denny Britz\u2019s Understanding Convolutional Neural Networks for NLP\u200a\u2014\u200aDenny\u2019s blog, WildML, is also an excellent resource with many deep learning explanations and tutorials.\n\nImage Completion with Deep Learning in TensorFlow by Brandon Amos. A deep learning tutorial that explains how to do image completion and inpainting via deep learning. Image completion and inpainting are closely related technologies used to fill in missing or corrupted parts of images\u200a\u2014\u200athis is important to designers and photographers, who often need to fill unwanted or missing parts of images. The code is also available on GitHub. Based on Raymond Yeh and Chen Chen et al.\u2019s paper Semantic Image Inpainting with Perceptual and Contextual Losses.\n\nDeep Learning Summer School lecture notes. Held the first week of August in Montreal and organized by Aaron Courville and Yoshua Bengio, professors at the University of Montreal, this conference provides a broad overview of current research in the deep neural networks. Speakers include preeminent deep learning researchers from Google, Facebook, Twitter, NVIDIA, and many others. All the lecture slides are available for review.\n\nVincent AI Artist (GitHub repository) by Saikat Basak. Vincent is an attempt to implement \u201ca neural algorithm of artistic style\u201d. A convolutional neural network (CNN) separates \u2018style\u2019 and \u2018content\u2019 from artistic images, and combines that artistic style with another image to create a unique expression. Leverage this repo to build your own of Prisma.\n\nRobotics Science and Systems (RSS 2016) Workshop notes and videos. This workshop held in Ann Arbor, MI on June 18, 2016 convened a broad set of experts to discuss the topic of deep learning in robotics, particularly around computer vision. Speakers such as Pieter Abbeel of UC Berkeley and Ashutosh Saxena of Brain of Things spoke about their research in the field. Their recorded talks and slides are available for review.", 
        "title": "Up to Speed on Deep Learning: August Update, Part 1"
    }, 
    {
        "url": "https://chatbotnewsdaily.com/meet-thousands-of-bot-developers-designers-inventors-and-enthusiasts-28da79764c42?source=tag_archive---------2----------------", 
        "text": "If you want to become part of our AI ecosystem just write us a message and we will help you find the right content and the right people for whatever you are looking for. You can be a writer, a developer or an expert in the field. We will get in touch and try our best to help you!\n\nIf you have any questions, feel free to contact us via team@chatbotnewsdaily.com", 
        "title": "Join our Community consisting of developers, writers and experts in the field of Artificial\u2026"
    }, 
    {
        "url": "https://medium.com/emergent-future/emergent-future-weekly-recapping-the-google-brain-teams-reddit-ama-ee2f2a89c300?source=tag_archive---------3----------------", 
        "text": "Issue 20\n\n\u00a0We change things up for our 20th issue with a recap of the Google Brain Team\u2019s Reddit AMA. The team spent nearly five hours answering questions about artificial intelligence, machine learning, deep learning, and the future of the team.\n\nPlus, we compile our top projects to try at home, and favorite articles from the past week.\n\nNot a subscriber? Join the Emergent // Future newsletter here.\n\nThe Google Brain Team is a group of research scientists and engineers that work to improve people\u2019s lives by creating intelligent machines. For the last five years they\u2019ve conducted research and built systems to advance this mission.\n\nHere are the 11 things we learned from their Reddit AMA on the future of artificial intelligence, machine learning, and data science. We\u2019ve pulled the most insightful quotes for brevity. Click through to see the full responses in context of the user-submitted questions, and other comments.\n\nOn the Team\u2019s Long Term Goals\n\n\u00a0We want to do research on problems that we think will help in our mission of building intelligent machines, and to use this intelligence to improve people\u2019s lives.\n\nOn the State of Machine Learning\n\n\u00a0Exciting: anything related to deep reinforcement learning and low sample complexity algorithms for learning policies. We want intelligent agents that can quickly and easily adapt to new tasks.\n\nUnderrated: maybe not a technique, but the general problem of intelligent automated collection of training data is IMHO under-studied right now\n\nOn Backpropogation\n\n\u00a0Backpropagation has endured as the main algorithm for training neural nets since the late 1980s. This longevity, when presumably many people have tried to come up with alternatives that work better, is a reasonable sign that it will likely remain important.\n\nOn Producing Consistently High-Quality Research\n\n\u00a0Learn what times of day you are at your most creative / productive, and try to protect those times to do your most important work: inventing algorithms, coding, writing papers.\n\nOn General AI\n\n\u00a0Question: On a scale of 1\u201310, 10 being tomorrow and 1 being 50 years, how far away would you all estimate we are from general AI?\n\nAnswer: A 6, but I refuse to be pinned down to whether the scale is linear or logarithmic.\n\nOn Using Machine Learning to Improve People\u2019s Lives\n\n\u00a0Developing ML techniques to improve the availability and accuracy of medical care is the single greatest opportunity for applied machine learning today.\n\nOn Training Data Required for Machine Learning / Deep Learning\n\n\u00a0Figuring out how to learn from more with less is a very exciting research area, both inside Google and in the larger research community.\n\nOn Bias\n\n\u00a0The fundamental problem is that machine learning models learn from data, and they will faithfully attempt to capture correlations that they observe in this data. Most of these correlations are fine and are what give these kinds of models their power. Some, however, reflect the \u201cworld that is\u201d rather than \u201cthe world as we wish it was.\u201d\n\nOn Current Machine Learning Challenges\n\n\u00a0The biggest challenge is how to build systems that can flexibly learn to accomplish many different tasks, from relatively few examples. This will require lots of work in unsupervised learning, reinforcement learning, transfer learning, and many other machine learning sub-disciplines, but is key to building the kinds of systems we want, which are not systems that are specialized to one or a handful of tasks, but rather intelligent systems or agents that can accomplish a vast array of tasks.\n\nOn Opaque Artificial Intelligence\n\n\u00a0Neural networks are tricky to understand, and developing techniques to understand them better is an incredibly important research area. There are a number of very promising directions, and we\u2019ve seen a lot of progress (especially optimization-based feature visualization).\n\nOn the TPU (Tensor Processing Unit)\n\n\u00a0The TPU is designed to do the kinds of computations performed in deep neural nets. It\u2019s not so specific that it only runs one specific model, but rather is well tuned for the kinds of dense numeric operations found in neural nets, like matrix multiplies and non-linear activation functions. We agree that fabricating a chip for a particular model would probably be overly specific, but that\u2019s not what a TPU is.\n\nEmergent Future is a weekly, hand-curated dispatch exploring technology through the lens of artificial intelligence, data science, and the shape of things to come. Subscribe here.", 
        "title": "Emergent // Future Weekly: Recapping the Google Brain Team\u2019s Reddit AMA"
    }, 
    {
        "url": "https://medium.com/@dollyfisher/businesses-are-beginning-to-see-the-value-of-ai-customer-service-987ec70bdf2?source=tag_archive---------4----------------", 
        "text": "Businesses are getting more and more interest in artificial intelligence, especially when it comes to customer service. As voice recognition and natural language processing systems become more accurate, more businesses are relying on it to automate their customer service. One virtual assistant startup company recently received $56 million in funding which was its best funding round to date.\n\nOne area of particular interest is chatbots. Think of chatbots as digital customer service agents who can interact with a business\u2019s customers to resolve issues, answer questions, and direct them to the right people when a live customer service agent is required. In 2016, it\u2019s estimated that chatbots will save businesses approximately $79 billion in customer service costs.\n\nHere are some interesting facts about chatbots:\n\nArtificial Intelligence News brought to you by artificialbrilliance\u00a0.com", 
        "title": "Businesses are beginning to see the value of AI customer service"
    }
]