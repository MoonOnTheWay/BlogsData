[
    {
        "url": "https://medium.com/@aviambale/transfer-of-learning-human-and-machine-d3b9314312b1?source=tag_archive---------0----------------", 
        "text": "I was reading this interesting article about Transfer of Learning in the annals of Educational Psychology. Why am I reading this? We work on Machine Learning and I trawl all peer-reviewed literature in various disciplines to see how we can approximate human learning. So, here is my summation, Buzzfeed listicle style\n\nThinking about these studies and the empirical data behind them, I was looking at how they transfer to machine learning", 
        "title": "6 axioms about Human Transfer of Learning. 3 extrapolations to Machine Learning"
    }, 
    {
        "url": "https://medium.com/deeper-learning/monkware-59316575107b?source=tag_archive---------1----------------", 
        "text": "The subtitle of the very first science-fiction novel was \u201cThe Modern Prometheus\u201d. And for as long as humanity has coveted the Fire of the Gods, we\u2019ve also worried about our ability to wield our new powers, and control our own creations.\n\nArtificial Intelligence (AI) is our latest gift of Promethean Fire.\n\nAs Chris Dixon explains, it\u2019s likely we\u2019re entering a new Golden Age of AI. For decades, the foundations of our civilisation have been technologies that have been intentionally programmed by human minds. But now we\u2019re beginning to imbue our modern world with autonomous intelligence, software with the ability to learn and generalise. We can create software that\u2019s now sufficiently complex, that we can\u2019t necessarily explain how it works.\n\nIn 2015, an open letter was written, signed by 150 prominent academics, entrepreneurs and AI researchers, among them Stephen Hawking and Elon Musk. Its signatories asked: how can we create AI systems that are beneficial to society rather than a threat? How do we ensure intelligent software we create is safe and robust?\n\nSome consider a possible Artificial Intelligence Revolution to be one of humanity\u2019s greatest existential threats. Should we be worried?\n\nIt\u2019s not often software makes the national news, but in March 2016 an AI system called AlphaGo managed to beat a Go Grandmaster, widely considered to be the best in the world. This was rightly considered by many to be a stunning achievement, Go is a highly intuitive strategy game, and it was thought that mastering Go might take another decade\u2019s work.\n\nThe success of AlphaGo relied on two key capabilities: one was the ability to imagine the future states of a game of Go, the other was the ability to form intuitions about which possible move was the best. It wasn\u2019t a perfect player, sometimes it made mistakes, yet it was still able to contrive rousing comebacks. Imagination and intuition, with a splash of fallibility; put like that, it\u2019s no wonder we can\u2019t help but see a kindred cognitive spirit.\n\nAlphaGo was made possible by a technology called Deep Learning, an approach based on neural networks, themselves an ersatz simulation of how the neurons in our own brains work. The same technology is already used to do all kinds of clever stuff, to translate between languages, to automatically recognise and categorise your photos, even to control self-driving cars.\n\nSo is all this further evidence that AI is beginning to acquire mental skills that we previously believed belonged only to ourselves?\n\nTo answer that, it\u2019s worth taking a moment to explain a couple of concepts: Weak AI, and Strong AI.\n\nWeak AI is a non-sentient automated intelligence that are capable of performing narrow specialised tasks. Personal assistants like Siri are a good example, they can understand natural language and follow instructions, but only if that instruction is something they\u2019ve been previously equipped to handle.\n\nBy contrast, Strong AI (also known as Artificial General Intelligence) is a self-aware intelligence that would be able to successfully perform any intellectual task that a human mind could. Note the use of the future tense here, Strong AIs are entirely hypothetical; right now, no Strong AI exists, or is even close to being built\u200a\u2014\u200athe only place you\u2019ll likely to encounter them is in cinemas.\n\nSo, it\u2019s worth bearing in mind that despite its apparent cleverness, AlphaGo is still a Weak AI, a highly specialised intelligence that achieved its skills by training for thousands of hours on a massive database of archived Go games.\n\nIt\u2019s as if AlphaGo had given away its possessions, donned saffron robes, and gone off to some remote mountaintop Go dojo; and then done nothing else but practice playing Go for a decade or two.\n\nJust playing and playing. Perpetual self-improvement, every microsecond of every minute, 24 hours a day. Never resting. Absolutely focussed. Relentless.\n\nAnd as you\u2019d expect, when the monkware finally did come down from the dojo, it kicked ass. Practice does indeed make perfect. Just don\u2019t challenge it to a game of chess, it\u2019s never even heard of it.", 
        "title": "Monkware \u2013 Deeper Learning \u2013"
    }
]