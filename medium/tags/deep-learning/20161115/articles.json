[
    {
        "url": "https://medium.com/@ForecastThis/5-big-obstacles-for-wealth-management-ai-37ad310c0c82?source=tag_archive---------0----------------", 
        "text": "At the Deep Learning in Finance summit in London earlier this year, a topic of conversation that was floated was the inexplicably slow adoption of advanced AI technologies within finance.\n\nIt\u2019s difficult to speculate on the accuracy of this premise with respect to investment management, without knowing what\u2019s going on in the geekier recesses of the world\u2019s hedge funds and quant shops. But having followed and worked on AI solutions within the space for a few years now, it\u2019s not hard to find some big reasons\u2026\n\nRightly or wrongly, hype surrounding the application of AI within investment management tends to focus on the identification of profitable trading strategies.\n\nHowever, framed simply as making optimal use of the available information, AI has the potential to benefit all aspects of the asset management pipeline, from economic forecasting, through alpha generation, to risk management.\n\nAssessing the potential of AI in any one of these settings will at best give a limited picture, and will at worst give a misleading picture. For example it is understood that simple \u201cbackward looking\u201d portfolio management can destroy alpha generated by the even most intelligent investment strategy.\n\nFor this reason, if we\u2019re going to start anywhere it probably makes most sense to apply AI to the tail end of the chain. But, moreover, AI offers a unique opportunity to remove these bottlenecks altogether and to create highly informed and highly responsive systems in which alpha generation and risk management are one integrated objective.\n\nMany of us would like to believe that we understand the limitations of back-tests, and the dangers of over-fitting. They are widely recognized and often written about. And yet we (both financial professionals and AI researchers) continue to obsess over such tests, and continue to make unjustifiable decisions on the back of them. While we get the basic principle and are happy to extol it to others, we rarely grasp the extent of its implications.\n\nSome professionals have estimated that the failure rate of AI algorithms, when they hit live tests, is about 90%. Those which make it though live tests often fail at the very next step.\n\nThe green plot below shows the back-tested PnL curve of a (recently deceased) AI driven hedge fund, proudly driven by \u201ca team of data scientists who have broken new ground in the discipline of predictive modelling\u201d. The red part of the plot shows what actually happened to their clients\u2019 capital when they began trading it.\n\nIt wasn\u2019t that their trading affected the market (although it certainly did in a small way). Nor was it that world events caused the market to suddenly shift gears and escape the grasp of their model (although that might also have happened). The likely truth is much simpler, and really should serve as a wake-up-call\u2026\n\nConsider the chart below which shows the back-tested Sharpe ratios of 50 completely meaningless randomly generated long/short strategies, trading the S&P 500 throughout 2016 YTD.\n\nThe first thing you ought to notice is that nearly a quarter of these random \u201cstrategies\u201d have Sharpes of greater than 3. This would by conventional accounts be considered excellent, and we weren\u2019t even trying! Looking at the alphas tells a similar story.\n\nThe problem is that generally speaking it is trivially easy\u200a\u2014\u200aif not comedically easy\u200a\u2014\u200ato come up with a strategy which exhibits outstanding test performance. This is not a problem that has arrived with the advent of AI\u200a\u2014\u200ait is a basic statistical truth which has been making it hard to confidently identify good fund managers for years. But the current predilection for \u201cplaying\u201d intensively with different algorithms has hugely exacerbated the problem.\n\nIt is for precisely this reason that serious, pipe smoking, scientists typically consider a \u201csignificant\u201d result to mean one that is reproducible in 99/100 independent trials. So if you\u2019re going to invest money predominantly on the basis of a back-test, you should probably start by asking to see the other 99 (statistical spoiler: the only way to run 100 independent trials is to test the same algorithm, unmodified, in something like 100 entirely unconnected market contexts).\n\nThis isn\u2019t even the full extent of the problem. The very moment we go back to the drawing board and start using insights from our failed models to improve our algorithmic approach (and what\u2019s the point of studying back-tests and paper trading output if we\u2019re not going to do that), the requirements for achieving statistical significance go through the roof! This is because, with all the best scientific will in the world, we\u2019re now actively selecting approaches which exhibit good test performance.\n\nFor this reason, if we want to ensure anything remotely like statistical rigor, we can never evaluate performance using the same data twice! This is of course patently unsustainable, and in fact it renders any back-test driven strategy selection methodology completely dead in the water.\n\nThis seems like a Cache 22. In a sense it is, but it\u2019s not in any way specific to AI. We\u2019re just asking the wrong questions.\n\nUndue reliance on paper tests is an example of a broader issue facing AI: when assessing these systems we need to refrain from applying arbitrary assessment criteria which we would not apply in other contexts such as in the hiring of human quants or the selection and application of more traditional statistical methods.\n\nIf we were considering hiring a human quant based on their past performance in a very narrow market context (and presumably either unimpressive or untested performance in all others), we would at least require that they could give a coherent, plausible and reasoned account of their working process.\n\nAccordingly, if somebody can actually back up an AI system with a suite of consistently impressive back-tests across a host of different market contexts, then by all means we should sit up and take notice\u2026 but probably our very next question should be regarding how the system operates and what its models look like under the hood. Why should we believe that it works?\n\nConversely, consider ARIMA, ordinary least squares regression, and mean-variance optimization\u200a\u2014\u200aworkhorse models and algorithms that have been used in economics and quantitative finance for decades. We neither completely rule out nor put everything behind these algorithms based on their test performance in a handful of narrow settings. Rather we accept them based on the soundness and limitations of their underlying math and logic\u2026 and we apply them with appropriate context and caveats.\n\nIt is entirely understandable that in a time of increasing economic uncertainty, and huge advances in AI and data availability, we should pursue a vision of fully automated investment management.\n\nClearly we are not there yet: we are at the profusely bleeding edge. Even so, it is hard to imagine a time soon when we will not want to know how and why our systems are making the recommendations they are. Even with an unbroken super-human track record. And even without regulatory restrictions.\n\nThere is evidence to suggest that\u200a\u2014\u200aeven once our AIs consistently have the edge on us\u200a\u2014\u200athe best results for a long time will be achieved by combining human and machine capabilities. Years after Garry Kasparov was beaten by Deep Blue, the best chess players in existence are collaborative human-computer teams. As if testament to the power of human intuition, Kasparov realized this fact and embraced it (anybody who blindly tells you that \u201cpure AI\u201d systems are best is just an ironic luddite).\n\nThe popularity (and by extension the contribution to industry) of linear regression\u200a\u2014\u200ain the face of many more advanced methods\u200a\u2014\u200ais a testament to its explicability as much as anything else. In order to take applied AI to the next level in finance\u200a\u2014\u200aor any high-stakes field of human endeavor\u200a\u2014\u200awe do not need ever more powerful black box algorithms. We need transparent, interpetable, interrogable, ones. We need AIs whose reasoning can be laid bare, from which we can take the best and leave the worst\u2026 AIs which can both fuel and be fuelled by our own expertise, curiosity and intuition.\n\nMethods like Deep Learning (which is a family of methods, not an algorithm per se) are only black boxes to the extent that the world is presently preoccupied with what they can \u201cdo\u201d. In many respects Deep Learning represents an opportunity to make the markets more understandable than ever before! We need to take this fork now. If we do not, we risk throwing out the baby of opportunity with the bathwater of risk-aversion.\n\nClearly there is an onus on AI developers to make the operational premises and the limitations of their technologies transparent, and not to be drawn into unsound or shallow demonstrations and justifications. It is, after all, unashamedly not in the purview of AI experts to devise and sell financial products and strategies, but rather to create enabling tools and technologies to empower industry professionals to do so.\n\nEven so, in order to succeed in this, said AI experts need to have a realistic grasp of the unique requirements and challenges of the financial sector. The financial and mainstream media have a very important role to play here, in particular by resisting the perpetuation of \u201cpop finance\u201d objectives.\n\nTo pick one example of many, it is notable that all recent media coverage of Hong Kong AI hedge fund Aidyia, led by AGI guru and all-round dude Dr. Ben Goertzel, has focused solely on the absolute return of the fund\u200a\u2014\u200aa figure which is widely recognized as being completely meaningless without reference to risk. Such reporting inevitably feeds back into research. Of the 20 or so highest-Google-ranking academic papers and presentations that I recently surveyed on the subject of automated market forecasting and trading, only a fraction made any reference to relevant concepts such as Sharpe Ratio, Alpha, or even standard deviation of returns, while the majority talked liberally about \u201cprofit\u201d or \u201creturns\u201d.\n\nRightly or wrongly, such goings-on project an image to the financial industry that the current state-of-the-art has fundamental limitations\u2026 and to some extent, as long as researchers are focusing on the wrong problems, the technology will remain irrelevant.", 
        "title": "5 Big Obstacles for Investment Management AI \u2013 ForecastThis \u2013"
    }, 
    {
        "url": "https://medium.com/@KMLabsEU/vision-2016-in-9-keywords-from-embedded-vision-to-deep-learning-2d780a951ca2?source=tag_archive---------1----------------", 
        "text": "Last week I took part in VISION 2016 in Stuttgart, curious to learn the latest development in the sector of Machine Vision for further developing our research activities in Konica Minolta Laboratory Europe. The fair, held from 8th to 10th November, has been visited by almost 10,000 visitors from 58 countries, and I think that the hottest topics were especially related with Embedded Vision, High Speed cameras, 3D vision and Deep Learning.\n\nOverall, VISION 2016 was crowded of robots manipulating and picking components and smart cameras demonstrating high speed barcode reading and face recognition. Finally, Deep Learning has definitely invaded the sector of Machine Vision. Of course, there was plenty of other technologies related to machine vision, I have selected only those that were interesting to me as Computer Vision researcher and fitted to the portfolio of our organization.\n\nThe following is a list to summarize many of the most interesting topics covered in VISION 2016:\n\nSo, I described the most interesting elements I have identified in the three days I was visiting the fair and I am also happy to mention some of the research institutions, whose activities I found interesting, such as German Fraunhofer IPA, Austrian AIT, French CEA and Swiss CSEM. Of course, plenty of other ideas and topics were presented and many other organizations took part in VISION 2016, but I won\u2019t be going into details for all of them. Please, if you have any other keyword fitting in my list, I would be happy to receive your suggestions: feel free to contact me at research@konicaminolta.eu and via Linkedin private message.", 
        "title": "VISION 2016 in 9 keywords: from Embedded Vision to Deep Learning"
    }, 
    {
        "url": "https://medium.com/the-quarter-espresso/introduction-of-neural-redis-part-2-6c22b42f412c?source=tag_archive---------3----------------", 
        "text": "is used to insert training examples for supervised learning. A training example should include the input(s) and the expected output(s).\n\nIf we want the neural network to infer the function as below:\n\nThus the neural network will actually infer the tunable parameters, to get the following equation:\n\nHere is one of the examples:\n\nThe inserted dataset will be appended into either training dataset or testing dataset.\n\nThe first returned value is the number of updated training dataset; the second returned value is the number of updated testing dataset.\n\nAssuming we have several training examples inserted as below:\n\nWe can train the neural network via \u00a0:\n\nis given for the auto detection of overfitting, which is based on the error rate in training/testing data.\n\nLet\u2019s see how it predicts the output via :\n\nThe accuracy of the prediction is related to the variety of training examples, the number of inserted training examples, and the number of dataset we\u2019ve trained.\n\nHere is how we get the details of the training in the neural network:\n\nThere are 6 examples in training dataset and 2 examples in testing dataset. Also the neural network was trained with 1344 steps in just a few milliseconds.\n\nPart 3 will show you how to do the classification.", 
        "title": "Introduction of neural-redis, part 2 \u2013 The Quarter Espresso \u2013"
    }, 
    {
        "url": "https://medium.com/@tanaydixit/cheer-up-exciting-times-ahead-72ca5701906a?source=tag_archive---------4----------------", 
        "text": "Just finished watching the latest episode of Last week tonight. The one where John Oliver rips into the United States for choosing Donald Trump. The episode was borderline depressing.There is too much happening everywhere. De-monetisation, trumpifcation, liberal lunacy or the right wing whataboutery.\n\nSo, I don\u2019t plan to add up to any of these sad thoughts. Instead I am trying to explain why I feel this is the best time to be alive and kicking. We as a generation have an opportunity so immense that we cant be bogged down by whatever the shit we read or hear.\n\nI am being positive and optimistic. Stop acting as if it\u2019s the end of the world!\n\nWe are living in a time with great possibilities. Here a few articles from the past few weeks that just show how far we have come.\n\n1. Uber is thinking of flying cars. Read this white-paper and then it doesn\u2019t seem so far off. https://www.uber.com/elevate.pdf\n\n5. Google\u2019s AI bots are now smart enough to encrypt their own messages\n\nIt will soon be tough differentiating an episode of Black mirror or Westworld with the real life.\n\nBut is this a bad thing?\n\nWe have the opportunity to pick up these new technologies. Choose a niche domain and start learning. There is plenty of information on the web to self learn. Plenty open source libraries with great support forums. Computational powers have never been more affordable. These technologies are at a stage where real life adoption has just started to pick up. Now is when the surge comes.\n\nI picked Deep learning in Fashion and Conversational commerce in fashion as my domains. For the past 8 months I have read numerous research papers on these domains. I am not an expert by any chance, But I am still better placed to understand how Deep learning is going change the fashion industry.\n\nWho knows? You may soon lose your job to all this automation you keep hearing about.", 
        "title": "Cheer up. Exciting times ahead \u2013 Tanay Dixit \u2013"
    }
]