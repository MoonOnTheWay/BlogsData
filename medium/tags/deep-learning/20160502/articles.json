[
    {
        "url": "https://medium.com/@brucerobbins/but-mathematical-techniques-are-a-kind-of-magic-7790014054b7?source=tag_archive---------0----------------", 
        "text": "But mathematical techniques are a kind of magic.\n\nOn occasion is may be good to play the cynical hand and try to reverse the hyperbole yet the emperor's vest is not a bad piece of tailoring. My tailor is very fond of three piece suits and what Americans refer to as the vest. As an item of clothing it can be taken for granted by the well dressed. Equally it can be disdained by advocates of other styles.\n\nIt would be foolish to under-estimate how significant machine learning is to technologists. I agree AI is not going to suddenly change life as we know it. But, a bit like math, it is magic. It is without doubt exciting, or at least it is to those of us who enjoy maths. Machine learning and AI are both something well worth getting excited about.\n\nThe Watson API has allows us to deliver much insight by simply plugging into the API. Amazon\u2019s AML makes complex predictive analytics a relatively trivial thing to implement. TensorFlow going open source allows us simply, and affordably, to incorporate learning from large tabular datasets and to treat images as analysable data.\n\nClassification of the facial features of your friends might be inconsequential: recognising the amounts of blood flow in a diagnostic data set can have significant consequence. Natural Language Processing (NLP) is having a radical impact on how we design interaction with our applications and enables multi language versions for comparatively little effort.\n\nNow it is true that none of this is new, but what is new is how much less of a time consuming drag and a chore it has recently become. I speak as someone who has spent eons dragging out bits of information from lines and lines of complex code, and the endless tweaking of algorithms.\n\nRefactoring, for small variations in desired output, with the current toolsets is no longer a major work effort. Using layers as opposed to reiterating through gargantuan lumps of data is a joy. This encourages and delivers more value, it makes performing the math fun, and yes quite a bit exciting.\n\nThe popular press loves things it does not comprehend and in such cases it often tends toward overstatement: my advice is not to read it. An intolerance to the views of non participants may, on occasion, be a good thing as in \u201cGet rid of the wife.\u201d As long as the \u2018hype\u2019 is a result of the products, that machine learning and AI employ, there is little to worry about.", 
        "title": "But mathematical techniques are a kind of magic. \u2013 Bruce Robbins \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/the-training-for-ai-gym-openai-open-4c7d3478763b?source=tag_archive---------1----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "The \u201cTraining For AI Gym\u201d, OpenAI Open \u2013 Hiroyuki Takayama \u2013"
    }, 
    {
        "url": "https://medium.com/bizcatalyst-360/big-data-artificial-intelligence-and-human-intelligence-fe8b92abd2c0?source=tag_archive---------2----------------", 
        "text": "BIG DATA CONSTANTLY hits that wall. Despite all the investment in infrastructure and people, Big Data just can\u2019t generate further value. This is happening because we\u2019re treating Big Data and the stuff it contains like algorithms and artificial intelligence (AI) just like we treat traditional information technology. And brick by brick this treatment constructs the wall Big Data just can\u2019t crack. From a high level, here is the wall.\n\nBrick 1\u200a\u2014\u200aBusiness knows business but doesn\u2019t understand AI. It\u2019s common for business to just delegate work to the data scientists and then have the data scientists come back with the right AI solutions. The problem is that the business has no context for how to correctly interpret the data provided by the AI. This leads to misunderstandings, lost revenue, and higher costs.\n\nBrick 2\u200a\u2014\u200aData scientists know data but don\u2019t understand business, culture or psychology. For AI to work, the designers, the data scientists, need to understand the humans and events in the ecosystems the data is collected from. AI looks for patterns to automate our judgment and intuition and to anticipate future events and behaviors. The effectiveness of how AI does this is limited to the understanding of the data scientists.\n\nBrick 3\u200a\u2014\u200aAI outperforms us humans. Though AI can outperform us humans through repetitive brute-force steps that\u2019s all AI is good at. AI cannot think outside of the box. Rather it often gets stuck in thinking a certain way. If an AI can beat a human at Chess or Go, that same AI can be blindsided by another human\u2019s approach and playing style. Without human intervention AI cannot learn from its mistakes.\n\nBrick 4\u200a\u2014\u200aUs humans outperform AI. We humans with detailed subject matter expertise and the right tools often outperform AI. Humans can look at something and give a ball park figure. We can take a small sample of data points extrapolate a conclusion and say it looks right. But we do get tired and we do make mistakes. AI helps us double check our work and keep us on the ball. We humans must learn to balance what we\u2019re good at with what AI\u2019s good at.\n\nBrick 5\u200a\u2014\u200aAI makes big mistakes. AI is only as good as its design and the data it has access to. AI doesn\u2019t have the common sense we have to give data the benefit of the doubt or take suspicious data with a grain of salt. We humans will always be needed to interpret the data AI provides and then improve the AI\u2019s accuracy.[/message]\n\n[bctt tweet=\u201dTo achieve the full benefits of Big Data we need to achieve the full benefits of AI.\u201d username=\u201dbizmastersglobal\u201d]\n\nLike us humans, AI is only good at doing certain things. For Big Data to work we must always balance and re-balance our investments, capabilities and competencies of our human intelligence with our artificial intelligence.\n\n[su_button url=\u201dhttp://bizcatalyst360.com/free-execubriefs/\" target=\u201dblank\u201d style=\u201d3d\u201d background=\u201d#ff4e07\" color=\u201d#ffffff\u201d size=\u201d1\" wide=\u201dyes\u201d center=\u201dyes\u201d radius=\u201d5\" icon_color=\u201d#2d3fff\u201d]CLICK HERE FOR FRESH INSIGHTS DELIVERED TO YOUR INBOX [/su_button]", 
        "title": "Big Data, Artificial Intelligence, and Human Intelligence"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/i-know-what-neural-network-is-what-tht-made-a-chart-1c2fa31e6d8?source=tag_archive---------3----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "\u201c I Know What Neural Network Is What Tht!?\u201d Made A Chart"
    }, 
    {
        "url": "https://medium.com/@michaelaalcorn/no-fear-neural-networks-b9bff05f64ed?source=tag_archive---------4----------------", 
        "text": "I was recently asked by my colleagues at Red Hat to write a non-technical introduction to deep learning that could be distributed to associates who were using tools incorporating some of my work. The following is that blog post.\n\nIn this blog post, I\u2019m going to attempt to provide an intuitive explanation of how neural network/\u201cdeep learning\u201d models work. The material covered in this blog post is summarized from several sources, including:\n\nA neural network is a mathematical model that is \u201cloosely\u201d inspired by how the brain works. If you\u2019ll recall from your Biology 101 course, neurons have something called a \u201c threshold potential\u201d, which describes how a neuron must reach a certain level of stimulation before firing (i.e., generating an action potential; see Figure 1a). When neurons fire, they let other neurons know by passing the signal over synaptic terminals, which is where the telodendria of one neuron meet the the dendrites of another neuron (Figure 1b). The coordinated firing of neurons controls everything from movement, to memory, to problem solving in animals.\n\nResearchers in deep learning intentionally use the word \u201cloosely\u201d when comparing neural network models to the brain because the brain is still significantly more complex than deep learning models both in terms of the number of neurons (nodes) and the number of synapses (connections) and the fact that the brain has several specialized structures that have specific functions. With that being said, the similarities between neural network models and the neuron firing mechanism I just described are readily apparent.\n\nThe original neural network model (first described by Frank Rosenblatt in 1957 and referred to as a \u201cperceptron\u201d) consists of several input \u201cneurons\u201d (the x circles in Figure 2), each of which has a connection with an associated weight (the w arrows in Figure 2). The input neurons (a \u201cneuron\u201d can also be referred to as a \u201cnode\u201d) correspond to features that will be used to make some prediction. For example, in the case of the Customer Asset Loss model, the input neurons contain things like: the number of times the customer visited a Solutions page on the Customer Portal, the number of bugs the customer opened in the past month, and the number of Premium assets the customer is currently subscribed to (the actual model has over 800 features). The values from the input neurons are then fed into a function node, which multiplies the input values by their associated connection weights. In the case of the Customer Asset Loss model, the function node calculation would look something like the following:\n\nIn this example, # Solutions page visits, # opened bugs, and # Premium assets correspond to the input neurons x1, x2, and x3 in Figure 2, respectively, while 5.2, 0.7, and 17.3 correspond to the connection weights w1, w2, and w3, respectively.\n\nIf the weighted sum of the input variables is greater than some threshold, then the function neuron \u201cfires\u201d and outputs a 1; otherwise, it outputs a 0 (this is the simplest case; in practice, neural network models incorporate many different functions with various output ranges).\n\nThe previous section described how a single node in a neural network works. However, neural network models can contain as many nodes as are desired (see Figure 3), yet the mechanism behind each node remains the same. To calculate the output for any given node, you simply need to identify the nodes from the previous layer that are connected to it. Each connection will have an associated weight, and so the output of your selected node is the weighted sum of its input nodes.\n\nThe middle columns of nodes in Figure 3 are referred to as \u201chidden layers\u201d because their outputs do not directly correspond to individual observable features (remember, the outputs are generated by applying a nonlinear transformation to a weighted sum of the input variables). The function nodes are typically arranged in \u201clayers\u201d because doing so makes training the model easier (I\u2019ll get to training soon).\n\nThe final layer of the neural network model is responsible for generating a prediction. In the case of the Customer Asset Loss model, we have a single node in the output layer that predicts the number of assets the customer is expected to drop. Therefore, our goal is to find the weights associated with each connection (in Figure 3, each line connecting two nodes) that will allow us to accurately predict asset loss.\n\nSo, how the heck are we supposed to learn all of those weights? Well, it\u2019s not easy, but a combination of calculus and decades of research in optimization theory provides us with the tools to succeed. Recall that the goal of our model is to accurately predict the number of assets that an account is going to drop. We can generate a prediction for each active Red Hat account by feeding the account\u2019s data (which correspond to the input features/nodes) into the model. Next, we can observe the actual behavior of each account and then calculate the model\u2019s error by subtracting the model\u2019s prediction from the observed number of dropped assets.\n\nObviously, our goal should be to find the weights that minimize the total error for all of the accounts (in practice, the value being minimized is typically the average of the squared errors). Unfortunately, because we can assign any number we want to any specific weight, there is an infinite number of possible weight combinations. However, each combination of weights has an associated total error, which creates an error \u201clandscape\u201d. Figure 4 shows the error landscape for a model with only two weights, \u03b8_0 and \u03b8_1, which can range in value from 0 to 1. Regions corresponding to high error are red and are at a high \u201celevation\u201d while regions corresponding to low error are blue and are at a low \u201celevation\u201d. Using this landscape analogy, our goal with the model is to end up in the lowest valley (which corresponds to the combination of weights that achieves the lowest error).\n\nWhile the entire error landscape is visible to us in Figure 4, in actuality, we don\u2019t have that luxury (machine learning would be really easy if that were the case!). Rather, finding the optimal model weights is more akin to being placed at a random starting point on a mountain in the middle of the night and then being told to find your way down. How would you do so? You can\u2019t rely on your eyes because it\u2019s too dark to see, so you would have to rely on your sense of touch. In that case, an obvious strategy might be to feel around on the mountain with your foot and then move in the direction with the steepest downwards slope.\n\nThis physical analogy is actually quite close to how model training via stochastic gradient descent actually works. Essentially, at any particular location on our error landscape, the model uses calculus to calculate the partial derivative of the error with respect to each of the weights. The partial derivatives tell us (approximately) how the error landscape slopes in the direction of each of the weights. The model then adjusts each of the weights by moving them a small amount \u201cdownhill\u201d. Next, the model recalculates the error and then repeats the process.\n\nAside: training a model with stochastic gradient descent is not unique to neural networks! Many machine learning algorithms use the exact same process during optimization.\n\nSo, what makes neural networks so special? Well, it\u2019s somewhat difficult to explain without using mathematical terminology, but neural networks learn complex relationships between variables. Essentially, deep learning models learn relationships between variables that are more than the sum of their parts. Neural networks are often described as \u201cfeature extractors\u201d for this reason; they are able to learn \u201cconcepts\u201d from the data.\n\nPerhaps one of the best visual demonstrations of this phenomenon was provided by the winners of the 2012 ImageNet competition. The ImageNet competition is an academic computer vision contest where teams design algorithms for classifying objects in images (Figure 5a). The winners of the 2012 contest used a deep convolutional neural network to achieve unprecedented accuracy on the task. But one of the most fascinating parts of the paper was the visualization of the features that the neural network learned. Figure 5b shows the features that were learned by the hidden units in the first hidden layer of the convolutional neural network. As you can see, the neural network was learning things like edges, patterns, and color gradients. You can imagine how later hidden layers might learn more \u201cabstract\u201d features, such as eyes, wheels, etc., by combining these simpler features, before eventually predicting the object, such as human, car, etc., based on the abstract features the model identified in the image.\n\nWhile we can\u2019t depict the features learned by our Customer Asset Loss model in the same visual way, the concept of learning \u201csimple\u201d features and combining them to learn more \u201cabstract\u201d concepts remains the same.\n\nToday, deep learning models are used extensively in a number of different areas. Current industry leaders in artificial intelligence research, such as Google, Facebook, and Microsoft, have all invested heavily in deep learning technologies because of their astounding accuracy on a wide variety of tasks.\n\nAt Red Hat, we need complex, powerful machine learning models (like deep learning) precisely because our customers are so complex. Because Red Hat\u2019s customers are more than the sum of their parts, linear models (i.e., models that don\u2019t incorporate nonlinear functions) are often less accurate than more complex machine learning methods. Our customers span industries and geographies, and they vary wildly in their size and revenue. Further, their technology demands and expectations are extremely specialized. For all these reasons and more, we need to use powerful machine learning methods to effectively harness all of our customers\u2019 information so that we can best anticipate their needs and provide them with proactive support.", 
        "title": "No Fear Neural Networks \u2013 Michael A. Alcorn \u2013"
    }, 
    {
        "url": "https://medium.com/bizcatalyst-360/big-data-artificial-intelligence-and-human-intelligence-d07ce1183771?source=tag_archive---------5----------------", 
        "text": "BIG DATA CONSTANTLY hits that wall. Despite all the investment in infrastructure and people, Big Data just can\u2019t generate further value. This is happening because we\u2019re treating Big Data and the stuff it contains like algorithms and artificial intelligence (AI) just like we treat traditional information technology. And brick by brick this treatment constructs the wall Big Data just can\u2019t crack. From a high level, here is the wall.\n\nBrick 1\u200a\u2014\u200aBusiness knows business but doesn\u2019t understand AI. It\u2019s common for business to just delegate work to the data scientists and then have the data scientists come back with the right AI solutions. The problem is that the business has no context for how to correctly interpret the data provided by the AI. This leads to misunderstandings, lost revenue, and higher costs.\n\nBrick 2\u200a\u2014\u200aData scientists know data but don\u2019t understand business, culture or psychology. For AI to work, the designers, the data scientists, need to understand the humans and events in the ecosystems the data is collected from. AI looks for patterns to automate our judgment and intuition and to anticipate future events and behaviors. The effectiveness of how AI does this is limited to the understanding of the data scientists.\n\nBrick 3\u200a\u2014\u200aAI outperforms us humans. Though AI can outperform us humans through repetitive brute-force steps that\u2019s all AI is good at. AI cannot think outside of the box. Rather it often gets stuck in thinking a certain way. If an AI can beat a human at Chess or Go, that same AI can be blindsided by another human\u2019s approach and playing style. Without human intervention AI cannot learn from its mistakes.\n\nBrick 4\u200a\u2014\u200aUs humans outperform AI. We humans with detailed subject matter expertise and the right tools often outperform AI. Humans can look at something and give a ball park figure. We can take a small sample of data points extrapolate a conclusion and say it looks right. But we do get tired and we do make mistakes. AI helps us double check our work and keep us on the ball. We humans must learn to balance what we\u2019re good at with what AI\u2019s good at.\n\nBrick 5\u200a\u2014\u200aAI makes big mistakes. AI is only as good as its design and the data it has access to. AI doesn\u2019t have the common sense we have to give data the benefit of the doubt or take suspicious data with a grain of salt. We humans will always be needed to interpret the data AI provides and then improve the AI\u2019s accuracy.[/message]\n\n[bctt tweet=\u201dTo achieve the full benefits of Big Data we need to achieve the full benefits of AI.\u201d username=\u201dbizmastersglobal\u201d]\n\nLike us humans, AI is only good at doing certain things. For Big Data to work we must always balance and re-balance our investments, capabilities and competencies of our human intelligence with our artificial intelligence.\n\n[su_button url=\u201dhttp://bizcatalyst360.com/free-execubriefs/\" target=\u201dblank\u201d style=\u201d3d\u201d background=\u201d#ff4e07\" color=\u201d#ffffff\u201d size=\u201d1\" wide=\u201dyes\u201d center=\u201dyes\u201d radius=\u201d5\" icon_color=\u201d#2d3fff\u201d]CLICK HERE FOR FRESH INSIGHTS DELIVERED TO YOUR INBOX [/su_button]", 
        "title": "Big Data, Artificial Intelligence, and Human Intelligence"
    }
]