[
    {
        "url": "https://medium.com/france/intelligence-artificielle-o%C3%B9-en-sommes-nous-d4ec1d6381f4?source=tag_archive---------0----------------", 
        "text": "Cette d\u00e9finition par le test, et non la caract\u00e9ristique intrins\u00e8que prouve bien notre incapacit\u00e9 actuelle \u00e0 d\u00e9finir pr\u00e9cis\u00e9ment ce qu\u2019est l\u2019Intelligence. La question de l\u2019 \u00ab\u00a0Intelligence Artificielle\u00a0\u00bb est plut\u00f4t celui de la \u00ab\u00a0Conscience Artificielle\u00a0\u00bb. Conscience dans le sens compr\u00e9hension de la complexit\u00e9 des t\u00e2ches, du contexte de r\u00e9solution des probl\u00e8mes auxquels elle est confront\u00e9e\u00a0: est-ce qu\u2019une machine est capable de savoir quel probl\u00e8me elle r\u00e9sout\u00a0? Est-elle capable d\u2019appliquer des strat\u00e9gies d\u00e9j\u00e0 apprises dans d\u2019autres contextes sur de nouvelles entr\u00e9es de donn\u00e9es\u00a0? En bref, est-elle consciente de son exp\u00e9rience\u00a0? On note qu\u2019on s\u2019approche de la d\u00e9finition du vivant\u00a0: un syst\u00e8me qui \u00e9volue, s\u2019adapte \u00e0 son environnement en continu.\n\nLa piste de la Macro-IA est plus fondamentale et non incr\u00e9mentale\u00a0: comment passer de 0 \u00e0 1 avec des technologies de rupture. On peut rapprocher cela \u00e0 la d\u00e9couverte de l\u2019\u00e9nergie atomique. Pour faire une grosse bombe, nous rajoutions des kg de poudre noir ou de TNT mais avec cette m\u00e9thode on n\u2019aurait jamais r\u00e9ussi \u00e0 s\u2019approcher de la magnitude d\u2019une bombe atomique.\n\nL\u2019application A verra et comprendra une image, que l\u2019application B transformera en texte, que l\u2019application C transformera en requ\u00eate pour de l\u2019information suppl\u00e9mentaire, que l\u2019application D transformera en appr\u00e9ciation d\u2019un contexte sp\u00e9cifique, que l\u2019application E transformera en nouveau code et en recherche\u2026\n\nOn peut imaginer qu\u2019\u00e0 l\u2019image de Watson, chacune des applications testent un tr\u00e8s grand nombre de chemins et choisissent les prochaines \u00e9tapes qui lui semblent le plus pertinentes selon la maximisation de certains crit\u00e8res.\n\nBien s\u00fbr, ce mod\u00e8le est aussi th\u00e9orique et de nombreuses personnes, pensent que nous ne pouvons comprendre le monde en tant que syst\u00e8me complexe que par un syst\u00e8me complexe. Et qu\u2019on ne peut pas cr\u00e9er un syst\u00e8me complexe \u00e0 partir de briques non-complexes sp\u00e9cialis\u00e9es, car chacune des briques sp\u00e9cialis\u00e9es devrait comprendre les capacit\u00e9s des autres briques pour pouvoir les solliciter. Dans ce contexte, il faudrait plut\u00f4t des briques g\u00e9n\u00e9riques qui interagissent entre elles de mani\u00e8re \u00e0 former un syst\u00e8me complexe auto-r\u00e9gul\u00e9.", 
        "title": "Intelligence Artificielle : o\u00f9 en sommes-nous ? \u2013 France \u2013"
    }, 
    {
        "url": "https://medium.com/@christian.bazant.hegemark/not-art-yet-algorithms-as-contemporary-assembly-lines-d0efa60ecacb?source=tag_archive---------1----------------", 
        "text": "In June 2015, Alexander Mordvintsev, Christopher Olah and Mike Tyka published a post on the Google Research blog about a visualization tool written to gain understanding in how artificial neural networks develop their data. Their specific focus was to improve knowledge on how interconnected layers of artificial neural networks communicate and enhance their individually developed information\u200a\u2014\u200awhat gets created when, and how this is then adapted while being passed from one layer to the next. They explain a self-feeding system whose feedback loop\u2019s initial layers tend to highlight and produce visual artefacts (e.g. by strengthening contours), and whose later, \u201chigher level\u201d layers use these previous computation\u2019s results to further manifest visual ciphers. They note that \u201c[b]y itself, [this system] doesn\u2019t work very well\u201d, but that by manually inserting a visual bias (a specific animal, a building, etc.), the algorithm is able to manifest these objects\u200a\u2014\u200aeven from the neutrality of random visual noise. To this end, all layers work serially to gravitate towards specific visual preferences\u200a\u2014\u200athey curate. Based on crowdsourced Big Data imagery, the algorithm thus visualizes how the virtual neural network imagines things to look like. The blog post uses the image of a dumbbell as example for a virtual neural network\u2019s semantic error: for the AI, it mistakenly seems to always include a lifting person\u2019s hands. Understanding the AI\u2019s projected semantics is crucial to its development, with misinterpreted data serving as proof of the algorithm\u2019s potency.\n\nUltimately though in its blog post, the team wonders \u201cwhether neural networks could become a tool for artists\u200a\u2014\u200aa new way to remix visual concepts\u200a\u2014\u200aor perhaps even shed a little light on the roots of the creative process in general\u201d. Might the currently described algorithm have more potential than your average Photoshop filter? Could it be used for artistic processes in a way that mattered aesthetically\u200a\u2014\u200aor even societally, as is expected from contemporary arts? Could the underlying algorithm constitute a self-learning, self-adaptive system similar to contemporary art practices, or even be related to the cultural, non-teleological drive of our species?\n\nI would like to elaborate on art as a contingent process closer related to developers researching their topic (here: neural networks), than to mechanically applying results (here: an algorithmic visualization method) of any previously contingent process. Although this case initially produces precanonized visual data, the highly volatile nature of canonization results in anything new quickly becoming established\u200a\u2014\u200aand hence losing its freshness. The attribution of \u201cnewness\u201d is therefore less relevant when found within an object, than when constituting a processes\u2019 target. Mechanically applying an algorithm stands far apart from a definition of art that cares about finding individual parameterizations for quality, since there no longer is the need to gain any personal understanding of the process\u2019s quality attributes. Calling an algorithm\u2019s output \u201cart\u201d turns out to be similar to calling a Fordist assembly line\u2019s output \u201cart\u201d: it is the consequence of treating art as a mechanistic, teleological dynamic.\n\nWhile working on my PhD thesis on the effects of digital culture on the expectations of contemporary painting, it became clear that a purely image-analytical approach would not facilitate a clear understanding of any visual medium\u2019s attribution. Instead, although by some understood as \u201cfool\u2019s errand\u201d, I realized for the thesis to require a clear cut definition of contemporary art as its foundation\u200a\u2014\u200awithout it, discussing media specifics seemed inappropriate: how could a specific medium be discussed without first knowing the system it operates within?\n\nI ultimately defined art as a process towards understanding individual quality attributions\u200a\u2014\u200aresulting in its native media independence, and highly volatile nature: artistic practices are, most of all, dynamics with only temporary validity. Media specific thinking in terms of e.g. painting, dancing, cooking is not required to discuss art ontologically, and doesn\u2019t necessarily help in understanding artistic processes. Instead, it can even block the view on what art can be.\n\nCraft on the other hand denotes the mechanical, latently repetitive application of a known process towards an preknown, teleological quality (a \u201cgoal\u201d). Just like art, craft is a volatile dynamic\u200a\u2014\u200achanging not only its object, but also the craftsman\u2019s individual mental and physical knowledge of it (something not necessarily the case with algorithms). Repeatedly doing something might feel to clone actions, but actually yields different results because of the operation\u2019s impact on object and subject.\n\nI understand art and craft as a M\u00f6bius strip\u2019s two sides: Every action within the artistic process (whether mental, physical, digital, algorithmical etc.) is in constant individual and societal flux between the poles of art and craft, with neither being able to exist without the other. Making a painting can fulfill art\u2019s criterion, as long as the painting process\u2019s qualities are unclear to its author. Cooking a soup can qualify as well, as long as its \u201cquality\u201d hasn\u2019t individually been clearly understood. If instead it is known (which is usually the case once a \u201crecipe\u201d has been formulated), the process qualifies as craft.\n\nBoth terms\u2019 modernist narratives therefore need to be transcended: there is no generally attestable beauty in art\u2019s objects or processes, and there is no hierarchy between art and craft. Calling something \u201cart\u201d or \u201ccraft\u201d does not elevate or diminish it.\n\nCanonization dynamics are highly relevant in understanding the connection between art and craft: what is initially new and fresh (precanonized), quickly becomes canonized on individual and/or societal levels (not necessarily influencing each other). Once individually canonized, mechanical repetition can be established to have an artistic process become (individual) craft; this establishing process itself usually can be understood as art: mechanizing/streamlining an open process requires an understanding that usually doesn\u2019t match the initial artistic process.\n\nThe Google Research blog post includes algorithmically produced imagery which at first seems visually fresh and pre-canonized. Skimming through more than just a few of these \u201cdeep dream\u201d images (e.g. at http://psychic-vr-lab.com/deepdream/) helps to understand their algorithmic base: strong brilliance and contrasts, strengthened contours, and a preference for curves. Like a Photoshop filter, the neural network\u2019s visualization operates on adapted output from some initial image input. What makes the neural network\u2019s algorithm stand out is its capacity for a curatorial preference, used to implement an allegedly individual goal\u200a\u2014\u200ato have it operate autonomously. This must not be mistaken with agency though\u200a\u2014\u200ait\u2019s still the human user who choses the visual bias, not the algorithm itself.\n\nLet\u2019s compare this consistent, algorithmically produced and guaranteed likeness, to the serial consistency offered by Fordist production lines. Do they constitute art? Isn\u2019t it rather the process (potentially resulting in the definition of said assembly line) that can qualify as such\u200a\u2014\u200abecause it is there that newness (precanonization) is aimed for? Shouldn\u2019t these autonomous agencies be treated as art\u2019s defining factors? How do algorithms satisfy these parameters?\n\nRemoving humans from production processes will always result in minimized contingency, therefore purifying any algorithmic process and output. But isn\u2019t art (and culture) exactly about contingency? Can\u2019t craft be translated to algorithmic form especially because of its lack of contingency\u200a\u2014\u200aand isn\u2019t that the reason why art doesn\u2019t yet exist in algorithmic form?\n\nArt and craft form a circular topology in which they continuously mutate into each other\u200a\u2014\u200aneither can exist without the other, and both happen only because of the other. The question of \u201cwhich came first\u201d constitutes another chicken/egg causality dilemma.\n\nWhere Fordist mass production\u2019s core is the production line, post-Fordism extends it to embrace a later generation\u2019s individualization and fragmentation\u200a\u2014\u200ain a way, Fordism establishes and parallelizes craft processes, into which post-Fordism tries to insert \u201cart\u201d as an illusion of contingency (industrially produced deckle edges on books are an easy example for this).\n\nToday\u2019s Big Data algorithms then natively blend Fordist and post-Fordist strategies to implement even more streamlined production environments; by using masses of anonymized user data, Big Data appears to be smart without requiring a human workforce: artificial intelligence. By offering an unexpected update on nonnegotioable bartering agreements (free services instead of monetary payment, in return for unlimited usage of user data), Big Data\u2019s AI is based on unlimited harvesting of individual data. This leads to the production of objects without physicality, creating an environment that\u2019s virtual except for its economic worth. All of this seems to only be possible because of the societal change in economic expectations: we don\u2019t need physicals as much as even just ten years ago\u200a\u2014\u200alives have become far more virtual than expected (in 2015, Amazon.com\u2019s biggest profit gain didn\u2019t happen because of their sale of physical objects, but through AWS, their virtual cloud computing service). So many physical domains have been replaced by virtual ones, that Star Trek\u2019s holodeck can easily be understood as the (virtual) invention of a pre-virtual mind: communication, education, leisure activities; movies, books, music, letters, money; transportation, physical storage spaces, etc.\n\nIn this global economy, humans are no longer the limiting factor: plattform efficiency can be improved through parallelization and virtualization of processes (hence AWS\u2019 success), transcending health or social security payments\u200a\u2014\u200aand many other constraints of physical existences. Algorithms are a new workforce that only requires humans for being established\u200a\u2014\u200abut not for being operated. The algorithmic creation of algorithms would diminish this requirement for human\u2019s agency even further\u200a\u2014\u200aand it would be only then that we\u2019d have to discuss art as algorithmic process.\n\nIn a way, the autonomous agency that makes humans such excellent problem solvers is what still keeps us far apart from machines. It\u2019s also what drives culture, and why art matters: for as a species, we survive because we expand our cultural normatives.\n\nSince they are not teleological, artistic processes are always pre- or post-Fordist\u200a\u2014\u200athey can\u2019t easily be assembly lined, whether their medium is painting, or the team effort of creating a video game. Only craft can be Fordist (e.g. the repetitious operation of creating video game assets), and therefore be represented in algorithmic form: algorithms constitute craft\u200a\u2014\u200ait\u2019s only their creation that can qualify as art. Algorithms can be understood as artistic processes once they are able to exist according to their own agency.\n\nPostmodernist individualism severly disrupts the Fordist production line: in addition to individualized (physical) mass products (individually engraved iPods, custom covers for smartphones, etc.), contemporary digital mass products tend to contain virtual elements to implement their individualization natively\u200a\u2014\u200asomething an earlier era of desktop computing didn\u2019t have to account for. Search engines, cloud based services (archives or document editing, mail services, etc.) are all natively virtual platforms, replacing a previous generation\u2019s need for their physical predecessors.\n\nBecause it works along a predefined process, it\u2019s possible to clearly locate Google\u2019s deep dream algorithm as craft\u200a\u2014\u200aany deterministic algorithm with predefined goals can only count as such: It\u2019s only self-developing, self-modifying algorithms that could implement artistic processes\u200a\u2014\u200aand with their individualized agenda, their own agency, they most probably would. Their media will be as varied as their results: for that is the single attribute uniting art through the millennia: the strive for the unknown, for the precanonized. For what is culturally essential for later generations, but doesn\u2019t yet exist: fire, the wheel, telegraph and phone, the touch paradigm etc. Once machines are able to adapt themselves individually in a currently unknown mode of agency, we will be able to discuss the difference between humans and machines for real. For now, agency in algorithms is mostly faked by processing global data sets.\n\nUltimately, algorithms will gradually replace all mechanical, repetitive labor (sorting, assessing, driving etc.):\n\nAlgorithms continuously dig deeper into traditionally analog domains, as these slowly get digitalized (Google Books Library Project for digitalizing preexisting objects; the Internet of Things for digitalizing nonexisting attributes traditionally analog). For now though, art can well be defined as whatever can\u2019t be produced algorithmically.\n\nAn algorithm designing and implementing a process similar to an artist entering an empty studio\u200a\u2014\u200acreating meaning from nothing, rephrasing and permuting semantics, highlighting individual preferences. Autonomous algorithms with an individual agenda.\n\nArt not only as culture, but as humanity\u2019s defining driving force. Once code is be able create art, we will have to rethink what it means to be human.\n\nAbout the author: After working for Rockstar Vienna as a programmer for six years, Christian Bazant-Hegemark studied Fine Arts at the Academy of Fine Arts (Vienna/Austria), and is currently awaiting the viva voce examination for his PhD thesis on the influence of digital culture on contemporary painting (Elisabeth von Samsonow, Felicitas Thun-Hohenstein). He lives and works in Vienna/Austria. You can check out his work at www.bazant-hegemark.com, and follow his research on contemporary painting at this blog, www.beyondmimesis.tumblr.com.", 
        "title": "Not Art Yet: Algorithms as Contemporary Assembly Lines"
    }
]