[
    {
        "url": "https://medium.com/@ilblackdragon/tensorflow-tutorial-part-3-c5fc0662bc08?source=tag_archive---------0----------------", 
        "text": "In the previous Part 1 and Part 2 of this tutorial, I introduced a bit of TensorFlow and Scikit Flow and showed how to build various models on Titanic dataset.\n\nIn this part, let\u2019s make a more complex model, something that can handle categorical variables.\n\nUsually in machine learning, handling of categorical variables requires creating a one-hot vector for each category. In deep learning, there is an alternative solution for that\u200a\u2014\u200adistributed representations or embeddings.\n\nUsing embeddings, you can represent each category as a vector of floats of the desired size, which can be used as features for the rest of the model. Note, that because of the fully differentiable nature of the TensorFlow components (and other Deep Learning frameworks), this allows to \u201ctrain\u201d the most optimal representation for your task. This has shown been the most powerful tool in the Deep Learning toolkit as it removes need to do manual feature engineering.\n\nThis brings most value when you have a lot of categories or discrete sparse values\u200a\u2014\u200ae.g. hundred and thousands. Then you get compression of the input from N categories to fixed size embedding.\n\nWhen you have a small number of categories it still works by using the embedding space to model one-hot vectors per category (e.g. by spreading categories around without any semantic).\n\nLet\u2019s continue with our Titanic dataset and try a simple example of using just Embarked field as categorical variable for prediction:\n\nFirst, we select only \u201cEmbarked\u201d column, for as our features. We then follow regular 20% train/test split.\n\nIt\u2019s always useful to analyze what kinds of values features have:\n\nThis is passed to CategoricalProcessor\u200a\u2014\u200aa helper class that maps categorical variables to ids. In this case it will create a vocabulary of S->1, C->2, Q->3 and unknonw/nan -> 0 and remap this column to integers.\n\nThe final model is simple, it leverages another helper function skflow.ops.categorical_variable which creates an embedding matrix of size n_classes by embedding_size and looks up ids from input in it. This is a similar to skflow.ops.one_hot_matrix but instead returning a learnable distributed representations for given categories.\n\nFinally train model and predict on a test dataset and voila, we got a model using distributed representations for categorical variables.\n\nAfter using embeddings, there is a simple model to compare with one-hot vector representation. It will map from class 1, 2, 3 into a vector with one at the position of the class and zero everywhere else. E.g. class C (2) will be mapped into [0, 0, 1, 0] vector.\n\nIn this case, given only one feature with 3 classes for prediction, results end up been exactly the same as using embeddings.\n\nYou can learn how to combine categorical and continues values in Part 4.\n\nAdditionally, as I mentioned above, the most value in using distributed representation coming from categorical features with large number of classes. In the Part 5 you can use this method of representing categorical variables for Natural Language Understanding tasks, like Document classification.", 
        "title": "TensorFlow Tutorial \u2014 Part 3 \u2013 Illia Polosukhin \u2013"
    }, 
    {
        "url": "https://medium.com/machine-intelligence-report/personal-views-on-the-future-of-artificial-intelligence-509c5db276fc?source=tag_archive---------1----------------", 
        "text": "On January 11th, I attended the first and public day of the NYU Symposium on the Future of AI, hosted by our colleagues and neighbors at NYU. Here are a few notes and thoughts about the event.\n\nI could not find any website describing the event. Here is a scan of the program of the first day.\n\nKeep in mind that I am not an AI person. My PhD is in databases. Take everything I say with a grain a salt. Also, the field is moving very fast: since January 11th, the Google Deep Mind team beat the EU Go champion using its AlphaGo software.\n\nKey industry players were present at the conference, including Google, Facebook and Microsoft. The overall message from industry can be summarized as:\n\nIndustry repeatedly acknowledged the fact that the next good idea is more likely to come from academia. This might be true in theory. In practice, the most successful AI techniques require an enormous amount of data, data that academia usually does not have access to.\n\nAt the technical level, the research directions mentioned were around (a) integration with reasoning, attention, planning, memory; (b) combination of supervised, unsupervised and reinforcement learning; and (c) effective unsupervised learning.\n\nAt the meta-level, challenges included (1) provably safe AIs (Microsoft), (2) AIs that can interact with humans \u2013 aka AIs like us \u2013 and also (3) better platforms that can bring AI to the many (Google).\n\nIf like me, you have not been following the field very carefully, see Richard Mallah's overview of 2015 top AI achievements [5].\n\nSelf-driving cars have been a boon for the AI community. Pun intended, this is really the killer (or rather un-killer) app and it keeps pushing the envelope for the entire field. First, driving is a great test case for AI challenges such as perception, learning and planning. Second, the auto industry produces cars en masse with a good track record of quality and reliability. Third, transportation is a very big industry with a clear impact on humans and their environment. When you combine these three elements, you get a great recipe for real innovation, i.e. the \u00ab\u00a0successful creation and delivery of a new or improved product or service in the marketplace\u00a0\u00bb as defined in [1].\n\nHaving realized that, the interesting question you should ask yourself \u2013 if you are not doing AI \u2013 is:\n\nAdvances in hardware like GPU had a strong impact on AI algorithms especially for deep learning, making them orders of magnitude faster (60x according to NVIDA). The R&D for these GPUs was mostly funded by the video game industry. It is ironic to see AI being applied to learning how to play video games, as demonstrated by Deep Mind [2,3] for Atari games. AI is also starting to disrupt other games like poker [4].\n\nThe Deep Mind team motivated their research interest for games by the fact this is a domain where you can easily gets lots of data.\n\nAdvances in neuroscience also had a strong impact on AI algorithms. Neural networks take their inspiration from the way our brain works. An interesting application of AI mentioned during the conference was \u00ab\u00a0AI assisted science\u00a0\u00bb where AI can be used to help and guide scientists doing their work. Think medicine, physics, astronomy, etc.\n\nSo, it seems that we have two AI virtuous cycles:\n\nWith AI playing an increasingly important role in our lives\u200a\u2014\u200adriving our cars, scheduling our lives, etc.\u200a\u2014\u200a, making it do the right thing becomes critical. Science fiction is a good inspiration for horror stories or predictions in this space, e.g. SkyNet, Iron Man\u2019s Jarvis, Spike Jonze\u2019s Her, or Asimov\u2019s Three Laws of Robotics.\n\nEric Horvitz from Microsoft Research mentioned some ethical and safety related requirements, like being able to\n\nNote that for self-driving cars, fallback cases (aka disengagements) must be reported to the US Department of Transportation.\n\nAssuming the AI system does faithfully what it is supposed to do, it is not always clear what this \u201cit\u201d should be. My guess is that something like the trolley problem in the context of self-driving cars will keep AI experts, entrepreneurs, ethicists, lawyers and policy makers agitated for some time.\n\nThank you to NYU for organizing this great event, with key players from the field, both from industry and academia.\n\nI am not familiar enough with the field of AI but it felt to me more like \u201cThe Future of Deep Learning\u201d than \u201cThe Future of AI\u201d. Also, the choice of speakers and panelists did not scream \u201cdiversity\u201d to me, with only one woman present. I am sure we want the future of AI to be more diverse.\n\nMy 3 personal take aways from the day are:\n\nTo best summarize my current and personal point of view about the future of AI, I will borrow a quote from @KJ_Hammond at Next:Economy conference:\n\nAnd nobody wants to be any AI's bully.\n\nSpecial thanks to Nikolai, Gideon, David and Hanna for comments on early versions of this post.\n\n[1] Innovation: The Five Disciplines for Creating What Customers Want, Curtis R. Carlson and William W. Wilmot, 2006.\n\n[4] Poker-CNN: A Pattern Learning Strategy for Making Draws and Bets in Poker Games, Yakovenko et al., 2015.", 
        "title": "Personal Views on the Future of Artificial Intelligence"
    }, 
    {
        "url": "https://medium.com/@KCBOMBARD/well-aware-a-culture-of-positive-mental-health-66e656ef481a?source=tag_archive---------2----------------", 
        "text": "What does it mean to have positive mental health? Do you have to be happy all of the time? Is it about how you deal with with disappointment, difficulty and change? These are some of the things that have been rattling around in my brain since starting to read Well Aware by Patrick Carney. How can we as educators support an environment in our classrooms that promote a culture of positive mental health?\n\nI have to admit that when we were given this opportunity to focus on a different type of learning in our monthly meetings, I initially thought the Modern Learning or Math would be the route to choose. I had passion and interest in these areas and felt that they would support my work in a much more direct manner. I thought to myself that it would be much easier for me to work with a group who had this as their focus. Then I remembered something from one of the articles or books by Jo Boaler on brain growth that I had read, and how truly deep learning occurred when there was a level of discomfort that allowed for new pathways to be created. I had this feeling of discomfort towards our focus on mental health and thought to myself \u201cokay, put your money where your mouth is and be uncomfortable\u201d. On a surface level I had an understanding of the importance of positive mental health and breaking down barriers around stigma, but still shied away from looking at this topic in a way that would allow for deeper learning. It has taken some personal experiences and reflections this past month around my bias towards mental illness to help me to realize why this might be.\n\nI have never blogged, partially because it is a risk, putting your own thoughts, feelings and reflections out there into the ether to be read, judged and commented upon (and perhaps even challenged) and partially because, I thought to myself\u200a\u2014\u200athere are people out there who are much more intelligent and engaging writers\u200a\u2014\u200awhy would anyone read what I wrote? But again, trying something, taking that risk is what we ask our students to do everyday as well as the teachers we support in our roles, so why should I be any different?\n\nIf I am being perfectly honest with myself\u200a\u2014\u200aI have carried some personal bias around the idea of mental illness for some time. I have a family relative with whom I have had a strained relationship with for the last 10+ years. In part this is because I have struggled to find empathy and understanding to their struggles with mental health. I would often think to myself \u201cI don\u2019t understand why they can\u2019t seem to get their act together\u200a\u2014\u200aI have a much busier life, have had just as many \u201cbad\u201d things happen to me and I still can manage? Why can\u2019t they?\u201d. Over the last month, the two of us have had to work closely together to deal with some very emotional and stressful issues. They still struggle with mental illness (extreme paranoia, manic depression) but since I have started to focus on being aware of my bias and acknowledge that they are doing the very best they are able to do, we have been able to work cooperatively together to accomplish what has needed to be done. In fact, we had a talk and we shared how we had missed each other in our respective lives. Things are not 100%, and I can sometimes still get frustrated, but now I look and see that this is my issue and not theirs.\n\nAlthough in upcoming posts, I will be spending more time reflecting on the learning occurring within my group and from my reading of Carney\u2019s \u201cWell Aware\u201d, I thought this first post should give the background and my entry point into my learning. Thanks for reading my ramblings\u2026", 
        "title": "Well Aware \u2014 A Culture of Positive Mental Health \u2013 KBombard \u2013"
    }
]