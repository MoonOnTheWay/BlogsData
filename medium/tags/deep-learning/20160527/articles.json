[
    {
        "url": "https://medium.com/@johnsmart/your-personal-sim-pt-4-deep-agents-understanding-natural-intelligence-7040ae074b71?source=tag_archive---------0----------------", 
        "text": "", 
        "title": "Your Personal AI (PAI): Pt 4 \u2014 Deep Agents (Deep Learning and Natural Intelligence)"
    }, 
    {
        "url": "https://becominghuman.ai/apples-ai-secret-how-the-43-muscles-in-your-face-will-play-a-big-part-of-apple-s-new-ai-and-siri2-de8d4f54894?source=tag_archive---------1----------------", 
        "text": "Computers Don\u2019t Know When You Are Happy\u2014Apple Is Adding a Previously Unseen Dimension To Your Device\n\nFrom the moment you are born, assuming normal eyesight, we open our eyes and fixate on the 43 muscles that control 1000s of nuances of facial expressions and emotion intent in the face of our parents. They inform a reaction to how to interpret the world, an extended sensor to help learn the basic emotions and reactions to the world around us.\n\n\u201cEmotient is the leading authority on facial expression recognition and analysis technologies that are enabling a future of emotion aware computing.\u201d\n\nIn the Spring of 2013 a team of scientists and researchers at the Machine Perception Lab at University of California, San Diego, was forming the technology and the basic elements of what was to become Emotient. The founding team were widely regarded as spearheading the use of machine learning for facial expression analysis with over 20 years of experience pioneering machine learning and computer vision technology for facial behavior analysis. The team has published hundreds of peer reviewed scientific publications, starting in 1995, which have been cited by thousands of other researchers in the field.\n\nBuilding around the work of Paul Ekman, Ph.D.[1] a pioneer in the study of emotions and facial expressions, and a professor emeritus of psychology in the Department of Psychiatry at the University of California Medical School (UCSF) where he has been active for 32 years, Emotient used AI to machine learn his ground breaking research in micro-emotions. This system is called FACET (Facial Action Coding System) [2] and Emotient applied machine learning methods to high-volume datasets that were carefully constructed by a team of behavioral scientists, including Dr. Ekman, who later joined Emotient\u2019s Advisory board with Dr. Terry Sejnowski, Ph.D.\n\nI have been a student of Dr. Ekman\u2019s work for many years and also a researcher in elements of AI including emotional intent extraction systems. I took immediate note when Emotient first began to demonstrate it\u2019s technology as well as the patents the company filed. It was ground breaking. I had since tested their systems up to the moment Apple acquired the company on January 7th, 2016.\n\n\u201cEmotient\u2019s proprietary algorithms make it possible to discern the most subtle expression or changes in expression and translate that into a defined emotional reaction. With a camera-enabled device or external webcam, our system can quickly process facial detection and automated expression analysis in real-time, or, for non time-sensitive requirements, it can scan images and videos in batch mode to deliver in-depth analysis of single-subject and multiple-subject videos. FACET leverages machine learning in large datasets in order to achieve optimal speed and utility.\u201d \u2014January, 2014\n\n\u201cThe new patent (US 9,105,119 B2), titled \u2018Anonymization of Facial Expressions,\u2019 inserts unequaled privacy protections into Emotient\u2019s expression analytics system via a proprietary method for anonymizing facial images before they have been processed for emotions and reactions. One of the patent\u2019s authors, Dr. Javier Movellan, a co-founder of Emotient, likened his company\u2019s technology to voting: \u201cWe do not want to recognize who is watching. All we care about is what they are watching and how they feel about it. Our goal is to provide avenues for people to express their feelings about content in an anonymous, effortless, and scalable manner, because there is enormous value to how people respond to what they\u2019re watching.\u201d\n\nEmotient\u2019s patented advanced technology was being used in many commercial situations to gauge consumer reactions on to government use cases to understand emotional intent in large groups. The technolgy centered around the FACET SDK and related APIs.\n\nEmotient initially focused on a commercial retail market for the primary use case for the technology. They met with success with a number of clients from consumer sentiment research to real time customer emotion feedback at large national retailers:\n\nApple\u2019s acquisition of Emotient included the technology, patents and principle research talent including Marian Bartlett, Ken Denman, Javier R. Movellan. There is no doubt that this team will be working on a wide number of uses for Emotient\u2019s technology at Apple one aspect will be Apple\u2019s Voice First devices and enhancements to Siri (I call this Siri2).\n\nI have studied and pointed out the important aspects of emtional facial reading for quite sometime [3]. In a recent posting about Voice First systems, I said:\n\nThere is very little doubt that Apple will use the amazing technology of Emotient on a spectrum of use cases including with photos and video analysis. However the power of truly understanding volition and intent is greatly aided by the decoding of microexpressions and the dynamic movement of the 43 muscles that form the emotions of our face. This will bring Apple\u2019s AI technology to Voice First devices that will afford far more exact intent extraction, to not only what we say, but to understand truly what we mean.\n\nWith the technology from the Siri team finally fully deployed and the self learning technology from VocalIQ [4] Apple will produce a Voice First device and there is little doubt that some day, perhaps very soon, it will also be greatly assisted by the technology of Emotient.\n\nThese new self learning systems will not be programed in any traditional sense, they will be taught, in the same manner you and I have learned. And this all started for all of us days after we were born, by gazing into the faces of our parents to understand the world around us.", 
        "title": "Apple\u2019s New AI will decode the 43 muscles in your face and help Siri2 understand you better."
    }
]