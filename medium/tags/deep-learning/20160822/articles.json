[
    {
        "url": "https://synecdoche.liber118.com/hylburt-speys-cd574abfa611?source=tag_archive---------0----------------", 
        "text": "The clients waved me over, near the tap. Three founders, whom we\u2019ll call \u201cAlasdair\u201d, \u201cFuentes\u201d, and \u201cChen\u201d. We ordered that pint or two at the tap and found an open table. Above the pub chatter we began exchanging minutiae about our favorite UK brews. Alasdair did much of the talking initially.\n\n\u201cCertainly you\u2019ve heard of our upcoming Brexit II vote?\u201d Alasdair asked. \u201cBelters, what a done deal. We\u2019ve given it 4:1 odds of passing.\u201d\n\nI cupped my ear, trying to hear him. Nodding enthusiastically, while struggling to translate what Alasdair seemed to consider conversational English. Did my best to look amazed, feeling thoroughly confused by both UK\u2019s dialects and politics. In retrospect what he said was startling, contra to almost all prevailing analysis.\n\nThe pub had a Lumo projecting interactive graphics. A pair of nishiki koi swam across our table in video, then down across the floor. One could grab a ghostly brocaded fish to signal the bar keeper for a food menu.\n\nVirtual fish bubbles and more banter spilled into our beers: Trump and shootings in the US, Fuentes\u2019 kiteboarding trip to Saipan, deep learning used to augment VR drone racing (Matt!) upcoming at the next Burning Man. Current debates between Java becoming the new COBOL versus embracing the twenty first century with Scala. Usual stuff.\n\nAbysmal. Yet more crazy-making, which was rapidly becoming par for the course. Sadly. Nasty targeted advertising, nasty retro start-up with nasty dinosaur tech leads, and an uber-nasty general manager who seriously needed to be on meds. We\u2019d agreed on scheduled deliveries in our contract, for which SkyBraynz was way ahead. Now she was not only breaking contract but escalating, trash-talking about us to other customers\u200a\u2014\u200awas that even legal?\n\nI drew a deep breath and closed my eyes, hoping it looked like a longish blink. Trying not to get upset in front of these three. Make it seem like jet lag or fatigue. Or something. I recalled my mantra of harmless names to call people who made me angry, selecting a good one: inconvenient fire drill. One of my favorites. Picture the words, silently, taking a deep breath. Repeat three times.\n\nNo way that James had said \u201cvacation\u201d to the monster, just no way. He knew about the problem. Not much I could do tonight without stirring up even more trouble. That was the monster\u2019s pattern: construct situations where any reasonable response would get spun all black-and-white, in favor of the emotional reasoning employed. Crap, crap!! Time for another mantra: itchy sweater, or decaf white choco vegan mocha? Both. Pictured, breathed, repeated.\n\nMy long blink gave way to a grimace, fading to a dull stare. I watched non-existent koi shimmy between our pints\u200a\u2014\u200auntil Alasdair\u2019s brogue began to chip its way back through.\n\nConversation at our table had shifted toward a particular streaming use case. They\u2019d mentioned corporate activism as their domain area without going into detail. Tossed out numbers as a target SLA.\n\n\u201cYour company holds the world speed record for training neural networks at scale?\u201d Alasdair nudged me. \u201cPure gallus, by the way.\u201d\n\n\u201cOr London.\u201d Alasdair traced the path of a virtual fish with his finger. \u201cSay you wire up that SkyBraynz with the framework we use to indict the most boggin, houghin bummers? For fun and profit o\u2019 coorse. Largest virtual assassin in this world, pointed at the usual mingin. There\u2019s an infinite supply but.\u201d\n\nAwkward, per my attempted translation: Alasdair rollin\u2019 white n\u2019 nerdy. Chen didn\u2019t move much, though now she turned to glare at Alasdair. Fuentes winced and set down his Buxton Rain Shadow. He held out a shiny, stainless steel tally counter, staring directly into Alasdair\u2019s eyes and pressing CLICK!\n\nI pushed for more details, trying to gauge the three.\n\nAlasdair shook his head between slugs. He described their origins as a company, Hylburt-Speys. Spin-off from a highly successful law firm in the US. Plaintiff trial lawyers, he explained, who\u2019d earned the moniker \u201cCorporation Killers\u201d for ample reasons.\n\nA gaggle of suits were playing a different Lumo game in the back. Someone kicked a projected garden gnome image\u200a\u2014\u200afrom the floor, halfway up the wall, sliding over a dartboard\u200a\u2014\u200ajust as an opponent tossed a dart and pinned said gnome to the bullseye. Bells and whistles erupted, with a few suits gloating loudly. I paused for noise to die back before trying to talk.\n\nAlasdair didn\u2019t answer. Instead, he threw me tech questions. Each more specific than the last: fault-tolerant idempotent updates, how to manage systemic back-pressure with reliable receivers across a wide range of sources upstream, decentralized online learning algorithms based on GPUs. A flurry of approaches for compression and overall speed-up. What was my take on latest best practices, off the shelf or purpose-built, for each category?\n\nAnother commotion in back peeled away my attention. Lumo games made that entire rear wall\u200a\u2014\u200aminus the dartboards\u200a\u2014\u200aappear like one big mirror. I kept nodding in cadence along with Alasdair\u2019s tech mansplaining, while studying the wall. Probably an array of LCD screens? The \u201creflection\u201d showed current players in the dart/gnome game transformed to have AR animal heads. Slogans ran\u00a0: \u201can entirely new kind of toy\u201d or \u201cstick your head in a beaver\u201d\u200a\u2014\u200aas tickers scrolled across an inactive corner.\n\nSkyBraynz could enhance that interaction so much. Would be fun to use DL to learn player moves, preempting them with cartoony beasts. Couldn\u2019t be a huge range of type body movements? Given some player log data, a neural network could start learning to anticipate people. Most people, probably. Must make a note to reach out to the Lumo founder.\n\nAlasdair hesitated, exchanging glances with his two partners first. \u201cEssentially a set of complementary businesses in a fankle, feedin\u2019 jujubes tae the parent law firm. A streaming app coordinates blether amongst said. All loosely coupled and specifically not in the US: hedge fund based in Asia, a German PR firm, competitive intelligence services out of Latin America.\u201d\n\n\u201cA globalized supply-chain, if you will.\u201d Alasdair grinned. The other two nodded in agreement. \u201cO\u2019 coorse they\u2019re most certainly legal in their own jurisdictions. The possibility of said houghmagandy owing to deregulation, globalization, trade agreements, the Internet, etc. Full Bhoona. Overall strategy flanges snuggly into TPP, TTIP, and so forth.\u201d\n\nOutside the gatehouse, a pair of mimes had caused a stir. They flew a drone constellation in a funnel-shaped formation\u200a\u2014\u200anot particularly unusual, except that their tiny drones were built from toy sharks. Sharknado, here live on the garden path of Euston. More performance art, welcome relief against a backdrop of bombings and violence.\n\nAlasdair paused to watch the street theatre, sipping his brew. Fuentes nudged him on. CLICK! again on the tally counter.\n\nAs the story unfolded, a streaming app used blockchain to create a distributed ledger\u200a\u2014\u200awhat Alasdair had mentioned about integrating the companies. Only the parent firm had complete details for any particular operation. Real-time analytics plus a healthy dose of deep learning applications throughout. Alasdair seemed especially chuffed about the DL, chugging his Kentish Pip when he\u2019d finished.\n\nFuentes tore in. Double CLICK on the counter. He seemed more of a business guy, less tech geek. A jock, more or less. He rattled off numbers about debt versus revenue, margins, EBITDA averages across sectors. Huge fan of Carl Icahn, shareholder activism, old school corporate raiders back in the 80s, etc. OTOH, their team had tracked developments in agile software methodology, distributed systems, micro-payments, blockchain, probabilistic programming, AI, etc. \u201cWe had a hunch there\u2019d be considerable long-term benefits by applying more advanced technologies, less heavyweight approaches. Think: Goldman Sachs meets Glassdoor.\u201d\n\nNearly blew a sip of Schiehallion out my nose. AI, blockchain, and Goldman Sachs in the same breath. Begeezus!\n\nDefinitely. Less potential complications for everyone involved. They\u2019d kept a minuscule footprint in media, having almost no public presence on the Internet. \u201cEven so, we would like to see some independent analysis circulate, especially for our data analytics approach.\u201d\n\nFuentes was pitching. Possibly for hiring purposes, one might imagine. Most of this kind of work was way too obscure for tech recruiters to field. I could craft an article about DL that put their work in a good light. Probably enough to attract some reasonably good candidates.\n\nThey agreed, one minor scowl by Fuentes notwithstanding. Holding out his tally counter. Another CLICK, slowly. It\u2019d be okay, pending his approval of my final draft.\n\nBottom line according to Fuentes: \u201cMany, many American companies are exposed, albeit in small, highly distributed ways. With machines we can use data mining to isolate those weakness points.\u201d Weaving together non-intuitive strategies that resulted, statistically, in large payouts. Yada yada. Some new twists, but with a summary punchline that almost everyone else used. Change the world.\n\n\u201cYou\u2019re a right numpty!\u201d Alasdair raised his glass to toast that tagline. I\u2019d guessed somewhat correctly how they must be big fans of the notion of exponential organizations. Though it wasn\u2019t clear whether they wanted to become an exponential org, or just enjoyed feeding on them.\n\nBloody hell, as I guess Brits would say. Early afternoon on the Eastern Seaboard, typical timing for the monster\u2019s melt-downs. Also time for a mantra: unnecessary movie sequel. Breathed, repeated, forwards and back. Should I contact James for advice? Would that somehow seem weak or indecisive to an investor? Didn\u2019t matter, the conversation at hand was much more important and finally digging into details.\n\nFuentes had been explaining a geopolitical backdrop that permitted Hylburt-Speys to exist. \u201cFinancialization following the 2008 global crash drove many large companies to stockpile cash. Most of it distributed throughout tax havens internationally. Some companies had even gone into debt rather than tap their cash reserves directly, which could trigger taxable events. Federal monetary policies meanwhile made the constellation of cash hoarding, complex debt strategies, and stock buybacks progressively more attractive.\u201d\n\n\u201cEven some tech start-ups in Silicon Valley followed this pattern,\u201d Alasdair added. \u201cThat made firms vulnerable. Though the cash mostly got used for share buybacks and dividends\u200a\u2014\u200aappeasing the activist shareholders.\u201d\n\nI got the point, in spite of the swirl of brews and jet lag. Mounting debt made firms doubly vulnerable to raiders, at least the kind who could leverage machine intelligence.\n\nFuentes continued, not amused. Ignoring my remark. \u201cThe parent firm invested significant efforts into root cause analysis across their history of trial outcomes. They paid other law firms for access to trial data, similarly mining for root causes.\u201d He made three loud CLICKs on his tally counter.\n\nThey\u2019d built machine learning models to characterize outcomes, segmenting opportunities for litigation. That project evolved into an AI system wired into financial data services, news feeds, social media, etc. Purpose-built to identify and assess potential defendants.\n\n\u201cPartners in the law firm didn\u2019t want to wait for clients to approach them with cases. They sought to identify high ROI opportunities in advance. Then cherry-pick the best, targeting proactively.\u201d Ergo their \u201cCorporate Killer\u201d nickname.\n\nAnother missive arrived in text. An image sent from the monster that took a few moments to render. A comic with a character jumping, arms up, yelling \u201cWooHoo!\u201d, accompanied by:\n\nMust. Ignore. Crazy-making. The baiting. Felt like how I\u2019d imagined the aftermath of a subway bombing. I resolved to not panic and carry on, recalling Brits pouring briskly into the open courtyard at Euston, past the turnstile construction and police barricade. Rubbed my eyes, then let a long sigh escape.\n\nAlasdair started, but Fuentes interrupted with yet another CLICK. \u201cSeveral reasons,\u201d he said, staring down Alasdair. \u201cMostly concerning how to push risk to the edges of our supply chain. The parent doesn\u2019t own controlling interest in any one component business\u200a\u2014\u200ajust enough for significant influence.\u201d Yeah, the notion of ownership works differently in other countries. As I\u2019ve been learning recently.\n\n\u201cAlso, regulatory environments within the US weren\u2019t stable enough. For example, in a hedge fund operating in Singapore they hold less than 50% and aren\u2019t considered decision makers. Minimal liability. The SG government rarely inquires about our fund\u2019s business activities, most of which involves trading neutral bonds. That makes the fund look relatively vanilla.\u201d He seemed to speak like a third grade teacher explaining division.\n\n\u201cWe provide the funds with lists of desired trades\u200a\u2014\u200ashorts, mostly\u200a\u2014\u200ato transact whenever their risk/reward simulations evaluate as neutral or better in upside.\u201d\n\n\u201cNeutral or better upside for a fund. Those trades accomplish goals directly for the parent firm.\u201d Then a CLICK for me.\n\n\u201cIf they place an identified trade within its specified time window, we pay fees plus credit the fund with tokens.\u201d Fuentes seemed annoyed. Four CLICKs, pausing in-between each. Then a long stare at me. Plus one more CLICK. \u201cAccumulate enough tokens, they qualify for more debt financing from the parent. More money to play with. A bond\u2019s activity is neutral for the hedge fund, but we\u2019ve added shape to markets.\u201d\n\n\u201cLook, Finance is only one aspect, what the markets allegedly believe.\u201d Fuentes was now talking down to me, a programmer. \u201cMarketing is another, what the public tends to believe.\u201d CLICK. \u201cThere\u2019s a third component, competitive intelligence services out of Costa Rica\u200a\u2014\u200awhat a company believes about itself.\u201d He paused to sip the Rain Shadow, then CLICKed again. \u201cTogether those represent something we call the \u2018Three Legs of the Stool\u2019\u200a\u2014\u200anamely Finance, Marketing, Intelligence.\u201d\n\n\u201cNo, not enough leverage there. We\u2019d tried that already.\u201d Another CLICK. \u201cIt\u2019s basically what everyone else does. Remember the AIs we use to cherry-pick defendants?\u201d Fuentes was gesturing a little too profusely. He bumped the table and Chen\u2019s ale spilled.\n\nFuentes leaned back. \u201cPerhaps we are chasing the wrong tiger.\u201d He put his tally counter back into a coat pocket, shooting a quick glance at Chen. Then back to me, squaring off: \u201cLook, are you even interested in working with us?\u201d\n\nMachine learning models had identified common theme among the parent firm\u2019s more successful cases. \u201cOur AIs identified how violence in action and speech had become considered a moral good in the corporatist workplace. Once that reached a point of being perceptually conflated with background violence in US cities, we had our weapons of choice ready.\u201d\n\n\u201cSo the system targets managers in companies, managers who create actionable legal violations. Or at least perceived ones.\u201d\n\nMore infuriating noise from the rage monster. I invoked the sun glare when I\u2019m driving just before sunset mantra for this one. Which definitely would require a call with James. He\u2019d made the original customer intro, then I\u2019d worked with Optimiumly founders to improve predictive models for their ad network.\n\nThen they\u2019d hired the monster\u200a\u2014\u200apoached from our previous employer, and promptly anointed in charge of the SkyBraynz project. After which the whole thing started to cave. At this point we probably spent 20\u201330% of the billable hours just untangling all the rumors, accusations, and FUD that spewed from the monster.\n\nEnough of that, must focus. Fuentes was on the fence, right when this gig began to sound interesting.\n\n\u201cThis is why we need you.\u201d Chen spoke for the first time. Deadpan, turning her head to look at my phone. Ignoring her Wild Swan that Fuentes had spilled, as Alasdair wandered off to fetch another round from the tap. I grabbed one of the koi, thinking that we should at least eat some food. Then asked:\n\n\u201cWe read Hacker News and Reddit. More specifically, we build AIs to scan the entire category.\u201d Chen was nothing if not precise. \u201cYour framework replaces Monte Carlo methods with reinforcement learning. Already doing that for your Shenzhen client?\u201d\n\nFuentes cut in before Chen could start. \u201cWe don\u2019t hunt people. We look for favorable situations, then reshape likely outcomes to become even more favorable for our business objectives.\u201d The tally counter reemerged from his pocket, then another CLICK.\n\nA bar keeper brought us a menu. Chen and I agreed on Scotch Eggs. I felt a deep need for food\u200a\u2014\u200athe beer was clearly talking on my behalf as we started our second round.\n\nFuentes rolled his eyes and leaned back from the table. Three CLICKs.\n\n\u201cAmericans mind the spondoolies,\u201d Alasdair offered. \u201cResults. Money. They\u2019ve built company cultures tae select for wud. Narcissists, histrionic personality disorders, borderline cases, all the drama. These represent far far too many of yer leaders in business.\u201d\n\n\u201cHo, here fannybawz, stap yer havering. You bloody well know what I mean. Leaders who lash out with rage, accusations. Execs dismiss that as competitiveness, all quite properly American.\u201d Alasdair looked slightly miffed. \u201cHere\u2019s a problem: yer people feel surrounded by violence, news about police shooting people of color, people shooting police, riots, random gun spray. Then they go off and work, where managers lash out, pretendy as doolally drill sergeants. Skivers an\u2019 knapdarloch. Breaking the very same senses us humans evolved tae steer clear of the seriously radge.\u201d\n\n\u201cMad rockets. Crazies. Steering clear of that lot overlaps with how we\u2019re wired to notice DSM\u20135 personality disorders. The very same whom we promote through corporatist ranks.\u201d\n\nAnother text blipped in from the monster, who\u2019d apparently begun contacting our engineers directly. Upping the ante. Something else that I couldn\u2019t quite parse, about calling James to insist on a reprimand for one of our engineers in particular. Seriously crazy. My mantra selection: squeaky grocery cart. Long deep breaths.\n\nChen answered me instead of Alasdair. \u201cSimple. Drawing similarity between DSM\u20135 and full psychopaths was considered red herring in court. It was assumed people didn\u2019t encounter dangerous psychos or seriously threatening situations often enough to pose valid arguments.\u201d She blinked. \u201cThat changed in 2016. High streets and undergrounds in America now seem to mix battlefield with psychiatric ward.\u201d\n\nI was perplexed, fatigued, and probably still thinking too much about the monster. Rage breeding rage.\n\n\u201cWe litigate against companies when enough employees feel threatened at work. Because managers acting out in rage, acting perceivably crazy. Legal tests for that have shifted recently. Maybe more unhinged due to enduring pressure of economic downturns. In any case, lawsuits on behalf of employees can be quite lucrative.\u201d Chen was adamant. Uncharacteristic for the hour plus that I\u2019d known her so far. \u201cEspecially on contingency terms. Especially when we pinpoint pressure on key executives.\u201d\n\n\u201cPlus hedge fund, pressuring finance departments. Plus freelance executive recruiters, spreading rumors. We can pretty much ruin any board meeting.\u201d\n\nFuentes pulled a few sheets of folded paper from a notebook, handing them to me. A4 dimensions looked odd. For that matter, their printed letterhead looked oddly archaic. Definitely not a DocuSign. \u201cI believe these terms are far more favorable than what your friend in China has offered?\u201d\n\n\u201cWe ask for 20%, preferred, one board seat.\u201d After his second pint Fuentes seemed all-business. He seemed more comfortable that way. \u201cWith this cash infusion you\u2019ll have both runway and reserves to expand. Plus a guaranteed level of monthly consulting hours.\u201d He sipped more Buxton brew. \u201cGame?\u201d\n\nChen stirred. \u201cWhat we want your machines to dream for us. \u2018The future belongs to those who believe in beauty of their dreams\u2019\u200a\u2014\u200aEleanor Roosevelt.\u201d\n\nAnother text came in. This time from Bobi, one of our best AI engineers.\n\nBobi wasn\u2019t going a day without work in this market. Nobody would be getting fired. Period. Even so, we couldn\u2019t afford to lose her. Much less afford to have her distracted right now because of the monster\u2019s machinations. We needed code, lots of great code. I invoked another of my favorites mantras: overdraft bank fee. Especially good mojo in that one. Texted Bobi, pouring my heart out trying to reassure her. Promising to send her grandmother a gift. Then back to Chen:\n\nChen blinked again. As if donating a poker tell on my behalf.\n\nAlasdair stared down his empty tumbler. Glaring at it. \u201cParent firm has convolutional neural networks in place for its AIs\u200a\u2014\u200askoosh. Hedge funds run themselves a bajillion MCMC simulations daily. Our competitive intel people use those thingmies too in prototypes\u200a\u2014\u200athe recurrent neural networks. All bogies coordinated via blockchain. Why not distribute that learning across? Heid Bummer of AIs that\u2019d be! Dogs baws, if you ask me.\u201d\n\nThe money would help. Though it sounded a little too good to be true. A carrot with no stick\u00a0\u2026 yet.\n\nMy turn to buy a round, so I wandered off. Following koi as they shimmied across the floor. Trying not to think about the mess back at the office.\n\nMade a detour toward the loo. Pub tables and their high seats scattered along one side of a wide hallway. I noticed board games on most of the tables, stopping to glance at one in particular. Almost like a Scrabble board, using small lettered blocks to spell words. However, unlike Scrabble, it had geometric patterns strewn at odd angles across the background, and strangely unfamiliar characters. They looked vaguely Art Deco, though more ornate. Some kind of symbols. Like a tripping typographer\u2019s attempted prank to forge coded manuscripts from the Renaissance.\n\nI hadn\u2019t noticed a person sitting near the table. She turned her eyes slowly away from the symbols, gazing fiercely up toward me. The old woman from the park, with her red shawl strewn over the opposite seat. She smiled lightly, then quoted another line from Shakespeare:\n\nMore cosplay\u200a\u2014\u200aalmost intimate, awkwardly, with a hint of transgression in her voice. I rushed off, not knowing how to respond. Embarrassed. Heading on toward the loo. The patterns of blocks that she\u2019d spelled out stuck in my jet-lagged mind.\n\nWhen I returned to our table, Fuentes seized his fresh pint and glared at me. CLICK! I imagined carrots morphing into sticks. Perhaps it was the beer dreaming? \u201cLet\u2019s be clear,\u201d he started. \u201cWe\u2019ll need some measure of your commitment.\u201d\n\n\u201cSee, this is what I mean.\u201d Fuentes pushed away from the table and wandered off in a huff. CLICKing several times over his shoulder without even bothering to look back at me.\n\n\u201cNae bother,\u201d said Alasdair. \u201cA wee bit pished and off to the bog. Quite thankfully before he rifted a honkin air beige out his Jacksy for us all to share!\u201d And drunken grins.\n\nJust then two of the suits from the back came chasing a garden gnome across the pub. Pushing each other, as if they were dribbling the ball down-field in a football match. Some kind of sports-ball. Or something.\n\nAnother text from Bobi. Totally freaked out. The monster had lashed out at more of our engineers \u2013\n\nCRASH!!! One of the suits landed atop our table. Pints spilled, glass shattered. Imaginary koi swam away in fear.\n\nAlasdair fumed, \u201cAwa, yi glaikit bastirt!\u201d Phrases seemed emergent, newly formed like flowing lava. The suits scrambled to full attention, apologetic in a way that only British people seem to know how to do. Offering to buy us another round, in earnest.\n\nMy phone had fallen in the scuffle, sliding across the floor toward where Chen stood away from the table. She picked it up, staring at the screen for a moment.\n\nThe old woman with the red shawl brushed against me as she hurried toward the gatehouse doors. Turned to wink. I stared, but then Chen nudged my arm. Offering my phone with two hands outstretched. Blinking.\n\nFuentes returned, asking about the commotion. Then stomped off with the suits to order our compensatory pints. CLICKing his tally counter under their noses with a glare. Alasdair tailed them, not quite finished fuming.\n\nChen got busy on her tablet, typing rapidly. She stopped for a moment, staring at her screen. Nodding quickly. \u201cPlease,\u201d she asked, \u201chave a look.\u201d Handing me the tablet.\n\nThis time I blinked. Their law firm had a pr\u00e9cis about the monster, in full detail. Already a long list of complainants giving what appeared to be depositions. Some of whom I recognized from our previous employer. Then risk estimates, a correlated graph of confidants and \u201cenablers\u201d along with links to bios for each. Also something about a bench warrant for outstanding traffic tickets?\n\n\u201cThis person is already among our high ROI targets,\u201d Chen blinked again. \u201cMerely matter of time before pre-trial gets green light.\u201d She shutoff her tablet quickly as Fuentes and Alasdair arrived back with our fresh pints.\n\nI wanted to recover our business conversation. Viable terms for working together seemed a distinct possibility.\n\n\u201cSmall but nonintuitive social networks,\u201d Chen explained. \u201cMost DSM\u20135s that we profile have enablers.\u201d\n\n\u201cGenerally, someone in an executive role,\u201d Fuentes interjected, \u201cwho keeps them properly shielded from blame. Entangled in so much business value that everyone must overlook the toxicity to the company culture. The value prop is to pressure the apologists with tangible business risks, albeit with methods arrived through covert means.\u201d\n\nFuentes received a call, walked off to find a quieter spot. Twirling his tally counter with three fingers.\n\n\u201cEver so properly entangled up in their shuches,\u201d Alasdair mumbled. \u201cRight, we\u2019ll be doing quantum physics next.\u201d His gregariousness had soured noticeably since the table crash, and with that his brogue thickened. \u201cDinnae get Fuentes started aboot that!\u201d\n\nChen confirmed about connected component analysis, adding that Fuentes nurtured rather odd beliefs about quantum physics. That encompassed aspects of the occult, along with their team\u2019s place in the world. I struggled to follow\u200a\u2014\u200asomething about superposition, entanglement, wormholes. A vague equating of \u201cblack magick\u201d with black holes, again more about the wormholes and ceremonial rituals. Where a Renaissance cult of early physics and math geniuses had made advances into quantum mechanics. Faint echoes of those early advances passed down to us half a millennium later as rumors about ritual magick. Their wizardry for bending time and space having been lost in a second Dark Age\u200a\u2014\u200awhich we now rather perversely called the Enlightenment.\n\n\u201cHe\u2019ll have some cailleach appearing all ghostly above a loch, amidst incantations and cantrip but,\u201d Alasdair sounding decidedly more inebriated now, sleepy. Almost nodding off.\n\nChen and I changed the subject as Fuentes walked back, counter firmly in hand. We talked more through the use case, though the table conversation began to wane. Fuentes grew more interested in texting. He\u2019d pull out the tally counter, check numbers on his phone, then text. Truly weird guy. Alasdair trailed further off, kept looking toward the back of the pub. Fuming still, between nods, as if he wanted to start a fight. Or sleep. Probably both.\n\nAfter we finished the round, I made polite excuses to leave. Jet lag, my talk early in the morning, etc. Fuentes pressed me to consider their term sheet carefully and get back to him as soon as possible.\n\nRetracing my path back through the Underground, just well enough to find my hotel. Then found my room, found my key card, collapsed on my bed.", 
        "title": "Hylburt-Speys \u2013"
    }, 
    {
        "url": "https://medium.com/autonomous-agents/part-2-error-analysis-the-wild-west-algorithms-to-improve-neuralnetwork-accuracy-6121569e66a5?source=tag_archive---------1----------------", 
        "text": "Wyatt Earp was the most famous lawman in the Wild West who is glorified beyond means for his abilities as a fearless gunman. He may not have been the quickest draw in the west, but was the most deadliest of his times. It has been stated that he often used to quote:\n\nNeural Net training is a bit like the wild west. The errors are quite lawless and unhinged. They can behave erratically without rules, rhyme or reason. The best way to arrest and stabilize a model is to get a hang on accuracy first as against trying to focus on training speed.\n\nIn the previous post \u201cPart-1: Error Analysis\u2026\u201d we learnt about different components of error and the respective error scoring methods. In this post, we are going to learn on how to improve upon these errors. Specifically, we are going to focus on accuracy.\n\nWe learnt that accuracy is a proximity of the predicted values to its true values. The equation for accuracy is:\n\nAs per the equation, the way to increase accuracy is to increase the true-positives and true-negatives over the total population.\n\nNote that the sum of total population is a given. As in, you do not have much wiggle room to reduce the total population by only training your Neural Nets on \u2018Relevant\u2019 items (or the positive set of a feature). Especially in a multivariate binary classification, the number of not-relevant items shall always be higher than the number of relevant items.\n\nIn other words, In the wine dataset, if you have 3 mutually exclusive class into which a wine can be classified, then the positive set shall always be 1 and the negative set shall always be 2 per wine (One of three classes is positive, 2 of 3 classes are negative). The negative set only increase as the number of classes increase for mutually exclusive multivariate binary classification.\n\nSo the only way to increase accuracy is to increase the true-positives and the true-negatives.\n\nIn the previous post, we analyzed the accuracy measure during validation (on the validation-set, not during training), after the network was fully trained. This is not a great place for error analysis if we do not know what was the accuracy of the network on the training set.\n\nLet me alter the wine tasting example a bit to walk you through the new observations.\n\nFirst I shall reduce the number of epochs to 25 and 1 iteration per epoch as follows:\n\nSecond, I shall comment out a important section of the code where I was using a regularizer (which I shall explain shortly) and momentum-value as follows:\n\nNow, I shall use a dip-stick to evaluate the wine tasting Neural Net model on 2 things.\n\nThe code for the changes is as follows:\n\nWhat I am doing here is print two different evaluation measures, one measure shall display the accuracy of the model on the data it was recently trained.\n\nThe other shall display the accuracy for a validation data-set that was NOT used to train the model. The idea of prediction is to predict good results on the NEW set of data which was NOT foreseen during training. (What good is a model otherwise?)\n\nThe results are as follows:\n\nNotice that the accuracy of the model to predict the data that was seen during training is far higher (0.9304) than its ability to predict data for not foreseen data (0.6508)\u00a0!! Now, you are wondering, what the heck\u00a0!! Right?\n\nIt\u2019s simple. The network is \u201cMemorizing\u201d the data from the training set here. So whenever you run a sample prediction on the training set, the network performs well (from memory) but it is not able to accurately predict new dataset from the validation set.\n\nTo understand, overfitting, let\u2019s look at the following depiction:\n\nThe first graph depicts a \u201cLinear Regression\u201d or a function that is asked to learn the total weights of all the points in the subspace and draw a best fit \u201cline\u201d. Of-course, we know that linear regression models are not great when it comes to multivariate binary classification problems. It\u2019s only used as a reference graph for explanation. So this graph is useless beyond showing us a hyperplane division of the data cluster (don\u2019t worry about hyperplanes for now).\n\nThe third graph depicts a polynomial function, that fits all the data points perfectly. This curve has memorized the underlying data-points as against learning anything about the underlying function of the subspace.\n\nThis curve is nearly useless in predicting where to plot a new data-point for a new input (x axis) in the feature subspace. Does the curve extend upwards? Should it drop back down? Should it plateau? Nothing. Zilch. This curve is overfitted.\n\nThe second graph is more interesting and intuitive. It seems to have learnt the underlying function of the subspace as against trying to memorize where the data-points are\u00a0! So given a feature input (on x-axis), we can intuitively state that the next data point as x-progresses can be plotted in the direction (upwards) as the function climbs. This is very useful for prediction.\n\nThe best possible way to identify overfitting in your Neural Net models is to plot a graph of accuracy for your training-set and validation-set data over number of iterations for the model.\n\nIf the validation set is not able to catchup with the training-set as illustrated, then you have a overfitted model.\n\nThe technique to break overfitting or memorization of the network is called \u201cgeneralization\u201d\n\nThere are umpteen number of ways to improve generalization of the Neural Nets. While I had provided a high level overview of generalization in the previous post titled \u201cIs optimizing your Neural Net a dark art\u201d which provides some key techniques, I shall focus on Weight Penalties, Early Stopping and using Weight Constraints as a generalizer.\n\nOne of the techniques used to generalize a Neural Net is to regularize. Regularization is function introduced to the loss function of the Neural Net. We add a Regularization term R(f) to the loss function to prevent the coefficients to fit perfectly.\n\nWe can decay the weights either by using a L1 or L2 regularization term added to the loss function. While an L1 regularization decays the absolute value of the weight, the L2 regularizer decays the squared weights.\n\nHere, we have added a weight penalty on the absolute value of the weight to the cost function as illustrated. This can be broken down as follows:\n\nUsing L1 weight penalty, when cost is zero, the weight can get to zero. This way many weights can get to zero and introduce sparsity in the network. This limits from having many large weights. L1 regularization helps in regularizing the network from perfectly fitting the feature vector. Instead, the network learns the feature vector more generally.\n\nAs noticed, the L2 regularizer penalizes the squared weights. The idea here is to keep the weights small enough, but not to let it slip to a zero. This keeps the network dense (unlike L1 weights which introduces sparsity).\n\nIn L2 regularization, when cost is zero, the weight gets a very small value. The beauty of the L2 regularizer is that it smoothens the output by changing the outputs much more slowly as input grows. The main difference between a L1 and L2 regularizer is as follows:\n\nNotice, in the code, I have used a L2 regularizer with the lambda of 1e-4 as follows:\n\nHere is the output on the validation set after using L2 regularization in the cost function:\n\nHence, proved\u2026 (It helps to keep the lambda between 1e-2 to 1e-6).\n\nAnother technique is to stop as early as possible during training before the network starts memorizing the features. This keeps the network semi-trained and hopefully general as against memorization. To understand this, let\u2019s take a look at the error curves below\n\nThe y-axis is the prediction error, and the x-axis is the number of iterations. One of the ways to regularize a network is to \u201cvisualize\u201d the prediction errors on one of the error measures (Either accuracy, recall or the overall performance measure, the F1 score) and stop the training of a network at a particular iteration or a epoch when the error scores starts to degrade.\n\nThe visualization is a cumbersome method, instead, you can use a model measure tracker which can keep track of the validation error w.r.t the training error on every iteration (mini-batch) or epoch and compare the measure with the previous iteration. If the error continues to improve then you continue with the iteration. As soon as the error starts to degrade, you can terminate the learning.\n\nSince I am using DL4J in the examples, It is prudent to point to the DL4J documentation which has a nice write on Early Stopping > here\n\nThe other technique is to use a weight constraint on the weights as against using a weight decay in the cost functions.\n\nThe constraint can be set on how large the weight is allowed to go. Usually, the best weight constraint is to clip the weights to the length on the vector of the incoming weights. The equations is as follows:", 
        "title": "Part-2: Error Analysis \u2014 The Wild West. Algorithms to Improve #NeuralNetwork Accuracy."
    }, 
    {
        "url": "https://medium.com/@hadrielle/linkedin-or-the-art-of-pretending-to-be-an-expert-46083b052600?source=tag_archive---------2----------------", 
        "text": "Long time no write. Been really busy learning some stuff @ku_leuven. Will try to write a couple posts later to finish explaining both my experience in Leuven, and to write a bit of my thesis on Natural Language Inference.\n\nBut, not today! Today is about LinkedIn and their inhabitants. LinkedIn, as you know, is a social network that used to be some serious deal, and right now seems more like the playground of recruiters posting their complex mathematical problems that if you solve, you are a genius.\n\nPart of being in social networks, is being in groups, were amazing content is posted and everyone in these groups are experts.\n\nI came across this article. I couldn\u2019t resist to read it (not that I tried hard or anything), as an eager learner that I am. Also the Venn diagram is wonderful, isn\u2019t it? And because I just had my first coffee of the morning, I\u2019m going to use a few minutes commenting on the article.\n\nBefore starting, I\u2019m no expert in the matter, so forgive me god/good people of the internet, but I\u2019ll be commenting on the article.\n\nI will be using the text from the post as is, so no misinterpretation can happen.\n\nRock solid start. I mean, I\u2019m no expert but, Quora sometimes has some questions that perfectly answered, and I have found some very well written explanations. Btw, shoutout to the Q&A sessions from Quora, latest I read from @fchollet, some interesting questions, with really interesting answers. (I think this is the first time in this post that I\u2019m being serious). But I know I know, Quora is quite new in the internet, and stackoverflow doesn\u2019t solve these tricky questions, let\u2019s check wikipedia. I know wikipedia is not the way to go but, here is another link.\n\nTo read a bit more about it, found really useful this. But some insight about the discussion can be found in this NVIDIA post, you know, the guys who build the GPUs so we can play videogames, errr train deep networks. I really meant train deep networks. Let\u2019s move again to the article.\n\nWell, I\u2019m sure I gave some explanation about it, but it\u2019s worth the check the venn diagram, because diagrams are fun.\n\nBy the way, it is amazing that the author of the post, cites himself as a source when he ellaborates on his points. Not sure who did he cite on his first post, or if an index out of bounds error arised. (Sorry. Not a funny joke.)\n\nThe article proceeds, the author does not explain any AI algorithm (not explaining as in a scientific way, but any example, anything), doesn\u2019t even bother to mention approaches based on logic or anything. A little bit of Turing tests, a little bit of weak vs strong AI and a bit of robots. (I\u2019m still amazed that no external sources were used to generate the article). To end the AI part, the author mentions that there have been some significant advances in AI, increasing performance in some areas.\n\nNext part he writes about Deep Learning (DL), and says, all of the previous advances are coming from DL, (the advances he mentioned in the AI section). Then he proceeds to say that the advances in DL are because of the advances on Neural Nets models, and because we now have better chips in which run these algorithms. Kinda forgetting that we can make use of this algorithms because data collection has been significantly improved in all aspects.\n\nThese is becoming super long and boring for the reader, so you get my point, lets check the final paragraph, Machine Learning. The author says that there are two definitions about it. First.\n\nI mean. What to say. I\u2019m certainly no expert on deep learning, if anything I know, it\u2019s about supervised learning, but this is about using google (an important skill of any data scientist out there, really, use google properly). Takes about 10 segs if you are clicking the search button, to type \u201cunsupervised deep learning\u201d and then click the button.\n\nYea, the fact that some deep learning algorithms need labeled data, in any Machine Learning setup, is called Supervised Learning. When data is not labeled, it is called unsupervised learning. Second definition:\n\nReally surprised that cloud computing and big data are not types of data science algorithms. I\u2019m assuming, the author refers as segmentation (clustering) as unsupervised learning algorithms, and classification and regression as supervised learning algorithms, a definition that extends in any kind of setups, not matter if its machine learning, deep learning, or real human learning.\n\nThe cherry on the top.\n\nI don\u2019t know, I\u2019ve been talking about LinkedIn and \u201cexperts\u201d for so long with collegues/friends that I guess today I felt like writing about it. It takes more time to write the post, and look for nice venn diagrams, than to actually gather the knowledge about certain topics. I know LinkedIn is all about selling oneself, and I\u2019m not the best at it, but in science, any kind of science, please, take five minutes of your life to write something coherent, something that can be used by others to learn.\n\nHere you have another Venn diagram. Because they are truly amazing. Have a nice day.", 
        "title": "LinkedIn or the art of pretending to be an expert. \u2013 David Torrejon Moya \u2013"
    }, 
    {
        "url": "https://medium.com/findo-io/smarter-technology-for-a-smarter-future-495669b52261?source=tag_archive---------3----------------", 
        "text": "Dropbox\u2026 Google Drive\u2026 Gmail\u2026 Evernote\u2026 the list goes on. We have so much information stored in our online accounts.\n\nWhat can we do with all of our disparate data in our personal cloud?\n\nWe can learn from it.\n\nAdvances in technology have allowed us to extrapolate insights from our data. We do this through machine learning, or more specifically, deep learning.\n\nIn a nutshell, deep learning is a computational process that mimics the way our brains form when we are children. As children, we start to distinguish dogs from other animals through experience. After seeing dogs in a variety of colors and sizes, we recognize patterns and common characteristics. We hear people refer to these animals as dogs. Essentially, we begin to understand what makes a dog a dog and not a cat. We learn.\n\nWe do this for pretty much everything. It\u2019s how we know how to say sentences that we haven\u2019t necessarily heard before\u200a\u2014\u200awe detect the grammar patterns in our parents\u2019 speech, we attach definitions to words. Eventually, we adopt the ability to put these words together to create our own sentences. The more we do it, the better we get.\n\nTechnology can now do the same. Deep learning allows programs to become smart and learn from experience. In the case of technology, experience equals data. The more data we have, the more our programs can learn. As our programs become smarter and better trained they can make educated assumptions and draw important insights.\n\nSo what does this mean for the information in your personal cloud? Findo can apply this type of deep learning to the data in your cloud. Findo trains itself and learns from your information.\n\nThis allows Findo to handle your email just like an assistant would\u200a\u2014\u200aby understanding the contents of your mail.\n\nPredictive Insights is Findo\u2019s robust feature that through deep learning, and acts proactively towards your inbox. It starts by filtering important and unimportant email. It then notifies you about the emails that require some type of action (confirming calls or meeting invites, sending out invoices, filling out applications, etc.). Findo knows which tasks are time sensitive and just like a personal assistant notifies you for completion.", 
        "title": "Smarter technology for a smarter future. \u2013 Findo.io \u2013"
    }
]