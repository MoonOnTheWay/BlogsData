[
    {
        "url": "https://medium.com/@ewencja/why-the-time-is-ripe-for-collaborative-robotics-ad0348a10f59?source=tag_archive---------0----------------", 
        "text": "Collaborative robots (cobots) are lightweight robots that work next to humans and assist them in repetitive, dangerous and tedious tasks. Unlike traditional robots, which work fenced off from humans and are pre-programmed to perform one task, cobots are small and flexible. They are relatively new\u200a\u2014\u200afirst models entered the market in 2009. So far around 15,000 have been installed globally. The reason for a relatively slow adoption has been mostly their price tag and safety concerns. Recent developments in robotics hardware and machine learning software solve these challenges.\n\nThis week\u2019s Hannover Messe, the world`s largest industrial fair, was filled with cobots. Every large equipment manufacturer showed one. The biggest news was the launch of FRANKA EMIKA from KBee, a Munich-based company owned to 40% by KUKA. At \u20ac 9,900 this robot changes the industry cost dynamics. Its gripper, motors and gears are not top quality and its load value is relatively low, but it will likely be sufficient for quite a few applications.\n\nThe price tag of comparative robots from KUKA, Fanuc or Bosch is around \u20ac40,000 and \u20ac100,000 and the unit economics (equivalent to man-hours) around \u20ac25/h. In September 2015 a Chinese company Ningbo Techmation released a \u20ac20,000 cobot. A further 2x price reduction from KBee opens up a range of new applications.\n\nThe most popular report on the robotics market by Boston Consulting Group (2015) talks about merely a 20% cost reduction (from around \u20ac 100,000 to \u20ac 80,000) in industrial robots between 2015 and 2025! This prognosis might need to be revised.\n\nThe second largest inhibitor to wide scale adoption of cobots have been safety issues. Here is where I think the recent development in software, and specifically deep learning, will bring key answers. The idea is that a robot is able to learn the environment around it and constantly improve on the catalog of objects and tasks it knows. The same way it will understand how humans move and anticipate unexpected behavior such as a collision. Where a camera that feeds the software can\u2019t see other sensors will help.\n\nDeep learning software will also improve the unit economics, adding to the already significant cost reduction in hardware. A robot that knows how to operate in new environments and how to grab new objects will of course be more adaptable and multi-functional. During its lifetime it will be able to serve more roles and needs, and pay for itself faster.\n\n$ 1.3 bn in venture capital went into robotics last year. Drones, robotic personal companions and surgical robots emerged as the three dominant investment categories. The classical applications for robots, like manufacturing and logistics, attracted only around 10% of the total capital. As the unit economics improve, startups jump into the classical applications and investors will pay more attention.\n\nAutomotive manufacturers already offer use cases where cobots can start working tomorrow, e.g. interior installations in automotive. Mercedes sets an example to other car manufacturers. By integrating a large number of cobots into its manufacturing it can customize its production lines. Tesla and BMW are doing it too.\n\nAt a cost of around \u20ac5 per hour mass adoption of collaborative robotics is imminent.", 
        "title": "Why the time is ripe for collaborative robotics \u2013 Ewa Treitz \u2013"
    }, 
    {
        "url": "https://medium.com/@vcjha/7-steps-to-understanding-deep-learning-2bca5109e53b?source=tag_archive---------1----------------", 
        "text": "Deep learning is a branch of machine learning, employing numerous similar, yet distinct, deep neural network architectures to solve various problems in natural language processing, computer vision, and bioinformatics, among other fields. Deep learning has experienced a tremendous recent research resurgence, and has been shown to deliver state of the art results in numerous applications.\n\nIn essence, deep learning is the implementation of neural networks with more than a single hidden layer of neurons. This is, however, a very simplistic view of deep learning, and not one that is unanimously agreed upon. These \u201cdeep\u201d architectures also vary quite considerably, with different implementations being optimized for different tasks or goals. The vast research being produced at such a constant rate is revealing new and innovative deep learning models at an ever-increasing pace.\n\nCurrently a white hot research topic, deep learning seems to be impacting all areas of machine learning and, by extension, data science. A look over recent papers in the relevant arXiv categories makes it easy to see that a large amount of what is being published is deep learning-related. Given the impressive results being produced, many researchers, practitioners, and laypeople alike are wondering if deep learning is the edge of \u201ctrue\u201d artificial intelligence.\n\nThis collection of reading materials and tutorials aims to provide a path for a deep neural networks newcomer to gain some understanding of this vast and complex topic. Though I do not assume any real understanding of neural networks or deep learning, I will assume your familiarity with general machine learning theory and practice to some degree. To overcome any deficiency you may have in the general areas of machine learning theory or practice you can consult the recent KDnuggets post 7 Steps to Mastering Machine Learning With Python. Since we will also see examples implemented in Python, some familiarity with the language will be useful. Introductory and review resources are also available in the previously mentioned post.\n\nThis post will utilize freely-available materials from around the web in a cohesive order to first gain some understanding of deep neural networks at a theoretical level, and then move on to some practical implementations. As such, credit for the materials referenced lie solely with the creators, who will be noted alongside the resources. If you see that someone has not been properly credited for their work, please alert me to the oversight so that I may swiftly rectify it.\n\nA stark and honest disclaimer: deep learning is a complex and quickly-evolving field of both breadth and depth (pun unintended?), and as such this post does not claim to be an all-inclusive manual to becoming a deep learning expert; such a transformation would take greater time, many additional resources, and lots of practice building and testing models. I do, however, believe that utilizing the resources herein could help get you started on just such a path.\n\nIf you are reading this and interested in the topic, then you are probably already familiar with what deep neural networks are, if even at a basic level. Neural networks have a storied history, but we won\u2019t be getting into that. We do, however, want a common high level of understanding to begin with.\n\nFirst, have a look at the fantastic introductory videos from DeepLearning.tv. At the time of this writing there are 14 videos; watch them all if you like, but definitely watch the first 5, covering the basics of neural nets and some of the more common architectures.\n\nNext, read over the NIPS 2015 Deep Learning Tutorial by Geoff Hinton, Yoshua Bengio, and Yann LeCun for an introduction at a slightly lower level.\n\nTo round out our first step, read the first chapter of Neural Networks and Deep Learning, the fantastic, evolving online book by Michael Nielsen, which goes a step further but still keeps things fairly light.\n\nDeep neural nets rely on a mathematical foundation of algebra and calculus. While this post will not produce any theoretical mathematicians, gaining some understanding of the basics before moving on would be helpful.\n\nFirst, watch Andrew Ng\u2019s linear algebra review videos. While not absolutely necessary, for those finding they want something deeper on this subject, consult the Linear Algebra Review and Reference from Ng\u2019s Stanford course, written by Zico Kolter and Chuong Do.\n\nThen look at this Introduction to the Derivative of a Function video by Professor Leonard. The video is succinct, the examples are clear, and it provides some understanding of what is actually going on during backpropagation from a mathematical standpoint. More on that soon.\n\nNext have a quick read over the Wikipedia entry for the Sigmoid function, a bounded differentiable function often employed by individual neurons in a neural network.\n\nFinally, take a break from the maths and read this Deep Learning Tutorial by Google research scientist Quoc Le.\n\nAn important part of neural networks, including modern deep architectures, is the backward propagation of errors through a network in order to update the weights used by neurons closer to the input. This is, quite bluntly, from where neural networks derive their \u201cpower,\u201d for lack of better term. Backpropagation for short (or even \u201cbackprop\u201d), is paired with an optimization method which acts to minimize the weights that are subsequently distributed (via backpropagation), in order to minimize the loss function. A common optimization method in deep neural networks is gradient descent.\n\nFirst, read these introductory notes on gradient descent by Marc Toussaint of the University of Stuttgart.\n\nNext, have a look at this step by step example of backpropagation in action written by Matt Mazur.\n\nMoving on, read Jeremy Kun\u2018s informative blog post on coding backpropagation in Python. Having a look over the complete code is also suggested, as is attempting to replicate it yourself.\n\nFinally, read the second part of the Deep Learning Tutorial by Quoc Le, in order to get introduced to some specific common deep architectures and their uses.\n\nThe specific neural network architectures that will be introduced in the following steps will include practical implementations using some of the most popular Python deep learning libraries present in research today. Since different libraries are, in some cases, optimized for particular neural network architectures, and have established footholds in certain fields of research, we will be making use of 3 separate deep learning libraries. This is not redundant; keeping up with the latest libraries for particular areas of practice is a critical part of learning. The following exercises will also allow you to evaluate different libraries for yourself, and form an intuition as to which to use for which problems.\n\nAt this point you are welcome to choose any library or combination of libraries to install, and move forward implementing those tutorials which pertain to your choice. If you are looking to try one library and use it to implement one of each of the following steps\u2019 tutorials, I would recommend TensorFlow, for a few reasons. I will mention the most relevant (at least, in my view): it performs auto-differentiation, meaning that you (or, rather, the tutorial) does not have to worry about implementing backpropagation from scratch, likely making code easier to follow (especially for a newcomer).\n\nI wrote about TensorFlow when it first came out in the post TensorFlow Disappoints\u200a\u2014\u200aGoogle Deep Learning Falls Shallow, the title of which suggests that I had more disappointment with it than I actually did; I was primarily focused on its lack of GPU cluster-enabled network training (which is likely soon on its way). Anyhow, if you are interested in reading more about TensorFlow without consulting the whitepaper listed below, I would suggest reading my original article, and then following up with Zachary Lipton\u2019s well-written piece, TensorFlow is Terrific\u200a\u2014\u200aA Sober Take on Deep Learning Acceleration.\n\nGoogle\u2019s TensorFlow is an all-purpose machine learning library based on data flow graph representation.\n\nTheano is actively developed by the LISA group at the University of Montreal.\n\nCaffe is developed by the Berkeley Vision and Learning Center (BVLC) at UC Berkeley. While Theano and TensorFlow can be considered \u201cgeneral-purpose\u201d deep learning libraries, Caffe, being developed by a computer vision group, is mostly thought of for just such tasks; however, it is also a fully general-purpose library for use building various deep learning architectures for different domains.\n\nKeep in mind that these are not the only popular libraries in use today. In fact, there are many, many others to choose from, and these were selected based on the prevelance of tutorials, documentation, and acceptance among research in general.\n\nWith libraries installed, we now move on to practical implementation.\n\nComputer vision deals with the processing and understanding of images and its symbolic information. Most of the field\u2019s recent breakthroughs have come from the use of deep neural networks. In particular, convolutional neural networks have played a very important role in computer vision of late.\n\nFirst, read this deep learning with computer vision tutorial by Yoshua Bengio, in order to gain an understanding of the topic.\n\nNext, if you have TensorFlow installed, take a look at, and implement, this tutorial, which classifies CIFAR-10 images using a convolutional neural network.\n\nIf you have Caffe installed, as an alternative to the above tutorial (or alongside), implement a convolutional neural network in Caffe for classifying MNIST dataset images.\n\nHere is a Theano tutorial which is roughly equivalent to the above Caffe exercise.\n\nAfterward, read a seminal convolutional neural network paper by Krizhevsky, Sutskever, and Hinton for additional insight.\n\nNatural language processing (NLP) is another domain which has seen benefits from deep learning. Concerned with understanding natural (human) languages, NLP has had a number of its most recent successes come by way of recurrent neural networks (RNN).\n\nAndrej Karpathy has a fantastic blog post titled \u201cThe Unreasonable Effectiveness of Recurrent Neural Networks\u201d which outlines the effectiveness of RNNs in training character-level language models. The code it references is written in Lua using Torch, so you can skip over that; the post is still useful on a purely conceptual level.\n\nThis tutorial implements a recurrent neural in TensorFlow for language modeling.\n\nYou can then use Theano and try your hand at this tutorial, which implements a recurrent neural network with word embeddings.\n\nFinally, you can read Yoon Kim\u2019s Convolutional Neural Networks for Sentence Classification for another application of CNNs in language processing. Denny Britz has a blog post titled \u201cImplementing A CNN For Text Classification in TensorFlow,\u201d which does just as it suggests using movie review data.\n\nThe previous steps have progressed from theoretical to practical topics in deep learning. By installing and implementing convolutional neural nets and recurrent neural nets in the previous 2 steps, it is hoped that one has gained a preliminary appreciation for their power and functionality. As prevalent as CNNs and RNNs are, there are numerous other deep architectures in existence, with additional emerging from research on a regular basis.\n\nThere are also numerous other considerations for deep learning beyond those presented in the earlier theoretical steps, and as such, the following is a quick survey of some of these additional architectures and concerns.\n\nFor a further understanding of a particular type of recurrent neural network suited for time series prediction, the Long Short Term Memory Network, read this article by Christopher Olah.\n\nThis blog post by Denny Britz is a great tutorial on RNNs using LSTMs and Gated Recurrent Units (GRUs). See this paper for a further discussion of GRUs and LSTMs.\n\nThis clearly does not cover all deep learning architectures. Restrictive Boltzmann Machines are an obvious exclusion which comes to mind, as are autoencoders, and a whole series of related generative models including Generative Adversarial Networks. However, a line had to be drawn somewhere, or this post would continue ad infinitum.\n\nFor those interested in learning more about various deep learning architectures, I suggest this lengthy survey paper by Yoshua Bengio.\n\nFor our final number, and for something a bit different, have a look at A Statistical Analysis of Deep Learning by Shakir Mohamed of Google DeepMind. It is more theoretical and (surprise, statistical) than much of the other material we have encountered, but worth looking at for a different approach to familiar matter. Shakir wrote the series of articles over the course of 6 months, and is presented as testing wide-held beliefs, highlighting statistical connections, and the unseen implications of deep learning. There is a combined PDF of all posts as well.\n\nIt is hoped that enough information has been presented to give the reader an introductory overview of deep neural networks, as well as provide some incentive to move forward and learn more on the topic.", 
        "title": "Deep Learning : How to start \u2013 Vikram Jha \u2013"
    }, 
    {
        "url": "https://medium.com/pankajmathur/a-simple-multilayer-perceptron-with-tensorflow-3effe7bf3466?source=tag_archive---------2----------------", 
        "text": "In this notebook, we will build a simple multilayer perceptron, basic building block for Neural Networks, with TensorFlow. We are using MNIST example dataset provided by default with TensorFlow package.\n\nHere are the hyper parameters we choose to run initial model:\n\nHere are the network parameters we choose to run multilayer perceptron:\n\nWe achieved 94.8% accuracy in 20 epochs with learning rate of 0.01 by running multilayer perceptron model build with TensorFlow on MNIST dataset.\n\nI am using Conda to install TensorFlow. You might already have a TensorFlow environment, but please check below to make sure you have all the necessary packages. If you have never used Conda environments before, please go through my other tutorial What is Anaconda and Why should I bother about it?\n\nAssuming you have conda install on your machine, please run the following commands to have tensorflow-playground ready for you to play.\n\nRun the following commands to setup your environment:\n\nAnd installing on Windows. In your console or Anaconda shell:\n\nAfter creating conda environment, clone this repository on your local machine via Git or GitHub Desktop\n\nunder tensorflow-playground environment on your terminal or shell window, cd to the cloned directory and then run following command:\n\nPlease find the public Gist of this code:\n\nThat\u2019s it, Just like my another article on quick logistic regression, now you can play around with various hyperparameters which you feel are good enough to improve accuracy on MNIST dataset.\n\nIf you a bit more adventurous, you can try replacing MNIST dataset with another sample dataset, such as CIFAR10. However, you have to download this data separately on your hard drive, extract it and access it via another python functions, something like below for your jupyter notebook.\n\nPlease do let me know your thoughts, questions under the comments section. I would really appreciate getting some feedback on this article & ideas to improve it.\n\nIn the meanwhile, Happy Thinking\u2026", 
        "title": "A Simple Multilayer Perceptron with TensorFlow \u2013 Pankaj Mathur \u2013"
    }, 
    {
        "url": "https://medium.com/the-circular-theory/why-complexity-and-simplicity-share-a-ubiquitous-circle-69df67b58ef2?source=tag_archive---------3----------------", 
        "text": "Any X and Y are joined (and separated) by a ubiquitous circle because an imaginary line is both diameter and circumference (the circle is conserved) (the circle conserves itself with any action).\n\nThus, a unit circle is the basis for everything, meaning, a line is a square is a cube is a circle. A matrix (any graphical representation) is defined by the circle (two-not-one is the basis for everything). Replication (redundancy and fungibility) is constant. Zero and one.\n\nThis is logical, although, not-always obvious. It simplifies complexity (if you take some time to think about it). Therefore, we already know everything we are ever going to know, where knowledge is the victim (and domain) of something we identify as \u2018mind.\u2019\n\nSo solving the mind-body problem is easy. Pi is the background state (the dimensionless coupling constant) for everything. (Complementarity is the basis for identity). Therefore, any verb is a noun, and vice versa. The two-state system is constant.\n\nTherefore, the subconscious state is what, in religion, we call \u2018God.\u2019 It echoes whatever we (it) see(s) around \u2018us.\u2019 Thus, pi is the only observer (an observer and an observation are joined and separated by a circle). This is a self-fulfilling prophecy (selflessness and selfishness are evenly distributed and constant 50\u201350). Conservation of the circle is the core dynamic in nature.", 
        "title": "Why Complexity and Simplicity Share a Ubiquitous Circle"
    }
]