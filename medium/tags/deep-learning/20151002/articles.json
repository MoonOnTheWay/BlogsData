[
    {
        "url": "https://medium.com/@JonRitter/novel-films-automated-animation-for-a-new-way-to-tell-stories-32f4fa81bd4b?source=tag_archive---------0----------------", 
        "text": "This product concept is one of the most challenging and fun ideas I have explored. It will require exponential progress on a number of technical fronts, but it could open up a whole new way to tell stories and to communicate ideas.\n\nThe basic idea is to turn the words of a novel (book, play or film script) into a movie using an AI system (e.g., IBM\u2019s Watson), natural language processing, automated (or accelerated) avatar generation, text to speech, and automated machinima / animation techniques.\n\nI will necessarily be using some shorthand to describe this business concept, so forgive me where the explanation sounds too simplistic. It either means I don\u2019t know what I\u2019m talking about or that I have chosen to write at a high level to accommodate the limits of a blog. You can choose as you deem appropriate.\n\nBasic framework for process of parsing a play via NLP [Admittedly way oversimplified]\n\nWhy this concept will not happen this week\n\nThis last part is where it all started to break down. My initial objective in researching this product idea was to attempt to determine whether the team that would be required to pull it together was more like a team of 3 PhDs working for 9 months (doable) or a team of 15 PhDs working for 4 years (less doable). At the time I was pushing hard on this idea, it seemed like the latter was the far more likely. Several of the key challenges that need to be overcome (in no particular order) are as follows:\n\nAll of that said, once we are able to overcome all (or at least most) of these challenges, there could be some amazing opportunities for new ways to tell stories. Once the movie has been created, changing out the characters (avatars) would be relatively straightforward. For a relaxing Friday night with friends, maybe you would use the Modern Family cast to play the characters of your favorite book. Imagine watching Gone With the Wind, but reversing the races of the key characters. Suddenly the story telling possibilities open up dramatically.\n\nFor a view of the current state of the art of this idea, you may want to take a look at the Plotagon app, Muvizu, Bot Colony or the robots created by the Russian company working on this idea. Anyone know their name? I recall that they were the furthest along on the text to movie concept, but I can\u2019t find them on the web anymore.\n\nConclusion\n\nAt the end of the day, this concept seems to be pretty well nestled in the university research phase. I still like the idea and will revisit the state of the art of the technical aspects of this challenging concept to be able to determine when combining the pieces may be more feasible. The author would enjoy hearing your thoughts.\n\nAnd finally, for you incredibly hearty souls who have made it all the way to the end of this piece and who may be interested in more reading on the subject, I offer a small glossary of relevant papers on the subject.\n\nNatural Language Processing\n\nAnnotation Tools and Knowledge Representation for a Text-To-Scene System, Bob Coyne, Alex Klapheke, Masoud Rouhizadeh, Richard Sproat, Daniel Bauer, Proceedings of COLING 2012 (2012)\n\nText to Scene Conversion\n\nText-to-Scene Conversion: An Introductory Survey, Shiqi Li, Tiejun Zhao, Hanjing Li, School of Computer Science, Harbin Institute of Technology, International Journal of Computational Science (2009)\n\nAVDT\u200a\u2014\u200aAutomatic Visualization of Descriptive Texts, Christian Spika, Katharina Schwartz, Holger Dammertz, and Hendrik Lensch, Vision, Modeling and Visualization (2011) [Paper suggests an alternative to wordsEye using parsed text (such as prepositions) for creation of more realistic 3D scene creation taking cues from text rather than external sources.]\n\nAutomating the Animation Process\n\nSceneMaker: Multimodal Visualization of Natural Language Film Scripts, Eva Hanser, Paul McKevitt, Tom Lunney, Joan Condell and Minhua Ma (2010)\n\nAutomatic Conversion of Natural Language to 3D Animation, PhD thesis by Minhua Ma, Faculty of Engineering, University of Ulster (2006)\n\nTowards Automatic Animated Storyboarding, Patrick Ye and Timothy Baldwin, University of Melbourne, Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence (2008)\n\nAutomating the Creation of 3D Animation From Annotated Fiction Text, Kevin Glass and Shaun Bangay, IADIS International Conference Computer Graphics and Visualization (2008)\n\nAutomating the Transfer of a Generic Set of Behaviors Onto a Virtual Character, Feng Huang, Xu and Shapiro, In Proceedings of the 5th International Conference on Motion in Games (MIG), Rennes, France (2012)\n\nEMOT\u200a\u2014\u200aAn Evolutionary Approach to 3D Computer Animation, Halina Kwasnicka and Piotr Wozniak, Wroclaw University of Technology, (2006)\n\nAcquisition of and Content Sources\n\nVSEM: An open library for visual semantics representation, Bruni, Bordignon, Liska, Uijlings, and Sergienya, University of Trento, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (2013)\n\nCollecting Spatial Information for Locations in a Text-to-Scene Conversion System, Masoud Rouhizadeh, Daniel Bauer, Bob Coyne, Owen Rambow and Richard Sproat\n\nText to Speech\n\nA na\u00efve, salience-based method for speaker identification in fiction books, Kevin Glass and Shaun Bangay, Rhodes University", 
        "title": "Novel Films: Automated Animation for a New Way to Tell Stories"
    }
]