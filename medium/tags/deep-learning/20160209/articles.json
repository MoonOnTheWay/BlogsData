[
    {
        "url": "https://medium.com/project-agi/some-interesting-finds-acyclic-hierarchical-modelling-and-sequence-unfolding-415735412003?source=tag_archive---------0----------------", 
        "text": "This week we have a couple of interesting links to share.\n\nFrom our experiments with generative hierarchical models, we claimed that the model produced by feed-forward processing should not have loops. Now we have discovered a paper by Bengio et al titled \u201cTowards biologically plausible deep learning\u201d [1] that supports this claim. The paper looks for biological mechanisms that mimic key features of deep learning. Probably the credit assignment problem is the most difficult feature to substantiate\u200a\u2014\u200aensuring each weight is updated correctly in response to its contribution to the overall output of the network\u200a\u2014\u200abut the paper does leave me thinking it\u2019s plausible.\n\nAnyway the reason I\u2019m talking about it is this quote:\n\n\u201cThere is strong biological evidence of a distinct pattern of connectivity between cortical areas that distinguishes between \u201cfeedforward\u201d and \u201cfeedback\u201d connections (Douglas et al., 1989) at the level of the microcircuit of cortex (i.e., feedforward and feedback connections do not land in the same type of cells). Furthermore, the feedforward connections form a directed acyclic graph with nodes (areas) updated in a particular order, e.g., in the visual cortex (Felleman and Essen, 1991).\u201d\n\nThis says that the feedforward modelling process (which we believe is constructing a hierarchical model) is a directed acyclic graph (DAG)\u200a\u2014\u200awhich means it does not have loops, as we predicted. Secondly, it is another source claiming that the representation produced is hierarchical (in this case, a DAG). The cited work is a much older paper\u200a\u2014\u200a\u201cDistributed hierarchical processing in the primate cerebral cortex\u201d [2]. We\u2019re still reading, but there\u2019s a lot of good background information here.\n\nThe second item to look at this week is a demo by Felix Andrews featuring temporal pooling [3] and sequence unfolding. \u201cUnfolding\u201d means transforming the pooled sequence representation back into its constituent parts\u200a\u2014\u200ai.e. turning a sequence into a series of steps.\n\nFelix demonstrates that high-level sequence selection can successfully be used to track and predict through observation of the corresponding lower-level sequence. This is achieved by causing the high-level sequence to predict all steps, and then tracking through the predicted sequence using first-order predictions in the lower level. Both levels are necessary\u200a\u2014\u200athe high level prediction provides guidance for the low-level to ensure it predicts correctly through forks. The low level prediction keeps track of what\u2019s next in the sequence.", 
        "title": "Some interesting finds: Acyclic hierarchical modelling and sequence unfolding"
    }
]