[
    {
        "url": "https://blog.alexlenail.me/ethics-are-too-complicated-for-words-85597f86b841?source=tag_archive---------0----------------", 
        "text": "Ethics fundamentally concern themselves with the rightness of decisions, so an ethical system can be formalized as some function on the domain of the infinite set of scenarios and decisions that maps each of those (scenario, decision) coordinates to a level of righteousness.\n\nEthical discussions traditionally concern themselves with the morally hazardous (situation, decision) subspaces and boundary conditions. The trolley problem, for example, is such a subspace, which helps us gauge the general shape of the \u2018ethics\u2019 function a person abides by.\n\nUnder this analogy, if we (temporarily) assume all decisions are either right or wrong, (discretizing the z-axis), learning ethics becomes isomorphic to the common task of binary classification from Machine Learning. Let\u2019s extend this analogy a little further and see what we find.\n\nDeontological Ethics, recall, are a simple analysis of the space of decisions: in any situation, some set of decisions is always wrong, independent of outcome. In the analogy to machine learning this system of ethics maps to the set of decision-stump-based models (decision trees, boosting, etc\u2026), some of the most na\u00efve models.\n\nUtilitarianism, evaluates likely outcomes of each decision, and ascertains which one to take based on an analysis of those predictions. That maps by analogy to a transform on the input space, and choosing between outcomes (and their probabilities) instead of actions. In machine learning, we call this a feature transformation, where the moral rectitude of a decision is nonlinear in the the input space but linear in the transformed space (which in this case is the predicted outcome of the decision from the situation).\n\nOnce you know whether a (situation, decision) will promote \u2018good\u2019, the ethics become very simple, according to Utilitarianism.\n\nBut decisions aren\u2019t made in either of these ways, nor should they. Neither of these models accurately nor satisfactorily approximates the distinction between right and wrong, or describes how humans face ethical choices. There\u2019s something missing, some amount of subtlety which these models don\u2019t seem to capture: they seem far too mechanical to cope with all of the grey areas of human existence.\n\nThe way humans respond to The Trolley Problem sheds some light on the nature of the gap between human decision-making and these two famous ethical approaches. Recall the first scenario: The Switch, in which the decision to save five results in the death of one. What would you do?\n\nMost people will flick the switch. However, hardly anyone claims they will throw the innocent Fat Man to his death, even though from a consequentialist standpoint, the outcomes are identical. If most would flick the switch (anti-Kant) but not push the fat man to his death (anti-utilitarian), then although both of these models seem plausible, a majority of polled humans don\u2019t abide by either of them. Many people devote themselves to coming into alignment with one of these systems, but I claim that misguided endeavor results from old, broken ethical rhetoric being allowed to retain a primacy it should have ceded long ago. These two systems, endlessly debated, do not actually drive our decision-making, nor should they.\n\nHow might a more complex machine learning model approach the task of discriminating between right and wrong (situation, decision) coordinates? Imagine for a moment a Neural Network\u2019s approach.\n\nWhat are the hidden units, the internal nodes, in this metaphorical algorithm? They are each unique transformations of the features of the (situation, decision) into deeper, less articulable, and yet more salient features. They are the concepts and ideals which as a whole represent the inexpressible notions of right and wrong.\n\nWhen confronted with the Trolley Problem, humans envision the scenario, pull from any experiences which are whatsoever similar by a variety of analogies and approximate values for a huge number of feature variables, making a great many predictions/assumptions about a great many potential decisions at once, and then choose from those the decision which they are most drawn to by some inarticulable intuition, which they may subsequently seek to justify, perhaps even using Utilitarian or Deontological rhetoric.\n\nHumans flick The Switch but refuse to push the Fat Man for reasons they can hardly express. We don\u2019t have the declarative semantic structures to handle all the complexity of our decision-making so we use metaphorical language, describing situations as \u201cgrey areas\u201d.\n\nBut we usually make very good decisions the vast majority of the time, because decision-making is a task for which we have an extraordinary aptitude, greater than any mechanistic model, greater than we can even describe in words. Deontological Ethics and Utilitarianism are not only wrong, but they dramatically undersell human potential.\n\nOur behavior has been meticulously refined for our entire lives performing an optimization algorithm machine learning researchers have yet to invent. Given a situation, we perform a series of deeply non-linear transformation of the input we receive from our senses; combinations of contextual cues and instinctual and learned motives and ideas provide an intuition of rightness, the source of our decisions.\n\nJeremy Bentham and Immanuel Kant were pioneers of ethical thinking in their time, but the fact that humans have flouted their teachings for centuries indicates to me that they must have missed something. Abstract Ethical arguments around these two simplistic paradigms only serve to undersell our own capacity for righteous action, and may lead us to worse decisions.\n\nMachine Learning, and the Neural Network algorithm in particular, provide a framework for re-examining the brain from a mathematically regimented standpoint, and furthermore, a language to grapple with some of the more sophisticated phenomena it produces, such as ethical decision-making.\n\nIn a parallel sense to how the brain inspired the Neural Network algorithm, the algorithm can inspire ways of understanding the brain.\n\nNext time you make a decision which causes you to think twice, try to examine the inner workings of your own mind, both conscious and unconscious, which might be driving your thinking. It might surprise you.", 
        "title": "The way we talk about Ethics is broken \u2013"
    }
]