[
    {
        "url": "https://medium.com/transmission-newsletter/3d-faces-generated-from-2d-photos-machines-learning-to-hand-write-more-7729c839e7f6?source=tag_archive---------0----------------", 
        "text": "Researchers at Pinscreen have published a paper on face digitization. They present a data-driven inference method that can synthesize a photorealistic texture map of a complete 3D face model given only a partial 2D view of a person in the wild. Crazy! Read the paper\u2026\n\nUdacity welcomed over 400 self-driving car enthusiasts to a private event in Mountain View, and videos from the talks have been uploaded to YouTube. There\u2019s an update on the Udacity open source self-driving car project, an awesome Q&A between Sebastian Thrun and Axel Gern, and a fantastic talk from George Hotz of Comma on their new project Neo. Enjoy!\n\nA great read from a group of researchers at Ohio State University who are aiming to achieve a 10x improvement on the standard hearing aid using deep learning. Such efforts could have transformational impacts for those who are hearing-impaired (~15% of adults). Be sure to listen to the audio! Read more\u2026\n\nFour fun deep learning experiments focussed on handwriting, created by members of the Google Brain team. Set aside 15 minutes to play with the interactive visualizations, including a deep learning model being asked to handwrite text. Read more\u2026\n\nThis open-source deep learning curriculum is meant to be a starting point for everyone interested in seriously studying the field. The author strove to put a list of resources that form a logical progression from fundamental to advanced. Enjoy!\n\nThis is a big deal! The law specifically allows vehicles that have no human controls\u200a\u2014\u200ano steering wheel, no pedals\u200a\u2014\u200ato be tested in Michigan. It makes clear that both automotive companies and tech companies are able to operate self-driving ridesharing vehicles. And it allows the sale of autonomous vehicles to the public once the technology has been tested and certified. Read more\u2026\n\nA worthwhile read on the techniques and tools that have come to the forefront in deep learning in 2016. The section on Generative Adversarial Networks is great! Read more\u2026\n\nA fun write-up on playing with generative models that focus on infusing motion into static pictures. The results, with the relatively small amount of data, are promising! Read more\u2026", 
        "title": "3D Faces Generated From 2D Photos, Machines Learning to Hand-Write & More"
    }, 
    {
        "url": "https://gab41.lab41.org/lab41-reading-group-swapout-learning-an-ensemble-of-deep-architectures-e67d2b822f8a?source=tag_archive---------1----------------", 
        "text": "Next up for the reading group is a paper about a new stochastic training method written by Saurabh Singh, Derek Hoiem, and David Forsyth of the University of Illinois at Urbana\u2013Champaign. Their new training method is like dropout, stochastic depth, and ResNets but with its own special twist. I recommend picking up the paper after going through this post, it is very readable and includes an excellent section on performing inference with a stochastically trained network that I will only touch on.\n\nAs you may recall, dropout works by randomly setting individual neuron outputs in a network to zero, essentially dropping those neurons from training and hence forcing the network to use a variety of signals instead of over-training on one. Stochastic depth (covered in a previous post) is similar, but instead of dropping neurons it bypasses whole layers! We can think of these operations a little more mathematically, but first I\u2019ll have to define some notation.\n\nI\u2019ll use block to mean a set of layers in some specific configuration (for example, a convolution followed by a ReLU), and a unit to be one of the computational nodes within the block (basically a neuron). X will be the input from the previous block, and F(X) will be the output from a unit within the current block.\n\nUsing this notation then, we can think about ResNets as consisting of blocks where ever unit in the block always reports X + F(X). A standard, feed-forward layer can be viewed in this framework as well, with each unit always reporting F(X). The paper includes a figure, which I\u2019ve edited and included below, showing feed-forward and ResNets in this scheme:\n\nThings become more interesting when we start thinking about stochastic training methods in this manner. Dropout can be thought of as randomly selecting the output for each unit from the following set of possible outcomes: {Zero, F(X)}. Likewise, stochastic depth can be thought of as randomly selecting between the outcomes {X, F(X)} for each block, so that every unit in the block returns X or F(X) together. Both of these training methods are shown in the figure below, which is again has been modified from the paper:\n\nSo now that I\u2019ve laid the groundwork, what does swapout add? Well, add isn\u2019t really the right word, swapout combines! It randomly selects from the four possible outcomes mentioned above: feed-forward, ResNet, dropout, and stochastic depth. They do this by allowing each unit to randomly select from the following outcomes: {Zero, X, F(X), X + F(X)}. Therefore, swapout samples from every possible stochastic depth and ResNet architecture, both including and not include dropout!\n\nIn addition to swapout, the authors define a simpler version called skipforward. Skipforward only allows units to select from the outcomes {X, F(X)}, that is limiting the choice to only stochastic depth and feed-forward. Both of these architectures are shown in the figure below, which is again from the paper with modification:\n\nOne of the dilemmas when using stochastic training methods is: how do I use the network at inference time? When training the network is constantly mutating as units pick different ways of behaving, but at inference time that network needs to be roughly static so that the same input will always yield the same prediction. We can make the network static in two ways:\n\nAlthough it seems like deterministic inference should be faster (because it does not require running multiple networks) it has several drawbacks. The first drawback is that you can not actually calculate the true expectation value for a swapout network, only approximate it. The second is the the fact that batch normalization\u200a\u2014\u200aone of the most powerful training methodologies, see our previous post for a summary\u200a\u2014\u200adoes not work with deterministic inference. The authors conclude (through testing) that stochastic inference works best.\n\nThe authors test swapout and skipforward networks against networks trained with stochastic depth, dropout, and various ResNet architectures. They conclude:\n\nOne final note on the paper: the way they define the various operations as random selections from a set of possible outcomes is, for me, a very intuitive way to think about them. I would love to see other papers use a similar framework for describing their network modifications!", 
        "title": "Lab41 Reading Group: Swapout: Learning an Ensemble of Deep Architectures"
    }, 
    {
        "url": "https://medium.com/intuitionmachine/design-patterns-for-self-driving-automation-81c2eebbd6ad?source=tag_archive---------2----------------", 
        "text": "Self Driving Cars are all the rage these days. When Udacity announced a \u201cself driving car engineering degree\u201d a few months ago, they were swamped with 11,000 hopefuls:\n\nI just happened to also be interested in this course. However, not necessarily from a self-driving car perspective, but rather from a more general perspective of self-driving \u201canything\u201d. So as my first steps at learning this vast emerging field, I am curating a set of design patterns in the field of what I call \u201cself driving automation\u201d. See: \u201cDesign Patterns for Self Driving Automation\u201d.\n\nI am hoping that this becomes a collaborative endeavor. The development of Design Patterns has historically been intertwined with the employment of a Wiki. In fact, one of the earliest Wikis, which likely pre-dates Wikipedia, was invented for the sole purpose of documenting Design Patterns.\n\nThe idea is that Design Pattern development is always a collaborative endeavor.\n\nSelf-Driving Automation is an entirely new field. It is usually described as Self-Driving Cars. Knowledge in this space is in its infancy and what better opportunity to start building a Design Pattern repository than in an emerging field. It is not only emerging, but also a complex field that involves the integration of a lot of different technologies and the real-time orchestration of these integrations. I hope in the next several months to be able to capture the knowledge into a form that is digestable by future practitioners.\n\nThe motivation as to why I use the word \u201cAutomation\u201d rather than \u201cCars\u201d is that I am seeking a more general application of this technology. A very glimpse of this idea of an automation that employs Deep Learning, Vision, Sensor Fusion and a whole lots of other technologies can be found in Amazon Go. Amazon Go isn\u2019t a car, it is a self-service retail store!\n\nThe concepts found in self driving cars, I believe is also transferrable to many other fields that have complex sensory environments and require realtime decision making. Design Patterns is the plan to disseminate knowledge in this exciting an emerging field of expertise.", 
        "title": "Design Patterns for Self Driving Automation \u2013 Intuition Machine \u2013"
    }, 
    {
        "url": "https://medium.com/ai-finance-start-ups-life/deep-learning-at-work-a9ed067a8707?source=tag_archive---------3----------------", 
        "text": "Intelligence is core to SmarterMe\u2019s vision in the future of work. Whether it is timely customer follow-up, next best actions suggestions, chatbot integration, or ranking for geo-located accounts, deep learning is the foundational technology that is used to power such IQs.\n\nTo answer this question, we ought to first understand supervised machine learning. In supervised machine learning, a prediction model is built based upon a set of input data ( features ) together with the corresponding output ( label). The set of input features is known as the training set; the model is a trained function such that it will give the best estimate or prediction for a new input. For the predicted output, it can either be a class that falls under a finite set of values ( e.g. male, female ) or it can be a real value ( e.g. housing prices ). To illustrate, one can build a model to predict the housing prices in the San Francisco Bay Area. The set of input features can be area footage, number of bedrooms, or the presence of a swimming pool. The training data will consist of the values of these features and the actual selling prices of the houses. Another example will be a credit loan risk model, with features such as age, income, loan size and existing debt, to predict the default rate.\n\nIn a deep learning neural network, there are nodes ( the neurons ) that are connected with each other. Additionally, a neural network contains multiple layers of neurons. The first layer is known as the the input layer composed of a set of input features. The output layer consists of neurons representing the different labelled classes. Multiple layers, known as the hidden layers, can be found between the input and output layers. The hidden layers aim to generate intermediate outputs, which in turn will serve as inputs for subsequent layers. Each hidden layer represents a model that needs to be trained. With this multi-layer approach, a deep learning network would find the best overall estimate function for a set of input features.\n\nConsider a handwritten digit recognition problem where by scanning images of digits, a model can be trained to determine the exact numerical digit. In this case, the pixel values of a 120x120 image can be used as the input features for the neural network. There will be a total of 14400 features as the input. Hidden layers can be set up to determine characteristics such as edges and lightness of the images. This model would not have been possible for some of the traditional supervised learning algorithms such as Support Vector Machines or logistic regression which can only support a limited number of input features.\n\nIn my previous blog post, we have identified that there is a correlation between the amount of email exchanges in various stages of a sales cycle and the closing of the deal. Based on this schedule, SmarterMe would remind the sales user to follow-up with the customers. Upon seeing the notification, the user can take the action to email, call or text the customer right at that time. However, by dismissing the follow-up reminder, the user can also provide the feedback that it is not the right time for follow-up.\n\nA deep learning model is created in which there are 120 input features, which are divided into 4 groups under the following category\n\nEach group has 30 features representing the number of interactions under the action type in each day of the last 30-day period.\n\nIn this same model, there will be 3 potential outputs ( \u201cDismiss Follow-up\u201d, \u201cSeen Follow-Up\u201d, \u201cTake action\u201d). They represent potential responses from the user. Notice that for the second option, it is equivalent to an no-op where the user has seen the notification but chooses not to respond.\n\nThere will be one hidden layer with 4 nodes, each representing the corresponding action type that includes email exchange, text exchange, call exchange and opportunity update.\n\nTo seed the model, we should place stronger weight for those days corresponding to the inflection points at which a pivotal result can be yielded. These nodes should be set up to point to the \u201cTake Action\u201d node.\n\nAs the user starts providing feedbacks ( or not ) upon seeing the follow-up reminders, these responses would be recorded and serve as the new training data to provide a better result.\n\nTo augment the training set, a group of selected customers are shown to the user as potential targets for follow-up. The specific actions taken by the user would be recorded, which would then be used to train and enhance the model. Over time, as more training data is collected, a function will be trained to predict whether a follow-up should be displayed to the user. Specifically, when the corresponding values for the interaction history for a contact for the last 30 days are used as the input for the neural network model, a recommended action for the follow-up will be shown to the user.\n\nThe Future is so Bright\n\nSeveral key strategies are used for this particular neural network model.\n\nWith this foundational architecture, other enhancements can be easily added. For example, we can expand the number of days beyond 30 days. Or instead of just recommending the user to follow up, a more specific suggestion such as asking the user to make the phone call can be made.\n\nWith such Deep Learning at work, the future of work is indeed very bright!", 
        "title": "Deep learning at work \u2013 AI, Finance, Start-ups, Social \u2013"
    }, 
    {
        "url": "https://medium.com/intuitionmachine/revue-issue-1-69a64d08418f?source=tag_archive---------4----------------", 
        "text": "Artificial Intelligence Just Broke Steve Jobs\u2019 Wall of Secrecy | WIRED\u200a\u2014\u200awww.wired.com\u00a0\n\n\u00a0Secrecy doesn\u2019t play in AI research. And as it happens, AI is more important to the future of tech giants like Apple than any other.\n\n10 Hot Consumer Trends 2017\u200a\u2014\u200aEricsson ConsumerLab\u200a\u2014\u200awww.ericsson.com\u00a0\n\n\u00a0Consumer trends come to light due to digital emmersion. The Ericsson ConsumerLab research gives you an insight in 10 hot consumer trends for 2017.\n\nNIPS 2016 Review, Days 0 & 1\u200a\u2014\u200aGab41\u200a\u2014\u200agab41.lab41.org\u00a0\n\n\u00a0Good morning, fellow machine learners. A few of us from Lab41 recently jumped the pond over to Barcelona, Spain, to see what machine learning and artificial intelligence stuffs we could glean from\u2026\n\n10 Exponential Growth Trends in Deep Learning\u200a\u2014\u200amedium.com\u00a0\n\n\u00a0Some people just don\u2019t grok it, no matter how hard you bang the table.Continue reading on Intuition Machine\u00a0\u00bb\n\n9 Misconceptions About Deep Learning\u200a\u2014\u200amedium.com\u00a0\n\n\u00a0We hear and read in the popular media about Artificial Intelligence (AI) all the time. We have movies about them. We hear about Elon Musk\u2026Continue reading on Intuition Machine\u00a0\u00bb\n\nElon Musk and DeepMind\u2019s AI training ground are being released to researchers | WIRED UK\u200a\u2014\u200awww.wired.co.uk\u00a0\n\n\u00a0The code and levels from DeepMind Lab are being made available on GitHub\n\nDo machines actually beat doctors?\u200a\u2014\u200aDr Luke Oakden-Rayner\u200a\u2014\u200alukeoakdenrayner.wordpress.com\u00a0\n\n\u00a0Spoiler: You know what they say about headlines that end with a question mark, right? If you ask academic machine learning experts about the things that annoy them, high up the list is going to be overblown headlines about how machines are beating humans at some task where that is completely untrue. This is partially because\u2026\n\nTop 10 AI failures of 2016\u200a\u2014\u200aTechRepublic\u200a\u2014\u200awww.techrepublic.com\u00a0\n\n\u00a0Recent developments in driverless cars, voice recognition, and deep learning show how much machines can do. But, AI also failed us in 2016, and here are some of the biggest examples.\n\nThe Only Way to make Deep Learning Interpretable is to Have it Explain Itself\u200a\u2014\u200amedium.com\u00a0\n\n\u00a0One of the great biases that Machine Learning practitioners and Statisticians have is that our models and explanations of the world should\u2026Continue reading on Intuition Machine\u00a0\u00bb\n\nCrafting Deep Learning Objective Functions now Obsolete\u200a\u2014\u200amedium.com\u00a0\n\n\u00a0Classical Machine Learning (ML) is based on setting a system with an objective function and finding a minimal (or maximal, depending on\u2026Continue reading on Intuition Machine\u00a0\u00bb\n\nDeep Learning is Non-Equilibrium Information Dynamics\u200a\u2014\u200amedium.com\u00a0\n\n\u00a0There are basically several camps studying neural like systems. There are the folks who insist on a biologically inspired approach. These\u2026Continue reading on Intuition Machine\u00a0\u00bb\n\nGitHub\u200a\u2014\u200aajarai/fast-weights: Implementation of Using Fast Weights to Attend to the Recent Past\u200a\u2014\u200agithub.com\u00a0\n\n\u00a0fast-weights\u200a\u2014\u200aImplementation of Using Fast Weights to Attend to the Recent Past\n\nGitHub\u200a\u2014\u200adeepmind/learning-to-learn: Learning to Learn in TensorFlow\u200a\u2014\u200agithub.com\u00a0\n\n\u00a0learning-to-learn\u200a\u2014\u200aLearning to Learn in TensorFlow\n\nGitHub\u200a\u2014\u200ajimfleming/recurrent-entity-networks: An implementation of \u201cTracking the World State with Recurrent Entity Networks\u201d.\u200a\u2014\u200agithub.com\u00a0\n\n\u00a0recurrent-entity-networks\u200a\u2014\u200aAn implementation of \u201cTracking the World State with Recurrent Entity Networks\u201d.", 
        "title": "Revue issue #1 \u2013 Intuition Machine \u2013"
    }
]