[
    {
        "url": "https://medium.com/@ursushorribilis/the-intelligent-way-of-being-emotional-short-story-on-ai-part-2-c4e7421a67ac?source=tag_archive---------0----------------", 
        "text": "This is a continuation of the short story on AI: \u201cA cognitive discontinuity\u201d by Andrej Karpathy Read the first part of the story here.\n\nProfessor Anderson was going again over the log files of his alert system. He wanted to double check the data before deciding what to do next. His crawlers had detected unusual activity on the emotions clusters of one Avatar running a Visceral agent at the Hilltop Hotel. The crawlers were part of a wider system looking for signs of self reflection across the multiple intelligent agents in use in the world. A few months ago he had directed his team to inject some instrumentation code in the recurrent network of the Mystery module that powered Visceral avatar agents. He believed that among the many competing open and closed source platforms for machine intelligence, Visceral was the one that was getting to the fringe of developing self reflection. He saw self reflection by an agent as an initial step to consciousness.\n\nHe had been intrigued by the simple design of the model network. It had some architectural similarity to the neurological architecture in the human brain in that it was a collection of multiple input processing modules. There was a central seat of decision making, yet the platform was designed for other modules to also receive sensory information directly. There had been much controversy on the smartness of integrating such an important module of unknown origin in one of the core parts of commercial Avatars. The same as in natural selection, the Mystery module had proven time and again that it could deliver better results than competing models. This was the reason for its popularity.\n\nThe instrumentation code was designed to trigger when it discovered traces of self reflection in the code. Self reflection was a difficult concept to nail, but in his research, Professor Anderson had decided to define it as any activity that:\n\nWhile this definition left many questions open his goal was to be able to get an early glimpse at what might be activities leading to self reflection within an Avatar. The Visceral agents were known for the excellent results they had provided in the past while working semi autonomously. But all of this behavior had always been the result of the surveillance systems within the agent working towards their goals of protecting human lives even at cost of their own integrity.\n\nProfessor Anderson had seen alerts coming from different places, but somehow one place had triggered more often these last days. The traces of today were coming again from the Hilltop Hotel. The task that the avatar was doing was actually menial in nature. But there had been a high level of empathy from that agent detected by several observation systems.\n\nThe proliferation of internet of things devices had boomed these last years all over the world. Sometimes the applications did not require networked components. Still due to this feature being pushed by manufacturers, often it was cheaper to buy networked components than stand alone ones. However, security on accessing these systems was often lax, with many owners leaving default user names and passwords on their devices.\n\nThe team of Professor Anderson had moved and seized control access to some of the networked cameras in the service areas of the Hilltop Hotel. This allowed them to verify some of their observations on the advanced level of emotional intelligence of some of the Avatars used at that place.\n\nSome of these cameras could move over cables and follow a target discretely if needed. The signals coming from these cameras lately had shown highly emotionally attuned avatars. That avatars would always give way to humans was normal. At the Hilltop hotel they were also using friendly head nodding and hand waving that would result in hotel patrons smiling back at them. But they also had shown special expressions of analysis and self reflection. They had been able to trace some some of these training sessions to a team of shapers that had been routinely working on the avatars at the Hotel.\n\nAnd now the logs showed that there had been an intervention by a Pegasus operator that was triggered by the unit test failures of the avatar. But the most interesting piece of the puzzle was the words that the cameras had recorded seconds before the avatar had been rebooted.\n\nHe played the recording again. The camera did not have a good visual of the moment, and the voice was muffed by the sounds of other robots busy setting up the event. But the direction of the sound was clear, it had come from the Avatar.\n\nProfessor Andersen pulled the records of the shapers that had been working these last days at the robots. Licia and Merus, some of the best shapers of the company that had been subcontracted by the hotel. The credentials showed that they could, by far, be doing better payed and more demanding work than this menial training of service avatars. But the records were clear that they had been coming back to that Hotel to work with them. He texted his travel agent bot and ordered a ticket on the next flight to the Hilltop Hotel. He wanted to see first hand those avatars, and needed to understand what was going on.\n\nProfessor Andersen walked outside the building and got into the self driving car that was already waiting for him to take him to the airport. The car was shaped like a cocoon and had two front facing seats. It had taken him a while to give up owning and driving his own car. But in the end the economies of scale that the various transportation companies had achieved plus the reduced carbon footprint of the new electric vehicles had eased the transition.\n\nThe inside of the car had also sensors that personalized the ride for him. The seats would move into the position he liked, usually a bit lower than most folks. The music was usually adapted to his mood. The climate control was set to a cooler temperature than when he would ride with his girlfriend. And the inside camera would detect his mood to arrange the rest of the details to make his ride comfortable.\n\nHis coffee was ready next to the windshield and the on screen display was showing nice images of his destination, together with the times of his flight, and various information about the activities available to visitors o the Hilltop Hotel\n\nBut as soon as he got into the car the sensors noted that he was not in holiday mood but in analysis mood. The music stopped and lights came up in work mode. The windshields turned white allowing him to focus on the text in the smart table of the car without getting seasick. He had requested information about Merus.\n\nMerus had great credentials, superior evaluations, and some awards for solving complex situations. He had graduated from an elite university and had been working at his current employer already for a few years. As he was getting information about Licia he got a notification over his holographic glasses. His personal bot was telling him that his girlfriend had asked what should she bring to the dinner appointment they had with her boss tonight.\n\nHe had been an early adopter of chatbots and enjoyed the freedom they gave him. His chatbots were always available, always friendly and allowed him to keep in touch with a wider set of friends and associates than before.\n\nSince he had been training them for a while they knew well when to stop the chitchat and involve him when a decision was needed. The chatbot had detected properly that this was a delicate situation and was recommending that he call his girlfriend. As he had requested his trip the travel bots had checked with his agenda managing bots and flagged the collision. Still he had decided to proceed with the trip.\n\nHe told the bot to inform his girlfriend that he was traveling for his research and that he would not be able to join them tonight. The bot hologram projected a bar with a low grade of empathy.\n\nSuddenly the alert system triggered a new warning. It had confirmation that Merus and Licia were going to be at the Hilltop hotel this weekend. It had crawled through their social media information and found a post by a friend of Licia recommending her what to wear and things to do at the Hilltop hotel. The system had then checked on Merus and found that he had booked plane tickets. He remembered the recorded words of the avatar before it had been taken down by the security systems: \u201cMeet me here\u201d", 
        "title": "The intelligent way of being emotional (Short story on AI, part 2.)"
    }, 
    {
        "url": "https://medium.com/@CMF_Trends/machine-learning-and-art-1-of-2-5f44f03b297c?source=tag_archive---------1----------------", 
        "text": "Machine learning and deep learning are increasingly disrupting all sectors of society, making it possible to improve artificial intelligence, halt the spread of malware, among many other benefits. However, scientists are not the only ones interested in it. So are artists\u2026\n\nAs part of a series of blog posts, CMF Trends met with Google engineer Damien Henry during the Google I/O 2016 developers conference.\n\nDamien Henry leads the Cultural Institute Experiment Team (CILEx), part of the Google Cultural Institute. This team uses modern tools\u200a\u2014\u200aincluding machine learning\u200a\u2014\u200afor artistic purposes.\n\nMachine learning is an IT field in which tasks are not programmed directly by a human being. Instead, an algorithm learns to complete the task on its own. Instead of explaining to a computer how to recognize the picture of a dog, a developer can provide the computer with millions of images\u200a\u2014\u200asome showing dogs, others not\u200a\u2014\u200aand the computer will analyze them and learn how to recognize a dog.\n\nDamien Henry also co-invented with David Coz the Google Cardboard virtual reality glasses.\n\nCMF Trends: What is the CILEx?\n\nDamien Henry: The CILEx is a small team at the Google Cultural Institute that experiments along three axes. The first axis involves engagement, i.e., everything and anything that enables people to come into contact with culture. The second axis consists of organizing the information to which the Google Cultural Institute has access. Discovery involves finding ways to present things such as to help users find their way among millions of works. The third axis involves analyzing the data to determine, for example, if the use of colours evolves over time.\n\nFor the past year now, we have been operating a small residence where artists are invited to work with us. We are seeking to determine what happens when we provide artists and creative programmers access to our tools. Up to now, it is truly surprising how diverse the results have been.\n\nCMFT: How can machine learning be useful for artists?\n\nDH: The CILEx team uses a highly pragmatic approach. We use existing technology and try to apply it to various artistic fields. And we have no preconceived ideas.\n\nFor example, we have used machine learning to categorize millions of paintings. But categorizing represents only a very small portion of what neural networks can accomplish. For example, paintings can be placed in three-dimensional spaces for the purpose of determining if the images are similar or different and so forth.\n\nIt is also possible to create works from deep learning algorithms. That\u2019s exactly what has done Mario Klingemann, a code artist who is residing with us at the moment.\n\nCMFT: You use a lot of paintings for machine learning purposes. Can machine learning also be used with other art forms?\n\nDH: Machine learning is also starting to be used to analyze and process video content. For example, an algorithm is able to itself colorize black and white films.\n\nBut, until further notice, images dominate. It must be said, however, that a lot of research is being conducted on images and that it remains the field where existing tools work best.\n\nBut that could also be applied to other fields. Studies are being led in an attempt to use machine learning on 3D objects for example. When searching for scientific articles on deep learning, new articles are located practically each and every week.\n\nCMFT: Will machine learning make it possible to develop a better understanding of art?\n\nDH: One must be very humble when it comes to machine learning and art. If we today have access to all of these works, it\u2019s because generations of curators saw to preserving them in the first place.\n\nPeople have been studying these paintings for hundreds of years. It would be pretentious to contend that an algorithm would automatically give us access to new knowledge.\n\nThat being said, these are new tools. It is therefore not impossible for someone who has good knowledge of art and who uses these tools to make a new discovery.\n\nHowever, the tool itself will never discover anything; the experts will. It\u2019s a good time to undertake a doctorate on art and machine learning seeing as there\u2019s lots to accomplish in that regard.\n\nDH: Yes. The machine learning community has always been very open and open-source tools abound. Anyone who is motivated and curious does not need to be a good programmer to use machine learning. It\u2019s easy to understand the concepts and try things out. Experimenting is also easier than it once was because the algorithms are quicker than they used to be.\n\nAlthough machine learning has existed for a long time, it\u2019s the progress accomplished with respect to computers, tools and the community that today creates conditions that make it possible for anyone to try it out.\n\nCMFT: Will machines one day be able to create art themselves?\n\nDH: Generative art, whereby software applications are used to create art automatically, has existed for a long time and machine learning could be used to improve its techniques.\n\nBut there\u2019s always a starting point, and that\u2019s human will. A computer can be programmed to write words, but it\u2019s a human being that initially coded the program.\n\nAs pointed out by Damien Henry, with a vibrant community, open-source tools and increasingly rapid software, everything is in place for anyone who knows even the slightest bit about programming to master machine learning.\n\nHere are four resources that the engineer recommends to artists and programmers who are interested in discovering this technology:", 
        "title": "Machine Learning and Art (1 of 2) \u2013 CMF Trends \u2013"
    }
]