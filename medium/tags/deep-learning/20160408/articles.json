[
    {
        "url": "https://medium.com/the-mission/7-innovative-companies-using-a-i-to-disrupt-their-industries-320597ad4631?source=tag_archive---------0----------------", 
        "text": "7 Innovative Companies Using A.I. to Disrupt Their Industries\n\nDespite predictions of a tech slowdown, big-name businesses like Facebook, Apple, and IBM are pouring resources into artificial intelligence (AI), changing the field and gaining the interest of venture capitalists everywhere. As investors actively seek innovative players in the AI space, more entrepreneurs are gravitating toward the technology as they build and grow their own companies.\n\nBusinesses such as Sentient, Context Relevant, and Scaled Inference all continue to work on their own multifunction AI platforms for computation and analysis, but this is only a small segment of the AI market. Multiple businesses now invest time and effort into purpose-built AI products. Here are a few of the businesses that are capturing attention in their respective industries for their AI work.\n\nWith total capital of $58 million, AI specialist Kensho is already showing just how serious investors are about the technology. Kensho\u2019s AI creation, Warren, has been called the \u201cSiri of the financial world.\u201d Investors can ask Warren natural-language questions and get responses, similar to the way IBM\u2019s Watson is being programmed to answer medical questions from health professionals. Currently, the software can answer basic questions on a limited number of topics but engineers are working on expanding Warren to account for grammatical and linguistic differences.\n\nLeadGenius uses a global network of more than 500 skilled researchers in 40 different countries to train a machine learning system for B2B sales. LeadGenius\u2019s data crawlers comb through websites, business directories, government filings, and credit agencies, much the same way Google\u2019s search engine crawls the web. LeadGenius researchers then clean, verify, and enrich that data, teaching the software what to look for the next time it searchers. LeadGenius also automates email outreach for sales teams by using a combination of human and machine intelligence to read sales emails and sort through the responses.\n\nThis San Francisco startup is serious about creating an AI-based medical diagnostics system that can accurately diagnose patients. Late last year, CIO reported that Enlitic plans to send engineers to dozens of medical imaging centers across the globe to install deep-learning algorithms. The goal is to learn as much as possible about reading medical images to create a system that will be able to interpret images from MRIs, CTs, ultrasounds, x-rays, and nuclear medicine.\n\nData is more important than ever to businesses, but working with pages of numbers can be complicated. Narrative Science\u2019s AI system will find a way to turn those numbers into readable content, then deliver that content to the professionals who need it. Called Quill, the technology is already being used to report on sports scores and earnings statements. Financial firms are now paying Narrative Science to put the technology to use in writing in-depth reports on stock performance for investors and regulators.\n\nX.ai\u2019s tool, Amy, schedules meetings for busy professionals. To put Amy to work, users simply copy Amy on an email where meeting times are suggested and Amy takes over, checking designated calendars and coordinating a time that works for both the user and the other party. Once a time has been chosen, Amy logs the time on the user\u2019s calendar and the meeting is set.\n\nA letter from an attorney can cost hundreds of dollars, but new AI software may be able to do the work for people. Legal Robot can help consumers by providing legalese for letters and reviewing contract language. While AI can\u2019t yet fight cases in court for clients, the software would make it easier for professionals to handle day-to-day business without having to consult a high-priced attorney.\n\nDIY tools have made it easier for anyone to create a website. However, the expertise that makes a professionally-designed website stand out can\u2019t be duplicated by design software. The Grid puts data to use in helping users create websites that bring results, giving them the information they need to know where to put a particular button or how to set up navigation on a certain type of site. Users enter information on what they\u2019re trying to accomplish and The Grid takes it from there.\n\nArtificial intelligence is an exciting new field of technology that investors in most industries are interested in supporting. As venture capitalists continue to search for businesses that are innovators in this space, more entrepreneurs will find ways to work it into their startups in addition to the many existing businesses exploring the field.", 
        "title": "7 Innovative Companies Using A.I. to Disrupt Their Industries"
    }, 
    {
        "url": "https://medium.com/planet-stories/a-colorful-harvest-in-rio-grande-do-sul-brazil-46b640eabb50?source=tag_archive---------1----------------", 
        "text": "The Earth\u2019s surface is constantly changing. Sometimes it\u2019s the result of natural processes, sometimes it\u2019s the result of human activity, and sometimes, it\u2019s both.\n\nOver the course of two months, Planet Labs satellites captured the transformation of this landscape in Brazil\u2019s southernmost state, Rio Grande do Sul. Dark green fields changed to a range of brown and yellow hues after harvest, and fallow fields turned vibrant green as another crop sprouted. The only areas that remained relatively unchanged were the roads and forest remnants along the boundaries between fields and winding stream beds.\n\nThese high-resolution images show details as fine as individual houses, and the trail left by a single tractor as it tilled a field. Over time, these large changes allow new types of analysis. For example, students at Wageningen University in the Netherlands used PlanetScope and RapidEye data to identify crop types in California\u2019s Central Valley. As the Planet Labs constellation grows over 2016\u2014getting closer and closer to daily coverage\u2014these insights will become commonplace.\n\nLearn more about how satellites are changing the agriculture industry.", 
        "title": "A Colorful Harvest in Rio Grande do Sul, Brazil \u2013 Planet Stories \u2013"
    }, 
    {
        "url": "https://medium.com/extremetech-access/nvidia-s-vision-for-deep-learning-ai-is-there-anything-a-computer-can-t-do-9b79d1fcff51?source=tag_archive---------2----------------", 
        "text": "It is nearly impossible to overstate the enthusiasm for deep-learning-based AI among most of the computer science community and big chunks of the tech industry. Talk to nearly any CS professor and you get an overwhelming sense that just about every problem can now be solved, and every task automated. One even quipped, \u201cThe only thing we need to know is which job you want us to eliminate next.\u201d Clearly there is a lot of hubris baked-in to these attitudes. But with the rapid advances in self-driving vehicles, warehouse robots, diagnostic assistants, and speech and facial recognition, there is certainly plenty of reason for computer scientists to get cocky.\n\nAnd no one is better at being cocky than Nvidia CEO, Jen-Hsun Huang. On stage, he is always something of a breathless whirlwind, and as he recapped the recent, largely Nvidia-powered, advances in AI, and what they portend for the future, it reminded me of a late-night infomercial, or perhaps Steve Jobs revealing one more thing. In this case, though, Nvidia has a lot more than one thing up its sleeve. It is continuing to push forward with its AI-focused hardware, software, and solutions offerings, many of which were either announced or showcased at this year\u2019s GTC.\n\nFor anyone who still thinks of Nvidia as a consumer graphcis card company, the DGX-1 should put that idea to rest. A $129,000 supercomputer with 8 tightly-coupled state-of-the-art Pascal-architecture GPUs, it is nearly 10 times faster at supervised learning than Nvidia\u2019s flagship unit a year ago. For those who want something a little less cutting edge, and a lot less expensive, Nvidia offers the M40 for high-end training, and the M4 for high-performance and low-power AI runtimes.\n\nIf you want access to these high-end GPUs you\u2019ll likely also need a high-end rig, like this Cipher model being shown off by Rave at Nvidia GTC 2016\n\nNvidia has supported AI, and especially neural net, developers for a while with its Deep Learning SDK. At GTC Nvidia announced version 5 of it neural network libraries (cuDNN). In addition to supporting the new Tesla P100 GPU, the new version promises faster performance and reduced memory usage. It also adds support for Recurrent Neural Networks (RNNs), which are particularly useful for applications that work with time series data (like audio and video signals\u200a\u2014\u200aspeech recognition, for example).\n\nCuDNN isn\u2019t a competitor to the big neural net developer tools. Instead, it serves as a base layer for accelerated implementations of popular tools like Google TensorFlow, UC Berkeley\u2019s Caffe, University of Montreal\u2019s Theano, and NYU\u2019s Torch. However, Nvidia does have its own neural net runtime offering, Nvidia GPU Inference Engine (GIE). Nvidia claims over 20 images per second, per watt for GIE running on either a Tesla M4 or Jetson Tx1. CuDNN 5, GIE, and the updated Deep Learning SDK are all being made available as part of an update to Nvidia\u2019s ComputeWorks.\n\nTensorFlow in particular got a big shout-out from Huang during his keynote. He applauded that it was open source (like several of the other tools are) and was helping \u201cdemocratize AI.\u201d Because the source is accessible, Nvidia was able to adapt a version for the DGX-1, which he and Google\u2019s TensorFlow lead Rajat Monga showed running (well, showed a monitor session logged into a server someplace that was running it).\n\nThe always-fascinating poster session in the GTC lobby featured literally dozens of different research efforts based on using Nvidia GPUs and one of these deep-learning engines to crack some major scientific problem. Even the winner of the ever-popular Early Stage Companies contest was a deep-learning application: Startup Sadako is teaching a robot how to learn to identify and sort recyclable items in a waste stream using a learning network. Another crowd favorite at the event, BriSky, is a drone company, but relies on deep learning to program its drones to automatically perform complex tasks such as inspections and monitoring.\n\nProgramming a problem-solving neural network is one thing, but for many applications the final product is a physical vehicle, machine or robot. Nvidia\u2019s JetPack SDK\u200a\u2014\u200athe power behind the Jetson TX1 developer kit\u200a\u2014\u200aprovides not just a Ubuntu-hosted development toolchain, but libraries for integrating computer vision (Nvidia VisionWorks and OpenCV4Tegra), as well as Nvidia GameWorks, cuDNN, and CUDA. Nvidia itself was showcasing some of the cool projects that the combination of the JetPack SDK and Jetson TX1 developer kit have made possible, including an autonomous scaled-down race car and autonomous (full-size) 3-wheeled personal transport vehicle, both based on work done at MIT.\n\nHuang also pointed to other current examples of how deep learning\u200a\u2014\u200amade possible by advances in algorithms and increasingly powerful GPUs\u200a\u2014\u200ais changing our perception of what computers can do. Berkeley\u2019s Brett robot, for example, can learn tasks like putting clothes away, assembling a model, or screwing a cap on a water bottle by simple trial and error\u200a\u2014\u200awithout explicit programming. Similarly, Microsoft\u2019s image recognition system has achieved much higher accuracy than the human benchmark that was the gold standard until as recently as last year. And of course, AlphaGo\u2019s mastery of one of the most mathematically complex board games has generated quite a bit of publicity, even among people who don\u2019t typically follow AI or play Go.\n\nIn line with its chin-out approach to new technologies, massive banners all over the GTC proclaimed that Nvidia\u2019s AI software learned to be a better driver than a human in \u201chours.\u201d I assume they are referring to the 3,000 miles of training that Nvidia\u2019s DAVENET neural network received before it was used to create the demo video we were shown. The statement reeks of hyperbole, of course, since we didn\u2019t see DAVENET do anything especially exciting, or avoid any truly dangerous situations, or display any particular gift. But it was shown navigating a variety of on and off road routes. If it was truly trained to do that by letting it drive 3,000 miles (over the course of 6 months according to the video), that is an amazing accomplishment. I\u2019m sure it is only a taste of things to come, and Nvidia plans to be at the center of them.", 
        "title": "Nvidia\u2019s vision for deep learning AI: Is there anything a computer can\u2019t do?"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/why-our-crazy-smart-ai-still-sucks-at-transcribing-speech-abb4c606f749?source=tag_archive---------3----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Why Our Crazy-Smart AI Still Sucks at Transcribing Speech"
    }
]