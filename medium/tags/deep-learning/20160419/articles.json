[
    {
        "url": "https://techstory.shma.so/deepjazz-b6b1443417b2?source=tag_archive---------0----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "deepjazz \u2013"
    }, 
    {
        "url": "https://medium.com/adatao-narratives/arimo-s-narrative-app-with-deep-learning-extension-shows-path-to-automate-200b-in-medicare-claims-477f7cfc9b0b?source=tag_archive---------1----------------", 
        "text": "When a healthcare provider submits a claim to Medicare, Medicare seldom pays the full amount. In fact, when the Center for Medicare and Medicaid Services (CMS) published its aggregated dataset containing 18M rows of Medicare claims data in 2013, the data showed that on average Medicare only pays about a third (37%) of the amount billed. Yet, while that 37% may be the average, it is not universal. The case for better Medicare claims adjustment is well known, just as high-profile cases of Medicare fraud are well publicized. According to research by The Economist, Medicare and Medicaid pay nearly $1T / year of which as much as $100B is fraudulent. And three of the top 20 of Medicare payment recipients revealed in the CMS data (more than $75M combined)\u200a\u2014\u200aDrs. Salomon E. Melgen, Asad U. Qamar, and Farid Fata\u200a\u2014\u200aface Federal Medicare fraud charges.\n\nDividing the claims into two groups\u200a\u2014\u200afraudulent versus legitimate\u200a\u2014\u200araises the question of whether data in one group has more in common with its own members than with members of the other group. If the answer is \u201cyes,\u201d then it also might be possible by way of a neural network to pick out the likely fraudulent claims on a cluster map. Furthermore, if a claim\u2019s appropriate adjustment amount is unknown, it might also be possible to estimate it with high accuracy by looking at its nearest neighbors on the map\u200a\u2014\u200aregardless of whether the claim is legitimate or not. That is the premise we tested using Arimo\u2019s Predictive Engine and Narratives software to build a Deep Learning (DL) model of the CMS dataset. In other words, could all the effort that goes into adjusting claims be done much faster by machine with much higher accuracy?\n\nSpanning two years, 2012\u20132013, the CMS dataset contains personally identifying information about healthcare providers and aggregated statistics concerning Medicaid claims, including:\n\nIf the fraudulent claims are consistently different from legitimate claims based on certain rules (even if unknown) then there might be patterns in the data that suggest such rules exist. One would expect, for example, that the adjustment amount\u200a\u2014\u200ai.e., the amount Medicare pays minus what it is billed\u200a\u2014\u200ashould be higher for fraudulent claims than for legitimate claims. As noted, on average Medicare pays 0.37 of a claim\u200a\u2014\u200aso the average adjustment downward, called the overcharge ratio, is 0.63 or:\n\nSo one rule to look for is that different claims have different overcharge ratios based on the amounts billed. Here we compare the distribution of overcharge ratios for the number of claims (CMS rows) overall versus by claim amounts:\n\nThe two graphs (left) do look very different. Higher claim amounts have higher overcharge ratios\u200a\u2014\u200asuggesting perhaps a diminishing-returns rule for bills \u201cinflated\u201d above a certain point. Also, notice that both graphs become discontinuous at about the 0.2 mark suggesting another rule of some sort kicks in there. Although these rules aren\u2019t known, there is evidence they exist and therefore potentially can be modeled to help distinguish fraudulent from legitimate claims. Further analysis reveals other evidence of hidden rules.\n\nNote, for example, how much more two specific types of healthcare providers were paid in cases where Medicare made little or no adjustment to claims (overcharge ratios <0.2). Of the 20 types ranked, internal medicine and family practice overwhelmingly were paid the most\u200a\u2014\u200aalmost $750M versus less than $300M for the remaining 18 combined.\n\nAnother rule seems to distinguish individual providers by amount paid\u00a0.\u00a0.\u00a0.\n\nAnd even more so if, again, only low overcharge ratios are considered\u200a\u2014\u200a0.2 or less\u200a\u2014\u200aas in this graph:\n\nAt $22M, Dr. Cockerill is the fourth largest receiver of Medicare, and yet $10M of his claims are barely adjusted at all by Medicare. All of the doctors on this list were paid large and largely uncontested sums by Medicare. Collectively the claims that overcharged less than 20% received a total of $3B.\n\nTo exploit these types of underlying rules we created a Deep Learning model to predict the overcharge ratio from claims data, excluding how much Medicare paid. We used the following network architecture to train and test a neural network on the CMS dataset:\n\nThe model achieved an accuracy of 85.6%\u200a\u2014\u200aconfirming that a machine could in fact perform Medicare claims adjustment with this level of accuracy, representing $200B in reduced payments with significantly reduced personnel costs.\n\nDisplaying a random sample of claims data also shows how high adjustment claims do tend to cluster. That means that given a claim whose appropriate adjustment amount is unknown, we can estimate it with high accuracy by looking at its nearest neighbors:\n\nThis kind of analysis can be used to distinguish regular claims from fraudulent ones and can be applied over a specific region, as in Florida, here:\n\nAgain, we see that the high adjustment claims tend to cluster together. Given a new, unprocessed claim, we could place it in this visualization to see what company it keeps.\n\nBut the model did more than just confirm that machine learning could adjust Medicare claims far faster and more accurately than current methods. It also confirmed that hidden rules often exist for distinguishing members of large datasets and that these rules can be modeled and applied even if not specifically known. Furthermore, it shows that there can be significant financial return in doing so\u200a\u2014\u200ain business cases that range from fraud detection, to assigning credit scores, to market segmentation, and more.\n\nThe key is Deep Learning\u200a\u2014\u200aor, more specifically, an ecosystem where the techniques of Deep Learning can themselves be robustly and economically applied in a practical way. Finding $200B only took 10 hours. And there\u2019s much more where that came from.", 
        "title": "Arimo\u2019s Narrative App with Deep Learning Extension Shows Path to Automate $200B in Medicare Claims\u2026"
    }, 
    {
        "url": "https://medium.com/@sujeetpillai/when-will-we-trust-ai-more-than-ourselves-33088bdaa729?source=tag_archive---------2----------------", 
        "text": "I just attended an excellent presentation by Dr. Lina Nilsson on Deep Learning application for data-driven healthcare. Great insights on how Deep Learning can be used for diagnostics, medical economics, drug discovery, etc. However it triggered some serious thought into how quickly we\u2019d be able to adopt these practices in the healthcare industry or other industries which impact public health and safety.\n\nLet me lay out the dilemma. Today some deep learning approaches have begun to perform better than humans in detecting cancerous cells from MRI scans. Project that scenario 5\u20138 years down the line and we\u2019ll have several algorithms that predict serious ailments better than fully trained doctors can. Hence there would be several edge cases where the best trained doctors in the world would rule out cancer whereas these algorithms would diagnose the patient as having cancer. In such scenarios, who do you trust? Do you trust the AI which has looked at millions of other patients and deduced the right characteristics of cancerous cells to detect it? Or do you trust the best trained doctors in the world who\u2019ve physically treated and diagnosed several thousands of potential cancer patients during their lifetime?\n\nWhat makes it worse is that the person responsible for assigning this trust is the doctor themselves who\u2019s in charge of the patient. Hence the doctor needs to mistrust his own learning and experience to trust this computer program who thinks they know better than him/her.\n\nThis wouldn\u2019t be such a big dilemma if it wasn\u2019t a life/death problem. If Facebooks AI mistags your friends face in your vacation photos, nobody dies. In healthcare diagnostics however it\u2019s a life-and-death question. If you disregard the algorithm and it\u2019s right, your patient dies. If you disregard your own experience and the algorithm is wrong, you put your patient through weeks/months of painful chemotherapy and expose him/her to various other threats.\n\nMy only solution is to run parallel chinese-walled diagnosis with algorithms and doctors for years and wait until the accuracy rates of these algorithms are beyond some threshold.\n\nBut then what is that threshold? When will we trust AI more than ourselves?", 
        "title": "When will we trust AI more than ourselves? \u2013 Thoughts from my walks \u2013"
    }, 
    {
        "url": "https://medium.com/@ricky.park/neural-net-of-things-nnot-58dcfcac4a2f?source=tag_archive---------4----------------", 
        "text": "I imagine that my grandchild plays and teaches a pet toy equipped dozens of GPUs. Is it feasible? I am not sure what will happen in the future.\n\nBut If there comes true, should we call it \u2018Neuron of Things(NoT)\u2019?\n\nWhere does AI of a pet toy come from? Is it from TensorFlow, Theano, Caffe, CNTK or a newcomer?", 
        "title": "Neuron of Things(NoT) \u2013 Ricky Park \u2013"
    }
]