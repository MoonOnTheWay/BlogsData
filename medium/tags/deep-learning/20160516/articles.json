[
    {
        "url": "https://gab41.lab41.org/classifying-arabic-sentiment-like-a-%D9%86%D8%A7%D8%B7%D9%82-%D8%A8%D9%87%D8%A7-%D9%83%D9%84%D8%BA%D8%AA%D9%83-%D8%A7%D9%84%D8%A3%D9%85-308682ee73ec?source=tag_archive---------0----------------", 
        "text": "For those of you wondering, I can\u2019t read or write Arabic. Neither can anyone else on our core team of developers and data scientists. This deficiency poses a problem since our project Sunny-Side-Up focused on sentiment analysis of tweets in foreign languages, including Arabic. Despite our team\u2019s illiteracy, we managed to achieve an F1 score of 0.753 after training and testing binary classifiers on 2.1 million Arabic tweets. We thought that was pretty nifty, so we wanted to share how we did it. Instead of focusing on accuracy, the main motivation behind this post is to walk through our methodology and show example results. We touch on classification performance towards the end, but this article focuses on details of our process so that others can build on it for additional work in this space. With that in mind, let\u2019s dive into the algorithms, assumptions, and engineering that made it possible.\n\nFor those of you who have read our previous blog posts on sentiment analysis, it comes as no surprise we wanted to use word vectors for Arabic sentiment analysis. For those needing a one-liner background, word vectors are a series of numbers that encode words\u200a\u2014\u200asuch as \u201cdog\u201d\u200a\u2014\u200aand the context in which they appear\u200a\u2014\u200asuch as \u201cwalk\u201d\u200a\u2014\u200ain a way that enables powerful mathematical operations. Basically, you feed a bunch of data into neural networks and the algorithms \u201clearn\u201d how all the different words relate to each other, generating a set of vectors that encode things like \u201cKing\u201d + \u201cWoman\u201d\u200a\u2014\u200a\u201cMan\u201d = \u201cQueen.\u201d To make that a bit more concrete, here is a slight preview showing the 200-dimensional vector that encodes the meaning of the word \u0625\u0630\u0643\u0627\u0631\u00a0:\n\nFor our purposes, the ultimate goal was to test the theory that word vectors could enable foreign sentiment analysis by people who don\u2019t speak the language (like us). As our last post on Chinese censorship demonstrated, that possibility exists since word vectors can serve as feature encoders for machine learning tasks like sentiment classification. The main issue for Arabic tweets, then, was to build a set of vectors that captured the meaning of enough Arabic words to be useful for predicting sentiment on unseen tweets. We had already somewhat benchmarked classification performance between Word2Vec and GloVe vectors, so for this task we (arbitrarily) chose the Word2Vec implementation in the Python library gensim.\n\nOur real first step, then, was to gather enough data for the neural nets to learn and encode meaningful context. To adequately test Word2Vec on Arabic tweets, we needed\u2026.Arabic tweets (of course). We wanted to use a dataset roughly the same fidelity as Stanford\u2019s Sentiment140, since that has become a de facto research set for Twitter sentiment analysis. Sentiment140 consists of a balanced set of 1.6 million positive- and negative-labeled tweets.\n\nAs most readers know, tweets contain many variations and abbreviations of both written and spoken text. Even in English, phrases like \u201cU B Cr8zy!\u201d dramatically increases the size of the vocabulary beyond what exists on other platforms. This unique Twitter vernacular exists for Arabic as well, perhaps more than other languages since Arabic encompasses several regional dialects AND Modern Standard Arabic (the formal written text) AND Romanized text like Arabizi. There are other variations, but the point is that \u201cArabic\u201d on Twitter includes a very broad and diverse set of words.\n\nSince we wanted to evaluate techniques that could tackle Arabic tweets, we needed a rough idea of how much data we needed to obtain the same fidelity as Sentiment140. According to the amazing computational linguistic expertise from University of Maryland\u2019s Center for Advanced Study of Language (CASL), they estimated we\u2019d need roughly six to seven times as much Arabic as English text to capture an equivalent slice of context to train our algorithms. The bottom line is we needed to obtain over 10 million sentiment-labeled Arabic tweets.\n\nTo obtain tweets, we turned to Twitter\u2019s public API, which provides a 1 percent sample of public tweets. We tapped into it for a few months and saved tweets with the Arabic language identifier (note: we\u2019re assuming, of course, that Twitter accurately identifies the correct language in the metadata). The great news is that Arabic text accounted for roughly 10 percent of our overall collection. The downside is the proportion with an acceptable sentiment label\u200a\u2014\u200aa topic we\u2019ll dive into next\u200a\u2014\u200awas very small, resulting in just over 2 million tweets.\n\nNot wanting to wait another several months to obtain 10 million labeled tweets, we decide to move on with the smaller dataset and turn our attention to the actual process of labeling, processing, and modeling the text.\n\nAfter collecting tweets, we initially had the notion of using Amazon\u2019s Mechanical Turk to crowdsource label generation, but that proved to be too time intensive and costly to pursue. Instead, we followed the lead of Sentiment140 and used emoticons as stand-ins for sentiment labels. The idea is that text containing \u201cpositive\u201d emoticons without any \u201cnegative\u201d emoticons is most likely conveying a positive sentiment. With several commonly-used emoticons in circulation, we had to decide which were positive and which were negative.\n\nBased on the Sentiment140 research paper, we started with eight commonly-used emoticons. The resulting dataset was a bit too small for our taste, so we decided to expand the label space with the lingua franca of Twitter\u2026.emojis! Lucky for us, they are a fairly well-researched extension of emoticons for sentiment labeling. Our main question, then, was what emojis we should include or exclude?\n\nNobody wanted to bias the results by picking emoticons based on favorites or some other arbitrary measure (can you imagine the horror if we included \u201cFace With Stuck-Out Tongue and Tightly-Closed Eyes\u201d?) Lucky for us, a recent December 2015 \u201cSentiment of Emojis\u201d paper outlined a methodology, scoring, and ranking for the sentiment of emojis. For our purposes, we selected the top 10 most often-used positive and negative emojis identified by the researchers. Adding a dash of analytic rigor, we also made our selections using a cutoff threshold\u200a\u2014\u200ato be included, each emoji needed a sentiment polarity score of at least 0.33 (on a scale from [0,1]) in its respective positive/negative category. The full list we used to search and label \u201cpositive\u201d and \u201cnegative\u201d tweets is below:\n\nOnce we collected and labeled the data, we needed a way to actually process Arabic text to feed into the Word2Vec algorithm. For those of you paying attention above, the first thing we did was remove those label-generating emoticons and emojis (as well as a few other things like retweet and username designators). The goal, of course, was to ensure the classifiers didn\u2019t learn those labels and instead would make classification decisions based on the textual content itself.\n\nNext, we needed a way to extract the content of each tweet. As our post on Chinese censorship and Anything2Vec described, Word2Vec builds a vector representation of a corpus of words. Therefore, the primary unit\u200a\u2014\u200aor token\u200a\u2014\u200afed into the algorithm is an individual word. The process of breaking a sequence of text characters into those individual tokens is called, naturally, tokenization.\n\nAs background, tokenization splits text on specific characters or sequences, which in English is most notably the space character (\u2018 \u2018). Other characters or symbols\u200a\u2014\u200asuch as the apostraphe and hyphen\u200a\u2014\u200aalso help divide words (depending, of course, on whether or not you want to split words based on those delimeters). For the purposes of our work, it is important to remember that tokenization depends on the structure and grammar rules of a particular language. Native speakers can take tokenization rules for granted (\u201cOf course the space character separates English words!\u201d), but those rules can be quite complex and arcane to non-speakers.\n\nSince Arabic is morphologically different than English, and since we can\u2019t read the language, we knew this tokenization step was crucial for our work. Basically, we knew we didn\u2019t want to end up with something like, \u201cTheP en I sMightier\u201d in Arabic (which of course we\u2019d have trouble detecting since we don\u2019t read the language).\n\nMost people involved in Arabic Natural Language Processing use Columbia\u2019s MADAMIRA since it is free for educational and research use. Our Lab\u2019s focus is open source, so we turned our focus to finding the best Arabic tokenizer with a more permissive (open source) license. After reaching the end of the Internets searching for \u201cArabic tokenizers\u201d (seriously, there\u2019s not much out there), we found two promising candidates:\n\nWith those two options, we generated one Word2Vec model for each tokenizer (to test the relative performance) on our entire corpus of 56 million Arabic tweets. We only kept words that appeared at least 10 times, which resulted in two different models with the following dictionaries:\n\nBased on the above emoticon + emoji labeling strategy, we filtered a set of 2.1 million tweets (1,067,972 within each label class) to evaluate binary classification performance. As is often the case, we used an 80/20 split of training and testing data. For each word vector model built from the two tokenizers, we benchmarked performance against additional word vectors:\n\nTo test classification performance, we chose three that represented commonly-used types of probabilistic, linear, and ensemble classifiers. Keeping in line with other work in this project, we used F1 score as our measure of accuracy.\n\nIt\u2019s hard to draw too many definitive conclusions from these results, but we have several few practical takeaways we\u2019d like to share:\n\nOverall classification performance was not our end goal. On the contrary, we wanted to provide a deep dive into our methodology while showing example outputs. We\u2019re confident someone could tweak something here or add something there and produce different results.\n\nWhile we don\u2019t want to dwell too much on the results, we are still impressed at how well a few Arabic non-speakers (with valuable language support) could pipeline data analysis tools and get usable results. By walking you through the data, NLP libraries, and labeling strategy, we hope this can serve as a foundation for additional work on Arabic sentiment analysis. If you\u2019re interested in building on our work, we invite you to check out the GitHub repository and take it from there!\n\nP.S. in case you\u2019re wondering, the article\u2019s title translates to \u201cClassifying Arabic Sentiment Like a Native Speaker.\u201d Now get out there and WordVec that sentiment!", 
        "title": "Classifying Arabic Sentiment Like a \u0646\u0627\u0637\u0642 \u0628\u0647\u0627 \u0643\u0644\u063a\u062a\u0643 \u0627\u0644\u0623\u0645"
    }, 
    {
        "url": "https://medium.com/@jamespereira/8-techniques-that-will-boost-your-memory-1dcbf29ed260?source=tag_archive---------1----------------", 
        "text": "As a trainer, one of my biggest challenges is figuring out how to help my training participants to retain more from what they learn.\n\nDon\u2019t we all wish we had photographic memories? And that friend or relative who seems to be able to recall minutest details from decades ago is probably blessed genetically or is an X-Men. And like the mutants, this gift is very rare.\n\nThese are eight techniques that I either use during my training sessions to boost memory retention and/or advise participants to do after the training.\n\nMany effective sales people will tell you that when they present their product\u2019s or service\u2019s features and benefits to prospects, while showing them an image or graph, the prospect\u2019s memory improves.\n\nMy sister is completing her PhD thesis on the topic of how reading aloud improves your writing skills. I guess reading aloud also ties in with memory in some strange physiological way, we haven\u2019t understood yet.\n\nI love this quote from Jim Rohn, which I share with participants who attend my Leadership training\u200a\u2014\u200a\u201cLeaders are readers.\u201d\n\nHere\u2019s some bad news for Amazon Kindle and you guys who love digital books. Recent studies show that reading a physical book improves memory much more than e-books.\n\nAll participants who attend my trainings always end up with painful hands because they do a lot of writing\u200a\u2014\u200aand who writes much anyway nowadays.\n\nAfter you\u2019ve read something, take time to summarise the salient points of what you learned.\n\nI suppose underlining and highlighting also aids in memory retention and my hunch is that it\u2019s not as effective as writing out a summary of what you learned.\n\nHere\u2019s more bad news for you digital aficionados\u200a\u2014\u200aresearch shows that writing on paper improves retention much more than writing on tablets or typing on computers. This the reason I still use printed work material for my participants rather than digital versions.\n\n3. Teach It or Demonstrate It\n\nWhen you teach someone what you\u2019ve recently learned, your brain remembers more. That\u2019s why teachers and lecturers (trainers too), tend to remember the details of what they teach after many repetitions.\n\nDemonstrating to others how something is done is a great memory enhancer. It\u2019s revision in practice. That\u2019s why the best surgeons are also teachers who have junior doctors attached to them.\n\nThis is very pertinent with regards to books. When you listen to something besides just seeing it in text or images, you remember more.\n\nThis is the reason audiobooks have become very popular. And many titles on Amazon exist in print, Kindle Books and Audible audiobooks. Kindle has become so popular that Amazon has created the Kindle Reading App that is free to be used with tablets, laptops and desktops.\n\nThere are some trainers who encourage their students to listen to their audio trainings at least 7 times to enhance retention.\n\nAfter you\u2019ve learnt something, immediately try to put it to practice. Whoever said \u201cknowledge is power\u201d was sadly mistaken. Tony Robbins got it right when he said, \u201cKnowledge is not power, execution is.\u201d\n\nIn my training sessions, participants always get to practice a skill immediately after it\u2019s taught. This greatly improves their confidence to try it out in their work situations.\n\nHere\u2019s some stats from the Learning Pyramid that substantiates everything I\u2019ve mentioned above:\n\nAs much as we all hated revisions in school, in the working world, repetition doesn\u2019t bore you but makes you skilful. Once again I quote Tony Robbins, \u201cRepetition is the mother of skill.\u201d\n\nResearch indicates that we forget 46% of what we learn, the following day!\n\nOne study advocates that to ideally remember, we must repeat our learning every 3 days. So revise, revise, revise.\n\nThere are several dietary supplements that clinical studies show improve your memory. One is gingko biloba. The other is cocoa flavanols. Both have been used for thousands of years. The former by the Japanese and the latter by the Mayans.\n\nThis is probably the most controversial of all the techniques. After numerous studies, science still doesn\u2019t have any conclusive proof that music improves memory.\n\nSome people say Vivaldi helps infants and children in their studies and these are probably merely anecdotal. Some will even swear that one of his Four Seasons ensembles if more effective than the other 3.\n\nRecently, I got hold of a music CD that helps people concentrate while studying and it\u2019s music with binaural beats. I use it sometimes during training sessions to help participants improve their memory but I don\u2019t the statistics yet.\n\nTake your pick of the method you like the best. Ultimately, you can\u2019t just depend on one method and you have to use several of the techniques. This is what we call blended learning\u200a\u2014\u200ausing different techniques to learn. No one method is superior to the others.\n\nI would love to hear your success stories or other experiences in using these techniques.", 
        "title": "8 Techniques That Will Boost Your Memory \u2013 James Pereira \u2013"
    }
]