[
    {
        "url": "https://medium.com/@erikhallstrm/work-remotely-with-pycharm-tensorflow-and-ssh-c60564be862d?source=tag_archive---------0----------------", 
        "text": "Wouldn\u2019t it be awesome to sit at a caf\u00e9 with your laptop, creating large neural networks in TensorFlow, crunching data with speeds of several terraFLOPS, without even hearing your fan spinning up? This is possible using a remote interpreter in PyCharm, and you get almost the same experience working remotely as working locally.\n\nHowever, this is currently only possible in PyCharm Professional (Community Edition will not do). If you are a student your University should have an arrangement so you can download it for free, otherwise you\u2019ll have to buy it. Here is how I set it up from scratch (you may want to skip some of the steps):\n\nThis is your stationary remote machine, perhaps fitted with one or several state-of-the-art GPU:s from Nvidia! (I don\u2019t like the current deep learning monopoly, but TensorFlow can only use Nvidia GPUs). First let\u2019s install the latest Ubuntu, I recommend the desktop version, you can always kill the GUI-service later to free up graphics memory. Connect it to Internet and check you LAN IP-address by opening up a terminal typing . I will assume it is in the instructions later.\n\nIn order to be able to communicate with your crunching-machine, you need to install SSH on it. Open up a terminal on your stationary computer and get it:\n\nEnable SSH X11-forwarding so that you can plot things, open the configuration file like this.\n\nThen locate the row that says\n\nSimply remove the hash-sign to uncomment the line, save and close the file.\n\nNext install the graphics drivers, they are usually proprietary, so you need to add a new repository to your package manager. What package you\u2019ll need depend on your graphics card and Ubuntu version. As of writing nvidia-367 is the latest one, see more on this page.\n\nNow it\u2019s time to install Cuda toolkit and and cuDNN, which are required to run TensorFlow. They are available from Nvidia\u2019s webpage, and to download cuDNN you are required to register. As of writing Cuda 8.0 and cuDNN 5.1 are the latest versions. For Cuda I prefer using the built in package manager, it makes it easier to keep track of what you have installed:\n\nMake sure that the symlink is set up correctly:\n\nThis is how to extract the cuDNN headers and copy them into the Cuda folder, and make them readable in the terminal (some of the filenames may be different for you):\n\nFinally add the environment variables you will need, append them to your\u00a0 file and then source it:\n\nAnd then install GPU enabled Tensorflow, check the version you need on this page ( is different for different systems):\n\nVerify that the installation is working by typing the following in your terminal:\n\nYou should get output similar to this if you have installed it on a GPU enabled system:\n\nDid it work? Great! Let\u2019s move on to your laptop\n\nOpen up your laptop and connect it to the same local network as your stationary machine.\n\nSo I\u2019m using a Macbook and it allows me to install programs with a very nice package manager called Homebrew. Even desktop apps can easily be downloaded with Homebrew Cask.\n\nGet what you need, including the PyCharm IDE.\n\nGenerate a SSH key-pair by executing the command below and then walk trough the guide (if you haven\u2019t done this already):\n\nNow copy the key to your remote machine so you can connect to it without typing a password every time. On the first time doing this you need to authenticate yourself with the password of your remote machine:\n\nEnable compression and X11-forwarding (useful for plotting data) by appending this to your file on your local machine.\n\nVerify that everything is working by connecting to your remote machine from your laptop.\n\nWhile still logged in, you should disable password login on your remote machine for security reasons. Open the configuration file with your favorite command-line editor.\n\nAnd uncomment the following line by removing the hash-sign:\n\nRestart your SSH server while still logged in on your remote (you have to authenticate yourself again).\n\nThe final thing you should do while still logged in with SSH on your remote is to find your display environment variable. This will be used later for plotting, I usually get .\n\nRemember the output of this command, we will use it later.\n\nThis is the funny part, how we can set up the remote interpreter so you execute the scripts on your remote machine. Let\u2019s get started, start up PyCharm and create a new Python project.\n\nOpen \u201cPreferences > Project > Project Interpreter\u201d. Click on the \u201cDotted button\u201d in the top-right corner and then \u201cAdd remote\u201d.\n\nClick on the \u201cSSH Credentials\u201d radio-button and input your information. Select \u201cKey pair\u201d on the \u201cAuth type\u201d, and select the \u201cPrivate Key file\u201d. It should be located in .\n\nClick on \u201cOK > Apply\u201d. Notice the \u201cR\u201d for remote on the Project Interpreter.\n\nThe remote interpreter can not execute a local file, PyCharm have to copy your source files (your project) to a destination folder on your remote server, but this will be done automatically and you don\u2019t need to think about it! While still in the \u201cPreferences\u201d pane, open \u201cBuild, Execution, Deployment > Deployment > Options\u201d. Make sure that \u201cCreate empty directories\u201d is checked. This way PyCharm will automatically synchronize when you create folders:\n\nNow go back to \u201cBuild, Execution, Deployment > Deployment\u201d and click on the \u201cPlus button\u201d, select \u201cSFTP\u201d and give a name to your remote. Click on \u201cOK\u201d:\n\nSet up the connection by first typing the IP of your remote in \u201cSFTP host\u201d, then selecting \u201cKey pair\u201d on the \u201cAuth type\u201d, and finally selecting the \u201cPrivate Key file\u201d. It should be located in , as shown in the screenshot below. You may then click on \u201cTest SFTP connection\u201d. Given that you can successfully connect you should set up mappings. If you\u2019d like you can click on \u201cAutodetect\u201d beside the \u201cRooth path\u201d, it will then find the place of your home directory on the remote. All paths you specify after this will be relative to this home path. Then go to the \u201cMappings\u201d tab.\n\nAs soon as you save or create a file in your local path, it will be copied to the \u201cDeployment path\u201d on your remote server. Perhaps you want to deploy it in a folder as shown below. This will be relative to your \u201cRooth path\u201d specified earlier, so the absolute deployment path will in our case be be :\n\nNow we are finished with the preferences, click on \u201cApply\u201d > \u201cOK\u201d, and then click \u201cTools > Deployment > Automatic Upload\u201d and confirm that it is checked:\n\nTo do the initial upload, right-click on you project folder in the project explorer and click on \u201cUpload to remote\u201d:\n\nYou should get a \u201cFile transfer\u201d tab on your bottom pane where you can see all the progress:\n\nThen click on \u201cTools > Deployment > Browse Remote Host\u201d. Drag and drop the window just beside the Project tab to the left. That way it will be really simple to switch between your local and remote project.\n\nThese deployment settings will work seamlessly as soon as you save and run a file, it is done so quickly you won\u2019t even notice it.\n\nOpen \u201cPreferences > Build, Execution, Deployment > Console > Python console\u201d and select the \u201cPython interpreter\u201d to be your remote one. Next click on the \u201cDotted button\u201d and input the required environment variables that we added before to when we set up the server. Notice that we also added a value to the \u201cDISPLAY\u201d variable we found out earlier when connecting to the server with SSH:\n\nThen go back to \u201cBuild, Execution, Deployment >Deployment > Console\u201d and select \u201cAlways show the debug console\u201d. It will be very handy when we\u2019re debugging:\n\nCreate a simple test-file called in your project, just containing this.\n\nNow go to \u201cRun > Edit Configurations\u2026\u201d Click on the \u201cPlus button\u201d and create a new Python configuration. Name it and select the script to run:\n\nNow enter the required environment variables as before. Tips: You can copy them all from the console settings we specified earlier, by using Ctrl+A and then the copy/paste buttons in the lower left corner. You access them by clicking the \u201cDotted button\u201d just to the right of the \u201cEnvironment variables\u201d line.\n\nNow we should be all done, it\u2019s time to test our setup. First open a terminal and make sure that you have at least one SHH channel with X-forwarding connected your server. If you have had a connections open for a while, you may have to exit and restart them:\n\nThen open the \u201cPython Console\u201d in the lower bar in PyCharm and type . Then you may type to verify that you are actually executing the commands on your server! This is what the output should be:\n\nNow go over to your script and select \u201cRun > Run\u2026\u201d from the top toolbar. Select your newly create run configuration \u201cTest\u201d. It should output something like this:\n\nLet\u2019s do some plotting, change your file to this:\n\nAnd then run it again with your run configuration \u201cTest\u201d, you should get this plot.\n\nThe plot is actually done on your remote server, but the window data is forwarded to your local machine. Notice that we changed the backed with , because it\u2019s a X11-supported display backend. You can read more about Matplotlib backends here. You can also change the default behavior in your -file. Remember that you need to have at least one open SSH-connection in a separate terminal to get this to work, with the correct value of the environment variable. If it didn\u2019t work try to restart your SSH connection.\n\nFinally do some debugging, click on the left bar to put a breakpoint, then go \u201cRun > Debug\u2026\u201d and select the \u201cTest\u201d configuration. You will see that the execution has halted and you are debugging your script remotely.\n\nIn order to access your machine over the internet you have to forward ports on you home router, that is different for different vendors. I recommend forwarding a different port than 22 on your router. There are plenty bots out there trying to hack in, and they will check that port by default, and might slow your connection (although you are pretty secure since you have turned of password authentication). So you could perhaps forward port 4343 on your router to port on IP (the default IP of our remote in this tutorial). Also to speed up the plotting you may change to a faster encryption.\n\nNext, let\u2019s do some more TensorFlow, perhaps experimenting with matrix multiplication on the CPU and GPU? (coming soon)", 
        "title": "Work remotely with PyCharm, TensorFlow and SSH \u2013 Erik Hallstr\u00f6m \u2013"
    }, 
    {
        "url": "https://medium.com/@erikhallstrm/hello-world-tensorflow-649b15aed18c?source=tag_archive---------1----------------", 
        "text": "In this tutorial we will do simple simple matrix multiplication in TensorFlow and compare the speed of the GPU to the CPU, the basis for why Deep Learning has become state-of-the art in recent years.\n\nIt\u2019s a framework to perform computation very efficiently, and it can tap into the GPU (Graphics Processor Unit) in order too speed it up even further. This will make a huge effect as we shall see shortly. TensorFlow can be controlled by a simple Python API, which we will be using in this tutorial.\n\nWhen a native computation is done in many programming languages, it is usually executed directly. If you type in a Python console, you will immediately have the result. Running a number of mathematical computations like this in an IDE also allows you to set breakpoints, stop the execution and see intermediate results. This is not possible in TensorFlow, what you actually do is specifying the computations that will be done. This is accomplished by creating a computational graph, which takes multidimensional matrices called \u201cTensors\u201d and does computations on them. Each node in the graph denotes an operation. When creating the graph, you have the possibility to explicitly specify where the computations should be done, on the GPU or CPU. By default it will check if a GPU is available, and use that.\n\nThe Graph is run in a Session, where you specify what operations to execute in the -function. Data from outside may also be supplied to placeholders in the graph, so you can run it multiple times with different input. Furthermore, intermediate result (such as model weights) can be incrementally updated in variables, which will retain their values between runs.\n\nThis code example creates pairs of random matrices, clocks the multiplication of them depending on size and device placement.\n\nYou see that the GPU (a GTX 1080 in my case) is much faster than the CPU (Intel i7). Back-propagation is almost exclusively used today when training neural networks, and it can be stated as a number of matrix multiplications (backward and forward pass). That\u2019s why using GPU:s are so important for quickly training deep-learning models.\n\nIn the next post we will use TensorFlow to create a recurrent neural network.", 
        "title": "Introduction to TensorFlow \u2014 CPU vs GPU \u2013 Erik Hallstr\u00f6m \u2013"
    }, 
    {
        "url": "https://medium.com/@devnag/seq2seq-the-clown-car-of-deep-learning-f88e1204dac3?source=tag_archive---------2----------------", 
        "text": "Let\u2019s start by diving into one of the problems that led to seq2seq\u200a\u2014\u200aautomated translation. Suppose you want to translate words from one language (say, English) to another language (say, German). You can\u2019t just map word-token to word-token, obviously; some tokens disappear in the translation, others appear from nowhere, some are highly context-dependent on the tokens around them, and some tokens converge or diverge like my personal favorite, \u201cRechtsschutzversicherungsgesellschaften\u201d (or, in English, \u201cinsurance companies that provide legal protection\u201d). Easy examples like this drive home the point that translation just isn\u2019t a token-level function.\n\nNow, a professional literature translator would say that translation isn\u2019t a sentence-level function, either (it\u2019s worth noting that both Nabakov and Borges translated the works of others, and considered it an act of literary creativity in its own right)\u2014but at least this simplification gets closer to the task.\n\nNow that we\u2019ve decided on sentence-level translation as the task, we have to ask ourselves\u200a\u2014\u200ahow can we possibly model that with deep learning? Whatever architecture you pick (feedforward vs. recurrent, deep vs. shallow, etc), you still have to pick the size of the input layer, the size of the output layer, and all the machinery within. But sentences are all sorts of different lengths! Do you build different networks for each length (say, one network that translates all of the 12-word sentences in English into 8-word sentences in German, and so on)? That seems absurd, and it is. Don\u2019t do this.", 
        "title": "seq2seq: the clown car of deep learning \u2013 Dev Nag \u2013"
    }, 
    {
        "url": "https://medium.com/@GarvitBhada/deep-learning-part-2-ccc2753a343a?source=tag_archive---------3----------------", 
        "text": "In this part of the blog, I will focus more on the Deep Learning tools which can help in performing Econometrics\u2019 tasks. Let\u2019s start with Recurrent Neural Networks or RNNs.\n\nAn RNN can be used for time series analysis. An RNN takes the output of a layer and feeds it back into the same layer. We usually have only a single layer in the entire network, however, since the feeding process goes on in different time periods, we can consider the single layer as a composition of multiple layers over different time periods. Let\u2019s clear the concept using a figure.\n\nIn the above figure, h (at different time periods) represents the output while X (at different time periods) shows the inputs. Now, the progression we see from left to right is for different time periods, but the layer that is being used is only one. The output at any time period is used as the input in the next time period and into the same layer.\n\nA major benefit of RNNs is that it can take a sequence of values as inputs and can output a sequence of values. If we stack a lot of RNNs together, we encounter the problem of vanishing gradient once again. A solution to that is the Gating technique, which we will not discuss here.\n\nAnother Neural Network which can be used for econometric methods includes Autoencoders, which is a type of RBM( Restricted Boltzmann Machine). Autoencoders help figure out the underlying structure of the data set.\n\nAutoencoders encodes the unlabeled inputs which can be decoded to form an accurate output. We try to minimize the nodes ( see figure below ) in the hidden layer and at the same time we want to preserve the information available in the inputs.\n\nAutoencoders have proven themselves in the application of Principal Component Analysis and studies have proven that they perform better than the traditional methods.", 
        "title": "Deep Learning ( Part 2 ) \u2013 Garvit Bhada \u2013"
    }, 
    {
        "url": "https://medium.com/variables-weekly/i-came-in-like-a-wrecking-ball-95fe6cbdd554?source=tag_archive---------4----------------", 
        "text": "Hello guys, welcome to this week\u2019s entry into Variables, Weekly. I\u2019m sure everybody knows by now that the Trumpocalypse is here. So I will not bore you with half baked rhetoric and some boring synopsis of the matter seeing as I am not an expert and even so called experts have been biting their tongues of recent.\n\nSo unto stories I followed this week excluding of course, the big elephant in the room.\n\nHow would you define modern day intellectualism? This Article takes a look at the life of Stuart Hall. Long but interesting if you\u2019re into this sort of thing\u200a\u2014\u200aLink\n\nEvery other week, we get news of a new startup promising to change the world of computing and revolutionise how we interact with Technology. Introducing Magic Leap\u200a\u2014\u200aLink\n\nHow The Concept of Deep Time is Changing\u200a\u2014\u200aLink\n\nHere is the summary of the article:\n\nDid you know activities related to humans have slowed down the rotation of the earth? Yeah you should take a look at the article.\n\nDonald Trump\u2019s ascent to power is a symptom of a much larger malaise sweeping through the West. Read how Europe\u2019s far right is ruthlessly re-branding itself\u200a\u2014\u200aLink\n\nEver wondered how deep learning systems work? Here, help yourself\u200a\u2014\u200aLink\n\nBrowsers, not apps are the future of mobile?\u200a\u2014\u200aLink\n\nDid Slack really not see Microsoft coming?\u200a\u2014\u200aHere\n\nBack to the big elephant in the room, I randomly picked op-eds that speak about my thoughts infinitely better than I would have. Feel free to disagree.\n\nRead this to check out Trump\u2019s policies and where he stands on a myriad of issues\u200a\u2014\u200aLink\n\nDid the Democratic party fail its following?\u2014 Link\n\nSee you next week. Peace and love.", 
        "title": "I Came In Like A Wrecking Ball \u2013 Variables, Weekly \u2013"
    }
]