[
    {
        "url": "https://medium.com/@awjuliani/simple-softmax-in-python-tutorial-d6b4c4ed5c16?source=tag_archive---------0----------------", 
        "text": "Softmax regression is a method in machine learning which allows for the classification of an input into discrete classes. Unlike the commonly used logistic regression, which can only perform binary classifications, softmax allows for classification into any number of possible classes. In this post I walk through the construction of a basic softmax classifier using python and ipython notebook. I show how to conduct digit recognition on the MNIST database, but the code can be applied to any number of machine learning problems. Feel free to reuse this code wherever may be helpful!", 
        "title": "Simple Softmax Regression in Python \u2014 Tutorial \u2013 Arthur Juliani \u2013"
    }, 
    {
        "url": "https://medium.com/@gitter/building-online-communities-deeplearning4j-c8fe2008559f?source=tag_archive---------1----------------", 
        "text": "We asked Adam & Chris, the founders of Deeplearning4j\u200a\u2014\u200afirst commercial-grade, open-source, distributed neural net library written for Java and Scala, with one of the most active communities on Gitter\u200a\u2014\u200ato share their thoughts, experiences and lessons learned on open source community building. Find out what they say and check out the deeplearning4j channel on Gitter.\n\nTell us about a little bit about yourself and the Deeplearning4j community. How did it all begin?\n\nWe started building Deeplearning4j in late 2013. Adam had been involved with machine learning for about four years, at that time, and deep artificial neural networks were looking more and more promising. The first network in Deeplearning4j was a restricted Boltzmann machine, since that was the net that Geoff Hinton had come up with back in 2006, which was the turning point in the field. I was working for another startup doing PR and recruiting, and had previously worked as a journalist, so I took care of the documentation (and still do), since we believed that proper communication was key to making open-source code valuable.\n\nWhat are they main issues discussed in the deeplearning4j channel?\n\nThe main issues used to be installation. Engineers in the community taught us a lot about how to write clearer instructions, and how to make the code and experience better. If we hadn\u2019t had that feedback loop, Deeplearning4j would be worse. Open source communities are an amazing for quality control! The sooner you fix an issue, the less demands you get from the community about that issue. It\u2019s a great incentive to move quickly.\n\nNow the main issue is loading data and neural net tuning. We are working on communicating better about that, and about making the framework better, so that ETL and tuning get easier. Finally, there are a lot of basic questions about machine- and deep-learning. Many software engineers have figured out that deep learning and machine learning are really powerful tools, so they\u2019re trying to grasp new ideas. We\u2019ve written a lot of introductory material, and we point them to various web pages where those ideas are explained.\n\nWhat common goals do you have as a community?\n\nThe community is centered around Deeplearning4j and our scientific computing library, ND4J, which powers the neural nets. So we answer questions about how to use the libs, and in the process, we help people understand more about deep learning in general. It\u2019s not a deep learning hotline, unfortunately, so there are some questions we don\u2019t tend to answer. But we do help engineers in the DL4J community build apps and understand how neural nets work. The common goal is to learn about deep learning, and to build cool shit. We\u2019ve only seen the tip of the iceberg in terms of what deep learning can do. So far, we\u2019ve seen huge advances in image recognition, machine translation, machine transcription and time series predictions. By many metrics, machine perception now equals or surpasses human perception, and that will change society in ways that are hard to imagine. Those changes just haven\u2019t been implemented yet. So the secondary goal of the community is to bring this narrow form of AI into the world, so that it can make a difference.\n\nWhat are the most important factors that you have taken into account while creating and maintaining the community? What factors contribute to the success of your community?\n\nCreating and maintaining a community is a huge commitment of time and effort. You have to be available, and you have to try to understand where other people are coming from. They don\u2019t always know the jargon to ask precise questions, so you have to have the patience to figure out together with them what they\u2019re trying to ask, or where they\u2019re stuck. We\u2019re not always as patient as we should be. Being available, making that effort, and offering support for powerful tools like this are a good way to build a community. When the makers of a big project are available to answer esoteric questions about how it works, that creates a lot of trust, because people know that you speak with authority and that if something is really broken, it\u2019s going to get fixed. There\u2019s a tight feedback loop between the community and the project creators.\n\nWhat are the key challenges that you encounter while managing the community?\n\nOne of the challenges is: What questions do we care about, and what questions do people need to answer for themselves? If someone has really basic questions about Java, an IDE like IntelliJ, or a build tool like Maven, most of the time they need to figure that out for themselves. Our Gitter channel isn\u2019t the right place to hash through that, although we do help in special cases, because sometimes you need to expand your heap space for neural nets to work.\n\nYou also have to find a balance between building the community and building the product. Ideally, you\u2019d have a big team with full-time support engineers and the rest of the team working on the code base. But most open-source projects have very small teams. There are just a handful of people capable of support, and they\u2019re the ones who also should be fixing bugs and adding features.\n\nHow do you encourage participants\u2019 commitment and contribution to the community?\n\nYou create a smart, friendly environment in the community. You remind them you appreciate contributions, and you show them, as best you can, what needs to be worked on. We created top-level files recognizing our contributors, showing people how to contribute, and laying down the rules of the community. We also wrote a devguide, and we now label all issues as bug, enhancement or documentation, so that people can scan the queue quickly and explore where they can add something.\n\nTell us a little bit about the time commitment required to set up and establish the community. How much community maintenance is required on an ongoing basis?\n\nSkymind is a distributed team, with engineers in Australia, Europe and the US, and Deeplearning4j community members in almost every time zone. There\u2019s a Skymind engineer watching the Gitter queue probably 12\u201316 hours out of any weekday. This is a pretty serious commitment, because there are less than 10 of us. It\u2019s not their full-time job, but maybe they\u2019ll be running unit tests and answering questions on Gitter in their downtime.\n\nBased on your experience, do you feel that the open source communities have changed and evolved over the past years? If so, how?\n\nOpen-source is winning the enterprise stack, so it\u2019s a lot more important than it used to be. The biggest organizations in the world are running on open-source software. Linux won the operating system, Hadoop won big data storage. And open-source won because when you do it right, you get better code. More eyeballs mean more uptime. So the size of the OSS community, and the quality of attention that software engineers bring to open-source projects, have both increased over the years.\n\nWhat advice would you give to someone who wants to start an online open source community from scratch?\n\nFirst, build something neat, something you care about. Focus on building one thing that works. Then, share it with people. They will help you improve it, and they may help you think about what to build next. Don\u2019t do too much big upfront development. Try to scope it so that you can ship in a reasonable amount of time. A few weeks, say. Open-source is valuable because it\u2019s a conversation, and the conversation leads you places, so that you and project evolve in ways you can\u2019t anticipate. Also, by open-source early, you\u2019re increasing your exposure and therefore your chances of getting help. We\u2019ve had amazing developers join the community and the Skymind team.\n\nWhat digital tools do you use to help manage and grow your community?\n\nThe code lives on Github, the conversation lives on Gitter. There are about 1360 devs on the Gitter channel now, so it\u2019s probably one of the more lively neural net conversations on the planet. Our website is hosted on Github, so the content lives there, too. We generate a lot of automatic documentation with Javadoc (always a WIP\u2026). We ask people to use Maven as their automated build tool. One of the biggest problems with any software is the install, and Maven helps make that a little easier. You need to constantly try to clear away obstacles, so that people can just use your code and not worry about other stuff.\n\nCan you share a success story of a community member that happened thanks to their participation in your channel?\n\nFor most of the stories, you just had to be there. But in general, a lot of data scientists and Java engineers come, and they just build something for their companies that works. They\u2019ll come back later and say: \u201cWe saw a 200% increase in ad coverage when we made DL4J part of the recommender system.\u201d Another guy built an app with DL4J and then an investor saw it and he raised funds. So that\u2019s all pretty cool. With open source, you\u2019re throwing a rock out into the ocean, and you don\u2019t always hear it hit the water. You can\u2019t even see the ripples. So it\u2019s encouraging when people come back and say \u201cthanks\u201d and tell us how it helped them. That makes it more meaningful.\n\nYou can visit the deeplearning4j community on Gitter.", 
        "title": "Building Online Communities: Deeplearning4j \u2013 Gitter \u2013"
    }, 
    {
        "url": "https://medium.com/jornal-do-empreendedor/tecnologia-o-que-o-futuro-est%C3%A1-trazendo-f782ccf7aec9?source=tag_archive---------3----------------", 
        "text": "A ind\u00fastria de computa\u00e7\u00e3o avan\u00e7a em dois ciclos na sua maioria independentes: ciclos financeiros e de produtos. Tem havido uma grande quantidade de discuss\u00f5es ultimamente sobre onde nos situamos no ciclo financeiro. Os mercados financeiros chamam muita aten\u00e7\u00e3o. Eles tendem a flutuar de forma imprevis\u00edvel e \u00e0s vezes descontroladamente. O ciclo do produto em compara\u00e7\u00e3o recebe relativamente pouca aten\u00e7\u00e3o, embora seja o que realmente impulsiona a ind\u00fastria de computa\u00e7\u00e3o para a frente. Podemos tentar compreender e prever o ciclo do produto atrav\u00e9s do estudo do passado e extrapolando-o em dire\u00e7\u00e3o ao futuro.\n\nHavia telefones com mais recurso na d\u00e9cada de 90 e os primeiros smartphones como o Sidekick e Blackberry no in\u00edcio de 2000, mas a fase de crescimento do smartphone realmente come\u00e7ou em 2007\u20138 com o lan\u00e7amento do iPhone e, em seguida o Android. A ado\u00e7\u00e3o de smartphones, desde ent\u00e3o, explodiu: cerca de 2 bilh\u00f5es de pessoas t\u00eam smartphones hoje. Em 2020, 80% da popula\u00e7\u00e3o mundial ter\u00e1 um.\n\nEssa nova arquitetura derrubou os pre\u00e7os dos sistemas de computa\u00e7\u00e3o b\u00e1sicos de cerca de US$ 100 para cerca de US$ 10. O Raspberry Pi Zero \u00e9 um computador Linux de 1 GHz que voc\u00ea pode comprar por US$ 5. Por um pre\u00e7o similar voc\u00ea pode comprar um microcontrolador com Wi-Fi que executa uma vers\u00e3o de Python. Logo esses chips v\u00e3o custar menos de um d\u00f3lar. Ser\u00e1 rent\u00e1vel incorporar um computador em quase tudo.\n\nH\u00e1 muitas coisas interessantes acontecendo em software hoje. Os sistemas distribu\u00eddos \u00e9 um bom exemplo. Como o n\u00famero de dispositivos tem crescido exponencialmente, tornou-se cada vez mais importante a 1) paralelizar tarefas em v\u00e1rias m\u00e1quinas 2) comunicar e coordenar dispositivos. As tecnologias de sistemas distribu\u00eddos interessantes incluem sistemas como o Hadoop e Spark para paraleliza\u00e7\u00e3o de problemas de Big Data e Bitcoin / blockchain para proteger dados e assets.\n\nMas talvez os avan\u00e7os de software mais interessantes est\u00e3o acontecendo em intelig\u00eancia artificial (AI). AI tem uma longa hist\u00f3ria de hype e frustra\u00e7\u00e3o. O pr\u00f3prio Alan Turing previu que as m\u00e1quinas seriam capazes de imitar com sucesso os seres humanos at\u00e9 o ano de 2000. No entanto, h\u00e1 boas raz\u00f5es para acharmos que a AI possa estar entrando em uma era de ouro.\n\nUma boa parte do excitamento com rela\u00e7\u00e3o a AI concentrou-se em algo chamado de deep learning, uma t\u00e9cnica de aprendizado de m\u00e1quina, que foi popularizada pelo famoso projeto de 2012 do Google que usou um cluster gigante de computadores para aprender a identificar gatos em v\u00eddeos do YouTube. O deep learning \u00e9 um descendente de redes neurais, uma tecnologia que remonta \u00e0 d\u00e9cada de 1940. Ele foi trazido de volta \u00e0 vida por uma combina\u00e7\u00e3o de fatores, incluindo novos algoritmos, computa\u00e7\u00e3o paralela barato, e a ampla disponibilidade de grandes datasets.\n\n\u00c9 tentador descartar o deep learning como outra moda do Silicon Valley. O excitamento, no entanto, \u00e9 apoiado por resultados impressionantes na teoria e no mundo real. Por exemplo, as taxas de erro para os vencedores do desafio IMAGEnet\u200a\u2014\u200aum concurso popular de vis\u00e3o de m\u00e1quina\u200a\u2014\u200aestavam na faixa de 20\u201330% antes da utiliza\u00e7\u00e3o do deep learning. Usando o deep learning, a precis\u00e3o dos algoritmos vencedores come\u00e7ou a melhorar, e em 2015 superou o desempenho humano.\n\nMuitos dos estudos, datasets e ferramentas de software relacionados com o deep learning tem utilizado c\u00f3digo aberto. Isto teve um efeito democratizante, permitindo que indiv\u00edduos e pequenas organiza\u00e7\u00f5es constru\u00edssem aplica\u00e7\u00f5es poderosas. O WhatsApp foi capaz de construir um sistema de mensagens global que serve 900M usu\u00e1rios com apenas 50 engenheiros, em compara\u00e7\u00e3o com os milhares de engenheiros que eram necess\u00e1rios para as gera\u00e7\u00f5es anteriores dos sistemas de mensagens. Este \u201cefeito WhatsApp\u201d agora est\u00e1 acontecendo em AI. As ferramentas de software como Theano e TensorFlow, combinados com data-centers em nuvem para treinamento e GPUs de baixo custo de implanta\u00e7\u00e3o, permitir\u00e3o que pequenas equipes de engenheiros possam construir sistemas de intelig\u00eancia artificial em state-of-the-art.\n\nAs startups construindo produtos AI ter\u00e3o que ficar com foco laser em aplica\u00e7\u00f5es espec\u00edficas para competir contra as grandes empresas de tecnologia que fizeram da AI uma prioridade. Os sistemas de intelig\u00eancia artificial ficam melhor \u00e0 medida que mais dados s\u00e3o coletados, o que significa que \u00e9 poss\u00edvel criar um ciclo virtuoso de efeitos de data network (mais usu\u00e1rios \u2192 mais dados \u2192 melhores produtos \u2192 mais usu\u00e1rios). A startup Waze utiliza os efeitos de data network para produzir mapas melhores do que seus concorrentes muito mais capitalizados. O sucesso das startups de AI seguir\u00e3o uma estrat\u00e9gia similar.\n\nCarros. As grades empresas de tecnologia como Google, Apple, Uber, e Tesla est\u00e3o investindo recursos significativos em carros aut\u00f4nomos. Carros semi-aut\u00f4nomos como o Tesla Model S j\u00e1 est\u00e3o dispon\u00edveis ao p\u00fablico e v\u00e3o melhorar rapidamente. A autonomia completa levar\u00e1 mais tempo, mas \u00e9 provavelmente que n\u00e3o mais de 5 anos. J\u00e1 existem carros totalmente aut\u00f4nomos que s\u00e3o quase t\u00e3o bom quanto os motoristas humanos. No entanto, por raz\u00f5es culturais e regulamentares, esses carros totalmente aut\u00f4nomos provavelmente precisar\u00e3o ser significativamente melhor do que os motoristas humanos antes de serem amplamente permitidos.\n\nA maioria das pessoas acha o Echo um chamariz at\u00e9 experiment\u00e1-lo sendo surpreendidos em constatar como ele \u00e9 \u00fatil. \u00c9 uma boa demonstra\u00e7\u00e3o de qu\u00e3o eficaz os always-on de voz podem se tornar uma interface com o usu\u00e1rio. Vai demorar um pouco antes termos bots com intelig\u00eancia generalizada capazes de realizarem conversas completas. Mas, como mostra o Echo, a voz pode ser um sucesso hoje em contextos limitados. A compreens\u00e3o da linguagem deve melhorar rapidamente a medida que os avan\u00e7os recentes do deep learning caminham para serem incorporados em dispositivos para comercializa\u00e7\u00e3o geral.", 
        "title": "Tecnologia: O que o futuro est\u00e1 trazendo \u2013 Jornal do Empreendedor \u2013"
    }
]