[
    {
        "url": "https://machinelearnings.co/deep-spelling-9ffef96a24f6?source=tag_archive---------0----------------", 
        "text": "I implemented my first spelling corrector years ago based on Peter Norvig\u2019s excellent tutorial\u200a\u2014\u200aa spelling corrector in 21 lines of Python code.\n\nSo I tried to fix it. I piled on double metaphone phonetic similarity, unicode support, multi-word expressions, weighted Damerau-Levenshtein edit-distance, efficient Trie and smart caching.\n\nAnd it still sucked.\n\nAnd the reason it failed to go beyond a simple toy is very simple\u200a\u2014\u200aI am not Google (and neither are you).\n\nEven in its simplest form, spelling a short word took a long time\u200a\u2014\u200asay ~0.1 seconds. That might be ok for some uses, but when you are dealing with real-time chat, faced with the upcoming bot gold rush, interactivity reigns supreme. And don\u2019t forget that spelling is only a single chain in the long processing pipeline of delivering value via Natural Language Understanding, dialog management, business logic and of course the actual application.\n\nThe root cause of the abysmal performance is that the speller is trying to brute-force its way to the right solution. Here is the core of Norvig\u2019s code:\n\nThe function looks at every possible edit to the input\u200a\u2014\u200aa deletion of any character, a transposition of any 2 adjacent characters, replacing any character in the input with a random character or simply inserting a random character. And for each of the results in the set of edited strings\u200a\u2014\u200ait calculates every possible edit again!\n\nThe result is a challenging amount of computation that needs to happen, and which grows exponentially with respect to the length of the input string.", 
        "title": "Deep Spelling \u2013"
    }, 
    {
        "url": "https://humanizing.tech/apple-s-in-house-gpu-acquisition-for-ai-assistance-1e1403c23890?source=tag_archive---------1----------------", 
        "text": "So Apple has confirmed that they are indeed in advanced talks with their main GPU supplier as a potential acquisition, but said that they are not going forward with it at this time.\n\nWhy are GPUs important? Historically they\u2019ve been used to process many many triangles necessary for 60 frames per second games on iPhones. But increasingly, they will be used for the intense artificial intelligence tasks required for machine and deep learning.\n\nRemember, deep learning is nothing more than lots and lots of connected equations. But running trillions of points of data through those equations in real-time and optimizing the architecture requires lots of processing power.\n\nIn small batches that will happen less and less in the massive data centers owned by Apple, Google, and Amazon and more at the \u201cedge\u201d where all these billion active mobile devices are.\n\nSo, what I think may happen is that you have a core deep learning or neural architecture that is back-tested and optimized by the PhD employees at the tech companies using their massive infrastructure.\n\nThat gives you the standard algorithm that will be used as the base layer for everything (e.g., computer vision).\n\nThen, on the \u201cedge\u201d iPhones and mobile devices (powered by these next gen GPUs), you have will personalized tweaks based on the user data streaming through a copy of this algo on the device in real time.\n\nNow, because privacy is such a huge public issue and AI really scares people (because media and ad impressions and therefore, scare tactics), we won\u2019t store any of the personal data, we will just pass it through the personalized algorithm in order to make very slight tweaks and modifications in real-time, then just dump and forget the raw data (you don\u2019t need the historical stuff anyways).\n\nSo, out the other end of the AI black box, you get the fastest and most accurate response, personalized exactly to you.\n\nWhat you may not have already considered is that you already have a robot in your home. It\u2019s just been branded an iPhone.", 
        "title": "Apple\u2019s In-House GPU Acquisition for AI Assistance \u2013"
    }, 
    {
        "url": "https://medium.com/@xdotai/what-alphagos-amazing-victory-doesn-t-tell-you-about-ai-in-2016-21cd45be0613?source=tag_archive---------2----------------", 
        "text": "What AlphaGo\u2019s amazing victory doesn\u2019t tell you about AI in\u00a02016\n\nAlphaGo\u2019s defeat of champion Go player Lee Se-dol has spurred another flurry of articles about AI. Among these was an announcement that Luc Besson will be directing a pilot for a new TV series titled Artificial Intelligence. Bet you can\u2019t guess the plot? Well, actually, you probably can: AI escapes the lab, goes AWOL, mayhem ensues. Its creators form a team of special agents to combat the now rogue AI. Sounds like Sci Fi at its formulaic best\u200a\u2014\u200aadvanced technology runs amok is eventually defeated by a ragtag team with good hearts and ingenious hacks.\n\nFun as it might be to watch, the show is likely to compound current misunderstandings of AI.\n\nThankfully, a few recent articles have begun to clarify the picture. The New York Times reporter Steve Lohr reminded us that advances in AI proceed in incremental steps rather than dramatic leaps. In TechRepublic, Hope Reese pointed out that AI is not necessarily synonymous with automation nor does it always (or even often) come in robot form.\n\nAnd yet, it will take many more clear-eyed articles to counter the TV and movie version of Artificial Intelligence because AI, today, is seamlessly woven into our daily lives. Google relies on AI to power its search results; Facebook relies on AI to find friends in your photos; and, of course, AI gives Siri some of her powers. It\u2019s everywhere and nowhere. As a result, we often don\u2019t realize when AI is shaping, and enhancing, our experience.\n\nAutonomous intelligent agents should begin to change the broader perception of AI. As the technology matures, we anticipate that user demand will shift from a model in which software assists us in completing a given task towards one in which agents do a job in full. Rather than demand that you interact with an app, these agents let you hand a job over completely, and go do other things. Such agents can take many forms. The Google Self-Driving Car Project is one. Our scheduling agent, Amy Ingram, is another. Once such agents are pervasive, users will have a much more concrete sense of AI in action.\n\nRight now, though, there is a very good, if banal, reason that these sorts of autonomous AI agents, ones that can do even a simple job in full, are still rare. They are very, very hard to build. You need to teach a piece of software to work alongside humans, with all the nuance and comprehension of context that humans possess.\n\nToday, the relatively small set of companies building autonomous agents use machine learning in one way or another, and many rely on Supervised Learning. This process requires several core elements: You need training data. You need humans to label training data. You need to model the universe in which your agent will operate. And you need a way to capture and process a massive amount of data to validate and refine your models (algorithms).\n\nFor the Self-Driving Car, Google needed to create a simplistic model of the real world in which cars exist (other vehicles, bicycles, pedestrians, pedestrians that are officers of the law, road conditions, signs and their meaning, etc.) and, on top of that, apply all of the elements of driving (accelerate, decelerate, stop, turn left, turn right, back up).\n\nHere at x.ai, we\u2019ve had to model all the elements of a meeting (time, date, participants, location). And lest you think that is an easy task, it took us over a year to find the perfect conceptual model for time alone, and the accompanying data annotation guidelines run 16-pages long.\n\nWe may not be geniuses, but we are reasonably smart people over here (Chief Data Scientist Marcos Jimenez was part of the Higgs boson hunting group at CERN). What makes AI hard to build and concepts like time hard to model is that humans do not typically behave in machine legible ways. We are imprecise communicators even when we think we are being clear, in part because we can rely heavily on context. To annotate and model all those subtleties is a laborious and time-consuming task, which requires a good deal of experimentation. (For example, we learned that prepositions that directly modify a time expression are very important if they precede a time expression, but are pretty much irrelevant if they come after a time expression.)\n\nThen too, in creating the models, you immediately confront a \u201cchicken and egg\u201d problem. You need at least some data upon which to build decent models. This means you need to collect data as you are building the models. But how? For some products, you can use an existing data set; however, this isn\u2019t always, or even often, the case.\n\nWe needed to create a dataset from scratch, and so we quickly had to build the data-collecting machinery itself. These systems are temporary but essential. Imagine you are building the New York subway system at the turn of the 20th century. You need to dig a bunch of massive tunnels. And to do this, you first need to custom build the drill, since no such system had yet been built at scale. In 1900, you can\u2019t buy an \u201coff-the-shelf,\u201d subway tunnel drill.\n\nIn the case of AI that relies on Supervised Learning, you need to develop the collection mechanism as well as the software used for labeling and verifying data. Google\u2019s Self-Driving Car Project mounted purpose-built sensors (a combination of lasers, radars, and cameras) on an ordinary car. To capture and process the millions of scheduling-related emails required to train Amy, we\u2019ve specially designed an email annotation console.\n\nAnd then, once you have the mechanism to capture and annotate data, you need to collect a huge amount of it to fully train the system. But how much? That depends somewhat on the level of accuracy you require. To schedule meetings, we need a very high-level of accuracy, otherwise you end up at one Starbucks at 2PM, and your client ends up at another one, three blocks away. For us, this requires millions of scheduling emails. As you can imagine, Google\u2019s Self-Driving car has even less room for error, which is in part why it has taken the project more than six years and over 2 million miles to amass enough data to deploy the car in test settings like Mountain View, California and Austin, Texas.\n\nFinally, once you get the system working, you must automate every element of it. Once we labeled a sufficient volume of data, we programmed the machine to take over this specific task. We have done the same thing with, for example, complex email threading: we manually threaded emails that defied the usual conversational logic, developed a threading algorithm based on that work, and then turned the task over to the machine. This took us more than a year from the first piece of data we collected to putting an active, intelligent threader in place, and we are still honing it.\n\nWhen Artificial Intelligence, the TV show, arrives on a screen near you, remember this: it has taken us two years to build the AI behind Amy\u200a\u2014\u200aand we are still perfecting her (and her brother Andrew). Today, Amy can schedule meetings pretty well, but she can\u2019t get you coffee or join your call. There\u2019s no doubt AI has the potential to transform the way we work and how we are entertained. But AI that is able to override the objectives it was designed for remains a Sci Fi fantasy.", 
        "title": "What AlphaGo\u2019s amazing victory doesn\u2019t tell you about AI in 2016"
    }, 
    {
        "url": "https://medium.com/@StephenMartindale/alphago-vs-lee-se-dol-haylee-s-synopsis-be717dd40a8f?source=tag_archive---------3----------------", 
        "text": "Hajin \u201cHaylee\u201d Lee, 3 dan professional Go player, secretary general of the International Go Federation, streamer, blogger, writer and creator of Haylee\u2019s World of Go / Baduk, has published a long and somewhat rambling account of the recent challenge match between Google DeepMind\u2019s AlphaGo (honorary 9 dan) and Lee Se-dol (9 dan professional) and I heartily recommend that you watch it.\n\nIt is a tale of clandestine phone calls and secret dinner parties, of people and the press and camera men and wives and daughters and friends. Haylee briefly touches on the games themselves, giving a light and digestible overview of the important moves in each game that will be immediately understood by anyone who plays Go and watched the games but her story is about more than the moves themselves\u200a\u2014\u200ait offers a glimpse behind the scenes, told in a friendly and familiar and unassuming style by someone who was instrumental in organising the spectacle that millions watched, earlier this month.\n\nAt one point, during the video, Haylee singles out a camera man, named Greg, from Google\u2019s documentary team, giving away clear evidence that a professionally produced story of the event is almost certainly in the works\u200a\u2014\u200asomething I would be very excited to watch.\n\nCoincidentally, it was while I was perusing the text-chat during the American Go Association\u2019s broadcast of the first game of the challenge match that I first discovered Haylee\u2019s World of Go, Hajin Lee\u2019s YouTube channel. I subscribed to it immediately and, since then, I have been enjoying her streamed games during which she plays Go on Tygem, a Korean server, and offers Malkovich-style comments on her thoughts and ideas and plans\u200a\u2014\u200aher videos have become a regular source of entertainment and cerebral stimulation for me and, although I am only a single-digit kyu player, I find her commentary to be quite understandable and educational. I believe she has also published a book\u200a\u2014\u200aan autobiographical account of her quest to become a professional player.", 
        "title": "AlphaGo vs. Lee Se-dol: Haylee\u2019s Synopsis \u2013 Stephen Martindale \u2013"
    }
]