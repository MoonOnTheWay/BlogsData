[
    {
        "url": "https://medium.com/machine-intelligence-report/deep-simplicity-6a93724688fa?source=tag_archive---------0----------------", 
        "text": "How do I feel about deep learning?\n\nI\u2019ve been asking myself that a lot when I think about machine learning and how I want to contribute to the field in the future. On one hand, deep learning has had a ton of commercial success. Much of the heavy lifting in image and text analysis in large corporations like Google and Facebook function via deep learning. With all of its successes, deep learning is arguably the state-of-the-art way to process huge reams of unmanageable data and extract conclusions or perform operations. The tech industry is also booming with confidence about its future. Since its recent re-emergence, deep learning has been partly responsible for many of the world\u2019s new crazy futuristic inventions like Google\u2019s autonomous car, or Clarifai\u2019s smart video querying.\n\nMoreover, deep learning is biologically based on our own brains (albeit somewhat loosely). Neural networks are composed of layers of individual units modeled after the neuron, each of which has the capability to express or suppress some input. Intuitively, it makes a lot of sense that the next generation of effective learning algorithms should model the way our own brains work.\n\nAnd then on top of that, deep learning makes our lives as computer scientists easier. While ordinary machine learning (I\u2019ll call it shallow learning) requires the user to help a machine teach itself, deep learning lets machines teach themselves to teach themselves... if that makes any sense. Hence, it\u2019s considered a deeper form of learning. In essence, shallow learning involves designing the rules by which the machine learns by hand. Given some data, we have to tell the computer exactly what to look for. Over time, many algorithms were developed to automate the learning, but selecting the right features, or (but most likely and) massaging the data into a usable form required expert knowledge. Deep learning automates the process of feature extraction as well, pushing the expert more and more out of the picture. Instead of handcrafting features, we can now use unsupervised algorithms to create features from data without us ever having to know what they are. By circumventing this step, learning models can learn which features are useful by themselves, saving us a lot of time. Algorithms no longer are fully dependent on how insightful the programmer is. And that\u2019s super valuable right?\n\nLet\u2019s give a short example. Let\u2019s say I have two piles of photos, the first being a bunch of pictures of cars, and the second being a bunch of pictures of random things, some of which are cars, some aren\u2019t. I want to design a machine that after having seen what many cars look like, can tell me if any picture is of a car or not.\n\nIn shallow learning, I might describe to the machine that a typical car has four circular objects, moves at a high speed, a constant color, etc. But this could also describe a lot of different things like a helicopter, a bird, or a bicyclist. It would take a lot of tuning and a more detailed knowledge of car features to better describe the vehicle. But in deep learning, I can show the pictures of cars to the machine, and it\u2019s features will automatically be generated. Maybe some of these features might also describe the color, or the wheels, but there might also be more complex features representing things like hull shape or curvature. In that case, deep learning would more accurately characterize a car and be better able to classify one.\n\nArguably, it seems like the only technical disadvantage of deep learning is that to reduce the likelihood of overfitting, you need a lot of data and a lot of processing power. But in today\u2019s modern age of technology, data and power are cheap.\n\nSo why do I still feel ambivalent about neural nets?\n\nDespite all of the positives, I\u2019m hesitant to go all-in on deep learning because of it\u2019s black box nature. Sure, it is a powerful tool, and by all means, I acknowledge it as a very useful learning algorithm, deserving much of the media attention that its received. But it\u2019s hard to know how a neural net does what it does. Even if it is classifying cars correctly 99% of the time, it\u2019s almost impossible to interpret what the features extracted represent. Instead of hand-picked features, the neural net returns a long array of weights, denoting which neuron units are more heavily accounted for. Sometimes we can figure it out by closely analyzing them. For example, in convolutional neural nets, many of the higher-level features closely resemble Gabor filters or edge detectors, which make a lot of sense when you are looking at images. But most of the time, they are cryptic and uninterpretable.\n\nYou may be asking: why does this matter? If deep learning is truly classifying at a 99% accuracy rate, why should I care what the features are as long as they work? It\u2019s a valid argument and really left up to the individual. For me, without understanding the feature engineering process, and without understanding how the innards of deep learning work, I think it will be difficult to truly engineer a smarter brain, and create smarter AIs, or make better classifiers and predictors. Even though the ceiling for deep learning is high, higher than anything else we currently have, it still has a ceiling. In my opinion, the next generation of learning algorithms that will be responsible for ground-breaking inventions will not be related to neural nets unless we make that black box more transparent. As researchers and scientists, I don\u2019t think we should settle. Yes, deep learning works well, but why? How can we understand and improve deep learning to further push the field?\n\nHere\u2019s one more thing to think about. The goal of machine learning is to create intelligent algorithms that mimic what our brains are capable of (and possibly surpass). If deep learning were truly the model by which our brains function, then our brains would need to be gigantic in size to store the processing power, number of nodes, and internal probabilistic models to do what deep learning does. Think about how large a network is needed to just recognize an image of a cat (about a billion parameters). Our brain doesn\u2019t learn by bombarding itself with sensory stimulus. Likewise, throwing as much data as possible at an arbitrary model may not make the best classifier possible. The true model should be more simple.\n\nWhat else is out there then if not deep learning?\n\nRecently, I\u2019ve been lucky enough to get my hands dirty with bayesian non-parametrics, and it\u2019s been really interesting. Because I\u2019m new to the field of machine learning in general, I can come off as naive, but I think of bayesian non-parametrics as a balance between shallow and deep learning. It combines both high-order features with a more transparent, more well-understood workflow.\n\nVery quickly, the idea behind bayesian non-parametrics is to supplant the ordinary hand-picked features with latent features. While this is similar to the feature engineering in deep learning, these latent features are created with more programmer involvement. (Often latent features are a byproduct of clustering of a mixture of language models or gaussian processes.) And because these systems are more transparent, it\u2019s much easier for us to correlate these latent features to interpretable descriptions.\n\nI think the best way to explain a machine learning algorithm is to play with a toy model. For simplicity, consider the following sequence of numbers as a data set of single featured vectors:\n\nIt\u2019s possible to create latent features using a mixture of language models. Still keeping it simple, let\u2019s go with a prior belief that there exists two distinct hidden states in our data, providing us with two language models. Let\u2019s call them a, and b.\n\nWhat a mixture model returns is the probability of the data to come from each of the two language models. After 40 or 50 iterations, the data likely converges to a sparse set of possible language model configurations. Sampling from the probabilities returns the following:\n\nImmediately, this looks less random than any other sequence but what does it mean? If you look closely, the two language models converged to describe two furtive patterns of data in the sequence. The a's represent a \u201cconstant-state\u201d, where the data has a sequence of consecutive 0's, or a sequence of consecutive 1's. The b's represent a \u201cchanging-state\u201d, where the data oscillates rapidly between 0's and 1's.\n\nBeing able to describe these two states in terms of probabilities helps uncover some of the more subtle characteristics of the input data. And being able to better describe the data to a machine greatly improves its predictive power. And more importantly, being able to understand what these features mean and how they arise is priceless.\n\nI was reading John Gribbin\u2019s Deep Simplicity and was fascinated by how he described one of the most complex theories in physics so simply. Of course Chaos Theory gets much harder than what Gribbin wrote about but the core of the science is very intuitive. Likewise, I think the best learning algorithm should be somewhat simple. I support deep learning initiative\u2019s to delve deeper into the data and look for less obvious features, and am very astounded with its predictive power, but I don\u2019t think its black box / big data nature is the best way to reach the right answer. I think one of my biggest goals for my academic future is to search for that best learning algorithm. Maybe I will end up working with neural nets, and maybe I won\u2019t. But I know that whatever it is will have to be deeper and simpler.", 
        "title": "Deep Simplicity \u2013 Machine Intelligence Report \u2013"
    }, 
    {
        "url": "https://medium.com/@jkarnows/find-your-dream-job-421e1f66029d?source=tag_archive---------2----------------", 
        "text": "A few months ago Andrej Karpathy wrote an excellent introductory article on recurrent neural networks, The Unreasonable Effectiveness of Recurrent Neural Networks. With this article, he released some code (and larger version) that allows someone to train character-level language models. While RNNs have been around for a long time (Jeff Elman from UCSD Cognitive Science did pioneering work in this field), the current trend is implementing with deep learning techniques organizationally different networks that attain higher performance (Long Short-term memory networks). Andrej demonstrated the model\u2019s ability to learn the writing styles of Paul Graham and Shakespeare. He also demonstrated that this model could learn the structure of documents, allowing the model to learn and then produce Wikipedia articles, LaTeX documents, and Linux Source code.\n\nOthers used this tutorial to produce some pretty cool projects, modeling audio and music sequences (Eminem lyrics, Obama Speeches, Irish Folk Music, and music in ABC notation) as well as learning and producing text that resembles biblical texts (RNN Bible and Learning Holiness).\n\nTom Brewe\u2019s project to learn and generate cooking recipes, along with Karpathy\u2019s demonstration that the network can learn basic document syntax, inspired me to do the same with job postings. Once we\u2019ve learned a model, we can see what dream jobs come out of its internal workings.\n\nTo do this, I performed the following:\n\n2. Use recurrent neural network to learn the structure of the job postings\n\n3. Use the learned network to generate imaginary job postings\n\nIn order to obtain my training data, I scraped job postings from several major U.S. cities from the popular indeed.com (San Francisco Bay Area, Seattle, New York, and Chicago). The code used to scrape the website came from this great tutorial by Jesse Steinweg-Woods. My modified code, available here, explicitly checked if a website was located on indeed.com (and not another website as the job posting structure was different) and stripped the website down to a bare bones structure. Having this more specific structure I thought would help reduce the training time for the recurrent neural network. Putting these 1001 jobs into one text document gives us a 4.2MB text file, or about 4 million characters.\n\nTraining the RNN was pretty straight forward. I used Karpathy\u2019s code and the text document generated from all the job postings. I set up the network in the same manner as the network Karpathy outlined for the writings of Shakespeare:\n\nI trained this network over night on my machine that has a Titan Z GPU (here is more info on acquiring a GPU for academic use).\n\nThe training procedure produces a set of files that represent checkpoints in training. Let\u2019s take a look at the loss over training:\n\nIt looks like the model achieved pretty good results around epoch 19. After this, the performance got worse but then came back down again. Let\u2019s use the checkpoint that had the lowest validation loss (epoch 19) and the last checkpoint (epoch 50) to produce samples from the model. These samples will demonstrate some of the relationships that the model has learned. While none of these jobs actually exist, the model produces valid html code that represents imaginary dream job postings.\n\nBelow is one of the jobs that was produced when sampling from the saved model at epoch 19. It\u2019s for a job at Manager Persons Inc. and it\u2019s located in San Francisco, CA. It looks like there is a need for the applicant to be \u201cpizza friendly\u201d and the job requires purchasing and data entry. Not too shabby. Here it is as a web page.\n\nAt epoch 50, the model has learned a few more things and the job postings are typically much longer. Here is a job for Facetionteal Agency (as a website). As you can see, more training can be done to improve the language model (\u201cTraininging calls\u201d) but it does a pretty good job of looking like a job posting. Some items are fun to note, like that the job requires an education of Mountain View, CA.\n\nBelow is another longer one (and as a website). Turns out the model wants to provide jobs that pay $1.50 an hour. The person needs to be a team player.\n\nThis was a pretty fun experiment! We could keep going with this as well. There are several knobs to turn to get different performance and to see what kind of results this model could produce. I encourage you to grab an interesting dataset and see what kind of fun things you can do with recurrent neural networks!", 
        "title": "Find your Dream Job! \u2013 Jeremy Karnowski \u2013"
    }
]