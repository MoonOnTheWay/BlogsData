[
    {
        "url": "https://medium.com/@devnag/a-simple-design-pattern-for-recurrent-deep-learning-in-tensorflow-37aba4e2fd6b?source=tag_archive---------0----------------", 
        "text": "tl; dr: You can hide/encapsulate the state of arbitrary recurrent networks with a single page of code In an ideal world, every deep learning paper proposing a new architecture would link to a readily-accessible Github repository with implemented code. In reality, you often have to hand-code the translated equations yourself, make a bunch of assumptions, and do a lot of debugging before you get something that may or may not be related to the authors\u2019 intent. This process is especially fraught when dealing with recurrent architectures (aka \u201crecurrent neural networks\u201d): computational graphs which are DGs (directed graphs) but not DAGs (directed acyclic graphs). Recurrent architectures are especially good at modeling/generating sequential data\u200a\u2014\u200alanguage, music, video, even video games\u200a\u2014\u200aanything where you care about the order of data rather than just pure input/output mapping. However, because we can\u2019t directly train directed graphs with directed cycles (whew!), we have to implement and train graphs that are transformations of the original graph (going from \u201ccyclic\u201d to \u201cunrolled\u201d versions) and then use Backpropagation through time (BPTT) on these shadow models. In essence, we\u2019re mapping connections across time to connections across space:\n\nNow, if you\u2019re just using vanilla LSTM/GRU, there are off-the-shelf components that you can duct-tape together easily. That\u2019s not the problem. The hard part is taking a new recurrent architecture and trying to code the novel graph while also handling all the unrolled state tricks without introducing new bugs. For example, suppose you found yourself perusing Alex Graves\u2019 bodice-ripping classic from 2013, \u201cGenerating Sequences with Recurrent Neural Networks\u201d, and wanted to implement his LSTM. Everywhere you see t-1 as a subscript is yet another place (and yes, Virginia, there are 7 in that little brick of symbols) that you need to worry about recurrent state: initializing it, retrieving it from the past, and saving it for the future. If you look at TensorFlow tutorials, you\u2019ll see a lot of code dedicated to worrying about packing and unpacking the various recurrent states. There\u2019s much room for error here, and a cruel and unusual intermingling of architecture and logistics. It becomes half-declarative, half-procedural\u2026and all-fugly. But with just a tiny amount of bookkeeping code, you can make it so much easier, and almost live the dream (!) of typing in recurrent equations and getting working TensorFlow code out the other side. We can even steal TensorFlow\u2019s idiom for get-or-create scoped variables. Let\u2019s briefly look at the relevant stanza:\n\nHere, the bp variable is a BPTT object that\u2019s responsible for all recurrent state. There are two interesting method calls here. bp.get_past_variable() handles both initialization from a random constant and retrieval of past state (t-1), and bp.name_variable() saves the current state for future suitors. Look how close this code is to the raw mathematical equations\u200a\u2014\u200aI\u2019ve left out the shape definitions for the weight matrices and bias vectors for clarity, but for the most part it\u2019s a 1-to-1 mapping: easy to write and easy to read. The only mental overhead is retrieving the recurrent variable(immediately before usage) and saving it (inline with usage), all in local context. There\u2019s no reference to this state anywhere else in the graph-building code. In fact, the rest of the code bears a striking resemblance to non-recurrent TensorFlow. Then, to generate the shadow (unrolled) model, we just call on the bp object to generate the sequence of connected graphs with a single line: This sequence of graphs has placeholders at the right places (where those inline constants will come back to make a dramatic cameo) and are stitched together at every bp.get_past_variable() call. During training (or inference), there are three places where all this recurrent state must be brought back into play. First, we have to send the working state into the feed dictionary (either the initialized constants defined above, or the working state from a previous training loop), and insert the training data into the unrolled placeholders. Second, we have to define the state variables we want returned from the session.run() method. Third, we have to take the post-session.run() results and extract out the state for the future.\n\nThe BPTT object takes care of that bookkeeping as well. Note that we\u2019re also passing a flag (bp.DEEP) in many of the calls here, during the training phase. This is because another common design pattern of recurrent networks is that you first train the unrolled/deep network but then infer using the cyclic/shallow network (with the same, shared post-training parameters). When we infer, we use the bp.SHALLOW flag which has a different set of placeholder variables and thus needs to manage a different state pipeline. There\u2019s also a convenience method (copy_state_forward()) to copy the final unrolled/deep state (recurrent variables) into the cyclic/shallow network before starting inference. Inference idiom\u200a\u2014\u200aalmost identical to the training phase, but feeding one frame of data at a\u00a0time Recurrent deep learning in TensorFlow can be\u200a\u2014\u200aif not easy\u200a\u2014\u200aa little bit easier. Want to check out the code + sample usage? Say no more.", 
        "title": "A simple design pattern for recurrent deep learning in TensorFlow"
    }, 
    {
        "url": "https://medium.com/@Francesco_AI/how-ai-is-revolutionizing-business-models-the-deepmind-strategy-8534d04b5ba9?source=tag_archive---------1----------------", 
        "text": "AI is introducing radical innovation even in the way we think about business, and the aim of this section is indeed to categorize different AI companies and business models.\n\nIt is possible to look at the AI sector as really similar in terms of business models to the biopharma industry: expensive and long R&D; long investment cycle; low-probability enormous returns; concentration of funding toward specific phases of development. There are anyway two differences between those two fields: the experimentation phase, that is much faster and painless for AI, and the (absent) patenting period, which forces AI to continuously evolve and to use alternative revenue models (e.g., freemium model).\n\nIf we look from the incumbents\u2019 side, we might notice two different nuances in their business models evolution. First, the growth model is changing. Instead of competing with emerging startups, the biggest incumbents are pursuing an aggressive acquisition strategy.\n\nI named this new expansion strategy the \u201cDeepMind strategy\u201d because it has become extremely common after the acquisition of DeepMind operated by Google.\n\nThe companies are purchased when they are still early stage, in their first 1\u20133 years of life, where the focus is more on people and pure technological advancements rather than revenues (AI is the only sector in which the pure team value exceeds the business one). They maintain elements of their original brand and retain the entire existing team (\u201cacqui-hire\u201d). Companies maintain full independence, both physically speaking\u200a\u2014\u200aoften they keep in place their original headquarters\u200a\u2014\u200aas well as operationally. This independence is so vast to allow them to pursue acquisition strategies in turn (DeepMind bought Dark Blue Labs and Vision Factory in 2014). The parent company uses the subsidiary services and integrates rather than replaces the existing business (e.g., Google Brain and Deepmind).\n\nIt seems then that the acquisition costs are much lower than the opportunity cost of leaving around many brains, and it works better to (over)pay for a company today instead of being cutting out a few years later. In this sense, these acquisitions are pure real option tools: they represent future possible revenues and future possible underlying layers where incumbents might end up building on top of.\n\nThe second nuance to point out is the emerging of the open source model in the AI sector, which is quite difficult to reconcile with the traditional SaaS model. Many of the cutting-edge technologies and algorithms are indeed provided for free and can be easily downloaded. So why incumbents are paying huge money and startups are working so hard to give all away for free?\n\nWell, there are a series of considerations to be made here. First, AI companies and departments are driven by scientists and academics, and their mindset encourages sharing and publicly presenting their findings. Second, open sourcing raises the bar of the current state of the art for potential competitors in the field: if it is publicly noted what you can build with TensorFlow, another company that wants to take over Google should publicly prove to provide at least what TensorFlow allows. It also fosters use cases that were not envisioned at all by the providing company and set up those tools as underlying technology everything should be built on top of which.\n\nReleasing free software that does not require presence of high-tech hardware is also a great way for 6 things to happen, as discussed below.\n\nThese are the many reasons why this model is working, even though there are advocates who claim incumbents to not really be maximally open (Bostrom, 2016) and to only release technology somehow old to them. My personal view is that companies are getting the best out of spreading their technologies around without paying any costs and any counter effect: they still have unique large datasets, platform, and huge investments capacity that would allow only them to scale up.\n\nRegardless the real reasons behind this strategy, the effect of this business model on the AI development is controversial. According to Bostrom (2016), in the short term a higher openness could increase the diffusion of AI. Software and knowledge are non-rival goods, and this would enable more people to use, build on top on previous applications and technologies at a low marginal cost, and fix bugs. There would be strong brand implications for companies too.\n\nOn the long term, though, we might observe less incentive to invest in research and development, because of free riding. Hence, there should exist a way to earn monopoly rents from ideas individuals generate. On other side, what stands on the positive side is that open research is implemented to build absorptive capacity (i.e., is a mean of building skills and keeping up with state of art); it might bring to extra profit from owning complementary assets whose value is increased by new technologies or ideas; and finally, it is going to be fostered by individuals who want to demonstrate their skills, build their reputation, and eventually increase their market value.\n\nAlthough these notes on the effect of open research on AI advancements in short versus long term, it is not clear where this innovation will be promoted. We are looking at the transition from universities, where historically innovation and research lie, to the industry. This is not a new concept, but it is really emphasized in AI context. It has been created a vicious circle, in which universities lost faculty and researchers to the benefit of private companies because they can offer a combination of higher salary, more interesting problems, relevant large unique datasets, and virtually infinite resources. This does not allow universities to train the next generation of PhD students that would be in charge of fostering the research one step ahead. The policy suggestion is then to fund pure research institutes (e.g., OpenAI) or even research-oriented companies (as for instance Numenta) to not lose the invaluable contribution that pure research has given to the field.\n\nMost of the considerations made so far were either general or specific to big players, but we did not focus on different startup business models. An early stage company has to face a variety of challenges to succeed, and usually, they might be financial challenges, commercial problems, or operational issues.\n\nAI sector is very specific with respect to each of them: from a financial point of view, the main problem regards the absence of several specialized investors that could really increase the value of a company with more than mere money. The commercial issues concern instead the difficulties in identifying target customers and trying head around the open source model. The products are highly new and not always understood, and there might be more profitable ways to release them.\n\nFinally, the operational issues are slightly more cumbersome: as abovementioned, large dataset and consistent upfront investments are essential and might be detrimental to a shorter-term monetization strategy. A solution to the data problem may be found in the \u201cdata trap\u201d strategy, that in venture capitalist Matt Turck\u2019s words consists of offering (often for free) products that can initialize a data network effect. In addition, the user experience and the design are becoming tangibly relevant for AI, and this creates friction in early stage companies with limited resources to be allocated between engineers, business, and design.", 
        "title": "The DeepMind Strategy \u2013 Francesco Corea \u2013"
    }, 
    {
        "url": "https://blog.produvia.com/curated-news-1-93527fda6808?source=tag_archive---------2----------------", 
        "text": "The race for Artificial General Intelligence (AGI) is well underway. There are many companies pursuing the idea of creating an AI that is as \u201csmart as a human across the board.\u201d (Wait But Why, 2015)\n\nThere are many different types of artificial intelligence. For the purpose of simplifying the complex, let\u2019s consider the following three AI categories:\n\nArtificial intelligence can also be understood as a pyramid of five stages: computing, automation, narrow intelligence, general intelligence, and superintelligence.\n\nComputing is any type of calculation that includes both arithmetical and non-arithmetical steps and follows a well-defined model understood and described by an algorithm; automation is technology by which a process or procedure is performed without human assistance; narrow intelligence is AI that specializes in one area; general intelligence is AI that specializes in all areas; superintelligence is AI that is smarter than humans in every way.\n\nThe company or organization that controlled this AI would become the next Superpower.\n\nLet\u2019s look at the competitive landscape for artificial general intelligence. There are many companies competing to build their own AGI. Three private companies come to mind: Deepmind, Open AI, or Singularity Net. Open AI and Google\u2019s DeepMind share a similar vision. Google\u2019s DeepMind is on a \u201cscientific mission to push the boundaries of AI, developing programs that can learn to solve any complex problem without needing to be taught how.\u201d (DeepMind, 2018) OpenAI is a \u201cnon-profit AI research company, discovering and enacting the path to safe artificial general intelligence.\u201d (OpenAI, 2018) SingularityNET is a open-source \u201cprotocol for AI algorithms and models\u201d which aims to provide \u201caccess a global library of AI tools\u201d by \u201ccombining open source principles, blockchain integration\u201d and machine learning. (SingularityNET, 2018) SingularityNET is \u201ccollection of smart contracts for a decentralized market of coordinated AI services.\u201d This allows anyone to \u201cadd an AI/machine learning service to SingularityNET for use by the network\u201d (SingularityNET Whitepaper, 2017).\n\nThere are also many countries pursuing the development and research of AI\u200a\u2014\u200aUnited States, China, Russia, United Kingdom, Israel and South Korea. In 2015, the United States government invested more than $1 billion in artificial intelligence research (Quartz, 2015). In 2018, it is reported that the United States private investment is around $70 billion per year. (Japan Times, 2018) In 2017, the Chinese government, announced plans to invest tens of billions of dollars into research and development of artificial intelligence (Technology Review, 2017). In 2018, it is reported that the Chinesse annual private investment in AI is under $7 billion per year. (Japan Times, 2018)\n\nIf an algorithm were to exist, what would it look like? Pedro Domingos believes that it is possible to build a master algorithm in which \u201call knowledge\u200a\u2014\u200apast, present, and future\u200a\u2014\u200acan be derived from data by a single, universal learning algorithm.\u201d (The Master Algorithm, 2015)\n\nWho will win this AI war? I believe that the war will be won by a company or organization that creates an AI able to use the best combination of algorithms to accomplish it\u2019s goal. Imagine the AI wants to detect cancer. This AI would then hire other AIs (other algorithms) to solve smaller problems, which would then be stitched together to solve the larger problem.", 
        "title": "Race to Artificial General Intelligence (AGI) \u2013"
    }, 
    {
        "url": "https://deephunt.in/deep-hunt-issue-10-f0adfda93342?source=tag_archive---------3----------------", 
        "text": "Samsung acquires Viv, a next-gen AI assistant built by the creators of Apple\u2019s Siri\n\nSamsung has agreed to acquire Viv, an AI and assistant system co-founded by Dag Kittlaus, Adam Cheyer and Chris Brigham who also co-founded Siri.\n\nA necessity in building an open source self-driving car is data. Lots and lots of data. And Udacity is helping out by open sourcing the data collected in Mountain View, CA by Lincoln MKZ. Along with an image frame from their cameras, they also include latitude, longitude, gear, brake, throttle, steering angles and speed.\n\nSelf-driving car testing in California is becoming a badge of progress for companies working in the space. Joining many others like Tesla, Cruise (which got its license before being acquired by GM), promising startup Drive.ai, and Baidu already, Wheego and Valeo bring the total companies to have this honor to 17!\n\nInsight Artificial Intelligence Fellow Program launches in Silicon Valley and New York\n\nExcited to announce the launch of the Insight Artificial Intelligence Fellows Program. This free, seven-week professional fellowship program will help scientists and engineers with machine learning experience to learn cutting-edge techniques in deep learning and join top AI teams in Silicon Valley and New York City.", 
        "title": "\u2014 Issue #10 \u2013"
    }
]