[
    {
        "url": "https://blog.getnexar.com/introducing-the-nexar-challenge-deep-driving-into-the-future-31e0ed9db4b7?source=tag_archive---------0----------------", 
        "text": "Nexar is building the first over-the-top vehicle-to-vehicle (V2V) network app that turns smartphones into connected AI dashcams. Leveraging millions of crowdsourced road miles from dozens of countries, jointed with deep learning on imagery and sensors as well as artificial intelligence driving-cognition technologies, Nexar provides a new, delightful, and really safe driving experience. This technology has the potential of saving the 1.3 million people who die on the road every year.\n\nSince launching in February 2016, we have tracked upwards of 20 million miles and recorded more than a half-million instances of driving incidents worldwide\u200a\u2014\u200aand we\u2019re just getting started.\n\nAlthough remarkable progress has been made in computer vision, the vast majority of both existing theories and technologies have yet to transition to the real automotive world, where there is a huge variety of road infrastructure, side buildings, road signs, vehicles, and most importantly, human driving behaviors.\n\nAt Nexar, we\u2019ve assembled a first class technical team dedicated to infusing state-of-the-art deep learning techniques into our world to help make it collision-free. Deep learning plays a key role in many of our ongoing projects: from a real-time avoidance system that can sense static and moving objects to prevent vehicle, cyclist and pedestrian collisions, to learning driving policies for an optimal and safe driving experience. We apply deep learning to various challenges of driving including: semantic scene understanding, cross-modal transfer learning, driver awareness understanding, and driver behavior policy.\n\nNow we want to open some of our deep driving challenges to the outside world and invite aspiring researchers to test their chops and potentially even join our team. Today, we are excited to announce our first Nexar Challenge (Using Deep Learning for Traffic Light Recognition), where you can compete to win prizes (1st place $5,000, 2nd place $2,000, 3rd place iPhone 7) and join our mission to make the roads safer.\n\nIn the traffic-light challenge, you will take the first step towards a collision-free world by applying deep learning techniques to recognize traffic lights in a car\u2019s driving direction while taking into account the network computational budget.\n\nWe can\u2019t wait to see what our challenge participants will come up with, and we hope you will have as much fun as we\u2019ve had while working on the deep-driving challenges here at Nexar.\n\nLet\u2019s Go!\u00a0\n\nClick Here For More Details", 
        "title": "Introducing The Nexar Challenge: Deep-Driving into the Future"
    }, 
    {
        "url": "https://medium.com/@venkatnagaswamy/marketing-automation-2-0-part-ii-adding-a-i-to-automation-4c1e27add1ce?source=tag_archive---------1----------------", 
        "text": "In Part I of this post, I ran through some of the issues with \u201cmarketing automation\u201d that make it a misnomer; there\u2019s precious little automation at work within present-day MA platforms.\n\nWe\u2019re taught to be skeptical about anything that seems to offer a panacea. But there\u2019s an elegant solution to the problems besetting Marketing Automation 1.0. It\u2019s not some pundit\u2019s hypothesis, either, but an answer that\u2019s being implemented in the here-and-now.\n\nArtificial intelligence is the cure, making one-to-one personalization and account-based marketing (ABM) into actionable realities.\n\nSince all deals are account-based, it\u2019s corollary that future B2B marketing automation will be account-based, demanding exactly the customized engagement A.I. provides.\n\nHow does that work in practice?\n\nHere\u2019s an example: One Mariana client gave both us and a traditional lead-gen service the same list of 5,000 companies, then asked each of us to identify the individuals at those firms in charge of SEM:\n\nIn other words, AI was able to extract twice as many qualified leads from the same data.\n\nThe power to make intelligent associations from a huge number of data points is how AI discerns patterns and behaviors that identify targets, rather than relying on titles and roles.\n\nIn fact, old-school lead-gen can be stymied by the fact that many of the people a marketer wants to reach don\u2019t go by the title being used in its persona-building. For example, we found that only 20% of people who are fulfilling the functions of a data architect actually used the title \u201cdata architect.\u201d The rest\u200a\u2014\u200a80%!\u200a\u2014\u200awent by titles like software engineer, senior software engineer, development engineer or others.\n\nDeep learning help solve all five of the issues we touched on in our previous post, where the last generation of marketing automation solutions came up short:\n\nCompanies of all types are already implementing machine learning in areas beyond marketing. \u201cAdopting AI\u201d is a hot meme in martech, the same way \u201cadopting marketing automation\u201d was over the last few years.\n\nOne quote that underscores the impact of AI throughout the enterprise comes from Gartner: \u201cBy 2018, 50% of the fastest-growing companies will have fewer employees than (they do) instances of smart machines.\u201d\n\nThe best deep learning systems don\u2019t require a marketer toss out their present marketing automation platform. They\u2019ll partner happily with it, sitting atop a marketing stack and integrating fluently with existing inbound/outbound tools and third-party plugins alike.\n\nSince they\u2019re SaaS systems, companies benefit from ease of integration and scalability, resulting in quick ramp-up so they\u2019re hard at work ASAP.\n\nFollow the six steps you\u2019ll see outlined next to add A.I. to your marketing automation suite, so you\u2019ll be perfectly positioned to reap the game-changing benefits of artificial intelligence.", 
        "title": "Marketing Automation 2.0, Part II: Adding A.I. to Automation"
    }, 
    {
        "url": "https://medium.com/data-science-at-home/ahem-detector-with-deep-learning-2c96219b0e28?source=tag_archive---------2----------------", 
        "text": "Do you know why you can\u2019t hear the ugly ahem sounds on the podcast Data Science at Home?\n\nBecause we remove them. Actually not us. A neural network does.\n\nLet me introduce the ahem detector, a deep convolutional neural network that is trained on transformed audio signals to recognize \u201cahem\u201d sounds. The network has been trained to detect such signals on the episodes of Data Science at Home, the podcast about data science at worldofpiggy.com/podcast\n\nSlides and technical details are provided provided here. Before getting to the details, a few concepts should be clarified.\n\nTwo sets of audio files are required, very similarly to a cohort study:\n\nWhile the detector works for the aforementioned audio files, it can be generalized to any other audio input, provided enough data are available. The minimum required is ~10 seconds for the positive samples and ~3 minutes for the negative cohort. The network will adapt to the training data and can perform detection on different spoken voice.\n\nOnce the training audio files are provided, just load the training set and train the network with the code in the ipython notebook. Make sure to create the local folder that has been hardcoded in the script files below. Build training/testing set before running the script. Execute first\n\nA GPU is recommended as, under the conditions specific to this example at least 5 epochs are required to obtain ~81% accuracy.\n\nA new audio file must be trasformed in the same way of training files. This can be done with\n\nThen follow the script in the ipython notebook that is commented enough to proceed without particular issues. The whole project is on github", 
        "title": "Ahem detector with deep learning \u2013 Data Science at Home \u2013"
    }
]