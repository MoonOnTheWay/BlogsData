[
    {
        "url": "https://chatbotslife.com/chatbots-make-useful-and-intelligent-bot-to-win-telegram-or-alexa-prize-abaefe839dee?source=tag_archive---------0----------------", 
        "text": "Here\u2019s a summary from our recent \u201cchatbot\u201d lecture at CTU FIT. The recent boom of messaging apps and breakthroughs in artificial intelligence make the field of AI chatbots a hot topic in today\u2019s market.\n\nChatbots are still far from being smart. They are much more useful for simple \u201ctransactions\u201d than for an enjoyable conversation.\n\nMost general chatbots frankly just sucks\u200a\u2014\u200aand are considered still in their infancy for now.\n\nMany developers are building chatbots on various platforms. However, most of them aren\u2019t very sophisticated. They\u2019re mostly \u201ctransactional\u201d, meaning that you can use them to call third party services. Conversational bots are useful just in very narrow domains (eg. talking about sport, movies or any other factoid conversations) as demonstrated by recently released Google AI bot.\n\nThe research of conversational bots is now very intensive and there are open source solutions enabling AI bots multimedia conversation with users. Most of solutions are however quite simple\u200a\u2014\u200athe conversation is programmed using a dialog manager.\n\nThere are open source dialog managers to almost any programming environment and the usage is quite simple.\n\nThere are also more sophisticated dynamic approaches as demonstrated by ViV.ai recently acquired by Samsung.\n\nSome chatbots made it to the market already and seem to generate some profit.\n\nThere are two teams at Czech Technical University in Prague working on chatbots.\n\nThey are backed by Data Science Laboratory and eClub that jointly organized their summer camps for talented students. Bellow are some of the outcomes of summer projects and long term research activities of CTU staffs.\n\nThis project under Datalab Summer Camp was sponsored by the Prague Visitor company. Most of the results will be open-sourced.\n\nHere are the highlights from the amazing demo presented by David P\u0159\u00edhoda and Jakub Drd\u00e1k both students of Faculty of Information Technology, CTU in Prague.\n\nThe architecture of the chatbot system communicating via Facebook Messenger consists of Wit.ai based intent recognition, their own dialog manager and a lot of third party services and data sources. It uses high quality local data from Prague Visitor and the Goout company (thanks for the API) so the Google chatbot cannot compete simply because it does not have access to such high quality live local data.\n\nThe bot is still more transactional than conversational, however it can understand surprisingly well, mostly thanks to the Wit.ai intent recognition engine.\n\nWhat impressed me is the feature \u201cmy perfect week\u201d. The bot asks you for the access to your Facebook profile.\n\nThen it extracts your preferences, descriptions of events you like or visited, translate it eventually to English and transforms it to tags using the Geneea Natural Language Processing API (thanks guys). Then tags are extracted from data provided by Prague Visitor, Goout, Trip Advisor and Foursquare, and the recommender engine suggests best suiting events just for you.\n\nYou can later filter based on these tags (e.g. just #Jazz concerts) or ask the bot for more restricted recommendations. There are more conversation options supported by the bot.\n\nHere is the recent set of implemented functions and it is growing everyday.\n\nWe have first testers, so we can observe how they interact with the bot. It was designed for tourists but my impression is that the bot will be pretty useful for locals too.\n\nGuys plan to win the Telegram prize. You do not need to be based in Prague, if you like to test it or participate. Just fill in the form.\n\nRecent developments in machine learning and artificial intelligence bring new opportunities for chatbot researchers and developers.\n\nDeep convolutional neural networks that proved superb performance in image processing can soon replace traditional methods for feature extraction from text. As demonstrated in this article, such approaches can be successfully applied to any text in any language.\n\nGenerative recurrent neural networks can capture higher level concepts and even compose poems. Generating chatbot responses is the obvious next step.\n\nSuch networks can also be used for the question answering.\n\nWhen you have enough data to train it, such as twitter conversations.\n\nRecurrent neural nets (RNNs) are state-of-the-art techniques in the document translation. So called Neural Machine Translation is a rapidly developing field making statistical approaches in linguistics obsolete. Here you can use one RNN as encoder to internal neural embedding and other RNN as decoder into target language. Chatbots can therefore understand any language soon.\n\nDeeplearning advances are improving speech recognition as well. The speech recognizer implemented in Lucida.ai bot can soon be replace by a single deep neural network (DNN) recently introduced by the Baidu research. This DNN can recognize both English or Mandarin Chinese and can be trained to any language (when data are available). Another component is a speech generator. Learn how Google DeepMind improved speech generation using DNNs.\n\nAnother challenge and great opportunity is to improve chatbots using advanced recommender system. Such systems need to be intent sensitive to be useful. There are some studies showing how to extend existing recommender systems in this direction, but a lot has to be done. Our recommender system already bring required flexibility and we are working hard to improve it.\n\nIn the second part of the lecture, our colleagues from Eclub presented their bot for the factoid question answering so you can try their demo and talk about movies. They also developed (within the Eclub Summer Camp) the Alquist manager for conversational bots and showed, how they can converse about mobile phones in the Czech language.\n\nThey consider to apply for the Alexa prize and look for students that are willing to develop conversational bots.\n\nYou should definitely keep your eye on AI bots with the rise of messaging apps and significant improvement of AI capabilities. Breakthrough in the field is close and you can already build useful and intelligent bots.\n\nLet us know if you are interested in testing our bots, help us with development, participating in competitions, or you\u2019re just into research.\n\nYou can develop your own chatbot instantly using our python template.", 
        "title": "How Deep Learning and Recommender Systems make Chatbots useful and more Intelligent"
    }, 
    {
        "url": "https://medium.com/@JarrettSmalley/quantum-deep-learning-4e225624931?source=tag_archive---------1----------------", 
        "text": "A lot of focus of research in the tech world in recent years has been on utilizing deep learning. Deep learning is a type of machine learning which utilizes connected graphs to simulate an array of artificial neurons [1]. Google has taken a particular interest in utilizing deep learning for a vast array of products. The Google Brain team, a research group composed of individuals who develop their own projects with machine learning, has implemented deep learning into multiple products, such as the Android speech recognition software and Google\u2019s photo search capabilities [2]. Google has also done extensive research with quantum computing, specifically in a partnership with NASA using D-Wave\u2019s [3] quantum annealing machine. Quantum computing is a field of computing aimed at developing a computer which takes advantage of various effects found in quantum mechanics to represent information in ways that traditional-classic computers cannot. The merge between these two advancing technologies is what I intend to lightly observe in this week\u2019s blog.\n\nWiebe et al., in their Quantum Deep Learning [4], of Microsoft Research developed a deep learning algorithm which could be implemented on a full scale quantum computer. In a type of traditional deep learning an algorithm, Gibbs sampling, is used to obtain sequences of observations [5]. This algorithm is often very slow and uses many computing resources. Wiebe et al. showed an algorithm which could greatly speed up this task, while utilizing less resources (in the condition where quantum computers are easily obtained and used). Adachi and Henderson, of Lockheed Martin, later documented how the D-Wave quantum annealing machine could be (and has been) used to help train a deep learning model. Their results showed similar accuracy ratings to classic computers training deep learning models, but in less time than classic computers. They go on to suggest how quantum annealing machines could be used in the future to continue to speed up deep learning tasks. Currently, Lockheed uses these works experimentally as research, but intend to use them in the near future.\n\nEven with these advancements and findings, quantum deep learning still seems to face multiple obstacles before it dominates the machine learning scene. Researchers from the Google Brain team do not believe that current quantum computing resources are really able to beat classic computers in deep learning as they currently exist, blaming the fact that current quantum computers cannot hold the vast amount of parameters that are needed to implement deep learning on large, full scale problems [5]. Another potential problem can be found in what is currently considered quantum. D-Wave\u2019s quantum annealing machine has drawn a lot of criticism from those who claim that D-Wave\u2019s machine is good, but it is not true quantum computing, and that the full potential which could be realized from quantum mechanics cannot be realized by this machine [6]. Current quantum resources may probably not be technologically advanced enough to do everything that is needed to fully implement deep learning with quantum.\n\nCurrently, there are multiple different companies pushing the boundaries of quantum computing and many hope to see great advancements in the near future [7]. The implementation of deep learning on a full quantum computer will most likely have unimaginable results, as this will exponentially speed up research efforts, while simultaneously increasing what these technologies might be applied to, as the technology became more common. Ultimately, quantum deep learning will probably see a new \u2018explosion\u2019 in technology and data science, but will their perhaps be any resultant downside? Will this possibly-infinitely powerful resource result in that singularity event that will cause the machines to rise up against humanity? Only time will tell as we continue to pave our way forward into the great unknown of technology.", 
        "title": "Quantum Deep Learning \u2013 Jarrett Smalley \u2013"
    }, 
    {
        "url": "https://medium.com/@imayhaveblinked/deep-learning-scala-and-why-everything-is-a-stream-93ae7f20bf9c?source=tag_archive---------2----------------", 
        "text": "Deep learning is defined as a (potentially infinite) set of network topologies with interactions between nodes in these networks governed by math functions, input -> goals(math) -> output.\n\nWhy are functional languages excellent fits for deep learning?\n\nWhen a programming language expressively continues these interactions inside business logic one can control the deployments of these functions over hardware with great benefits in performance.\n\nNot necessarily deep learning related. By enabling an easy way of defining an agnostic DSL Scala allows flexibility in modeling intent: ~> is beautiful.", 
        "title": "Deep learning, Scala and why everything is a stream."
    }, 
    {
        "url": "https://medium.com/@tristan.mcinnis/thanks-for-this-list-i-would-say-you-should-add-some-of-the-china-startups-6fd56f84289a?source=tag_archive---------3----------------", 
        "text": "Thanks for this list\u200a\u2014\u200aI would say you should add some of the China startups. I\u2019m a consultant in Shanghai China working on two autonomous vehicle projects at the moment and have been spending a lot of my time looking at the market here.\n\nI would definitely add some of the Chinese startups to the list. One good example would be UISEE: http://www.uisee.com/\n\nSee the NYTimes article here: http://www.nytimes.com/2016/04/04/technology/chinas-companies-poised-to-take-leap-in-developing-a-driverless-car.html?_r=0\n\nYunOS from Alibaba is also interesting. I would suspect that since Alibaba has companies that do HD Mapping (e.g.:AutoNavi) that they can have the advantage with the car OEMs in China when they get closer to bringing Lvl 3/4 cars to the market.", 
        "title": "Thanks for this list \u2014 I would say you should add some of the China startups."
    }
]