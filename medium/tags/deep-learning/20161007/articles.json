[
    {
        "url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-6-partial-observability-and-deep-recurrent-q-68463e9aeefc?source=tag_archive---------0----------------", 
        "text": "In this installment of my Simple RL series, I want to introduce the concept of Partial Observability and demonstrate how to design neural agents which can successfully deal with it. As always, in addition to a theoretical discussion of the problem, I have included a Tensorflow implementation of a neural agent which can solve this class of problems.\n\nFor us humans, having access to a limited and changing world is a universal aspect of our shared experience. Despite our partial access to the world, we are able to solve all sorts of challenging problems in the course of going about our daily lives. In contrast, the neural agents we have discussed so far in this tutorial series are ill equipped to handle partial observability.\n\nWhen we think about the kinds of environments used until this point to train our networks, the agent has had access to all the information about the environment it might need in order to take an optimal action. Take for example the Gridworld used in Tutorials 4 & 5 of this series:\n\nBecause the entire world is visible at any moment (and nothing moves aside from the agent), a single frame of this environment gives the agent all it needs to know in order to maximize its reward. Environments which follow a structure where a given state conveys everything the agent needs to act optimally are called Markov Decision Processes (MDPs).\n\nWhile MDPs provide a nice formalism, almost all real world problems fail to meet this standard. Take for example your field of view at this very moment. Can you see what is behind you? This limited perspective on the visual world is almost always the default for humans and other animals. Even if we were to have 360 degree vision, we may still not know what is on the other side of a wall just beyond us. Information outside our view is often essential to making decisions regarding the world.\n\nIn addition to being spatially limited, information available at a given moment is also often temporally limited. When looking at a photo of a ball being thrown between two people, the lack of motion may make us unable to determine the direction and speed of the ball. In games like Pong, not only the position of the ball, but also it\u2019s direction and speed are essential to making the correct decisions.\n\nEnvironments which present themselves in a limited way to the agent are referred to as Partially Observable Markov Decision Processes (POMDPs). While they are trickier to solve than their fully observable counterparts, understanding them is essential to solving most realistic tasks.\n\nHow can we build a neural agent which still functions well in a partially observable world? The key is to give the agent a capacity for temporal integration of observations. The intuition behind this is simple: if information at a single moment isn\u2019t enough to make a good decision, then enough varying information over time probably is. Revisiting the photo example of the thrown ball A single image of a ball in motion tells us nothing about its movements, but two images in sequence allows us to discern the direction of movement. A longer sequence might even allow us to make sense of the speed of the ball. The same principle can be applied to problems where there is a limited field of view. If you can\u2019t see behind you, by turning around you can integrate the forward and backward views over time and get a complete picture of the world with which to act upon.\n\nWithin the context of Reinforcement Learning, there are a number of possible ways to accomplish this temporal integration. The solution taken by DeepMind in their original paper on Deep Q-Networks was to stack the frames from the Atari simulator. Instead of feeding the network a single frame at a time, they used an external frame buffer which kept the last four frames of the game in memory and fed this to the neural network. This approach worked relatively well for the simple games they employed, but it isn\u2019t ideal for a number of reasons. The first is that it isn\u2019t necessarily biologically plausible. When light hits our retinas, it does it at a single moment. There is no way for light to be stored up and passed all at once to an eye. Secondly, by using blocks of 4 frames as their state, the experience buffer used needed to be much larger to accommodate the larger stored states. This makes the training process require a larger amount of potentially unnecessary memory. Lastly, we may simply need to keep things in mind that happened much earlier than would be feasible to capture with stacking frames. Sometimes an event hundreds of frames earlier might be essential to deciding what to do at the current moment. We need a way for our agent to keep events in mind more robustly.\n\nAll of these issues can be solved by moving the temporal integration into the agent itself. This is accomplished by utilizing a recurrent block in our neural agent. You may have heard of recurrent neural networks, and their capacity to learn temporal dependencies. This has been used popularly for the purpose of text generation, where groups have trained RNNs to reproduce everything from Barack Obama speeches to freeform poetry. Andrej Karpathy has a great post outlining RNNs and their capacities, which I highly recommend. Thanks to the high-level nature of Tensorflow, we are free to treat the RNN as somewhat of a black-box that we simply plug into our existing Deep Q-Network.\n\nBy utilizing a recurrent block in our network, we can pass the agent single frames of the environment, and the network will be able to change its output depending on the temporal pattern of observations it receives. It does this by maintaining a hidden state that it computes at every time-step. The recurrent block can feed the hidden state back into itself, thus acting as an augmentation which tells the network what has come before. The class of agents which utilize this recurrent network are referred to as Deep Recurrent Q-Networks (DRQN).\n\nIn order to implement a Deep Recurrent Q-Network (DRQN) architecture in Tensorflow, we need to make a few modifications to our DQN described in Part 4 (See below for full implementation, or follow link here).\n\nFor this tutorial however I\u2019d like to work with something a little less flashy, though hopefully more informative. Recall our Gridworld, where everything was visible to the agent at any moment. By simply limiting the agent\u2019s view of the environment, we can turn our MDP into a POMDP. In this new version of the GridWorld, the agent can only see a single block around it in any direction, whereas the environment itself contains 9x9 blocks. Additional changes are as follows: each episode is fixed at 50 steps, there are four green and two red squares, and when the agent moves to a red or green square, a new one is randomly placed in the environment to replace it. What are the consequences of this?\n\nIf we attempt to use our DQN as described in Parts 4 and 5 of this series, we find that it performs relatively poorly, never achieving more than an average of 2.3 cumulative reward after 10,000 training episodes.\n\nThe problem is that the agent has no way of remembering where it has been or what it has seen. If two areas look the same, then the agent can do nothing but react in exactly the same way to them, even if they are in different parts of the environment. Now let\u2019s look at how our DRQN does in the same limited environment over time.\n\nBy allowing for a temporal integration of information, the agent learns a sense of spatial location that is able to augment its observation at any moment, and allow the agent to receive a larger reward each episode. Below is the Ipython notebook where this DRQN agent is implemented. Feel free to replicate the results yourself, and play with the hyperparameters. Different settings for many of them may provide greater performance for your particular task.\n\nWith this code you have everything you need to train a DRQN that can go out into the messy world and solve problems with partial observability!", 
        "title": "Simple Reinforcement Learning with Tensorflow Part 6: Partial Observability and Deep Recurrent\u2026"
    }, 
    {
        "url": "https://medium.com/frog-and-toad-are-cofounders/strange-decisions-e4809a668a29?source=tag_archive---------1----------------", 
        "text": "Owl sat down at his desk. \u201cI have realized that intelligence can be simulated, and that it\u2019s time I let the idea of our uniqueness go,\u201d he said with a yawn. \u201cI need to find out how long we have left, before we can build hardware capable of replicating my brain.\u201d\n\nOwl noticed a new product that had been developed by a startup at his incubator. It was a neural network that had been deep-learned to make hiring decisions. \u201cWhile there remain certain advantages to being human,\u201d remarked Owl, \u201cit\u2019s clear that this neural network has its own desires and goal systems.\u201d\n\nOwl decided to figure out how the computer had managed to replicate the decision-making process of a human brain.\n\nBut no matter how hard he looked, all he saw were programmers and data scientists who babbled to him about \u201ctensors\u201d and showed him spreadsheets of historical hiring data which had been hand-labeled with \u201cA+ choice\u201d and \u201cbad culture fit.\u201d\n\nOwl tried to chill, but he could not.\n\n\u201cIt may just be working in HR today, but what if this neural network grows bigger and smarter while I am not paying attention?\u201d said Owl. \u201cA powerful AI could be a danger to humanity.\u201d\n\nOwl\u2019s engineers fed the neural network random noise. The network \u201cdreamed\u201d about a 23-year old white male with a computer science degree and no children or outside hobbies. \u201cThe network has discovered the objectively perfect job candidate!\u201d gushed Owl.\n\nOwl\u2019s engineers re-trained the network. The network now rated candidates more highly if they had previously worked at a successful startup, or if either the first or third letters of their middle name were \u2018T\u2019. \u201cThe network is adapting, and is able to accurately predict the future!\u201d cried Owl.\n\nOwl demanded to see the brain of this adaptive, predictive AI. The engineers showed him connectivity diagrams of \u201cneurons\u201d and huge tables of numerical weights. \u201cBut these are just numbers,\u201d said Owl. \u201cShow me how the network learns and grows and thinks and feels.\u201d\n\nThe engineers rolled their eyes, and began classifying resumes with the software again. \u201cThe learning is back!\u201d shouted Owl. \u201cLearning, thinking, growing intelligences, all without human intervention! I will never sleep tonight!\u201d\n\nOwl talked to a writer from the New Yorker at a party. \u201cWho can tell us what goes on in the mind of this AI? Not you! Not me! It\u2019s unknowable.\u201d\n\nWith a start, Owl realized how important his discovery was.\n\nOwl got on his private jet. He flew to his compound in Big Sur. It was stocked with gold ingots and gas masks.\n\n\u201cTo a neural network,\u201d said Owl. \u201cWe humans must seem like slowed-down whale songs. Let it grow as smart as it wishes. I will stay right here where I am safe.\u201d\n\nAnd that is what he did.", 
        "title": "Strange Decisions \u2013 Frog and Toad are Cofounders \u2013"
    }, 
    {
        "url": "https://blog.asadmemon.com/shortest-way-to-deep-learning-41e704d65ef?source=tag_archive---------2----------------", 
        "text": "The reason these courses take so much time is because of all the theory and math to these algorithms. Which is good for writing accurate algorithms but a good hacker can just look it up when needed. If you, like me, just want to get your hands dirty asap then this post should help you wing it!\n\nTo fulfill prerequisites for the deep learning course, first we need to learn some ML algorithms and how to implement them in scikit-learn (a Python framework for Machine Learning).\n\nThe following plan should take a full weekend:\n\nThe first deep learning assignment is pretty hard so you are not alone. Here are some pointers for the final problem:\n\nYou already know a bit about linear regression, this assignment can be solved using an extended version of that, called Logistic Regression. You will need to read about it here. After that the sk-learn\u2019s docs about it should make some sense. Give it a shot!\n\nThe assignment is also explained in great detail in the next chapter. So don\u2019t worry if you don\u2019t understand all the bits yet.\n\nIf you are successful in understanding and solving the first assignment, the rest of the course shouldn\u2019t require any other resources.\n\nI should emphasize that this isn\u2019t a replacement for going through the full course. Choose this plan only if the alternative is not learning at all.", 
        "title": "Shortest Way to Deep Learning \u2013"
    }, 
    {
        "url": "https://gab41.lab41.org/across-the-network-ai-week-in-review-oct-7-59a14d7de905?source=tag_archive---------3----------------", 
        "text": "Across the Network\u200a\u2014\u200aAI Week in Review Oct\u00a07\n\nWelcome back to another edition of Across the Network\u200a\u2014\u200aLab41\u2019s weekly look at what is going on in the world of AI. This week, the lab team has been busy all week in DC for a series of events and meetings. For this reason our Slack channels have been a little quieter than usual, but they are still full of gems worth sharing! As always these are all links that I pulled from the Lab41 Slack channels.\n\nFull Resolution Image Compression with Recurrent Neural Networks\u200a\u2014\u200aA few months ago, Google used deep learning to slash data center cooling costs, and now Google is applying deep learning to compress images, which could reduce storage requirements. In this paper, Google uses an encoder/decoder network to compress images better than jpeg and without all that ridiculous blockiness. We think it is super cool!\n\nHyper Networks\u200a\u2014\u200aThese networks combine aspects of RNNs and deep ConvNets, using a small number of parameters to simulate a large neural network. This blog post presents an example of this Hyper Network generating handwriting. Check it out!\n\nVideo Pixel Networks\u200a\u2014\u200aThere has been a lot of recent work using deep networks to encode raw signals like WaveNet for digital audio and PixelCNN for raw image data. The Video Pixel Networks encode spatial and temporal dependenices among pixels in videos which is really computationally demanding and generally an impressive feat, and it also includes video of robots pushing things around\u2026winning!\n\nInsight Artificial Intelligence Fellow Program\u200a\u2014\u200aThis week Insight Data Science announced the launch of a free professional fellowship program targeted towards scientists and engineers with some ML experience who would like to learn more about cutting edge deep learning techniques and are seeking jobs with top AI teams in NYC or Silicon Valley. The seven week program is designed to fill the gap between academic ML and product development. A few of our own data scientists here at Lab41 are alumni of the Insight Data Science program, and we are excited to one day meet graduates of this new fellowship program! Whitepaper here.\n\nEuropean Conference on Computer Vision\u200a\u2014\u200aECCV is taking place next week from October 8- 16 in Amsterdam. Attendance includes admission to two invited tutorials by leading scientists in vision or multimedia\u200a\u2014\u200awe hope to make it to Bengio\u2019s tutorial \u201cDevelopments in Deep Learning\u201d and Tao Mei\u2019s tutorial, \u201cBridging Video and Language with Deep Learning.\u201d We are excited about the planned talks and tutorials since a few of us here at the lab will be in attendance! So if you attend and see us in our black North Face jackets or swanky new red Lab41 screen t-shirts, make sure to come say hi!", 
        "title": "Across the Network \u2014 AI Week in Review Oct 7 \u2013"
    }, 
    {
        "url": "https://medium.com/@cjemichael/will-artificial-intelligence-end-humanity-350a0365eddf?source=tag_archive---------4----------------", 
        "text": "The short answer is yes, if we let it.\n\nAlmost everyone I meet these days is talking about Artificial Intelligence. Most tech vendors say it\u2019s a core part of their offering, but only a few are really using it. There is clearly a gap between marketing fluff and the truth. Which is nothing new.\n\nArtificial Intelligence is really big news. It is already changing our world, and has potential to go much, much further. Will it cure all disease and solve big global problems, like hunger and poverty? Or will it make us all redundant then kill us off #skynet?\n\nArtificial Intelligence (AI for short) is best defined as intelligence exhibited by machines. This can be observed when a computer, or a robot controlled by a computer, acts in a way which appears intelligent.\n\nAnts are intelligent to a certain extent. So, perhaps a better definition is computer systems able to perform tasks requiring human intelligence.\n\nA computer telling you 2+2=4 is not AI. However, a self driving car is a good example of a computer utilising as much, if not more, intelligence than a human.\n\nWhat\u2019s the difference between machine learning and deep learning?\n\nMachine learning is related to AI. It is a technique whereby computers (or machines) are given the ability to learn without being explicitly programmed. Rather than follow a set of pre-defined instructions, the machine is trained using large volumes of data along with some clever algorithms, so over time it gets better and better.\n\nA real world example of machine learning is number plate recognition. The \u2018machine\u2019 is shown thousands of images of cars with number plates and it then learns to work out which portion of the image contains the number plate and to decipher the number plate into a text string.\n\nDeep learning is an extension of machine learning. Where machine learning relies on nonlinear or parallel processing (i.e. multiple calculations being performed at the same time, rather than in a linear sequence), deep learning requires a neural network, essentially a complex network much like the human brain, which adds multiple layers and connections.\n\nIn simple terms it is machine learning on steroids, which can enable the processing of more data, more quickly and with less manual input.\n\nWhat are the benefits of AI?\n\nThere are many benefits AI can bring to us all. Here are three real-world examples:\n\nSo why is AI such big news now?\n\nIt can be argued that AI started with the development of a calculating machine by Wilhelm Schickard in 1623. However it was not until 1956 that the field of AI research was formally founded at Dartmouth College.\n\nThen in 1997, IBM developed a computer called Deep Blue which became the first computer to defeat a chess grand master, Garry Kasparov. Earlier this year (2016), Google developed a computer system called AlphaGo which beat Fan Hui, Europe\u2019s reigning Go champion. Go is an exponentially harder game to master than chess and even Google\u2019s experts were not expecting such a break through till 2025.\n\nWe are seeing more step changes in the capabilities of AI and we are seeing these earlier than predicted. Things are getting faster.\n\nThere are three critical components needed for machine learning, deep learning and hence AI:\n\nAccording to Moore\u2019s law, computers double in power every two years. Over the past 40 years, this exponential growth has been a key enabler in the development of AI.\n\nBut over the last 5\u201310 years we have seen something else too. The rapid adoption of social networks, mobile technology and now Internet of Things (IoT), mean that we are creating more data than ever before. According to statistics for 2015, we are creating 2.5 quintillion Bytes of data every day, which would fill 10 million Blu-ray discs. And these discs when stacked on one another, would measure the height of 4 Eiffel Towers.\n\nWith the advent of cloud computing, tech giants like Amazon, Microsoft and Google have enabled very cheap storage for (almost) limitless volumes of data. Even more significantly, they are also now providing access to large arrays of extremely powerful networked computers, which in turn employ Graphical Processor Units (GPUs). And it is these GPUs which are ideally suited to machine and deep learning.\n\nThere are also an increasing number of platforms (many of them open source) which make it easier and quicker to build AI solutions. A good example of this is TensorFlow.\n\nSo the promise is exponentially more data, more processing power and better algorithms, accessible to everyone at an affordable price.\n\nHow can I use AI in my business?\n\nHere are my top tips:\n\nOf course there are many more providers and partners who can help. Just be aware that quite a few are making empty promises.\n\nWhere is this all going?\n\nDepending on who you believe, the cleverest machines right now have the cognitive ability of a small mammal, although in many cases they can perform individual tasks (like playing Go) much better than humans.\n\nThe scary thing is that they are getting better so quickly. The technological singularity is the hypothetical advent of artificial general intelligence (also known as \u201cstrong AI\u201d). Such a computer, computer network, or robot would theoretically be capable of recursive self-improvement (redesigning itself), or of designing and building computers or robots better than itself. According to the experts, this will happen some time between 2030 and 2045.\n\nEventually a machine will have more intelligence than all humans on the planet combined. When you combine this with the speed of development in other fields, like robotics and nano technology, it all gets rather worrying. Imagine these robotic dogs becoming our next police force or army.\n\nThe doomsday scenario is that we don\u2019t build in a kill switch and machines start to make big decisions without us. Like manipulating the economy, or starting a war.\n\nHowever I am remaining optimistic. AI has so many applications to help people, business and society as a whole. We just need to do two things.\n\nThe recent partnership on AI, formed by Google, Facebook, Amazon, IBM and Microsoft, is a great start.\n\nWe now need to reform our education system - to focus on Maths and coding. If we can make this fun and get more kids to love it, then we\u2019ve got a good chance.\n\nHow do I learn more?\n\nIf you want to know more, follow any of the links in this post. Whatever you do, don\u2019t bury your head in the sand. Read as much as you can, play with it and if possible building something.\n\nUs humans need to stay ahead of the machines.", 
        "title": "Will Artificial Intelligence end humanity? \u2013 Chris Michael \u2013"
    }, 
    {
        "url": "https://medium.com/@reworkyulia/top-10-areas-of-machine-intelligence-you-need-to-know-3f074b53f7bd?source=tag_archive---------5----------------", 
        "text": "The artificial intelligence market is growing rapidly, and companies are now looking to invest in technologies that can help them gain a competitive edge in business. What are the latest breakthroughs in machine intelligence research and how will their application impact the future of business and society?\n\nMachine Intelligence is the umbrella term for the growing ecosystem of companies working in the areas of artificial intelligence, deep learning, machine learning and robotics fields. The explosion of this rapidly advancing market has caught the attention of press and an increasing number of large-scale investments, and despite the hype there are valuable applications of the technology which can be used to help us to solve real challenges in business and society.\n\nWith only one month to go, we\u2019re highlighting the 10 not to be missed topics at the upcoming Machine Intelligence Summit, taking place in New York on 2\u20133 November.\n\nThe Future of Talking Machines: What\u2019s Next?\n\n1. Facebook AI Research (FAIR) have created memory networks to improve natural language understanding for question answering and dialogue management. Read our Q&A with summit speaker Antoine Bordes, Research Scientist at FAIR, here.\n\n2. How can natural language processing (NLP) help you develop better products? Avneesh Saluja of Airbnb gives us an insight into how the company that changed travel are leveraging machine intelligence technologies.\n\n3. How can machine intelligence improve education? Chaitanya Ekanadham from Knewton will give chase expertise on using deep learning to identify deficiencies, provide appropriate remediation, and report actionable insights to students, teachers, and administrators.\n\n4. Industries such as healthcare are prime targets for disruption by machine intelligence. At the summit, we\u2019ll be holding a session that looks at the impact of AI on areas like diagnostics and drug discovery, as well as the ethics and risks of applying machine intelligence to medicine and healthcare.\n\n5. Worried about the future of food and how we will be able to feed the growing world population in 2050? Erik Andrejko from Climate Corporation will be delivering a presentation on using machine intelligence in agriculture for a more efficient and sustainable food supply chain.\n\n6. Nervana Systems, a renowned company in the machine learning space, was recently acquired by Intel in a bid to improve their AI offering. Hanlin Tang, Senior Algorithms Engineer, will join the summit to share expertise on using deep learning at scale.\n\n7. Clement Farabet join us again to update us on how Twitter is using deep learning for Content Representation. You can view his previous presentation here.\n\n8. Machine learning is teaching computers to predict future human behaviour. Don\u2019t miss Carl Vondrick\u2019s talk on his pioneering DL algorithms that use YouTube videos and TV Shows to train machines in clairvoyance.\n\nHow Can You Leverage Machine Intelligence For Your Business?\n\n9. Machine intelligence can provide a sharp competitive edge in business. Alexander Statnikov, VP of Machine Learning and Digital Modeling at American Express, joins us on the panel discussion to explore how advances in AI are helping them protect their clients.\n\n10. Are you looking to hire experts in machine intelligence areas like neural networks, social robotics or computer vision? Or perhaps you\u2019ve just graduated and are ready to share your skills with the AI world? At our speed-networking talent expo you can connect with your dream employer or employee!\n\nAttendees at the summit will include CTOs, founders, data scientists, researcher directors, software engineers and entrepreneurs from companies and institutions such as Google, Accenture, Intel, Fujitsu, Capital One, Harvard University, Comcast, Etsy, Samsung, MIT and more. Join us there to connect with and learn from the leaders of the machine intelligence revolution.\n\nThe Machine Intelligence Summit will be taking place in New York, on 2\u20133 November 2016. Tickets are limited for this event, so register early to avoid missing out! Book your place at the summit here.", 
        "title": "Top 10 Areas of Machine Intelligence You Need To Know"
    }, 
    {
        "url": "https://medium.com/@willgdjones/tensorflow-tutorials-94de9f3e97c8?source=tag_archive---------6----------------", 
        "text": "Instead of reading through tutorials, I know that the best way to learn is to write tutorials yourself. As such, here are my own version of the common beginner deep learning tutorials which use the MNIST dataset, a data-set of handwritten digits from Yann LeCunn. They are written as self-explanatory Jupyter Notebooks and assume TensorFlow is installed. I\u2019m using an NVIDIA Quadro M6000 GPU. The tutorials implement logistic regression, a single-later perceptron, and a multi-layer perception.", 
        "title": "Tensorflow tutorials \u2013 Will Jones \u2013"
    }, 
    {
        "url": "https://medium.com/@tanaypratap/is-ai-going-to-eat-your-pie-92839bf3c1a7?source=tag_archive---------7----------------", 
        "text": "Let\u2019s do a little crystal ball gazing! shall we? Artificial Intelligence. Call it Data Science, Machine Learning, Deep Learning or whatever, we don\u2019t know what it will be called after 20 years but these fields or their kids will be the champions of tech and tech related jobs.\n\nWhy? Because its major job is to render other people jobless. The advances that are being made everyday, anything which is repetitive and doesn\u2019t require original thinking can be replaced in another 10 years by AI.\n\nThis starts from replacing the drivers today for cabs, tomorrow for trucks. If you can master computer vision and thinking related to it the possibilities are limitless.\n\nLeave the biggies for moment, granted that they have resources and capital to invest, even a small farmer in Japan replaced people with bot for sorting cucumber! Do you see? This is such a menial task and if you read the full story you will realize how many problems he has solved with this single approach.\n\nBots are the new conversationalists. They are in a very nascent state but down the line they are going to replace Call Center jobs and cut the need of a human to assist at many places. Leave Siri and Google Now for a moment, even the new players are mastering this tech. For instance, this company does your day to day tasks like booking a cab or airplane using bots. Just see how much these companies, Amazon and Google\u00a0, are investing in bots. Microsoft recently selected 13 startups to mentor and all have AI at its core theme.\n\nNow let\u2019s come to MBAs and business decision makers. Well big data got the first slice out of their jobs and AI will cut even a bigger one. It will not only provide insights into business it will also start predicting the next best move for it. See here, AI taking decisions for where to invest!\n\nOkay, what about entertainment, AI can\u2019t entertain us right? Wrong! You will be amazed that Google is creating music and art using AI. There\u2019s this fashion company which is designing clothes, using, no prizes for guessing it \u2018AI\u2019. Another one here is trying to release fashion lines based on it, and this is not Google, this is a startup from India! And this one is amazing, IBM Watson creates a movie trailer itself for a movie which is based on AI.\n\nAnother big area where AI is faring well is Healthcare. It can predict what diseases you are most susceptible to based on your DNA and habits. This company here, is counting blood cells using AI, this job required a human till now and was susceptible to errors which could be very dangerous. I read yesterday that Microsoft is going to \u201csolve\u201d Cancer in 10 years, again, using AI.\n\nThe industrial revolution automated a lot of jobs, then computers came and did that again and next it will be AI. Computers have never fared well when it comes to pattern recognition and decision making but that is changing now.\n\nThere\u2019s a huge paradigm shift where in instead of writing programs for computers we are training them how to write programs themselves. I would suggest that irrespective of your current field, start at least understanding how this works. It\u2019s no rocket science,and no you don\u2019t need a fancy PhD to start even using it. Here\u2019s a small blog post which I wrote and which you may find useful in case you want to start learning it.\n\nWhile we are far far away from Matrix or Skynet type AI we are very near to a future where you don\u2019t have to work just for the sake of it. If one is not ambitious enough and wants to live life in a comfortable manner he can just relax and let the AI minions do the work! For others, there\u2019s going to be a lot of cutting edge research work!", 
        "title": "Is AI going to eat your pie? \u2013 Tanay Pratap \u2013"
    }
]