[
    {
        "url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-1-5-contextual-bandits-bff01d1aad9c?source=tag_archive---------0----------------", 
        "text": "In Part 1 of my Simple RL series, we introduced the field of Reinforcement Learning, and I demonstrated how to build an agent which can solve the multi-armed bandit problem. In that situation, there are no environmental states, and the agent must simply learn to choose which action is best to take. Without a given state state, the best action at any moment is also the best action always. Part 2 establishes the full Reinforcement Learning problem in which there are environmental states, new states depend on previous actions, and rewards can be delayed over time.\n\nThere is actually a set of problems in-between the stateless situation and the full RL problem. I want to provide an example of such a problem, and show how to solve it. My hope is that those entirely new to RL can benefit from being introduced to each element of the full formulation step by step. Specifically, in this post I want to show how to solve problems in which there are states, but they aren\u2019t determined by the previous states or actions. Additionally, we won\u2019t be considering delayed rewards. All of that comes in Part 2. This simplified way of posing the RL problem is referred to as the Contextual Bandit.\n\nIn the original multi-armed bandit problem discussed in Part 1, there is only a single bandit, which can be thought of as like a slot-machine. The range of actions available to the agent consist of pulling one of multiple arms of the bandit. By doing so, a reward of +1 or -1 is received at different rates. The problem is considered solved if the agent learns to always choose the arm that most often provides a positive reward. In such a case, we can design an agent that completely ignores the state of the environment, since for all intents and purposes, there is only ever a single, unchanging state.\n\nContextual Bandits introduce the concept of the state. The state consists of a description of the environment that the agent can use to take more informed actions. In our problem, instead of a single bandit, there can now be multiple bandits. The state of the environment tells us which bandit we are dealing with, and the goal of the agent is to learn the best action not just for a single bandit, but for any number of them. Since each bandit will have different reward probabilities for each arm, our agent will need to learn to condition its action on the state of the environment. Unless it does this, it won\u2019t achieve the maximum reward possible over time. In order to accomplish this, we will be building a single-layer neural network in Tensorflow that takes a state and produces an action. By using a policy-gradient update method, we can have the network learn to take actions that maximize its reward. Below is the iPython notebook walking through the tutorial.\n\nHopefully you\u2019ve found this tutorial helpful in giving an intuition of how reinforcement learning agents can learn to solve problems of varying complexity and interactivity. If you\u2019ve mastered this problem, you are ready to explore the full problem where time and actions matter in Part 2 and beyond of this series.", 
        "title": "Simple Reinforcement Learning with Tensorflow Part 1.5: Contextual Bandits"
    }, 
    {
        "url": "https://medium.com/@Francesco_AI/why-artificial-intelligence-is-now-more-important-than-ever-b2e96addac67?source=tag_archive---------1----------------", 
        "text": "Why AI Is More Important Than\u00a0Ever\n\nThe reason why we are studying AI right now more actively is clearly because of the potential applications it might have, because of the media and general public attention it received, as well as because of the incredible amount of funding investors are devoting to it as never before.\n\nMachine learning is being quickly commoditized, and this encourages a more profound democratization of intelligence, although this is true only for low-order knowledge. If from one hand a large bucket of services and tools are now available to final users, on the other hand, the real power is concentrating into the hands of few major incumbents with the data availability and computational resources to really exploit AI to a higher level.\n\nApart from this technological polarization, the main problem the sector is experiencing can be divided into two key branches: first, the misalignments of i) the long term AGI research sacrificed for the short term business applications, and ii) what AI can actually do against what people think or assume it does. Both the issues stem from the high technical knowledge intrinsically required to understand it, but they are creating hype around AI. Part of the hype is clearly justified, because AI has been useful in those processes that are historically hard to be automated because of the requirement of some degree of domain expertise.\n\nSecondly, the tight relationship machine and humans have, and how they interact with each other. We are participating to an enormous cultural shift in the last few years because the human being was originally the creature in charge of acting, while the machine was the security device for unwanted scenarios. However, nowadays the roles have been inverted, and machines are often in charge while the humans are simply monitoring.\n\nEven more important, this relationship is changing our own being: people normally believe that machines are making humans more similar to them as humans are trying to do the same with computers, but there are thinkers who judge this cross-pollination as a way for humans to become even more humans (Floridi, 2014). The only thing that seems to be commonly accepted is that fact that, in order to shorten the AI adoption cycle, we should learn how to not trust our intuition all the time, and let the machine changing us either in a more human or more mechanical way.\n\nSo the natural question everyone is asking is \u201cwhere machines stand with respect to humans?\u201d Well, the reality is that we are still far from the point in which a superintelligence will exceed human intelligence\u200a\u2014\u200athe so-called Singularity (Vinge, 1993). The famous futurist Raymond Kurzweil proposed in 1999 the idea of the law of accelerating returns, which envisages an exponential technological rate of change due to falling costs of chips and their increasing computational capacity. In his view, the human progress is S-shaped with inflection points corresponding to the most relevant technological advancements, and thus proceeds by jumps instead of being a smooth and uniform progress.\n\nKurzweil also borrowed Moore\u2019s law to estimate accurately the precise year of the singularity: our brain is able of 10\u00b9\u2076 calculations per second (cps) and 10\u00b9\u00b3 bits of memory, and assuming Moore\u2019s law to hold, Kurzweil computed we will reach an AGI with those capabilities in 2030, and the singularity in 2045.\n\nI believe though this is a quite optimistic view because the intelligence the machines are provided with nowadays is still only partial. They do not possess any common sense, they do not have any sense of what an object is, they do not have any earlier memory of failed attempts, they are not conscious - the so-called the \u201cChinese room\u201d argument, i.e., even if a machine can perfectly translate Chinese to English and vice versa, it does not really understand the content of the conversation.\n\nOn the other side, they solve problems through structured thinking, they have more storage and reliable memory, and raw computational power. Humans instead tried to be more efficient and select ex-ante data that could be relevant (at the risk of losing some important information), they are creative and innovative, and extrapolate essential information better and faster from only a few instances, and they can transfer and apply that knowledge to unknown cases.\n\nHumans are better generalists and work better in an unsupervised learning environment. There are easy intuitive tasks almost impossible for computer (what humans do \u201cwithout thinking\u201d), while number-intensive activities are spectacularly easy for a machine (the \u201chard-thinking\u201d moments for our brain)\u200a\u2014\u200ain other words, activities essential for survival that have to be performed without effort are easier for human rather than for machines.\n\nPart of this has been summarized by Moravec\u2019s paradox with a powerful statement: high-level reasoning requires little computation, and it is then feasible for a machine as well, while very simple low-level sensorimotor skills would demand a gigantic computational effort.\n\nAll the considerations made so far do not end in themselves but are useful to sketch the important design aspects to be taken into account when building an AI engine. In addition to those, few characteristics emerged as fundamental for progressing toward an AGI: robustness, safety, and hybridization.\n\nAs intended in Russell et al. (2015), an AI has to be verified (acting under formal constraints and conforming to formal specifications); validated (do not pursue unwanted behaviors under the previous constraints); secure (preventing intentional manipulation by third parties, either outside or inside); and controlled (humans should have ways to reestablish control if needed).\n\nSecond, it should be safe according to Igor Markov\u2019s view: AI should indeed have key weaknesses; self-replication of software and hardware should be limited; self-repair and self-improvement should be limited; and finally, access to energy should be limited.\n\nLast, an AI should be created through a hybrid intelligence paradigm, and this might be implemented following two different paths: letting the computer do the work, and then either calling in humans in for ambiguous situations or calling them to make the final call. The main difference is that the first case would speed things up putting the machines in charge of deciding (and would use humans as feedback) but it requires high data accuracy.\n\nMy conclusion is that AI is coming, although not as soon as predicted. This AI spring seems to be different from previous phases of the cycle for a series of reasons, and we should dedicate resources and effort in order to build an AI that would drive us into an optimistic scenario.\n\nFloridi, L. (2014). The Fourth Revolution: How the Infosphere is Reshaping Human Reality. OUP Oxford.\n\nKurzweil, R. (1999). The Age of Spiritual Machines: When Computers Exceed Human Intelligence. Penguin Books.\n\nVinge, V. (1993). \u201cThe Coming Technological Singularity: How to Survive in the Post-Human Era\u201d. In NASA. Lewis Research Center, Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace: 11\u201322.", 
        "title": "Why AI Is More Important Than Ever \u2013 Francesco Corea \u2013"
    }, 
    {
        "url": "https://blog.deepomatic.com/search-the-world-with-deepomatic-api-50c9aebd0529?source=tag_archive---------2----------------", 
        "text": "We are proud to announce that our visual search API is now made public. Register on developers.deepomatic.com and enter a world where end-users can search your own catalogue of images by taking a picture of packaged goods, print media, posters, and more!\n\nOur technology combines specially-tuned deep learning-based features and our proprietary geometric filtering algorithm to provide the best visual search engine as a service in the world, no less\u00a0;-). You can upload your catalogue of images with a few requests to our API, making it searchable in minutes.\n\nThe list of use-cases is vast and we can\u2019t wait to see how you will use this technology for your own applications. In order to inspire you, here is how we use visual search at Deepomatic:\n\nSo if you think we can help you, drop us a line at hey@deepomatic.com or try Deepomatic Search API for free on developers.deepomatic.com.\n\nDevelopers, you can also check the documentation on api.deepomatic.com. Your feedback is precious as we will keep improving our API to better fit your use-cases. So, check it out and let us know what you think!", 
        "title": "Search the world with Deepomatic API \u2013"
    }, 
    {
        "url": "https://medium.com/shidanqing/bnns%E5%AE%9E%E7%8E%B0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-48d4cd4c14ed?source=tag_archive---------3----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "BNNS\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc \u2013 shidanqing \u2013"
    }, 
    {
        "url": "https://medium.com/@jayaprime/fractal-art-mandala-fused-with-googles-deep-dreams-ai-9297d5854995?source=tag_archive---------4----------------", 
        "text": "\u21165 of 36 in the \u201cSpectral Recursion\u201d series\n\nFacts: Of the 564 currently confirmed exoplanets, only thirty-two register as habitable. Eleven of these are strikingly similar to our own Terra: size, shape, and at a distance from their star of origin to keep them from freezing and from burning up. Whether or not any of these are already inhabited remains to question. Want to take a ride?\n\nIncept: I grabbed the shot from NASA of Kepler-62e, the largest exoplanet that we\u2019ve discovered so far. After adding it to a fanned PDJ fractal in Apophysis, I processed it with Google\u2019s Deep Dreams AI, before finally painting on a new layer of colors.\n\nStores:\n\n\u2022 Purchase the beautiful Kepler-62e Deep Space Dreamer fractal on Redbubble\n\n\u2022 Purchase the beautiful Kepler-62e Deep Space Dreamer fractal on Society6\n\nMore: This fractal mandala has a long history, with design variations published online and in books. The most recent deep dream mandala version appears as the two-page spread in the book \u201cSpectral Iteration: A Prismatic Journey thru the Beautiful Art of Fractals and Abstracts\u201d (pictured below). The book is filled with other fractals and abstracts, including inspirational poetry to match the art. It\u2019s available for purchase in hardback and softback format here on Amazon.", 
        "title": "Fractal art mandala fused with Google\u2019s Deep Dreams AI"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/google-unleashes-deep-learning-tech-on-language-with-neural-machine-translation-594e22d11e6c?source=tag_archive---------6----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Google Unleashes Deep Learning Tech on Language With Neural Machine Translation"
    }
]