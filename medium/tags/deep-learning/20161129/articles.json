[
    {
        "url": "https://medium.com/@akashg/character-recognition-using-tensorflow-a93dbbdf4af?source=tag_archive---------0----------------", 
        "text": "TensorFlow is an open source library for numerical computation using data flow graphs. Nodes in the graph represent mathematical operations while edges represent multidimensional arrays (called tensors) communicated between them. TensorFlow was originally developed by researchers working at google brain team within google\u2019s machine intelligence research organisation. TensorFlow allows us to quickly to construct and deploy architecture to one or more GPUs or CPUs on a desktop, server or mobile device with single API. TensorFlow is mainly used for conducting deep neural network research but it is general enough to be used for many other purposes.\n\nOur goal is to develop a neural network in tensorflow which can recognize devanagari characters from images. We have already seen how to develop neural network from scratch for poker hand prediction here.\n\nData consists of two parts, one for training and one for testing. We have images of size 320*320 each of which has a character in it. The output is an integer between 0 to 103(both inclusive) representing the character.\n\nThe general architecture is to have an input node for each pixel and have 104 output nodes. If ith node outputs 1 then the network has recognized the image as ith character. Now having good enough number of layers and enough neurons should give us good results as we have done in previous case.\n\nAs it turns out, this architecture is very bad for various reasons. Firstly having input of size 320*320 is not recommended as it makes the size of network very large which will enormous amount of time to train. Secondly having large number of layers again takes unreasonable time to train. Thirdly if look at the input, mostly the images are white with very thin black lines indicating character. This means most of inputs are 1 and extremely few are 0. This kind of input is not very good. We need good number of neurons representing the actual input data and not all 1.\n\nWe do the following transformation on the input. First we invert the images so that we can get 1 and 0 interchanged. Then we apply gaussian blur to increase thickness of character(making more input represent the character). Then we resize the image. This done to decrease the size of network. We finally have 80*80 size images.\n\nHere is the python code for input transformation:\n\nNext we start develop an architecture for neural network. As a general rule when we don\u2019t have any specific architecture, we have number of features equals number of input, number of classes equals number of outputs and decreases neurons by factor of 2 or 4 in each new layer.\n\nWith some experiments we can find that network with 3 or more hiddenlayers takes long time to train on PC. So we stick with just 2 layer architecture. Next we vary other parameters and check for accuracy. Architecture with 1024 neurons in first layer and 256 neurons in second hidden layer gives good result. We stick with the well known sigmoid activation function.\n\nWe just need to have a good error function. Again as a general rule we take a function of error regularised with weights and biases. This configuration gives us about 70% accuracy.\n\nThe python code for the architecture is\n\nThe input and validation data can be obtained from here.\n\nThe time taken for writing and deploying this network was very small(except for debugging time). So tensorflow makes it easier to quickly test and deploy models. We finally managed to achieve 72% accuracy with small size network.", 
        "title": "Character Recognition using TensorFlow \u2013 Akash Garg \u2013"
    }, 
    {
        "url": "https://medium.riminder.net/lintelligence-artificielle-au-service-de-l-emploi-a15aebd993d0?source=tag_archive---------1----------------", 
        "text": "Aujourd\u2019hui, nous avons la chance de vivre \u00e0 une \u00e9poque o\u00f9 le march\u00e9 et les entreprises regorgent de donn\u00e9es li\u00e9es \u00e0 l\u2019emploi. Gr\u00e2ce aux techniques de \u00abbig data\u00bb, il est possible de capturer, normaliser, stocker et rendre accessible la donn\u00e9e. Cependant, pour en tirer le meilleur parti, il faut \u00eatre capable de l\u2019analyser. Comme le dit Prof. Ivar Ekeland (\u00c9cole Normale Sup\u00e9rieure)\u00a0: \u00abla donn\u00e9e ne parle jamais d\u2019elle-m\u00eame, il faut trouver le moyen subtil de la faire parler\u00bb. De plus, lorsque la taille de la donn\u00e9e qu\u2019on \u00e9tudie est infiniment grande, on ne peut se fier ni \u00e0 la recette, ni au flair, ni \u00e0 l\u2019intuition. La donn\u00e9e a besoin de mod\u00e8les math\u00e9matiques et d\u2019algorithmes adapt\u00e9s. Le \u00abdeep learning\u00bb est en train de r\u00e9volutionner le fonctionnement des g\u00e9ants des technologies (Facebook, Google, Apple, Microsoft, IBM\u2026), la fonction RH n\u2019est pas une exception.\n\nEn s\u2019appuyant sur des corr\u00e9lations, nettement plus pertinentes que de simples recherches par mots-cl\u00e9s, cette technologie permet par exemple de\u00a0: suivre l\u2019\u00e9volution rapide du march\u00e9 de l\u2019emploi, pr\u00e9dire le prochain poste d\u2019un candidat, \u00e9valuer sa candidature automatiquement \u00e0 partir de son CV en analysant son parcours, ses exp\u00e9riences, ses comp\u00e9tences traverses, et en mesurant son ad\u00e9quation avec la culture de l\u2019entreprise. Loin de \u00abcloner\u00bb les candidats, cette technologie offre de nouvelles perspectives de recrutement en favorisant la pertinence, la flexibilit\u00e9, la diversit\u00e9, la rapidit\u00e9 du processus et en apportant des preuves tangibles.", 
        "title": "L\u2019intelligence artificielle au service de l\u2019emploi \u2013"
    }, 
    {
        "url": "https://medium.com/@datacapital/machine-learning-from-fundmental-capabilities-to-features-to-solutions-be80ae6adf18?source=tag_archive---------2----------------", 
        "text": "A few points to consider:\n\nAnother question frequently encountered by enterprises thinking about using ML technologies: Should we buy horizontal technology platforms or should we buy a product/application that solves pain points in my industry (and related industries)?\n\nTo answer this question we should look at ML/AI market maturity and how sophisticated the buyer is (do they have a solid data science team, have they executed big data projects previously and so on\u2026.)\n\nTo simplify the challenge, let\u2019s take a look at Solar module value chain:\n\n1.An end customer\u200a\u2014\u200aResidential home or commercial building wants to buy a solar module or solar system\n\n2.What will those customers do with polysilicon or wafer or a single cell?\n\n3.If the buyer is a system integrator and is interested in controlling the value chain, he/she can think about backward integration to compete well. BUT If the market is nascent and there is no customer buying a solar module, then it is useless to think about polysilicon or wafer in the short term.\n\n4.In a nascent industry such as AI, end customers are first looking for new capabilities or solving a business problem i.e. can they do a better job of predicting X\u200a\u2014\u200areduce churn, detect fraud, prevent failures etc,. So Applications come first to demonstrate the value proposition of a technology.\n\n5.Therefore it is advisable to first think of Applications in the short term and then underlying technology enablers in the value chain in the long run. This recommendation doesn\u2019t apply universally to all types of organizations. Some are more advanced than others.\n\nBased on the buying hierarchy concept first outlined by Windermere Associates, most customers follow a four phase buying pattern: functionality, reliability, convenience, and price (source: Clayton M. Christensen\u2019s Innovator\u2019s Dilemma)\n\nObviously it is not practical to predict market adoption in such generalized fashion. (remember all prediction are made up). However customers should fully understand how their data science project is going to benefit the organization in quantitative terms: total cost of project, time to fully implement, payback period, ROI, prioritizing higher NPV projects\u2026\u2026\u2026\u2026and the criteria goes on.", 
        "title": "Machine Learning \u2014 From Fundmental Capabilities to Features to Solutions"
    }, 
    {
        "url": "https://medium.com/@cytora/three-ways-artificial-intelligence-can-transform-commercial-insurance-eea2c9ef57b0?source=tag_archive---------3----------------", 
        "text": "If you want business insurance in 2017, chances are you\u2019ll be dealing with a bot not a broker. An artificially intelligent system will scrape all of your valuable information from the web, create a holistic representation of your business, and decide if you are eligible or not\u200a\u2014\u200aand at what price\u200a\u2014\u200awithin a matter of seconds.\n\nMore information exists on the web now than ever before. Every two years, we create ten times more data than has ever existed in human history [1]. By 2020, technology conglomerate Cisco, predicts we\u2019ll be swimming in 2.3 zettabytes of web data [2], and strategists at the UK Ministry of Defense believe that by then, 90% of what happens in the physical world will be described in unstructured web text.\n\nIn this post, we are going to briefly explain three ways that AI can help insurers utilise this data to enhance their operations;\n\n1. AI gives insurers access to an increasing number of observations about risk\n\nInsurers can now use AI to gather web data and turn it into intelligence. Actuaries and analysts have been slicing and dicing their internal data for decades, but they have never had access to so much of it from third parties before. AI enables insurers to gather and synthesize unstructured and structured data from disparate sources all over the web, and weave it together with their existing intelligence.\n\nUsing AI, insurers can generate a more factual, robust representation of commercial risk that is built from more than just historical claims data. For commercial insurance, an industry that is heavily dependent on statistical analysis and predictive modeling, this is a pretty big deal.\n\nCommercial underwriting traditionally relies on the analytical expertise of humans and their ability to manipulate historical datasets. Emerging risks such as cyber attacks, where claims data is immature or sparse, are difficult to underwrite. Exposure is hard to predict and difficult to price.\n\nThis makes it incredibly tricky for insurers to provide intelligent and competitive pricing to the masses of business owners who want cyber coverage, further illustrating the point that these days, a lack of data usually leads to a lot of missed opportunities.\n\nIn these cases\u200a\u2014\u200aproducts converge towards the norm and exclude the profitable opportunities that exist at the margins or in niches. Machine learning methods such as deep learning solve this problem.\n\nDeep learning uses multi-layered neural networks to learn and can apply complex mathematical calculations to data over and over again, learning from each interaction. This is especially useful for identifying significant patterns that are difficult to spot in vast amounts of data and help commercial underwriters to extract new insights incredibly quickly.\n\nAI helps by introducing new data from the web\u200a\u2014\u200asuch as a complete history of reported and unreported data breaches, and the characteristics of companies incurring them. It then analyses this data at lightning speed and rapidly predicts the probability of loss.\n\nUltimately this means insurers are able to underwrite new risks in emerging markets faster than ever, leading to new sources of revenue, and more competitive pricing.\n\nWith regard to Cyber risk, instead of solely focusing on the revenue and sector of a company to predict loss frequency, underwriters can consider factors like media profile, reputation, and political stance.\n\nWhen a large business receives negative media coverage, does this increase the likelihood that they will experience a cyber breach?\n\nThe use of web data combined with machine learning makes it possible for insurers to answer questions like this. Equally, information that commercial insurers used to rely on customers to provide can now be pre-populated in seconds using services like Google Maps, OpenStreetMap and LinkedIn.\n\nHaving access to all of this insight makes it increasingly easy for insurers to identify good risks, and allow them to focus resources on creating profitable products in these areas.\n\nThere is a possibility that soon, AI will be able to create a true representation of risk. It\u2019s not really a question of if commercial insurers will embrace the capabilities of AI, it\u2019s a question of who will do it better, first.", 
        "title": "Three Ways Artificial Intelligence Can Transform Commercial Insurance"
    }, 
    {
        "url": "https://medium.com/@Mehrceey04/andela-bootcamp-self-clinic-home-day-2-bc905a6df28a?source=tag_archive---------4----------------", 
        "text": "It\u2019s the second day of the self learning clinic, today started in a very cool manner, programming logic was on word count and find min/ max numbers. The norms of writing tests and codes continues.\n\nMy most challenging tasks for today was on HTTP/ Web, we\u2019re to write a simple command line application that consumes a Public API using a HTTP client library. It was very unfamiliar to me, not until I had to do the task, I had to source for help from forums and friends who had worked with it before me. I learnt something new again today, thanks to Andela!\n\nIts been an awesome-challenging day for me.\n\nWill be here again soon!", 
        "title": "Andela BootCamp/ Self Learning Clinic \u2014Day 2 \u2013 Halimat Mercy Oseni \u2013"
    }, 
    {
        "url": "https://medium.com/@nonmult/ai%E3%81%B8%E3%81%AE%E6%9C%9F%E5%BE%85%E3%81%A8%E4%B8%8D%E5%AE%89-42b9965cc3ee?source=tag_archive---------6----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "AI\u3078\u306e\u671f\u5f85\u3068\u4e0d\u5b89 \u2013 nonmult \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/human-cognition-has-been-exceeded-ms-sakakibara-cto-explained-deep-learning-framework-410f6efc83f2?source=tag_archive---------8----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Human \u201dCognition\u201d Has Been Exceeded -MS Sakakibara CTO Explained Deep Learning Framework"
    }
]