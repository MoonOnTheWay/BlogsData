[
    {
        "url": "https://machinelearnings.co/machine-learnings-11-86e6bc7cf3fb?source=tag_archive---------0----------------", 
        "text": "1/ Facebook, Amazon, Google, IBM, and Microsoft built a partnership to conduct research and promote best practices in advancing artificial intelligence. link\n\n5/ IBM Watson created the first movie trailer created entirely by artificial intelligence. link\n\n6/ MIT scientists developed a device that uses radio waves to detect whether someone is happy, sad, angry or excited. link\n\n7/ Las Vegas casino announces plan to use BrainChip machine learning security technology to detect dealer errors by monitoring video streams.link\n\n9/ Clarifai launched custom training and visual search products to make it easier for developers to build AI into apps. link\n\n10/ Otto announced plan to offer freight hauling services using autonomous trucks in 2017. link\n\n12/ Google introduced the Open Images dataset of ~9 million URLs to images that have been annotated with labels to help the machine learning community train deep neural networks from scratch. link", 
        "title": "AI Brings the Big 5 Together \u2014 #11 \u2013"
    }, 
    {
        "url": "https://medium.com/@marcelo_tibau/intelig%C3%AAncia-artificial-e-suas-tend%C3%AAncias-2103e430e703?source=tag_archive---------1----------------", 
        "text": "Nos \u00faltimos 15 anos, IA conseguiu cumprir a sua expectativa hist\u00f3rica de permear a vida do ser-humano. \u00c9 verdade que um dos grandes respons\u00e1veis por isto s\u00e3o os \u201cpequenos\u201d equipamentos que carregamos em nossos bolsos e bolsas diariamente, os smartphones. De todo modo, ao se tornar uma for\u00e7a central em nossa sociedade, a pr\u00f3pria IA vem se modificando. O grande objetivo das mentes por tr\u00e1s do seu desenvolvimento, n\u00e3o \u00e9 mais construir sistemas que s\u00e3o inteligentes, mas construir sistemas inteligentes que s\u00e3o confi\u00e1veis e focados no ser-humano.\n\nPode parecer um simples \u201cjogo de palavras\u201d, mas a realidade \u00e9 que esta vis\u00e3o traz uma mudan\u00e7a profunda no direcionamento das pesquisas no campo da IA. Para resumir este direcionamento, usarei apenas um termo: dados. Quem tem familiaridade com a hierarquia DIKW percebe imediatamente o que isto quer dizer. Dados s\u00e3o a base em que se constr\u00f3i o conhecimento. Ao focar neles, as pesquisas em Intelig\u00eancia Artificial se aproximam cada vez mais do que transforma o ser-humano em ser-humano, a alta capacidade de aprendizagem\u200a\u2014\u200ade transformar conhecimento em sabedoria.\n\nDeep Learning: sei que parece t\u00edtulo de filme B, mas penso que vale a pena dar uma explica\u00e7\u00e3o um pouco mais t\u00e9cnica aqui do que na \u201cpalhinha\u201d de algumas linhas acima. \u00c9 chamado de aprendizado profundo, a habilidade de se treinar com sucesso redes neurais convolucionais (em teoria da informa\u00e7\u00e3o, convolucional \u00e9 um tipo de c\u00f3digo para detec\u00e7\u00e3o de erros). Em machine learning, a rede neural convolucional funciona de maneira inspirada no c\u00f3rtex visual dos animais, reconhecendo largura e altura de um volume e se ativando quando \u201cv\u00ea\u201d algo similar em uma determinada posi\u00e7\u00e3o espacial. Um dos campos que mais se beneficiam disto \u00e9 o da vis\u00e3o computacional, que pode ser aplicada em reconhecimento de objetos (e atividades gerais de reconhecimento) e \u00e1reas de percep\u00e7\u00e3o artificial como voz e linguagem natural (os idiomas que falamos). Sei que a maioria n\u00e3o ligar\u00e1 \u201co nome \u00e0 pessoa\u201d, mas saibam que coisas comuns que usamos\u200a\u2014\u200acomo os filtros para fotos de aplicativos como Instagram\u200a\u2014\u200ase beneficiam destes conhecimentos.\n\nAprendizado por refor\u00e7o (reinforcement learning): n\u00e3o sei quantos dos que me leem tiveram a experi\u00eancia de terem \u201caulas de refor\u00e7o\u201d no col\u00e9gio. Lembro do drama que era para mim chegar duas horas antes das aulas \u00e0s quintas-feiras, para ter aula de refor\u00e7o em portugu\u00eas. O objetivo deste tipo de aula era, no meu caso, utilizar a l\u00edngua portuguesa em situa\u00e7\u00f5es pr\u00e1ticas reais (escrever cartas, interpretar textos e entender suas implica\u00e7\u00f5es). Funciona de modo similar no caso das m\u00e1quinas, envolve ensin\u00e1-las a aprender algo necess\u00e1rio para executar a\u00e7\u00f5es no mundo real. O modo de se fazer isto \u00e9 atrav\u00e9s de estruturas sequenciais para tomada de decis\u00e3o baseada em experi\u00eancia. Este campo, estagnado h\u00e1 d\u00e9cadas, tomou um impulso com o surgimento do deep learning. Um exemplo pr\u00e1tico \u00e9 o AlphaGo, desenvolvido pela Google, para ensinar m\u00e1quinas a jogar o jogo chin\u00eas Go (para mais detalhes tanto de um quanto de outro, inclu\u00ed links que direcionam ao site do AlphaGo e \u00e0 explica\u00e7\u00e3o do jogo original na Wikip\u00e9dia). O AlphaGo foi treinado inicialmente atrav\u00e9s de um banco de dados criado por especialistas humanos no jogo e posteriormente, via aprendizado por refor\u00e7o, praticando atrav\u00e9s de jogos contra si mesmo. A aplica\u00e7\u00e3o desta \u00e1rea \u00e9 bem din\u00e2mica, atua desde viagens espaciais at\u00e9 extra\u00e7\u00e3o de petr\u00f3leo em grandes profundezas (como no caso do nosso pr\u00e9-sal).\n\nVis\u00e3o computacional: esta \u00e9 a forma mais proeminente de percep\u00e7\u00e3o da m\u00e1quina hoje. \u00c9 uma das \u00e1reas de IA que teve a sua evolu\u00e7\u00e3o impulsionada pelo aparecimento do deep learning. Pela primeira vez, os computadores s\u00e3o capazes de executar algumas tarefas de classifica\u00e7\u00e3o visual melhor do que as pessoas. Combinada com computa\u00e7\u00e3o gr\u00e1fica, tem sido a respons\u00e1vel pela \u201cexplos\u00e3o\u201d da tend\u00eancia de realidade aumentada.\n\nProcessamento de linguagem natural: muitas vezes usado em conjunto com o reconhecimento autom\u00e1tico de voz, o processamento de linguagem natural \u00e9 outra forte tend\u00eancia da \u00e1rea de percep\u00e7\u00e3o da m\u00e1quina. 20% das consultas ao Google j\u00e1 s\u00e3o feitas por voz e alguns testes j\u00e1 mostram a possibilidade real de us\u00e1-lo para tradu\u00e7\u00e3o em tempo real. O foco dos estudos est\u00e1 se concentrando cada vez mais no desenvolvimento de sistemas capazes de interagir com as pessoas por meio do di\u00e1logo (e n\u00e3o simplesmente reagir a comandos digitados).\n\nInternet das Coisas: tamb\u00e9m conhecida pela sigla IoT (Internet of Things), \u00e9 um dos grandes focos de pesquisas na \u00e1rea de Intelig\u00eancia Artificial. Est\u00e1 relacionada \u00e0 ideia de que uma grande quantidade de dispositivos (ou coisas) podem ser interconectados para coletar e compartilhar seus dados sensoriais (eletrodom\u00e9sticos, ve\u00edculos, edif\u00edcios, m\u00e1quinas fotogr\u00e1ficas e roupas s\u00e3o alguns exemplos). Embora seja uma quest\u00e3o que envolva em grande parte a cria\u00e7\u00e3o de tecnologia e a utiliza\u00e7\u00e3o de rede sem fio para conectar os dispositivos, h\u00e1 um enorme desafio no processamento e uso inteligente destas imensas quantidades de dados (a serem) gerados que ainda precisa ser equacionado. Outro ponto, \u00e9 que atualmente esses dispositivos utilizam uma quantidade grande de protocolos de comunica\u00e7\u00e3o incompat\u00edveis. IA est\u00e1 sendo utilizada tanto para desenvolver solu\u00e7\u00f5es para lidar com esta possibilidade exponencial de big data quanto para ajudar a domar a \u201cTorre de Babel\u201d.\n\nH\u00e1 ainda outras tend\u00eancias que de t\u00e3o espec\u00edficas, prefiro n\u00e3o abordar\u200a\u2014\u200acomo computa\u00e7\u00e3o neurom\u00f3rfica (neuromorphic computing), cria\u00e7\u00e3o de algoritmos baseados na teoria dos jogos, sistemas colaborativos, dentre outros. O que une estas tend\u00eancias n\u00e3o citadas e as demais que comentei \u00e9 a sua caracter\u00edstica human-aware (centrada no ser-humano\u200a\u2014\u200acomo mencionado no in\u00edcio do texto). Isto quer dizer que por mais complicado que possa parecer, todas estas iniciativas s\u00e3o especificamente modeladas e desenvolvidas com o foco nas pessoas que se espera que elas interajam. Por enquanto n\u00e3o h\u00e1 o risco de se criar algo como o sistema Skynet\u200a\u2014\u200ado Exterminador do Futuro. O maior risco trazido pelo deep learning para o aprendizado da m\u00e1quina, \u00e9 o processo conhecido como overfitting. Assim como n\u00f3s, seres-humanos, as m\u00e1quinas tamb\u00e9m apreciam a boa e velha decoreba. Quando percebem que uma resposta n\u00e3o muda, elas simplesmente a decoram. O overfitting ocorre quando tentam generalizar algo que \u00e9 espec\u00edfico, usando o que decoraram. Como se pode ver, o que faz a diferen\u00e7a em qualquer aprendizado \u00e9 o contexto.", 
        "title": "Intelig\u00eancia Artificial e suas tend\u00eancias \u2013 Marcelo Tibau \u2013"
    }, 
    {
        "url": "https://medium.com/the-technews/vocalzoom-sensor-can-recognize-what-you-say-by-detecting-your-skin-vibrations-b7f2f49fb614?source=tag_archive---------2----------------", 
        "text": "Your skin is your reflection. Anything about you, from your age to when you last fall sick can be known from your skin. Using that fact, an Israeli startup named VocalZoom wants your skin to do much more complicated analysis, understanding what you say.\n\nThe skin of our face makes exquisite vibrations while we talk. The amount of vibration is too low to be seen by human eye, but with an instrument called interferometer, VocalZoom team noticed it detect weird measurements.\n\n\u201cWhen it measures the face, we found out that the vibrations were caused only by the speaker\u2019s voice and were not affected at all by any background voice,\u201d said VocalZoom CEO Tal Bakish to Digital Trends. \u201cAt this point we realized that we have a disruptive technology to extract the voice of speaker in any noisy condition.\u201d\n\nThe team built a sensor that can measure vibrations just by focusing on the speaker\u2019s face from within a few feet, which are then translated into an acoustic signal. \u201cThis acoustic output is then fed into a typical speech enhancement or noise-reduction[program] to be fused with an acoustic microphone to create a practically noise-free signal that is fed to an automatic speech recognition [program],\u201d said Bakish.\n\nVocalZoom claims the resulted signal features very limited background noise, compared to those recorded by microphones and noise reduction units. Bakish hopes that signal may help match facial gesture with a speech to build more secure and accurate speech verification software.\n\n\u201cOver the past decade, solutions have relied only on data collected for training and strong processing technologies, such as neural networks and deep learning,\u201d he said.\u201cNow it is clear that to reach the 100 percent performance required for user adoption, the microphone technology needs to improve.\u201d\n\nThe startup is currently in a partnership with Intel, Motorola Solutions, 3M, and some other companies. You can expect its technology featured in consumer devices as early as the next year. Also, they want to include the feature for voice control in vehicles and discussing it with some major car makers.", 
        "title": "VocalZoom sensor can recognize what you say by detecting your skin vibrations"
    }, 
    {
        "url": "https://resources.trainingdata.com/how-deep-learning-allowed-computers-to-see-be52a97e5330?source=tag_archive---------3----------------", 
        "text": "One of the biggest challenges of the 21st century is to make computers more similar to the human brain. We want them to speak, understand and solve problems\u200a\u2014\u200aand now we want them to see and recognize images. For a long time, our smartest computers were blind. Now, they can see. This is a revolution made possible by deep learning. Machine learning: The first step Understanding machine learning is quite easy. The idea is to train algorithms on large databases to make them able to predict results from new data. Here\u2019s a simple example: We want to predict the age of a tree thanks to its diameter\u2026", 
        "title": "How deep learning allowed computers to see \u2013"
    }
]