[
    {
        "url": "https://blog.deepomatic.com/beyond-classification-announcing-our-image-detection-apis-363707d73c32?source=tag_archive---------0----------------", 
        "text": "However, most real-world problems can\u2019t be addressed by image classification only. For these use-cases, the weapon of choice is called image detection.\n\nRecently, this field has seen multiple dramatic improvements. Computers now have the ability not only to tag images but also to detect and localize items in those images. Two exceptionally powerful algorithms were released recently:\n\nThe latter now has the speed to allow real-time detection while slightly improving the accuracy of the former. At Deepomatic, we strongly believe that these algorithms will be the cornerstone of many commercial applications. However to make the most of these algorithms, we need a specific fuel: large-scale, high-quality specialized datasets. That\u2019s why we have built an annotation platform dedicated to efficiently create those datasets, which can be then used to train and deploy high-quality models in production.\n\nWe are proud to announce our first 4 specialized detection APIs for fashion, weapons, furniture and urban street scenes. You can use these detectors by requesting your API token here.\n\nOn the demo videos shown above, the detection is performed in real-time. None of the frame images belong to the training or validation sets. On the contrary, it is applied to a new type of images. This reflects the recognition quality that you can achieve when you have access to high-quality datasets.", 
        "title": "Beyond classification: announcing our image detection APIs"
    }, 
    {
        "url": "https://medium.com/seldon-open-source-machine-learning/highlights-of-ieee-big-data-2016-nearest-neighbours-outliers-and-deep-learning-696d014d8cdf?source=tag_archive---------1----------------", 
        "text": "From the 5th to the 8th of December, the IEEE international conference on big data was taking place in Washington DC. As a Data Scientist working for Seldon, I was invited to give a Keynote Speech at the workshop \u201cAdvances in High Dimensional Big Data\u201d.\n\nDuring these four days, hundreds of PhD students and industry experts gave presentations on their latest research, creating a unique opportunity for the academia and the industry to meet.\n\nHere is a brief overview of the three conferences that resonated the most with Seldon.\n\nK-Nearest Neighbours are a set of techniques to find the closest neighbours of a point in a dataset, according to a given metric (for example the Euclidian distance). These techniques can be applied to deal with the cold start problem of recommender systems.\n\nFor example, in the context of news recommendation, the most widely used algorithms are called collaborative filtering: they look at who has read an article and recommend it to other users who have shared the same interests over time. However, when a new article is published and no one has read it yet, this method cannot be used, and this is called the cold start problem. One way to solve this problem is to find the most similar article in terms of content and use this nearest neighbour as a proxy to serve recommendations.\n\nBut text based dataset are very high dimensional and conventional K-Nearest Neighbours methods fail or computations become intractable. The most naive algorithm, brute force search, would compute the distance between all the points and sort them to find the closest ones.\u00a0\n\nTo mitigate this, Ville Hyvonen from the university of Helsinki and his co-writers have developed a new technique for fast K-Nearest Neighbours search that builds on top of the existing space-partitioning trees.\n\nThe algorithm they propose is called Multiple Random Projection Tree (MRPT), and works as follows:\n\nThey were able demonstrate that their method is faster than the current state of the art. And all this is not just theoretical: One of the co-writers, Liang Wang, has built a proof of concept semantic recommender system called Kvasir that you can read about on his website: http://www.cl.cam.ac.uk/~lw525/kvasir/#.\n\nOutlier detection is another area of interest to Seldon. How do you identify points in a large dataset that were generated by a different distribution? More generally, how do you identify patterns in the data that do not conform to the expected behaviour? This has many use cases in a wide range of applications such as cyber security, fault detection and fraud detection for credit cards, or insurance.\u00a0\n\nOn Monday, Jay Luan from Cylance Inc, a computer security company, was presenting an algorithm called Influence Sketching. Their algorithm revisits a measure of sample influence from classical statistics called Cook\u2019s Distance, which quantifies how much your regression output would be impacted by excluding individual points.\n\nThis measure requires the computation of transpose(X)*X (X being your entire dataset) which becomes infeasible for large problem sizes. By adding random projections in the mix Jay and his colleagues were able to derive a high performance approximation to the Generalised Cook\u2019s Distance. They obtain good results when applying their algorithm to identify mislabelling in the field of malware detection. Given a database of software files that have been labelled as malicious or inoffensive by a first algorithm, the task is to narrow down a list of points that were more susceptible to be mislabelled for further analysis.\u00a0\n\nWe believe that this algorithm has great potential to be applied in broader areas.\n\nIn their paper, Jianbo Yuan and his colleagues address the cold start problem using a deep learning approach to match new items to existing ones. In a first step, they turn text content into a low dimensional vector using a transformation (embedding) that preserves the meaning: documents that have similar meaning will be close in this space. They can then use standard techniques to find the nearest neighbour, for example a similarity matrix can be built on these vectors to find the closest items.\u00a0\n\nThey used doc2vec, the current state of the art deep learning technique, for doing the text embedding. They show that their approach outperforms other similarity techniques such as TF-IDF and LDA both in accuracy and complexity by a significant margin.\u00a0\n\nThis is of high interest to us as we have been doing our own research into deep learning for content-based recommendation. In particular we have just successfully replicated Ask the GRU: Multi-Task Learning for Deep Text Recommendations which uses Recurrent Neural Network for mixing content based recommendation and collaborative filtering. It certainly looks like deep learning is about to find new applications in the domain of recommender systems and Seldon intends to be part of it!\n\nThese papers are all available on Aminer:\n\n\u200a\u2014\u200aFast Nearest Neighbor Search throughSparse Random Projections and Voting\n\n\u200a\u2014\u200a\u201cInfluence Sketching\u201d: Finding Influential Samples In Large-Scale Regressions\n\n\u200a\u2014\u200aSolving Cold-Start Problem in Large-scale Recommendation Engines: A Deep Learning Approach", 
        "title": "Highlights of IEEE Big Data 2016: Nearest Neighbours, Outliers and Deep Learning"
    }, 
    {
        "url": "https://insights.untapt.com/deep-learning-study-group-6-a-history-of-machine-vision-6786d891b88c?source=tag_archive---------2----------------", 
        "text": "A fortnight ago, our Deep Learning Study Group held a particularly fun and engaging session.\n\nThis was our first meeting since completing Michael Nielsen\u2019s Neural Networks and Deep Learning text. Nielsen\u2019s work provided us with a solid foundation for exploring more thoroughly the convolutional neural nets that are the de facto standard in contemporary machine-vision applications.\n\nIn Session 6, we dug into the first third of the lectures from the much-hyped Convolutional Neural Networks for Visual Recognition course led by Stanford\u2019s illustrious Fei-Fei Li, Andrej Karpathy and Justin Johnson.\n\nWith respect to theory, we covered:\n\nIn addition to theory, colourful study group member Dmitri Nesterenko, who is Director of Software Engineering at the XO Group downtown, went into considerable, helpful detail describing his adventures writing a k-Nearest Neighbours implementation from scratch with the NumPy library.\n\nFinally, with valuable suggestions from many folks in the room, we crafted a rough plan of the subject matter we\u2019ll be covering in future sessions:", 
        "title": "Deep Learning Study Group #6: A History of Machine Vision"
    }, 
    {
        "url": "https://medium.com/@oyarzo.pablo/amazon-go-is-the-future-here-or-is-this-another-back-to-the-future-promise-e8b6873a7954?source=tag_archive---------3----------------", 
        "text": "Now the fun part. This is where all the tech they mention comes into play.\n\nComputer Vision is definitely the major player. Lots of cameras are gonna track you from the moment you walk in \u2018till the moment you walk out. Not scary at all.\n\nMy guess is that they\u2019re gonna have 4 types of cameras according to their location.\n\nSensor fusion means deep integration between some of the hardware (like the cameras), so whatever it sees makes sense, by giving some context to the information it gets. I can imagine an array of IR sensors at the bottom of the shelves, but I don\u2019t think that\u2019s it, they\u2019re probably using radar technology, exactly what they meant when they said \u201ctech used in autonomous driving\u201d. They could be placed in the ceiling directly above each shelf.\n\nDeep learning isn\u2019t gonna be the star of the show, but it\u2019s going to be pretty important by making the store smarter over time. How? You may ask. Well, by learning how to read the data being input via the radar, the system can learn how to sense the presence of each item with great accuracy, without the hassle of great lighting conditions or the items being arranged perfectly.\n\nAlso, they can use the AI to test various locations for items, with the intention of identifying which one works best.\n\nPossible Issue #2: Let\u2019s say you don\u2019t wanna buy something and you wanna leave it, but you forgot where you took it from or you\u2019re just too lazy and you placed it in the wrong place, where you saw items with similar packaging. The system can get confused about which item is the one that you\u2019re holding. Sure, that can be solved with Deep Learning, but it\u2019s still something to be aware of.\n\nSolution: Areas for unwanted items in the aisles.\n\nFor those wondering what happens if your phone dies at this point, well, everything continues as it should. The only change would be that you probably won\u2019t receive the notification when you walk out of the store.\n\nPossible Issue #3: What if I\u2019m consuming in the store? Would the AI be trained to recognize the consumption of goods, consumer behavior, etc.\n\nSolution: Train the AI.\n\nPossible Issue #4:What if I drop the item and somebody else picks it up? Is the AI capable of seeing that? What if I forget to give the item back to the other person? Does she/he gets charged or do I?\n\nSolution: Train the AI.\n\nRecommendation #2: Having stops for people to drop off items, and also watch what they currently have in their shopping carts, would be very helpful.", 
        "title": "Amazon Go: Is the future here or is this another \u2018Back to the Future\u2019 promise?"
    }, 
    {
        "url": "https://chatbotslife.com/evidence-of-skynets-rise-2016-12-16-dae525608017?source=tag_archive---------4----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Evidence of Skynet\u2019s Rise, 2016\u201312\u201316 \u2013"
    }, 
    {
        "url": "https://humanizing.tech/joy-video-script-baidu-nips-deep-learning-slides-5691762011eb?source=tag_archive---------5----------------", 
        "text": "I haven\u2019t been hearing Merry Christmas or Happy Holidays from very many people lately, and it makes me sad. We\u2019re all so wrapped up in our everyday lives and getting the next thing done that it seems we are forgetting some of the basics. I\u2019ve been trying to say the phrase over the last few weeks as a thanks after checking out at a store, an office goodbye, or even signing off a phone call. You might be surprised how a simple little phrase like that can light up someone\u2019s otherwise dreary or stressful day.\n\nMy fianc\u00e9 wrote this wonderful video script for a creative agency to use for their holiday greeting, but sadly they\u2019re overloaded with client work to get it out in time. If there\u2019s someone out there who\u2019d like to try their hand at it before Christmas, we\u2019d love to see what you come up with.\n\nOne of the leaders of the AI industry published his slides from this month\u2019s NIPS conference. We found the end-to-end learning piece for autonomous vehicles interesting since that fuzzy middle is what Biologic Intelligence is so very good at.\n\nIn it, he also talks about AI Product Management and links to his book, which he\u2019s giving away for free after an email sign up. It\u2019s not massive, but enough to get your feet wet thinking the right way.", 
        "title": "Joy Video Script, Baidu NIPS Deep Learning Slides \u2013"
    }, 
    {
        "url": "https://medium.com/@aurliensmith/hello-there-11c2e2256fc3?source=tag_archive---------6----------------", 
        "text": "Have you used Tensorbox or do you have insights about it?\n\nIf so, how does it perform compared to algorithms you mentioned? (Fast/Faster-RCNN and SSD)\n\nIs it slower and / or less accurate?", 
        "title": "Hello there, \u2013 Aur\u00e9lien Smith \u2013"
    }, 
    {
        "url": "https://medium.com/@analytics/analytics-vidhya-secret-santa-kick-start-your-data-science-learning-in-2017-with-this-gift-7de3e4e1d6e5?source=tag_archive---------7----------------", 
        "text": "Analytics Vidhya Secret Santa\u200a\u2014\u200aKick start your data science learning in 2017 with this\u00a0gift!\n\nThe first things which come to my mind, when I think about Christmas are holidays, family time and festivities! Yes\u200a\u2014\u200ait is that time of the year.\n\nFor us at Analytics Vidhya, our community is our extended family. Helping you learn is like breathing for us and ultimately seeing you grow in your career is our growth.\n\nIf you were to judge by amount of time spent, then Analytics Vidhya would be our primary home. So, it is only natural that we do something special with our community members to mark the arrival of Santa Claus!\n\nWell, it is quite simple! Here are the steps:\n\nOnce you do so, Santa will pull out a small little gift from Analytics Vidhya, especially for you.\n\nHope you enjoy these gifts from our Secret Santa. If you like them, do leave gifts for us in the comments section below!", 
        "title": "Analytics Vidhya Secret Santa \u2014 Kick start your data science learning in 2017 with this gift!"
    }
]