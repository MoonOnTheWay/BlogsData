[
    {
        "url": "https://medium.com/@hongthaiphi/l%C3%A0m-th%E1%BA%BF-n%C3%A0o-%C4%91%E1%BB%83-x%C3%A2y-d%E1%BB%B1ng-m%E1%BB%99t-m%E1%BA%A1ng-neural-%C4%91%C6%A1n-gi%E1%BA%A3n-trong-9-d%C3%B2ng-m%C3%A3-python-90b528c9e0d4?source=tag_archive---------0----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "L\u00e0m th\u1ebf n\u00e0o \u0111\u1ec3 x\u00e2y d\u1ef1ng m\u1ed9t m\u1ea1ng neural \u0111\u01a1n gi\u1ea3n trong 9 d\u00f2ng m\u00e3 Python"
    }, 
    {
        "url": "https://blog.deepomatic.com/learning-fine-grained-similarity-for-fashion-with-deep-multi-modal-representations-8ce7aad52316?source=tag_archive---------1----------------", 
        "text": "This dataset is composed of 70 227 e-commerce dresses and their associated raw textual description.\n\nOur goal was to extrapolate the similarity matrix based only on sparse triplet-ranking information, where a triplet is a set of 3 images (a,b,c) and the ranking is of the form \u201cb is the intruder\u201d.\n\nWe built a complete pipeline system with Human-in-the loop to find the most informative triplets to annotate among all O(N\u00b3) possibilities, and approximate an unknown similarity matrix.\n\nWe built a complete pipeline system with Human-in-the loop to find the most informative triplets to annotate among all O(N\u00b3) possibilities, and approximate an unknown similarity matrix.\n\nThe triplets were sampled according to an increasing distribution function of the uncertainty among the surrogate matrices.\n\nThe idea is that annotated triplets with high uncertainty bring more information according to our objective loss function (described below).\n\nBefore putting our algorithm in production we evaluated the number of iterations our model needs to approximate a \u201cGroundtruth\u201d similarity matrix, according to an objective loss function:\n\nThe Hard term measures how well the similarity ranks near-to-query products (we set K=100), while the Full term is a more global ranking term which especially takes into account the capacity to discriminate the intruders.\n\nBecause in our use case the ranks of non-similar products are not relevant, we force the loss to not take in account triplets with a and b far from the query by setting T << N (we set T=50).\n\nThis study stated that 600 000 triplets were requisite to have an acceptable loss value.\n\nOur dataset consisted in 4000 different dresses from the retailer Zalando.\n\nUsing our proprietary annotation platform as an Oracle, we outsourced 911 452 triplets annotations.\n\nBecause similarity in fashion may be somewhat subjective, and in order to learn a consitant reprensentation, operators had been given some instructions especially to discriminate on style (casual dress, cocktail dress, maternity dresses,\u2026) before anything else.\n\nIf we look at the triplets sent to the operators (based on our sampling function), it\u2019s quite interesting to see their evolution over iterations.\n\nThe very first triplets are quite heterogeneous and it\u2019s very easy to find the intruder:\n\nBetween 150 000 and 450 000 iterations, triplets start being really homogeneous:\n\nFrom iteration 600 000 to the last ones, finding the intruder becomes more difficult and operators must make some trade-offs between visual features such as pattern, shape or color:", 
        "title": "Learning Fine-Grained Similarity for Fashion with Deep Multi-Modal Representations"
    }, 
    {
        "url": "https://medium.com/@farshchi/how-analog-and-neuromorphic-chips-will-rule-the-robotic-age-d232e7ff9bed?source=tag_archive---------2----------------", 
        "text": "This is a guest post. The views expressed here are solely those of the author and do not represent positions of IEEE Spectrum or the IEEE.\n\nWhen it comes to new technologies and products, we tend to think of \u201cdigital\u201d as synonymous with advanced, modern, and high-def, while \u201canalog\u201d is considered retrograde, outmoded, and low-resolution.\n\nBut if you think analog is dead, you\u2019d be wrong. Analog processing not only remains at the heart of many vital systems we depend on today, it is now going to make its way into a new breed of compute and intelligent systems that will power some of the most exciting technologies of the future: artificial intelligence and robotics.\n\nBefore discussing the upcoming analog renaissance\u200a\u2014\u200aand why engineers and innovators working on AI and robot applications should be paying close attention to it\u200a\u2014\u200ait might be helpful to understand the significance and legacy of the Old Analog Age.\n\nDuring World War II, analog circuits played a key role in enabling the first automatic anti-aircraft fire-control systems and, in the decades that followed, analog computers became an essential tool for calculating flight trajectories for rockets and spacecraft.\n\nAnalog also became prevalent in control and communication systems used in aircraft, ships, and power plants, and some of those systems are still in operation to this day. Until not long ago, analog circuits controlled vast portions of our telecommunications infrastructure (remember the rotary dial?), and they even ruled the office copy room, where early photocopier machines reproduced images without handling a single digital bit.\n\nOur love for analog persisted for so long because this technology proved, again and again, to be accurate, simple, and fast. It steered our rockets, sailed our ships, recorded and played back our music and videos, and connected us to each other for many decades. And then, starting in the mid- to late-1960s, digital came along and rapidly took over.\n\nFeedback carburetors were introduced to mix fuel more efficiently as a function of exhaust emissions. They were complex, fragile, unreliable devices that were quickly rendered extinct by electronic fuel injection systems that digitally calculated air/fuel mixtures to control emissions. It is unlikely that these types of precision control systems will go back to being analog. However, the intelligent machines that run on top of them\u200a\u2014\u200alike the self-driving AI on a car\u200a\u2014\u200amay run on analog and neuromorphic computers.\n\nWhy was analog abandoned for digital? The biggest weakness of analog is that it\u2019s rigid, and it gets exponentially more complex when you try to make it flexible. More complexity brings a disproportionate reduction in reliability (bad), so engineers began to notice that Moore\u2019s Law was making dense compute extremely reliable and cheap.\n\nMeanwhile, MEMS and microfabrication techniques commoditized sensors that capture physical signals and convert them to digital. Soon enough, operational amplifiers were abandoned for logic gates that got exponentially cheaper just as Moore\u2019s Law predicted. Mechanical linkages became \u201cfly-by-wire,\u201d and designers pushed digitization further to the edge.\n\nNow, after a long hiatus, Carver Mead\u2019s prediction of the return to analog is starting to become a reality\n\nIn today\u2019s consumer electronics world, analog is only used to interface with humans, capturing and producing sounds, images, and other sensations. In larger systems, analog is used to physically turn the wheels and steer rudders on machines that move us in our analog world. But for most other electronic applications, engineers rush to dump signals into the digital domain whenever they can. The upshot is that the benefits of digital logic\u200a\u2014\u200acheap, fast, robust, flexible\u200a\u2014\u200ahave made engineers practically allergic to analog processing.\n\nNow, however, after a long hiatus, Carver Mead\u2019s prediction of the return to analog is starting to become a reality.\n\n\u201cLarge-scale adaptive analog systems are more robust to component degredation and failure than are more conventional systems, and they use far less power,\u201d Mead, a Caltech professor and microelectronics pioneer, wrote in an influential Proceedings of the IEEEpaper in 1990. \u201cFor this reason, adaptive analog technology can be expected to utilize the full potential of wafer-scale silicon fabrication.\u201d\n\nHardware engineers typically view analog as a necessary evil to interact with the physical world. But it turns out that AI and deep learning algorithms seem to conform better to analog and neuromorphic compute platforms.\n\nAt my firm Lux Capital, we funded Nervana, which built ASICs that ran convolutional neural networks natively to accelerate the training of deep learning algorithms. Although the mathematical operations were done in the digital domain, the overall system architecture mimicked the human brain at a very high level.\n\nThe approach worked well for training AIs in the cloud, though it still consumed too much power to run a portable device like an untethered robot. Nevertheless, Nervana\u2019s expected performance boost was so compelling that Intel rushed to acquire the company.\n\nWe\u2019re at a unique intersection where the neural networks we\u2019re trying to implement are more suitable to analog designs, while demand for these types of AI circuits is expected to explode\n\nAsk almost anyone (even kids) to sketch out a picture of a robot, and you\u2019ll likely get an image that resembles Rosie, the robot maid from The Jetsons, or C-3PO from Star Wars. That\u2019s not surprising\u200a\u2014\u200athat\u2019s the vision of robots that science-fiction has portrayed in books, television, and movies for decades. More recently, however, the idea of what a robot is or looks like seems to be evolving. Ask a millennial for an example of a robot and the answer might be Roomba, Amazon\u2019s Echo, or maybe even Siri.\n\nScience fiction promised us a future populated by humanoid robots like C-3PO and Rosie. The robots we have today are something very different, though: They are task-specific machines like automatic vacuums, camera drones, and voice-based assistants. Analog sensing and compute systems could significantly improve the capabilities of today\u2019s robots and AI, making them faster, smaller, and less power-hungry. They may not give us Rosie, but they\u2019ll enable robotic applications we have yet to envision.\n\nThere\u2019s a clear trend that more and more gadgets and other systems that are part of our lives\u200a\u2014\u200afrom thermostats to cars\u200a\u2014\u200awill become more intelligent, more robotic. These systems will require computers that are small, portable, and low power; they will also need to be super responsive and alert at all times. This is a tough set of requirements for today\u2019s compute systems, which typically consume sizable amounts of power (unless they\u2019re on standby) and need to be cloud-connected to perform useful functions. That\u2019s where analog can help.\n\nInspired by nature, scientists have been experimenting with analog circuits to better see and hear while consuming a fraction of the power. Stanford\u2019s Brains in Silicon project and the University of Michigan IC Lab, with backing from DARPA\u2019s SyNAPSE and the U.S. Office of Naval Research, are building tools to make it easier to build analog neuromorphic systems. Stealthy startups are also beginning to emerge. Rather than attempt to run deep nets on standard digital circuits, they have designed analog systems that can perform similar computation with much less power, with inspiration from our analog brains.\n\nWhy the move to analog now? The answer is simple: We\u2019re at a unique intersection where the neural nets we\u2019re trying to implement are more suitable to analog designs, while demand for these types of AI circuits is expected to explode.\n\nTraditional hard-coded algorithms only function when the innards of the compute are accurate and precise. If the circuits that run traditional hard-coded algorithms aren\u2019t precise, errors will grow out of control as they propagate through the system. Not so with neural nets, where the internal states don\u2019t have to be precise and the system adapts to produce the desired output for a given input. Indeed, our brains are incredibly noisy systems that work just fine. Engineers are learning that they can implement deep nets in silicon using noisy analog approaches as well\u200a\u2014\u200ayielding an energy savings on the order of 100x.\n\nThe implications are huge. Imagine a future wearable device or an Amazon Echo-type assistant that uses almost no power\u200a\u2014\u200aor can even harness it from the environment\u200a\u2014\u200arequiring no power cables or batteries. Or picture gadgets that won\u2019t have to be \u201ccloud connected\u201d to be smart\u200a\u2014\u200athey\u2019ll carry enough \u201cintelligence\u201d that they will be able to work even where no Wi-Fi or cellular coverage is available. And this is just the beginning of what I expect to be a whole new category of amazing AI and robot products to emerge in the not-too-distant future\u200a\u2014\u200athanks to good ol\u2019 analog.", 
        "title": "How Analog and Neuromorphic Chips Will Rule the Robotic Age"
    }, 
    {
        "url": "https://medium.com/the-weekly-missive/deep-learning-powered-twitter-bot-launches-presidential-bid-to-benefit-charity-b61bb0253e1b?source=tag_archive---------3----------------", 
        "text": "Yesterday, the DeepDrumpf team announced DeepDrumpf2016.com , a website for the AI candidate listing his procedurally generated positions , an opportunity to bid for cabinet seats, and a donation link to the \u201ccampaign\u201d. All proceeds go to supporting women in STEM.\n\nIt might be quite some time until an artificially intelligent agent can actually launch a real bid for the White House, but in the meantime we\u2019ll have to settle for this. DeepDrumpf is a deep learning-powered AI vulgarian which uses a corpus of Donald Trump speeches to generate tweets that sound almost as incoherent and angry as the real thing.\n\nBradley Hayes, a postdoc at MIT\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL), explained how DeepDrumpf back in March. According to a post on CSAIL\u2019s blog announcing DeepDrumpf, Hayes said \u201cThe algorithm essentially learns an underlying structure from all the data it gets, and then comes up with different combinations of the data that reflect the structure that it was taught.\u201d\n\nCSAIL\u2019s communications manager Adam Conner-Simons went into a little more detail:\n\nUsing this method, DeepDrumpf has come up with some real gems, and there are others that fall into the uncanny valley, at times sounding eerily like the real @RealDonaldTrump twitter persona.\n\nAs the real presidential race continues to careen off the rails, I decided it\u2019d be fun to pull out some of my favorite DeepDrumpf tweets. And by favorite, I really mean some of the more horrifying ones.\n\nOn second thought, maybe an AI president isn\u2019t such a good idea after all.", 
        "title": "Deep Learning-Powered Twitter Bot Launches \u201cPresidential Bid\u201d To Benefit Charity"
    }, 
    {
        "url": "https://medium.com/@katyaseberson/how-to-focus-on-video-courses-you-are-not-passionate-about-34a6ac9cc44c?source=tag_archive---------4----------------", 
        "text": "I have a short video course on Udemy, dedicated to Making Online Learning Stick. When new students join the course, they usually receive a personal message from me where I welcome students to the course and asked them about their Online Learning Challenges. Paul shared that he is currently taking a lot of Real Estate and Investment Courses and finds them extremely boring. By boring he means that he is not passionate about those subjects. His question was how to stay focused on topics he is not passionate about?\n\nI personally believe that preexisting passion is extremely rare and follow your passion is a terrible advice. Because of that advice a lot of college student feel pressured to do exhausting soul searching early on. The expectation is this: once I find the subject I am passionate about, I won\u2019t have to apply effort to learn it, it will be easy and painless. When freshmen and sophomore students think they found their passion, they switch majors instead of focusing on getting really good at something they are currently learning.\n\nPaul thinks that if only he had a different topic to learn about, his discipline and focus would magically amplify and learning will just happen.\n\nPaul has a reason to think that. The conventional wisdom on career success is follow your passion, but it is seriously flawed. It not only fails to describe how most people actually end up with compelling careers, but for many people it can actually make things worse: leading to chronic job shifting and unrelenting angst.\n\n\u201cFollow your passion\u201d might just be terrible advice.\n\nIf \u201cfollow your passion\u201d is bad advice, what should I do instead?\n\nPassion is an epiphenomenon of a working life well lived. Don\u2019t follow your passion; rather, let it follow you in your quest to become so good that they can\u2019t ignore you. If Paul applies himself and masters Real Estate and Finance Course just like his job requires him to, he will probably end up loving his job and becoming passionate about REIT (Real Estate Investment Trusts and other investment vehicles.)\n\nMy advice is to move your focus away from finding the right learning material, toward learning right, and eventually build a love for what you do.\n\nA universal icon, Steve Jobs, in his commencement speech to Stanford University gave this terrible advice: follow your passion and don\u2019t settle.\n\nIf a young Steve Jobs had taken his own advice and decided to only pursue the topics he loved, he would probably have been one of the Los Altos Zen Center\u2019s most popular teachers. But he didn\u2019t follow this simple advice. Apple Computer was decidedly not born out of passion, but instead was the result of a lucky break\u200a\u2014\u200aa \u201csmall-time\u201d scheme that unexpectedly took off.\n\nIra Glass: \u201cIn the movies there\u2019s this idea that you should just go for your dream, but I don\u2019t believe that. Things happen in stages. It takes time to get good at anything\u201d\u200a\u2014\u200athe many years it took him to master radio to the point where he had interesting options. \u201cThe key thing is to force yourself through the work, force the skills to come; that\u2019s the hardest phase.\u201d\n\nThere are many complex reasons for workplace satisfaction, but the reductive notion of matching your job to a pre-existing passion is not among them.\n\nIt\u2019s interesting to see that the strongest predictor of someone seeing their work as a calling is the number of years spent on the job. The more experience they have, the more likely they are to love their work.\n\nThe happiest, most passionate employees are not those who followed their passion into a position, but instead those who have been around long enough to become good at what they do.\n\nMy first advice to Paul is to do what Steve Jobs did and not what he said. Aka, apply himself to the lessons without thinking about the level of passion he posses for the topics.\n\nSecond advice is to stop saying that you find something boring or that you are NOT passionate about something. The only person who is affected by this statement is you and the effect is NOT a positive one. When my reading clients come to me, I tell them to stop saying that they hate reading. It feels better to read, once they stop complaining about it. Instead, we begin to say that reading is HARD. Once we identified what the problem is, we can take a look at what\u2019s hard about. Once we know what\u2019s hard about reading we can focus on that issue to make reading easy and enjoyable.\n\nI tend to see that a lot of online student find courses boring when courses are hard. Well, any meaningful learning will get hard and if you change a conversation from boring to hard, we can then see what\u2019s hard about it and focus on making it less shard or even easy.\n\nThe third advice is to get interested and go deep.\n\nWe already know that Paul has to take a finance course on investments because his job requires him to. Let\u2019s say the course isn\u2019t self-paced and has a start day (most MOOC\u2019s have a start date now.) I recommend signing up early and taking a look at the table of contents. Let\u2019s say the table of contents says: passive index. I would Google the term passive index and also ask myself\u00a0: \u201cis there an active index?\u201d\n\nThese questions are sending probes to my mind, priming my learning, getting me interested and excited about learning.\n\nI also like to familiarize myself with the professor\u200a\u2014\u200amake him/her real. Send them an email, introduce yourself. Read a wiki page. I use this tactic from books. Before I read a book, I read about the author. It helps to know the time when the writer lived/lives. What are his or her key friendship and influencers.\n\nAdvice number four. Paying attention to details might also help. Uncertainty is the worst enemy of our brain. If you are just a bit unsure on what\u2019s required of you\u200a\u2014\u200ayou will procrastinate.\n\nGet certain about these:\n\nHow long is the course?\n\nWhen does the course start?\n\nWhen will I be taking the course? Where will I be (coffee shop, home, office, gym, lobby, etc.0\n\nPut it on your schedule to take away decision making and spend that extra cognitive power on actually learning.\n\nLastly, master curiosity again! We all are naturally curious about things we do not know. Unfortunately, as kids we are told to suppress the innate questioning of what something is, how something works, etc. To get better at learning something that we don\u2019t naturally share a passion for, it is a good idea to play a curious kid with that topic and go berserk with questions on what something is, why not this way, etc. Over time, this could help you develop an active interest for that topic that you began as a disinterested learner.", 
        "title": "How to Focus on Video Courses you are Not Passionate about?"
    }, 
    {
        "url": "https://medium.com/@scott_17538/the-journalists-guide-to-deepgram-fa3fc101624d?source=tag_archive---------5----------------", 
        "text": "Just before the second presidential debate, we at Deepgram announced an initiative to give accredited journalists free access to our powerful speech search engine until Election Day (November 8, 2016).\n\nThe response, quite frankly, has been amazing! We\u2019ve signed up journalists from dozens of national and international outlets, and have really enjoyed speaking with them over the past week. Our initiative has been covered in TechCrunch, and we were named one of the \u201cFive Tools for Journalists To Enhance Election Coverage\u201d by The Columbia Journalism Review.\n\nHere, we\u2019ll discuss some possible ways to use our platform that go beyond searching for sound-bites, and extend an invitation for feedback on how to make Deepgram more useful.\n\nDeepgram lets people search for keywords within spoken audio data like speeches, interviews, and personal voice memos. For journalists, we assumed the main utility of Deepgram was searching for damning soundbites from politicians. (After all, our initiative to give journalists access to Deepgram was inspired by the Trump tapes brought to light by David Fahrenthold on Friday, October 7.)\n\nBut after speaking with many journalists about how they do their work, we think Deepgram is useful for more than just soundbite search. Our platform can make the entire process of researching pieces easier. Instead of transcribing or manually listening to tens or hundreds of hours of audio content, Deepgram helps journalists search through that audio directly. We also make sharing and searching through the result of all that research easier.\n\nSome journalists have asked about using Deepgram to create transcripts of spoken-word audio data. We do offer a transcription feature, and in many circumstances it can be pretty accurate. But, Deepgram helps journalists process interviews and search for quotes more efficiently by eliminating the initial step of transcribing audio recordings.\n\nDeepgram helps journalists and media organizations turn the typical research workflow on its head. A speech search-first workflow lets journalists and research analysts identify the key segments of audio that may need to be transcribed by hand later. Deepgram saves journalists and media organizations time and financial resources by letting them find key words and phrases within tens or hundreds of hours of audio, with no need to transcribe or annotate it all up front.\n\nWe built media sharing directly into Deepgram. At the bottom of any file in our platform, there is a unique HTML iframe element that journalists (or a web developer they work with) can paste into almost any content management system.\n\nBy default, we let users embed searchable audio media. We can create searchable videos as well, but for now that service is only available by request. (Our contact information is at the end of this post.)\n\nEmbedding searchable media makes pieces more interactive and engaging. For example, if a journalist were writing about a political candidate\u2019s speech about tax policies, they might quote the candidate once or twice, but by embedding a searchable version of the speech and some recommended keywords (like \u201cloopholes,\u201d \u201ccarried interest,\u201d \u201cestate tax,\u201d etc.) they can invite readers to dig deeper into the candidate\u2019s position themselves.\n\nWe demonstrated this to great effect in our blog post originally announcing our \u201cFree Deepgram for Journalists\u201d program by embedding Donald Trump\u2019s acceptance speech at the DNC. Here\u2019s a screenshot of the video and our suggestions to readers.\n\nIf you really want to use Deepgram for generating transcripts, you should know the following. If the audio recording is high-quality, the speaker\u2019s pronunciation is crisp, and there isn\u2019t a lot of background noise (like music, crowds clapping, etc.) Deepgram can transcribe words from spoken audio as well as specialty computerized transcription services.\n\nBut those services aren\u2019t as accurate as human transcribers. For now, you\u2019ll probably still have to copy-edit our transcriptions for punctuation and word accuracy. That being said, we\u2019re constantly improving our transcription capabilities.\n\nIf you\u2019re an accredited journalist and want to use Deepgram in your work, remember that it\u2019s free to use between now and Election Day! Just email us and we\u2019ll be more than happy to give you Deepgram credits (worth 75\u00a2 per hour of audio content) for free!\n\nWe are committed to helping journalists search (and research) smarter. We would love to hear your feedback and suggestions for how to improve Deepgram for journalists and media organizations. We\u2019d also like to hear about how you\u2019ve used Deepgram in your work.\n\nFeedback, suggestions, and requests for embeddable videos and Deepgram credits for accredited journalists can be sent to: Press@deepgram.com.", 
        "title": "The Journalist\u2019s Guide To Deepgram \u2013 Scott Stephenson \u2013"
    }
]