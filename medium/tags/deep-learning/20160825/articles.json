[
    {
        "url": "https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0?source=tag_archive---------0----------------", 
        "text": "For this tutorial in my Reinforcement Learning series, we are going to be exploring a family of RL algorithms called Q-Learning algorithms. These are a little different than the policy-based algorithms that will be looked at in the the following tutorials (Parts 1\u20133). Instead of starting with a complex and unwieldy deep neural network, we will begin by implementing a simple lookup-table version of the algorithm, and then show how to implement a neural-network equivalent using Tensorflow. Given that we are going back to basics, it may be best to think of this as Part-0 of the series. It will hopefully give an intuition into what is really happening in Q-Learning that we can then build on going forward when we eventually combine the policy gradient and Q-learning approaches to build state-of-the-art RL agents (If you are more interested in Policy Networks, or already have a grasp on Q-Learning, feel free to start the tutorial series here instead).\n\nUnlike policy gradient methods, which attempt to learn functions which directly map an observation to an action, Q-Learning attempts to learn the value of being in a given state, and taking a specific action there. While both approaches ultimately allow us to take intelligent actions given a situation, the means of getting to that action differ significantly. You may have heard about DeepQ-Networks which can play Atari Games. These are really just larger and more complex implementations of the Q-Learning algorithm we are going to discuss here.\n\nFor this tutorial we are going to be attempting to solve the FrozenLake environment from the OpenAI gym. For those unfamiliar, the OpenAI gym provides an easy way for people to experiment with their learning agents in an array of provided toy games. The FrozenLake environment consists of a 4x4 grid of blocks, each one either being the start block, the goal block, a safe frozen block, or a dangerous hole. The objective is to have an agent learn to navigate from the start to the goal without moving onto a hole. At any given time the agent can choose to move either up, down, left, or right. The catch is that there is a wind which occasionally blows the agent onto a space they didn\u2019t choose. As such, perfect performance every time is impossible, but learning to avoid the holes and reach the goal are certainly still doable. The reward at every step is 0, except for entering the goal, which provides a reward of 1. Thus, we will need an algorithm that learns long-term expected rewards. This is exactly what Q-Learning is designed to provide.\n\nIn it\u2019s simplest implementation, Q-Learning is a table of values for every state (row) and action (column) possible in the environment. Within each cell of the table, we learn a value for how good it is to take a given action within a given state. In the case of the FrozenLake environment, we have 16 possible states (one for each block), and 4 possible actions (the four directions of movement), giving us a 16x4 table of Q-values. We start by initializing the table to be uniform (all zeros), and then as we observe the rewards we obtain for various actions, we update the table accordingly.\n\nWe make updates to our Q-table using something called the Bellman equation, which states that the expected long-term reward for a given action is equal to the immediate reward from the current action combined with the expected reward from the best future action taken at the following state. In this way, we reuse our own Q-table when estimating how to update our table for future actions! In equation form, the rule looks like this:\n\nThis says that the Q-value for a given state (s) and action (a) should represent the current reward (r) plus the maximum discounted (\u03b3) future reward expected according to our own table for the next state (s\u2019) we would end up in. The discount variable allows us to decide how important the possible future rewards are compared to the present reward. By updating in this way, the table slowly begins to obtain accurate measures of the expected future reward for a given action in a given state. Below is a Python walkthrough of the Q-Table algorithm implemented in the FrozenLake environment:\n\nNow, you may be thinking: tables are great, but they don\u2019t really scale, do they? While it is easy to have a 16x4 table for a simple grid world, the number of possible states in any modern game or real-world environment is nearly infinitely larger. For most interesting problems, tables simply don\u2019t work. We instead need some way to take a description of our state, and produce Q-values for actions without a table: that is where neural networks come in. By acting as a function approximator, we can take any number of possible states that can be represented as a vector and learn to map them to Q-values.\n\nIn the case of the FrozenLake example, we will be using a one-layer network which takes the state encoded in a one-hot vector (1x16), and produces a vector of 4 Q-values, one for each action. Such a simple network acts kind of like a glorified table, with the network weights serving as the old cells. The key difference is that we can easily expand the Tensorflow network with added layers, activation functions, and different input types, whereas all that is impossible with a regular table. The method of updating is a little different as well. Instead of directly updating our table, with a network we will be using backpropagation and a loss function. Our loss function will be sum-of-squares loss, where the difference between the current predicted Q-values, and the \u201ctarget\u201d value is computed and the gradients passed through the network. In this case, our Q-target for the chosen action is the equivalent to the Q-value computed in equation 1 above.\n\nBelow is the Tensorflow walkthrough of implementing our simple Q-Network:\n\nWhile the network learns to solve the FrozenLake problem, it turns out it doesn\u2019t do so quite as efficiently as the Q-Table. While neural networks allow for greater flexibility, they do so at the cost of stability when it comes to Q-Learning. There are a number of possible extensions to our simple Q-Network which allow for greater performance and more robust learning. Two tricks in particular are referred to as Experience Replay and Freezing Target Networks. Those improvements and other tweaks were the key to getting Atari-playing Deep Q-Networks, and we will be exploring those additions in the future. For more info on the theory behind Q-Learning, see this great post by Tambet Matiisen. I hope this tutorial has been helpful for those curious about how to implement simple Q-Learning algorithms!", 
        "title": "Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks"
    }, 
    {
        "url": "https://medium.com/data-science-brigade/a-diferen%C3%A7a-entre-intelig%C3%AAncia-artificial-machine-learning-e-deep-learning-930b5cc2aa42?source=tag_archive---------1----------------", 
        "text": "Nos \u00faltimos anos a popularidade de IA explodiu, especialmente desde 2015. Muito disso tem a ver com a disponibilidade dos GPUs ( graphic processing units ) que fazem com que processamento paralelo seja mais r\u00e1pido, mais barato e mais poderoso. Tamb\u00e9m tem a ver com todo a enxurrada de dados que temos hoje na internet (todo o movimento de Big Data)\u200a\u2014\u200aimagens, textos, transa\u00e7\u00f5es, dados de mapas, pode escolher.\n\nIA tem sido parte da nossa imagina\u00e7\u00e3o e fervor dentro de laborat\u00f3rios de pesquisa desde que alguns cientistas come\u00e7aram com o termo nas confer\u00eancias de Dartmouth em 1956 e deram luz ao campo de IA. Nas d\u00e9cadas desde ent\u00e3o, IA tem sido vista de forma alternada entre a chave do futuro mais brilhante da nossa tecnologia e baboseira de fic\u00e7\u00e3o cient\u00edfica\u200a\u2014\u200acoisa de nerds aficcionados querendo que m\u00e1quinas fa\u00e7am muito mais do que deveriam. Francamente, at\u00e9 2012, a realidade era um pouco de ambas.\n\nPor exemplo, quando o AlphaGo da Google derrotou o mestre Sul Coreano Lee Se-dol em uma partida do jogo de tabuleiro Go mais cedo nesse ano, os termos IA, machine learning e deep learning foram usados na m\u00eddia para descrever como o Alpha Go venceu. Todos esses tr\u00eas s\u00e3o parte do motivo da vit\u00f3ria sobre Lee Se-Dol. Mas eles n\u00e3o s\u00e3o a mesma coisa.\n\nNaquela confer\u00eancia no ver\u00e3o de 1956 o sonho dos pioneiros da IA era de construir m\u00e1quinas complexas\u200a\u2014\u200apossibilitadas por computadores que emergiam na \u00e9poca\u200a\u2014\u200aque possu\u00edssem as mesmas caracter\u00edsticas da intelig\u00eancia humana. Esse \u00e9 o conceito que pensamos como \u201cIA gen\u00e9rica\u201d\u200a\u2014\u200am\u00e1quinas fabulosas que tem todos os nossos sentidos (e talvez at\u00e9 mais), toda a nossa raz\u00e3o e pensam como n\u00f3s pensamos. Voc\u00ea j\u00e1 viu essas m\u00e1quinas em filmes como amigos\u200a\u2014\u200aC-3PO\u200a\u2014\u200ae inimigos\u200a\u2014\u200aO Exterminador do Futuro. M\u00e1quinas de IA gen\u00e9ricas ficaram nos filmes e na fic\u00e7\u00e3o cientifica por um bom motivo; ainda n\u00e3o conseguimos criar algo do tipo, pelo menos n\u00e3o ainda.\n\nMachine Learning da maneira mais b\u00e1sica \u00e9 a pr\u00e1tica de usar algoritmos para coletar dados, aprender com eles, e ent\u00e3o fazer uma determina\u00e7\u00e3o ou predi\u00e7\u00e3o sobre alguma coisa no mundo. Ent\u00e3o ao inv\u00e9s de implementar as rotinas de software na m\u00e3o, com um set espec\u00edfico de instru\u00e7\u00f5es para completar uma tarefa em particular, a m\u00e1quina \u00e9 \u201ctreinada\u201d usando uma quantidade grande de dados e algoritmos que d\u00e3o e ela a habilidade de aprender como executar a tarefa.\n\nMachine learning veio direto das mentes do pessoal do in\u00edcio da IA, e a abordagem com algoritmos atrav\u00e9s dos anos incluiu \u00e1rvore de aprendizado, programa\u00e7\u00e3o l\u00f3gica indutiva, agrupamento, aprendizado refor\u00e7ado, redes Bayesianas, entre outros. Como sabemos, nenhuma dessas solu\u00e7\u00f5es chegou ao objetivo final de uma IA gen\u00e9rica, e mesmo uma IA limitada estava fora do nosso alcance com as abordagens iniciais de machine learning.\n\nOutra abordagem em forma de algoritmo do in\u00edcio do movimento de machine learning, Redes Neurais Artificias, surgiram e desapareceram atrav\u00e9s das d\u00e9cadas. Rede neurais s\u00e3o inspiradas pelo nosso entendimento da biologia do nosso c\u00e9rebro\u200a\u2014\u200atodas as interconex\u00f5es entre neur\u00f4nios. Mas, diferente de um c\u00e9rebro biol\u00f3gico onde qualquer neur\u00f4nio pode se conectar com qualquer outro neur\u00f4nio dentro de uma certa dist\u00e2ncia f\u00edsica, essas redes neurais artificiais tem camadas discretas, conex\u00f5es e dire\u00e7\u00f5es de propaga\u00e7\u00e3o de dados.\n\nSe voltarmos para nosso exemplo da placa de pare, as chances s\u00e3o de que enquanto a rede est\u00e1 sendo ajustada ou \u201ctreinada\u201d, est\u00e1 produzindo respostas erradas\u200a\u2014\u200arecorrentemente. Ela precisa de treino. A rede precisa ver centenas de milhares, at\u00e9 milh\u00f5es de imagens, at\u00e9 os pesos de cada informa\u00e7\u00e3o recebida pelos neur\u00f4nios estarem t\u00e3o precisamente calibrados que conseguem responder de forma correta praticamente toda vez\u200a\u2014\u200acom neblina ou sem neblina, com sol ou chuva. \u00c9 nesse ponto que a rede neural aprendeu como que uma placa de pare se parece; ou a rosto de sua m\u00e3e no caso do Facebook; ou um gato, que \u00e9 o que Andrew Ng fez na Google em 2012.\n\nO grande avan\u00e7o de Ng foi de pegar essas redes neurais, e essencialmente faze-las grandes, aumentar as camadas e os neur\u00f4nios, e ent\u00e3o aliment\u00e1-las com um n\u00edvel massivo de dados para que fossem treinadas. No caso de Ng, eram imagens de 10 milh\u00f5es de v\u00eddeos do YouTube. Ng colocou a palavra \u201cdeep\u201d no deep learning, que descreve todas as camadas nessas redes neurais.\n\nHoje, reconhecimento de imagens por m\u00e1quinas treinadas atrav\u00e9s de deep learning em alguns cen\u00e1rios possuem uma taxa de acerto maior que a de humanos, e isso varia de gatos at\u00e9 identificar indicadores de c\u00e2ncer no sangue e tumores em exames de resson\u00e2ncia magn\u00e9tica. O AlphaGo da Google tamb\u00e9m aprendeu as regras do jogo e treinou para sua partida\u200a\u2014\u200acalibrou sua rede neural\u200a\u2014\u200ajogando contra si mesmo repetidamente.\n\nDeep Learning permitiu muitas aplica\u00e7\u00e3o pr\u00e1ticas de machine learning e por extens\u00e3o o campo todo de IA. Deep learning se quebra em diversas tarefas de maneira que todo tipo de ajuda de uma m\u00e1quina \u00e9 poss\u00edvel, mesmo as mais remotas. Carros que dirigem sozinhos, melhor sa\u00fade preventiva, mesmo recomenda\u00e7\u00f5es melhores de filmes, todos j\u00e1 est\u00e3o aqui ou no horizonte. IA \u00e9 o presente e o futuro. Com a ajuda de Deep Learning, IA pode at\u00e9 chegar no estado de fic\u00e7\u00e3o cient\u00edfica que imaginamos por tanto tempo. Se tivermos um C3PO, vou querer. Agora, pode ficar com seu Exterminador.", 
        "title": "A Diferen\u00e7a Entre Intelig\u00eancia Artificial, Machine Learning e Deep Learning"
    }, 
    {
        "url": "https://medium.com/@johnrosania/10-ways-to-increase-deep-work-8883ba5b57dd?source=tag_archive---------2----------------", 
        "text": "The quiet casualty of our hyper-connectivity, the unending psychic drain by the mystical internet, is our ability to focus. The fact is, the less you focus and concentrate in your life, the more your ability to do so wears away.\n\nI recognize this each time I sit down to work on the next act of a play or the new verse of a song. I feel my attention swing and dip, waver and jump, and then rudder into its well-trodden desire for techno-distraction. Every month an important project slips past unfinished, I notice my fading attention and my atrophying concentration.\n\nBut the more I want to create, the more I recognize the need for consistent and sustained periods of focus. Whether it\u2019s writing a play, composing a new harmony, or developing a proposal, attention that sticks to the task at hand, is the essential creative skill.\n\nThe ability to do deep focused work, is \u201cbecoming increasingly rare at exactly the same time it is becoming increasingly valuable in our economy\u201d writes Cal Newport, author of Deep Work. (14)\n\nAs we place more of our attention on shallow activities like social media posting, email responding, and web surfing, we erode meaningful uses of our energy and our ability to do deep work. Over time, we might encounter an increased resistance to focusing, a discomfort with going deep, and a lackluster energy to do the work that means the most to us. Yet, there are strategies that can bring us back to life.*\n\nDeep work requires, at a minimum, uninterrupted concentration in a distraction-free environment. The reason is relatively simple. Newport writes:\n\nMultitasking in effect is doing the opposite. It forces the brain to engage in a range of tasks without assigning priority inhibiting the isolation and growth of targeted neural circuitry. If you want to learn a new skill like playing the piano or write a screenplay, you\u2019re shooting yourself in the foot by working in open work spaces or coffee shops that create the perfect environment to impedes deep work states. Neuroscientists running experiments for the British TV special, The Secret Life of Office Buildings tell us:\n\nGiven how many of us find it challenging to create time to work on our most important projects, we\u2019d do better to put a premium on distraction-free environments that allow us to go deeper.\n\nUnfortunately, our brain is not very good at moving back and forth between concentration and distraction. A text or slack message, a phone call, even a friendly greeting are just a few of the ways our attention is interrupted. These small interruptions then add up, fragmenting our attention and diminishing the total energy we have to give to our task.\n\nEven more, interruptions exponentially increase the amount of time needed to complete a project. For those of us with limited time to focus on our most important projects, this idea alone should be enough to get us to do all we can to block out interruptions for the duration of our work sessions.\n\nThe how is obvious (go to the library, wear headphones, turn off all phones and alerts, tell co-workers your offline for the next two hours, find an isolated corner, close your door), its the will to do so that is often left unengaged.\n\nFocused attention is a skill that increases with practice. Like a new workout, the first few weeks are tiring and hard. We want to give up and do something easier. In the same way, as we increase the length of time in which we stick with increasing loads of cognitive intensity, we may want to stop, grab something to eat, check our phones, get another cup of coffee, etc.\n\nBut like exercise, the fluttering of attention away from what we are doing is part of the workout. We just keep bringing our attention back. And some interesting neurological benefits are garnered by those who do so.\n\nIn addition to producing more meaningful work, rapt concentration creates a mental environment where there is no attention left to worry, perseverate, or fall into despair.\n\nRoutines and rituals move us beyond good intentions and help \u201cminimize the amount of\u00a0.\u00a0.\u00a0. limited willpower necessary to transition into a state of unbroken concentration.\u201d (100)\n\nThe more specific and simple you can make your routines and rituals, the more likely they will support you when things get tough. When I am experimenting with a new ritual to increase my deep work states, I run through it a few times like an actor reviews their movements on stage. I get it in my body as much as possible so that when I\u2019m tired or wanting to do something else, I give over to the ritual and let it guide me into my work (this is also a basic principle of most spiritual disciplines).\n\nThe type of ritual or routine is only limited by your imagination.\n\nHere are a few examples:\n\nFor most of us, email does not create new value nor engage us in meaningful work. It\u2019s by and large reactive, depressing, and endless. When responding to email is left unscheduled, it eats away at our downtime, fragmenting our attention, and diminishing our rest.\n\nEmail is one of the key examples illustrating Newport\u2019s principle of least resistance, wherein the absence of clear focus, \u201cwe will tend toward behaviors that are easiest in the moment.\u201d (58) Rather than taking charge of our attention and making the tough decision of what to work on when, we may drag our heels letting our inbox decide our daily fate.\n\nNewport identifies four basic approaches to deep work, the monastic (long uninterrupted periods of working, i.e. a week, a month), the bimodal (multi-day depth binges, say from Friday-Sunday), the rhythmic (habit-based approach that creates daily routines\u200a\u2014\u200asee chain method, daily schedule.), and the journalistic (finding short depth periods during a fluctuating schedule\u200a\u2014\u200abest for those already confident in their abilities).\n\nAll three philosophies have advantages and disadvantages. For example, a bimodal person who focuses for a three-day weekend may achieve a level of cognitive intensity unavailable to a person following the rhythmic or journalistic philosophy. On the other hand, the rhythmic person may be doing more deep work in total over a month period and can fit their deep work sessions into their daily work schedule.\n\nI\u2019m inspired by the fact that, for most people, all four philosophies can be tried during a year and tested to see which produces the greatest results and the deepest creativity for you.\n\nThere is a reason that train rides, hiking, wandering, and traveling have long been a fascination of artists. These activities place the artist in unexpected terrain, encourage new perspectives, and pull them from the routine of their daily lives.\n\nTo inspire deep work or push through a challenging dip in a project, try doing something unexpected. Newport mentions a few inspiring examples including J.K. Rowling\u2019s move to a luxurious hotel to finish the last of the Harry Potter books, Bill Gates\u2019 Think Weeks in which he goes to a remote location with a stack of papers and books to read and think about, and entrepreneur Peter Shankman\u2019s legendary 30-hour round-trip flight to Tokyo on which he completed an entire book manuscript.\n\nThese, of course, are rare examples fit for a small segment of the population, but they point to something we can all do: find ways to encourage openness and curiosity while keeping deep work in mind. Some examples could include going camping, house-sitting, asking to use a friend\u2019s summer house during the off-season or your parent\u2019s house when they travel, renting a cabin, taking a cross country train ride, taking a solitary hike or a long drive while thinking through a problem, or exploring a new library in your area.\n\nThe paradox is that idleness and rest are necessary to get deep work done. The outpour of energy needed to achieve focused intensity requires their opposite: relaxed, open attention, and rest. But the busy, frenetic mind remains obsessed with creating reasons why boredom, idleness, and rest could not possibly increase our creative output, how we\u2019ll get behind, how we\u2019re not dedicated enough.\n\nTo counteract this tendency, Newport gives us reasons why downtime is essential. The most obvious is that rest is required to restore the energy needed for cognitive intensity. Particularly useful is getting adequate sleep and walking in nature (walking in cities seems to deplete energy).\n\nMore interestingly, he tells us that downtime aids insights. Citing a 2006 paper in Science that questions whether the benefits of conscious deliberation in decision making are justified, the Dutch psychologist Ap Dijksterhuis concludes that they are not. Following this thought Newport writes:\n\nThe final reason given for building rest and restorative activities to balance your deep work sessions is that the work that evening downtime replaces is usually not that important. The mind can easily turn on anxiety and stress and encourage us to start working again after dinner. But Newport cautions us against this habit. The activities you do in the evening are of lower energy and quality and will most likely not advance your important goals. In most cases, they can be easily deferred.\n\nThe most common way, we are presented, to deal with our increasing screen time usage and fragmented attention is summarized like this: take short breaks from your generalized state of distraction. Internet Sabbaths or digital detoxes, in which a person takes one day a week or a few days every quarter to refrain from digital toys, are the most common.\n\nIf your goal is to increase your ability to focus and reduce the background noise of the mind, these methods don\u2019t work. They do not provide enough time and attention to work at the level of brain wiring and habit formation. In fact, they help to keep you unfocused most of the time\n\nNewport proposes an alternative: take breaks from focus, not from distraction. Instead of scheduling time away from distracting technology, schedule your usage of them. To do this, consider all your internet surfing, email responding, social media posting, and even texting as distracted activities. Then schedule their usage during the day and don\u2019t use them at any other time. To be clear, it\u2019s not about not using your devices, but deciding consciously when to use them. Every time you decide to use your phone and do your email, rather than an alert or an open tab on your computer conditioning you to do it, you improve your ability to focus.\n\nBy scheduling your distracted time and maintaining the rest of your life in focus, you\u2019ll reclaim (some) of your ability to be attentive and present and improve your deep work sessions.\n\nCognitive intensity is hard. You\u2019re pushing your abilities, building new skills, creating new ideas. There\u2019s no way around this challenge. But our smartphones and internetting keep rattling off a singsong of freedom that reads like this:\u201cNo matter where you are, we\u2019re here for you, just a click away. You can always remove yourself from whatever you don\u2019t like (a conversation, a party, waiting in line at the market) and jump right into a land of endless fascination.\u201d\n\nBut this freedom is fool\u2019s gold. Embracing it reduces your ability to keep going when the work becomes uncomfortable. And it will. If it doesn\u2019t, you haven\u2019t seen what you can really do. This is the gift of deep work. You create the conditions to call upon the greatest expression of your own resources, resources you were almost sure you didn\u2019t have. It sounds almost heroic because it is.\n\n*I am grateful to Cal Newport and his excellent book Deep Work from which these ideas have been gathered.", 
        "title": "10 Ways To Increase Deep Work \u2013 John Rosania \u2013"
    }, 
    {
        "url": "https://blog.unnati.xyz/neural-networks-the-first-cut-3553aeedbf4a?source=tag_archive---------3----------------", 
        "text": "As I get ready to do my first solo workshop on Deep learning in the field of Natural Language Processing, my anxiety levels are extremely high and I am definitely excited.\u00a0\n\nThe anxiety levels have made me read numerous papers\u00a0, blog posts and definitely some code. I feel I have made a small progress in understanding the subject and this makes me feel a little comfortable.\n\nDeep learning is really not too hard to understand if you think about it from a real world angle. What we are really trying to do is to build systems that can emulate the human mind.\n\nTo explain neural networks, I will take a an real world example and then we will see how they are represented in an NN world. Let us take the simple example of catching a ball when it is thrown at us. If you ask a small kid how he does it\u00a0, you will hear him say well you throw the ball and I catch it. If you try to look a little closer\u00a0, there are so many things that the human brain is doing in such a short span time and with the input data changing every second. The human brain is computing the size of the ball, the speed of the ball, the trajectory and checks how confident you are in catching this ball. All of these computations are done in real time and you have an outcome, either you catch the ball or you fail to catch it. Overtime if you are constantly trained to catch the ball, you will eventually see that your confidence levels are high and your outcome essentially is almost positive.\n\nIf you were to let a system catch a ball, the very first thing that you need to do is provide inputs to the system i.e translate the type of ball into something that a computer can understand. You would do the same for all the different forms of input. Now your input set is ready.\u00a0\n\nThe next step is defining what you want to do with these inputs and the process of performing an operation on a given input in the field of NN is defined as activation function. The node that performs this activation function on the input is essentially called the neuron. Our nervous system has 10\u00b9\u00b9 neurons so having just one neuron might not yield us good results.So you add multiple neurons that can perform the same function on the set of defined inputs. We call this bunch as the hidden layer.\n\nNow the very next question we ask ourselves is, okay what is the use of adding more neurons to do the same function, this is answered by weight matrix. Before explaining what weight matrix is, let us understand what it means in the real world. Every input we considered for the ball example plays some part in the outcome, how much part it plays is what is defined the Weight matrix. As we do not know what is the prominence of each input we just randomly assign weights to input to initiate the process. These weights, multiplied for every input combination are used as inputs for the neurons. Now we have considered all our inputs and we have built something that emulates the human brain. We still do not know if the system caught the ball or not. To know this we pass the output of all the neurons to another node that generates the output by behaving as another neuron that operates on incoming data i.e output of the hidden layer, thereby telling us if the ball has been caught for a given set of input.We are now done with the first pass of NN and this is termed as feed forward.\n\nNow this is where things get really interesting, we have the output from the system and the outcome of a real entity, there is a very high chance the system predicted the wrong outcome. The reason is, the system does not understand the inputs and their prominence aka weights properly. This needs to be corrected, we find the difference between the expected outcome and system generated outcome and we call this error. We need to reduce the error, we cannot modify the inputs but what we can modify are the weights. So that is exactly what happens in an NN, by a process known as Back-propagation which is beautifully explained by Christopher Colahs Blog on Back propagation. This process of adjusting weights to reduce error is when the actual learning starts. Once the weights are adjusted, the feed forward process begins from the first layer all the way to the output.\n\nSo now you have started training your model and your model is learning slowly. In the ball catching example, I mentioned that a person becomes a better catcher if you train him over time. This is exactly what we do with our model too, we keep reiterating our process eventually giving us an intelligent system that can predict if a person can catch the ball or not based on different criteria.\n\nThis is how an NN works and this is our first small step to building intelligent systems.", 
        "title": "Neural Networks \u2014 The first cut \u2013"
    }, 
    {
        "url": "https://medium.com/@bhaskar.q89/the-other-side-of-artificial-intelligence-next-generation-ai-specific-chips-eb5a73376d3?source=tag_archive---------4----------------", 
        "text": "Most of the attention that AI has received over the last decade has only been on the software side, but the \u2018Silicon\u2019 side of things have not received much attention, even though there was (still) a pressing need for better chips and significant developments occurring in this space. Pioneers like Yann Le Cunn and Andrew NG have always focused on both sides of the coin i.e. hardware + software. Better hardware is required to enable shorter training times, better memory access for deep/machine learning algorithms while working with bigger sized training data sets, as well as shorter prediction times all the while minimising error rates. GPUs had previously brought efficiencies ranging in between 9X to 72X over conventional CPUs (Source). Better hardware and chip architectures could bring in a further factor of 10X improvement in efficiency.\n\nBut behind the scenes, most of the technology giants realize the need and market opportunity for creating dedicated chips (AI Accelerators) for AI applications. Both Google and Microsoft are known to have used custom ASICs to enhance machine learning capabilities of their respective search engines. Intel has made its priorities clear with the $16.7B acquisition of FPGA maker Altera, and the recent ~$400M acquisition of Nervana Systems, a startup working on custom ASICs for deep learning. These acquisitions have given Intel enough ammunition to compete with Nvidia, which is currently dominating the deep/machine learning hardware space.\n\nThe priority for most of these giants is to produce an AI specific chip which could power the next generation high performance data centers. These chips could further power the next generation of IoT devices (Smart Phones, Smart Cars, Smart Toys, Robots etc.) and provide them with in-device AI capabilities, making them less dependent on a remote cloud infrastructure.\n\nStartups have not been far behind in the race. The space has seen an influx of $589M of venture capital and private equity. Knuedge, founded by a former NASA head recently came out of stealth mode after a decade, with a $100M funding announcement. Nervana Systems was acquired recently by Intel for ~$400M. Mobileye, a company which powers the ADAS of prominent car companies like BMW, Volvo, GM, Renault, Tesla(until recently) is leading the way in the self driving car space.\n\nAcademia is also not shying away from this space. Recently, MIT researchers had presented Eyeriss, a chip which was 10X as efficient as a mobile GPU, and could run deep learning algorithms locally on a mobile phone.Going further, we can expect more activity from established companies as well as startups in this space. These developed chips powering next generation IoT devices and data centers.", 
        "title": "The Other Side Of Artificial Intelligence \u2014 Next Generation AI Specific Chips"
    }, 
    {
        "url": "https://medium.com/@chintu30/question-for-experts-if-the-neural-nets-are-in-fact-running-locally-on-the-device-87a1cda2da0b?source=tag_archive---------5----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Question for experts: if the neural nets are in fact running locally on the device \u2013"
    }, 
    {
        "url": "https://medium.com/@itsquiz15/new-pedagogies-for-deep-learning-52317e0426ee?source=tag_archive---------6----------------", 
        "text": "Do you know how to achieve deep learning in the classroom?\n\nThere are few advices from innovative educators from EDtalks.\n\n21st century teaching requires new approach and educators look for the educational way that fits modern children. The teachers create collaboration in the classroom to deliver deep knowledge. They use devices to engage young people in learning and save time.\n\nNew pedagogies provides liberal curriculum, it focuses on how relevant is education using a common language for the deep understanding. In a modern network, educators have access to the educational experience of others to reinforce their efforts and estimate past experience, generate new ideas and work on challenging issues. Global partnership \u201cNew pedagogies for deep learning\u201d involves 600 schools from different countries to make a difference in the modern education.\n\nThe study shows that learners\u2019 brain activity is almost non-existent during lectures and is lower than when they are asleep. Learners estimate their education as boring and unnecessary. Educators try to create new pedagogies and spread it in different countries and to get learning outcomes through effective relationships. The new educational approach opens the power of digital tools needed in the modern society. It prepares the children to become life-long learners.\n\nNew pedagogies demands to create an opportunity for students to be equal learning partners, a permanent assessment of the learning progress. Technology is used to master content knowledge and integrate new skills outside of school.\n\nA new way of teaching reduces the cost and kindles curiosity, it uses deep learning tasks that target the learners in a right way. Active learning brings aspiration and new digital tools provide high-quality and fast feedback.\n\nThe students may see entire amount of information that they need to learn. The learners know what wait for them on the next level and the appropriate requirements.\n\nThe educators and the students collaborate with each other, also the children perform tasks together. Their understanding becomes deeper and stronger, they learn more conscious.\n\nThe teachers put together the learners from different year groups. Children are ready to teach younger students and the study becomes more interesting. The students remember and understand more information through the teaching.\n\nThe learners gain negotiation and communication skills as well in cooperation. They see their progress and may share their experience with other to grow together.\n\nThis is a modern learning environment that helps teachers to explain new materials and it supports learning process at all levels. \u201cThe new pedagogies provides a framework for change management when the teachers won\u2019t adopt anything unless they believe it\u2019s in the best interests of children and learners\u201d, Jacqui Duncan, Cashmere Primary School principal.\n\nMany schools already use devices for reading and writing in the classroom, also they share their assignments online to estimate their works and get the advices. Technology connects the learners with a lot of useful tools and provides a possibility for the self-directed education. The experts say that digital education improves learners\u2019 communication skills. The children learn to manage their ideas and thoughts in a meaningful way. Also, their grammar becomes better.\n\nFor example, Newham Collegiate Sixth Form Centre uses a new form of feedback that involves data collection, self-assessment and videos questions. The teachers give the students tasks with ready success criteria for the self-assessment. The educators use apps that create a test to check the knowledge and videos to visualize difficult themes. Then, teachers provide the learners with the detailed feedback using apps. Innovative feedback switches the focus from the summative result to reflecting on the material.\n\nNew pedagogy fosters social benefits through cooperation between teachers and students. The teachers put together the learners from different year groups. Children are able to teach younger learners and the education becomes more interesting. The students remember and understand more information through the teaching.\n\nThe new educational approach opens the power of digital tools needed in the modern society. Technology connects the learners with a lot of useful tools and provides a possibility for the self-directed education. A new way of teaching reduces the cost and kindles curiosity, it uses deep learning tasks that target the learners in a right way. Active learning brings aspiration and new digital tools provide high-quality and fast feedback.", 
        "title": "New Pedagogies for Deep Learning \u2013 Itsquiz \u2013"
    }
]