[
    {
        "url": "https://gab41.lab41.org/lab41-reading-group-generative-adversarial-nets-d2c5fccc7ffa?source=tag_archive---------0----------------", 
        "text": "One of the great things about working at Lab41 is that we are always taking on new and exciting projects, but this means we need to stay knowledgeable in many different subjects and techniques. In order to stay up-to-date and expand our horizons we read and discuss about one paper a week. The most common subject of these papers is machine learning, but any topic that we deem interesting and useful could show up. We thought you might find these papers interesting, so we plan to start posting about our findings on Gab41.\n\nThis week\u2019s paper (arXiv version) is by Ian Goodfellow and introduces the concept of Generative Adversarial Nets (GANs).\n\nMany of the problems tackled by machine learning can be broken down into one of two types: discriminative and generative. A discriminative task seeks to classify some input, and a generative task seeks to create a model that can generate data that looks like the training data. For example, an algorithm that identifies cats in photos is performing a discriminative task, while an algorithm that generates images of cats is performing a generative task.\n\nNeural networks have proven to be extremely effective at discriminative tasks\u200a\u2014\u200abeating 95% accuracy on various test benchmarks\u200a\u2014\u200abut perform less effectively at generative tasks. Goodfellow\u2019s key idea was to turn the generation of images (normally a generative task) into a partially discriminative task to benefit from this effectiveness. In a GAN model there are two networks. One network, the generative network G, learns to generate fake images while the other network, the discriminative network D, learns to detect fake images. The model is adversarial because the two networks \u201cfight\u201d: the generative network makes forgeries, the discriminative network tries to detect them, and both networks are constantly learning to beat the other network.\n\nThe model is trained by using a data distribution x, and a noise distribution z. The generative network takes in noise and outputs images: G(z). A toy example of an image from the training set (left) and the output from the generative network (right) are shown below.\n\nThe discriminative network takes in both real images and fake images and classifies them: D(x) and D(G(z)) respectively. It should return 1 for real images, and 0 for fake images. A discriminative network that is well trained would perform as shown in the image below.\n\nThe two networks are trained using different optimization functions. The generative network tries to minimize the function log(1-D(G(z))). This function is minimized when the discriminative network incorrectly classifies a fake image as real. The discriminative network tries to maximize the function log(D(x)) + log(1-D(G(z))). The first term is maximized when the network correctly identifies real images, and the second is maximized when it correctly identifies fakes. Note that both networks are optimizing log(1-D(G(z))), but that one wants to make it small while the other wants to make it large!\n\nGoodfellow trained his model on various datasets including MNIST, TFD, and CIFAR-10. The results are shown below for MNIST and TFD:\n\nEach row contains a few examples generated by the model, while the furthest right column (highlighted with a yellow border) are the closest examples from the training set.\n\nSome of the challenges of GAN models are that it can be difficult to synchronize the generative and discriminative networks. If one network is much better at its task than the other network, than the left behind network will have trouble learning because it always loses. Additionally, there is no explicit modeling of the probability of the data distribution; if it is required, it must be approximated from the model.", 
        "title": "Lab41 Reading Group: Generative Adversarial Nets \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/the-next-generation-ai-demo-the-viv-app-co-founder-of-siri-a-voice-conversation-recognition-3e9309c028b9?source=tag_archive---------1----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "The Next Generation AI, Demo The Viv App Co-founder of Siri a Voice Conversation Recognition"
    }
]