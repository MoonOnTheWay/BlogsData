[
    {
        "url": "https://medium.com/machine-learning-world/neural-networks-for-algorithmic-trading-part-one-simple-time-series-forecasting-f992daa1045a?source=tag_archive---------0----------------", 
        "text": "This is first part of my experiments on application of deep learning to finance, in particular to algorithmic trading.\n\nI want to implement trading system from scratch based only on deep learning approaches, so for any problem we have here (price prediction, trading strategy, risk management) we gonna use different variations of artificial neural networks (ANNs) and check how well they can handle this.\n\nNow I plan to work on next sections:\n\nI highly recommend you to check out code and IPython Notebook in this repository.\n\nIn this, first part, I want to show how MLPs, CNNs and RNNs can be used for financial time series prediction. In this part we are not going to use any feature engineering. Let\u2019s just consider historical dataset of S&P 500 index price movements. We have information from 1950 to 2016 about open, close, high, low prices for every day in the year and volume of trades. First, we will try just to predict close price in the end of the next day, second, we will try to predict return (close price\u200a\u2014\u200aopen price). Download the dataset from Yahoo Finance or from this repository.\n\nWe will consider our problem as 1) regression problem (trying to forecast exactly close price or return next day) 2) binary classification problem (price will go up [1; 0] or down [0; 1]).\n\nFor training NNs we gonna use framework Keras.\n\nFirst let\u2019s prepare our data for training. We want to predict t+1 value based on N previous days information. For example, having close prices from past 30 days on the market we want to predict, what price will be tomorrow, on the 31st day.\n\nWe use first 90% of time series as training set (consider it as historical data) and last 10% as testing set for model evaluation.\n\nHere is example of loading, splitting into training samples and preprocessing of raw input data:\n\nIt will be just 2-hidden layer perceptron. Number of hidden neurons is chosen empirically, we will work on hyperparameters optimization in next sections. Between two hidden layers we add one Dropout layer to prevent overfitting.\n\nImportant thing is Dense(1), Activation(\u2018linear\u2019) and \u2018mse\u2019 in compile section. We want one output that can be in any range (we predict real value) and our loss function is defined as mean squared error.\n\nLet\u2019s see what happens if we just pass chunks of 20-days close prices and predict price on 21st day. Final MSE= 46.3635263557, but it\u2019s not very representative information. Below is plot of predictions for first 150 points of test dataset. Black line is actual data, blue one\u200a\u2014\u200apredicted. We can clearly see that our algorithm is not even close by value, but can learn the trend.\n\nLet\u2019s scale our data using sklearn\u2019s method preprocessing.scale() to have our time series zero mean and unit variance and train the same MLP. Now we have MSE = 0.0040424330518 (but it is on scaled data). On the plot below you can see actual scaled time series (black)and our forecast (blue) for it:\n\nFor using this model in real world we should return back to unscaled time series. We can do it, by multiplying or prediction by standard deviation of time series we used to make prediction (20 unscaled time steps) and add it\u2019s mean value:\n\nMSE in this case equals 937.963649937. Here is the plot of restored predictions (red) and real data (green):\n\nNot bad, isn\u2019t it? But let\u2019s try more sophisticated algorithms for this problem!\n\nI am not going to dive into theory of convolutional neural networks, you can check out this amazing resourses:\n\nLet\u2019s define 2-layer convolutional neural network (combination of convolution and max-pooling layers) with one fully-connected layer and the same output as earlier:\n\nLet\u2019s check out results. MSEs for scaled and restored data are: 0.227074542433; 935.520550172. Plots are below:\n\nEven looking on MSE on scaled data, this network learned much worse. Most probably, deeper architecture needs more data for training, or it just overfitted due to too high number of filters or layers. We will consider this issue later.\n\nAs recurrent architecture I want to use two stacked LSTM layers (read more about LSTMs here).\n\nPlots of forecasts are below, MSEs = 0.0246238639582; 939.948636707.\n\nRNN forecasting looks more like moving average model, it can\u2019t learn and predict all fluctuations.\n\nSo, it\u2019s a bit unexpectable result, but we can see, that MLPs work better for this time series forecasting. Let\u2019s check out what will happen if we swith from regression to classification problem. Now we will use not close prices, but daily return (close price-open price) and we want to predict if close price is higher or lower than open price based on last 20 days returns.\n\nCode is changed just a bit\u200a\u2014\u200awe change our last Dense layer to have output [0; 1] or [1; 0] and add softmax output to expect probabilistic output.\n\nTo load binary outputs, change in the code following line:\n\nAlso we change loss function to binary cross-entopy and add accuracy metrics.\n\nOh, it\u2019s not better than random guessing (50% accuracy), let\u2019s try something better. Check out the results below.\n\nWe can see, that treating financial time series prediction as regression problem is better approach, it can learn the trend and prices close to the actual.\n\nWhat was surprising for me, that MLPs are treating sequence data better as CNNs or RNNs which are supposed to work better with time series. I explain it with pretty small dataset (~16k time stamps) and dummy hyperparameters choice.\n\nYou can reproduce results and get better using code from repository.\n\nI think we can get better results both in regression and classification using different features (not only scaled time series) like some technical indicators, volume of sales. Also we can try more frequent data, let\u2019s say minute-by-minute ticks to have more training data. All these things I\u2019m going to do later, so stay tuned\u00a0:)", 
        "title": "Neural networks for algorithmic trading. Simple time series forecasting"
    }, 
    {
        "url": "https://medium.com/@jzig/17-neural-network-interpretations-of-a-random-doom-screenshot-13823abe575b?source=tag_archive---------1----------------", 
        "text": "I\u2019ve been messing around with neural network image manipulation since I saw the original Deep Dreams article, and lately I\u2019ve been interested in projects like neural-style that go farther artistically. On top of that I just bought a new PC with an expensive graphics card that I wanted to try out with CUDA, so it seemed like fun to dive in. After doing a bit of research I found out that running these projects on Windows is bit tricky, and I didn\u2019t want to do the work necessary to get a hardware Linux installation running (CUDA doesn\u2019t work in VMs), so I experimented with what was available\n\nThe neural-style implementation is built on top of something called Torch, which is a LUA-based architecture for scientific computing. Looking around I couldn\u2019t find an up to date Windows version that would work out of the box. But I did find style-transfer, which is an implementation of the same research paper in pycaffe instead of Torch. Luckily, this worked for me because I had already gotten pycaffe working with Deep Dreams, using this very detailed and helpful guide. I also had to install opencv using the second solution in this StackOverflow thread. Things were up and running.\n\nThe way style-transfer works is that one image is the \u201ccontent\u201d image that is used as the initial image seed, and the second is the \u201cstyle\u201d image which is analyzed for visual properties to borrow. Roughly, the resulting image will have the large scale structure of the first image, with the artistic flair of the second. I wanted to see how it would work with game visuals so I downloaded a few low res game screenshots from Google Images to use as source files.\n\nEach run of the algorithm takes around 10 minutes to compute, and I started messing around with various combinations and neural models. Not all combinations end up being particularly interesting. Here\u2019s my first attempt, which is a disaster:\n\nI discovered that vgg16 on the default settings worked well, and that images with a strong figure and background split work well as content. For the style image you want one that shows a good variety of elements with interesting detail that the algorithm can learn from. One content image that worked well was this doom screenshot:", 
        "title": "17 Neural Network Interpretations of a Random Doom Screenshot"
    }, 
    {
        "url": "https://medium.com/@azntaiji/bots-in-the-news-ai-driven-vehicles-enterprise-bots-and-deep-learning-732f042beb2?source=tag_archive---------2----------------", 
        "text": "Good afternoon bot enthusiasts, and TGIF! Today, we\u2019ll examine the effects of AI in autonomous vehicle recognition development, explore bot relationships in the enterprise and define deep learning.\n\nWhile most autonomous vehicles rely on radar and sensors to make real-time decisions on the road, AI and deep learning are poised to take automotive to the next level. According to a recent report by analytics firm IHS, \u201cAI could help these self-driving vehicles recognize patterns and learn from the behavior of other vehicles on the road.\u201d\n\nWith AI embedded in infotainment systems and ADAS (Advanced Driver Assistance Systems), IHS predicts a rise in shipments\u200a\u2014\u200a115 million\u200a\u2014\u200afrom 2015 to 2025. In addition, these new and improved systems will be capable of eye tracking, monitoring of the vehicle and driver condition evaluations.\n\nToday\u2019s automotive innovators like Tesla, Google and BMW are already investing a lot into AI. In fact, the 2015 BMW 7 Series is the very first to offer a new approach: wireless connectivity. To join the trend, other big names like Nissan and Volkswagen have begun to partner up with AI companies like Mobileye, to provide better visual identification.\n\nFor more on AI in autonomous vehicles, click here.\n\nThe fear that bots will fully automate businesses and take away jobs just isn\u2019t true. With the integration of bots in enterprise, redundant and monotonous tasks can become automated.\n\nBut for bots to even be considered a stepping stone into this ideal workplace, they must first be mobile online, all the time. They need to be accessible to all users, across all platforms. Second, bots need to be able to communicate with humans effectively. This means the introduction of APIs that enable easy developer access. Lastly, bots need to be smart.\n\nBots can transform the enterprise, but businesses need to strike a balance between a fully automated workforce and human-driven workforce. Bots and humans need to work together to become effective.\n\nRead more about the topic on ITProPortal by clicking here.\n\nJust like magic, deep learning seems to amaze users with its rapid growth and intelligence. In reality though, it\u2019s just math when boiled down to the basics. Deep learning is comprised of millions of examples and training, along with manual human labor to get the system to work.\n\nTo illustrate, deep learning is designed like the human brain, however it\u2019s much simpler in what it\u2019s able to process. Essentially small tasks, like detecting patterns and playing games are what deep learning currently specializes in.\n\nThe science and work people have put into deep learning are what make this system amazing, even if it\u2019s not magic\u200a\u2014\u200aanother step ahead into the bright and exciting future of AI.\n\nRead more on Wired here.", 
        "title": "Bots in the News: AI-driven vehicles, enterprise bots and deep learning"
    }, 
    {
        "url": "https://medium.com/this-week-in-machine-learning-ai/ml-ai-at-apple-ibms-deep-thunder-exciting-new-deep-learning-research-twiml-2016-06-17-4f3c03d3ce25?source=tag_archive---------3----------------", 
        "text": "This week\u2019s podcast digs into Apple\u2019s ML and AI announcements at WWDC, looks at the new Deep Thunder offering by IBM and The Weather Company, and discusses exciting new deep learning research from MIT, OpenAI and Google.", 
        "title": "ML & AI at Apple, IBM\u2019s Deep Thunder & Exciting New Deep Learning Research \u2014 June 17, 2016"
    }
]