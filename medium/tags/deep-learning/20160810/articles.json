[
    {
        "url": "https://medium.com/the-ai-lab/how-to-start-a-deep-learning-startup-not-from-scratch-a-tutorial-bff4e096a7b2?source=tag_archive---------0----------------", 
        "text": "You build your product like a furniture from IKEA: by quickly assembling ready-made parts:\n\nPay attention to design, it matters. Code can be left dirty, you will clean the mess later. Like a cheap IKEA furniture, things will fall apart quickly, but don\u2019t worry, you are not crafting a piece of museum.\n\nYour product should be \u201cminimal viable\u201d (MVP), which means that it should be viable enough to be shown to users, while requiring the minimal amount of effort to be produced.\n\nNow, let\u2019s get to the practical details:\n\nThe core feature of the product is based on deep learning. You don\u2019t need a deep understanding of deep learning to get started: you can use transfer learning, or an open-source API. You can also use a commercial API to get started, but think about a fallback plan. First, this API costs money at some point, and second, it is more risky if the provider pivots, or simply shuts down. In deep learning, many companies dream to get acquired by a competitor, don\u2019t rely on a mock startup too much.\n\nFor my product, I choose the OpenFace library of face recognition, which re-implements Google\u2019s FaceNet paper. And I am satisfied.\n\nThe deep learning feature is packaged into a web or mobile application. A web framework like Python Flask, and a database like MySQL, are usually enough.\n\nIf your product uses live streaming, then you will probably need websockets, available in autobahn. In this case, you use a twisted server for deployment. Otherwise, deploying on a HTTP Apache server is enough.\n\nFor hosting, I used AWS free tier, but now there are many other alternatives.\n\nAnd when bugs happen, the first reflex is to google the error message, the second reflex is to try asking a good Stack Overflow question (which might require substantial preparation). If it fails, ask your rubber duck. It works.\n\nFinally, register a fancy dot-com domain, or not-dot-com domain, and associate it with your server.\n\nBONUS: For the streaming part, instead of websockets, it would be nice to adapt WebRTC for peer2server communication, as WebRTC is primarily peer 2 peer.\n\nHow do I ask a good question?\u200a\u2014\u200aHelp Center\u200a\u2014\u200aStack Overflow\n\nCreating a Web App From Scratch Using Python Flask and MySQL, Jay\n\nHow to Retrain Inception\u2019s Final Layer for New Categories, TensorFlow", 
        "title": "How to start a deep learning startup, NOT from scratch: a tutorial"
    }, 
    {
        "url": "https://medium.com/axiomzenteam/ai-is-an-ai-problem-33cacdbf9762?source=tag_archive---------1----------------", 
        "text": "Not every problem has a thousand solutions, but finding a problem with only one is very rare. That\u2019s why when AI researchers seek to solve problems, they use a method called \u201coptimization\u201d to find not only the solution to a problem, but to find the best solution to that problem.\n\nImagine the nature of the problem as a mountain. Every time they run an algorithm to seek a solution, they\u2019re looking for the mountain peak.\n\nFinding that peak involves running the algorithm over and over. Like climbers making their way up the mountain, the algorithm tests solutions and then compares them against each other, looking for the best one.\n\nHowever, if all of the steps start out at the same point, they can only ever climb one mountain. What if it turns out that they\u2019re standing in a mountain range\u200a\u2014\u200athat there\u2019s a better solution out there, using a different starting point?\n\nTo ensure that researchers don\u2019t get stuck on a small mountain range, they use diverse techniques and random restarts while optimizing. This introduces an element of the chaotic, and makes sure that you don\u2019t end up with a poor local optimum. This is a foundational element of machine learning\u200a\u2014\u200abut it\u2019s one researchers have forgotten when looking at the field of artificial intelligence. Because creating true general artificial intelligence is a problem, and lately, we\u2019re exploring only one path to find its solution.\n\nResearchers have begun to focus exclusively on deep learning, to the potential detriment of optimization. No one knows if deep learning will end up being a local optimum, or if it will be the peak we were searching for all this time.", 
        "title": "AI is an AI Problem \u2013 Axiom Zen Team \u2013"
    }, 
    {
        "url": "https://humanizing.tech/nervanas-product-overview-deck-on-their-ai-deep-learning-capabilities-5aab1e4067c?source=tag_archive---------2----------------", 
        "text": "Created in April before their Intel acquisition\n\nWe\u2019ve done a lot of research into the field of deep learning and artificial intelligence, mainly because at its core it\u2019s really just math. It\u2019s a trendline for some data that helps you predict something. Deep learning is very good at very specific tasks, like reading handwriting, or keeping a car in between two brightly colored highway lane markings, but it\u2019s not so good at more general things.\n\nMost of the media doesn\u2019t really understand that we\u2019re dealing with a scatter plot chart in Excel, where you can right click and select \u201cadd trend line\u201d, and that is the basis of what\u2019s happening with artificial intelligence.\n\nDeep learning will hit a limit, but in the meantime, it\u2019s the hottest thing on the street. Heck, even I\u2019ve profited from investing in NVIDIA early before their recent deep learning chips and software. I\u2019ll write more on that in the coming weeks, with another announcement following shortly after that.\n\nYesterday news broke that Intel made their move to catch up to NVIDIA by acquiring a young startup in the deep learning space called Nervana. The founder came from Qualcomm and had been doing some interesting things in the biological neural networking arena. The goal was low power usage without sacrificing massive computing capabilities, but Nervana\u2019s focus was a platform directed towards regular enterprise business.\n\nIt proved a smart move in the short term. Nervana went on to raise $24.4M before the acquisition for a reported $350M. That\u2019s a pretty good hourly rate and 10x return for a few years work.\n\nThe problem still remains that it\u2019s expensive and time-consuming to train deep learning models on millions of data points. That\u2019s with the innovations by Nervana. Just to get started with them it\u2019s going to cost you $10,000 per month.\n\nThat\u2019s why I believe eventually these large cloud services houses will start charging for power or data throughput instead of just \u201ccompute\u201d time which is a bit of a black box. More on that in the Read More section below.\n\nWe managed to get our hands on the deck they used for talking with prospective customers, which will give you some sense as to how they\u2019re marketing themselves. Much of this is likely to get subsumed by the Intel mothership, but I imagine that the platform will remain independent.\n\nMeanwhile I fully expect Intel to proceed quickly with integrating Nervana\u2019s chip innovations into their own superstar GPUs.", 
        "title": "Nervana\u2019s AI Product Overview Deck \u2013"
    }, 
    {
        "url": "https://medium.com/self-driving-cars/geoffrey-hinton-4eb03312b56c?source=tag_archive---------3----------------", 
        "text": "I\u2019ve been doing a little reading both about and from Geoffrey Hinton, who is fairly the godfather of neural networks.\n\nSeparately, I\u2019ve also been listening to Malcolm Gladwell\u2019s podcast, Revisionist History.\n\nOne of Gladwell\u2019s recent episodes focused on creativity, and the popular notion that creativity is a product of youth and genius.\n\nIt turns out that notion is true!\n\nBut it is also true that creativity can be a product of a lifetime of tinkering, or so Gladwell contends.\n\nAnd that\u2019s where I see the connection to Geoffrey Hinton.\n\nHinton was born in 1947, which made him 63 years-old in 2010, the year he and his graduate students developed and published AlexNet, the deep neural network that blew the machine learning field wide open.\n\nThis was the product of a lifetime of working on neural networks. Hinton was one of the original leaders in the field in the 1980s, and developed the practice of back-propagation, which is still a critical element of deep neural networks.\n\nBut neural networks faded into relative obscurity until AlexNet revolutionized the field with a GPU implementation in 2010.\n\nIt\u2019s nice for the rest of us to remember that our engineering life doesn\u2019t end at 30.", 
        "title": "Geoffrey Hinton \u2013 Self-Driving Cars \u2013"
    }, 
    {
        "url": "https://medium.com/age-of-awareness/do-the-wildest-thing-ever-3bfa4e109761?source=tag_archive---------4----------------", 
        "text": "We know that food, and our world, is changing. Instead of thousands of varieties of plants, our average diet consists of about 20. Nutritionists say this is not enough. We shop at warehouses for \u201cfresh\u201d produce where industrial packages of cellophane-wrapped peppers announce: \u201cFarmer\u2019s Market\u201d and \u201cJust Picked.\u201d\n\nWe buy the lies and comfort ourselves because the alternatives of canned and frozen and pre-chewed food are worse. Many of us are dying from obesity, and diabetes. Our food system is badly broken. But we feel powerless to change it. Whether it\u2019s organic, for food miles, fresh food any time of the year, special herbs, or food that contains certain minerals\u2026 people everywhere want to control their food destiny.\n\nJust imagine fresh vegetable and fruit varieties, long forgotten by grocery stores. There are lost plants wired to our brains to spark creativity, passion, to heal. We no longer eat them.\n\nflux imagined a future where every person can be part of the solution to the way we humans connect to each other and the planet that sustains us. This solution can be as creative and wild as the minds of the entire human race.\n\nWant to enter into the wild world of growing your own food? You are not alone. Millions of us feel the same way. And that\u2019s why we keep building, when everyone around us calls us crazy.\n\nOur solution, Eddy, let\u2019s you take food matters into our own hands. Access cutting-edge technologies until now available only to big industry. With Eddy, we\u2019re already starting to spark new memories and connections in homes, small businesses, restaurants and community centers.\n\nAdd Eddy to any hydroponic garden, and he helps you grow the world\u2019s most sustainable and fresh food.\n\nIt\u2019s a collective effort: With Eddy, every seedling you plant, and memory you bite into, builds a better future for all of us.\n\nJoin us in making life-worthy connections through food. Go wild with us.", 
        "title": "Do the wildest thing, ever \u2013 Age of Awareness \u2013"
    }
]