[
    {
        "url": "https://medium.com/smart-cars-a-podcast-about-autonomous-vehicles/navigating-around-the-sticky-question-of-crash-optimization-75c4d55ba0e9?source=tag_archive---------0----------------", 
        "text": "The future is closer than it may appear. The technology for fully autonomous vehicles (AVs) is getting better, and regulators may soon create a path for AVs to operate on the road without a human driver. As the future becomes reality, more questions will be raised as to how AVs will operate without humans in control. In particular, what happens when things go wrong and a crash occurs? How does an AV act differently from human drivers in a crash scenario?\n\nWe know that use of AVs will reduce the total number of accidents, and likely eliminate tens of thousands of deaths per year due to human error, but there will still be unavoidable crashes (because physics). So how will AVs decide which way to turn, how hard to brake, and who to endanger when they cannot avoid a crash? Will AVs be programmed with special algorithms for \u201ccrash optimization\u201d? Who will decide?\n\nThese questions have led to much debate around the ethics of self-driving cars and the need for an open discussion of how crash optimization algorithms will work. Professor Patrick Lin and others have written extensively and thoughtfully on the ethical issues raised by self-driving cars\u200a\u2014\u200aincluding analyses of complex dilemmas involving trolleys, baby strollers, narrow bridges and one lane tunnels. These dilemmas raise more questions than they answer, and some have brushed them aside as unlikely hypotheticals. Others have noted these are classic ethical dilemmas for a reason: there is no good answer.\n\nThus, whether these hypotheticals are likely to occur, or morally important, may not ultimately matter because even if we debate the issues endlessly among ourselves\u200a\u2014\u200agovernments, companies and AV owners are unlikely to reach a consensus as to who should live or die in unavoidable crashes. The answer will always depend\u200a\u2014\u200aam I in the car or the pedestrian? Is it my child on the sidewalk? We are human after all.\n\nSo how can we move forward to reap the benefits of AVs and also set expectations for public opinion around what will happen when AVs crash? How can we write algorithms for crash optimization if there is no good answer as to which way the AV should swerve\u200a\u2014\u200atoward the baby stroller or the old person, the SUV or the motorcycle, off the bridge or into the school bus? Or at least there is not a good answer we can agree on.\n\nOne path forward might be the use of machine learning to allow self-driving cars to develop crash optimization algorithms the same way they learn other aspects of driving. How would this work? Would it still require humans to pick and choose the training data, involving the same need for ethical judgments? Or could we feed in millions of miles of human driving and let it extrapolate from there? Would using machine learning for crash optimization be different from how AVs are using it to follow roads and navigate obstacles? How would we test it to see the end results?\n\nWe are willing to live with the status quo of how humans drive today. Would it be any worse than the status quo, or presumably better since the driver will not be distracted, impaired or drowsy? Many have noted that humans don\u2019t make explicit crash decisions, that they \u201creact\u201d and not \u201cdecide\u201d whether to brake or which way to swerve, but whether it\u2019s a decision or not, it seems there is learning there that might be an acceptable baseline.\n\nEthicists note that AVs can be more precise in executing explicit ethical decisions in ways that humans cannot, that they should do \u201cbetter\u201d than humans can in the same situation. In other words, why not set the bar higher than what can be learned from human driving? But that assumes that we could agree on what is \u201cbetter\u201d and program it in with the precision required. Until then, perhaps a path forward involves a more circuitous route.\n\nWho knows, maybe like Deep Mind\u2019s AlphaGo playing a game of Go against a human champion, the AVs might think of a move we hadn\u2019t considered, and maybe then it really will be a \u201cbetter\u201d outcome.", 
        "title": "Navigating Around The Question Of Crash Optimization"
    }, 
    {
        "url": "https://medium.com/the-baryon-group/intelligence-of-things-iot-2-0-e52d2596de8e?source=tag_archive---------2----------------", 
        "text": "As more and more devices are connected each day, our reliance on the cloud increases as well. The Internet of things ushered in several fascinating devices addressing millions of use cases. Most of these devices leverage their connection to the cloud in order to communicate amongst each other, relay critical information back to host systems, or retrieve content to serve requests.\n\nThe Amazon echo is a great example of a multi-purpose connected device. This little gadget will allow you to make any request via voice command, then attempts to satisfy the request through its connection to the Internet, specifically amazons servers. Amazon even provides a marketplace where developers can create web hooks to any endpoint, enabling users to make any request of any service available via simple voice commands.\n\nSiri is yet another example of a popular connected assistant. From retrieving our weather in the morning and setting alarms at night, Siri does a great job of handling small tasks that we otherwise would have to navigate our phone to accomplish.\n\nHowever, these two well-known voice-powered assistants have a fundamental drawback. They do not work when not connected to the Internet. Now, of course, if the request made by the user requires the Internet this is a dealbreaker. But what if we did not always need to retrieve information from the Internet? How can we make these devices less dependent on the cloud, but enable them to make decisions locally?\n\nThink of a future where Siri could use the forward facing camera on your phone to identify you through video, and simultaneously recognize who you are while you tell her to unlock your phone. This wouldn\u2019t be possible today because she requires a connection to Apple servers in order to run the machine learning models that help Siri process the natural language that you speak to her.\n\nI read an interesting article this week about a company called Movidius. They are working on a chip that allows you to run trained Deep Neural Nets at low-power on any machine using a dedicated VPU or visual processing unit.\n\nFor those of you familiar with Google\u2019s Project Tango tablets, you\u2019ll recognize Movidius since they\u2019re the ones that provide the spatial recognition chip.\n\nQualcomm has also announced a new deep learning SDK for its machine learning platform \u201cZeroth\u201d. Here is an excerpt from Qualcomm:\n\nWith these two leading the way to run trained neural nets locally, our connected devices will no longer have to resort to making calls to the cloud in order to make intelligent decisions. Autonomous drones and intelligent dash cams are only the beginning.\n\nI recently binge watched the cinematic cutscenes for the Halo game series on YouTube. After reading about the developments in this space, I couldn\u2019t help but draw parallels to how master chief plugs Cortana into any device or into the back of his helmet, having her transfer with the chip. I don\u2019t imagine this is too far off from our future. The evolution of this technology coupled with augmented reality should make for very interesting times ahead.", 
        "title": "Intelligence of Things (IoT 2.0) \u2013 The Baryon Group \u2013"
    }
]