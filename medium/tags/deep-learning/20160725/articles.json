[
    {
        "url": "https://medium.com/learning-machine-learning/getting-tensorflow-theano-and-keras-on-windows-70c18f2c533b?source=tag_archive---------0----------------", 
        "text": "Updated\u00a0: Since writing this tensorflow for windows came out and my workflow completely changed, so I recommend just using keras on top of Tensorflow for deep learning. I\u2019m also updating the relevant parts with that information in mind. Also, I\u2019m using Python 3.5 currently because Tensorflow is not available for Windows in any other version. Either way, if you need 2.7, just get an instance from AWS, they are pretty cheap or switch your OS ^___^\n\nFrom the official documentation of Theano it\u2019s mentioned that Anaconda installs all dependencies of Theano.\n\nFrom the docs we see\u00a0:\n\nFor the latest stable release 0.7 (as of March 2015) run instead:\n\nEither way, a folder Theano will be created with the library downloaded to it.\n\nNote\u00a0: There\u2019s some test scripts in the documentation too.\n\nNote\u00a0: You must have Python 3.5 for it. I\u2019m using the Anaconda distribution from Continuum in a separate environment.\n\nKeras currently is the official API for tensorflow. Keras can be configured to run with Tensorflow or Theano on the backend. Just follow the instructions from here\u00a0: \u201cSwitching from Tensorflow to Theano\u201d\u00a0. Installation is basically a one-liner.\n\nThe end. This doc will probably not be actively maintained unless needed.", 
        "title": "Getting Tensorflow, Theano and Keras on Windows \u2013 Learning Machine Learning \u2013"
    }, 
    {
        "url": "https://medium.com/all-of-us-are-belong-to-machines/gentlest-introduction-to-tensorflow-part-2-ed2a0a7a624f?source=tag_archive---------1----------------", 
        "text": "Summary: We show in illustrations how the machine learning \u2018training\u2019 process happens in Tensorflow, and tie them back to the Tensorflow code. This paves the way for discussing \u2018training\u2019 variations, namely stochastic/mini-batch/batch, and adaptive learning rate gradient descent. The \u2018training\u2019 variation code snippets presented serve to reinforce the understanding of the role of Tensorflow placeholders.\n\nThis is part of a series:\n\nIn the previous article, we used Tensorflow (TF) to build and learn a linear regression model with a single feature so that given a feature value (house size/sqm), we can predict the outcome (house price/$).\n\nHere is the review with illustration below:\n\nIn machine learning (ML) literature, we come across the term \u2018training\u2019 very often, let us literally look at what that means in TF.\n\nThe goal in linear regression is to find W, b, such that given any feature value (x), we can find the prediction (y) by substituting W, x, b values into the model.\n\nHowever to find W, b that can give accurate predictions, we need to \u2018train\u2019 the model using available data (the multiple pairs of actual feature (x), and actual outcome (y_), note the underscore).\n\nTo find the best W, b values, we can initially start with any W, b values. We also need to define a cost function, which is a measure of the difference between the prediction (y) for given a feature value (x), and the actual outcome (y_) for that same feature value (x). For simplicity, we use least minimum squared error (MSE) as our cost function.\n\nBy minimizing the cost function, we can arrive at good W, b values.\n\nOur code to do training is actually very simple and it is labelled with [A, B, C, D], which we will refer to later on. The full source is on Github.\n\nOur linear model and cost function equations [A] can be represented as TF graph as shown:\n\nNext, we select a datapoint (x, y_) [C], and feed [D] it into the TF Graph to get the prediction (y) as well as the cost.\n\nTo get better W, b, we perform gradient descent using TF\u2019s tf.train.GradientDescentOptimizer [B] to reduce the cost. In non-technical terms: given the current cost, and based on the graph of how cost varies with other variables (namely W, b), the optimizer will perform small tweaks (increments/decrements) to W, b so that our prediction becomes better for that single datapoint.\n\nThe final step in the training cycle is to update the W, b after tweaking them. Note that \u2018cycle\u2019 is also referred to as \u2018epoch\u2019 in ML literature.\n\nIn the next training epoch, repeat the steps, but use a different datapoint!\n\nUsing a variety of datapoints generalizes our model, i.e., it learns W, b values that can be used to predict any feature value. Note that:\n\nYou can train the model a fixed number of epochs or until it reaches a cost threshold that is satisfactory.\n\nIn the training above, we feed a single datapoint at each epoch. This is known as stochastic gradient descent. We can feed a bunch of datapoints at each epoch, which is known as mini-batch gradient descent, or even feed all the datapoints at each epoch, known as batch gradient descent. See the graphical comparison below and note the 2 differences between the 3 diagrams:\n\nThe number of datapoints used at each epoch has 2 implications. With more datapoints:\n\nThe pros and cons of doing stochastic, mini-batch, batch gradient descent can be summarized in the diagram below:\n\nTo switch between stochastic/mini-batch/batch gradient descent, we just need to prepare the datapoints into different batch sizes before feeding them into the training step [D], i.e., use the snippet below for[C]:\n\nLearn rate is how big an increment/decrement we want gradient descent to tweak W, b, once it decides whether to increment/decrement them. With a small learn rate, we will proceed slowly but surely towards minimal cost, but with a larger learn rate, we can reach the minimal cost faster, but at the risk of \u2018overshooting\u2019, and never finding it.\n\nTo overcome this, many ML practitioners use a large learn rate initially (with the assumption that initial cost is far away from minimum), and then decrease the learn rate gradually after each epoch.\n\nTF provides 2 ways to do so as wonderfully explained in this StackOverflow thread, but here is the summary.\n\nTF comes with various gradient descent optimizer, which supports learn rate variation, such as tf.train.AdagradientOptimizer, and tf.train.AdamOptimizer.\n\nAs you have learned previously, if we declare a tf.placeholder, in this case for learn rate, and use it within the tf.train.GradientDescentOptimizer, we can feed a different value to it at each training epoch, much like how we feed different datapoints to x, y_, which are also tf.placeholders, at each epoch.\n\nWe illustrated what machine learning \u2018training\u2019 is, and how to perform it using Tensorflow with just model & cost definitions, and looping through the training step, which feeds datapoints into the gradient descent optimizer. We also discussed the common variations in training, namely changing the size of datapoints the model uses for learning at each epoch, and varying the learn rate of gradient descent optimizer.", 
        "title": "Gentlest Introduction to Tensorflow #2 \u2013 All of Us are Belong to Machines \u2013"
    }, 
    {
        "url": "https://gab41.lab41.org/tensorflow-3-ways-46a46bef895d?source=tag_archive---------2----------------", 
        "text": "I recently started my first real project in Tensorflow. The larger effort, Attalos, was aimed at exploring vector spaces containing multiple types (modalities) of data. This post is about work that I did looking into how to project image features into a word vector space. The goal of the project is to be able to do image search more effectively.\n\nThis article isn\u2019t about getting started with Tensorflow and it\u2019s not directly about the projection that I was attempting to do. Instead, this article is a walk down the path I took in implementing a regression with neural networks in Tensorflow. Specifically, it\u2019s about finding some of the higher-level abstractions I loved in Keras in tensorflow.contrib (and yes, I know Keras can run on Tensorflow).\n\nI mentioned above that I was trying to project image features into a word vector space. More specifically I had extracted 2048 dimensional vectors of image features from an Inception v3 model. The task I was completing was to regress those features into a 300 dimensional word vector space based on GloVe.\n\nI ended up doing the same regression three different ways (at different abstraction levels):\n\nThe first approach had its origins in Theano (another deep learning library Lab41 has previously used). In Theano (and Tensorflow) the user is responsible for everything. You define a graph of computation that is merely a thin layer on top of a matrix math library.\n\nIn order to represent our regression in Tensorflow (or Theano) it\u2019s best to first mathematically represent our calculation:\n\nFor the loss function (what we are trying to optimize) I used mean squared error:\n\nIn raw Tensorflow the graph setup looks like the code snippet below. We start by defining our variables (input image features, target word vectors, and the weights). We then create our computation graph (in this case a two layer perceptron). Finally we setup our optimization by defining a loss function and then specifying an optimizer for that loss. All together that creates:\n\nThe above approach worked but I was left thinking that I surely can\u2019t be the only person who was interested in a dense, fully-connected neural network and it seemed silly (and error prone) to start from scratch. (Maybe I was just bitter because I forgot to initialize my network properly and learned that a vector of all zeros is actually a local minimum for my problem).\n\nAfter a little reading I learned about tensorflow.contrib. This is a place where new ideas can get tested before they get integrated into the core library. Try two borrows from the \u201clayers\u201d portion of contrib, which gives us a Keras like abstraction for layers.\n\nOur network from above now looks like this:\n\nAs a non-deep learning expert I can look at this and reason about what\u2019s happening (vs. the code from the 1st approach where I find myself counting sigmoids to figure out the depth of the network).\n\nThe above approach gives you almost all of the flexibility from the 1st approach while avoiding some of the pitfalls and ending up with something a little easier to approach. Try 3 borrows from another part of the contrib section, \u201clearn\u201d which is based on the SkFlow work.\n\nSpecifically I can define the architecture for a neural network based regression:\n\nIf you\u2019ve used scikit-learn before this interface looks familiar. You define your model, call a fit function, and then a predict function after that. Having a scikit-learn like interface to deep learning primitives makes deep learning much more accessible but at the expense of flexibility. This also means that it is easy to replace calls to scikit-learn with calls to \u201clearn\u201d functions.\n\nGoing through this process there were a few things that struck me:\n\nThe three approaches represent different abstraction levels and which is best really depends on your interest and what you are trying to do. In general the \u201clayers\u201d library provides me with the abstraction level that most matches the way I think about neural networks. It gives me the flexibility to connect things way I want without too much boilerplate code. The \u201clearn\u201d library is great if what you\u2019re interested in is DNN classification/regression or if you were already using scikit-learn and wanted to maintain that interface.", 
        "title": "Tensorflow 3 Ways \u2013"
    }, 
    {
        "url": "https://medium.com/@emilmikhailov/on-july-21st-we-made-history-d656bbda6273?source=tag_archive---------3----------------", 
        "text": "On July 21st, We Made History. For the first time (ever?), big and well-respected tech company has made the product launch at our AI Meetup Series. NVIDIA\u2019s CEO Jen-Hsun Huang gave us the courtesy and has revealed the brand New NVIDIA TITAN X: The Ultimate\n\nOne of the things we, as a startup, put emphasis on is building strong AI community in San Francisco. Our mission is to move forward the research and technology advancement, share knowledge, learn and implement latest technologies. In order to do that, we do a lot of activities, in particular, we bring tech leaders across the industry to participate in our AI Meetup Series.\n\nLast Thursday, we had the privilege to interview one the founding fathers of modern AI research Andrew Ng.\n\nThe whole event was pretty challenging from the organizational standpoint: more than 1000 people total expressed the interest to participate, we had to double the capacity and ended up hosting the event at Stanford Faculty Club. Luckily, we had support from our partners Baidu Research and NVIDIA, that took a lot of questions out of the table\n\nOne part that was pretty challenging personally for me was standing on the stage in front of 500+ people and speaking. The moment I took the mic, every phrase I\u2019ve prepared was immediately forgotten. The only thing that was in my mind at that moment was Eminem\u2019s lyrics from Lose Yourself =)\n\nThe Eminem\u2019s lyrics made me laugh inside, and the whole thing just disappeared. Time to start the event\n\nAndrew came up on the stage and we started our Q&A. Having him on the stage and being able to ask about Deep Learning, trends, and the latest research, his views on the AI applications and how AI will affect the future of humanity was truly a thrilling experience! In particular, his views on the alternative version of basic income is super exciting and something we haven\u2019t heard before. He didn\u2019t manage to elaborate on this topic a lot due to time restrictions, but I hope we can expect something to be released by Andrew pretty soon.\n\nAfter a series of questions, we had to wrap up and move to the next item on the agenda and, at that point, it was time to go to questions from the audience. Then something unexpected has happened: I\u2019ve seen Jen-Hsun at the end of the room with his hand up. It was a no-brainer to pick an attendee to ask the question.\n\nSo we did lose control of the podium, but it was totally worth it! Jen-Hsun started to ask Andrew questions on the technology, capabilities of deep learning, how to establish SAT test for deep learning and much more. One of the funniest moments was when Jen-Hsun told Andrew:\n\nIt was back and forth between two friends who know each other for a long time, until the moment when Jen-Hsun asked Andrew:\n\nAnd then the historic moment has happened:\n\nThis was one of the craziest product launches ever in the history of technology.\n\nAfter that, we continued with the great talks from researchers from Baidu Bryan Catanzaro on HPC and Deep Learning and Eric Battenberg on Baidu\u2019s Deep Speech 2.\n\nHuge kudos to Baidu and NVIDIA teams for making this happen!\n\nHere is the full record of the event:", 
        "title": "On July 21st, We Made History. \u2013 Emil Mikhailov \u2013"
    }, 
    {
        "url": "https://medium.com/@piotrekk/your-posts-are-really-informative-and-i-would-definitely-recommend-them-to-everyone-strating-with-e5d53c15ef7e?source=tag_archive---------4----------------", 
        "text": "Your posts are really informative and I would definitely recommend them to everyone strating with machine learning. What I miss is more practice from \u201cmathematical side\u201d. After reading all parts, I know how everything works \u201cin theory\u201d and I can use \u201csome magic\u201d libraries that do all stuff for me, but I want to know how is it working \u201cunder the mask\u201d, writing real code. I understand that things you show now are too complex to explain in one article, but maybe you should dedicate one part for making practical lesson that uses less complex and less \u201cspectacular\u201d algorythms, but explains the math?", 
        "title": "Your posts are really informative and I would definitely recommend them to everyone strating with\u2026"
    }, 
    {
        "url": "https://medium.com/humanandmachine/teach-me-go-alphago-sensei-baf3e8efd62d?source=tag_archive---------5----------------", 
        "text": "Recently DeepMind made headlines with their artificial intelligent system AlphaGo on defeating Lee Sedol one of the world\u2019s best Go player. This victory was second in line for AlphaGo against a top notch human player, the previous one was against Fan Hui, although not high a prolific player as Lee Sedol but still among the best.\n\nIt is not for the first time that a machine has outplayed humans. They have beaten us at scrabble, crosswords, chess (DeepBlue) and most recently at Jeopardy a rather complicated game which requires amazing comprehension ( a difficult NLP problem) and a large amount of knowledge (which is although not hard in this era of Wikipedia) to decipher the clue and frame a response. Although it was bound to happen in that a machine would be able to outplay and defeat human in a game as complex as Go, however it was not anticipated to happen in at least in this decade.\n\nWhat interests me in this particular victory of AlphaGo is the spark of genius it showed in couple of moves it played, particularly Move 37. It was a move that a human would have never played. Go is a pretty old game invented some 5500 years back in China and has been played by lots of people, but still no one has landed on that particular move or at least it has not been recorded. Its amazing that a machine would do so. The machine not only surprised everyone with that move but most likely inspired Lee Sedol to a daring move 78 in the next game. The machine landed on this particular move by its training on millions of moves it went through while training.\n\nNow imagine what if you have a sensei who can teach you these kind of moves as you practice against him/her. A sensei that can analyse and direct you to the right & the wrong moves as you practice against him/her, a teacher who has literally played all recorded games move by move and have played countless other against himself/herself and can analyse and introspect and share that information with you, thus enhancing your performance. This kind of sensei could be made for numerous other games and perhaps also to teach skills like writing, programming, etc.\n\nWouldn\u2019t such a sensei be worth learning from? And maybe just maybe help level the playing field to get talented but underprivileged people to up their skills & open more avenues to them.", 
        "title": "Teach me Go, AlphaGo Sensei! \u2013 humanandmachine \u2013"
    }, 
    {
        "url": "https://medium.com/deepgram/cheap-automatic-speech-transcription-93fce6b8611a?source=tag_archive---------6----------------", 
        "text": "We\u2019ll match anybody\u2019s price. We don\u2019t care. We\u2019ll do it.\n\nWe\u2019ve tested with millions of minutes. It works, yo.\n\nYou are losing money every time you transcribe without Deepgram.\n\nOur transcription goes head to head with any machine transcription provider.\n\nGoogle has pretty good accuracy and their Speech API access has two tiers\u200a\u2014\u200aFree and Beta. The Free one is limited to only 50 API calls per day, the audio files have to be short (tens of seconds), and only accepts flac file type\u200a\u2014\u200anot very useful. The Beta version is limited in number of users and runs on Google Cloud Platform. Overall Google\u2019s Speech API is very restricted.\n\nDeepgram can do any length of audio file and any file type. Got something that\u2019s hours long? No problem. Got some weirdo Microsoft WMA file? We\u2019ll take care of you.\n\nWhatever you can do with Google you can do with Deepgram, just faster, cheaper and easier.\n\nDepends on how crappy your audio is, but we\u2019re competitive with the leading speech-to-text APIs (most times we\u2019re better).\n\nWe have two tiers for transcription\u200a\u2014\u200asuper cheap and super fast.\n\nFor super fast, we\u2019ll get it back to you in 2x the audio length or less. For the super cheap plan, your transcription will be done in a couple hours.\n\nPlan Cost Speed Super Cheap $0.40 per hour completed in a few hours Super Fast $0.99 per hour completed in under 2x audio length\n\nAny audio file. Seriously, we\u2019ll make it work with anything but if you upload a text file, we\u2019ll ban your API key (just kidding\u200a\u2014\u200aor are we?). Seriously though, don\u2019t upload text.\n\nLots of hamsters on lots of wheels. We\u2019re hiring a vet (email us at vetneededforhamsters@deepgram.com)!\n\nTest out the Deepgram API then write a tutorial blog post\u200a\u2014\u200awe\u2019ll give you $200 in free credit. We\u2019re not bloggers, we\u2019re physicists, so we suck at this. No, really, we need your help.", 
        "title": "Cheap Automatic Speech Transcription \u2013 Deepgram \u2013"
    }
]