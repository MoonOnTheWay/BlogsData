[
    {
        "url": "https://medium.com/@erikhallstrm/using-the-tensorflow-lstm-api-3-7-5f2b97ca6b73?source=tag_archive---------0----------------", 
        "text": "In the previous post we modified our to code to use the TensorFlow native RNN API. Now we will go about to build a modification of a RNN that called a \u201cRecurrent Neural Network with Long short-term memory\u201d or RNN-LSTM. This architecture was pioneered by J\u00fcrgen Schmidhuber among others. One problem with the RNN when using long time-dependencies ( is large) is the \u201cvanishing gradient problem\u201d. One way to counter this is using a state that is \u201cprotected\u201d and \u201cselective\u201d. The RNN-LSTM remembers, forgets and chooses what to pass on and output depending on the current state and input.\n\nSince this primarily is a practical tutorial I won\u2019t go into more detail about the theory, I recommend reading this article again, continue with the \u201cModern RNN architectures\u201d. After you have done that read and look at the figures on this page. Notice that the last mentioned resource are using vector concatenation in their calculations.\n\nIn the previous article we didn\u2019t have to allocate the internal weight matrix and bias, that was done by TensorFlow automatically \u201cunder the hood\u201d. A LSTM RNN has many more \u201cmoving parts\u201d, but by using the native API it will also be very simple.\n\nA LSTM have a \u201ccell state\u201d and a \u201chidden state\u201d, to account for this you need to remove on line 79 in the previous script and replace it with this:\n\nTensorFlow uses a data structure called internally for its LSTM:s, where the first element in the tuple is the cell state, and the second is the hidden state. So you need to change line 28 where the is placeholders are declared to these lines:\n\nChanging the forward pass is now straight forward, you just change the function call to create a LSTM and supply the initial state-tuple on line 38\u201339.\n\nThe will be a list of hidden states as tensors, and will be a LSTMStateTuple which shows both the hidden- and the cell state on the last time-step as shown below:\n\nSo the returns the cell- and hidden state in a tuple. They should be separated after calculation and supplied to the placeholders in the run-function on line 90.\n\nThis is the full code for creating a RNN with Long short-term memory.\n\nIn the next article we will create a multi-layered or \u201cdeep\u201d recurrent neural network, also with long short-term memory.", 
        "title": "Using the LSTM API in TensorFlow (3/7) \u2013 Erik Hallstr\u00f6m \u2013"
    }, 
    {
        "url": "https://medium.com/intuitionmachine/why-its-difficult-to-begin-using-deep-learning-in-investment-research-ea89e7a5130f?source=tag_archive---------1----------------", 
        "text": "Much ink has been used on the importance of AI, and more specifically, Deep Learning in the lives of our businesses. That it is the new electricity.\n\nThe business of Research is one of the most at-risk to dis-intermediation by Deep Learning (for the purposes of this write-up, I\u2019ll use AI and Deep Learning interchangeably, even though they are not. It\u2019s just that AI is more widely recognized by the populace).\n\nThe domain of research is much more than the be-speckled grad student toiling away beside glass beakers in a science lab.\n\nFor example, one off the most competitive fields to enter is being an equity research analyst. Equity research analysts on Wall Street can earn as much as $115k+ their first year after college. A sexy job and salary. There is much incentive to becoming a research analyst.\n\nThis $115k (going up to the millions, if wall street bonuses are included) is also a cost to the bank. The bank has an incentive to lower costs, say by hiring one less analyst but augmenting the remaining ones with research pre-processed with AI.\n\nIn fact, this is what both the equity research and the investment banking departments are focusing on at this moment.\n\nNow, \u201cresearch\u2019\u201d can be broadly defined as ingesting a lot of data, indexing/arranging the data into a coherent pile, and ultimately triggering some sort of recommendation or conclusion from the research.\n\nThis type of research is certainly done by any investment organization (and as we have seen, spending a lot of money on the process). Additionally, within the capital allocation process, the types of data being ingested and researched are varied, as are the industry \u2018verticals:\u2019 oil/gas, shipping, retail, tech, you name it.\n\nAll along the investment process\u200a\u2014\u200afrom deal origination (\u2018I\u2019d like to help you raise money, but I need to study your business\u2019) to bankruptcy (unearthing value in bankruptcy document papers\u200a\u2014\u200a\u2018vulture investing\u2019 ) and beyond, data and content are manipulated day in and day out.\n\nAll corporations, large and small, do all sorts of research: a Japanese telecom company needing research into corporate venture capital targets in the US, for example. Or a Brazilian beverage company seeking more investment opportunities in Europe.\n\nThere\u2019s clearly a need to get ahead of the growth of data sources and the speed at which these data are growing. If the decision is made to get started on AI for research, the next obvious question is, how?\n\nWhile there has been a flurry of articles from academia about the latest breakthroughs, and some surfacing about other companies beginning to implement their Deep Learning projects, there are very few examples of how to actually get started on a Deep Learning project for research.\n\nThere are a few reasons for this.\n\n2. Where do I find the AI experts? You might have heard there is a 2 million shortage of qualified computer programmers. There is an even bigger demand for data scientists. We would suspect there is a more acute demand for AI/Deep Learning professionals. Cade Metz of Wired writes:\n\n3. Eleven other thoughts. We published eleven other thoughts on why there might be a cognitive gap between the worlds of business and AI, in our piece \u201cEleven Biases why Experts are Missing the Train on Deep Learning\u201d.\n\nDo you know what? You should get started anyway.\n\nGet started because, like electricity was to businesses in a previous era, AI will change the business landscape for this era.\n\nThere are relatively risk-free and non-destructive ways to get started in adding Deep Learning to your research initiatives.\n\nMeasure (many times) cut once. The old adage still works in the digital era.\n\nBefore you back up the truck at Home Depot and start buying planks of wood, windows and light fixtures, you spend the time and effort to first create your project on paper.\n\nIn the building example, you get an architect to design what your building would look like. In the world of AI entry points, this is working to define a Technical Roadmap to building your AI project.\n\nI call it relatively risk-free and non-destructive because no permanent, large-expenses need to be made. No permanent hires, no expensive hardware and software teams. In the era of the Gig Economy, a Technical Roadmap is the perfect entry point to:\n\na) get you working on the thought processes needed to roll-out a Research Proof-of-Concept\n\nb) make you aware of which of your research workflows can be augmented by AI\n\nc) give you options to pinpoint cost savings afforded by AI-enhanced Research\n\nd) get you to put down your AI books and journals and start working on doing AI\n\nWe\u2019ll work on fleshing out your options for getting started on your path to implementing a Deep Learning project, from Roadmap to Proof-of-Concept to Pilot Project and finally Production Environment. All in a relatively risk-free, and non-destructive way.\n\nFor more information on Research Machine visit: http://www.intuitionmachine.com/research-machine/", 
        "title": "Deep Learning Playbook for Investment Research \u2013 Intuition Machine \u2013"
    }, 
    {
        "url": "https://medium.com/@rajendramishra18/5-tactics-to-teach-a-novice-about-machine-learning-6eb813ac795b?source=tag_archive---------2----------------", 
        "text": "How to teach a novice the most complex thing in the world \u201cMachine Learning\u201d. If you too fear from Machine Learning, do not worry. Complexity is created by the people who have invented the simplicity of that new field so as to increase the barrier to entry in their field. The people or more specifically the organizations who have identified this idea are competing with the pioneers of the field.\n\nSo, I am here to answer the most basic but the toughest question of Mankind. How to teach a novice about Machine Learning. Well I was in teaching for almost two years. I have handled all these scenarios when I was active in the field of tutoring. This post may be slow paced as well as pretty basic as my target audience is the novice. I am going to use all my tactics and experience of teaching in this post so as to make the most complex thing on the earth, the most simple one.\n\nLet\u2019s flush each and everything that we know. Start fresh. Develop Insights.\n\nUse examples. The best possible example to fit each and every case that you want to present.\n\n\u201cTechnical jargons\u201d. Avoid them initially. These are the terms that I mentioned as complexity created by the inventors.\u00a0:D\n\nCreate an environment where everyone including the tutor are on the same page. No one knows anything.\n\nNow, while driving your lecture, make your audience think. Let them visualize. Help them in developing perception.\n\nMentioned above are the tactics that I have used successfully to engage with my students, create a friendly environment and make them understand things better. If you understood the tactics that I mentioned above, you will realize them in the post that will follow.\n\nOK! So Let\u2019s start. Let\u2019s imagine that their is a kid who doesn\u2019t have any idea about fruits. But he is aware of a farm where there are many apple and orange trees. You are a lazy lad so you are asking that kid to go to the farm and bring apples. The kid not being aware of how an apple may look like, what are the possibilities that strike in your mind so that you get the apple from the farm?\n\nOk let\u2019s point out the possibilities:\n\n1) Instead of that kid you go to the farm and bring the apples.\n\n2) Give the boy a checklist of features so that he can identify what an apple may look like and bring the apple.\n\nScenario 1\u00a0: Not possible! I told, you are lazy right!\n\nScenario 2\u00a0: Yes! Can be done. Feasible as well.\n\nSo let\u2019s consider scenario 2. You tell the kid that there are two kinds of fruits in the farm, Apple and Orange. I am giving you a checklist in which I have mentioned some features that a fruit may have. The checklist is:\n\nAs shown in the table above you handed over the checklist to the kid and asked him to go to the farm and bring apple. Now what do you think the kid will do? He will go to the farm. He will verify the details of the fruits in the farm with the checklist that you provided. He will try to find out the best possible fruit whose attributes match the description given in the checklist.\n\nOK now if you have followed the example correctly just list the challenges that the kid may face?\n\nOK here are few:\n\n1) The description of color is Dark Red in case of apple. It is a general color. But it may happen that the apple in the farm may not be Dark in complexion. And even there may be cases where the apple has almost a similar color as orange, but rare.\n\n2) Both grow on tree! What! a lot of confusion right.\n\n3) Seeds\u200a\u2014\u200aOh that\u2019s great. Can identify pretty well. But what if the fruits in the farm do not have seeds, again rare case.\n\n5) Both the fruits may be in same shape and size\n\n6) And even the identification of all these attributes depend on the kid\u2019s understanding\n\nOh guess what? We have covered the machine learning and the challenges in Machine Learning by this example. Machine Learning model is like that kid. We provide the model with the kind of data that we see in the table above. Finally the model tries to find the best possible match based on the attributes that it identified in a fruit and the checklist that you have provided to it.\n\nSo let\u2019s relate this stuff to Machine Learning. The kid relates to the specific model in Machine Learning. The Attribute that we have defined in the table above to create the checklist is represented as a vector generally referred as Attribute vector or Feature vector. There may be any number of attributes that we may need for a specific task. So say if we have some \u2018d\u2019 number of features or attributes to represent our knowledge about fruit as in the example above then we are referring a vector in d-dimensional space. And this will be the case with all the fruits that we may want to identify with the likes of apple or orange or grape or pear. Each one of them will be represented as a vector in d-dimensional space. Now, the space that these vectors belong to is called Feature space.\n\nOK so enough technicality. Let me ask you a question. Let us consider that your are lazy enough to provide the checklist of attributes as well. Now you do not want to provide the kid, the checklist as well. How are you going to handle the scene?\n\nOk let me give you a possible scenario. You have some sample fruits in your home. Instead of preparing the checklist, handover the sample fruits to the kid and tell him to identify the attributes. So leave the kid for five to six hours with sample fruits. Now once the kid has spent enough time with the samples, tell him out of those samples, which all are apples and which are oranges. Now the kid will have some understanding of the attributes that he shall find as to identify apple and orange.\n\nCan you identify the possible challenges the kid may face?\n\n1) Whether the kid brings apples or oranges totally depends on his understanding, which he developed from the sample fruits that were given to him\n\n2) The possibility is there that the sample fruits that were given to him were not the best representatives of General Fruit class\n\n3) The kid may have some biases towards some of the fruits which may hamper his choice of attributes selection\n\nOh wait! You know what we have covered two important methods of Machine Learning. Supervised machine learning and Unsupervised machine learning. Let\u2019s relate to the example. Providing the kid with only sample fruits for identifying the attributes or features of Fruit class is actually unsupervised machine learning. You are just provided with the sample data, and from that data you need to identify the generalized attributes. So Unsupervised Learning is mainly used to learn Feature representation. Unsupervised Learning has many applications in Clustering, Topic Modeling as well. The next phase where after five to six hours you tell the kid that what samples in the sample fruits given to him are actually apples and oranges. This is the case of Supervised Machine Learning. So in this case we used a Hybrid approach. The kid learned the features on his own (Unsupervised) and then we provided him with respective class labels i.e. apples or oranges (Supervised).\n\nGenerally what people do once they have been given the feature vectors as specified in section 1 or the attributes that their model has identified using Unsupervised learning as described in section 2. So if I say the feature vectors that we have are points in d-dimensional space, do you agree with that? Are you able to visualize that? Ok let me help you in identifying that.\n\nLet\u2019s say for some task we have just 1 feature. In that case we will have 1 dimensional vector. The feature space in this case will be 1-Dimensional space like number line. So 1 dimensional feature vector in this feature space is a 1-dimensional point. In other words the position of the point in the feature space will be relative to just one axes. Similarly in 2-dimensional feature space the 2-dimensional vector will be a point whose position in the plane will depend on two axes X and Y. This way in d-dimensional space, d-dimensional feature vector is a point whose position in the plane depends on d axes.\n\nNow I will take the example of Classification task in Machine Learning. In Classification, people usually try to fit a line or curve in the d-dimensional space so that various data-points in that space can be separated in their respective classes. If you want a linear classification i.e. want discrete value either 0 or 1, apply some linear classifiers. If you want continuous value i.e. some value between 0 and 1 and based on some threshold you want to decide the class, use some non-linear classifiers like sigmoid or softmax.\n\nDisclaimer\u00a0: This is a personal web blog. The opinions expressed here represent my own and not those of my employer.", 
        "title": "5 Tactics to teach a novice about Machine Learning!"
    }, 
    {
        "url": "https://blog.vilynx.com/the-technology-behind-a-vilynx-tag-a7a8753aea1d?source=tag_archive---------3----------------", 
        "text": "Tagging a video based on its contents is easy for the human brain, but can be very time consuming. So, what happens when the stream of new videos becomes so large that even an army of people couldn\u2019t tag them all? More than 75% of internet traffic is video and more than 220,000 hours of video is uploaded to YouTube every day , and is only going up. There is no feasible way to tag all of this content by hand. This is where machine learning comes in.\n\nApplying Machine Learning to feature recognition and video tagging is not that easy. A video usually has 30 frames per second, which means there are a lot of images to process if you want to understand a video. And there are so many videos being added every day. Performing video recognition at large scale requires: a) distributed computing capabilities to pre-process and extract the relevant features of the videos and b) a vast training set capable to understand different concepts, objects, people, actions and the relationships among them.\n\nIn this context, the training set is key. You need a large vocabulary (tags for different words, actions and concepts) and many occurrences of these tags among your videos to allow your neural networks to learn. In order to recognize every type of video, you need to train the computer with a massive number of videos that are very diverse, and well-tagged. In addition, it is important to have a training set that grows and evolves every day so you can be ready to recognize people, objects and actions that are new to the internet.\n\nGetting these training sets is an issue for many people. With very few open datasets available, currently the best offering of a tagged video dataset is YouTube-8M. It offers, as the name suggests, 8 million videos. This means a total of 500k hours of footage and 4800 possible tags. The problem with this dataset is the low number of tags per video, with only 1.8. There is a sharp limit to how much information you can get from one tag. In addition, it is now a static dataset, so it will not grow and add new things, making it inherently out of date.\n\nHere at Vilynx we decided that we wanted to build an evolving dataset. A video dataset able to grow with time, to understand better the concepts and relationships between words, to \u201cgrok\u201d what people are talking about, and to relate it to current videos. So we created a weakly-supervised architecture capable of extracting knowledge from the web, social networks and people\u2019s interactions, and relate it to current and older videos. A deep-learning stack that is awake day-and-night crawling videos and contextual information, and getting smarter every day. This is how it works:\n\nWhile YouTube-8M is limited to 4800 tags, and the next best one, Sports-1M is limited to 487 tags, Vilynx10M\u2019s limit is the dictionary. Currently we are at 40,000 tags and growing, without any duplicates. This is the largest vocabulary of any video dataset to date.\n\nWith this technology, we are building our own database of videos to surpass the likes of YouTube-8M and Sports-1M. We use it to train our computers to recognize videos better than anything, to provide specific keywords for our customer\u2019s videos and to leverage new products on top of them. We call it Vilynx10M. This is how it stacks up to the competitors:", 
        "title": "The Technology Behind a Tag \u2013"
    }, 
    {
        "url": "https://medium.com/@VentureScanner/artificial-intelligence-category-innovation-quadrant-q4-2c10a531ce7a?source=tag_archive---------4----------------", 
        "text": "Our Innovation Quadrant provides a snapshot of the average funding and average age for the different Artificial Intelligence categories and how they compare with one another.\n\n\u00a0\n\n\u00a0\u2022 Heavyweights: Categories with high average funding and high average age. These categories are comprised of companies that have reached maturity with significant financing.\n\n\u2022 Established: Categories with low average funding and high average age. These categories are comprised of companies that have reached maturity with less financing.\n\n\u2022 Disruptors: Categories with high average funding and low average age. These categories are comprised of companies that are less mature with significant financing.\n\n\u2022 Pioneers: Categories with low average funding and low average age. These categories are comprised of companies that are less mature with earlier stages of financing.\n\nThe definitions of the Artificial Intelligence categories represented in the above Innovation Quadrant are as follows:\n\nDeep Learning/Machine Learning (Platforms): Companies that build computer algorithms that operate based on their learnings from existing data. Examples include predictive data models and software platforms that analyze behavioral data.\n\n\u00a0\n\nDeep Learning/Machine Learning (Applications): Companies that utilize computer algorithms that operate based on existing data in vertically specific use cases. Examples include using machine learning technology to detect banking fraud or to identify the top retail leads.\n\nNatural Language Processing: Companies that build algorithms that process human language input and convert it into understandable representations. Examples include automated narrative generation and mining text into data.\n\nSpeech Recognition: Companies that process sound clips of human speech, identify the exact words, and derive meaning from them. Examples include software that detects voice commands and translates them into actionable data.\n\nComputer Vision/Image Recognition (Platforms): Companies that build technology that process and analyze images to derive information and recognize objects from them. Examples include visual search platforms and image tagging APIs for developers.\n\nComputer Vision/Image Recognition (Applications): Companies that utilize technology that process images in vertically specific use cases. Examples include software that recognizes faces or enables one to search for a retail item by taking a picture.\n\nGesture Control: Companies that enable one to interact and communicate with computers through their gestures. Examples include software that enables one to control video game avatars through body motion, or to operate computers and television through hand gestures alone.\n\nVirtual Assistants: Software agents that perform everyday tasks and services for an individual based on feedback and commands. Examples include customer service agents on websites and personal assistant apps that help one with managing calendar events, etc.\n\nSmart Robots: Robots that can learn from their experience and act autonomously based on the conditions of their environment. Examples include home robots that could react to people\u2019s emotions in their interactions and retail robots that help customers find items in stores.\n\nPersonalized Recommendation Engines: Software that predicts the preferences and interests of users for items such as movies or restaurants, and delivers personalized recommendations to them. Examples include music recommendation apps and restaurant recommendation websites that deliver their recommendations based on one\u2019s past selections.\n\nContext Aware Computing: Software that automatically becomes aware of its environment and its context of use, such as location, orientation, lighting, and adapts its behavior accordingly. Examples include apps that light up when detecting darkness in the environment.\n\nSpeech to Speech Translation: Software which recognizes and translates human speech in one language into another language automatically and instantly. Examples include software that translates video chats and webinars into multiple languages automatically and in real-time.\n\nVideo Automatic Content Recognition: Software that compares a sampling of video content with a source content file to identify the content through its unique characteristics. Examples include software that detects copyrighted material in user-uploaded videos by comparing them against copyrighted material.\n\n\u00a0\n\nWe are currently tracking 1498 Artificial Intelligence companies in 13 categories across 73 countries, with a total of $9 Billion in funding. Click here to learn more about the full Artificial Intelligence landscape report and database.", 
        "title": "Artificial Intelligence Category Innovation Quadrant \u2014 Q4"
    }
]