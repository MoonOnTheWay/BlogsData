[
    {
        "url": "https://medium.com/intuitionmachine/the-alien-look-of-deep-learning-generative-design-5c5f871f7d10?source=tag_archive---------0----------------", 
        "text": "What happens when you have Deep Learning begin to generate your designs? The commons misconception would be that a machine\u2019s design would look \u2018mechanical\u2019 or \u2018logical\u2019. However, what we seem to be finding is that they look very organic, in fact they look organic or like an alien biology. Take a look at some of these fascinating designs.\n\nThe photo above design is described as follows:\n\nThis is a car frame that is designed by a generative algorithm:\n\nThe design on the right of an antenna is twice more effective that that on the left:\n\nMany of these designs come from Autodesk\u2019s DreamCatcher research.\n\nGenerative designs also exist not only in the physical world but also in the design of neural networks themselves:\n\nThese Long Short Term Memory (LSTM) are designed by an algorithm and shown to be more effective than the conventional LSTM (Note: These are Neural Networks designed with memory elements). These are generative neural architectures, machines that learn to learn, more like meta meta-models. Learning apparently is not uniform and I highly suspect that meta-level reasoning is a primary mechanism in learning and that is reflected by its biological manifestation. After all, isn\u2019t learning enhanced by diversity as well as adaptability? The same ingredients to biological survival?\n\nWhat is surprising is that these designs do not exist for the sake of style. Rather, these designs are actually the optimal solutions to multiple competing design requirements. Why do they look organic or biological? Is there some underlying fundamental principle that exists in biological systems that leads to this? Why aren\u2019t the solutions sparse, but rather complex?\n\nEven a more deeper question is, if these were the optimal designs, then why don\u2019t inanimate objects look like this? Inanimate objects that are complex tend to have a fractal style:\n\nThe self-similar repeating patterns that we see in crystals and coastlines\u00a0,despite looking complex, certainly have a style that is different from organic or biological styles. Deep Learning clearly has similar capabilities as biological systems. I suspect that this difference originates from the difference in computational machinery that generates these. It indeed is fascinating that the style of these generated objects are a reflection of the process of its originator.\n\nSelf-similarity are created through uniform processes that occur in multiple scales. In contrast, biological processes also do occur in multiple scales, diversity rather uniformity is encouraged. Humans for example, exhibit a five fold symmetry. We see similarity occurring at multiple scales, meaning we see interesting features different coarse levels of granularity, however we also see diversity. This is why designs by Deep Learning systems look biological, the construction process use similar mechanisms.\n\nA recent study \u201cInside an AI brain\u200a\u2014\u200aWhat does machine look like?\u201d Reveals similar biological like complexity in Deep Learning systems. Here is a visualization of a ResNet-50 Deep Learning network:\n\nIt indeed is fascinating that the complexity if very different from the complexity we find in chaos theory.\n\nOne misconception is that Artificial Neural Networks or Deep Learning are biologically inspired. This is NOT true. It may have thought as being true back in the 1950\u2019s when the Perceptron was first introduced. However, at best, Deep Learning employs a cartoonish version of a neuron and the newer architectures consist of computational elements that are very different from how a biological neuron would function. Nevertheless, it is indeed surprising though, that despite being very different from biology, that the resulting observable behavior appear to be very similar between both. Clearly, there is a set of fundamental processes underlying all of this that is both shared by biology and Deep Learning. That fundamental processes is what we are all seeking to discover.\n\nOne final thing though, just because DL exhibits some behavior that appears to be biological, it still is a far cry away from something that is intelligent. However, we at least know of one instance of an intelligence, and that happens to be biological.\n\nKnow more about this at Intuition Machine, read the publication: https://medium.com/intuitionmachine or join the FaceBook group: https://www.facebook.com/groups/deeplearningpatterns/\n\n\u2661 Heart if you find this discovery fascinating!", 
        "title": "The Alien Style of Deep Learning Generative Design \u2013 Intuition Machine \u2013"
    }, 
    {
        "url": "https://medium.com/@ksakmann/behavioral-cloning-make-a-car-drive-like-yourself-dc6021152713?source=tag_archive---------1----------------", 
        "text": "I collected the training data by driving the car on the flat terrain training track. The performance of the CNN can then be checked by letting the car drive autonomously on the same track or ideally on a second track that is considerably more windy with steep hills and that should not be used for training. Below are some pictures from the different cameras on the car on the training track.\n\nThis is an article to provide my thoughts on an interesting project I did for the Udacity Self-Driving Car Nanodegree. The code and technical details can be found here . The goal is to teach a Convolutional Neural Network (CNN) to drive a car in a simulator provided by Udacity. The car is equipped with three cameras that provide video streams and records the values of the steering angle, speed, throttle and brake. The steering angle is the only thing that needs to be predicted, but more advanced models might also want to predict throttle and brake. This turns out to be a regression task, which is very different from usual applications of CNNs for classification purposes.\n\nUnbalanced data\n\nWhile driving the car under normal conditions the steering angle is very close to zero most of the time. This can clearly be seen in the raw training data. Below are the steering angles I recorded while driving the car around the track while staying as close as possible to the middle of the lane. This is all the data I collected for training the final model (~9000 images or driving 3\u20134 laps).\n\nThe left/right skew is due to driving the car around the track in one direction only and can be eliminated by flipping each recorded image and its corresponding steering angle. More troublesome is the bias to driving straight: the rare cases, when a large steering angle recorded are also the most important ones if the car is to stay on the road. One possible solution would be to let the car drift to the edge of the road and recover before a crash occurs. I tried this, but found it an unsatisfactory solution, because in that case the car still goes straight most of the time\u200a\u2014\u200adirection \u201coff the track\u201d\u200a\u2014\u200awith a few large steering angles sprinkled on top. As a result a CNN trained on such data typically does not even complete the training track, unless the training data is \u2018just right\u2019. I got a CNN to drive the car around the training track this way, but the model failed on the test track.\n\nAnother solution would be to sample the extreme angle events more often than the small angles ones. However, since they are rare, a large amount of training data may need to be collected for the model to avoid overfitting.\n\nInspired by this post, I therefore decided to simulate all recovery events synthetically. For training I drove the car as smoothly as possible right in the middle of the road. The rationale behind this was to record the ideal steering angle at all times. Recovery events were then simulated by distorting and cropping the recorded camera images and adjusting the steering angle. By chaining image distortions, random brightness corrections and crops together a practically infinite number of training images could thereby be generated from the little training data I had gathered. This worked surprisingly well.\n\nData augmentation\n\nI used images from all three cameras. Images taken from the side cameras are akin to parallel translations of the car. To account for being off-center I adjusted the steering angle for images taken from the side cameras as follows: ignoring perspective distortions one could reason that if the side cameras are about 1.2 meters off-center and the car is supposed to get back to the middle of the road within the next 20 meters the correction to the steering should be about 1.2/20 radians (using tan(\ud835\udefc)~\ud835\udefc). This turned out to be a quite powerful means to make the car avoid the sides of the road.\n\nIn the next stage each image got sheared horizontally. The pixels at the bottom of the image were held fixed while the top row was moved randomly to the left or right. The steering angle was changed proportionally to the shearing angle. This had the effect of making curvy road pieces appear just as often in the training set as straight parts.\n\nSo far all transformations had been performed on the full 320x160 pixel images coming from the cameras. In the next stage I chose a window of 280x76 pixels that eliminated the bonnet from the bottom of the image and cropped off the part above the horizon in flat terrain at the top. For each image the location of this window was displaced randomly from the center along the x-and y-axes by up to \u00b120 and \u00b110 pixels, respectively. The steering angle was changed proportionally to the lateral displacement of the crop. Thereby, also images of the car being in hilly terrain were simulated and a greater variety of images than available from the side cameras could be obtained. The result was then resized to 64x64 pixels.\n\nFinally, each image was randomly flipped (horizontally) with equal probability in order to make left and right turns appear as frequently. Also brightness was randomly adjusted.\n\nChaining all these transformations can be done efficiently in batches that get generated on the fly during training from the recorded images.\n\nModel architecture and training\n\nThe CNN I chose is a pretty standard CNN consisting of 4 convolutional layers with ReLU activations, followed by two fully connected layers with dropout regularization. Finally a single neuron formed the output that predicted the steering angle. One noteworthy thing is the absence of pooling layers. The rationale behind avoiding pooling layers was that pooling layers make the output of a CNN to some degree invariant to shifts of the input, which is desirable for classification tasks, but counterproductive for keeping a car in the middle of the road. I trained the network on an Ubuntu 16.04 system using an NVIDIA GTX 1080 GPU. For any given set of hyperparameters the loss typically stopped decreasing after a few epochs (200000 images each).\n\nResults\n\nThe results came as a pleasant surprise after several nights without any progress. The car not only completed the training track, but even the test track. Shown below are the results for one of the earliest incarnations of this model, before hyperparameter tuning.\n\nI was surprised how well the car drove even on the test track. The CNN had never seen this track. The performance on the training track was a little bumpy, but I quite liked it too, because it showed that the car was not merely memorizing the track. It recovered successfully from a few critical situations, even though none of those maneuvers had been performed during training.\n\nConclusions\n\nSummarizing, this was a really interesting project. It would be interesting to see whether recovery events can also be simulated from real world data. Currently, I can\u2019t see why not. The project cost me countless of hours of sleep over a two week period of time, gray hairs and cursing included, but the result was well worth it. Deep learning is an exciting field and we\u2019re lucky to live in these times of discovery.\n\nFor more details please check out the code and the readme here:\n\nhttps://github.com/ksakmann/CarND-BehavioralCloning", 
        "title": "Behavioral Cloning \u2014 make a car drive like yourself"
    }, 
    {
        "url": "https://medium.com/dcrucsco/understanding-artificial-neural-networks-df9d25941793?source=tag_archive---------2----------------", 
        "text": "I started learning about Artificial Neural Networks few months back, in the beginning it all seemed good until there came a point when I wasn\u2019t able to apply my knowledge freely due to all the \u2018easy\u2019 frameworks which abstract tons of things behind a simple looking function. Not to blame frameworks but that is what makes us lazy in learning important concepts. This post is for anyone who wants basic understanding of ANNs and how frameworks like TensorFlow operate. Let\u2019s begin!\n\nOur brain is made up of billions of cells called neurons. They are connected to each others to create pathways which define all our thinking and daily activities.\n\nAs you might notice there\u2019s a cell body which is kind of main part of the cell and then there\u2019s this thing called an axon, kind of like a wire but going forward to a set of synapses which are little gaps between this neuron and some other neuron and what happens is, the information spike trains travel down the axon. When the cell body fires, it has an electrical impulse, it travels down the axon and then causes across the synapses excitation to occur on other neurons which themselves can fire again by setting out spike trains and so they\u2019re very much a kind of a computational unit and they\u2019re very very complicated.\n\nSo what in the field of artificial neural networks we have is a kind of a cartoonish version of the neuron and networks of neurons and we actually put them together to compute various things. And one of the nice things about the way that their setup is that they can be tuned or changed so that they fire under different conditions and therefore compute different things and can be trained through learning process.\n\nThis is how artificial neural network looks like.\u00a0\n\n- We give X1, X2\u00a0\u2026 Xn as inputs to neuron which actually is the strength or rate of firing.\u00a0\n\n- W1, W2\u00a0\u2026 Wn are weights or the sensitivity to fire on.\u00a0\n\n- Y is the output.\n\nSumming up Xi and Wi gives us something called as activation. Then we ask if it is greater than or equal to firing threshold (\u03b8). If it is, then we are going to say output is 1 and if its not then 0. This kind of networks is called as Perceptron. They are single-layered and produce binary output.", 
        "title": "Understanding Artificial Neural Networks \u2013 dcrucsco \u2013"
    }, 
    {
        "url": "https://medium.com/@YvesMulkers/30-top-videos-tutorials-courses-on-machine-learning-artificial-intelligence-from-2016-2be74dd49766?source=tag_archive---------3----------------", 
        "text": "2016 has been the year of \u201cMachine Learning and Deep Learning\u201d. We have seen the likes of Google, Facebook, Amazon and many more come out in open and acknowledge the impact machine learning and deep learning had on their business.\n\nLast week, I published top videos on deep learning from 2016. I was blown away by the response. I could understand the response to some degree\u200a\u2014\u200aI found these videos extremely helpful. So, I decided to do a similar article on top videos on machine learning from 2016.\n\nPeople often ask us \u201cHow should I get started with data science & machine learning?\u201d\n\nThere can not be just one answer to this question. The anatomy of machine learning is quite vast. One needs to decide their own framework and time period to get comfortable with machine learning. Through this article, I want to help you reach that comfort zone.\n\nIn this article, I have compiled popular and most viewed machine learning videos, tutorials and courses from 2016. I want to help you to get started with machine learning and gain expertise building predictive models using machine learning. You are free to decide your own framework and time period to watch these videos. It is always advisable to take baby steps but feel free to mould it as per your wish.\n\nIn order to help you, I have arranged the article and suggested a way to go through them. Hope you find it useful.\n\nIn this article, I have segregated the videos for beginner & advanced. The first section of the article will introduce you to machine learning basics and the underlying theory to make you get comfortable with the machine learning. If you are just getting started with machine learning then this section should be your first stop. Go through these videos one by one, and put the learning into practice with a practice problem.\n\nFor those who already have a basic understanding of machine learning, you should start with the advance machine learning videos. These videos will introduce you to various machine learning libraries, modeling techniques and other advanced concepts of machine learning. Once you are thorough understanding with advanced concepts of machine learning, try your hands on Black Friday practice problem.\n\nAfter you have an understanding of how machine learning works, embark upon the next section on the applications of machine learning. These videos will blow your mind on how machine learning is changing the world. Find out how companies today are using machine learning to makes things simpler for us.\n\nIn this video, Tetiana Ivanova shares her journey of becoming a data scientist in just 6 months. Participating in hackathons got her started with machine learning. If you have been wondering whether to go for analytics post-graduate program or become self-taught data science professional, you must watch this video. Tetiana shares her real life experience of making the career move, the hardships and truth behind the facade of a higher education. Either you are a beginner or someone transitioning his / her career to data science then I would recommend that you must watch this video. This video will leave you inspired.\n\nIn this course from Carnegie Mellon University, it will take you through basics of machine learning and statistical modeling. You will learn about parametric & non-parametric regression, clustering, boosting, graphical methods, minimax theory, dimensionality reduction, etc. This course is best suited for students with a sound background in statistics & mathematics. Alongside, there are assignments & solution which would further improve your concepts. Feel free to skip the initial few minutes of the first video.\n\nThis course on machine learning from the University of Waterloo will take you through machine learning basics and advanced concepts. It\u2019s a conceptual course which will educate you on mathematical relations in ML algorithms. It has been taught by multiple professors including Shai Ben David, author of book Understanding machine learning.", 
        "title": "30 Top Videos, Tutorials & Courses on Machine Learning & Artificial Intelligence from 2016"
    }, 
    {
        "url": "https://medium.com/@gonzalomartin/seis-cosas-que-he-aprendido-sobre-c%C3%B3mo-pensar-sobre-la-inteligencia-artificial-4fa2bea0d35?source=tag_archive---------4----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Seis cosas que he aprendido sobre c\u00f3mo pensar sobre la inteligencia artificial"
    }, 
    {
        "url": "https://medium.com/@aditya.lakshay/how-many-layers-does-your-neural-network-have-d20b284b1214?source=tag_archive---------5----------------", 
        "text": "Companies have long relied on buzzwords to describe themselves in the process of courting venture and angel investors. There is however a significant churn in the buzzwords that aid you in getting funded. Move over \u201cCurated\u201d, \u201cUber of X\u201d, hello \u201cDeep learning\u201d, \u201cReinforcement Learning\u201d. Neural Networks have suddenly become the name you casually drop at a party to look important and feed interested investors. So when RocketAI happened, I was not surprised in the least.\n\nInvestors who do not have any inkling of Neural Networks were all \u201camazed\u201d and \u201cblown away\u201d by the new \u201cTemporally Recurrent Optimal Learning\u201d (TROL(L)) system that was introduced. (In full honesty, my friends and I played with many other names including \u201cRecurrent, One-Directional, Focal, Local Memory Auto-Encoded and Optimized\u201d (ROFLMAO) Neural Networks!)\n\nEven before the RocketAI prank, I could always feel my bullshit meter going off the charts when someone from a startup used Deep Leaning, Machine Learning, AI and Neural Networks in the same breath. In November (in Toronto), I attended a talk by the CEO of a startup that is attempting to automate Accounting. They had been funded by one of the Big 4 and were terribly proud of using all the above buzzwords to change the world. At the end of the presentation, he asked if anyone from the attendees would like to ask any questions and I had a go at him almost immediately. I asked him about the actual use of Deep Learning in Accounting, whether it actually demanded a Neural Network solution and how many people were working on the product.\n\nI wasn\u2019t expecting a clear, concise answer but what he said shed some light on the funding scenario. He said that they had only one person in the company who was looking after the ML/DL part. He added that he wasn\u2019t hands on with that part as it was not his domain. Surprising, considering that their source of competitive advantage stems from tech, something they were hardly investing in.\n\nThe other day, I was having lunch with a bunch of friends who were being inundated with VC calls (http://attentive.ai/) and he casually mentioned one of the experiences he had with a VC. \u201cHow many layers does your neural network have?\u201d asked the VC. While my other friends casually sniggered upon the brazenness of the VC, in the aftermath of the RocketAI troll, I found it striking a chord. In these times of diminishing returns and exits, it becomes all the more important to fund the right ones.\n\nIt is important to consider from the point of view of the VC and also the CEOs if such questions are indeed useful. It is obviously instrumental for VCs to gauge as to who is running the show, who is the tech guy, who is the business end of it. The answers also help the VCs understand if the company is actually doing what it claims to be, if it is actually leveraging technology or just employing buzzwords for funding.\n\nDoes this actually bode well for the founders though? It helps the genuine contenders to show off their new tech while the pretenders are left in the cold. However, VCs are also notorious for sharing ideas generously. Should the founders really about their tech in such a setting?\n\nOn the other hand, It also offers them a chance to determine if that investor is the right fit for them. While the minority of the startups might interpret it to be meddling behavior, the majority of them appreciate the fact that the investors make a genuine interest and also make an effort to keep up to date with evolving technology.\n\nIf anything, the world needs the money to be going into the right startups that are really solving problems rather than ones that are raising capital using buzzwords. Asking the right questions to startup people regarding their tech competencies is\u00a0. I would rather have a VC that asks me \u201cHow many hidden layers are you using and why at all are you using DL? Why can\u2019t this be solved using regular ML algorithms?\u201d than the one who is only concerned about the sum I am aiming to raise without appreciating and understanding the need for it.\n\nOverall, investors need to be more diligent because it improves the system for both ends of the spectrum. Founders get a more responsible, diligent investor while investors have a good classifier for weeding out pretenders to the throne.", 
        "title": "How many layers does your neural network have? \u2013 Aditya Lakshay \u2013"
    }, 
    {
        "url": "https://medium.com/bbm406f16/week4-eat-count-2800134cf44f?source=tag_archive---------6----------------", 
        "text": "Last week, we talked about deep learning frameworks, their advantages and disadvantages then we tried to decide which one is suitable for our project and which one to choose. As a result, we decided to use Tensorflow Framework for our project and we implement a simple network by using Tensorflow\u2019s own tutorial and tested it on MNIST handwritten digits data set. This week we will be talking about the experiment results of testing this network on our Food-101 data set.\n\nThe first network that we implemented consists of three layers and one fully-connected layer. On each layer, we have one convolutional layer and one pooling layer. We used 5x5 sized filters on each layer with 2 strides. We used 2x2 paddings on data. On the first layer we had 32 channels, on the second we had 224 and on the third we had 64 channels. Then we connected it with the fully-connected layer. This is actually a very simple network and we made first experiments with it.\n\nWe choose our first class size as 3 and tested this network on 3 food classes. At the beginning\u00a0, we get about %60 accuracy on these 3 classes. Then we try to find a way to increase this accuracy, we implement some preprocessing approaches in order to increase accuracy. [1] First we used zero-center approach and normalize it, and we tried another pre-processing approach PCA wightening. After applying these techniques, our accuracy increases to about %80. After getting this result, we decided to pass next step with 10 different classes.\n\nWhen we directly use this network, we got some poor results with it. The accuracy was about %20 on 10 different food classes because the network architecture was not enough to classify well. Then we implemented the AlexNet\u2019s layers on our network. [2] It has 5 convolutional networks and 3 fully-connected layers. On the first layer, we have 96 channels and 11x11 sized filters with stride 4x4. On the second layer\u00a0, 256 channels and 5x5 sized filters with stride 1x1. Third and fourth layers have 384 channels and 3x3 sized filters with stride 1 and last layer we have 256 channels and 3x3 sized filters. Then we connected it to 3 full-connected layers. After testing this, we get about %30 accuracy on 10 classes.\n\nOn next blogs, we will talk about what we do to increase the accuracy and how we extract our second data set about calories of foods.", 
        "title": "[Week4 \u2014 Eat & Count] \u2013 bbm406f16 \u2013"
    }, 
    {
        "url": "https://medium.com/the-data-intelligence-connection/30-top-videos-tutorials-courses-on-machine-learning-artificial-intelligence-from-2016-e8be3b632518?source=tag_archive---------9----------------", 
        "text": "2016 has been the year of \u201cMachine Learning and Deep Learning\u201d. We have seen the likes of Google, Facebook, Amazon and many more come out in open and acknowledge the impact machine learning and deep learning had on their business.\n\nLast week, I published top videos on deep learning from 2016. I was blown away by the response. I could understand the response to some degree\u200a\u2014\u200aI found these videos extremely helpful. So, I decided to do a similar article on top videos on machine learning from 2016.\n\nPeople often ask us \u201cHow should I get started with data science & machine learning?\u201d\n\nThere can not be just one answer to this question. The anatomy of machine learning is quite vast. One needs to decide their own framework and time period to get comfortable with machine learning. Through this article, I want to help you reach that comfort zone.\n\nIn this article, I have compiled popular and most viewed machine learning videos, tutorials and courses from 2016. I want to help you to get started with machine learning and gain expertise building predictive models using machine learning. You are free to decide your own framework and time period to watch these videos. It is always advisable to take baby steps but feel free to mould it as per your wish.\n\nIn order to help you, I have arranged the article and suggested a way to go through them. Hope you find it useful.\n\nIn this article, I have segregated the videos for beginner & advanced. The first section of the article will introduce you to machine learning basics and the underlying theory to make you get comfortable with the machine learning. If you are just getting started with machine learning then this section should be your first stop. Go through these videos one by one, and put the learning into practice with a practice problem.\n\nFor those who already have a basic understanding of machine learning, you should start with the advance machine learning videos. These videos will introduce you to various machine learning libraries, modeling techniques and other advanced concepts of machine learning. Once you are thorough understanding with advanced concepts of machine learning, try your hands on Black Friday practice problem.\n\nAfter you have an understanding of how machine learning works, embark upon the next section on the applications of machine learning. These videos will blow your mind on how machine learning is changing the world. Find out how companies today are using machine learning to makes things simpler for us.\n\nIn this video, Tetiana Ivanova shares her journey of becoming a data scientist in just 6 months. Participating in hackathons got her started with machine learning. If you have been wondering whether to go for analytics post-graduate program or become self-taught data science professional, you must watch this video. Tetiana shares her real life experience of making the career move, the hardships and truth behind the facade of a higher education. Either you are a beginner or someone transitioning his / her career to data science then I would recommend that you must watch this video. This video will leave you inspired.\n\nIn this course from Carnegie Mellon University, it will take you through basics of machine learning and statistical modeling. You will learn about parametric & non-parametric regression, clustering, boosting, graphical methods, minimax theory, dimensionality reduction, etc. This course is best suited for students with a sound background in statistics & mathematics. Alongside, there are assignments & solution which would further improve your concepts. Feel free to skip the initial few minutes of the first video.\n\nThis course on machine learning from the University of Waterloo will take you through machine learning basics and advanced concepts. It\u2019s a conceptual course which will educate you on mathematical relations in ML algorithms. It has been taught by multiple professors including Shai Ben David, author of book Understanding machine learning.", 
        "title": "30 Top Videos, Tutorials & Courses on Machine Learning & Artificial Intelligence from 2016"
    }, 
    {
        "url": "https://medium.com/bbm406f16/week3-what-the-food-f863771352ff?source=tag_archive---------10----------------", 
        "text": "Last week we talked about our dataset and we decided to make some changes in this week.\n\nWe have to create dataset ourselves, and we want to our dataset contains every meal. But there are some problems. While creating our dataset, we have to find different photographs of each meal in a restaurant. But there are very few photographs of some meals like cultural meals. So, we decided to work on fast food restaurants. Because they have a lot of photographs and price information on theinternet.\n\nWe will use deep learning for our project and we need a deep learning library. We haven\u2019t decided yet. But we have chosen our options, Keras or MatConvNet.\n\nKeras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research. (Reference: https://keras.io/)\n\nMatConvNet is a MATLAB toolbox implementing Convolutional Neural Networks (CNNs) for computer vision applications. It is simple, efficient, and can run and learn state-of-the-art CNNs. Many pre-trained CNNs for image classification, segmentation, face recognition, and text detection are available. (Reference: http://www.vlfeat.org/matconvnet/)", 
        "title": "[Week3 \u2014 What the Food?] \u2013 bbm406f16 \u2013"
    }, 
    {
        "url": "https://medium.com/@prashobnair/the-future-is-exciting-923c06b8be1?source=tag_archive---------11----------------", 
        "text": "Its the end of 2016 and the right time to reflect on the growing trends in technology and how they will pan out in the future. As mentioned in my last post, I think we are going to hear more and more of AI and machine learning next year as well. I would be interested to see how the big corps use AI in more and more real life products and make life easy for the consumers.\n\nOne revolutionary technology (I think its already here to some extent) that I am waiting for is the widespread use of deep learning for medical diagnostics. I know that companies like Google Deepmind and countless startups are working on it but I think its still not \u201cwidespread\u201d enough. Probably because training the machines for medical diagnostics is hard and time consuming. You would need professionals to classify the images and x rays. And with the doctors and medical professionals already overworked with patients, and also expensive resources on per hour basis, I think it would need significant amount of time and money to develop a trained data set. It would need significant government support, financial muscles for the company and also work through the regulatory hurdles related to privacy to come up with a viable product. But the impact would be mind blowing. It would do what penicillin did. Imagine if a doctor in rural India (who is not an expert in any particular domain, but smart enough to understand results and suggest follow up and more importantly kind enough to work in rural areas ) can get the X-ray of a old patient and upload it to website or take a photo of the X-ray using some application. The application or the website can then leverage deep learning to do a expert level diagnosis of whether the x-ray shows any signs of say TB or any other illness and tell the doctor the results and also possible follow up actions. Technologies like these would be a god send for the millions of poor people in the world with no access to advanced medical care. This would be like bringing expert level care to each and every individual. If there is any deep learning/machine learning related application that I would like to develop in the near future, then it would be this. As an engineer, this is the closest I can get to helping people directly. And there is nothing more special than that.\n\nBack to less exotic and more fundamental tech changes that I see is the recent push for cashless transactions in my home country. I hope the current drive by the govt to make the public go as cashless as possible becomes at least partially successful if not a complete one. That would help the country leap frog into the future and yet at the same time help in cracking down on the problems of black money (money on which tax has not been paid), corruption and other social maladies. Lots of start ups are working on lots of solutions to these problems. I guess 2017 would be the best time for Fintech startups to be in India. The potential is beyond imagination. If we can create a nice, intuitive solution which doesn\u2019t depend on the user to be technologically literate, doesn\u2019t depend on always on internet connectivity at the user side, doesn\u2019t depend on complex steps for setting up and daily use and is secure enough to withstand the onslaught of scammers and fraud, then its going to be revolutionary. Time and again, I get restless and start dreaming of some application which can do this but beyond the initial sense of excitement and adrenalin rush, I don\u2019t do anything more. If there is one application that I would really like to do in 2017 as my pet project, then it would be this. The sad part is that being away from the country is a big roadblock. I cant talk to the banks or the user. The two crucial end points for this to be successful. So even if I create a well abstracted application, without tying up the ends, the application would be zombie. Anyways, even if it turns out be a zombie, I would like to go ahead and create one just for the heck of it. Money or no money, its just the intellectual kick that you get upon creating something that excites me.\n\nWell, thats about it. I hope I can get my acts together and do something rather than just talk and write. Its easy to write a 5 minute post on the ideas that might change the world. But it takes enormous perseverance and conscientiousness to do something meaningful that will actually positively help some one if not the whole world. Hope 2017 is the year when the words turn into action for me. I am excited and motivated.\n\nHappy new year in advance to all.\n\nps: By the way, if you think any of the ideas mentioned above is cool (they are not new for sure) or are looking at someone to dive in and work on similar ideas then drop me a line.", 
        "title": "The future is exciting \u2014 2017 Expectations \u2013 Prashob Nair \u2013"
    }
]