[
    {
        "url": "https://medium.com/@bmc_/what-makes-alphago-so-strong-and-why-does-it-matter-372ae7c6bc73?source=tag_archive---------0----------------", 
        "text": "For a game the western world doesn\u2019t know much about Go is implausibly harder than Chess. Forget playing it, it\u2019s hard to even tell who\u2019s winning. Humans have trouble scoring a half-completed game between pros.\n\nOn average, there are 250 different moves you can make (compared to Chess\u2019 35) at any given time. And to reiterate, even if you could look 9 moves ahead, a number which seems small but leads to as many possible Go positions as there are stars in the observable universe, it won\u2019t help because you still have no idea which of those 10\u00b2\u00b2 positions are better for you!\n\nHumans get around this by only seeing good moves. I\u2019m not being poetic when I call it intuition, if you ask a pro why they made a given move their answer will often be \u201cit was good shape\u201d or \u201cthe other sequences didn\u2019t feel right\u201d. (For a great illustration of this there\u2019s a book called the Go Consultants)\n\nThis is what makes Deep Convolutional Neural Networks (I\u2019ll just call them NNs) such a good match for Go. By inventing them we\u2019ve somehow distilled a very pure form of pattern recognition, which Go seems to be about.\n\nMy previous favorite paper, from 2014, took a bunch of professional games and trained a NN to predict the next move. The idea is when the network is given a new position it\u2019ll play the move a professional would have played. This network, without looking ahead, without anything but \u201cthis move feels better\u201d, plays around how well amateurs play after years of study.\n\nStrong amateurs destroy it though, because of two flaws:\n\nIt fails hilariously and makes rookie mistakes when you give it a situation which never comes up in pro games. Go involves a lot of implicit threats which are rarely carried out. Networks learn to make those threats but lacking training data are incapable of following up.\n\nFacebook mitigated that first problem by combining it with a technique called Monte Carlo Tree Search (MCTS). The intuition here is that we\u2019ve returned to computer as cold calculating machine however instead of looking at every position it probabilistically looks at the positions which the NN thinks matters. It still can\u2019t score positions so it uses a massive hack which is, depending on your worldview, either ugly or elegant, but definitely effective.\n\nThe second problem is deeper: If it\u2019s just trained to imitate pros how can it ever become better than pros?\n\nThis is the problem AlphaGo solves. Deep Mind trained a NN to predict the move a professional would play, and actually did worse than state of the art networks, but then retrained that network to play the move which will win the game.\n\nIf you\u2019re a professional, this is the same move. But if you\u2019re this crazy NN+MCTS hybrid they can be pretty different (like not wasting moves on threats you can\u2019t carry out). They trained it by having it play against previous versions of itself, effectively using human data to bootstrap a better player.\n\nThey also did what will go down in history as hilariously obvious in retrospect but which nobody saw coming, they trained not one but two different networks. The first network is as described above and the second network scores positions. They use the first network to figure out where to play, cutting down the width of the search tree; and they use the second network to figure out whether a position is good, cutting down the depth of the search tree. They actually combine that second network with the MCTS hack to get the best of both techniques. (speed and accuracy)\n\nThere are a couple cool other things in the paper, like the fact that they managed to write a distributed version which runs across 1202 CPUs. It\u2019s not surprising that they have so many CPUs, it\u2019s surprising that they were able to write a distributed version at all. That alone would have been a revolutionary paper, nobody else is quite sure how to do it yet.\n\nSo the real answer to what makes AlphaGo so strong is, \u201cthe people at Deep Mind are geniuses and invented this deep reinforcement learning stuff in the first place\u201d. Why does it matter? Because we weren\u2019t able to cheat this time. Computers beat humans at chess not by being smarter but by thinking faster.\n\nGo has been pitched to you as a sort of intellectual Everest. That it\u2019s hard is reason enough to attempt to solve it. Glory will go to the team to solve it first. That\u2019s a little true, but Go also feels like it takes some very human skills to master. If you asked people, 10 years ago, whether computers could have \u201cintuition\u201d they\u2019d say definitely not.\n\nIf AlphaGo ends up beating Lee Sedol it will be validation that we\u2019ve finally unlocked one small piece of human intelligence. We\u2019ve gotten a lot closer to understanding Go. By formalizing pattern recognition, we\u2019ve gotten a little closer to understanding ourselves.", 
        "title": "What makes AlphaGo so strong? \u2013 Brian Cloutier \u2013"
    }, 
    {
        "url": "https://medium.com/@eranshir/the-road-ahead-c8c2a07a152b?source=tag_archive---------1----------------", 
        "text": "We started Nexar because we believe in several things that few people do.\n\nWe believe that you don\u2019t have to wait for self driving cars to put a real dent in the 1.3M annual road fatalities. In fact, we believe all of the technology needed to stop most of the accidents happening today is already here.\n\nWe believe that you don\u2019t need expensive $30K sensors, dedicated networks, or specialized hardware to do that. In fact, your smartphone will do just fine, thank you very much, assuming you\u2019ll hook it up to your cell network, alongside many other smartphones around you.\n\nMoreover, we believe that both driver behavior and car insurance practices can be dramatically changed in a short time scale.\n\nWe started Nexar also because we believed in a few things which we now have shown to be true.\n\nWe believed we will be able to fully reconstruct an accident with just the imagery and sensor data from a single smartphone. We proved it and are building a totally new insurance claims process as a result.\n\nWe believed that we will map & analyze a city, its roads, and its cars, with just a small sliver of the drivers, and are releasing today a first report which covers the most dangerous driving zones in San Francisco.\n\nWe believed we will be capturing an endless stream of incidents and accidents in no time, and we most definitely proved that.\n\nIn the past four months we have been running a private beta program with a group of pro drivers in San Francisco, tracking over 100K Miles per week, and capturing thousands of road incidents (including e.g. over 800 red light runnings). Today we are embarking on a new phase of our journey, and are releasing Nexar to the App Store. We want all drivers on the road to have the same level of protection as Reggie, one of our SF pro drivers, who was hit by a car driving home one night.\n\nUsing Nexar, Reggie had a video of the accident that he could share immediately. But he also had a full and accurate reconstruction of the accident, millisecond by millisecond. In fact, our accident report also included the projected impact on the car, and force exerted on Reggie, so that he could prove exactly what impact the car and him suffered. Think of all of the times you heard of or were involved in disputes concerning an accident. We want to make that a thing of the past.\n\nBut we\u2019re not stopping there. As we want to prevent accidents in the first place, we will soon be introducing smart warnings, in an effort to reduce the probability of accidents. We want to warn you before you get into dangerous intersections. We want to alert you when approaching potholes, especially by night, or in the rain. We want to make you aware of a car braking hard five cars ahead of you, so that you can change lane with enough time, and avoid a potential chain accident. We want to warn you when you drive next to a car that has been seen driving recklessly in the past.\n\nToday, we are so excited Nexar is finally out, and you can join our network, and start protecting yourself and others, on the road. There\u2019s a long road ahead, but together, we can make it safer.", 
        "title": "The Road Ahead \u2013 Eran Shir \u2013"
    }, 
    {
        "url": "https://medium.com/@PraylinDiana/deep-learning-for-trekking-da82014856e5?source=tag_archive---------2----------------", 
        "text": "Around two years back, Bubby and me went for a small trek from Chopta to Chandrashila, North India. Even though, the distance was about 5km(3.10 miles), we camped at a place in between named Tungnath. Our plan was to get up early in the morning and to reach Chandrashila peak top before sunrise so that we can enjoy it to the fullest.\n\nOur camp was surrounded by snow. We got up very early and left our camp around 4am. We planned to reach the top before 5 am so that we reach there before the sunrise. We left really early that there was none before us. We used the trails which were left over the last day evening. Unfortunately the snow was pretty fluffy the previous day evening and hardened over the night. We realized this half way through the snow and there was no going back. We didn\u2019t have shoes with spikes and hence fell down a couple of times, but we hold each other every time. By our team work, we reached the half way.\n\nSun started to show its rays. We can see people going to the top in far away. We realized that we can\u2019t carry forward any further and stopped. The ice wall in front of us was so steep that we couldn\u2019t scale it with bare shoes and no ice axe or anything that can counter balance our weight. Finally, a guy from Germany helped us with a stick using which we were able to get back in trail.\n\nI remembered this incident when I read that drones were developed to search forest trails for lost people. These drones were developed by the researchers at the University of Zurich. With these drones, missing persons can be found and rescued quickly in forests and mountain terrains where searching them might take a long time. The researchers use AI to teach the drone to independently recognize and follow trails.\n\nThe research team solved the problem using Deep Learning, a machine learning technique used to learn feature hierarchies based on artificial neural networks. More basically, deep learning is a computer algorithm that learns to solve complex tasks from a set of \u201ctraining examples,\u201d much like a brain learns from experience. This drone was able to find directions correctly in 85% of the cases.\n\nI am so happy that AI is presenting a dream world to us so that we can live without much difficulties. But, I want AI to grow much more, at least till when I ask my phone, \u201cHey Nexi, where are you?\u201d and it has to reply \u201cI\u2019m under your pillow!!!\u201d", 
        "title": "Deep Learning for Trekking \u2013 Praylin \u2013"
    }, 
    {
        "url": "https://medium.com/@jggreene12/a-i-and-deep-learning-breaking-the-rules-6cd4169822d3?source=tag_archive---------3----------------", 
        "text": "Change is inevitable with the current state of tech disrupting every second of every day of our lives. We are not going back to the rotary telephone or the CRT TVs. The past, the present, and the future depends on how we want tech to impact and influence our lives as we live and breathe into our next stage of evolving. As a student at Holberton School, I had an opportunitiy to experience a day learning about Artificial Intelligence and Deep Learning.\n\nClose friends Louis Monier, co-founder of Altavista and Gregory Renard, leading xBrain\u2019s technical team, did an amazing presentation on giving an introduction into this world. While having personal interests into data analytics and business intelligence, I was pleasantly surprised at how big data is within the realm of Deep Learning. I thought the information getting everyone up to the current state going over the history of computers was engaging and not as abstract or boring as perceived to be.\n\nInstead of telling you exactly what Deep Learning is, what I quickly learned at Holberton School is that it is a community driven space for self discovery to research the answers for yourself first a.k.a. Google. This is a great start for you to learn how to learn something you might not be familiar with. The presenters did give everyday examples of Deep Learning which includes Netflix, Spotify, YouTube recommendations, Google Photos by search, Siri for Apple Iphone, and the autonomous car.\n\nWe must realize that just a few years ago Deep Learning was not well known in the community or even a trend. There were two options that had a divide within the A.I. community on how to approach the better solution. The first option was to write a set of rules where it stays within those boundaries of their use, without the flexibility to change in a messy world, high costs and the inability to scale. The other option was for the A.I. to learn from the data by finding patterns automatically, ability to adapt, scale, and remain at low costs.\n\nSome of the main points emphasized the two wanted everyone to understand for A.I. is that using a rules based approach is going to have limitations. A better approach would be to let the machine gather the data and learn from the data because \u201cMore data is always going to be better than a fancy algorithm\u201d said Louis.\n\nWe ended the last hour with a fireside chat discussing the philosophical issues that arrive when applying A.I. and Deep Learning. The power of positive change with tech can easily swing to a negative if we do not take heed to our actions in society where we should always question our humanity. We saw great examples shown in Hollywood Sci-Fi movies of the future we dream of where robots do cater to our every need to the nightmares of killer robots. A solution I am an advocate for is education which includes exposure and awareness.\n\nA big issue of job disruption was a topic heavily discussed that does not have a clear solution, but could change the typical concept of living as a whole. What would the world be like if robots disrupted the 9\u20135 workplace forever? These questions were very thought provoking and fascinating to explore to conclude that the future is unknown. We live in a time where there is so much data to be explored. The role of a programmer to problem solve is just a small piece of the grand scheme of things when it comes to caring for what kind of society we want to have together if we can create it. It will be interesting to see what the next ten years will be as this area in the industry of tech grows. Artificial Intelligence and Deep Learning might be called something else by then.", 
        "title": "A.I. and Deep Learning: Breaking the Rules \u2013 Joe Greene \u2013"
    }, 
    {
        "url": "https://medium.com/@butcallmeJo/his-intelligence-is-real-but-he-is-not-c19c036c8f36?source=tag_archive---------4----------------", 
        "text": "His intelligence is real. But he is not.\n\nMy whole life, I pictured Artificial Intelligence to be what the future will be like without a thought of how it would be done. After watching Terminator, I pictured an earthful of Arnold\u2019s and after watching I, Robot, I pictured heartless robots whose will was dictated by bits, bytes and statistics that humans could not understand. My friend\u2019s father has worked on robotics and AI for most of his life and too many times we talk theory and philosophy about AI and robots. Most of the time, conversation turns to the possibilities and potential of artificial intelligence. We imagine a world where a lot of the world\u2019s misery can be tended to automatically.\n\nI thought that it may be just a dream. A dream that might not happen, especially not in this century. That is until last friday when Gregory Renard (Angie: \u201cSiri before Siri\u201d) and Louis Monier (AltaVista: \u201cGoogle before Google\u201d) came to @Holberton School to talk about Deep Learning. The talk took the whole day, with very interesting perspectives from the leaders in AI and Deep Learning and interactive hands-on experiments using ConvNetJS. ConvNetJS is a very interesting tool to teach the fundamentals of Deep Learning in a simple fun game..Um I mean interface.\n\nRenard and Monier opened up my eyes about the fathomless immensity of AI and Deep Learning. Their presentation showed me all the utilization possibilities of Deep Learning and how reachable AI and machine learning are. While the concept of robots/AI being on the same level as humans might not ever be reachable, I believe that even now, many machines are actually more \u201cintelligent\u201d than humans. But, what is \u201cintelligence\u201d?", 
        "title": "His intelligence is real. But he is not. \u2013 Josquin Gaillard \u2013"
    }, 
    {
        "url": "https://medium.com/@dora.korpar/siri-today-sci-fi-tomorrow-e5c528264bc9?source=tag_archive---------5----------------", 
        "text": "Last week at Holberton School, we got the opportunity to learn about artificial intelligence and deep learning from two great minds in the field, Gregory Renard and Louis Monier. After an incredible 8 hours of playing, listening, and discussion, I came away with a sense of hope and excitement for the future. I can now officially say I\u2019m on the AI bandwagon. But let me put that in perspective.\n\nUp until our lesson, all I knew about AI was from movies like (you guessed it) AI, Bicentennial Man, and I, Robot. I was actually reasonably sure that I, Robot was a warning sent to us from the future of what would happen if we dared to build truly intelligent robots (and obviously Will Smith is from the future, too).\n\nBut with this fear of AI that I had (ready? it\u2019s about to get real), I was actually giving in to what I consider one of humanity\u2019s greatest flaws: fear of the unknown. Everyone read Hamlet in high school, right? It was in the famous \u201cto be or not to be\u201d soliloquy that he said, \u201c[The dread of the unknown] makes us rather bear those ills we have than fly to others we know not of.\u201d Most of us have this natural tendency to resist change because we\u2019re unsure of what could happen. At least, I know I do. We are creatures of habit, after all.\n\nAnd this fear has been a part of the human condition for a long time, since way before Shakespeare. I\u2019d bet it was probably even evolutionarily beneficial at some point in our history (biology major over here!), but\u2026 there\u2019s a rub. It\u2019s this kind of thinking that stymies innovation, that chokes progress, and that ultimately makes us all complacent. Which is not a good thing.\n\nNow, I\u2019m not saying to throw caution to the wind and start handing out smart houses and personal AI assistants to everyone. First of all, we\u2019re not there yet. Siri and Baidu\u2019s app FaceYou are some pretty incredible feats, but there\u2019s still a long way to go before we meet some of the expectations Hollywood has set for AI. Second, there are lots of implications and potential consequences to consider. But don\u2019t worry, they are being considered. In great depth. Some huge names, both in and out of the industry, including Stephen Hawking, Elon Musk, and Noam Chomsky, have signed an open letter on artificial intelligence. This letter basically states that research into AI is important and needs to be done, but research on how to prevent its misuse (which we all know inevitably leads to the \u00adMatrix) is just as important. To that end, many of those same people went on to sign another open letter detailing the importance of keeping AI out of weaponry. So don\u2019t think engineers and programmers are just turning a blind eye to the issues in the name of growth or wealth. We know there are dangers, and acknowledging and studying those \u201cpotential pitfalls\u201d is the best way to prepare for them.\n\nWhat I am saying is that we should consider the potential. AI\u2019s potential is really almost limitless. Do you want to know what your pet is thinking? What about your plants? How about having your taxes done without you ever even thinking about them (and for free)? There are so many applications for AI in our daily lives, that it\u2019s sometimes hard to distance yourself enough to see them. Ask yourself, what are things I have to do but hate doing? I, for example, hate shuffling through 4 email addresses every day, doing laundry, and cooking. Let\u2019s automate all those kinds of things. And once we free ourselves from the mundane, then an even better question can be asked: what are things you want to do but never have the time for? Because, to me, that might be AI\u2019s greatest benefit\u200a\u2014\u200amore time to do things we enjoy, more time with family and friends, more time to create.\n\nAnd there\u2019s so much more than just eliminating busy work. Let\u2019s give autonomy to the disabled and elderly, individual school curriculums tailored to every child, and the eradicate homelessness and poverty (it\u2019s in the open letter!). We\u2019re talking about improving everyone\u2019s lives in some way. Big stuff. And yes, for some of my examples, a lot of things are going to have to change. And it\u2019ll probably be pretty hard. And things might get a little crazy. But that doesn\u2019t mean they aren\u2019t worth doing, right? Remember, change is not an inherently bad thing. If we have the capability to change things for the better, don\u2019t we have a responsibility to do it? I think so. Either way, I believe there are big things in store for us. The future is happening.", 
        "title": "Siri Today, Sci-Fi Tomorrow \u2013 Dora Korpar \u2013"
    }, 
    {
        "url": "https://medium.com/@theekanems/artificial-intelligence-and-deep-learning-7d747f825208?source=tag_archive---------6----------------", 
        "text": "It\u2019s no longer fiction folks. Machines can finally learn how to do some basic thinking like we do on a daily basis. Though not like we can mostly but quite close. In the near future, I expect to see AIs built into phones and everyday personal devices handling tasks for us like calling the plumber if you have a broken pipe or fixing your appointments the way you like it. But what is AI really and how did we get this far?\n\nArtificial Intelligence is the intelligence inhibited by software or machines.\n\nTo the everyday Joe, Computers are pretty much intelligent already. It\u2019s common knowledge that computers exist that can simulate the movements in the galaxies and tell how close to our dear planet, a meteorite would fly by. Well yes but can it (the machine or software) tell what\u2019s in the picture? Well\u2026 No. So you can see now it\u2019s not about solving the problem; it\u2019s more about learning to solve the problem. You can call that Machine Learning and one of the branches we are going to talk about is Deep Learning.\n\nIn 1959, Arthur Samuel defined machine learning as a \u201cField of study that gives computers the ability to learn without being explicitly programmed\u201d\n\nThe way we think for example is quite fascinating don\u2019t you think? Our brains are made up of cells called neurons and each neuron communicates with the other deciding on what needs to be said or done. That\u2019s is a huge amount of neurons doing some serious tasks, no wonder we need food and lots of sleep! To achieve this in a computer (artificial neural networks), we will need to have groups of mathematical functions bundled up in an organised manner and say \u201chey guys, learn to do this\u201d. Here is how this would work.\n\nWe stack up neurons to receive input, process (based on special mathematical algorithms) and give an output. So say we wanted to know what was in the picture. The neuron in the bottom layer is going to pick a tiny piece of the picture and make some calculations using it (based on the algorithms again). It does not understand anything about the image in question but what it does understand is that it\u2019s giving a signal that is useful to another neuron\u2019s calculations and in turn will give a signal to yet another neuron and so on. At this point you would already know that there may be layers upon layers of neurons doing actual work. At the top of the neuron layer chain are two neurons who are tasked with output. They look at the all the computations and make the decision about what\u2019s in the picture. And Yes, it's a slow process especially when compared to the power of the human brain who can look at a cat in any form, shape or size and say \u201cOh that\u2019s a cat\u201d.\n\nDeep Learning are of two types. Supervised and Unsupervised.\n\nSupervised deep learning involves simply showing the software or computer how to deal with a task of specific classification for a significant amount of time. More like:\n\nThis is a picture of a cat.\n\nThis is a picture of a cat walking.\n\nThis is a picture of a cat lying down\u2026\n\nAnd then at the end you ask what\u2019s this\u2026 And it goes, \u201cit is a cat\u201d\n\nAnd you ask what is it doing\u00a0\u2026 and it goes, \u201cit is walking\u201d\n\nIn unsupervised deep learning, you leave the algorithm to decide based on patterns it picks from the data. This can be very powerful in some applications like personal assistants and games as it learns what to do based on patterns it gets. Its application is endless.\n\nThere is still a long way to go when it comes to machine learning and perfecting the artificial intelligence unit. Will they learn to be sarcastic? Who knows. Once we figure out how to make them work faster and run on better hardware we may possibly see a lifelike AI as seen in the HALO series.", 
        "title": "Artificial Intelligence and Deep Learning \u2013 SonOfTheWeb \u2013"
    }, 
    {
        "url": "https://medium.com/@DamazoAli/paving-the-way-for-ai-d20d0546a1a0?source=tag_archive---------8----------------", 
        "text": "Most people seem to think \u201cAI\u201d or artificial intelligence is a thing of the distant future. But we can\u2019t be further from the truth. While we may not be at the \u201chave your own robot to perform simple household tasks\u201d days just yet. AI and Deep Learning are being utilized to predict what we want to eat, watch, and buy. As well as facial recognition and, now, self driving cars are right around the corner.\n\nLate last year, Google submitted their design for a self-driving car to the US National Highway Traffic Safety Administration (NHTSA) outlining the design. Earlier this month, the NHTSA responded agreeing with Google, explaining the software could qualify as the driver for the vehicle.\n\nNvidia utilizes Deep Learning coupled with cameras and sensors to absorb information around a vehicle, which is then fed to their NVIDIA DRIVE auto-pilot car computer.\n\nAn example of Deep Learning or Machine Learning would be Nvidia engineers recording around 40 hours of video from the cameras mounted on their cars, which was then manually tagged by frame. Taking the 68000 or so objects in the footage, the engineers fed these images to servers, which began to study them by identifying their patterns, shapes, and angles. Over time, the computer starts to identify object, such as a car. However, Deep Learning allows the computer to categorize the information in layers. These layers are then stacked and the machine learns what computer scientists call a \u201chierarchical representation.\u201d This is where each layer looks for a specific shape or pattern and passes it up, allowing it to eventually learn and understand the concept of a person crossing the street, for instance.\n\nWhat\u2019s next? Further down the road, I see Deep Learning as a crucial tool towards each and every one of us with our own personal robot helper. Perhaps, giving each and every piece of technology we own the ability to know what we want, and when we want it. Question is, whether or not what we\u2019re building for ourselves is bringing us together or pushing us further apart?", 
        "title": "Paving the way for AI \u2013 Damian Ali \u2013"
    }
]