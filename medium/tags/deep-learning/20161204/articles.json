[
    {
        "url": "https://medium.com/@erikhallstrm/backpropagation-from-the-beginning-77356edf427d?source=tag_archive---------0----------------", 
        "text": "The whole network is shown below, from the input vector x , to the output activation vector a\u1d38 . The connections leading in to a specific neuron is shown in colors in two layers:\n\nThe matrix multiplications in this formula is visualized in the figure below, where we have introduced a new vector z \u02e1. which is the activation without the application of a component-wise transfer function, so that a \u02e1 = \u03c3( z \u02e1 ). I will call this value the \u201cinput sum\u201d of a neuron.\n\nWe have a fully-connected feed-forward neural network. It has L layers (could be any number) and any number of neurons in each layer. The activations of the neurons in layer l is stored in an activations column-vector a \u02e1, where the superscript index denote the layer. The connections from the neurons in layer l-1 to the layer l are stored in a weight matrix W \u02e1, and the biases for each neuron is stored in a bias column-vector b \u02e1.\n\nI have tried to understand backpropagation by reading some explanations, but I\u2019ve always felt that the derivations lack some details. In this article I will try to explain it from the beginning hopefully not leaving anything out (theory wise at least). Let\u2019s get started!\n\nOne thing we can do, just to get a feeling of it is to write the network computation into one mathematical expression. Let\u2019s write down the formula for calculating the n:th element of the output vector in the final layer:\n\nHere we have introduced new notation where w\u02e1\u1d64\u1d65 is denoting the connection from the v:th neuron in layer l-1 to the u:th neuron in layer l, and b\u02e1\u1d64 is the bias of the u:th neuron in layer l. The expression can be a bit confusing, particularly because of all the new indices. But the biggest takeaway from this is that the neural network is just a mathematical function. And this function can be derived with respect to any variable. We will use our newly introduced notation, and define an error function, or \u201ccost\u201d function C using a sample of our training data, and then see how the error changes as we change our weights.\n\nThree adjacent layers anywhere in the network are shown in the figure below, the index letter for the neurons in the layers are j, k and m respectively, and the index letter for the layer is l.\n\nFirst calculate the input sum of a neuron k in layer l:\n\nThen take the transfer function, it could be any function with a first derivative:\n\nNow finally calculate the input sum of a neuron m in layer l+1.\n\nHere we have gone forward one step in the layers, from the activations in layer l-1 to the input sums of neurons in layer l+1. An error function C is defined using one example from our training data, and its derivative is calculated with respect to a single weight in layer l.\n\nYou may notice the sum in the expression above, it is due to the chain rule, all contributions from the neurons in layer l+1 have to be accounted for since their value is affecting the end error (their value is depending on the weight that we are taking the derivative with respect to). This is visualized in the figure shown above.\n\nOne important thing to remember is that we have fixed k and j, thus we only see how the error changes when one single weight is manipulated in the calculation. All the other weights are held constant, and the derivative of a constant is simply zero. But the m index in layer l+1 is not fixed, the activation of all neurons in that layer are changed as we change our specified weight.\n\nNow let\u2019s make a definition, the \u201cerror signal\u201d of a neuron k in layer l as how much the total error changes when the input sum of the neuron is changed:\n\nSo every neuron in the whole network now has an error signal defined. But if you look at the equation above, you will see that we have already expanded this expression:\n\nSo we have a recursive formula for the error signals, using our definitions:\n\nYou may wonder what happened with the biases, they are also \u201cweights\u201d and the error function should be derived with respect to them as well.\n\nSo the gradient of the cost function with respect to the bias for each neuron is simply its error signal!\n\nIn order to use this recursive formula we need to obtain the first error signal in the series, i.e. the error signal of the neurons in the final layer L. This is the starting value, after having this we can \u201cpropagate\u201d backwards calculating all the error signals.\n\nThe only derivative that has to be calculated here is the derivative of the cost function with respect to the activations of the last layer, which is the output of the network. So this will depend on the error-function we choose.\n\nSince we now can recursively calculate all the error signals for all neurons in the network, it is possible to obtain the derivative of the cost function with respect to all weights. Training is done by subtracting from each weight a small fraction of its corresponding derivative, called the delta rule. Since everything is known, the network is trainable! But we would like a more efficient notation, since we previously only worked with scalars. Vector and matrix notation is to the rescue! Remember that we stored all weights for layer l in a matrix W\u02e1, where the weights connecting from all neurons in l-1 to a neuron in l are stored as as rows? Take a look at the first figure in the article to be reminded about this. Now use the weight matrix, take its transpose. That will mean that the connections to the neurons in the layer are stored as columns. Put all the error signals for the layer in a column vector, and multiply it with with the transposed weight matrix. Sorry about this, but new notation again, there are a total of M neurons in layer l+1 and K neurons in layer l.\n\nThe similarity sign is because we are lacking the multiplication of the derivative of the input sum in layer l. Make sure you understand this matrix multiplication, use pen an paper to sketch the calculations if possible.\n\nFinally using all we derived previously, we can state formulas for calculating the gradient of the cost function with respect to the weights as following:\n\nThe nabla symbol is the derivative with respect to the output variables of the final layer, and the dot with a circle denotes component-wise multiplication.\n\nUsing these formulas we can effectively write an algorithm train the network, using single training sample at a time.\n\n7. Update the weights according to the delta rule.\n\nThis explanation is how to train a network using only one training sample at a time, but how to do it using batch learning? What we can do is just putting the inputs of the training samples as columns in a matrix, doing the forward propagation the input sums and activations will also be in matrices, where column index is the sample index, and the row index is the neuron index.\n\nSimilarly the error signals for different layers and samples will be in matrices. However, the derivatives of the cost function with respect to the weights will be in a three-dimensional tensor using the dimensions . Reducing a sum over the samples in this tensor will give the gradient matrix for the weights in the actual layer, and the weights can be updated using the delta rule.\n\nIn the next article we will be building a simple neural network from scratch, that can be trained using this theory (coming soon).", 
        "title": "Backpropagation from the beginning \u2013 Erik Hallstr\u00f6m \u2013"
    }, 
    {
        "url": "https://medium.com/intuitionmachine/the-different-ways-that-internet-giants-approach-deep-learning-research-753c9f99d9f1?source=tag_archive---------1----------------", 
        "text": "I\u2019ve been working for quite a while now in trying to make sense of the research developments in Deep Learning. The methodology I\u2019ve employed is through the cataloging of Design Patterns. It\u2019s been quite effective in disentangling this ever growing complex field. In fact, as new surprising research is published by the giants in this field, my own conceptual understanding of how it all fits together continues to be tweaked.\n\nThere are, however, certain patterns that I have observed that is actually outside that of a general understanding of Deep Learning. What I\u2019ve observed is that the different leading research groups seem to emphasize different kinds of approaches in solving the riddle of artificial intelligence. Now, a bit of a caveat here, I\u2019m not privy to the internal machinations inside these organizations. So if there\u2019s some secret sauce that an organization is brewing, then obviously I wouldn\u2019t know about it.\n\nHowever, by just reading the research publications, that fortunately come out quite occasionally, one gets a sense that organizations favor one approach from the other. (Note: The approaches are not mutually exclusive) So, with that out of the way, let me give you my intuition on the biases (or rather preferences) that each of the big players in the field approach Deep Learning research.\n\nEver since Google bought out DeepMind after seeing their Atari game playing AI, DeepMind has always had the preference of using Reinforcement Learning in their approach. They certainly use Deep Learning as a component in most of their research but always seems to emphasize its combination with RL. The DL research tends to focus on using variational methods that are embedded as non-parametric layers in their models. They also have a focus on attention mechanisms and memory augmented networks. In terms of breadth of research, I don\u2019t think there is any organization that is remotely close to DeepMind. DeepMind research seems to be driven by the need to discover the nature of intelligence. You can find more of their work here: https://deepmind.com/research/publications/ [DMT]\n\nGoogle has a distinct pragmatic and engineering approach in how they approach their research. You can see how they make endless tweaks on the inception architecture. They have detailed work on how they arrange their DL architectures around the compute resources that they have available. Google also combines other traditional algorithms like beam search, graph traversals and generalized linear models with DL\u00a0. The approach seems to also emphasize the need for scalable solutions. Google is able to achieve impressive results as a consequence of their massive computational and data resources. You can find their research here: https://research.googleblog.com/ [GOO]\n\nThis is headed by Yann LeCun. It is unclear how strong this group is since it seems that most innovative research comes from LeCun\u2019s group in NYU. LeCun\u2019s group does an experimentation that explores the fundamentals, this is a sorely missing aspect that groups fail to perform enough. FAIR has published a couple of good open source implementations in Torch. They\u2019ve done some good work applying DL in certain problems. It is, however, hard to see if there is any particular research preference. I find it difficult to discern an overarching theme of their research. Maybe you might have better luck: https://research.fb.com/publications/?cat=2 [FAC]\n\nIs similar to Google in that their approach is very pragmatic and engineering oriented. Microsoft surprisingly has top notch computer science talent that had led to the discovery of Residual networks. They have other novel approaches like the Decision Forrest that indicates that the company clearly has thought leadership in this space and is not a company that is just a follower. Their Cognitive toolkit, despite coming late in the game, is a high- quality piece of engineering. It likely is one of the better frameworks out there with respect to learning using distributed computers. I would say that Microsoft is likely second to Google in their research contributions. That\u2019s a big statement to make considering none of the original DL researchers have joined their team. See: https://www.microsoft.com/en-us/research/research-area/artificial-intelligence/ [MIC]\n\nOpenAI was founded by Elon Musk (and some other lesser dudes) driven by the fear of seeing how quickly other firms had acquired Deep Learning talent. If you can\u2019t compete on financial terms, then offer academic freedom instead. OpenAI tends to favor the approach of using generative models, more specifically generative adversarial networks (GANs). They\u2019ve also made a serious effort towards the Reinforcement Learning space. What\u2019s curious though is that despite the impressive results of GANs, is that DeepMind seems to have a preference towards variational models instead. A glimpse of their research priorities can be found here: https://openai.com/requests-for-research/ [OPEN]. Microsoft has offered its Azure service to OpenAI thus potentially assuring OpenAI\u2019s allegiance.\n\nThis is Yoshua Bengio\u2019s group that is never really short on publications. Bengio is one of the few brave researchers who has not succumbed to joining a commercial entity. Similar to Lecun\u2019s NYU group, the approach focuses on trying to understand why DL works. The group also has plentiful work on tweaking DL with new models and learning algorithms. MILA is arguably the best academic DL research group on the planet (see: https://mila.umontreal.ca/en/ ) [MILA]. Google was pretty savvy by helping the group to some additional spare change. This move encouraged Hugo Larochelle to exit from Twitter ( quickly becoming a non-player ) and join the newly founded organization.\n\nHeaded by Richard Socher, most of the work coming from this group has an obvious bent towards solving NLP problems using RNN based approaches. These solutions will tend towards networks that employ memory in their construction. The output of these folks are quite impressive and therefore should be taken very seriously. Here\u2019s their work: http://metamind.io/research-list.html [META]\n\nAndrew Ng\u2019s group that likely was one of the first organizations to really create massive GPU systems with Infiniband networks. They\u2019ve done a lot of work emphasizing infrastructure and have open source some of their solutions. Their research focus has been in image and speech processing. In the latter, they\u2019ve done extremely well. Their research can be found here: http://research.baidu.com/institute-of-deep-learning/ [BAI]. Baidu was also originally involved with BMW with regards to self-driving cars.\n\nNvidia is betting the bank on Deep Learning solutions. They have the best engineering team that is out there tweaking their GPUs to get maximum performance. They are completely absent in terms of innovative DL research, but you can trust them to have spent serious effort in building the computation resources required for DL. They, however, have likely one of the leading implementations on self-driving cars. Their end-to-end DL solution for self-driving cars is one of those DL research papers that I remember that\u2019s notable.\n\nIntel was in deep trouble prior to their acquisition of the Nervana startup. Their hardware solutions were nowhere near competitive to Nvidia\u2019s. Nervana is very good at engineering the computational infrastructure used by Deep Learning. Some of the fastest implementations on GPU hardware come from Nervana. The speculation here is that Nervana was acquired for its software chops and not necessarily for the hardware they were designing. It is curious that the Nervana hardware solution ETA is mid-2017, that in the DL field is a very long time. You won\u2019t find a lot of research publications coming out of Nervana, I don\u2019t think they were able to amass enough DL talent while they were still a startup. However Intel is a player you cannot write off, they have technology shared with Micron ($MU) that may give them an insurmountable advantage in this space.\n\nIBM got this entire AI craze going wheb Watson destroyed its human competitors in Jeopardy. They were perceived to have been way ahead of everyone back in 2011. Unfortunately, Deep Learning came along and IBM has been slow to react in this space. Watson certainly uses DL in some of their solutions, however, they are almost non-existent in terms of DL research. They have this TrueNorth neuromorphic computing thing going, but that\u2019s mostly more hype than actual substance. IBM is not as prominent a researcher in the DL space, but if you look hard enough you\u2019ll find some: https://arxiv.org/abs/1604.08242 [IBM].\n\nNot really much to say here other than the hiring of Russ Salakhutdinov from CMU tells you that future research would emphasize his bent toward unsupervised learning approaches. Apple is busy acqui-hiring companies. Some of the bigger hires (i.e. Dato) were in the ML space. Unfortunately, their acqui-hires were mostly in the data science and big data space. I think when Apple realized that DL was different from ML, they rushed out and bought out Salakhutdinov. Apple\u2019s culture is extremely secretive, so I\u2019m not sure if their lack of research publication is an indicator of lack of expertise or towing the corporate line. Update: BusinessInsider reports Apple will start publishing their work.\n\nNot much to say other than the support of MXNet was a good thing. They had originally open sourced a framework called DSSTNE, it was unfortunately destined to receive a lot of neglect by the community. It\u2019s hard to get attention when there are so many competing frameworks that are out there. MXNet is actually impressively good considering that it did not have a big corporate backer.\n\nUber has made recent acquisitions of Otto (Self-Driving Trucks) and just recently started their AI Lab through the acquisition of Geometric Intelligence. Gary Marcus, the founder, was featured previously in other publications, he was unimpressed at that time with Deep Learning capabilities. It is important to note that Gary Marcus is a cognitive psychologist and not a computer scientist. Geometric Intelligence, however, was able to hire a basket load of ML practitioners. Uber\u2019s acquisition by all likelihood was an acqui-hire considering that is unlikely that Geometric Intelligence had any revenue, much less any product to speak of.\n\nJust another caveat, these are just my impressions and I am certain, given the deluge of information in the DL space, that I may have missed some publications that these organizations may have put out that should have been recognized. So my apologies if you feel my review was unfair.\n\nMy point though of this article is just to point out that AI research landscape is not homogeneous. Different organizations have different priorities in what they believe as important research areas. There is definitely an AI race going on and the likely winner is the company that actually was the one lucky enough to have put resources in the winning research approach! It is indeed very odd, that given the high stakes involved, that there\u2019s an implicit gamble that every firm seems to be making.\n\nAn early overview of ICLR 2017 gives an idea of the DL research activity of the above organizations.\n\nI am certainly surprised how low Baidu and Salesforce.com are on this list. Nevertheless, quantity does not necessarily always reflect quality. Let\u2019s wait till the submissions get reviewed. Also worth pointing out are the universities without a corporate affiliation, you will find that some of them have startup spinoffs that are ripe for corporate acquisition (just like Geometric.AI).", 
        "title": "Deep Learning Race: A Survey of Industry Players\u2019 Strategies"
    }, 
    {
        "url": "https://blog.vilynx.com/vilynx-in-action-at-nips-this-week-af2d947b9484?source=tag_archive---------2----------------", 
        "text": "What a busy couple of weeks at Vilynx! After a big day at AWS reInvent in Las Vegas, our CEO Juan Carlos traveled to Los Angeles with VP of Sales Mike to meet with customers, then home for his daughter\u2019s birthday party, and soon on the plane again to Barcelona attending a machine learning conference, Neural Information Processing Systems (NIPS).\n\nOur team has worked so hard the last couple of months preparing for this big show. We\u2019ll be partnering once again with Intel (thank you!) to showcase the Vilynx Deep Tagging technology that uses machine learning to automatically generate keywords for videos tags. Visitors will get to play in our fun photo booth to experience what our technology is all about. We will provide you with sports props, such as a football, basketball, or a tennis racket. Our technology will then be able to identify what sports you\u2019re playing based on the props.\n\nA second demo will also take place where we\u2019ll be using any video and auto tagging it based on people, object, action, and background.\n\nOne thing worth mentioning is that our Machine Learning experts, Asier and Delia, will be presenting their machine learning research papers at the show.\n\nOne last thing, if you\u2019re interested in the details behind our technology and need some bedtime reading, Intel and Vilynx have jointly written this white paper on our video tagging technology.", 
        "title": "in Action at NIPS this week \u2013"
    }, 
    {
        "url": "https://medium.com/@ooohiroyukiooo/facebooks-advice-to-students-interested-in-artificial-intelligence-6df9817df3dc?source=tag_archive---------4----------------", 
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out.", 
        "title": "Facebook\u2019s Advice to Students Interested in Artificial Intelligence"
    }, 
    {
        "url": "https://medium.com/sasikanth-kotti/descriptive-statistics-final-project-python-fdb128422a08?source=tag_archive---------5----------------", 
        "text": "Welcome to the Descriptive Statistics Final Project! In this project, you will demonstrate what you have learned in this course by conducting an experiment dealing with drawing from a deck of playing cards and creating a writeup containing your findings.\n\nBe sure to check through the project rubric to self-assess and share with others who will give you feedback.\n\nThis experiment will require the use of a standard deck of playing cards. This is a deck of fifty-two cards divided into four suits (spades (\u2660), hearts (\u2665), diamonds (\u2666), and clubs (\u2663)), each suit containing thirteen cards (Ace, numbers 2\u201310, and face cards Jack, Queen, and King). You can use either a physical deck of cards for this experiment or you may use a virtual deck of cards such as that found on random.org (http://www.random.org/playing-cards/).\n\nFor the purposes of this task, assign each card a value: The Ace takes a value of 1, numbered cards take the value printed on the card, and the Jack, Queen, and King each take a value of 10.\n\n1. First, create a histogram depicting the relative frequencies of the card values.\n\n2. Now, we will get samples for a new distribution. To obtain a single sample, shuffle your deck of cards and draw three cards from it. (You will be sampling from the deck without replacement.) Record the cards that you have drawn and the sum of the three cards\u2019 values. Replace the drawn cards back into the deck and repeat this sampling procedure a total of at least thirty times.\n\n3. Let\u2019s take a look at the distribution of the card sums. Report descriptive statistics for the samples you have drawn. Include at least two measures of central tendency and two measures of variability.\n\n4. Create a histogram of the sampled card sums you have recorded. Compare its shape to that of the original distribution. How are they different, and can you explain why this is the case?\n\n5. Make some estimates about values you will get on future draws. Within what range will you expect approximately 90% of your draw values to fall? What is the approximate probability that you will get a draw value of at least 20? Make sure you justify how you obtained your values.\n\nDeck_Cards.csv contains deck of fifty-two cards divided into four suits, along with assigning each card a value: The Ace takes a value of 1, numbered cards take the value printed on the card, and the Jack, Queen, and King each take a value of 10)\n\nBelow is the format:", 
        "title": "Descriptive Statistics Final Project \u2014 Python \u2013 Sasikanth Kotti \u2013"
    }
]