[
    {
        "url": "https://medium.com/@joeDiHare/three-things-from-the-tensorflow-summit-1efbfc6014f8?source=user_profile---------1----------------",
        "title": "Three things from the TensorFlow summit \u2013 Stefano Cosentino \u2013",
        "text": "Even though there were many more, I left the meeting thinking that I had learned three things from the tf summit today.\n\nUp until the previous tf release, you couldn\u2019t just print a variable in whenever you want and expect to see the output. These shortcuts are for pytorch users, TensorFlow uses graphs. Well, now tf supports eager execution, which allows developers to manipulate variables at various stages during training. This makes it very easy to debug and develop.\n\nAnd, it comes at a very small computational cost. Benchmark showed that with a machine with GPUs the slowdown was negligible and that they are working on making it even smaller.\n\ndeeplearning.js has now become part of tensorflow and you know what does this mean: we can import models, train new models, and do inference all without leaving the browser. The crew also demoed a few apps that required online image recognition. Support & integration with node.js coming soon.\n\nThis was in the air and many are already working on: using beefy computers to optimize architecture and hyper-parameters on top of learning from the data. One interesting slide they showed was that one such optimization led to a model that had autonomously learned to use skip-connections.\n\nAlso learned on the same day.\n\n- They tried a bunch of different updates rules, some complex some simple. Many of these outperformed Adam optimizer. (presented @ ICML 2017).\n\n- Within their main effort to predict eye diseases from iris scans, they also performed a toy experiment where they tried to predict gender from the same scans. It shouldn\u2019t work, right? Accuracy was >80%.\n\n- \u201cpythonification\u201d seemed an important point across talks. There is a clear intent to turn elements of the ML pipeline \u2014 like data or tf.variables \u2014 into python objects that can be easily iterated on, printed or modified."
    },
    {
        "url": "https://medium.com/@joeDiHare/deep-bayesian-neural-networks-952763a9537?source=user_profile---------2----------------",
        "title": "Deep Bayesian Neural Networks. \u2013 Stefano Cosentino \u2013",
        "text": "Conventional neural networks aren\u2019t well designed to model the uncertainty associated with the predictions they make. For that, one way is to go full Bayesian.\n\nHere\u2019s my take on three approaches.\n\nBut first. What are we trying to do?\n\nAny deep network has parameters, often in the form of weights ( , , \u2026) and biases ( , , \u2026). The conventional (non-Bayesian) way is to learn only the optimal values via maximum likelihood estimation. These values are scalars, like or .\n\nOn the other hand, a Bayesian approach is interested in the distributions associated with each parameter. For instance, the two parameters above might be described by these two Gaussian curves after a trained Bayesian network has converged.\n\nHaving a distribution instead of a single value is a powerful thing. For one, it becomes possible to sample from a distribution many many times and see how this affect the predictions of the model. If it gives consistent predictions, sampling after sampling, then the net is said to be \u201cconfident\u201d about its prediction.\n\nThe pain point\n\nEstimating those distributions, of course, is the hard part. These are generally referred to as posterior densities, and are estimated using the Bayes rule.\n\nThe problem is the denominator \u2014 also known as model evidence. It requires integrating over all possible values of the parameters (i.e., all weights and biases space), and it is often not doable in practice.\n\nInstead, pseudo-numerical approaches can be chosen where the solution to those integrals is approximated: option 1, 2 and 3 mentioned before.\n\nSince computing exact integrals for the Bayes rule is hard, MCMC (Markov Chain Monte Carlo) is used to approximate these. The idea behind MCMC is really handsome and I\u2019d suggest this uber-famous blogpost to get code and an insight behind the approach. Maths aside, however, this method is the slowest and the least sexy of the three options.\n\nPros: In theory MCMC eventually leads to great results, with approximations that resemble the real thing (posteriors).\n\nCons: In practice it takes a long time to converge, when it ever does.\n\nVariational inference is an approach to estimate a density function by choosing a distribution we know (eg. Gaussian) and progressively changing its parameters until it looks like the one we want to compute, the posterior. Changing parameters no longer requires mad calculus; it\u2019s an optimization process, and derivatives are usually easier to estimate than integrals. This \u201cmade-up\u201d distribution we are optimizing is called variational distribution. There is some really elegant math that shows how choosing the optimal parameters for the variational distribution is equivalent to maximizing a lower bound, and definitely worth checking it up at some point. But if you want to know how to get it to work, and leave the theory aside for now, I have prepared a short tutorial for an 8-category classification task using .\n\nSetting up the variational distribution. We\u2019ll choose Gaussians. As for inference technique, we pick one based on KL divergence. The actual estimation of the KL is carried out estimating the ELBO via a \u2018black-box\u2019 variational approach (if you care about what it means >> read this).\n\nModel has been defined, we\u2019re now ready to start a tf session and train.\n\nOne can now sample these distributions ( for the weights, and for the biases) and look at the spread around each prediction, which indicates model uncertainty.\n\nYou can play with and for this. In conclusion:\n\nPros: it is faster than plain MCMC, and libraries like help getting your Bayesian net up and running in minutes.\n\nCons: it might get slow for very deep Bayesian net, and performance isn\u2019t always guaranteed to be optimal.\n\nMC dropout is a recent theoretical finding that provides a Bayesian interpretation of the regularization technique known as \u201cdropout\u201d. The reasoning is a little as follows. Variational inference is a Bayesian approach to estimate posteriors using an arbitrary distribution, the \u201cvariational distribution\u201d introduced earlier; the dropout, instead, is a form of regularization for neural networks where neurons are randomly turned on or off during training to prevent the network to depend on any specific neuron. And here is the key idea of MC dropout: dropout could be used to perform variational inference where the variational distribution is from a Bernoulli distribution (where the states are \u201con\u201d and \u201coff\u201d). \u201cMC\u201d refers to the sampling of the dropout, which happens in a \u2018Monte Carlo\u2019 style.\n\nIn practice, turning a conventional network into a Bayesian one via MC dropout can be as simple as using dropout for every layer during training AS WELL AS testing; this is equivalent to sampling from a Bernoulli distribution and provides a measure of model\u2019s certainty (consistency of predictions across sampling). It is also possible to experiment with other variational distributions.\n\nPros: It is easy to turn an existing deep net into a Bayesian one. it is faster than other techniques, and does not require an inference framework.\n\nCons: Of course, sampling at test time might be too expensive for computationally-demanding (eg real time) applications."
    },
    {
        "url": "https://medium.com/@joeDiHare/from-another-postdoc-to-autonomous-cars-381d7d8dfb63?source=user_profile---------3----------------",
        "title": "From another Postdoc to Autonomous Cars \u2013 Stefano Cosentino \u2013",
        "text": "I like to believe I wasn\u2019t the typical academic \u201cmisfit\u201d. I had published consistently (2 s.d. above average already after my PhD), I had given my own lectures, and was lucky enough to have worked with top scientists in the field for 8 years straight. \n\nSure, I still felt stupid most of the times, but this isn\u2019t unusual either for an academic.\n\nI left academia because I aspired to have three things it couldn\u2019t provide.\n\nI also wanted to be paid more, which I came to realize much after my decision had been made, but that now feels important nonetheless.\n\nMy story should resonate with other academics that long for similar goals, and so I am sharing four things I learned along the way. This journey took me from a second postdoc to a job as data scientist in about 6 months. The job I eventually landed is in AI at a Silicon Valley company that builds autonomous cars, but this post isn\u2019t about that.\n\nlisten \u2014 be interested/ing \u2014 code \u2014 fail gracefully\n\nI didn\u2019t decide I wanted to give up my career in academia overnight. It ripened slowly. While my conversion took 6 to 12 months, it brewed for much longer, and it started with \u201clistening\u201d. I went to local meetups, watched youtube and coursera lectures, and listened to a ton of podcasts.\n\nlisten \u2014 be interested/ing \u2014 code \u2014 fail gracefully\n\nHalfway through my first postdoc (in acoustics) I had a quarter life crisis. I felt I was in the wrong place, at the wrong time. Being too afraid to let people down, it didn\u2019t even cross my mind my aspirations could be worth breaking a three-year postdoc commitment. Instead, I started using every spare hour of my time to create all sorts of things outside my field of work. I made several android apps, I built websites and wearables, and became a trustee for a national charity. All those projects, even the silly ones (Oh boy, have I told you about the mirror that receives emails?) turned out to be my secret weapon in interviews.\n\nlisten \u2014 be interested/ing \u2014 code \u2014 fail gracefully\n\nAs an ML/AI engineer you are expected to code at the level of a software engineer. Raise your hand if you can code the dijkstra\u2019s algorithm to find the shortest path in a graph. I didn\u2019t even understand what this sentence meant, but there are many resources out there that can help you. Knowing what I know now, I wish somebody had said to me: Ditch matlab, use python. Teach yourself javascript, maybe C++ or JAVA, and practice on LeetCode painstakingly. There are no shortcuts.\n\nlisten \u2014 be interested/ing \u2014 code \u2014 fail gracefully\n\nInterviewing is so random. Companies are continuously walking the line between the fear of missing out on a good candidate and the dread of hiring someone who doesn\u2019t meet their bar. The result is an imperfect hiring process that will fail you more than help you.\n\nI spent a day at [insert-company-name-here] where I went through 8 interviews back to back. Before I had only interviewed once for my PhD and once for my first postdoc. Three hours total, maybe. This new interview process turned out to be a physical and emotional marathon. Days or weeks later an email would come in saying \u201c\u2026unfortunately, the ultimate decision of the team was to pass on your candidacy at this time\u201d. One failure after another, something in you breaks and rebuilds again. By failing you get stronger, better and bla, bla, bla \u2014 point is, it\u2019s rough out there for somebody switching careers, so be ready to pick yourself up a few times before learning how to walk.\n\nWhether or not this is worth it, in the end, is something you truly find out along the way.\n\nSpecial mention:\n\nJoining Insight was one of the best career choices I made. Through their AI program I met amazing people, learned a ton, and got to interview at top companies in Silicon Valley. Ask me."
    },
    {
        "url": "https://medium.com/@joeDiHare/deploy-a-django-1-10-app-to-aws-beanstalk-using-python-3-4-and-mysql-on-a-mac-a46ccee2c44?source=user_profile---------4----------------",
        "title": "Deploy a django 1.10 app to AWS beanstalk using python 3.4 and MySQL on a Mac.",
        "text": "Tutorial to accomplish what the title suggests it would accomplish.\n\nIt is heavily inspired by this post. But if you want to know why doing it, to what avail, and really, why not hiring somebody that does it for you. I can\u2019t help.\n\nAlso note. These things expire soon. LAST EDITED: Apr-2017.\n\nvenv will be the name of your folder. I have used python 3.4 because currently aws supports that. Don\u2019t use python 2 with this tutorial or things will explode.\n\nYou can get a django project from wherever, as long as it uses django 1.10 and python 3. I\u2019d suggest you use this one from codingforentrepreneurs.\n\nFirst, create the folder (src/.ebextensions) and open it:\n\nThen copy the following two files:\n\nThe first file tells aws to install the required packages for mysql.\n\nThe second file contains commands (\u201ccontainer_commands:\u201d) that tell aws to run your django app from beanstalk.\n\nThe container_commands: tell aws to migrate, create super user, and collectstatic. This works because a script to create superuser (\u2018admin\u2019, password: \u2018admin\u2019) was added here src/kirr/createsu.py (see here).\n\nThe option_settings: set (1) WSGIPath, (2) the static directory, and (3) the python path in 02_python.config to match your project\u2019s directories.\n\n(OPTIONAL) I like to see hidden folders via finders, so in my terminal I enabled it as:\n\n $ defaults write com.apple.finder AppleShowAllFiles TRUE \n\n $ killall Finder\n\nAws EBS uses git to know when something has changed. From the root directory (venv):\n\nThe -f (\u201cforce\u201d) is to ensure that hidden folders are added.\n\nWell, good luck. Let me know how it goes, and do check this post for more."
    },
    {
        "url": "https://medium.com/@joeDiHare/treasure-hunt-part-3-of-3-data-science-e4971c5525f2?source=user_profile---------5----------------",
        "title": "That time we revolutionised our traditional treasure hunt (part 3/3) ~ the data science.",
        "text": "In my two previous posts I described the premise and the technical aspects of the web app we built for a treasure hunt.\n\nThis post describes the data analysis I did afterwards.\n\nIt was a freaking success. 31 teams turned up (we had a cap at 30), 29 started the game, 20 completed all clues, 6 arrived after the end, only 3 retired. There were no clues that went missing, no glitch in the app.\n\nIn a multiple factor analysis, being the fastest to solve a cue was a good predictor of success, but not the most important. Instead, being able to complete the hunt without asking for help/solutions, which came with penalties, was the most important predictor for the final position. Unsurprisingly, the top two teams did not ask any help or solutions.\n\nBecause the paths between clues were chosen randomly, some teams had longer journeys than others. However, this advantage did not affect the performance. \n\nWe looked at correlations between total length of journey for every team and the amount of time it took them to finish the hunt. Similarly, we looked also at the travel time predicted using google map API. Correlation were all small, negative, and statistically not significant. That said, the winner of the caccia did have a journey that was 1.2 s.d. lower than average.\n\n2 minutes 47 seconds. This includes scanning a QR code, reading the clue, solving it, driving to the place, finding the QR there and scanning it. Not bad. Or maybe, some of the clues were too easy.\n\nThe winner completed the hunt solving the 13 clues at an average pace of 8m6s per clue. Pretty impressive. The average pace was 12 minutes per clue, and the slowest scored an equally impressive 21m7s per cue.\n\nMore you say? Here is an infographics of the caccia:"
    },
    {
        "url": "https://medium.com/@joeDiHare/treasure-hunt-part-2-of-3-b2a36847639a?source=user_profile---------6----------------",
        "title": "That time we revolutionised our traditional treasure hunt (part 2/3) ~ the web app.",
        "text": "In my previous post I described the premise that lead me to build the web app for a treasure hunt.\n\nThis post describes the technical bits of the app (pretty high nerdiness level).\n\nI used the following languages/skills:\n\nJAVASCRIPT\n\nHTML/CSS\n\nMATLAB\n\nPYTHON\n\nThing is, I am not a full blown expert at any of these. But I am curious and I learn quickly. All of my code is publicly available on github.\n\nThis was written using a single html file (index_cacciatorre16.html) and a bunch of individual javascript files to handle the logic. It was hosted on the public space of my domain (www.guhu.website).\n\nThe QR code contains the link above with a parameter identifying the place where the code was hidden. E.g.:\n\nThe javascript code would ask for a password, then find a match in a look-up table, and eventually display the appropriate information:\n\nEvery user response was logged. This included:\n\nAll this information was logged in Spreadsheets using a service called Sheetsu. Sheetsu provides an interface with the google API where I can easily use the spreadsheet as a database without any SQL. \n\nHandy, and fairly cheap: $12.\n\nThe clue might have been in a place with slow connection. Therefore, for the app to work smoothly, I had to reduce the size of files to its bone.\n\nI stripped down all the unnecessary bits and set the browser leverage so that most files were saved on the first connection to the server. I checked the performance with Google PageSpeed. I received thumbs up.\n\nWhile the teams were out playing the game, I needed to be able to check their progress to\n\n- monitor if there was a problem (e.g. many teams all stuck on the same cue).\n\n- Find out of possible sabotaging.\n\n- Know every team\u2019s score, so to easily compute the final score & the winner.\n\nThis is what the CMS looked like."
    },
    {
        "url": "https://medium.com/@joeDiHare/treasure-hunt-part-1-of-3-3c6fe9112bd2?source=user_profile---------7----------------",
        "title": "That time we revolutionised our traditional treasure hunt (part 1/3) ~ the story",
        "text": "Christmas traditions are an important element of where I am from . The big meals with family, the odd uncle that asks you\u2019re married yet?, the gift of a pair of socks. In this suburb of Naples where I am from, Torre del Greco, there\u2019s also another tradition that is only 10 years old. We call it \u2018la caccia\u2019, and it\u2019s a treasure hunt on St. Stephen\u2019s day.\n\nIt\u2019s a terrific event where hundreds of people gather in teams and drive around the city for hours solving puzzles and collecting clues that will eventually lead to the treasure: \n\n1) a table game that is the same every year, \n\n2) champaign bottles to celebrate with everyone, and \n\n3) fame.\n\nLast year it was the 10th edition and our team came first. It was a great night. We celebrated for days and spoke about if for months and months. And when we stopped, we started talking about the caccia that was to come. It was the long chased opportunity to do it our way, and we wanted to organise the best caccia ever. \n\nTo me, a scientist and an engineer who had left his small hometown 8 years before, this meant doing something the grinch himself would have said \u201cdude, maybe it\u2019s too far\u201d: bring a tech revolution into our very traditional, Christmas treasure hunt.\n\nThis is the first of a 3-part post describing the challenges we faced (part I), the solution that was built (part II), and the data science that came out of it (part III).\n\nA treasure hunt has M teams and N clues that lead to N places. You only solve one clue at the time to \u2018unlock\u2019 the clue for the next place. In our case, we had M=30 different teams and N=13 places/clues. Since every team has a different path, with the traditional method we needed M different envelopes for every places: it\u2019s like more than 300 envelopes and paper sheets. There\u2019s got to be a better way to do it \u2014 I thought.\n\nAs the caccia grew bigger in participation, one huge problem started happening more and more: at some point during the hunt, clues would go missing. This would happen if envelopes were moved; sometimes unintentionally (e.g. cleaners sweeping), other times it was the result of a sabotage. Plus, the system had a huge caveat: because in every place there were envelopes for all the teams, containing different clues depending on the individual path, a team could cheat by opening the envelopes of different teams.\n\nTorre del greco is too big to be a village, and too small to be a city. It\u2019s still a very conservative place in the south of Italy. How do I simply make a ten-year-old game run on a smartphone? Is this going to take away part of the fun? Would people understand the benefits? Would the software work as expected?\n\nThis are the key points of the software I designed.\n\nHence I built a web app. Whenever a team solved a puzzle and reached the place, they would find a new QR code. After scanning it with their phone the appropriate next clue would be displayed on the screen (see Fig below).\n\nIt didn\u2019t stop there. There were more features:"
    },
    {
        "url": "https://medium.com/@joeDiHare/why-logging-my-morning-banana-was-important-as-a-data-scientist-working-with-fitbug-860028e34fac?source=user_profile---------8----------------",
        "title": "Why logging my morning banana was important as a data scientist working with Fitbug",
        "text": "Fitbug is a company in the health & fitness sector \u2014 just like Fitbit. Both companies make fitness trackers that count steps and other things.\n\nBut, unlike other companies, Fitbug is focusing on a mobile app (\u201ckiqplan\u201d) that combines data from all kind of fitness trackers, such as Nike fuelband, Jawbone, Samsung Health and what not. More importantly, their business model is shifting towards a B2B where large companies buy subscriptions for their employees. The employees use the app, get fit, healthy; and everyone\u2019s happy.\n\nIn an industry where decent fitness trackers are being sold for as little as 15$, a B2B strategy makes sense.\n\nWhen I got at Fitbug, as one in a team of 4 data scientists via Pivigo, the repositioning of the company played a central role in planning our first move in the project: navigating the database containing decades of user data to understand what had and hadn\u2019t worked, and generate insights that could influence the product development going forward. \n\nThis post summarises one of the deliverables that were produced.\n\nBut first, one quick warning about the content of this post. When you gather 4 data scientists, and let them talk for long enough, Godwin\u2019s Law adapted to data science would predict that two magic words start recurring:\n\nWell, my warning is that this post does not describe any fancy machine learning, and it is for a simple reason:\n\nInstead, we ended up developing a tool to track the performance of the kiqplan app.\n\nLet me motivate this choice using my own data, as a user of the app.\n\nThe graphs tells how often I used the app to log things like meals or gym sessions. Note: week 1 to 5 on the x-axis refers to the time we spent at Fitbug working on this project.\n\nA voice over would narrate it like this:\n\n\u201cHe installed the app in October for the first time. Didn\u2019t know what to do at first, but started to enter basic information in week 1. Mid-week 1, he started logging in meals, activity, and mood. You can see he\u2019s started a fitness challenge and he\u2019s liking using the app very much.\n\nBy week 2 he is in love with the app and the concept. He is convinced this is going to be his life from now on. He\u2019d continue to log in like crazy, get fit, monitor his health. He feels good.\u201d"
    },
    {
        "url": "https://medium.com/@joeDiHare/https-medium-com-joedihare-pewresearchcenter-8f7ac6c99272?source=user_profile---------9----------------",
        "title": "A nonlinear model to answer two questions from the data set \u201cWeb IQ, Productivity, Being Informed\u2026",
        "text": "The report following the dataset \u201cWeb IQ, Productivity, Being Informed (Sept. 12\u201318, 2014)\u201d[Pew Research Center, 1] describes some statistics of internet users, and the role that digital technology is reported to have on their work lives. \n\nOf particular interest is the comparison between \u201coffice-based\u201d and \u201cnon-office-based\u201d workers and how their productivity is affected by internet usage.\n\nWhile many key points are already addressed with parametric statistics, two additional questions could be used harnessing machine learning:\n\ni) Is there anything distinctive in the way \u2018office-based\u2019 and \u2018non-office-based\u2019 employee respond to this questionnaire?\n\nii) What happens to productivity when employers restrict access to certain websites?\n\nAnswering the first question is a matter of capturing the structure in the data and see what factors are important to group the employees\u2019 answers as being from office- or non-office-based. Given the nature of the dataset (survey\u2019s data), a Random Forest could be a good place to start (Nr.Trees = 15). This model should tell us if there is a trend\n\nData preparation included the dismissal of responses from non-employed users. Data normalisation and regularization were not necessary with the chosen approach. The partition for the training and testing datasets was 90\u201325%, with a 15% overlap to make up for the small number of data points. This choice isn\u2019t best practice considering the class of non-linear model chosen (tree bagger) as it can lead to overfitting \u2014 yet, let\u2019s go ahead for the purposes of this investigation.\n\nLet me explain what this means. Since one can predict from all other answers if a user is office-based or not, we\u2019ve partially answered whether these two groups responded significantly differently in the questionnaire. They do, and we\u2019re saying this with an accuracy of 82.6%. But we haven\u2019t quite answered which features are more important. \n\nSeveral approaches could be pursued at this stage (e.g. PCA or correlation coefficients), but the accuracy of our non-linear model suggests we can infer the importance of each feature from the increase in prediction error at each feature permutation. Features that don\u2019t affect the prediction error when permuted are less important, and can be neglected by the model. The permutation analysis reveal that using as few as 20 features (a reduction in dimensionality of about 4!) is enough to maintain good classification performance. \n\nUltimately, this is what we learned from looking into the 20-feature subset:\n\nSome of the factors that predict office and non-office based workers are collinear, such as answering Q6a (\u201cHow often, do you work outside your workplace?\u201d). In other cases, there might be an intuitive connection between working remotely and, for instance, answering Q9 (\u201cHow important is a landline phone to your job?\u201d). In other cases the relationship is less intuitive, such as answering whether or not Moore\u2019s Law applies to transistors (Q39). (=> if you say yes, then you probably work at home more).\n\nOverall, while these features alone are poor predictors, they can be used successfully in the nonlinear model described above for classification of office/non-office based workers.\n\nFinding an answer to the second question (the effect of internet restrictions on productivity at work) is perhaps harder. This is mostly due to the self-reported nature of the data, especially in evaluating productivity, and partially due to non-specificity of the questions. \n\nResponses were analysed from three questions in the survey that could possibly share causality. The questions are (paraphrasing):\n\nThese responses were used to reveal possible differences between two groups: i) those whose employers apply restricted access to certain websites at work (in green), and ii) those whose employers do not (in grey) (from Q15: Does your company block your access to certain websites while you are at work?).\n\nWhile Q7 does not show any significant group difference in the importance of internet for work, Q14 reveals a statistically significant prevalence of respondents in the internet-restricted category saying that yes, internet is very important when working remotely (Fisher\u2019s test, p<0.01). Conversely, those who do not have internet restrictions at work, find internet less essential when working remotely.\n\nRemarkably, however, this has no effect on (self-reported) productivity (Q26) for either group (cf figure to the left).\n\nIf one was rushed to summarize this in a sentence, it could be that restricting internet access at work does not affect productivity, and it may make remote work more reliant on internet. Perhaps because remote work is unrestricted.\n\n(Slight caveat: these differences could arise from the job typology, whereby those who work at home have also fewer reasons to be subject to internet restrictions, e.g. in the case of freelancers. And this is why one should never rush to unsubstantiated conclusions\u2026)."
    },
    {
        "url": "https://medium.com/@joeDiHare/https-medium-com-joedihare-every-olympic-event-should-include-one-average-person-competing-for-reference-8abce5fb1b1e?source=user_profile---------10----------------",
        "title": "Re: Every Olympic event should include one average person competing for reference.",
        "text": "American gymnast Simone Biles enchants with her sublime technique and strength, fastest man on Earth Usain Bolt has won again the 100 m sprint, and swimmer Michael Phelps has collected his 23rd gold medal in career (or, differently put, Michael Phelps\u2019s COUNTRY has just reached 36th position in all-time gold medals).\n\nAs the Olympic Games draw to a close and I have watched loads of athletes doing extraordinary things on TV (many of which I never thought possible or desirable), web\u2019s recent viral quote comes to mind:\n\nWhat Bolt did right there, looked amazing, but just how precise his arm swinging was\u2014 remains somewhat unclear.\n\nIf Dave, 27 year old barber from Essex, were there racing shoulder-to-shoulder with the gold medallist \u2014 we\u2019d finally get it.\n\nPowered by a passion for data science that gets inexplicably stronger with the futility of the problem, I started asking Google about average sprinters, swimmers, jumpers and whatnot. I hoped to find data from, say, a fitness app like Nike+ that I could compare with scores from pros; but an evening of searching left me empty handed and I considered abandoning the project.\n\nThen, the average but Olympic Ethiopian swimmer Robel Habte started racing, and I knew I had to pursue my quest for comparison. Ultimately, I focused my efforts on one discipline, the 100 metre sprint, and opted for an alternative approach to compare Bolt\u2019s and Dave\u2019s performance using nothing more than a set of assumptions and some questionable math.\n\nLet\u2019s start from Bolt\u2019s most recent result: completing the 100 m dash in 9.81 seconds.\n\nHow quickly can the average man run 100 metres?\n\nI needed to make an assumption on the type of distribution underlying population performance. A common one is to use a \u2018normal distribution\u2019 \u2014 the bell curve reflecting the assumption that most people score in the middle, some will be very good, some very bad.\n\nTo characterise this curve one needs a mean (the centre of the bell curve) and a standard deviation (sd, the width). The mean is Dave\u2019s performance, which is unknown, but I will try to infer it using as much as ONE point on this curve (and a *cough* arbitrary *cough* choice of the sd).\n\nThe one point being Bolt\u2019s 9.81 seconds.\n\nThis is how.\n\nFirst, we need to know the probability of Usain being who he is in this competition: the number one in the world. Back to Google \u2014 how many average runners exist that Usain would beat in a competition?\n\nRoughly, there are 945 million (male) people aged between 20 and 35. Outside this range wouldn\u2019t be the \u201caverage Dave\u201d anymore. From this number we\u2019ll drop half assuming that only every other individual is \u2018run-able\u2019, and could have had an opportunity to compete (and maybe beat) Usain.\n\nThe probability of Bolt being Bolt is then\n\nI now have one point on this curve, and I can estimate how far Bolt is from the mean using inverse cdf(x). That distance turns out to be 5.87 sd. \n\nA lot. \n\nFor sake of comparison, in medicine a sd of 2 is often used to diagnose pathological cases from just-a-little-weird-but-OK cases.\n\nThe mean of the bell curve can be estimated as being 5.87 sd away from the performance value obtained by Mr. Bolt. This leads to 15.68 s.\n\nConclusion: the average man racing with the big guys would have arrived about 5.5 seconds after most professional runners in Rio.\n\nAnd here you go, the plot I was after all along:"
    },
    {
        "url": "https://medium.com/@joeDiHare/actionable-metrics-for-working-out-that-thing-others-seem-to-successfully-achieve-when-hitting-the-8e5897466a52?source=user_profile---------11----------------",
        "title": "Actionable metrics for working out. \u2013 Stefano Cosentino \u2013",
        "text": "My friend does (hot, power) yoga, he\u2019s toned and when my abs meet his abs, mine want to crawl up in the fetal position under my tummy. He works out almost every day and he enjoys what he does. Good for him.\n\nAt some point last year, I decided it was time to catch up. It was doing okay, and for some time I hit the gym just as much, toned up a little, and nearly decided to tattoo my side arm. But there is a difference between me and him which will always keep me lagging behind: he likes working out, at least to some extent. I don\u2019t.\n\nI am a calm, rational, reassuring person; who simply loses his temper when working out. All sorts of negative thoughts run through my mind: \u201cOur body is not meant to be pushed to the limits like this!\u201d \u2014 \u201cYou\u2019re doing this just for narcissism!\u201d \u2014 \u201cOh, you\u2019ve been conditioned by society, you puppet\u201d. And so on. There is nothing in the process of working out, as is, that I enjoy.\n\nI am now thinking \u2014 is there a way, for me, to fix this?\n\nIn my ordinary, non-aggressive, non-working-out life, I am a scientist and developer. I enjoy a lot of things, but those that stuck with me are those that embody a simple principle, beautifully put by Bret Victor: being able to see the effect of my actions and improve upon them.\n\nWouldn\u2019t it be great if, at every stroke I make, every squat, I could see how my body is moving and improving? There are many bio signals that can be recorded from the body, and we\u2019ve only been looking at few, non actionable ones\u2014 like heart rate or number of steps.\n\nCouldn\u2019t we measure myogenic potentials with simple bands around the muscles I am training? These measurements would correlate with muscle fibres being recruited during workout, and possibly indicate strength on a day-to-day bases. Oh, and what about the chemical sensors? One could target specific hormones \u2014 this stuff is really cool. If I could see what I am doing, see those little improvements, maybe I\u2019d enjoy what I\u2019m doing.\n\nI\u2019m not saying that the standard way of exercising is broken, but it doesn\u2019t work for all. This short rant was my suggestion on how it could be improved using technology and basic physiology."
    }
]