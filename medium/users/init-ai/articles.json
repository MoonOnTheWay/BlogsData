[
    {
        "url": "https://blog.init.ai/tutorial-building-a-conversational-booking-bot-with-init-ai-and-acuity-scheduling-e717df35adf6?source=---------0",
        "title": "Tutorial: \u200bBuilding a Conversational Booking Bot with Init.ai and Acuity Scheduling",
        "text": "We\u2019ll be building a conversational chat bot for Lego Party\u2019s Facebook page to handle the two most common scheduling tasks for clients:\n\nWe\u2019ll need both an Acuity Scheduling account and an Init.ai account (no credit cards required!). Acuity Scheduling is an online appointment scheduler with all the bells and whistles Lego Party needs, as well as a developer friendly scheduling API for checking upcoming classes and creating new bookings. Init.ai\u2019s a developer platform for building conversational apps powered by Natural Language Processing, with direct integration to Facebook Messenger.\n\nThe application itself will consist of a single server component written in Node.js using Acuity\u2019s SDK, Init.ai\u2019s SDK, Moment.js and a sample app from Init.ai. And we\u2019ll be building it to do this:\n\nGet started with Acuity Scheduling by signing up for a free trial here. Feel free to poke around! But for this project we\u2019ll need some classes, so don\u2019t leave without creating a couple \u201cClass\u201d appointment types, and be sure to offer a few sessions for each class. Here\u2019s the upcoming class schedule folks see when they visit my client scheduling page:\n\nOnce you have your classes set up, have a quick look at the scheduling APIs we\u2019ll be integrating:\n\nInit.ai is in a free beta \u2014 signup only requires a GitHub account. After signing up, create a new Project for Class Bookings. The complexity of dealing with the Init.ai is abstracted away nicely by their SDK so I won\u2019t focus on that here. Instead, there are a couple key concepts to keep in mind for the implementation:\n\nThe first step in a new project is to create some training language \u2014 the more the better! Init.ai has a simple markup language for the task. Here\u2019s an example:\n\nA user kicks off a conversation, and the service makes a reply. An intent, marked with an asterisk, follows each message, eg. . And entities, marked with brackets and followed by it's optional type and a name in parentheses, are defined inside messages eg. .\n\nFor this project, you can find example training conversations in the github project. Add those to your new Init.ai project and Init.ai will automatically populate a list of intents and entities for you. Then just click \u201cTrain your model\u201d in the main menu and Init.ai will build the model to power the application. That\u2019ll take a few minutes, but we can carry on in the meantime!\n\nFinally under Settings, connect a messanging plugin. Init.ai has a built in \u201ctest\u201d messenger you can find in the bottom right-hand corner of your Init.ai console. For this project we\u2019ll use Facebook Messenger, which supports a couple extra features that the test messenger doesn\u2019t. First you\u2019ll need a Facebook page \u2014 you can create a new one here for testing \u2014 then enable the Facebook Messenger connection.\n\nFor the rest of this project you\u2019ll interact with your chatbot through the Facebook Messenger. As soon as your Facebook page is connected, we\u2019ll start the server and build our application.\n\nNow we\u2019re ready to dive into the code. First, we\u2019ll start up the server.\n\nWe\u2019ll be starting with a sample project Init.ai has put together. Clone that repository to get started:\n\nNow install base modules, and the couple additional modules we\u2019ll be using:\n\nWe\u2019re almost ready to start the dev server. First, grab your Acuity user ID and API key from Business Settings \u2014 Integrations. We\u2019ll pass those into our server\u2019s environment now because we\u2019ll need them in a minute.\n\nThen, to start the server run:\n\nOur dev server will start a \u201cwebhook\u201d tunnel to receive messages from Init.ai:\n\nJust copy and paste that webhook into Settings under Webhooks in your Init.ai project. Note: Each time you restart the dev server, you\u2019ll need to update that webhook URL in your project settings!\n\nThis sample application contains a bit of boilerplate code that\u2019s worth checking out, but everything we\u2019ll need to edit is in a single file: . Code in this module will be executed each time we receive an event (eg. a message) from Init.ai through the webhook tunnel started by the server.\n\nFirst things first, include the modules and a bit of config that we\u2019ll be working with:\n\nThis module itself exports a function which is run for each message we receive through Init.ai, and returns a promise:\n\nA lot of our service\u2019s intents are asynchronous, and will gather data from Acuity\u2019s API \u2014 Init.ai\u2019s SDK is built to help with this type of asynchronous task. In the promise body, create instances of the Acuity and Init.ai SDKs:\n\nEach edit we make to this file triggers the development server to reload. Our Acuity credentials are already in the server\u2019s environment from when we started the server, so we\u2019re good to go! Now we can write the logic for the two conversation tasks:\n\nConversations in Init.ai are controlled by a flow. Tasks for a particular conversation, such as \u201cbook a class\u201d or \u201ccheck bookings\u201d, are called streams. Each stream can have multiple steps such as getEmailAddress. And each step usually corresponds to a pair of question-answer intents, processing the entities from a message to store data, request new data, etc.\n\nAll of this is set up in the method, the main entry point for our Init.ai conversation logic. Add this down to the bottom of and then we'll fill in the steps above it:\n\nOur two conversation types, or streams, are and . Most people will book a class before they check their bookings, so we define that as the default stream using the attribute. The attribute lets us map other intents to specific streams. In our case, we'll map the intent to the stream.\n\nNow we\u2019ll define our first step: . Add this step above the call to :\n\nEach step has a few different pieces. In our application, we\u2019ll be using , and . The method takes any entities and other data extracted from a message and decides what to do with them. Irregardless of where we are in a conversation, is run for each step when any message is received. Chatters can provide info in an unexpected order, or provide info for multiple steps all at once, but each step should only concern itself with that step's entities.\n\nExecution continues and decides which stream we're in. Steps for the current stream are executed in order, and is called. If the step has everything it needs and can be considered complete, should return true. For the first step that is not satisfied, the method is called and execution finishes.\n\nIn our first step, we\u2019re extracting an appointment type from the response (hopefully!) \u2014\n\nreturns structured data from pre-defined replies in a prompt \u2014 we'll cover that in a minute. If we've received an appointment type ID, store it in the conversation state, akin to a session in a web application.\n\nThis step is considered satisfied once we have an stored.\n\nIf it\u2019s not satisfied, will be called. We'll fetch a list of appointment types from the Acuity API, filter it for public classes, and send a reply with those options to the chatter.\n\nA nice feature of the Facebook Messenger is the ability to create convenient reply buttons for the user.\n\nOur appointment type prompt creates a button for each class which displays the class name, and has the stored. When the user selects a button, we'll receive a reply with that data from that method called in .\n\nThe service\u2019s reply is defined with , sending the intent and the class buttons:\n\nLast of all is called. We made an asynchronous request to the Acuity API. resolves the promise, and the service ships the response back to the user.\n\nOur next step is to pick a particular class session. Similar to appointment types, we\u2019ll grab available class sessions from the Acuity API and provide a list of convenient buttons to choose from. We\u2019ll extract the session from the postback data and satisfy the step once the datetime is saved:\n\nFor fetching the session info from Acuity, we\u2019ll use the endpoint for the current month and the selected appointment type from the first step.\n\nUnlike the previous two steps which extract info from the user\u2019s button choice, grabs the email entity directly from the client's message using . This step is also shared \u2014 it is used in both the stream and the stream.\n\nThe prompt for this step sets an expectation if we\u2019re not in the default stream:\n\nSince is shared between multiple streams, that serves as a hint that reply should provide an e-mail address and should be part of the current stream (eg. ).\n\nNow we\u2019re ready to collect the user\u2019s name. Another benefit of using the Facebook Messenger connection is that it\u2019s aware of the user\u2019s Facebook profile, including their name. We can grab that with and automatically store it to the conversation state.\n\nJust in case it\u2019s not available, our training data contains an intent to prompt the user for their name.\n\nFinally we\u2019ve got what we need to book an appointment:\n\nThis step won\u2019t contain an step since we're not looking for anything else from the user and the method returns false since it's the last step. To book the class, the method will call Acuity's API with the client info we've been collecting in the conversation state:\n\nAfter creating the booking, we can clear out the for this booking. This resets things for the user, allowing them to book another class or check their upcoming bookings:\n\nLast, we\u2019ll send a response to the client letting them know the appointment is confirmed. The second argument for is a map of entities for the intent to include in the message to the client. In this case, we'll want to echo the class name and time back to the client in the confirmation message:\n\nHere\u2019s the full listing for the step:\n\nWith these steps implemented, you\u2019ll be able to interact with the booking bot through Facebook Messenger and schedule an appointment: https://www.messenger.com/\n\nOnce a couple appointments are scheduled, it\u2019s time to implement the stream to check existing bookings. To keep things simple we'll look up a user's schedule by their e-mail address, reusing the step. After we have a client's email, there's only one more step: to provide the user with their upcoming schedule.\n\nWe\u2019ll use Acuity\u2019s API along with two parameters: and , set to now:\n\nIn the response, we\u2019ll check if there are any upcoming appointments and decide which response intent to send to the client:\n\nIf there are any upcoming appointments matching the email address, we\u2019ll format them into a list for the response. First, sort them in chronological order then format them into a list with one session on each line. Similar to the confirmation step in the stream, we'll provide that data for the response entities:\n\nJust before calling we'll clear the expected stream with . This resets the hint set in , allowing the client to enter a different stream such as booking another class after checking their schedule. Here's the complete listing for our final step:\n\nNow that that\u2019s implemented, we can check our schedule:\n\nWell, this article didn\u2019t write itself! But Conversational AI has come a long way, and today is more dev-friendly than ever. Creating a bot that performs well for the two tasks I gave it \u2014 that\u2019s not bad for an afternoon!\n\nYou can find the full source code for this project on github. From there, there are two major improvements that can be made:\n\nPlugging a conversational interface into existing APIs such as Acuity Scheduling is already a practical way to bring useful conversational functionality to other apps such as Facebook Messenger. From here, it\u2019ll only get better!"
    },
    {
        "url": "https://blog.init.ai/how-to-add-intelligence-to-cx-so-that-you-thrive-fbffbf0becfd?source=---------1",
        "title": "How to add intelligence to CX so that you thrive \u2013",
        "text": "How to add intelligence to CX so that you thrive\n\nAirlines are in the news a lot lately and they can teach us a lot about what you should (and shouldn\u2019t) do when it comes to CX (customer experience).\n\nDo you have an airline that you prefer to fly? On any given day I can fly a multitude of airlines, and price dictates the carrier. But occasionally if the stars align, and pricing isn\u2019t too bad, I get to fly certain airlines where the experience is better (or more fun). Perhaps they give me snacks, let me stream movies, have decent seats, etc.\n\nAnd I will do whatever I can to avoid flying on airlines where short of tagging my ear for processing, they\u2019ve done all they can to dehumanize me. The planes can be relatively similar, pricing can be lower, but that experience is so bad that I will gladly pay to avoid it. And, unfortunately, the bad experiences are so pronounced that I may not fly that airline ever again. Companies are aware of how bad interactions are detrimental to brand loyalty and are looking for technology to help agents avoid mistakes when chatting with customers."
    },
    {
        "url": "https://blog.init.ai/init-ai-partners-with-kustomer-to-provide-intelligence-for-their-service-crm-f29faea8b014?source=---------2",
        "title": "Init.ai partners with Kustomer to provide intelligence for their Service CRM",
        "text": "Init.ai, the leading provider of intelligence solutions to high-touch businesses as they scale announces a partnership and integration with Kustomer, a leader in CRM for support teams.\n\nYou can now seamlessly utilize the powerful deep-learning capabilities of Init.ai to deliver a better, faster, and more consistent customer experience from directly inside the Kustomer platform. Their platform unifies customers information \u2014 conversations, custom objects and tracking events \u2014 into an interface designed to make it simple for support teams to provide higher quality, more efficient customer service.\n\nThe partnership between the companies opens up the ability for Init.ai customers to improve the insight and service they deliver to their customers. Customers can leverage the Init.ai intelligence functionality with the rich data and support capabilities of the Kustomer platform to deliver a personalized experience, improve agent workflows, and scale customer conversations so that support team members can deliver high touch service to more customers.\n\nCompanies can now deliver enhanced productivity for support teams via Init.ai + Kustomer, including custom objects and workflows tailored to your business needs. The Kustomer integration enables Init.ai customers to:\n\nSupport teams need to provide seamless, timely, and highly personalized customer service while also managing an exploding number of touchpoints and applications that do not have a central hub for information and action. Kustomer is a CRM that unifies customer information into a timeline-based dashboard for support teams to communicate with customers across channels, view a customer\u2019s history, and transaction through third-party systems like Shopify and Slack.\n\nThe new Init.ai integration with Kustomer is available upon approval, and companies interested in learning more can contact the Init.ai team at sales@init.ai.\n\nAbout Init.ai Init.ai is a deep learning solution that helps you provide a better and more consistent customer experience. The cutting-edge NLP and extensible tooling offer powerful functionality and seamless integrations with CRMs and messaging and live chat providers to empower sales and service teams to scale personalized, real-time conversations with customers. The company is backed by top investors including: Boldstart Ventures, Techstars, Valence Ventures, and Esther Dyson. Visit www.init.ai to learn more.\n\nAbout Kustomer Kustomer is the leading CRM for support teams and provides everything needed to serve customers better. This includes a behavioral customer dashboard, agent intelligence and custom features including objects and workflows. Founded by the team that built Assistly, which was sold to Salesforce and became Desk.com, the company is backed by Canaan Partners, Boldstart Ventures, Social Leverage and BoxGroup."
    },
    {
        "url": "https://blog.init.ai/init-api-f9e22499ca06?source=---------3",
        "title": "Introducing: the Init.ai API and self hosting \ud83c\udf81 \u2013",
        "text": "In classic startup style, we are kicking off 2017 with a feature release!\n\nOur mission is to provide the best possible tools to help companies use natural language to serve their customers.\n\nDevelopers are an important part of how we help companies help their customers, and today we are taking a big step forward in developer experience with the release of two highly requested features:\n\nAs a developer I get giddy when a service releases an API, because an API means the power, flexibility, and freedom and to use a product exactly how and where you want. These two exemplify that by combining to add substantial flexibility to the Init.ai platform. You can now:\n\nUltimately our goal is to make the entire Init.ai suite of tools available via APIs, but we are starting with the essentials: the Remote API. We call this set of endpoints the Remote API because because these are what a remote server uses to manage users and conversations within a running Init.ai application.\n\nThe API is available over HTTPS and speaks JSON. Here are the docs: https://docs.init.ai/reference.\n\nConversational applications consist of many moving pieces, from messaging connections, to machine learning models, to programatic code that connects to other services and manages the interaction.\n\nUntil today, Init.ai always hosted your application\u2019s business logic in an isolated environment managed automatically for you. While this makes it easy to get up and running, for some companies this introduces overhead in how to connect their conversational application to existing systems running on their own servers.\n\nNow companies using Init.ai have the option to host application business logic in their own AWS account, on Heroku, in their own datacenter, or any other location available to receive HTTPS webhooks.\n\nAs messages and events are received:"
    },
    {
        "url": "https://blog.init.ai/init-ai-a-platform-for-conversation-a1b8a2c885c9?source=---------4",
        "title": "Init.ai: a platform for conversation \ud83d\udcac\ud83c\udf89 \u2013",
        "text": "Init.ai is a set of APIs and tools that work together to make creating sophisticated conversational applications simple.\n\nWe have spoken with many companies across many verticals, and we had a clear take-away: the conversational-apps that offer really great, impactful user experience will be built by companies who take the task seriously and use serious tools to do it.\n\nInit.ai supports a modern software development workflow: it\u2019s extensible, every part of an application can be tracked in version control, and it\u2019s designed for collaboration between colleagues. (Yes, testing is coming too.)\n\nWe have not built a visual, tree-like editor into Init.ai. We could, but so far the experiences created by tools like that have not been robust. Conversation is generally more nuanced than a decision tree, and our ultimate goal is to move in the direction of fluid interaction. Visual programming tools have been tried for decades yet have not made an impact except in limited, lower-value use cases. We are skeptical of applying the same concepts to conversation because conversational interaction is even harder than most ordinary programming tasks.\n\nInit.ai is built around conversation. We think about that term very holistically \u2014 a conversation is a sequence of messages over chat or voice and can include text, images, and events. And we built all our tooling conversation first.\n\nCreating a conversational application by focusing on actual, back-and-forth interactions ultimately means better user experience. It forces the application creator to focus on the experience the user actually sees.\n\nFor training, we do offer a visual interface \u2014 and it\u2019s simple to use \u2014 but it\u2019s backed by all the power expected of a developer platform. In fact, this tool writes human-readable training data files that you can later edit, and the way you re-train your language model is via a Git push.\n\nWhen you push your repository, we deploy your code to a hosted environment and we send your example language data to a set of GPUs that train a neural network specifically for your application.\n\nOn the NLP side, we\u2019re doing something interesting. Init.ai can determine the different meanings between \u201ccool\u201d in this conversation, solely based on conversational context."
    },
    {
        "url": "https://blog.init.ai/pick-your-platform-wisely-c5ab5bc7555d?source=---------5",
        "title": "11 best messaging platforms for your chatbot or conversational app",
        "text": "From WhatsApp to Telegram to WeChat to Kik to Facebook Messenger, each messaging platform takes its own approach to servings its users. Their interfaces, capabilities, and focus all subtly vary. Each has its own user base with distinct demographics who are receptive to different types of products and experiences.\n\nBuilding a successful conversational app, service, or bot on messaging requires understanding the users of each platform, from their key demographics to their reason for using the service. But with so many messaging platforms and such variety in capabilities and approaches, it can be difficult to understand where to launch your next big hit.\n\n\u201cIf you build it they will come\u201d is not a good strategy with bots and conversational interfaces. To get traction, it\u2019s important to understand your target customers and their needs. That means thinking about how to solve their problems most efficiently and then figuring out how and where to deliver that solution.\n\nFor many use cases, the popular answer right now is to serve customers though messaging. But first you need to pick which messaging platforms to target.\n\nThe messaging platforms vary in several key ways:\n\nSlack is first and foremost a workplace communication tool. However, its elegant user interface and client apps has allowed it to be used for customer support, online communities, and in some cases even communication between social groups from the real world.\n\nIn many ways, Slack has become one of the most misunderstood and misused-by-developers platforms.\n\nSlack has been very forward about having an open platform and has welcomed bots for quite some time. As one of early messaging channels to both support bots and become popular in the USA and Europe, it has served as a test bed for many types of bots.\n\nMany companies have been so eager to introduce bots to their customers that they have even ventured beyond Slack\u2019s core userbase \u2014 people at work \u2014 to offer services that are more personal and consumer focused.\n\nThe problem is, Slack isn\u2019t always the best place for some of those services. Shopping for shoes or checking your personal finances via a bot on Slack doesn\u2019t really make sense \u2014 those should probably be on consumer messaging channels.\n\nDemographics: Mixed, but mostly people at work\n\nInteresting capabilities: Primarily oriented around channels and groups, not one-on-one communication, although direct messages are a major feature. Limited but support of buttons.\n\nHow to approach: Focus on doing things that are useful for Slack\u2019s users, who are primarily at work. Slack might not be the best place for entertainment bots, personal finance tools, and non-work related uses, but it\u2019s great for getting work done.\n\nInteresting fact: Slack has a venture fund investing in companies enabling bots on its platform. Slack itself has started to invest in language processing technology as well.\n\nFacebook Messenger has exploded in the United States in terms of mindshare in the bot space. Messenger recently crossed 1 billion users across every part of the world. Messenger is unique in that has a unique connection to Facebook itself, which is still the the dominant social networking platform globally.\n\nMessenger is being used primarily for promotional, entertainment, and information purposes right now. However, Facebook has the potential to make it easy to monetize direct services and e-commerce transactions, through integration with Facebook\u2019s payment system.\n\nInteractions on Messenger are a hybrid right now. \u201cStructured messages\u201d \u2014 lists of images with buttons \u2014 are critical for giving a good user experience right now. But Facebook as a company is investing heavily in machine learning, though its research group and its acquisition Wit.ai, and it is likely that eventually natural language will play a bigger role in automated Messenger experiences.\n\nGeography: Developed countries like the US, Canada, and Europe, but Facebook itself is popular globally\n\nMessaging capabilities: User-to-user. Bots and conversational apps are not allowed in groups right now. Structured messages like carousels are recommended by Facebook.\n\nNotes: Messaging with business is done via messaging with Facebook Pages, and a presence on Facebook goes hand-in-hand with a presence on Messenger\n\nHow to approach: Messenger is a great place for consumer-focused applications, especially in North America. For now, judicious use structured messages will deliver the best user experience, but as conversational tools get better this will change.\n\nWhatsApp is the dominant app in the green countries in the map above. That\u2019s most of the world!\n\nWhatsApp is one of the largest messaging platforms and has been the most popular messaging platform in the majority of countries in the world for quite some time.\n\nIt has historically been much more popular in developing countries, since its original value proposition was as a replacement to expensive SMS. WhatsApp is owned by Facebook, and together with Messenger, gives Facebook dominant coverage of messaging in most countries in the world.\n\nWhatsApp is not open to bots or conversational apps yet, but there is speculation it is coming soon.\n\nGeography: Developing countries and those in developed countries with whom they communicate\n\nHow to approach: WhatsApp is not open to bots yet. When it does open, keep in mind its primary audience \u2014 people in developing countries \u2014 and focus on their needs.\n\nKik is new cool new kid on the block.\n\nKik has become a phenomenon among young Americans. Its target audience is ripe for influence, but short on money.\n\nIf you\u2019re creating a bot or conversational app and looking to approach the Kik crowd, then direct monetization is probably not a good option. Kik users are still deciding on what products to use when they get older. Their decisions on what stores to shop at, what bank to use, what clothes to wear, have not been made yet and are open to influence. So the smart strategy with Kik is to be fun, accessible, and hip, forming a lasting good impression.\n\nIn some ways Kik both competes and complements Snapchat, which also has some chat features and is popular in an overlapping demographic.\n\nMessaging capabilities: Kik has substantial support for bot features, including buttons that replace the keyboard to drive navigation. Bots can be mentioned in group chats or messaged one on one.\n\nInteresting facts: Kik\u2019s Bot Shop is one of the most extensive and well developed bot discovery system.\n\nHow to approach: Don\u2019t try to monetize Kik users immediately. Try to gain mindshare so that as they get their first job and start to form their own ecosystem of service providers, they pick you.\n\nWeChat is dominant in China, but it can be spotted in other countries as well.\n\nWeChat in many ways started the bot explosion in the rest of the world. The service has supported automated accounts for several years.\n\nExperiences on WeChat still serve as inspiration for bot makers in the rest of the world. For example, WeChat\u2019s heavy support of non-textual content, from buttons and images to what could best be described a \u201cmini apps\u201d embedded in conversations \u2014 and the success of these extra features \u2014 has served as evidence that bot makers need to go beyond plain text to provide simple, compelling user experiences.\n\nWeChat separates accounts into those publishing content, and those used for serving customers. Although the platform supports automated responses, humans are expected to support interactions as needed.\n\nInteresting notes: WeChat has very significant revenue per active user, thought to exceed $7 USD per year, which is a telling sign of the opportunities for western messaging platforms\n\nHow to approach: Historically WeChat has been relatively inaccessible to western companies. This is starting to change, however. In fact, WeChat is now accessible via connectors like Smooch.io to companies in the west. However, your app will need to be well localized. As with every platform, to be successful, you must focus on the needs and habits of the users on the platform.\n\nTelegram is unique in its openness. It has had public APIs and bot access for much of its history. It even open-sources its client applications. It has open source clients, and an open, flexible protocol. Telegram embraces privacy in a way that other messaging platforms shy away from.\n\nThe platform is comparatively small, with about 100 million users, and is not dominant in many countries in the world. However, the users it does have are well distributed and its user base is growing.\n\nGeography: Distributed, with little concentration or dominance in a specific region.\n\nNotes: Telegram\u2019s founder has a $1 million USD fund to incentivize developers to create high quality bots, awarding $25k for each the company deems interesting.\n\nHow to approach: Launch your service on Telegram alongside other messaging platforms\n\nSkype, believe it or not, is a messaging platform too. Microsoft surprised many when, with their Bot Framework releases, they also opened Skype to automated agents and bots. These include text and image messages, similar to what is available on other messaging platforms, as well as something more exotic: video bots.\n\nGeography: Global, with low penetration in messaging but high in audio and video\n\nMessaging capabilities: Historically video and audio based, with with nascent and rapidly emerging bot and conversational app capabilities included carousels with buttons and other types of visually structured messages. Bots within groups are also supported.\n\nHow to approach: Skype, despite Microsoft\u2019s efforts, is still primarily an audio and video communication platform. Its dominance in that space gives it a large install base, however, so there is opportunity to have great reach with relatively little competition relative to the other messaging platforms. Long term, leveraging Skype\u2019s video bot capacities could provide interesting opportunities that other platforms do not offer.\n\nViber is a messaging, voice, and video communication app with a large user base. It is dominant in parts of Europe, Asia, and Africa. In the US, Viber is frequently associated with its encryption capabilities, which has made it populate in countries and environments with close surveillance. The company has previously announced plans to begin marketing and expansion in the United States more heavily, but it faces stiff competition.\n\nViber is currently exploring its Viber for Business offering, which enables Service Messages and an API. However, businesses need to request access.\n\nHow to approach: If you are targeting a country where Viber is popular, then it would be prudent to request access to the Viber for Business Service Message API.\n\nGoogle\u2019s messaging products are turning into a suite of related offerings. At their annual Google I/O conference, they announced two new products to accompany Hangouts: Allo and Duo. Only Google knows how precisely these new platforms will fit in the ecosystem. They announced publicly that they will both be available by the end of the summer (Duo already is) so we will be able to see them soon.\n\nWhat Google has shared is exciting in capabilities. In addition to new clients, the company is opening up to businesses who wish to offer bots and conversational services.\n\nDuring their demonstrations, Google also hinted at some of the language processing technology they are working with, including the capability to understand the content of images within the conversations. Google is an obvious leader in this type of technology, although image content understanding is offered by Microsoft and others, and the conversational language understanding that Google touted is being approached by others, including my company Init.ai\n\nHangouts is not open to developers right now. It is expected to become more business focused over time.\n\nDemographics: Google users, which is much of the world, especially those on Android.\n\nGeography: Distributed, but limited in countries with restrictions like China\n\nMessaging capabilities: Unknown at this point, but includes both text and structured content.\n\nHow to approach: When launched, an open Allo and Hangouts will give access to a tremendous install base, and launching consumer services on these platforms should be prioritized.\n\nLine is a messaging platform and social network dominant in Asia. It has been growing rapidly, but it is approaching penetration in Japan. Line recently went public and raised over $1 billion to support its expansion plans.\n\nLine also includes voice and video calls. The platform also has a payment solution called Line Pay.\n\nThe service received attention in April when it launched a \u201cfirst come first serve\u201d restriction around its experimental bot APIs.\n\nMessaging capabilities: Line\u2019s bot platform is very new, and different levels of accessibility depending on the type of Line account you connect it to.\n\nTwitter\u2019s history has seen wild swings between good fortune and growth, and lack of direction and stagnation.\n\nTwitter is still very popular in the technology community, and it is mandatory for American businesses to maintain an active presence on the platform to support their customers and maintain public relations. There is significant opportunity in automating interactions between customers and business on Twitter, especially for routine support questions.\n\nTwitter is a unique medium, however, in that it is primarily pubic, not private. Historically its messages have been limited in length, so communications have a distinct style from other, more conversational messaging platforms.\n\nDemographics: Early adopters and technologists who have used it since its early popularity, as well as consumers seeking a public support forum.\n\nMessaging capabilities: Comparatively limited, based on single limited length messages, with no real support for anything other than images\n\nNotes: Twitter has changed its position towards developers over time. Initially it embraced them, then it restricted access, and now the company is trying to become more open again.\n\nHow to approach: Twitter is a good tool for mass communication and quick questions-and-answers between consumers and businesses. The best opportunities are around lowering the cost of handling support questions at scale.\n\nSome people have theorized that the messaging platforms will consolidate over time. That is certainly possible. But it\u2019s not necessarily likely.\n\nEven within single countries, each service appeals to its own demographic in a unique and difficult to replicate way. It\u2019s the same reason Facebook, Instagram, Snapchat, and Pinterest all exist simultaneously despite all letting users share images. They serve different purposes and cater to differently demographics.\n\nFor bot and conversational app developers, the best strategy will remain understanding your target customer, what services they use, and what they want. Messaging apps might grow and shrink in popularity over time, but in a world with diverse needs, there will likely always be a significant number of choices for both users and businesses."
    },
    {
        "url": "https://blog.init.ai/the-human-vector-incorporate-speaker-embeddings-to-make-your-bot-more-powerful-ade6fdfca035?source=---------6",
        "title": "The human vector: Incorporate speaker embeddings to make your bot more powerful",
        "text": "In human conversations, we rely on assumptions about how other speakers conduct themselves. This is known as the cooperative principle in the field of pragmatics. This principle breaks down into \u2018maxims\u2019 for speech that speakers either follow or flout. In short, we rely on others saying truthful statements, providing as much information as possible, being relevant, and saying things appropriately. When speakers purposefully flout these maxims, it carries meaning that we can understand (e.g. sarcasm, in which a speaker makes statements that are obviously untrue). When deviation from the maxims is unintentional, however, it can derail a conversation.\n\nConsider these example exchanges from \u201cA Persona-Based Neural Conversation Model\u201d:\n\nThe problem here is that our knowledge of the world makes this a clear violation of the Maxim of Quality (paraphrase: say things that are true). One person can\u2019t live in two different places or be two different ages at the same time. That means that we understand at least some of the responses to be untrue. It\u2019s conceivable that a skilled speaker of English could make these exact same statements intentionally and make an implicature in the process. In the last exchange above, for example, the responder could be making a joke about the amount of reading required for a psych major. Whether it\u2019s actually funny is a matter of taste. The difference with bots is that we don\u2019t expect humor. It becomes clear to us that inconsistent responses are unintentional and that makes communication difficult.\n\nThe specific issue of inconsistent responses is intrinsic to language modeling because data-driven systems are geared toward generating responses with the highest likelihood, without regard for the source of that response. When searching through the output space, an inference is made based on the most likely sequence of words to follow another sequence according to the model. In the study referenced above, the baseline model is an LSTM recurrent neural network, an architecture common in conversational AI. It uses the softmax function to create a probability distribution over possible outputs and picks the most likely next word in the sequence, no matter who generated it in the training data. Human speakers expect consistent personas from the bots they speak to and current techniques are ignoring that."
    },
    {
        "url": "https://blog.init.ai/the-product-designers-guide-to-conversational-commerce-cbe466753add?source=---------7",
        "title": "The Product Designer\u2019s Guide to Conversational Commerce",
        "text": "It is now time to fundamentally re-imagine the chat experience to accommodate these changes in technology and motivation.\n\nFurthermore, consumers want to interact with products directly through messaging services. According to a survey Smooch.io conducted in April \u201c65% said they want to be able to message a business.\u201d\n\nRecently, there has been a similar shift brought on by the growing popularity of chat apps like Facebook Messenger, WeChat, and WhatsApp. In fact, usage of these have surpassed usage of other forms of social media , and these apps are predicted to add more than one billion new active users through 2018 . This might not come as much of a surprise. Humans want to feel more connected to each other and messaging apps create that direct connection.\n\nAs the iPhone was introduced and grew in popularity, designers had to adapt to accommodate touch into their existing products. In many cases they built products that existed only through a touch interface. The iPhone shifted human-computer interaction, and is still changing the way people interact with technology.\n\nDesign lives at the crossroads of change in technology, human motivation, and aesthetic. It is in a designer\u2019s DNA to evolve alongside change, constantly building newer \u2014 and better \u2014 things which utilize this change to make people's lives easier.\n\nThis doesn\u2019t mean we need to create another app to chat through. I feel like we\u2019ve solved that. We need to start thinking about making apps we can talk to.\n\nConversational apps are autonomous services that people can interact with using natural language over existing messaging channels. Typically generalized as \u201cbots\u201d, conversational apps take this concept a step further and will bring about a new shift in human-computer interaction.\n\nI\u2019ve been thinking in this dimension for years and I want to share some of the things that I have discovered through playing, testing, and breaking things.\n\nUsers want to interact with businesses over chat. Soon, they will expect to chat with businesses in the same way they expect to interact with them on Twitter or how they expect them to have a website.\n\nIn China, many business will set up shop on WeChat well before they have a website. In some cases, they choose not to create a website at all.\n\nCurrent methods (websites, social media etc) work off of \u201cpush\u201d mechanics. Businesses create and push content outwards to the world. Experiences over chat, via conversation, are \u201cPull\u201d. Users pull from businesses and services by getting the information they want, when they want it.\n\nHang on a minute, haven\u2019t these \u201cbots\u201d been around forever? Sure, remember SmarterChild? Or, if you\u2019ve ever spent any time in IRC, you\u2019ve probably interacted with a few there.\n\nThese days, we have many more tools and technologies at our disposal. This new technology is enabling us to take experiences that were once tedious and simplify them while leveraging existing messaging platforms.\n\nLet\u2019s illustrate this by taking a look at a couple examples.\n\nConsider your banking app. It\u2019s really good at pushing numbers into a table, and keeping those numbers up-to-date. It\u2019s also good at categorizing and displaying data related to transactions. But when you want to pull from this experience, say to figure out what your average spending on \u201cgroceries\u201d is over the last few months, it gets very tedious.\n\nI can hear you asking, What could this look like in a \u201cconversational app\u201d?\n\n*Instead of trying to figure out (and building UI for every potential case) we let the user decide what they need (pull) from the app without having to anticipate all of their needs.\n\nYou might be thinking: \u201cWell , typing out that query is still like 65 characters long, which means over 65 taps. That is a lot to ask the user.\u201d Sure it is a lot of taps, but did you have to:\n\nThe effort required to translate your desired outcome into what\u2019s available in the presented UI is high. A well designed conversational app can lower this effort because language is understood and translates directly to intent. However, to counterpoint my counterpoint, the functionality of any particular app is not always clear. This is doubly so when language has few constraints. That is why we need to very seriously consider the design of these experiences. Consider how intimidating an empty text input and blinking cursor are when you don\u2019t know what you can do with it.\n\nI know what kind of shoes I want, color, size, and my price range. So why do I need to filter a search manually when I could really just \u201csearch\u201d for exactly what I need.\n\n\u201cHey Zappos, I need new shoes. Something size 12, black, sporty, under $50\u201d\n\nIt could also be handled in an additive way with prompts to fill in missing information. This way the user never has to memorize required parameters while offering better discovery to new users.\n\nSometimes we don\u2019t know exactly what flight we want, and a natural language interface is an ideal use for this.\n\n\u201cI\u2019m Looking for flights at the end of August to New York under $500. My flight times are flexible\u201d\n\nPush notifications and alert emails aren\u2019t always great, but sometimes they\u2019re necessary. As a \u2018visual\u2019 UI you have to display all available options. With language we can hide unnecessary options until they become relevant.\n\n\u201cGOOGLE! I need you to tell me anytime there\u2019s a great new cat video\u201d\n\nThis should give you an idea of how a natural language interface can help create a smarter and smoother user experience.\n\nThe examples above are great for a single input, but we\u2019re here to talk about conversation! Conversation is rich and dynamic, it\u2019s not just about an isolated input source.\n\nOne thing that trips me up is how to think about conversation as an interface. It\u2019s not as tangible as a button or a form, which means it\u2019s not as straightforward. These guidelines have been helpful when designing conversational apps.\n\n1) Engage: Be responsive, poignant, and helpful. When onboarding users, ramp them up slowly while giving them prompts for what to do!\n\n2) Recall: Be aware of context. Listen, don\u2019t ask things you already know or can infer. If you have historical information (like purchase history) use it!\n\n3) Anticipate: Be predictive when possible.\n\n4) Adapt: Conversation is organic. It flows, it has a rhythm. It\u2019s not mechanistic or rule based. Make sure your app doesn\u2019t break when users inevitably change their minds about something!\n\n5) Reflect: Repeat important pieces of information to confirm user needs. This is especially important when it\u2019s a critical piece of the flow, like a delivery address.\n\n6) Steer: Use cues, directions, prompts, or instruction to guide the flow of the conversation. Help the user succeed. This is a great way to deal with contextual discovery for some features.\n\nNow that you\u2019ve got all this great information, how can you start putting it to use? I\u2019ve outlined my workflow when putting this information into practice. It looks roughly like this:"
    },
    {
        "url": "https://blog.init.ai/how-techstars-brought-us-together-by-tearing-us-apart-95c04aaa9853?source=---------8",
        "title": "How Techstars Brought Us Together by Tearing Us Apart",
        "text": "How Techstars Brought Us Together\n\nby Tearing Us Apart\n\nEarly last winter, during one of our Sunday night founders syncs, the idea of applying to Techstars was brought up. We went through the requisite steps of discussing the pros and cons, the alternatives, and a fair amount of \u201cwhat-ifs\u201d. Ultimately, we decided that an accelerator was the right move for our company and that the upcoming Techstars Boulder class would be an ideal fit. While the application process itself was what I expected, I came to realize that getting into Techstars represented one of our first goals as a startup. Should we get in, not only would that provide a degree of validation for our product, but it would also prove to be our first win as an early team. Once we were accepted, a new wave of reality swept over the team. Two of us (including myself) were still full-time employees at another company. A commitment to Techstars also meant a complete commitment to Init.ai. I admit, I had my share of concerns about the Techstars program. These concerns were mostly personal and centered around the location. The decision to pack up and leave home for three months to live and work in a city which I had never been was difficult for me. But this was something I had always wanted to be a part of. I knew that success depends on taking risks and moving outside of your comfort zone. As founders, we were already distributed between Chicago, San Francisco, and New York; at least this meant I would not be alone in taking this leap. Despite earlier fragmentation in the decision to do Techstars, it was already uniting us. Month 1: Slow Down to Speed up Since I arrived in Boulder after the first week of the program, I missed the introductory retreat and lost out on some prime seating in the office. Regardless, I was impressed with the early camaraderie forming amongst the working teams. We were all working to solve extremely different problems but at the same time facing many similar ones. My goal before the program was clear cut \u2014 leave my current job, head to Boulder, and go heads down to build our product. We were warned early that we should not expect to get much work done in the first few weeks of the program. Despite these warnings, I maintained that I would still be able to pull this off. I was dead wrong. I grew to realize that when they said \u201cslow down to speed up\u201d, they really meant slow down. We were pushed to challenge our assumptions on our approach to our business and also to continue to force ourselves out of our comfort zone. The first few weeks consisted mainly of sessions and meetings on any number of topics from project management to mentorship strategies. As a team we felt quite overwhelmed and I worried about being pulled away so often from working on the product. I had such a strong desire to build the product our way and I wasn\u2019t receptive to a lot of the feedback and advice we were receiving. Across our team, we held different views about the benefits of this barrage of information. All in all, I think we balanced each other out though. Maybe that was the point.\n\nOnce we had \u201csettled in\u201d to the program, it was time for us to resume our movement on the hiring front. We had been conducting interviews in the weeks leading up to the program, but had put that process on hold during our adjustment period. After only a a few weeks into the program, we brought on two engineers and an intern. Adding chaos to chaos seemed like the perfect recipe for success. As it turns out, hiring at that point was a great decision. We were still early enough in the program and the lifecycle of our company where these hires could help shape our direction. But we also had enough time under our belt to sort out how we wanted to work with a growing team. The Techstars team welcomed our new hires as if they\u2019d been there all along. One of the managing directors even offered to help with finding them a place to stay! Team growth and culture is close to our hearts as founders. A lot of that stems from previous jobs, but we also saw an opportunity to construct our own framework for building a company that people would love working for. At the end of the day, a job is a contract between an entity and an individual. But, a job should also be symbiotic. Its not to say that I don\u2019t believe in structure, but that it is imperative all members of the team feel they have ownership and a voice to enhance the product. I have seen managers act as though an employee does not have a vested interest in the success of the product. To me, this doesn\u2019t compute \u2014 particularly at a startup where the performance of the product has a direct impact on your success as an individual. That is a deeper topic for another day though. Between Techstars\u2019 advice on on boarding, culture, and help with housing the team, we had an easier time growing our company at this early stage. Each week during the program, all the companies would assemble for a recap of the previous week and to discuss goals for the upcoming week. We found it difficult to adjust to this weekly cadence. For one, these meetings were on Thursdays, which meant a Monday-Thursday timeframe for goals. Yes, we worked through the weekends and we worked on Fridays, but we still clung to the nuances of a M-F work week. I still don\u2019t know if that was the wrong decision, in many ways I feel it set us up better for post-program life. We also had trouble setting KPIs and OKRs in these meetings given the state of our product. Our platform was immature and evolving at such a rapid pace that it was difficult to plan a day or two ahead, let alone a week. We missed many of our goals on the technical front but did much better on the business and marketing goals. It was rough to keep missing goals and drink fail juice (literally). But, from these failures a new, larger goal began to emerge. That goal was to get our team into a place where we could begin to operate efficiently enough to start hitting the goals we set. By the end of the program we were hitting a stride and achieved our final two. Aside from the individuality of the goals, these weekly gatherings served as a social catalyst for the companies in the program. Having these few hours each week gave us all insight into the personalities of our peers and fostered a shared mentality. It felt very much like classmates in school. People formed their own groups and cliques. But, at the end of the day, you all shared the same experience and that meant something. The program itself ends with the presentation of a demo day pitch. The final weeks were spent focused on nailing this presentation. Since we had hit a stride, we were also building product at a fantastic pace. This pitch was another part of the experience where we underestimated the amount of time and effort required. Building product would have to slow down to accommodate it. However, in the end, I saw it as the final polish on the framework of our product to that point. That realization, made all the nit picking and frustrations worth it.\n\nBefore leaving Boulder, I took some time to reflect on my experiences and what they meant. I\u2019ll make no bones about it, I did not love being away from home for that long. I think that was the hardest part for me personally. However, I would not change our decision to work away from home. We have talked about this many times. Had the program been in my hometown, we would not have been forced into team building. Bonding is naturally accelerated when four founders live in cramped quarters and have dinners and drinks with their first three employees. For various reasons, namely: discomfort, unfamiliarity, and truthfully \u2014 ego, I didn\u2019t take advantage of the program as much as I should have. As a team, we did much better. But Techstars, is as much of a personal experience as a company experience."
    },
    {
        "url": "https://blog.init.ai/a-completely-open-siri-bot-platform-not-so-fast-5d7b794ab9dc?source=---------9",
        "title": "A completely open Siri bot platform? Not so fast \u2013",
        "text": "Every top tech company has announced their interest in conversation as a way to interact with computers this year. Microsoft announced their Bot Framework, Facebook opened Messenger to developers, Google announced Allo, and Amazon keeps expanding Alexa. Until recently, one tech giant was missing: Apple.\n\nAt their WWDC conference, Apple announced its entry in the conversational interface space. But in distinct Apple style, the company did it a perplexing way. In both its Siri and Messages announcements, Apple offered a hint of open integration, but in unexpected ways that were not comprehensive. The primary reason for the limitations was not user experience considerations, for which Apple frequently is excused for its restrictions. Instead, Apple faces serious strategic threats that prevent that from embracing conversational interfaces.\n\nDevelopers get a way to integrate with Siri. This is something third party developers have wanted and requested for years. The potential for innovative services via Siri is exciting and irresistible, but details matter.\n\nThe nature of the Siri integration is underwhelming. Apple\u2019s SiriKit \u2014 what they call their tools for integrating with Siri \u2014 is limited to specific use cases and it restricts how a developer can integrate Siri into their own products.\n\nSiri was opened in a way that further reinforces the concept of installing an app on your Apple device. As a consumer, to add functionality or features to Siri, you must install an iOS app. As a developer, to integrate with Siri, you must create a special addition to your iOS application that enables Siri to tell the iOS app when the user wants to do something. Siri extensions cannot be built or added outside the context of an iOS app.\n\nSiriKit does not allow a developer to leverage Siri\u2019s language processing or voice recognition capabilities for arbitrary reasons. Apple has created a limited list of use cases that Siri will recognize and understand on its own. A developer may create an iOS app that fulfills the wishes that Siri determines the user has. But they are not allowed to do so outside a few use cases, and even within those use cases they are restricted in how innovative they can be since Apple has predetermined what the conversations can look like.\n\nSome common domains are clearly ripe for third party Siri integration, like mapping and playing music. Yet they have been excluded from third party innovation. The most likely explanation seems to be that integrations with services like Google Maps and Spotify might compete with Apple\u2019s existing solutions like Apple Maps and iMusic.\n\nA completely open Siri looks quite different than what was announced. While downloaded apps might still play a role in a completely open Siri, the capabilities offered to developers would go far beyond a limited set of domains and would give developers the power and freedom to be truly innovative in every domain.\n\nAn open Siri would likely look very similar to Amazon\u2019s Alexa. Alexa\u2019s third-party skills are not limited in the type of service they can implement. Developers are free to be innovative in any domain. Despite the freedom, users access the extensions to Alexa\u2019s core in a relatively seamless way. The end user only needs to reference the name of the third party service in his or her interaction.\n\nAlexa is a very different service than Siri. Alexa is extended through connections between Amazon\u2019s servers and those of the third party developers, not installed apps. That is because Alexa is a hosted cloud service and is not tied to a specific device.\n\nIt is unlikely that a fully open Siri would simply offer the language processing technology behind Siri to developers. That would remove too much control over the end user experience from Apple.\n\nThe Apple Messages announcement was similarly predictable in its implementation strategy. Like Siri, third party enhancements to Messages require users to install conventional iOS apps. These apps will enhance the functionality of the Messages app running on their phone. For example, as you are typing to another person in Messages, you might get access to a relevant app embedded within Messages app. This is convenient but this most definitely not the same type of conversational interaction that Microsoft, Facebook, and Google are headed towards.\n\nIf Apple were to embrace conversational interaction the same way other large companies have, it would open iMessage itself to developers in addition to extending the Messages app. There was speculation that Apple might open iMessage to third-party developers and might even extend it beyond just Apple devices. Neither happened.\n\nThe Messages integration Apple announced, and its restrictions on iMessage, reinforce the need to own an Apple device. Again, strategic and competitive positioning forced this outcome.\n\nApple does have reason to open iMessage to developers. Facebook opened up Messenger because allowing companies to offer services within Messenger means that its users will spend more time in Facebook\u2019s products. If users are able to shop, get information, and be entertained within Messenger, they will be compelled to Messenger more and alternatives that do not allow these activities, like iMessage, less. Apple could have taken the same approach with iMessage to keep it on a level playing field. But it did not.\n\nApple needs to maintain its hardware sales, and that means maintaining differentiation between the hardware it sells and that of its competition. The reason people buy an Apple phone instead of the hundreds of competing products is the unique benefits that Apple\u2019s iOS and its ecosystem offer: user interface, consistency, and simplicity.\n\nEnabling users to do more activities via messaging platforms, even Apple\u2019s own iMessage, could erode the completive advantage of iOS and Apple\u2019s devices. Conversational services \u2014 whether delivered via Facebook, Google, Telegram, Kik, or iMessage \u2014 make downloading mobile applications less necessary.\n\nConversational apps are poised to replace many native mobile apps. Although not widespread yet, but conversational apps will transform common activities from shopping to money management, even if they might never be suitable for some activities, like games and photos. And no app download will be required. For those activities users will not even have to leave messaging apps, meaning that the operating system surrounding the messaging interface becomes less and less important.\n\nA reduction in the usage of installed mobile apps relative to messaging would seriously threaten Apple\u2019s primary business by eroding the differentiation that iOS offers, threatening their hardware sales. With messaging as the interface, users would experience fewer of iOS\u2019 benefits and differentiating characteristics. Apple therefore cannot promote the displacement of mobile apps by conversational services yet.\n\nIf conversational interfaces reach the potential that Apple\u2019s competitors envision, Apple will face difficult choices. Given the current landscape, Apple could need to either broaden its revenue streams beyond hardware or figure out a way to compete on the same turf as Google, Microsoft, and Amazon.\n\nToday, Apple is not well positioned to compete on the conversational interaction battlefield. Conversational services tend to be delivered via hosted cloud services. And as they mature, conversational services will become more and more reliant on advanced machine learning technology as expectations for their user experience moves beyond simple bots towards full natural language. Apple\u2019s competitors are stronger in both areas.\n\nApple\u2019s ventures into cloud applications have generally been \u2018me too\u2019, defensive offerings like iCloud and Apple Music. They are not Apple\u2019s strength, which has been understandable since cloud services have not been a core revenue stream for the company.\n\nIn the field of machine learning, Google, Microsoft, and Facebook, all have substantial natural language processing research and technology endeavors. That is not to say Apple cannot make advances in machine learning if it becomes a priority: Amazon started at a relative disadvantage as well and was able to acquire high caliber researchers and achieve excellent results on speech recognition with their Alexa services.\n\nPure research capability is not necessarily a requirement to delivering great conversational products. Apple certainly has the capability to take existing research and apply it at scale to deliver excellent products. In fact, it is startups with limited research resources, but tight product focus, like like Api.ai, Init.ai (of which I am a founder), and the once-independent Wit.ai, that are advancing the frontier of conversational user experience today, not the larger companies with more substantial research budgets. But Apple does not necessarily have a competitive advantage in conversational product design at this point.\n\nThe broader issue is not that Apple is behind in the fields of cloud services and machine learning: it is that Apple does not have an inherent advantage in either. In the most optimistic light, the company is only on par with its competitors. Entering a market without a clear way to outcompete would be uncharted and precarious territory for Apple. So, for now, Apple needs to prevent that conversational interaction developing into a battleground on which it is ill equipped to compete. That is why Siri, Messages, and iMessage are so limited.\n\nThe unresolved question is where Apple goes from here. Their competitors are unencumbered by the same business model considerations and have a head start in the relevant expertise. Apple seems to be publicly marketing that its differentiator is its respect for privacy and protecting. But in a world where privacy seems to matter less and less to consumers, only time will tell whether this strategy will be sufficient."
    },
    {
        "url": "https://blog.init.ai/teaching-machines-to-talk-my-role-in-innovating-machine-understanding-449e58d88c77",
        "title": "Teaching machines to talk: My role in innovating machine understanding",
        "text": "We are participating in a world where the limit to what computers can do is less bounded than ever. Firmly past the AI winters, speculation about where machine learning can take technology is reaching new heights of not only optimism but tangible results. In Alan Turing\u2019s fever dream of 2016, it seems like computers can learn just about anything. We are the Jetsons!\n\nNot quite. But the tools we have for artificial intelligence are powerful, certainly. Big tech players, Google and Apple, have recognized that and are pouring money and effort into beefing up their ML chops. The good news is, you don\u2019t have to be a multi-billion-dollar corporation to put machine learning to use for you. Do you have a vested interest in interacting with users via text in an intuitive, natural way? An impatience for the clicking-around user interfaces of yesteryear? Machine learning will work for you.\n\nDevelopers like me are starting with the tool that ushered in the current AI boom \u2014 the neural network. From simple to complex, neural networks take their inspiration from the way human neurons pass signal to learn. If you\u2019re curious about how that works or what we\u2019re learning about neural networks at init.ai, my coworker, Robert, has written some great overviews.\n\nSo if this tool is so powerful, what can it do?\n\nNeural networks can pick out dogs, sure, but they can also parse, analyze, classify, and generate natural language. Machine learning aims to create computers that don\u2019t just execute commands when it comes to those tasks but figure out for themselves how input spaces pattern. We give machines the ability to make inferences about language data and adjust based on their errors \u2014 to understand their input. This is great news for anyone looking to automate seamless text interaction with a user base.\n\nUser interaction with conversational interfaces is moving far beyond the Moviefone clunkiness of years past. You might have heard of chat bots, but with experimentation applied to trusted machine learning techniques, we can far surpass them. Foundations in canonical machine learning strategies create the opportunity for innovation and experimentation in training data collection, data scope, and model engineering.\n\nAt init.ai, it\u2019s my job to use my experience studying natural language and natural language processing to create conversational interfaces that demonstrate what it means for machines to really understand the world around them. I apply my intuitions about language and experience with machine learning models to make better AI for you."
    },
    {
        "url": "https://blog.init.ai/three-impactful-machine-learning-topics-at-icml-2016-465be5ae63a",
        "title": "Three Impactful Machine Learning Topics at ICML 2016",
        "text": "The International Conference on Machine Learning (ICML) is the leading international academic conference in machine learning, attracting 2000+ participants. This year it was held in NYC and I attended on behalf of Init.ai. Three of the tutorial sessions I attended were quite impactful. Anyone working on conversational apps, chatbots, and deep learning would be interested in these topics.\n\nI\u2019ve written before about Residual Neural Network research, but listening to Kaiming was informative. In the talk, he described motivations for increasing the depth of neural networks. He demonstrated obstacles to increasing depth and initial solutions. Additionally, He showed how residual networks increase accuracy with increased depth beyond these initial solutions. Moreover, Kaiming justified using identity mappings in both the shortcut connection and the post-addition operation. Finally, He gave empirical results that ResNets yield representations generalizing to many problems.\n\nKaiming showed how deeper neural networks had won recent ImageNet competitions. Yet, extending them beyond a depth of about twenty layers decreases performance.\n\nA few techniques are enough to get this far. Careful weight initialization and batch normalization enable networks to train beyond ten layers.\n\nWeight initialization reduces vanishing and exploding behavior in the forward and backward signals. For healthy propagation, one should force the product of all layers\u2019 scaled variances to be constant. Thus, one should rescale the scaled variance of each layer to be one. For a linear activation, one can use:\n\nFor a rectified-linear (ReLU) activation, one can use:\n\nFor a rectified-linear network with 22 layers, initializing with the second equation converges faster. The same network with 30 layers requires the second form to progress at all. The second form makes sense because ReLU drops half of the input space."
    },
    {
        "url": "https://blog.init.ai/icml-2016-non-convex-optimization-5b824f0b724",
        "title": "ICML 2016: Non-Convex Optimization \u2013",
        "text": "The International Conference on Machine Learning (ICML) is the leading international academic conference in machine learning, attracting 2000+ participants. This year it was held in NYC and I attended on behalf of Init.ai. Three of the tutorial sessions I attended were quite impactful. Anyone working on conversational apps, chatbots, and deep learning would be interested in these topics.\n\nThis third post on non-convex optimization is part of a three part series on these important topics.\n\nAnima Anandkumar covered methods that achieve guaranteed global optimization for non-convex problems. Machine learning problems are optimization problems, often non-convex. But, non-convex problems have an exponential number of critical points. These saddle points impede the progress of gradient descent and Newton\u2019s method. She detailed conditions that define different types of critical points. She gave algorithms to escape well-behaved functions to find local optima. Such well-behaved functions are twice-differentiable and have non-degenerate saddle points. Stochastic gradient descent and Hessian methods can escape saddle points efficiently. She showed how higher-order critical points impede the progress of these algorithms. She detailed specific problems for which global optima can be reached: matrix eigen-analysis and orthogonal tensor decomposition."
    },
    {
        "url": "https://blog.init.ai/icml-2016-memory-networks-for-language-understanding-f2ed4c8819c4",
        "title": "ICML 2016: Memory Networks for Language Understanding",
        "text": "The International Conference on Machine Learning (ICML) is the leading international academic conference in machine learning, attracting 2000+ participants. This year it was held in NYC and I attended on behalf of Init.ai. Three of the tutorial sessions I attended were quite impactful. Anyone working on conversational apps, chatbots, and deep learning would be interested in these topics.\n\nThis second post on Memory Networks is part of a three part series on these important topics.\n\nJason Weston motivated building an end-to-end dialog agent. He detailed a simple model that makes headway toward this goal: Memory Networks. He provided means to test this model against a set of toy benchmarks. He described the benchmarks as an escalating sequence of tasks. Jason showed a revised memory network model that learns end-to-end without explicitly supervised attention. He gave real-world datasets where memory networks do well and where they do poorly. He portrayed a way to scale efficiently to large datasets. He presented two revisions: one using key-value pairs and another learning from textual feedback. Finally, he asked questions motivating future research.\n\nFirst, Jason introduced a set of beliefs describing an ideal dialog agent. It should use all its knowledge to perform complex tasks. It should converse at length and understand the motives underlying the dialog. It should be able to grow its capabilities while conversing. It should learn end-to-end.\n\nNext, Memory Networks (MemNNs) were introduced. Memory Networks combine inputs with attention on memories to provide reasoned outputs. He limits the first iteration\u2019s scope to be as simple as possible. It consists of a recurrent controller module that accepts an initial query. To start, its memory is loaded with a set of facts. The query and facts are bag-of-words vectors. The controller predicts an attention vector (with a supervision signal) to choose a fact. It reads the chosen memory to update its hidden state. After several repetitions, or hops, it formulates an output. The output ranks possible responses from a dictionary of words. Error signals back-propagate through the network via the output and the supervised attention episodes.\n\nHe described a set of toy benchmarks of increasing complexity. Each benchmark consists of a set of short stories. Each story is a sequence of statements about an evolving situation. The model should read a single story and answer one or more questions about it. Within a benchmark, the stories test the same skill. Across the different benchmarks, the skills get more difficult.\n\nA revised model, the End-to-end Memory Network (MemN2N) learns without attention supervision. It uses soft-attention (a probability vector) to read the memory. Thus, it is fully-differentiable and can learn from output supervision alone. The newer model still fails on some toy benchmark tasks. Yet, it succeeds on several real-world benchmarks, such as children\u2019s books and news question sets.\n\nAnother revision, the Key-Value Memory Network splits each memory cell into two parts. The first part is a lookup key used to match the incoming state vector. The second is a value combined with attention to produce the read value. Key-Value MemNNs closely match state-of-the-art on some real-world question-answering datasets.\n\nFinally, a third revision learns only through textual feedback. It learns to predict the response of a \u201cteacher\u201d agent that provides feedback in words. Mismatches between predicted and actual feedback provide a training signal to the model.\n\nExplore the papers, code and datasets in slide 87. Find questions for future research in slide 10, slide 83 and slide 88."
    },
    {
        "url": "https://blog.init.ai/icml-2016-deep-residual-networks-2f1665cd8624",
        "title": "ICML 2016: Deep Residual Networks \u2013",
        "text": "The International Conference on Machine Learning (ICML) is the leading international academic conference in machine learning, attracting 2000+ participants. This year it was held in NYC and I attended on behalf of Init.ai. Three of the tutorial sessions I attended were quite impactful. Anyone working on conversational apps, chatbots, and deep learning would be interested in these topics.\n\nThis first post on deep residual networks is part of a three part series on these important topics.\n\nI\u2019ve written before about Residual Neural Network research, but listening to Kaiming was informative. In the talk, he described motivations for increasing the depth of neural networks. He demonstrated obstacles to increasing depth and initial solutions. Additionally, He showed how residual networks increase accuracy with increased depth beyond these initial solutions. Moreover, Kaiming justified using identity mappings in both the shortcut connection and the post-addition operation. Finally, He gave empirical results that ResNets yield representations generalizing to many problems.\n\nKaiming showed how deeper neural networks had won recent ImageNet competitions. Yet, extending them beyond a depth of about twenty layers decreases performance.\n\nA few techniques are enough to get this far. Careful weight initialization and batch normalization enable networks to train beyond ten layers.\n\nWeight initialization reduces vanishing and exploding behavior in the forward and backward signals. For healthy propagation, one should force the product of all layers\u2019 scaled variances to be constant. Thus, one should rescale the scaled variance of each layer to be one. For a linear activation, one can use:\n\nFor a rectified-linear (ReLU) activation, one can use:\n\nFor a rectified-linear network with 22 layers, initializing with the second equation converges faster. The same network with 30 layers requires the second form to progress at all. The second form makes sense because ReLU drops half of the input space."
    },
    {
        "url": "https://blog.init.ai/conversational-apps-for-facebook-and-beyond-init-ais-integration-with-smooch-3f0f7e21e47",
        "title": "Conversational apps for Facebook and beyond: Init.ai\u2019s integration with Smooch",
        "text": "So now that you know how we integrated, let\u2019s talk about some other advantages of using Smooch to build your conversational apps. If you are building a conversational app or chatbot you\u2019ll also benefit from Smooch\u2019s clear scope and trigger model. This model allows you to capture all messages and to separate them into those from app end users and those from the app creator. For our demo app, we only subscribed to messages from the app end user. With this subscription, Smooch calls the webhook on our platform each time a user sends a message. We then add the message to the conversation we store on our side for processing by our conversational NLP and business logic systems, which, in turn, decide how to respond.\n\nWe appreciated Smooch\u2019s attention to security in how they treat webhooks. Our internal API is closed, but webhooks are necessarily open, so security is always at the forefront of our minds as well. For each incoming webhook, Smooch passes a shared secret, unique to that webhook, via an HTTP header, so we can verify that it is in fact coming from them.\n\nAs a trusted platform provider, we are deeply concerned with eliminating any potential for data loss, even for a simple demo app. If a company is chatting with a customer and loses any of that dialogue, the integrity of the app could be compromised. Smooch has a retry mechanism, which means that when they send a request to Init.ai, if for any reason our platform does not accept it, Smooch will re-send it three more times, with increased timeouts in between.\n\nAnother advantage to using Smooch is the rich level of information that is contained in the webhook payload. We are able to capture message data, user info, platform and device information with ease. That level of detail helps our system understand user intent and tailor our replies for each platform. For Facebook we are able to send out much richer replies than we would if we were using SMS only. We can also use that information to populate our analytics dashboards."
    },
    {
        "url": "https://blog.init.ai/alexa-can-you-add-custom-nlp-to-amazon-echo-b743606906f5",
        "title": "Alexa, can you add custom NLP to Amazon Echo? \u2013",
        "text": "A funny thing happens when you get a tech company a new toy: they make new (and frequently awesome) things. Last Friday night, Init.ai did a little experimenting with Amazon\u2019s Echo and their assistant service Alexa.\n\nAs a team, we at Init.ai think about talking to computers a lot. A real lot. So we were excited to see what could be built using Alexa and the Echo, and how it would work technically.\n\nAlexa is really cool because it\u2019s extensible, via what Amazon calls \u201cSkills.\u201d The Echo is pretty cool too, mainly because it has a great audio input system, consisting of seven \u201cfar field\u201d microphones. It enables the Echo and Alexa to pick up voice when other systems wouldn\u2019t.\n\nWe dove in pretty quickly. Once you have an Amazon developer account, creating an unreleased, private-to-you Alexa skill is really easy. There\u2019s an option to create one within the Amazon Developer Console, and it\u2019s a few simple steps:\n\nWe chose to use Lambda for the logic system, since we are familiar with it. (Lambda is also one of the places developers on the Init.ai platform can run their conversational app\u2019s business logic.)\n\nGetting a basic Skill up and running was trivial. Amazon\u2019s sample projects provide a decent starting point.\n\nAlexa isn\u2019t really set up for conversation. Or more accurately, it is, but only to the extent that most bot building platforms and frameworks (like Microsoft\u2019s, or Botkit) are today.\n\nIt looks something like this:\n\nThe problem here is step 3. That\u2019s because we wanted to go beyond basic question and answering with the Echo. We wanted to ask followup questions, and we wanted to do it in a sane way.\n\nTypically, handling followup messages means tracking the conversation state in your bot or Skill\u2019s logic system, then handling the intent from the NLP system in various ways depending on where the user is in the conversation flow. It\u2019s a clumsy, but necessary technique in most systems.\n\nBut we know that conversations can be handled a little more elegantly than that.\n\nSo we hacked it.\n\nNow, to be clear to those not versed in tech parlance, I use the word \u201chack\u201d in the friendliest of terms \u2014 we used Alexa in an unusual way to yield results we couldn\u2019t otherwise get given its limitations \u2014 nothing nefarious.\n\nWe made an Alexa app with custom NLP and business logic, using Alexa\u2019s pre-built NLP system only as a conduit.\n\nSpecifically, we wanted to use the NLP system built into Init.ai. Its design is different than Alexa\u2019s. It tracks both sides of a conversation between computer and human, and then determines intent and slots based on that conversation history.\n\nUsing a conversational NLP system like Init\u2019s has various benefits. For example it can determine the difference between the intent of the message \u201ccool\u201d in the conversation \u201cWhat temperature would you like the HVAC set to? Cool.\u201d and the conversation \u201cIs it okay to raise the temperature to 85 degrees? Cool.\u201d.\n\nIt can also make conversational apps simpler to write, and I\u2019ll hint at why later.\n\nGetting raw message text from the Alexa service required some creativity though. It\u2019s not sent to the Lambda function when Alexa executes it.\n\nAfter some quick searching and testing, we found a solution: collect the entire text within a slot that spans the whole message.\n\nIn the Alexa console it looks something like this:\n\nAnd voila! The raw text is now included in the Lambda request!\n\nIt\u2019s easy to access. The JavaScript looked something like this:\n\nNow that we had raw text, connecting to the Init platform was straightforward, although slightly awkward.\n\nInit.ai has an HTTP API where we could post messages we received from Alexa. But Init\u2019s API response is not synchronous. There are various reasons for this. The most fundamental reason is that Init.ai is more than just an NLP API: it also manages conversation flow and generates responses. Init\u2019s internal complexity means that it handles many interacting moving pieces in a way that means the overall system needs to be asynchronous.\n\nAlexa\u2019s calls are synchronous though. So in our Alexa Lambda invocation, we had to post incoming message from the user to Init.ai, and then we had to poll Init.ai for the outbound message, making Alexa wait. This is less than ideal, but it worked for our experiment, and the delay was imperceptible. A real integration would obviously look different.\n\nBut it worked! By talking HTTP between the Lambda invocation from Alexa and the Init.ai API, we were able to send raw text and receive responses, without having to deal with Alexa\u2019s NLU or write a new business logic system specifically for our Alexa skill. In fact, the app we connected to was also available over multiple text-based messaging platforms.\n\nThe result was really enjoyable!\n\nIn the Lambda invocation from Alexa, we instruct it to pass the user message text to the Init.ai, speak the response, then wait for a new message and repeat. The Echo could now hold a conversation.\n\nHere\u2019s what it sounded like:\n\nExcuse the video quality. That\u2019s what happens when you do experiments at 1AM. In case you didn\u2019t hear, Techstars Boulder Demo Day is coming up ;)\n\nThe results were good, but they were not perfect.\n\nAlexa\u2019s speech recognition feels pretty good when you\u2019re using it as an end user. It\u2019s not perfect \u2014 and it\u2019s especially troublesome for one of our Russian-accented engineers \u2014 but it generally feels pretty good.\n\nSeeing the raw text was not quite as encouraging. Alexa\u2019s speech to text is good, but sometimes it got words wrong and missed some words in a disruptive way.\n\nHere are the logs from the demo video:"
    },
    {
        "url": "https://blog.init.ai/residual-neural-networks-are-an-exciting-area-of-deep-learning-research-acf14f4912e9",
        "title": "Residual neural networks are an exciting area of deep learning research",
        "text": "I am highlighting several recent papers that show the potential of residual neural networks. Residual neural networks, or ResNets (Deep Residual Learning for Image Recognition), are a technique Microsoft introduced in 2015. The ResNet technique allows deeper neural networks to be effectively trained. ResNets won the ImageNet competition in December with a 3.57% error score. Recently, researchers have published several papers augmenting the ResNet model with some interesting improvements.\n\nResNets tweak the mathematical formula for a deep neural network. They tweak the layers\u2019 equations to introduce identity connections between them. The identity function is simply id(x) = x; given an input x it returns the same value x as output. A layer in a traditional neural network learns to calculate a function y = f(x). A residual neural network layer approximately calculates y = f(x) + id(x) = f(x) + x. Identity connections enable the layers to learn incremental, or residual, representations. The layers can start as the identity function and gradually transform to be more complex. Such evolution occurs if the parameters for the f(x) part begin at or near zero.\n\nThe ResNet technique has shown deeper neural network models can train successfully. The model Microsoft used in ImageNet 2015 has 152 layers. That\u2019s significantly deeper than previous competition winners. Deeper models tend to hit obstacles during the training process. The gradient signal vanishes with increasing network depth. But the identity connections in ResNets propagate the gradient throughout the model.\n\nResearchers have hypothesized that deeper neural networks have more representational power. Deeper nets gain this power from hierarchically composing shallower feature representations into deeper representations. For instance, in face recognition, pixels make edges and edges make corners. Corners define facial features such as eyes, noses, mouths and chins. Facial features compose to define faces."
    },
    {
        "url": "https://blog.init.ai/distributed-tracing-the-most-wanted-and-missed-tool-in-the-micro-service-world-7b5864c6249f",
        "title": "Distributed tracing \u2014 the most wanted and missed tool in the micro-service world",
        "text": "We, as engineers, always wanted to simplify and automate things. This is something in our nature. That\u2019s how our brains work. That\u2019s how procedural programming was born. After some time, the next level of evolution was object oriented programming.\n\nThe idea was always the same. Take something big and try to split it into isolated abstractions with hidden implementations. It is much easier to think about complex system using abstractions. It is way more efficient to develop isolated blocks.\n\nThe way we did system architecture design was evolving too:\n\nThese approaches are based on the same ideas:\n\nThis sounds reasonable. We can build complex systems just by adding new small parts or reusing existing ones. We build blocks; then we can build of these blocks anything we want. This is like a \u201cLego\u201d where you can add new parts (if you need them of course).\n\nBut, we always have to have balance \u2014 and micro-service architectures are no exception. The more you decouple things the less control you have. All you will know is that you have a cool infrastructure where lots of micro-services speak to each other. At some point you won\u2019t be able to see the big picture at all.\n\nThis is a typical micro-services architecture. We can see six micro-services with some dependencies (which are possible RPC-calls). Also, after some research we have found some infrastructure usage patterns. Let\u2019s name them \u201cmicro-service routes\u201d:\n\nSo, here we see 3 micro-service routes:\n\nAs we can see:\n\nImagine a situation where your \u201cMake payment\u201d flow becomes slow for some reason. You are collecting payments 3 times slower than usual. You need to see where it gets stuck. Also, what if it slows down only in some particular cases? Say only for customers from Australia, who have unread messages in their inboxes. So, they are able to pay in only 30% of cases. You are loosing money and loyal customers. You know that \u201cMake payment\u201d route includes A, B, C, D and F. At the same time you have no idea what the hell is going on. Sounds like a nightmare, right?\n\nIn the classical software world we can easily find problems using tools like debugger and profiler. This is good for monolith applications where everything is running inside one process. But.. what if you application is doing RPC call? Guess what? All that you will see in your super cool APM/debugger/profiler/etc is something like \u201cexternal call to XYZ-system, time taken 16.5 seconds\u201d. Wow, this is really slow, right? Cool, you\u2019ve just found a bottle neck!\n\nWill this find be helpful to understand why you app has been experiencing the latency issues? The answer is \u201cYes\u201d. Will it be helpful to fix the problem and make you app to be fast again? The answer is \u201cNo\u201d. What if that \u201cXYZ-system\u201d is doing calls to 3 other micro-services while serving your call? What if those 3 micro-services also do calls to other micro-services? What if you have say 20+ micro-services speaking to each other in many different ways?\n\nThis is the world where all your business logic is decoupled into small, isolated, distributed and available over network parts (aka micro-services). The world where you don\u2019t see anything. Welcome!\n\nSo, you need to see a big picture:\n\nWe know everything about any particular micro-service. But we want to see how they interact as a group in different cases. So, we need a different view.\n\nRemember \u201cNetwork\u201d panels in Chrome debugger or Firebug? When you want to understand why some page is loading so slow \u2014 you open debugger \u201cNetwork\u201d panel with timeline chart. There you can see which resource blocks the page loading/rendering process.\n\nNow, imagine that you have the same but for your backend! In this case you resources are micro-services. The call tree is your micro-service route. Also we can see a timeline! Micro-services are waiting for each other as they do RPC-calls and wait for reply.\n\nSo, instead of this:\n\nYou will see this:\n\nSo, now we can see:\n\nHuh, that\u2019s a lot of insights! We had no idea that it works like that. So, do you see where did we spend most of the time? Right, it is micro-service \u201cD\u201d! \u201cA\u201d is waiting for \u201cC\u201d and \u201cC\u201d is waiting for \u201cD\u201d. Micro-service \u201cD\u201d takes about a half of the time spent in this micro-service route. So, no we know that \u201cMake payment\u201d route has a bottleneck and this is the micro-service \u201cD\u201d. The next question we would ask is what are other routes where micro-service \u201cD\u201d plays some role? Is it a bottleneck there too or not? Anyways, now we know how to fix a \u201cMake payment\u201d route right away \u2014 just fix micro-service \u201cD\u201d.\n\nI would like to draw your attention to these key points:\n\nYou might ask \u2014 how can I get all this? This is what distributed tracing systems give to you. Systems like Google Dapper. The actual implementation of distributed tracing system is another one big topic. I will write a post about it one day for sure, just stay tuned! The most curious readers can find lots of details in a Google Dapper research doc here.\n\nNow, you are in the micro-service world where you can see everything."
    },
    {
        "url": "https://blog.init.ai/the-roi-of-conversational-ai-d8b03c09ae91",
        "title": "The ROI of (Conversational) AI \u2013",
        "text": "Developers spend 3 months a year creating and updating the Dunder Mifflin Android app. This is an ongoing annual cost of $30,000. That\u2019s actually quite conservative compared to what Michael has seen quoted elsewhere. And remember, that is ongoing as technical bugs are continuously found and users have trouble with everything from logins to formatting. All that for an app with just an OK interface and a difficult learning curve for customers who don\u2019t use it daily. He loves the idea of a SaaS conversational app \u2014 or MaaS (messaging as a service) if you want to be cheeky \u2014 that can reduce his app development costs and allow his developers to focus on other material decisions.\n\nMichael understands that AI will never fully replace human interaction. His top reps, Dwight and Jim, have walked many a customer back from the ledge. But often customers prefer human interaction only when it comes to complicated issues and are happy to use AI when they have routine issues (shipping dates, return policies, etc.). Michael looks beyond the world of simple bots and wants an intelligent app that uses conversational natural language processing. This form of NLP will help reduce his more routine customer service loads and decrease costs by 25% ($25,000 annually).\n\nWhat about revenue expansion you ask?\n\nAll in, Dunder Mifflin is leaving $7,281,573 of revenue on the table. What if his platform agnostic conversational app could capture that?\n\nMichael adds all the numbers up and realizes he has:\n\nHe ends up paying $30,000 annually for a conversational app that functions over iOS, Android, SMS, Facebook, and Slack. That is a 24,355% ROI. Not too shabby for a paper company."
    },
    {
        "url": "https://blog.init.ai/the-first-messenger-apps-the-good-the-bot-and-the-ugly-eeeef88afcc2",
        "title": "The first Messenger apps : The good, the bot, and the ugly",
        "text": "Yesterday Facebook ushered in a new era for messaging and conversational interfaces. At the F8 conference, they opened the Messenger platform API and added support for Bots.\n\nFirstly, Facebook\u2019s presentation was incredible. The structured messages are a great mechanism to enhance textual interface with rich content and actions. The API is simple, and gives business the opportunity to be there with Messengers 900,000,000 monthly active users. They also presented some very interesting verticals to showcase with their launch partners (on-demand, e-commerce, news, information).\n\nI, for one, cannot wait to build, and see what can be built, on this platform.\n\nHowever, my first impressions with these bots, and those of the people I\u2019ve spoken with, have been disappointing. In this market, first impressions are everything. I am deeply concerned that the initial bots will turn Messenger\u2019s user base away from bots and their potential.\n\nDuring the conference today, they announced their key release partners and, naturally, I played with the headliners.\n\nThe focus on these verticals was absolutely tactical and underscores the potential Facebook sees in conversational commerce. Here\u2019s some of my thoughts on the initial bots.\n\nMy first few messages to Poncho were met with total silence, I\u2019ll chalk it up to load or something, but it fell a little flat. After a few hours, I tried again and was greeted with classic Poncho style.\n\nThe cadence was feeling good, typing indicators removed most of the feeling of talking to a machine, and its unique personality really helped.\n\nSomething is definitely missing. Better natural language processing. There are a number of funny examples on twitter, and I tried to trick it immediately by telling it where I was, and where I live (two different places). It went with the first location it saw. \u00af\\_(\u30c4)_/\u00af I\u2019ll let it slide.\n\nA coworker of mine had a less pleasant experience. He got lost in a flow that Poncho must not have tested well and failed to find an escape. Poncho does not handle the non-happy-path of onboarding well, and it fails to guide a lost user back to safety."
    },
    {
        "url": "https://blog.init.ai/selling-shovels-for-the-bot-rush-f86f7eceee72",
        "title": "Selling shovels for the Bot Rush \u2013",
        "text": "In case you haven\u2019t noticed, bots are big. Bots, and their more sophisticated brethren conversational apps, have dominated the tech media this year.\n\nTech luminaries, from Mark Zuckerberg with his New Year\u2019s Resolution to build an AI to control his home, to Chris Messina of Uber and his hashtag #ConvComm, have placed bots and bot-like services at the center of the tech world\u2019s consciousness. They\u2019re everywhere and they\u2019re on everyone\u2019s mind.\n\nIn coffee shops, startup studios, and accelerators everywhere, starry-eyed entrepreneurs are flocking to this new digital wild west: where UI disappears, text roams the screen, and promises of profitable new services made possible by rapidly growing platforms await those who build bots and conversational services.\n\nThe optimism is infectious. Mobile app users now spend more time in messaging than in any other activity, even social networking.\n\nReaching users in messaging is extremely attractive from a business perspective. Whether it\u2019s to sell products, advertise, inform or entertain, businesses want to reach users in messaging because that\u2019s where users are already. Bots and conversational apps enable them to do that, like mine shafts into the mountains of messaging users and their virtual wallets filled with gold.\n\nBuilding bots \u2014 particularly natural language conversational apps \u2014 is not easy though. Like the 49ers before them, the prospectors of today\u2019s Bot Rush are discovering that reaping the rewards of the frenzy is actually quite difficult, at least technically.\n\nBefore we continue, I\u2019d like to make a distinction between a \u201cbot\u201d and a \u201cconversational app.\u201d The two terms are often used interchangeably but differentiating them is helpful.\n\nBots, as opposed to full conversational apps, are simple. A \u201cbot\u201d resembles its namesake \u2014 robotic, mechanic, and rigid. Bots have already proliferated on platforms such as Slack and Telegram because they are easy to make and deploy.\n\nIn the context of the Bot Rush, think of bots as the pans and sluices prospectors used to extract gold from rivers. Bots are simple, but they\u2019re cheap and relatively effective.\n\nBots aren\u2019t appropriate for every messaging opportunity though. For that, Bot Rush prospectors need tools that are more sophisticated.\n\nNatural language conversational apps resemble humans in their communication style. They are less robotic, and while they won\u2019t pass a Turing Test, they are much more natural to use.\n\nThink of conversational apps as the deep shaft mines of the Bot Rush. They are the hardest type of messaging app to make, but their power and simplicity make them much more effective than mere bots.\n\nThe California gold rush of 1849 was filled with tales of riches, but the gains were not uniformly distributed. Some miners struck it big, gaining untold wealth from their lucky finds. Others tried and ended up penniless.\n\nToday\u2019s Bot Rush resembles the gold rush in some ways. There are massive amounts of money to be made, and most likely the spoils will not be evenly divided.\n\nUnlike the gold rush, however money from messaging is not a finite resource. It will continue to reap rewards long into the future, because signs point to conversational interaction between humans and computers as being a lasting change. The potential of humans and computers conversing with each other is too great for this trend to simply evaporate.\n\nLike the gold rush, one of the strongest businesses you can be in in the Bot Rush is the supplier of equipment and services to enable the prospectors to strike it rich. In 1849, the merchants of San Francisco made fantastic sums by selling shovels, equipment, and other supplies to miners who bore a striking resemblance to the flocks of messaging entrepreneurs of today \u2014 at least in optimism and ambition, if not appearance and aesthetic.\n\nCompanies are emerging to fill the needs of the Bot Rush prospectors.\n\nFirst, there\u2019s the owners of the mountains themselves. Undoubtedly they will charge rent for access to the riches they contain, but overall they benefit from the Bot Rush.\n\nNext, there\u2019s the messaging aggregators and connectors. They connect the mountains of messaging users to the conversation apps and bots.\n\nThe bot builders and hosts help setup simple bots. In gold rush terms, these were the guys cutting down trees and making the pans and sluices.\n\nFinally, there\u2019s the platforms that enable natural language conversational apps. In gold rush terms, these were the builders of mine shafts. The serious tools. As you can imagine, these take a bit longer to create, but reap far greater rewards."
    },
    {
        "url": "https://blog.init.ai/stop-hitting-things-and-use-your-words-conversation-is-ui-evolved-7069c90864eb",
        "title": "Stop hitting things and use your words. Conversation is UI evolved.",
        "text": "For quite some time, the physical world has been the foundational metaphor for concepts in user interface design. I don\u2019t mean leather backgrounds in apps, or note taking apps that look like a binder, or buttons with shading to add dimensionality.\n\nWe have been abstracting away user intention in a bad way. Instead of asking users directly what they want to accomplish with our products, we ask indirectly, via metaphors and riddles.\n\nWhy? Because user interfaces have been mimicking the physical world and the way in which intention is conveyed in it. The result is interfaces far removed from actual user thoughts and desires.\n\nBut now that is starting to change. Abstraction is being removed. And the end of abstraction is giving rise to what some have predicted will be the biggest shift in human-computer interaction in decades: the rise of conversation as interface.\n\nWhat is a button? In the digital world, a button usually looks something like this:\n\nA button is a mechanism for a human to tell a computer that he or she wants to do something. What that something is varies \u2014 it could be selecting something, it could be triggering an action, it could be navigating to a different part of an interface \u2014 but the exact result doesn\u2019t matter. The point is, with a button touch conveys intention.\n\nBut why does a button look like it does? For an answer, think about the physical world.\n\nWhen you want something done in the flesh and bone and wood and metal world, you walk up to an object, and you manipulate it. Usually using your hands.\n\nMost things in the physical world are controllable by touch. If you want to interact with them, you push, pull, squeeze, turn, or grab them.\n\nIn the physical world, communicating complex intention using touch is painful. Sometimes literally, but almost always in cognitive load. Representations of those complex intentions are transformed into controllable objects, and in the process complexity rapidly blossoms into chaos.\n\nEver see something like this?"
    },
    {
        "url": "https://blog.init.ai/joining-init-ai-to-build-deep-learning-for-conversational-apps-623545ada595",
        "title": "Joining Init.ai to build deep learning for conversational apps.",
        "text": "As I write, DeepMind\u2019s algorithm is surpassing the world\u2019s best Go players in ability. AlphaGo plays against Lee Se-dol, the world\u2019s second best Go player, in a set of five matches this week. Soon, the same deep learning technologies will approach human-level natural language ability. That means we, as software users, will be able to converse with our computers in a natural way. Our utterances towards our machines will have fewer constraints, yet still be correctly interpreted.\n\nWe at init.ai are bringing deep learning technology to conversational apps. We are studying the research in the field that is openly published every day. We have seen the steady performance gains on tasks in vision and language over the past several years. It is time to start building upon these proven technologies which are now available.\n\nWho are you?\n\nWhy is this now possible? Deep learning describes a set of trainable components that stack together in many layers. These components, neural networks, are fully differentiable. Their gradient, or derivative, may be calculated throughout the network given an error signal. An error signal communicates how much incorrect behavior the network has, and how to reduce the error.\n\nIt appeared, for many years, that these components were too difficult to optimize. Altogether, they lack a mathematical property that simpler machine learning algorithms have: convexity. Convexity ensures that an algorithm always makes progress during training. But recent research shows for large non-convex models, training is as possible as for convex models.\n\nAlong an axis, a critical point on the function can be a minimum, maximum or saddle point. Critical points of high dimensional models are increasingly unlikely to be local minima. Thus, an optimization algorithm almost-always has an escape route to reach an accurate score. Deep learning research formulates training schemes to bypass saddle points via these routes.\n\nNow that training any given model is likely, the important choice is to shape your model architecture to solve your problem. This is the differentiable programming paradigm: specify a model shape but learn the logic from data.\n\nMany model shapes have arisen in the research, and several apply to language understanding. The word2vec algorithm represents a word with a dense vector of learned parameters. The vectors are derived from the word\u2019s contexts within a relevant dataset. The contextual knowledge word vectors provide is like the visual context AlphaGo exploits to reduce its game search tree.\n\nGiven a word vector model, the next advancement is the sequence model. The recurrent neural network is the simplest, and the long short-term memory model and the gated recurrent unit model build upon it. These models can process sequences of inputs and perform a task on each token in the sequence, or on the entire sequence.\n\nThe sequence-to-sequence model goes further. It digests an input sequence into a summary, which it expands into an output sequence. Sequence-to-sequence can perform language translation.\n\nFurther developments have two prominent branches: attention-based models and automata-augmented models. Each performs both sequence and sequence-to-sequence tasks.\n\nAttention-based models review inputs and cached intermediate states to weight their relative importance. These models are able to perform text and image question answering tasks.\n\nAutomata augmented models give recurrent neural networks a differentiable memory unit. These units could be a stack, queue, deque or random access memory array, as in the Neural Turing Machine. Such models are algorithmically capable. They can learn to perform a sequence of steps to implement some simple algorithms.\n\nThe Neural GPU may be one of the most impressive. It improves upon the Neural Turing Machine by parallelizing its computations through convolution operations. Essentially, it learns cellular automata to implement algorithms.\n\nAt init.ai, we will be employing some of these and other relevant models for powering truly conversational apps."
    },
    {
        "url": "https://blog.init.ai/load-balancing-or-balancing-on-the-edge-of-a-cliff-abeb7112f346",
        "title": "Load balancing or Balancing on the edge of a cliff?",
        "text": "As a backend developer/architect I was always interested in this topic. When you need to scale big \u2014 load balancing is the first thing you want to start thinking about.\n\nIt doesn\u2019t matter whether you are building a backend for one of your Apps or your product is a SaaS/PaaS used by 3rd parties. Your backend should be solid like a rock, otherwise you will lose your user base fast. The loyalty of your users depends on the backend. If you build a SaaS then your platform API is going to be a foundation for many other applications. Their success will depend on your platform. So, your backend should be reliable, stable and scaleable to any amount of traffic.\n\nSounds scary enough, right? Well, if you still want to build your killer app and make this world a better place \u2014 keep on reading\u2026\n\nThe good news is that load balancing will help you in most cases (if you use it properly). Let\u2019s take a look what is load balancing.\n\nSo, there is a load balancer box:\n\nLoad balancer faces the real traffic first; here your request\u2019s life cycle starts. It is important to have a \u201csuper high-availability\u201d setup for load balancer. If load balancer dies \u2014 everything dies. Keep that in mind and make sure it will survive anything except an asteroid. There are many techniques how to setup a load balancer (this is out of scope of our discussion here). Take a look at AWS ELB \u2014 it does a great job. Also, consider DNS health checks and multi geo-region setup on AWS. This actually might survive even an asteroid disaster!\n\nThis layout allows you to solve many problems:\n\nLooks like all our problems are solved:\n\nOf course, there are still many things which could fail. Our backend servers will likely do queries to some DBs/storage. Also, they will be sending requests to other internal/external services. So, you will need to make sure that all those parts are scaleable and reliable as well. For the sake of brevity let\u2019s say all our internal services are behind load balancers too. You can do this on AWS using VPC internal ELBs.\n\nYou might ask why this post has \u201cbalancing on the edge of a cliff\u201d in its title? Everything seems to be good, right?\n\nI\u2019d like to speak more about health checks as this is the place where things might go bad. Let\u2019s recap what happens when some of your backend servers fail:\n\nOk, we need to answer to several questions:\n\nLoad balancing flow looked so smooth and reliable before\u2026 Now, we have to think about lots of things.\n\nIf you don\u2019t plan the computational capacity of your pool \u2014 you will get in trouble. The worst scenario is when your pool behind the load balancer appears empty. Load balancer will mark all existing backend servers as \u201cunhealthy\u201d. The new backends will face the storm of existing traffic and will likely become unhealthy as well. Your pool of backend servers will be catching up, but never makes it. Don\u2019t forget, your traffic is not going to stop, it will be the same or even growing.\n\nSo yeah \u2014 now it looks more like balancing on the edge of a cliff!\n\nThe good news \u2014 there is a list of simple things which can help to prevent this \u201cworse collapse scenario\u201d:\n\nLast thing I wanted to mention \u2014 the thing I actually don\u2019t like in load balancers. Load balancers don\u2019t respect backend servers. They just send traffic to them and don\u2019t care if backend dies because of this traffic.\n\nI wish one day I had a load balancer which would take in account many backend metrics before sending traffic to it:\n\nSay I am a smart load balancer: \u201cI know everything about my backend servers. So, if I know that this backend is already 90% busy serving other requests why do I need to send to it more? I don\u2019t want to kill it, I won\u2019t do that. If all my backend servers are busy \u2014 sorry. I\u2019ll be processing existing traffic, all other extra requests will be just timed out. Once I have more backends less busy and ready to serve I will make them busy. But again, respecting metrics from those guys\u201d.\n\nIf you know about any solution like this \u2014 let me know, I will be more than happy to test it!\n\nAnd the very last thing \u2014 let\u2019s have a dream.\n\nImagine the world where load balancer doesn\u2019t send any requests to backend servers. Moreover, our load balancer is not a load balancer anymore, in a sense we know it. It is something like a storage for requests where they wait for a chance to reach backend. The backends would become just workers. They will be pulling requests from this storage, serve them and send results back. Now our backend servers decide how much traffic they can serve by themselves. If you don\u2019t have enough workers then some of your requests will expire and user will receive a time out error.\n\nA good analogy would be a restaurant. \u201cCustomers\u201d are our requests. \u201cRestaurant\u201d is our storage for requests. \u201cWaiters\u201d are our backend workers. Waiters can work as fast as they can. Waiters can serve as many customers as they can. Every waiter decides when he/she is ready to serve the next customer, right? The key point is that you will always have some number of your customers served and happy, guaranteed! Some of your waiters might fail but other waiters will have no idea about that. Other waiters will be busy serving their current customers. If you don\u2019t have enough waiters some of you customers will be waiting for too long. They will leave the restaurant disappointed. Scale, hire more waiters!"
    },
    {
        "url": "https://blog.init.ai/messaging-will-replace-your-apps-resistance-is-futile-sometimes-7c691366ae2b",
        "title": "Messaging will Replace Your Apps \u2014 Resistance is Futile (Sometimes)",
        "text": "Conversational apps are making headlines and becoming the topic of discussion amongst app developers. Cade Metz\u2019s recent article discusses how many believe that apps will be replaced with artificial intelligence and messaging; I want to expand on some of the benefits. I\u2019ll get to the heart of why a combination of messaging and AI is a promising trend and explain why this new technology is so promising.\n\nUsers don\u2019t need a multitude of layers that make answering their questions difficult: download app, open app, find help, search for question. That\u2019s a lot of needless friction. So when Metz asked:\n\n\u2026well the answer is: not every app has the same staying power. Messaging allows newer and smaller companies to increase their customer reach without significant resource-spend. Companies aren\u2019t forced to develop apps on multiple platforms, they don\u2019t need to promote those apps to find users, and they don\u2019t have to spend significant resources to create unique interfaces because platform-agnostic conversational apps allow them to conveniently bypass all those issues.\n\nMoreover, as Metz does correctly point out, messaging is a growing trend but many use cases are becoming cost prohibitive and there is a shift to include AI to help alleviate those costs. Uber can afford to have a massive customer support staff, but smaller companies are not so fortunate. Answering some of your customers\u2019 questions easily through AI allows you to focus resources more on growth instead. Time is money. But this isn\u2019t just a trend that Chinese companies of WeChat can benefit from; it\u2019s a major benefit to any user in any geography on any platform.\n\nAnd here\u2019s a secret I\u2019m going to let you in on: it isn\u2019t binary. It\u2019s a false dilemma to say that companies must choose either between a messaging app or a conventional app. The reality is that apps can have conversational features. Yes, you can have a graphical user interface but you can also add conversation and artificial intelligence into your current apps as well. By doing this you can get the best of both worlds. Much like the Borg have done.\n\nNow, I can\u2019t say with absolute conviction that messaging is the only way to move forward. But I can say, without a hint of hesitation, that mobile apps are presenting a multitude of issues that messaging may ameliorate. That much is \u201cknown\u201d. It\u2019s going to be fantastic to not have to deal with as many lifeless and frustrating apps anymore. And those worried about AI not working because of \u201cunknown\u201d technology need to remember all the \u201cknown\u201d problems with current app development."
    },
    {
        "url": "https://blog.init.ai/if-you-re-not-thinking-conversation-first-you-are-doing-it-wrong-19126f2924bc",
        "title": "If you\u2019re not thinking conversation first, you are doing it wrong",
        "text": "Conversation is the purest form of interaction and should be the basis for higher level designs.\n\nDesigning a user experience is a challenge for even the most skilled companies. It is a problem of nuance, and it is complicated by the fact that users interact with brands and companies in many different ways. Deciding what experience to optimize for first is an important decision, and the optimal answer has been evolving over time.\n\nAlex Iskold (https://twitter.com/alexiskold) recently posted an article on how companies that aren\u2019t thinking mobile web first in their designs are making a mistake.\n\nAlex\u2019s basic premise is that mobile devices are increasingly becoming the default platform through which consumers reach brands and companies. To effectively design for the mobile platform, it\u2019s important to think within mobile\u2019s constraints from the start. The reason it makes sense to start with mobile \u2014 and then expand on your mobile designs to adapt to desktop and other platforms if needed \u2014 is that in design it is far easier to add than to remove. Therefore, it\u2019s best to start with the minimal experience and then augment if needed or appropriate.\n\nI absolutely agree with Alex\u2019s assertion that it is easier and more effective to add to a design than to remove from it. But I suggest that the design process should start at an even more fundamental level: conversation."
    }
]