[
    {
        "url": "https://medium.com/scaleabout/youtube-the-future-of-television-427d4bf809c2?source=---------0",
        "title": "Youtube the Future of Television? \u2013 ScaleAbout \u2013",
        "text": "When Youtube was first created in 2005, it was intended to be a place for people to easily share videos with their friends. I bet nobody expected for it to become the launching pad for the next big television and media sensations. The lines of internet stardom and mainstream media fame are becoming more and more blurred; film and television stars have been making moves to Youtube, including Will Smith, Mayim Bialik, Dwayne \u2018The Rock\u2019 Johnson, and Shay Mitchell who all have popular channels.\n\nSurprisingly, the inverse transition is just as common -Youtube creators who\u2019ve gone from a single youtube video to youtube stardom, to television and beyond\n\nHere is a list of stars who blur the lines of television and Youtube:\n\nHannah Hart began her Youtube channel while housesitting for her friend one night in New York. She decided to get drunk and try and make grilled cheese, and thus My Drunk Kitchen was born. Since then, Hannah has gained over 3 million followers and led numerous charity initiatives. Her Youtube channel even boasts celebrity guests like Sarah Silverman, Elizabeth Banks, and Lance Bass.\n\nIn 2017, Hannah Hart was tapped to have her own show on The Food Network where she combines her love of travel and food. The 6 episode series, I Hart Food, was very popular among viewers and critics alike. She\u2019s also had a hand in creating three feature length films with fellow Youtube star and next on our list, Grace Helbig.\n\nGrace Helbig is known for her sarcasm, deadpan humor, and comedic makeup tutorials. Her hilarious personality and hatred of emotional vulnerability led her to have a very successful podcast entitled \u201cNot Too Deep\u201d. In her over 6 years on Youtube, Grace has earned over 3 million followers.\n\nThe New Jersey native was a once aspiring actress living in LA. Now she\u2019s a successful content creator and writer with credits including live shows, television, and film. So it was no surprise why she was tapped by the E! Network to have her own interview show. Though The Grace Helbig Show only had one season, her charm has earned Grace a large following, both on Youtube and off.\n\nAs Issa Rae tells it, she was procrastinating doing an assignment for university when \u201cAwkward Black Girl\u201d was born, her YouTube alter-ego, based on her real life experiences of working, dating, and just living life as an awkward person. The series went totally viral for its portrayal of this relatable, loveable character not often depicted in media.\n\nHBO took notice of this Youtube sensation and offered Issa the option to adapt a show for the network inspired by her Awkward Black Girl character and series. With two seasons released, her HBO show Insecure is critically acclaimed, earning her multiple Golden Globe Nominations for both her writing and acting. Issa is also currently in the process of creating three other shows for HBO.\n\nThese foul mouthed, New York goddess comedians were self producing videos on Youtube long before they were a Comedy Central hit. Their Youtube show, also called Broad City, followed two Jewish 20 something girls trying to navigate life in New York city post-college. Hailed for creating hilarious situations out of the mundanity of daily life, these women caught the attention of some well known comedians, namely Amy Poehler of Saturday Night Live and Parks & Recreation fame.\n\nPoehler went on to personally mentor Abbi and Ilana throughout their process of writing their show for television, and she serves as an executive producer for the show. Broad City, along with its loveable characters, and their outlandish antics, has achieved critical acclaim. These comedians not only made the transition from Youtube to television, but also from improv shows to Comedy Central. Bonus, all their original webisodes are still live on their Youtube channel.\n\nYou might recognize Colleen Ballinger better by her Youtube character, Miranda Sings. Miranda Sings\u2019 weird voice, strange look, and over-the-top personality led to a huge cult following of over 8 million subscribers. However, that\u2019s not her only successful channel, Colleen also operates a channel for her to share content as herself out of character, also a huge success with over 5 million subscribers.\n\nIt was clear that the character of Miranda had a fanbase who wanted to learn more about her story. Colleen began working on a show for her Miranda character which was picked up by Netflix. The series, Haters Back Off, explores the world of Miranda and her family. With two seasons already published on Netflix, Colleen was able to bring her loveable character to a whole new audience. She\u2019s also one of the first Youtubers to go from Youtube to Netflix. Miranda is still producing content on all of her channels.\n\nWith Youtube\u2019s growing presence and constantly growing audiences we may wonder do we even need primetime shows anymore?\n\nOnly time may tell. While once a place for cat videos, Youtube has become a major player in both popular culture and limitless new content. Although each of these creators had a different path from Youtube to television, there is one thing that they all share, each one is a fantastic storyteller whose unique perspectives appeal to mass audiences and provide entertainment to millions of people. At the end of the day, whether viewers are watching content on HBO, Comedy Central, Netflix, or Youtube, all that really matters is that it\u2019s quality content.\n\nIs there someone we should add to this list? \n\nLet me know in the comments below."
    },
    {
        "url": "https://medium.com/scaleabout/students-startups-and-the-future-of-internships-b4ce192a3854?source=---------1",
        "title": "Students, Startups, and the Future of Internships \u2013 ScaleAbout \u2013",
        "text": "From student-run startups to entrepreneurial college internships, students and startups have a rich history. Most people know that Mark Zuckerberg started Facebook while he was studying at Harvard, and while it might be the most well known, it\u2019s far from the only startup born/founded in a college dorm room.\n\nCarnegie Mellon alums and high school sweethearts Susan Gregg Koger and Eric Koger started their online based clothing startup Modcloth while they were still teenagers. Evan Spiegel dropped out of Stanford because his app, Snapchat, was taking off. Steve Huffman and Alexis Ohanian met at the University of Virginia\u2019s Computer Science program and together they created a startup that would become Reddit. The list goes on and on, and incidentally, includes my ScaleAbout co-founder Adam Frank and myself. We began brainstorming startup ideas together after meeting in a mathematics course, back then we didn\u2019t have the same knowledge and resources to understand startups the way college students do today.\n\nUniversity is quickly becoming synonymous with early startup accelerator\n\nMore and more universities are realizing that entrepreneurship is not simply a goal students strive for after matriculation, but an academic expectation. Schools like MIT, Harvard, Duke, and UCLA all have university-run startup incubator programs, not to mention regularly scheduled school-sponsored hackathon. This entrepreneurial shift to academia has been swift; it\u2019s apparent when you look at the experience of current university students and recent graduates, versus the experience my classmates and I had in university only five years prior.\n\nHowever, hackathons and curriculum additions are not all it takes to make it in the hi-tech sector post-graduation. Cornell University recognizes the importance of hands-on experience in the field and has begun offering startup internship programs as part of the student curriculum. Students get paired with startups \u2014 conducting research, mapping competitive landscapes, and creating business plans \u2014 all with the support of the university. Similarly, Brown University\u2019s Center for Entrepreneurship offers all students accessibility to startup internships, independent of their field of study. Their internship program, while focusing on practical skills of entrepreneurship, supports students and even provides investment opportunities for qualified ventures. The existence of these programs, and many others, solidifies the important role of students in the startup sphere, and more importantly, distinguishes participating students as superior potential interns in the eyes of to their employers.\n\nMost students will agree that doing an internship is important, but they might not know how important it is to participate in an internship with early stage startups\n\nNow more than ever, students have a major role to play in startups. The high tech field is advancing at a staggering rate with new concepts, programs, and platforms popping up globally every year. No one knows this better than college students, because they tend to be the earliest adopters for new technology, social media, and consumer products. That is precisely why students are vital additions to startups. Student interns have the possibility to make a major impact, especially in an early stage startup.\n\nWhile interning at Google is a fantastic opportunity, not to mention a good resume enhancement, the potential mark an intern can make is so small in the grand scheme of things. Internships at large-scale tech companies are often in very niche areas, not focusing on the larger understanding of startup operations. Students who have a chance to get involved with smaller startups get to witness the product of their efforts, and they get to take a more hands-on role in entrepreneurship. Our intern from Cornell, Andy, echoed this idea.\n\nThe student startup connection is not only limited to the companies either; there are venture capital firms dedicated to getting students involved in startup investments. Dorm Room Ventures and Rough Draft Ventures both utilize the power of students to help identify successful student-led startups. In fact, this movement extends beyond the US \u2014 it\u2019s an international phenomenon \u2014 namely fresh.fund, an Israel-based VC, is the first student-focused venture capital fund in the region, employing student [investors/managers/VCs] to scout and invest in student-run startups. I can speak to their effectiveness personally, it was their student investor team that helped to fund ScaleAbout.\n\nUniversities understand the changing landscape regarding the part a student may play in the startup world, and I know firsthand the value that student interns bring to startups. After all, students are now graduating with valuable, practical skills in entrepreneurship. To the benefit of a developing startup, there is a growing number of young and capable recent graduates entering the workforce.The important question is this:\n\nHow will you, as a student, set yourself apart when entering the job market?\n\nThe answer is simple: Do your homework. Prepare yourself for the role and industry you aspire to, through an internship at an early stage startup."
    },
    {
        "url": "https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e?source=---------2",
        "title": "A gentle introduction to Doc2Vec \u2013 ScaleAbout \u2013",
        "text": "In this post you will learn what is doc2vec, how it\u2019s built, how it\u2019s related to word2vec, what can you do with it, hopefully with no mathematic formulas.\n\nNumeric representation of text documents is a challenging task in machine learning. Such a representation may be used for many purposes, for example: document retrieval, web search, spam filtering, topic modeling etc.\n\nHowever, there are not many good techniques to do this. many tasks use the well known but simplistic method of bag of words (BOW), but outcomes will be mostly mediocre, since BOW loses many subtleties of a possible good representation, e.g consideration of word ordering.\n\nLatent Dirichlet Allocation (LDA) is also a common technique for topic modeling (extracting topics/keywords out of texts) but it\u2019s very hard to tune, and results are hard to evaluate.\n\nIn this post, I will review the doc2vec method, a concept that was presented at 2014 by Mikilov and Le in this article, which we are going to mention many time through this post. Worth to mention that Mikilov is one of the authors of word2vec as well.\n\nDoc2vec is a very nice technique. It\u2019s easy to use, gives good results, and as you can understand from it\u2019s name, heavily based on word2vec. so we\u2019ll start with a short introduction about word2vec.\n\nword2vec is a well known concept, used to generate representation vectors out of words.\n\nThere are many good tutorials online about word2vec, like this one and this one, but describing doc2vec without word2vec will miss the point, so I\u2019ll be brief.\n\nIn general, when you like to build some model using words, simply labeling/one-hot encoding them is a plausible way to go. However, when using such encoding, the words lose their meaning. e.g, if we encode Paris as id_4, France as id_6 and power as id_8, France will have the same relation to power as with Paris. We would prefer a representation in which France and Paris will be closer than France and power.\n\nThe word2vec, presented in 2013 in this article, intends to give you just that: a numeric representation for each word, that will be able to capture such relations as above. this is part of a wider concept in machine learning \u2014 the feature vectors.\n\nSuch representations, encapsulate different relations between words, like synonyms, antonyms, or analogies, such as this one:\n\nSo how is it done? word2vec representation is created using 2 algorithms: Continuous Bag-of-Words model (CBOW) and the Skip-Gram model.\n\ncontinuous bag of words creates a sliding window around current word, to predict it from \u201ccontext\u201d \u2014 the surrounding words. Each word is represented as a feature vector. after training, these vectors become the word vectors.\n\nAs said before, vectors which represent similar words are close by different distance metrics, and additioanly encapsualte numeric relations, such as the king-queen=man from above.\n\nThe second algorithm (described in the same article, and well explaiend here) is actaully the opposite of CBOW: instead of prediciting one word each time, we use 1 word to predict all surrounding words (\u201ccontext\u201d) skip gram is much slower than CBOW, but considered more accurate with infrequent words.\n\nAfter hopefully understanding what is word2vec, it will be easier to understand how doc2vec works.\n\nAs said, the goal of doc2vec is to create a numeric representation of a document, regardless of it\u2019s length. But unlike words, documents do not come in logical structures such as words, so the another method has to be found.\n\nThe concept that Mikilov and Le have used was simple, yet clever: they have used to word2vec model, and added another vector (Paragraph ID below), like so:\n\nIf you feel familiar with the sketch above, it\u2019s because it is a small extension to the CBOW model. but instead of using just words to predict the next word, we also added another feature vector, which is document-unique.\n\nSo, when training the word vectors W, the document vector D is trained as well, and in the end of training, it holds a numeric representation of the document.\n\nThe model above is called Distributed Memory version of Paragraph Vector (PV-DM). It acts as a memory that remembers what is missing from the current context \u2014 or as the topic of the paragraph. While the word vectors represent the concept of a word, the document vector intends to represent the concept of a document.\n\nas in word2vec, another algorithm, which is similar to skip-gram may be used Distributed Bag of Words version of Paragraph Vector (PV-DBOW)\n\nHere, this algorithm is actually faster (as opposed to word2vec) and consumes less memory, since there is no need to save the word vectors.\n\nIn the article, the authors state that they recommend using a combination of both algorithms, though the PV-DM model is superior and usually will achieve state of the art results by itself.\n\nThe doc2vec models may be used in the following way: for training, a set of documents is required. a word vector W is generated for each word, and a document vector D is generated for each document. The model also trains weights for a softmax hidden layer. In the inference stage, a new document may be presented, and all weights are fixed to calculate the document vector.\n\nThe thing with this kind of unsupervised models, is that they are not trained to do the task they are intended for. E.g, word2vec is trained to complete surrounding words in corpus, but is used to estimate similarity or relations between words. As such, measuring the performance of these algorithms may be challenging. We already saw the king ,queen,man, woman example, but we want to make form it a rigorous way to evaluate machine learning models.\n\nTherefore, when training these algorithms, we should be minded to relevant metrics. One possible metric for word2vec, is a generalization of the above example, and is called analogical reasoning. It contains many analogical combinations, here are some:\n\nA success in this task is getting very close results when caclulating distances between matching pairs.\n\nDoc2vec was tested in the article on 2 tasks: the first is sentiment analysis, and the second one is similar to the analogical reasoning above.\n\nHere are 3 paragraphs from the article. a dataset of such paragraphs was used to compare models. it is easy to see which 2 should be closer:\n\nThis dataset (was not shared as far as I know) was used to compare some models, and doc2vec came out as the best:\n\nOne of my clients, ScaleAbout, uses machine learning methods to match \u201cinfluencer\u201d you-tube videos to content-articles. Doc2vec seems to be a great method for such match.\n\nHere is an example for what the ScaleAbout does: in this article, about home made lights in a tree stump, you may see at the bottom 4 related video about woodworking stuff:\n\nScaleAbout current model uses tagging mechanism to tag the videos and the articles (\u201ctopic modeling\u201d) and measuring distance between tags.\n\nScaleAbout has a few corpora of text, related to the themes of its\u2019 clients. E.g, there is a 100K manually tagged documents about \u201cdo it yourself\u201d, for publishers such as above. There are 17 possible tags for each article (e.g, \u201chome decor\u201d, \u201cgardening\u201d, \u201cremodeling and renovating\u201d etc.). For this experiment, we decided trying to predict the tags using doc2vec and some other models.\n\nScaleAbout\u2019s current best model was a convolutional neural network, on top of word2vec, which achieved accuracy of around 70% in predicting the tags for the documents (as described here).\n\nDoc2vec model by itself is an unsupervised method, so it should be tweaked a little bit to \u201cparticipate\u201d in this contest. Fortunately, as in most cases, we can use some tricks: If you recall, in fig 3 we added another document vector, which was unique for each document. If you think about it, it is possible to add more vectors, which don\u2019t have to be unique: for example, if we have tags for our documents (as we actually have), we can add them, and get their representation as vectors.\n\nAdditionally, they don\u2019t have to be unique. This way, we can add to the unique document tag one of our 17 tags, and create a doc2vec representation for them as well! see below:\n\nwe will use gensim implementation of doc2vec. here is how the gensim TaggedDocument object looks like:"
    },
    {
        "url": "https://medium.com/scaleabout/want-to-choose-the-right-influencers-6-must-read-tips-4a83599f52c6?source=---------3",
        "title": "Want to Choose the Right Influencers? 6 Must Read Tips",
        "text": "This is crucial. Regardless of how funny, engaging, or entertaining an influencer might be, if they don\u2019t feel connected to your brand the content they produce will automatically have an inauthentic feel to it. Look for influencers who are already customers.\n\nWhile viewers enjoy the honesty and relatability of influencer videos, unprofessional videos have significantly lower conversion statistics. They don\u2019t have to be a Hollywood director, but make sure their videos are clear, well edited, and fun to watch.\n\nThe higher a follower count, the less connected followers feel. It is easier to produce video content that 5\u201310k people enjoy than to please 250K followers. Micro-Influencers have the most impactful voices in today\u2019s market.\n\nConsumer bases are diverse. Diversity in your influencer selections enables each consumer to find someone they relate to and can connect with. Don\u2019t just higher cookie cutter influencers, embrace the ones that break the mold.\n\nBy definition, Influencer Marketing requires brands to let go of complete creative control. Find influencers who have a successful track record. See their previous work and build the trust that is necessary for an effective campaign.\n\nFinding a relatable influencer, who loves your brand, and comes with an impeccable track record, is not enough. Do they understand your product and all its features? Can they verbalize how it works, and portray it in a positive light? If the answer to those questions is yes, then you have found an influencer for your campaign!"
    },
    {
        "url": "https://medium.com/scaleabout/https-medium-com-scaleabout-the-power-of-the-lesser-knowns-38079a158129?source=---------4",
        "title": "The Power of the Lesser Knowns \u2013 ScaleAbout \u2013",
        "text": "Considering the effectiveness of influencer marketing, the pace of brands embracing the strategy has been fairly slow. For decades brands have controlled the creation of their content, allowing for a carefully crafted message and image. Influencer content is user generated and the unique characteristics \u2014 authenticity, honesty, relatability \u2014 that allows for influencer marketing\u2019s success force brands to relinquish complete autonomy of their message.\n\nBrands therefore feel more comfortable working with fewer influencers. It allows for the most control and maintains the century old principle that a brand\u2019s name and reputation are to be carefully crafted and protected. Popular influencers, with upwards of a million followers, can work hand-in-hand with a brand and include their advertising agency and in-house marketing team throughout the creative process.\n\nHowever, brands can\u2019t have the best of both worlds. Creative control is the antonym of authenticity. Working with popular influencers might be well within a brand\u2019s comfort zone of controlling the narrative, but it undermines the whole foundation of influencer marketing.\n\nThe solution? Working with many smaller unknown influencers.There are two main benefits of working with micro influencers, with followings between 10,000 to 100,000 followers. First, the content isn\u2019t contrived, it has a sense of realness which some of the larger influencers have lost. Second, regardless of an influencer\u2019s popularity, not all customers will connect with one influencer. Each viewer is drawn to something else, with a diverse influencer base, brands have the opportunity to connect with the largest number of customers each with their own unquantifiable preferences. With a larger pool of influencers for a customer to choose from comes the greater chance for a personal connection and more importantly belief in what the influencer has to say.\n\nSo if you trust your product, have faith that influencers will represent it well. It is time to embrace the power of organic branded content and get out of the way to allow for hundreds of unique personalities using their individual creativity to connect with our consumers."
    },
    {
        "url": "https://medium.com/scaleabout/how-influencers-are-changing-beauty-standards-for-the-better-26979a835841?source=---------5",
        "title": "How Influencers are Changing Beauty Standards for the Better",
        "text": "The beauty industry thrives off of fear. The fear of not meeting the media expectation of beauty. People spend millions every year trying to achieve what they are told is beautiful, perfect skin, plump limps, tiny waists etc. The media has influenced our perceptions of physical beauty, convincing us to believe that beauty is airbrushed models splashed across magazine pages. Less than one percent of the population have that body type, leaving the other 99% feeling inadequate.\n\nSadly, marketing that strikes at consumers insecurities and fear are convincing consumers that if they spent more money they might be able to make themselves beautiful. However, a new wave of marketing, influencer marketing, has proven more effective since it encourages purchasing from a point of empowerment.\n\nUnlike classic advertising, influencer marketing is consumer generated native content. Typically found on social media, a beauty influencer garners a following who listen to advice and tips about makeup or styling. The influencer will review various makeup products and offer tips to his or her following. What\u2019s so powerful about influencers is that they all look different. There\u2019s no one skin color, body size, or style that is beautiful. Influencers can showcase beauty in all of its forms. Viewers can find the influencer they connect with the most, maybe it\u2019s someone who looks like them, maybe it\u2019s someone who empowers them to feel comfortable in their own skin.\n\nThe narrative has shifted from, buy this product because you need to meet a standard, to I really like this product because it makes me feel nice and it works well for me. Consumers respond to this type of product marketing, it\u2019s similar to a friend recommending a new lipstick to you. You are more likely to trust their opinion because it\u2019s authentic. There is no longer a need to compare yourself to the photoshopped ideal of beauty, you can feel empowered to feel beautiful just the way they are. After all, beauty comes from within.\n\nWith this perspective in mind, it is quite logical why influencer marketing is more effective than classical marketing devices of the beauty industry. Having models or celebrities pushing products reinforces an unrealistic and unachievable standard. Some big players in the beauty industry are making strides to support healthy body image, but it\u2019s not to the level of the influencer world. While scaring a person into buying a product works, consumers that make decisions through the influence of positivity are much happier."
    },
    {
        "url": "https://medium.com/scaleabout/advertising-vs-content-where-should-the-line-be-drawn-a6897cac8a5b?source=---------6",
        "title": "Advertising vs. Content \u2014 Where Should the Line Be Drawn?",
        "text": "A Youtube personality posts a video reviewing the latest matte liquid lipstick from a well known brand. She stresses the amazing product you get at a great price point. She tries on a competing product adjusting the lighting, this product looks dull and inferior compared to the first one. The Youtuber, or influencer, has built trust with her followers, so the video persuades them to form a positive association with lipstick one and a negative association with lipstick two. Can blatant manipulation be defined as native content?\n\nIn a neutral world, influencers are merely enthusiasts about a particular trend, hobby, or space. Their motivation to garner a following stems solely from their passion for a specific subject or product. The influencer wants to share their latests purchases to show their following how they found their favorite app or the perfect pair of jeans.\n\nThen came the big brands with astronomical advertising budgets who recognized the effectiveness of peer to peer branding. The conversion rates on influencer content surpassed the industry benchmarks and then some. So brands began reaching out to influencers to not only pay for new content, but also to collaborate on content creation. This had two adverse effects: one, the original influencers lost their impartiality and two, a new wave of people are aspiring to be influencers for the lucrative payoff.\n\nPutting the legality aside, the essential question is whether social media users will stop trusting influencers. The less organic and honest influencers become, the less trusting their following will be. Brands have shifted from focusing on large influencers with hundreds of thousands of followers to focus on micro-influencers, defined as influencers with social media followings under ten thousand. The shift was caused by brands learning that there are increased engagement rates with the smaller influencer\u2019s follower base. The reason is clear, larger influencers have definitionally become less trustworthy since their sheer number of followers are indicative of brand relationships. Brand relationships mean that the content being generated is steered by the brand and is no longer reliable or impartial.\n\nPeople have a sixth sense for authenticity. The more brands try to meddle in influencer content creation the more reception of the content will suffer. Brands are tip toeing a fine line between quantitative influencer content creation and maintaining the qualitative advantages micro influencer content provides.\n\nBrands are quickly learning that it isn\u2019t up to them to write the dictionary definition of advertising and content. While they might be able to lobby for the legal jargon, the honesty antenna of social media users will continue drawing the line between content and advertising."
    }
]