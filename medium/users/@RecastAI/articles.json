[
    {
        "url": "https://chatbotsmagazine.com/build-super-human-chatbots-introducing-context-management-d9e24309c890?source=user_profile---------1----------------",
        "title": "Build super human chatbots: introducing Context Management",
        "text": "Building bots has been growing as a hobby in the tech world. Many companies offer bot building services, or integrate chatbots as smart assistants. However, things do not always run smoothly. Bots still have quite a lot to learn, and it is our mission at Recast.AI to push the boundaries of what has been done to provide the best bot building experience.\n\nOne of the issues we always had when building bots was detecting keywords when they are not included in a sentence.\n\nIn this scenario, a user wants to find a good restaurant in Italy. Unfortunately, her name is the same as the city she\u2019s in right now: Florence! When the bot asks for the location of her desired restaurant, she simply answers \u201cFlorence\u201d. Unfortunately for her, the bot understands it as a name. In itself, it isn\u2019t wrong, but that is still not what is expected of him for the current conversation. Florence is very disappointed, has lost all trust in this chatbot, and leaves the conversation.\n\nThis happens much more than we\u2019d like to. In the past month, our team has been working on different ideas, and is today proud to announce that we\u2019ve reached a solution! We are glad to announce our newest feature: context management.\n\nContext management gives bots built with Recast.AI a greater sense of conversational awareness. It helps you create human-like conversations by reducing the chances of misdetected entities. This release drastically improves the performance of your entity detection. During a conversation, your bot is learning as much as possible from the flow, the user answers, the vocabulary choice. By doing such an analysis, it is capable of predicting the answers at all times, therefore understanding them much better.\n\nThis feature is not something tangible: it is integrated into all bots using Bot Builder with Skills. And because of it, Florence can make her restaurant booking smoothly.\n\nWe\u2019re not stopping there, trust me! Today\u2019s release is a big step in conversational technologies, but we want to go further than that. Tomorrow, we\u2019ll be working on providing context on whole intents, languages, sentiment and emotions. These will allow the use of humor, sarcasm, foreign words, and overall improve the liveliness of chatbot conversations. And after mastering that in an intra-conversational level, we\u2019ll just keep expanding to inter-conversational awareness and then global user awareness. Sweet, right? We\u2019ll keep you updated.\n\nIf you want more technical information, please read our changelog. If you have any questions, please join our Slack Community to talk with the team!\n\nVisit Recast.AI, our collaborative Bot Platform & join us on Twitter, Facebook and LinkedIn :)"
    },
    {
        "url": "https://chatbotsmagazine.com/countering-internal-covariate-shift-with-batch-normalization-f79d132a7812?source=user_profile---------2----------------",
        "title": "Countering Internal Covariate Shift with Batch Normalization",
        "text": "Batch normalization is a recently developed technique to reduce training time. Sometimes, it can even improve the accuracy of a model. But what exactly is batch normalization? Simply put, it is a way to counteract the internal covariate shift between two layers of a neural network. If you are like me, and you did not find this answer very helpful, let\u2019s break down what the internal covariate shift is and why it is messing with your network and how batch normalization is a genius solution.\n\nGiven a neural network composed of several layers, the forward propagation can be abstracted as function composition (function composition): each layer can indeed be viewed as a function that takes as input a vector from \u211d\u207f and outputs a vector from \u211d\u1d50 (for a layer of \ud835\udc5a neurons preceded by a layer of \ud835\udc5b neurons). For each function, there is a linear mapping from \u211d\u207f to \u211d\u1d50, given a matrix \ud835\udc64 of weights of dimension \ud835\udc5b, \ud835\udc5a, followed by the addition of the biases \ud835\udc4f (\ud835\udc4f \u22f2\u211d\u1d50) and finally a non-linear activation (e.g the sigmoid function).\n\nWhen a network is viewed as functions composed (the similarity of concept between function composition and deep learning is subject to many speculations among researchers) with one another, it is easier to notice that the output of a function (except for the first layer aka the input function) would be affected by the small changes of all preceding functions.\n\nLet\u2019s consider the sigmoid activation function \ud835\udf0e. Let \ud835\udc67 = \ud835\udf0e(\ud835\udc4a\ud835\udc62 + \ud835\udc4f), for \ud835\udc62 the input and \ud835\udc4a, \ud835\udc4f respectively the weights and the biases. It can be verified that as |\ud835\udc65|grows (see derivatives for the sigmoid function), \ud835\udf0e\u2019(\ud835\udc65) approaches 0, meaning that the gradient of the sigmoid function vanishes. In the case of our layer, for each of its dimension \ud835\udc65=\ud835\udc4a\ud835\udc62 + \ud835\udc4f, except for low values of the components of \ud835\udc65, the gradient will vanish.\n\nImagine a bunch of guys putting out a fire, organized in parallel lines, trying to pour water inside buckets from the the front line to the back, where there is a building burning. In this metaphor each guy is like a neuron, and each line of guys are like the layers of a neural network.\n\nImagine that after each back and forth passage of the buckets of water, a large number of your firefighters stopped working, or worse, spilt pretty much all their water where they are and you, as their leader, you would be helpless to make them learn how to hold their bucket. If they are training to become firefighters, as you could imagine, it would not be effective. It is what is happening to a network when it is subject to ICS, at each forwardpropagation and backpropagation, a large portion of your neurons will permanently stop learning.\n\nThe dramatic part is that this effect has the ability to amplify as your network goes deeper. For each backpropagation step, and for each layer, small changes in the output of the preceding layer might shift the distribution of the inputs of the layer of interest to the vanishing gradient zone. Some interesting simulations can be found at batch norm simulation. At the end of the training, a lot of your neurons might be in the saturated regime of the nonlinearities and they will be prevented from learning anything, which will probably decrease the accuracy of your network.\n\nIn a nutshell this is the Internal Covariate Shift.\n\nFirst, if you wish to mitigate the dire effect of ICS and its associated vanishing gradients, you could use a very low learning rate to train your network, typically below 1.10\u207b4. Usually, this has the effect of limiting the shifts in the input\u2019s distribution of each function that constitute the neural network. But this is at the expense of a much longer training time. Another popular technique was to carefully initialize the weights of the network. The most popular initialization was the He initialization. But you have then to take into account new and complicated hyper\u2013parameters. By the way, rectified linear units (ReLU) were also introduced to solve, at least partially, the problem of vanishing gradients.\n\nICS and vanishing gradients made it harder to go deeper with neural networks. Even when the ICS between two adjacent layers was not dramatic, meaning not too many weights or biases were sent to the saturated regime of the nonlinearity, the backpropagation step could be more about correcting the change induced by the previous layer. This could also be counteracted by dropout. One can view dropout as a way to make the computation of each neuron independent. Indeed, if a change in parameters is detrimental to the task of a network and if that cannot be partially corrected by the following layer, the chances that such a change might be eliminated are higher.\n\nOverall, ICS was counteracted with careful initialization, a very low learning rate and the addition of dropout. The cost of going deeper was then a much longer training time due to dropout and a slower learning rate and the addition of new hyper-parameters.\n\nAgain, take my example of the firefighter apprentices. Imagine that you want to train them to handle their buckets of water very, very slowly. This is what you would do by reducing the learning rate of network during the training phase.\n\nIf you want to implement dropout with your firefighters, you would also need to stop one guy working at each epoch (a forward and backward propagation). In order to avoid water loss, the idea is to force the guy that came before to hold both reponsability and his water instead of counting on the next guy trying to catch the bucket.\n\nAs for He initialization, the metaphor starts to get out of hand!\n\nThe solution came with the realization that when the inputs of a network are transformed so that they have a zero mean and unit variance, the network converges faster. At first Ioffe and colleagues tried to subtract to \u02e3\ud835\udc58 \u2014 the output of the \ud835\udc58\u1d35\u1d49\u1d57\u02b0 layer \u2014 the mean of all training values at this layer. By doing that, the authors realized that some parameters could increase indefinitely through backpropagation while the overall loss would remain unchanged. To remedy this effect, the authors divided the output \u02e3\ud835\udc58 by the variance of batch values. Ioffe et al tried to introduce this transformation inside the network, with \u02e3\ud835\udc58 the batch output of a layer which is then transformed in \ud835\udcce\ud835\uddcd, the output of batch normalization. \ud835\udc38(\u02e3\ud835\udc58) is the mean of training batch values and \ud835\udc49 \ud835\udc4e\ud835\udc5f(\u02e3\ud835\udc58) its variance. \ud835\udefe and \ud835\udefd are two trainable parameters and the beauty of this framework is that it is end-to-end differentiable, so that both \ud835\udefe and \ud835\udefd can be learned. \u22f2 is introduced to prevent division by zero in case the variance equalled zero.\n\nTo conclude my firefighter story, batch normalization would be to reposition the firefighters at the right distance between each line of firefighters so that their individual learning would not be affected by too much by where the teammates that came before placed the bucket.\n\nIoffe and colleagues succeeded in training their network with a much higher learning rate, while reducing the need for dropout and also allowing the usage of saturating nonlinearities for deep network. As matter of fact, they reduced the training time by a factor of 14. And, the cherry on top, they even gained a few percentage points accuracy for image classification. Today batch normalization is commonly used for vision-related tasks and for deep learning in general.\n\nYou can easily implement a batch-normalization layer in keras:\n\nHope that helps! Let me know in the comments if you have any questions, and happy coding.\n\nHe, Kaiming et al. (2015). \u201cDelving deep into rectifiers: Surpassing human-level performance on imagenet classification\u201d. In: Proceedings of the IEEE interna- tional conference on computer vision, pp. 1026\u20131034.\n\nIoffe, Sergey and Christian Szegedy (2015). \u201cBatch normalization: Accelerating deep network training by reducing internal covariate shift\u201d. In: International conference on machine learning, pp. 448\u2013456.\n\nNair, Vinod and Geoffrey E Hinton (2010). \u201cRectified linear units improve re- stricted boltzmann machines\u201d. In: Proceedings of the 27th international con- ference on machine learning (ICML-10), pp. 807\u2013814.\n\nSrivastava, Nitish et al. (2014). \u201cDropout: A simple way to prevent neural net- works from overfitting\u201d. In: The Journal of Machine Learning Research 15.1, pp. 1929\u20131958.\n\nWiesler, Simon and Hermann Ney (2011). \u201cA convergence analysis of log-linear training\u201d. In: Advances in Neural Information Processing Systems, pp. 657\u2013 665.\n\nThis blog post was written by Jean-Yves Pasquier. Thanks!\n\nVisit Recast.AI, our collaborative Bot Platform & join us on Twitter, Facebook and LinkedIn :)"
    },
    {
        "url": "https://chatbotslife.com/france-2-0-understanding-matcha-the-wine-advisor-chatbot-764a55f46fa2?source=user_profile---------3----------------",
        "title": "France 2.0: understanding Matcha, the wine advisor chatbot",
        "text": "As a French chatbot startup in Station F, it was only a matter of time until we started talking about wine. We met with the CEO and co-founder of Matcha, a wine technology service, to understand their product and discover their vision of winetech.\n\n\u201cMatcha develops data and wine-advice technologies for the wine industry, such as wine sellers, wholesalers and restaurants around the world, to help them sell better.\n\nThe story of Matcha started 3 years ago with Eduardo and Benoit, my 2 partners. Benoit and I were both passionate about wine and partnered up to form a sommelier consultancy for restaurants 5 years ago. As wine experts, our families and friends often asked for advice on wine choices; and during our time as sommeliers, many wine retailers and distributors we worked with were very eager to find a solution that offered their customers the best advice on wine.\n\nSeeing the opportunity, we decided to mix wine expertise and AI to create Matcha in 2016.\u201d\n\n\u201cWe created a bot that can answer any wine purchase question, just as any good wine advisor would do in a wine cellar shop or in a restaurant. We cover more than 10 use cases, and a lot more are ready to help consumers!\n\nThe first thing we did when working on the conception was focusing on natural language processing. It was mandatory for us that the bot could provide the same experience \u2014 in terms of interaction and natural conversation \u2014 that a human expert would deliver.\u201d\n\n\u201cDefinitely! Wine is one of the most beautiful products you can get. It\u2019s full of history: humans have made it for more than 5000 years! However, it is a complex and intimidating product, because most of the time, you don\u2019t have much information on what\u2019s inside your bottle. People who do not work in the industry do not necessarily understand what the cuv\u00e9e or the vintage is, and can\u2019t really learn without help. This makes the wine industry a bit inaccessible.\n\n \n\n It is therefore a challenge to mix such an emotional product with tech and AI, but the result is worth it.\n\n \n\n The winetech movement in France is getting stronger. If you ask me, I\u2019d say it focuses on two main things:\n\n \n\n \u2014 help wine makers produce better wine, by challenging the vinification and wine making processes, or assist winegrowers with issues in their vineyards\n\n- simplifying and boosting wine distribution, which is what we do at Matcha.\u201d\n\n\u201cWell! Our product market fit is good. We launched the product 3 months ago, after extensive discussion with our network of distributors about their needs and expectations. Things are going good! The first metrics show a doubling of conversion rates.\n\n \n\n We have come to a high-value niche market where the competition is emerging just like us. That means we are not a threat to anyone, have a lot of space to cover, and a lot of freedom!\u201d\n\n\u201cBuying wine should always be a pleasure, centered around quality, personalised and interactive advice. To offer this kind of service digitally, nothing comes closer than a bot. A chatbot offers an experience focused on natural and efficient conversation, and that is exactly what we wanted to offer.\u201d\n\nYou can try out Magnum by Matcha on Messenger or visit their website. Many thanks to the team for their valuable insights! Share your thoughts in the comment section."
    },
    {
        "url": "https://chatbotsmagazine.com/a-vision-into-the-future-of-hr-bots-will-help-recruiters-be-more-humane-85e137a0a2c8?source=user_profile---------4----------------",
        "title": "A vision into the future of HR: bots will help recruiters be more humane",
        "text": "A Vision into the Future of HR: Bots Will Help Recruiters Be More Humane\n\nThe Human Resource industry is on the verge of a long-awaited transformation. The need for clear and well-defined processes make it an industry ripe for automation. Yet, considering the legal and human dimensions, it isn\u2019t just about automating the customer-facing processes: it needs a complete overhaul. Language processing is rapidly evolving. We now have the tools required to design efficient HR bots to cover specific tasks.\n\nI\u2019ve recently met Arthur Boivin who is at the forefront of HR innovation to discuss these changes. The company he founded, Botmatic, is building the new tools of HR. It harnesses the power of AI to offer automated services that are tailored to each individual. We shared our vision and expertise and decided to co-produce a piece on the upcoming impact of chatbots in HR.\n\nChatbots offer a unique advantage from an HR perspective: with a bot, what you ask is what you get. To put it another way: they remove the human variable in the enforcement of processes. There will be no personal interpretation or liberties taken with the process \u2014 if the process is sound so is the service.\n\nOne of the main concerns in HR departments is compliance. They require strict controls over the processes to make sure the company is compliant with employment and hiring laws. Data-protection is also a growing concern nowadays. The arrival of the new European data protection legal framework (GDPR, which will be enforced on May, 25th 2018) might be a turning point.\n\nThe main actors in the industry will have to sanitize their practices (at least in Europe\u2026) if they want to avoid facing penalties in court. Indeed, the GDPR will completely change the way data is collected and handled:\n\nChatbots will quickly prove themselves useful for GDPR compliance: they can help get consent, update information or offer accessible opt-out options for prospects. Essentially, they reduce the pain and the necessary steps required to update your customer, prospect or candidates files.\n\nBots for Human Resources are not just another bot. The team behind Botmatic had to rethink the whole experience of creating a bot to match HR profile knowledge and habits. They launched an HR bot service built on the Botmatic conversational platform: HR Converse.\n\nThe UI is carefully thought through. Arthur Boivin, Botmatic\u2019s CEO says their goal was to create a bot builder which would be \u201cas simple as writing on Medium.\u201d\n\nIn terms of UX, it translates into two main governing principles:\n\nThe user experience on Botmatic is refreshing. The screen is divided into two panels:\n\nBoth panels are in sync with each other: moving in the conversation through the text editor will switch the tree view to the right position.\n\nWithin the text panel, symbols and indentation are used to design the conversation flow.\n\nMessages are nested together using indentation. To create a new user input with several variations, you can simply add all the variations (expressions) indented, below the input:\n\nThe creating and tagging of entities is also done from the text panel of the left. Any word can be linked to a property simply by clicking on it. On the screenshot below, \u201cengineer\u201d is being tagged as a \u201cposition\u201d.\n\nProperty is the kind of expression the bot is waiting for. Entities on Botmatic are linked to Recast.AI. No need to leave the Botmatic interface to go on Recast.AI. They work together.\n\nThe right side of the screen displays the conversation flow of the bot. It\u2019s synchronized with the left side: clicking any box in the flow will bring you where the action is in the text, and it also works the other way around.\n\nThe test console is also synchronized with the tree:\n\nOutside the bot building interface, Botmatic also provides features to segment your bot audience or create campaigns that are automatically sent when certain conditions are met. You can also handle the integrations, including ChatBase (bot analytics service) and SmartRecruiters (Applicant Tracking System) for now as well as the messaging channels: Messenger, Slack or Web Messenger. Skype will be available soon. The Botmatic team also deploy custom integration depending on the HR software used by its clients.\n\nHR Converse, the first packaged bot made by Botmatic, tackles the recruitment and follow-up processes. Right now, applying to a company is often much more painful that it needs to be. The follow-up is often still lacking.\n\nHR Converse is here to solve these issues with a chatbot. Integrated to all current channels, from emails to the applicant tracking system (such as SmartRecruiters), the bot is able to update the candidate depending on his application status. Since the update of the candidate\u2019s profile is simplified, the information stays up-to-date and actionable.\n\nThe product proved itself particularly useful for recruitment agencies. Other specific industries, such as temp agencies enjoy the accuracy of the profile the bot builds. It learns the availabilities of each worker and keeps their information updated. This gives them a better visibility of their workers\u2019 schedule.\n\nBotmatic launched its early access a few weeks ago. Among the first use cases, some workflows are already finding their purpose: data collection and updating, availability management (temp agencies) and recruitment process follow-up.\n\nTo understand what were the needs and requirements of Botmatic, we went straight to the source: Samuel Roy, Botmatic\u2019s CTO and co-founder.\n\nWe used api.AI before it became Dialogflow. It was the first NLP API we used to design our prototype. Back in the day, we were already looking for a long-term partner since NER is key in our conversational platform.\n\nOn the support part, with the first integrations coming up, we needed to get in touch with the support team. Unhappy with the reactivity from Dialogflow at the time, we looked around, tried Recast.AI and found our match. We had quick and generous answers from their support team to help us go deeper in our integrations. It was very much appreciated.\n\nOn the technical side, we also had better results with Recast.AI than Dialogflow on the text recognition part even if now Dialogflow is bridging the gap. Indeed in early 2017, Recast.AI had more entities available and more languages. More entities mean that we can deliver an accurate entity/property couple and in the end a better user experience.\n\nOn the integration part, it was not possible to create bots through the Dialogflow API. This means users would have needed to use two different interfaces to design their bot and plug it to the NLP. With Recast.AI we built a full integration and reached a one-service solution.\n\nIn the end, we chose Recast.AI as our key partner. We chose to integrate their NER solution because we needed to rely on effective support to deliver the best chatbots available 24/7. We were looking for a highly scalable service provider to grow the business.\n\nHR Converse is the first product based on Botmatic conversational platform and it will continue to expand. Indeed HR Converse is already used by recruiting and staffing agencies. It has been successful in screening candidates and keeping in touch with them long term.\n\nThe next step is HR automation with features like onboarding management. To deliver the best experience for new employees, companies can deploy 24/7 chatbots to provide safety rules, key information, registration checklist, key contacts and tips to help new recruits fit into their environment quickly.\n\nAs soon as onboarding is done the chatbot can take over and help employees manage their time off, timesheet, and overtime. They also take care of all the daily admin chores of corporate life. They\u2019ll book your train ticket to Barcelona, and the room to go with it! Companies can get quick and easy feedback from their staff to monitor their happiness at work.\n\nTomorrow, recruiters in charge of screening candidates and updating their profile on a regular basis will become copywriters. HR copywriters will be in charge of designing conversations to bring the best experiences possible to potential candidates.\n\nChatbots will free HR workers from the numerous tedious and repetitive tasks they are still doing today. Therefore, they will have the time to provide actual value to applicants. Instead of skimming through piles of CVs and taking care of the first steps of the recruiting process, they will focus on client and candidate relationships. They\u2019ll be able to be more empathetic, advise applicants on their career choices and help them find the right training for the job they want.\n\nHR people will spend more time on bringing the best experience to their talent pool rather than calling endless lists of candidates. In the end, empathy will be key and recruiters will be there to advise people on their career mobility. Chatbots will take care of the rest."
    },
    {
        "url": "https://chatbotslife.com/github-repo-heroku-explained-how-to-host-your-bot-server-python-8b3ec4f071ce?source=user_profile---------5----------------",
        "title": "GitHub Repo & Heroku Explained: How to host your bot server [Python]",
        "text": "In the first tutorial, we hardcoded the port in our script ( port = \"5000\" [line6 in server-self-run.py]). This time, we'll need to define the port as an environment variable (Heroku requirement). Hopefully, this is done in two simple steps:\n\nThe first and the biggest change we have to do is to modify the port used by our webapp.\n\nEssentially, we just need to modify the port and the host of our app. Here\u2019s how:\n\nOur server file need slights adjustments to work on Heroku. You can find both files on the GitHub repo:\n\nTo do so, we encapsulate our query in the function. Therefore, our port is now defined as it follows:\n\nNote: Although we have to import os in our script, it\u2019s not needed in the requirements.txt. Indeed, os is one of the base python library, such as time or sys: these libraries are available as soon as Python is installed.\n\n3. PUSHING THE NEW FILES TO OUR GITHUB REPO\n\nDuring the last two steps, we modified server.py and created requirements.txt, procfile and app.json.\n\nOnce we have the updated and newly created files on our GitHub repo, we are ready to deploy to Heroku.\n\nNow, that we\u2019ve been through the Git process, it\u2019s time for some good news. Heroku offers an easy and potent GitHub integration: once your connect the two accounts, new files pushed on the master repository on GitHub will be automatically deployed to Heroku (unless you rather do it manually).\n\nNote: If the CLI grew on you, or you would rather not connect your Github and Heroku accounts, Heroku also offers a CLI to deploy your servers. It won\u2019t be covered in this tutorial, so we recommend you check Heroku\u2019s Getting Started guide if you want to do it this way.\n\nThe account creation process on Heroku as it\u2019s straightforward so we won\u2019t detail it. Once you have you account, create a new app, and connect to your GitHub account to deploy it automatically. Just follow the GIF:\n\nOnce automatic deployment is active, every time you push to your GitHub repo, Heroku will deploy the new files to your server.\n\nIf you would rather deploy manually but still benefits from the convenience offered by the GitHub<->Heroku integration, you can use the Manual Deploy option (click on the button). If you do so, remember to go back on Heroku and click this button every time you update your code. Here's a GIF:\n\nOnce your app is deployed on Heroku, the only thing left to do is to tell Recast.AI where to find it.\n\nHere\u2019s the whole process in a GIF:\n\nNow, before we go on Messenger to test our bot, let\u2019s access the logs. They\u2019ll prove helpful if you don\u2019t get it working right the first time.\n\nYou have two main ways of accessing Heroku\u2019s logs:\n\nFrom Heroku website: if you click on the More button, at the top left on Heroku, you can access your server logs.\n\nFrom any terminal: if you have installed Heroku CLI (available on Chocolatey of course), you can access your logs from any terminal.\n\nYou can access the logs in real time with the following command:\n\nWith access to the logs, we\u2019ll have all we need to debug in case of a faulty script. Let\u2019s have a look at the common issues:\n\nSince we set up the webhook our bot call as , we must make sure the the bot base URL address we pasted does not have an ending /: . Here on the screen, we have a trailing slash in the bot base URL, which leads to a POST request on unable to be processed triggering a redirect (301) and method not allowed (405) errors.\n\nNO RESPONSE ON SERVER AND NGROK\n\nIf nothing happens both on your server and on ngrok, it means Recast.AI can\u2019t reach it. It\u2019s most certainly due to a typo in the bot base URL, or the complete lack of it.\n\nHeroku put your app to sleep when they\u2019ve been inactive for a while. Hence, the first user who aks a crypto price after a long downtime might wait a while. You can upgrade your account to avoid this, or make another script to keep your bot server always up. It\u2019s a great follow-up exercise.\n\nHave an issue with your bot? Is something unclear in this tutorial? Feel free to comment or join our Slack to discuss it."
    },
    {
        "url": "https://chatbotsmagazine.com/2017-bot-overview-perspective-on-top-bots-and-top-channels-for-bots-d03310f9a864?source=user_profile---------6----------------",
        "title": "2017 Bot Overview: Perspective on top bots and top channels for bots",
        "text": "2017 Bot Overview: Perspective on Top Bots and Top Channels for Bots\n\nBots have had their fair share of headlines for the last couple years, yet 2017 might have been decisive for the industry. In fact, all the major chat platforms have improved their bot API tremendously and the integration of bots within their messaging app.\n\nTalking with a chatbot is now an everyday event, while the digital marketing industry as a whole is only now waking up to the potential of bots.\n\nToday, the whole bot ecosystem is more mature. Each actor, from bot building services like us to the chat platforms is preparing their products and services for mass adoption. As a result, both the quality and the quantity of bots are increasing.\n\nThe bot ecosystem is moving away from the \u201cfun chatbot phase\u201d towards a \u201cbusiness bot phase\u201d: bots which provide the answers to actual business issues, such as the scalability of support resources. This is being driven by corporate bots such as customer support chatbots.\n\nAs the main actors, aka Messenger, Slack, Twitter, Telegram and Kik are gaining new users and bots every day, patterns are emerging. Messenger is the home of business bots for instance, while Telegram is strong on chatbot games. Each network found its target market and is now adapting to it.\n\nWinter is coming, and now is the time to look back and what happened this year on the main platforms. So, let us give an overview of the main channels for bots and what they\u2019re best suited to.\n\nMessenger is the leading bot platform for most. Many businesses now have a Messenger bot to do anything from QnA to customer support. While most messenger bots are still relatively simple, more and more complex use cases are emerging thanks to new techs.\n\nActually, chatbots were at the heart of Facebook\u2019s F8 last April [Facebook F8: what you should understand about the future of Messenger, Jasmine Anteunis, Recast.AI Blog, 19 April 2017], the team announced no less than:\n\nWant to have a deeper look at the Messenger chatbot ecosystem? Check our resources:\n\nMessenger may be one of the most visible bot platforms today, yet the competition is fierce. Numerous challengers pushing the bot ecosystem forward. Let\u2019s have a look.\n\nSlack held its developer conference, Frontiers, in September this year [ Workspaces of the future \u2014 Slack Frontiers 2017 recap, Eric Soelzer, 15 September 2017]. The team made several announcements with a recurring common theme: a gradual reduction of friction between the products we use at work every day.\n\nFirst of all, the Slack team is working towards reducing context switching, i.e allowing users to get more work done straight from Slack, with new features such as shared channels. This allows admins to open selected channels to people from other organizations, to reduce friction and increase collaboration.\n\nAlso, the team announced Drivebot, offering a deeper integration with Google Drive services. Slack found its market and is now pushing its product every day to fit it best. The impact of Slack on companies and startups has been massive already, yet this might just be the beginning.\n\nSlack bots can reach vast numbers of users in a professional context. Finally, because many Slack bots are here to make their users more productive, they can reach record high retention rates.\n\nIn its own way, Twitter was the first platform to pioneer the use of bots at scale. While it wasn\u2019t deliberate on the part of its founder (was it really? Why Twitter is still teeming with bots, Mashable, 16 October 2017), bots have amounted to a large share of the user base since the beginning.\n\nA research paper published earlier this year by the University of Southern California and Indiana [Online Human-Bot Interactions: Detection, Estimation, and Characterization, Onur Varol, Emilio Ferrara, Clayton A. Davis, Filippo Menczer, Alessandro Flammini, 27 Mars 2017] estimated the share of bot users between 9% (30 million) to 15% (50 million) of the total user base.\n\nNow, behind this reality there are two kind of bots. On the one hand, we have fake accounts made just to promote a cause or product. On the other hand, there are bots made by creative developers which cover interesting and useful use cases. This is what we\u2019ll focus on.\n\nThis year has been a busy one for the Telegram Core team too. The last major update, bot API v3.0 [Telegram Core Team \u2014 Bot API v3.0 changelog, 18 May 2017] added support for integrated payments, video messages, and multilingual bots.\n\nFurther updates followed in August, enabling a better integration of bots within the app with the inline mentions. Until now, users had to chat directly with the bot to trigger it. Now, with inline mentions, they can trigger them from any conversation. No more bots imprisoned by their own chat!\n\nTelegram host vibrant communities from all around the world, with a particularly active Russian community. Games group (such as Werewolf) make up the biggest share of the top active groups [Top Telegram Chats, Combot.org, Updated Daily] while cryptocurrencies discussions are gaining traction.\n\nWhile Messenger seems to be the preferred host for business bots, Telegram found its uses among other communities. Hence, the future is bright for chatbot-games, as the technical capabilities of bots are continuously improving allowing more diverse and engaging games to be designed.\n\nEven though Kik get less media coverage than Messenger, particularly in Europe and in the US, it is one of the pioneering chatbot platforms.\n\nKik\u2019s Bot Shop [Kik Is Launching a Shop for Users to Interact With Chatbots From Brands, Adweek, 5 April 2016], was launched more than one year prior to Facebook\u2019s equivalent (the Discover tab announced at F8).\n\nKik\u2019s team has a great vision for their product, which they envision as a whole ecosystem. Here\u2019s how Ted Livingstone, CEO of Kik presents the project:\n\nOur ultimate vision is for Kik to be one of hundreds or thousands of digital services for Kin.\n\nThe Kik team experimented with integrated payments when they launched the Kik Points three years ago [Kik Points Are Here!, Kik Blog, 11 December 2014]. Now, they are moving forward with a cryptocurrency, a token called Kin. The ICO ended in September, successfully raising $98 million.\n\nThe seamless integration of payments in a messaging app is a must-have for user retention. Kik\u2019s previous experiences on this issue might give the team a welcomed head start to make their vision a reality.\n\nTo wrap this up, let\u2019s have a look at what we had just a year ago. Last January, we wrote our first top with ten impressive bots back then:\n\nThe top bots which made it to the 2017 version (such as Instalocate) dramatically evolved. They gained loads of features and greatly improved their understanding of natural language.\n\nEven so, most of the top bots of 2016 were simply pushed out. New bots tackling innovating use cases and providing a better experience replaced them. That might be the one key takeaway of this retrospective: a chatbot is a forever ongoing project.\n\nUndeniably, top bots which stay there are being constantly monitored and improved by their makers. Only an objective look at the data can tell if a bot is working as intended.\n\nHave an issue with your bot? Is something unclear in this tutorial? Feel free to comment or join our Slack to discuss it."
    },
    {
        "url": "https://chatbotslife.com/introducing-bot-skills-or-how-to-provide-outstanding-conversational-experiences-c840f03be336?source=user_profile---------7----------------",
        "title": "Introducing Bot Skills: or how to provide outstanding conversational experiences",
        "text": "Developers are now aware that bot building is something they might have to do in the coming years. Bots are finding their place in private and professional lives, as many use cases focus on augmenting our productivity or addressing business challenges.\n\nHowever, bot building is still a mystery to many, and isn\u2019t clearly defined: it\u2019s coding, but it\u2019s also implementing a conversational logic, and it has a big language component. Often, building a bot is very time consuming, and time/quality ratio isn\u2019t very rewarding to a developer.\n\nAnd sometimes, the whole experience is even frustrating! A developer can have this amazing AI idea in mind, but fail to create it through lack of means, lack of appropriate tools or an underperforming technology.\n\nTo solve these issues, we\u2019re launching a brand new bot building tool to improve the quality of your bot building and keeping it as simple as before: Bot Skills. Bot Skills are a new bot making concept. They allow you to go much deeper in the perfecting of your conversational interfaces.\n\nWhen building a bot, many people create a dialog tree, but they aren\u2019t usually very efficient. It is much more powerful to think in terms of \u201cwhat will my bot know how to do? What are its tasks and abilities? Will it give me the weather and the time?\u201d. When thinking like this, you quickly understand the purpose of Bot Skills. A skill is a defined brick in your bot which manages one specific part of the conversation, such as greetings, weather, order, payment, and many others. Therefore, when building a bot, it\u2019s essential to build the skills you want it to master.\n\nThink of your bot flow differently with triggers and requirements\n\nBot Skills introduce two new concepts: triggers and requirements. Usually, in bot building, the bot brings the user along a specific path. With Bot Skills, the bot reacts to user inputs. That makes it very adaptable, giving the lead of the interaction to the user. A trigger defines why a skill should be activated after a user message (e.g after the mention of a word or detection of an intent); a requirement is a key information necessary to complete the skill (e.g obtain the email and user ID to complete a booking).\n\nWith these new elements, you are able to create much more adaptable flows: whether the user gives all the information, none at all, or one piece at a time, your bot juggles through the responses to get the necessary data and complete the conversation, without you having to code this logic.\n\nIntegrated into our new Bot Builder is a rich messaging creation module which allows you to create bot answers in rich messaging directly on Recast.AI. You don\u2019t need to do it in your code anymore! Now fully integrated with Bot Connector, you can connect to any channel that supports rich messaging in a few minutes.\n\nCall external services easily with webhooks integrated in the platform\n\nBot Skills can ping any external service through webhooks, such as an API to connect to client databases (e.g. world weather or train schedules APIs) or your own. Everything is integrated in the platform.\n\nBenefit from a community of 22 000+ developers sharing their skills\n\nSince its foundation, Recast.AI has been built on the idea of community. Skills are no exceptions! They are sharable, forkable and improvable by all Recast.AI members. Today, more than 22 000+ developers use our platform to build bots. So if you\u2019ve built the most amazing flight booking skill, please share and show it to the world! We\u2019ll also be happy to promote it for you.\n\nWe hope these features will allow you to go further in your bot building to provide outstanding experiences. You can check our changelog and tutorials to keep improving your bot building skills! Happy coding.\n\nJoin our Slack to exchange with botmakers from all around the world and learn the best practices."
    },
    {
        "url": "https://chatbotsmagazine.com/the-art-of-bot-design-178f8dc8bfdf?source=user_profile---------8----------------",
        "title": "The art of bot design \u2013",
        "text": "We will come back to the second item from the Unix philosophy later in the article, be patient. \ud83d\ude09 Also, notice the third item about text streams; with chatbots we are spot on!\n\nThis identity is the heart of your bot ; from the very start, it should be clear for users what they can expect from it. They should be reminded regularly what the bot is able to do and how to interact with it . Keep it as lean as possible because, even if your bot does one thing, human conversation will bring new cases to handle which can quickly get out of control.\n\nBot identity doesn\u2019t refer to the personality but really to what the bot can or cannot do. It can be seen as a user story; would you start working on a feature without a user story? That\u2019s the same for a chatbot, it is nonsense to start training without an identity.\n\nI\u2019m a strong advocate of this philosophy and I think it applies to all kinds of programs including chatbots. It is particularly important for chatbots to do one thing and do it well because they handle an input as beautiful as it is evil: human conversation. Even for a simple use case, the spectrum of possible conversations is just too large so design little , minimal and start off with a clear bot identity.\n\nLike any project, bot training has to start with design so today we will learn exactly that: how to design the smartest of chatbots , based on machine learning. Buckle up! It\u2019s gonna be design all the way down .\n\nBot developers can now focus on the heart of their chatbots: its NLP training and this is a crucial part because you want your bot to be well-trained and feel smart.\n\nBot building requires a variety of development skills like bot design, hosting the bot, connecting it to channels, writing some code or training intents. Mastering all skills can be painful so we work hard at Recast.AI to ease each step of the bot building process . After the release of our Bot Connector, we are proud to have shipped a new Bot Builder to speed up this process even more.\n\nBecause it will be here sooner than you think!\n\nIndeed, every bot project starts the same: Define the identity\u2026 Wow, the bot is very simple to implement, it should be quick!\n\nSlow down my friend and expect some bumps on the road. As minimal as your bot may be, it will necessarily face additional unhandled questions. This is the periphery of the bot identity or its perimeter. Here again, you must keep it small and lean.\n\nLet\u2019s illustrate this phenomenon with a simple package tracking bot. When given a package number, the bot can reply its status. \u201cOrdered\u201d, \u201cShipped\u201d or \u201cDelivered\u201d. Now, here are the kind of rebound questions you could expect:\n\nThis is the periphery of your chatbot. Don\u2019t worry though, your bot does not need to handle everything, quite the contrary, its perimeter must be kept minimal. There is a general rule of thumb to define the right perimeter: your bot should know the meaning of everything it says to the user.\n\nHere, as the bot replies three different statuses, it must be able to explain what each status is or it will just look stupid. Because of this rule, it is usually good practice to create gazettes. Gazettes bundle together words that belong to an entity so they are well suited to list the business vocabulary the bot will face. Extending the bot will be much easier if it can refer to a finite list of what it should know ;)\n\nNow that you have a clear identity and a limited and defined perimeter for your bot, it\u2019s time to design your bot training! It was a long road but skipping previous steps would produce a weak, incoherent bot.\n\nTraining a bot is about filling intents and tagging entities; if you\u2019re not 100% clear with what intents and entities are, start with this tutorial.\n\nFilling intents with expressions is equivalent to building a sentence classifier: Whenever a user sends a new sentence to your bot, it will be classified into one of the intents. You can visualize your bot training as a set of clusters: large circles in a two-dimensional space, one circle per intent and incoming sentences are assigned to one of the circles.\n\nHere, all clusters are dissimilar enough but for a a risk of overlapping between the blue and black one which are dangerously close\n\nThe classifier will be efficient if the circles are well separated. The key is to maximize the inter-cluster distance. The extra difficulty with NLU is the diversity of expressions needed for an intent. Each circle must be large enough without overlapping.\n\nIt\u2019s tricky to build an efficient classifier and these are some common pitfalls:\n\nWhen facing these expressions, the classification won\u2019t be accurate enough. You could force the separation by training each intent with new expressions but you will end up with hundreds of them, living in the fear of a classification mismatch. Don\u2019t fix your classifier down the road, design it correctly early on ;)\n\nAll sentences containing said entity will end up in this intent: a real classification black hole! Entities should enrich incoming sentences, not impact the classification. You might think \u201cIt\u2019s fine, I\u2019m sure this entity will only be useful in this particular context\u201d. Sadly, your bot will quickly struggle with new rebound questions about this entity. Because of the black hole, you won\u2019t be able to classify these questions.\n\nTo find out about your intents\u2019 diversity, check the \u201cTraining analytics\u201d of your bot in the Monitor tab. A bot missing diversity will feel like a child that knows a single way to express each intention. Try to reach about 30 expressions per intent and don\u2019t hesitate to fill in long expressions and common typos.\n\nHow can you avoid these pitfalls? By following some design guidelines ;)"
    },
    {
        "url": "https://chatbotsmagazine.com/nodejs-chatbot-tutorial-a-movie-bot-with-recast-ai-6a68ca1da524?source=user_profile---------9----------------",
        "title": "NodeJS chatbot tutorial: A movie \ud83c\udfa5bot with Recast.AI",
        "text": "By the end of this tutorial, you will be able to build a fully functional movie bot! It will able to make movie recommendations based on several criteria. We\u2019re using Recast.AI platform to build the bot and The Movie Database for information on movies.\n\nNeed to see it to believe it? That\u2019s wise. Come have a chat with MovieBot then (Messenger).\n\nInteracting with third party APIs (such as The Movie Database) allows for much more interesting use cases that simple QnA chatbots. With Bot Skills, we added the option to call webhooks directly from the builder, which makes it even easier.\n\nYou\u2019ll need a Recast.AI account, Node.JS and potentially Ngrok for testing.\n\nBefore we jump in, please check this guide instead if you are looking for a guide detailing the creation of your first bot.\n\nThis tutorial covers Node.JS only. If you would rather code with Python, check this tutorial covering a similar use case.\n\nLet\u2019s get to it!\n\nIntents are helpful to determine the overall meaning of a sentence. For our use case, knowing that the user wants to watch something is not enough.\n\nWe need to know what the users want to watch.\n\nEntities are designed to solve this problem: they extract key information in a sentence.\n\nLet\u2019s imagine you are a telco company providing phone and internet access, and your bot has an intent that understands when people are complaining about an outage:\n\nThe entities extracted will help understand what is going wrong, where and since when.\n\nFor our movie bot, we will try to extract 3 key pieces of information:\n\nTo help you speed up your development, Recast.AI extracts several entities by default : Dates, locations, phone numbers\u2026 An exhaustive list is available here.\n\nThe entity will be helpful:\n\nSee the little star next to the entity name? It differentiates a gold entity from a custom one.\n\nWe will use it to fulfill our third requirement: the movie language.\n\nWe will create custom entities to extract the information we need. As with intents, training is very important: the more examples you add to your bot, the more accurate it gets.\n\nTraining your entities can happen through multiple intents. Entities are independent of intents.\n\nFor our movie bot, we only need one intent, , and 3 entities:\n\nOpen the intent and add expressions. Make sure to cover every possibility, this means a healthy mix of expressions with:\n\nTo tag your expressions, select the text you want to tag and type your entity name:\n\nYou should add many more examples: 15 would be nice, but a production-ready bot would require at least 40 examples to perform well.\n\nSince we just need to make sure all our criteria are filled before calling a Node.JS API, the build part will be rather simple.\n\nWe will just need one skill, let\u2019s call it .\n\nYou can find an example of a configured skill here.\n\nWe want to trigger this skill if the intent @discover is present:\n\nThis tab helps you collect data before moving to Actions.We want to make sure the user specifies a medium, a genre, and a language before moving on:\n\nThe requirements will be checked one by one. They can all be fulfilled on the first message, for example if the user says I want to watch a crime movie in English, then the Actions will be triggered immediately.\n\nFor each Requirement, you can choose to send a message if it is complete or if it is missing.\n\nSending messages when a requirement is complete can make your bot more lively: A crime movie? I love them too!, but are almost mandatory when the requirement is missing: You need to ask your users to fill what you need to know.\n\nFor example, I send quick replies with suggested genres if #genre is missing:\n\nOnce you have setup questions for the 3 groups of entities, go to the tab.\n\nOnce the requirements are fulfilled, we want to call our API to actually perform the search.\n\nCreate a action. You can either type a full URL (eg: ), or a relative url ( ). Recast will use the parameter in you bot settings when you type a relative URL.\n\nNext, add an action to empty the memory once the call has been made.\n\nIf you don\u2019t have a public server, or if you want to test your bot during development, ngrok is a very handy tool: It creates a public URL for you and forwards requests to your computer.\n\nOnce you installed it, run\n\nAnd copy the URL (https://XXX.ngrok.io). All requests made to these URL will be forwarded to the port 5000 of your computer.\n\nAll your bot needs now is its API to get your movies!\n\nThe NodeJS part of this bot is fairly simple: It will behave as an HTTP proxy between Recast.AI and The Movie Database.\n\nWhen your application receives a request from Recast, it sends a search query to the Movie Database with the criteria of your user and formats the JSON answer to the Recast\u2019s message format.\n\nYou will need a token to use the Movie Database API, go here to generate one, and fill your file:\n\nLet\u2019s create an Express application to handle the requests from Recast:\n\nWe asked Recast to send a POST request to when a user has filled his search criterias.\n\nThe main goal of our controller is to pick and format the preferences from the memory to send them to the Movie Database\u2019s API:\n\nThere are two functions here that we have not declared yet: and .\n\nWe need because the Movie Database can't search for a specific genre based on its English name, but rather on a custom number.\n\nHere is how to translate a genre name to its id:\n\nNow that we have extracted and formatted all the filters of the request, we need to send the request to the Movie Database and format the answer:\n\nAll being well, you should see:\n\nMovie recommendation, weather, health, traffic\u2026 With third-party APIs, everything is possible! Now that you\u2019re familiar with the workflow, we can\u2019t wait to hear from you about what you\u2019re building!\n\nHave an issue with your bot? Is something unclear in this tutorial? Feel free to comment or join our Slack to discuss it."
    },
    {
        "url": "https://chatbotsmagazine.com/build-a-cryptocurrency-chatbot-with-python-meet-sato-the-cryptobot-c8dd59423f25?source=user_profile---------10----------------",
        "title": "Build a cryptocurrency chatbot with Python: Meet Sato the cryptobot",
        "text": "Chatbots have an incredible potential. Yet, for bots to be efficient, they must integrate and exchange data with existing services and processes.\n\nThe ability to fetch data from external API allows for more complex use case that a simple Q and A logic. Moreover, this ability combined with NLP offers even more opportunities.\n\nFor instance, Sato \u2014 the cryptobot we\u2019ll be building today, is able to recognize all cryptocurrencies, even those not even listed yet. I won\u2019t have to do anything for him to be able to process queries on crypto appearing even years from now, because Sato, deep-down, understood what a cryptocurrency symbol is (after being fed with thousands of them).\n\nBy the end of this tutorial, we will have a bot able to fetch data from a third party API depending on what our users input, and reply to them with the value fetched. Here\u2019s the end-result of what we\u2019ll build today: a cryptobot aka a chatbot able to fetch any cryptocurrency price.\n\nIn a rush? Here is all you need to build your own:\n\nNeed to see it to believe it? That\u2019s wise!\n\nOr if you would rather understand how it was made, go through with the tutorial.\n\nThe goal today is to build bot able to recognize a question about pricing on any cryptocurrency. Let your imagination flow, it could be really anything there is involving data available on third party APIs.\n\nBefore we dive in the tutorial, let me give you some information on how Sato works.\n\nSato is a bot made to answer basic questions about cryptocurrencies and fetch their prices. Here\u2019s an overview of what he can do:\n\nToday, we\u2019ll focus on the skill fetching the crypto prices, as it requires an external API call. Essentially, Sato needs three things to be able to detect a question about crypto price and return the value asked:\n\nFirstly, he needs an intent (@crypto_price) with diverse expressions and cryptocurrencies mentioned, so he can efficiently recognize these questions. Here are some of the expressions used to define the @crypto_price intent:\n\nSecondly, for Sato to be able to recognize all cryptocurrencies, he\u2019ll need the biggest list you can find. I found 1200+ on CoinMarketCap which is good enough to begin with. I created a gazette of the crypto names to improve its understanding.\n\nThirdly, we\u2019ll need to build a skill which triggers when the @ask_price intent or #crypto_name entity is recognized:\n\nYou can also add #crypto_name as a requirements, to make sure no API called is fired without parameters:\n\nThis skill must also call your webhook that we\u2019ll setup below:\n\nDon\u2019t forget to add a memory reset after the webhook trigger, it\u2019s required to clean the memory after each answer.\n\nFinally, we\u2019ll test our bot straight in Messenger, so you\u2019ll need to create a page and an app and connect it. Everything is documented in the tab and in the getting started tutorial.\n\nTo keep it concise, this tutorial will not detail the creation of a bot. We\u2019ll start from a functioning bot already.\n\nTo meet me there, you have two options:\n\nYou\u2019ll also need an account on Recast.AI to complete this tutorial.\n\nNathan wrote an exhaustive tutorial on how to build your first bot with Recast.AI so I\u2019ll leave the basics to him. Feel free to reach our to our community on Slack if you need some help.\n\nRecast.AI is collaborative bot platform, it works pretty much like GitHub. Which means you cansimply fork my bot Sato and start from here. Here\u2019s how:\n\nSince we want to interact with our bot, we\u2019ll need a server to be able to receive the results of the NLP made by Recast.AI and send our responses back.\n\nOn the bot builder, go to the tab to find an example of base code required to start your API. We give examples in Node.JS, PHP, Python and Ruby. This tutorial will be Python only.\n\nTake some time to look at the code to get a better understanding of what we\u2019ll be doing: we\u2019ll build on this code during this tutorial. You can save it in your favorite text editor for now.\n\nAs you can see, the server script uses the Flask as a web framework, so we\u2019ll need it.\n\nFor the API call, we\u2019ll also use Requests. Let\u2019s go ahead and install both:\n\nNow that we have the base server, let\u2019s make it run and test it. It will allow us to be more incremental in the process so the debugging (if any) is simplified.\n\nTo expose our local server to the internet, we\u2019ll need ngrok.\n\nNote: If you are using Windows like me, there is awesome package manager \u2014 Chocolatey which works pretty much like apt-get on UNIX. With it, you\u2019ll be able to install ngrok in one line . Moreover, Chocolatey adds ngrok to your PATH, allowing you to start ngrok from any terminal simply by typing .\n\nNow is the time to start our server and test it, this implies:\n\nHere\u2019s is the whole process in a GIF:\n\nIt\u2019s about time to start building! Let\u2019s have a look at the api call we\u2019ll be doing to get the price of any cryptocurrency. Several APIs are available for this purpose so I just went ahead and picked one: Cryptocompare API.\n\nCryptocompare API offers thousands of possibilities, but for the sake of simplicity, we\u2019ll stick with the basics. We want the price of the matched crypto in BTC, USD and EUR.\n\nHere\u2019s how the call is structured(here for ETH):\n\nYou have two parameters:\n\nSo, in our case, we\u2019ll only need to adapt the parameter to the recognized cryptocurrency, while the rest of the call stays the same.\n\nNow that we know how to fetch the prices, we need to go back to our server code and upgrade it so it can:\n\nLet\u2019s have a look at the data returned by Recast.AI on a user input. To do so, you click the button present on all pages, on the top-right. Then, you can switch between the smart view and the JSON view by using the toggle highlighted below:\n\nHere, our symbol is accessible with . Since the value and the raw and identical in this case, you can use either.\n\nOn our server, the JSON returned by the website test panel is encapsulated into the dictionary (see server code). So we need an extra step to retrieve it on our server:\n\nFor the API call, we\u2019ll be using Requests. Don\u2019t forget to import it in your server\u2019s script, then, we build our base request (r):\n\nGo ahead and print it, but you may be disappointed:\n\nIndeed, if you want to get the values returned by the call, you need to print . The good news is that JSON returned by Cryptocompare is really as simple as it could be:\n\nGreat! Now, we just have one last step to figure out: returning the prices to the user.\n\nNow, it\u2019s time to finish our base server code upgrade: we need to edit the replies returned to include our freshly fetched data. To do so, we\u2019ll edit the message returned by our server code:\n\nWe\u2019ll be editing the replies only, to include the prices we fetched:\n\nSince the reply is a string, we must use the modulo (%) operator to include our prices in the string. Here, the first %s tells Python to look for a string while the two following %f indicates floats.\n\nOur upgraded server is now finished, here\u2019s the whole code :\n\nWith our new server completed, we now have all the pieces of our puzzle. Let\u2019s assemble it:\n\nHere\u2019s the whole process in a GIF:\n\nNow that you have the basics to build a bot able to fetch third party data, what\u2019s gonna be? You show us!\n\nPS: Since this tutorial uses ngrok, your computer must be on and ngrok must be running for your bot to function. Next week, we\u2019ll see how to host your server so it is always available. In the meantime, happy bot building! \ud83e\udd16"
    },
    {
        "url": "https://chatbotsmagazine.com/top-telegram-bots-of-2017-8-innovating-and-fun-chatbots-2f7b7d025be7?source=user_profile---------11----------------",
        "title": "Top Telegram Bots of 2017: 8 innovating and fun chatbots",
        "text": "Along with Messenger and Kik, Telegram has been one of the pioneering messaging platforms for bots. Indeed, their bot API was launched more than two years ago already, in July 2015.\n\nSince then, a tremendous amount of bots popped on the platform, with various level of utility. To save you some tedious digging, we went in, tried a countless amount of them and went back with our top telegram bots. Without further ado, here are our top telegram bots:\n\nStorebot is a bot made to help you find more bots: it\u2019s no self-replicating AI yet, but will pass as close enough. After a quick setup (time zone and age for NSFW telegram bots), you can start the discovery.\n\nYou can display the top charts, search bots directly, or browse them by categories. Here\u2019s what Storebot had for me when I searched for \u201ccryptocurrency\u201d:\n\nIt\u2019s one of the best designed bot on Telegram, give it a try at least to see what a Telegram bot can do!\n\nIf This Then That is a tool which lets you create workflow linking two different apps together, such as: \u201cWhen I publish a new tweet, add it to a Google Sheets.\u201d\n\nTelegram is fully integrated on IFTTT which lets you interact with any apps you have connected to IFTTT, straight from the Telegram chat: you can trigger an external service simply by messaging a bot.\n\nConsidering the countless amount of possibilities this integration offers, it\u2019s definitely one of the most potent bots available now on Telegram. Check it out.\n\nDon\u2019t let yourself get fooled, this bot is sadly not a time machine. Unlike Slack, Telegram does not have a built-in reminder function and this is precisely what Delorean_Bot is offering.\n\nThe UI is neat, and the bot is really straightforward and easy to use. The features are a bit limited, but more than sufficient for simple reminders. Try it out.\n\nTelegram is awesome, but yet have to conquer the world. Hopefully, there are bots available to give your telegram groups more reach. Channels2Rss Bot does exactly what it names would suggest.\n\nThe bot generate an RSS feed from any channel or group of your choice, making it easy for non-Telegram users to at least follow the discussion happening on the platform. What\u2019s not to like?\n\nReaching a team decision is hard; some projects stall just because they are not owned or pushed by anyone, or blocked by some. Every messaging apps now have polling solutions, either built-in or available with a bot.\n\nTelegram is no exception and that\u2019s precisely what Pollbot is about. It lets you create bots you can then send to your friend. It\u2019s unobtrusive and tremendously simplify collaborative workflows. For large groups which need to reach a consensus (hello cryptocurrencies), it\u2019s a must!\n\nTelegram is the home of cryptocurrencies. Indeed, almost all crypto have an official Telegram group. Along with Reddit, this is where most of the community discussion takes place.\n\nConsidering the pool of crypto-enthusiast on Telegram, it\u2019s no surprise to find a top telegram crypto bot on this list. MoonKeyBot does one thing and does it well: it notifies you of pumps (important price movements) in formation.\n\nWikipedia will be 17 years old soon, and for most of us \u201cdigital native\u201d, it had been here since our very early days on the internet. Have the knowledge base of the world available at hand is awesome, but what makes it even better are all its integrations.\n\nWiki is one of these. It let you search and pull entries from ANY chat on Telegram, using the @wiki \u201cquery\u201d command. Here is an example on @wiki Telegram:\n\nNo more excuses for not checking the wiki!\n\nHave you ever played the game Cards Against Humanity? It\u2019s a party game in which players complete fill-in-the-blank statements using words or phrases typically deemed as offensive, risqu\u00e9 or politically incorrect printed on playing cards.\n\nIt\u2019s fun and translates pretty well into chat form. The bot was made a year ago, by a fellow Redditor (u/davepike/) and received an instant traction from the community. Give it a go with your friends!\n\nIf you didn\u2019t find a match in the list above, you can still build your very own chatbot. We offer a bot building platform, allowing you to easily create bots powered by a strong NLP technology. With the Bot connector, you can connect your bots to the main channels in minutes, including Messenger, Kik, Slack or Twitter.\n\nDon\u2019t know where to start? Check our tutorial: Make your first bot on Recast.AI\n\nIf you would like to go further, you can also access our NLP directly with the API.\n\nTelegram has been very aggressive on its bot platform, constantly adding new features allowing to create smarter and more integrated bots. Six months after the beginning of bots on the platform, they added inline bots (like @wiki) which can be triggered from any chats.\n\nTelegram doesn\u2019t have as much visibility as Messenger for bots, yet the features it offers to bot builders are impressive. 2018 will be an interesting year for bot platforms, stay tuned."
    },
    {
        "url": "https://chatbotslife.com/top-slack-bots-of-2017-10-chatbots-and-a-few-hacks-ef8aaf6c87db?source=user_profile---------12----------------",
        "title": "Top Slack Bots of 2017: 10 chatbots and a few hacks",
        "text": "Top Slack Bots of 2017: 10 chatbots and a few hacks\n\nIn a few years since its launch in August 2013, Slack quickly became the reference for communication and collaboration in the corporate world. One the main feature that allowed Slack to reach its critical mass this fast is the incredible customization potential it offers.\n\nThe SlackBot and GrowthBot are now well known and widely used. Yet, there are countless of other incredible bots, hacks, and integrations available on the platform. Here is a quick selection of our top Slack bots:\n\nWorkbot works like a Zapier/IFTTT (IfThisThenThat) for Slack. It allows you to create workflow connecting different apps and chat inputs together. It can prove itself useful from anything from support ticket management, IT and security procedures.\n\nWorkbot is currently able to connect to 200+ apps. The goal of Workbot\u2019s team is to offer \u201ccodeless\u201d integration. More than 150 000 recipes are available and ready to deploy in a few hours.\n\nHow awesome would it be if you could summon an army of monkeys, right from Slack, to try clicking any buttons, links and such of your website? Then, the monkey commander in chief will get back to you with a detailed report of every 404, images missing alt descriptions, pages missing meta and so on.\n\nIt\u2019s precisely MonkeyTestIt\u2019s goal: their digital monkeys try every interaction possible on your website on your behalf so you don\u2019t have to. It makes sure you haven\u2019t missed anything. Expect the cutest monkey emojis with a thorough reporting, the perfect balance of facts and fluff.\n\nWhen your team gets larger, it becomes harder to preserve the start-up spirit and atmosphere. Lunch outings are particularly difficult: between the different lunchtime and dietary preferences, it can be quite a back and forth to reach an agreement.\n\nNot anymore, with LunchTrain! No more spams in your channel for lunch negotiations: with a simple command (/LunchTrain) any user can propose a train. The bot then reaches to all users privately to offer them to \u201cboard the train\u201d (=get notified when the party is leaving).\n\nFinally, a way to plan group lunch outings without spamming the Slack!\n\nSharing knowledge within a team and a company is essential: the bigger the company, the harder the challenge. Powered by machine learning, Obie.AI provide instant answers to any questions your team asks.\n\nBe it for onboarding or developing an internal knowledge base, Obie quickly proves itself useful to keep the team focused and informed.\n\nEven in a 20 person startup, finding a time where all expected participants of a meeting are available is definitely a pain. Meekan is here to help you find the perfect meeting time in seconds!\n\nIt integrates with Slack and common calendar apps (currently Google Calendar, Office 365 and iCloud). Meekan is fast and particularly handy if you have to coordinate teams working in different time zones. Give it a try!\n\nReaching a team decision is hard; some projects stall just because they are not owned or pushed by anyone, or blocked by some. Conclude lets its users start a session and share their idea with the /propose command.\n\nIt creates a dedicated chatroom for the decision where users will be able to discuss it. Once they reach a conclusion, they can close the room with /conclude. The chat is saved and archived for later.\n\nSometimes, simpler is better! If Conclude seems too much for you, we\u2019ve got a back-up plan: SimplePoll. It lets you create polls straight in Slack, using the /poll command. Here is an example: .\n\nDonut is quite different than the other bots we presented today. Indeed, Donut is made for community Slacks, to foster engagement and exchanges. In a sentence, what Donut does is matching two users together and encouraging them to meet.\n\nYou can create a dedicated channel for Donut, and it will pair its members via Direct Message (DM) every 1\u20134 weeks. The pairings can be especially helpful for onboarding because they help integrate new hires into your existing community.\n\nSlack simplified file sharing within teams, allowing for direct exchanges bypassing the folder/sharing structure of files sharing app (Dropbox, Google Drive\u2026). Yet, if a lot of pictures are shared daily, it quickly becomes hard to retrieve old images.\n\nThat\u2019s precisely where Pixibot comes into play: it analyses every single image uploaded to your Slack, read and extract its text and then saves the information it retrieves as comments under the image. Essentially, Pixibot creates a searchable archive of all your images by tagging them.\n\nSocial Media is huge yet more time-consuming than ever. For a brand, being efficient on social media means enforcing a well-thought process and finding the best tools. Although social media management solutions on Slack are obviously limited, some are quite efficient at taking tedious tasks out of your hands.\n\nThis is precisely what Yala is about: it uses AI to find the best time to post and help you improve your social media presence overall. It currently supports Facebook, Twitter, and LinkedIn.\n\nIf you didn\u2019t find a match in the list above, you can still build your very own chatbot. We offer a bot building platform, allowing you to easily create bots powered by a strong NLP technology. With the Bot connector, you can connect your bots to the main channels in minutes, including Messenger, Kik, Slack or Twitter.\n\nDon\u2019t know where to start? Check our tutorial: Make your first bot on Recast.AI\n\nIf you would like to go further, you can also access our NLP directly with the API.\n\nSome Slack integrations are incredibly useful yet very basic. They are mostly one-feature-app, which makes them a bit too simple to be classified as \u201cSlack bots\u201d in our book. Nevertheless, these apps can be incredibly useful, here are our favorite Slack hacks:\n\nNot a hack per-se, but it can make you tremendously more productive. You can view all shortcuts with the /shortcut command.\n\nWith a slash command, Website Screenshots returns a screenshot of the specified URL to the Slack channel. Incredibly simple, and more or less useful depending on the situation.\n\nThe reminder function is handy to not forget about small and recurring tasks. It supports recurring reminders ( /remind me every Tuesday at 11AM to do something ) and depending on your Slack's permissions, it lets you create reminders for other persons.\n\nWhen a reminder is triggered, the Slackbot will come to remind you. It also offers several postponing option, built-in. You can view all of your reminders with the command.\n\nWant to go deeper into Slack bots? A few months ago, we collected a list of 700+ Slack bots and produced an infographic to represent the most recurring bot categories.\n\nClick here for more info on the infographic and to see our full list of 700+ Slack Bots"
    },
    {
        "url": "https://chatbotsmagazine.com/top-messenger-bots-of-2017-8-chatbots-setting-the-bar-ff450d69e74c?source=user_profile---------13----------------",
        "title": "Top Messenger Bots of 2017: 8 chatbots setting the bar",
        "text": "Messenger is definitely one of the main bot hubs. Since the F8 conference earlier this year, Facebook clearly made bots a priority. And they were right to do so: the amount of bots available on Messenger exploded. The recent launch of the \u201cDiscover\u201d tab on the apps is another strong signal: it helps users find new bots to chat with.\n\nNowadays, most of the big companies already have a Messenger bot or are planning to build one.\n\nSo, we\u2019re left with a platform aiming to become/stay the #1 Bot Platform and an armada of bots. Some are impressive, yet most are simply bland. In the hope of pushing bot makers to surpass themselves, or simply giving some visibility to smart and efficient bots, we decided to establish a selection of our top messenger bots.\n\nHere we go!\n\nDoNotPay is offering free legal assistance to people in diverse situations. Its creators are constantly offering new use cases. Initially, it offered free legal aid to people seeking asylum in the US and Canada by helping them complete immigration form. Now, they even offer a chatbot to take part in Equifax\u2019s class actions. More than 1000 different bots are available, and the users can look for one relevant to their situation directly for DoNotPay homepage.\n\nWe are enthusiastic to see the legal use cases of chatbots getting traction: it seemed like an obvious one since the very beginning. We expect DoNotPay to be the first of many.\n\nMeetic/Match launched its chatbot this year, Lara. Lara is essentially a conversational interface to Match\u2019s services: she guides users through the creation of their profile and quizzes them about their preferences to find the best matches. Everything happens within the messaging app, so the users don\u2019t have to switch.\n\nWe love Lara because it seems to be an innovative response to the \u201cswipe fatigue\u201d which appeared in the wake of Tinder. Let\u2019s see how she goes from here.\n\nBots, among many other things, can be a tremendous personal assistants. MeditateBot helps you stay calm \u2014 a simple but powerful value proposition, right? To do so, the bot guides its users through meditation exercises. Users can also set daily reminders to get into a regular meditation habit.\n\nWe are watching MeditateBot closely because its seems like the next step after the first wave of basic assistant bots (weather, movies, news\u2026). Indeed, this time the bot goes a step further and fully integrate itself into the daily routine of its users. Winning bet?\n\nWTF is That is the perfect example of \u201csimple yet powerful\u201d. You take a picture, send it to WTF is That and it literally tells you WTF is that thing you just sent him. The use case is light, yet it is a very good showcase of the potential of computer vision.\n\nThis bot is essentially a showcase of the recent progress made with computer vision tech. Expect to see a lot more bot with computer vision in the coming years, with more and more complex use cases and abilities.\n\nLearning a language is hard. Even if your motivation is huge, it\u2019s a permanent effort to find time every day to practice. Duolinguo, a language learning app decided to go one step further with chatbots: Duolingo bots. It makes it easy to practice writing in another language. The user can pick the personality of the bot he interacts with, to make it more fun.\n\nEven though the conversations are still simplistic, we think Duolinguo is pioneering a use case that has the potential to become massive in the upcoming years. Stay tuned!\n\nThis one is much more specific than the others \u2014 it\u2019s mostly a bot for frequent flyers. Instalocate tracks flights for you, straight on Messenger. You can receive alerts about delays, query him about the flight status or get a compensation easily in case of a delay.\n\nInstalocate is particularly interesting because it mixes two use cases: the information bot (flight tracking/status) with features similar to DoNotPay since it also helps you get compensations in case of delays.\n\nERWIN is a riddle bot. If you are the kind of person who is excited by solving a puzzle, you may fall in love. You start the game by asking a riddle and everything goes from here, right in Messenger. If its riddles are too difficult, ERWIN can also give clues, you just have to ask for it!\n\nBots have been around for a while and we\u2019ve been expecting a good riddle bots for a a while already. Erwin is one of the most promising bots on this use case, let\u2019s wish him the best!\n\nProjectMurphy is a bit different from the other bots presented today. While its use case is purely about having fun, it does it quite well: he answers \u201cwhat if\u201d questions. The conversation flow is simple: you ask ProjectMurphy essentially anything and it replies with a picture that represents the question.\n\nWe tried it with diverse sort of questions, from the most basic to existential questions and were not disappointed.\n\nIf you didn\u2019t find a match in the list above, you can still build your very own chatbot. We offer a bot building platform, allowing you to easily create bots powered by a strong NLP technology. With the Bot connector, you can connect your bots on the main channels in minutes, including Messenger, Kik, Slack or Twitter.\n\nDon\u2019t know where to start? Check our tutorial: Make your first bot on Recast.AI\n\nIf you would like to go further, you can also access our NLP directly with the API.\n\nWant to go deeper into Messenger bots? Earlier this year, we listed 1000+ Messenger bots and sorted them by category. Here is the infographic:\n\nClick here for more information and to see the full list"
    },
    {
        "url": "https://chatbotslife.com/master-bot-analytics-why-do-chatbot-love-logs-1b2f8d439dd8?source=user_profile---------14----------------",
        "title": "Master bot analytics: Why do chatbot love logs? \u2013",
        "text": "In this section, we will show an example of a stack allowing us to register raw data, structure it and display it on a visualization dashboard . We will use Logstash, Elasticsearch and Kibana, but you can use anything you like, including a custom script fetching data from a simple database. We think a dashboard has a lot of advantages though : it\u2019s easier to read, much easier to display graphs, it can be shown to colleagues, managers, business partners, it updates itself\u2026 It makes your bot analytics easier to read and process.\n\nYou can also log business goals . You haven\u2019t set business goals for your bot? Check this tribune explaining why it\u2019s necessary . For a pizza booking bot, it could be the selection of a pizza and it\u2019s payment. For a support bot, it could be every time the user is satisfied with your help, either implicitly by matching intents and sentiment analysis, or explicitly with a satisfaction survey. In general, clicking on a link, asking for more information, asking questions outside the scope of the bot or finishing a conversation flow are useful things to log.\n\nFor starters, it is always useful to know when new users start a conversation with your bot. That will allow you to track the number of new users everyday. Logging messages makes it possible to know how many are sent everyday, as well as the average number of messages per conversation per day, and the number of messages per conversation. You can also know the number of returning users , you might say that they are the ones sending messages on a different day than the day the conversation started for example.\n\nThis is where data comes in. Data that will help you analyse what is going on , that will allow you to set well defined KPIs, to know your users and their expectations better, and maybe find out new use-cases and business opportunities. The evolution over time of your metrics also makes it possible to value the changes you make to your bot or to your marketing strategy.\n\nYou\u2019ve got a bot running. Or maybe you don\u2019t? Then you should! Great ! But now what ? When you launch your bot into the wild, be it a commercial one or not, you usually want to know how users interact with it, what they gain from it and how you can make the experience better. But that certainly isn\u2019t an easy task : who uses my bot, why are they using it, did they get what they expected, are my business objectives completed\u2026 Indeed, those are high level questions that can\u2019t be answered by just taking a look at conversations held: you must dive into your bot analytics.\n\nA sample of what Kibana can do\n\nWe will use \u201cMovie Bot\u201d as an example, you can chat with him here : link, he\u2019s quite the nice chap.\n\nSo let\u2019s get to the meat of it all. Or maybe tofu, that\u2019s up to you.\n\nOn macOS, you can just do :\n\nOn other systems, you can download them on their maker\u2019s website : elasticsearch, logstash, kibana. For each project, you will find the binary you are looking for in the folder.\n\nMake sure you have a Java8 JRE or JDK on your system.\n\nBy default elasticsearch will listen on port 9200.\n\nLogstash will allow us to make bulk inserts into elasticsearch, set some fields (like the timestamp) automatically for us, have multiple input sources (files, HTTP APIs, other DBs\u2026) and more.\n\nIn this example, we want a HTTP API we can call from anywhere, from any platform or language we might be using. Here is config file for that :\n\nThis config tells logstash to accept requests on port 4242. Here are some other input sources you might be interested in : link. By default, the input adds a and a field, which I am not interested in, but you might be. We also tell logstash where to find our elasticsearch DB (no port specified = default elasticsearch port), and in which index to put our data. In this case, we want to have the freedom to specify the index to use as an argument to the API, so that's what we do. You can find more output plugins here.\n\nYou can launch logstash like so :\n\nTo allow Kibana to know about your indexes and the fields you are going to be using, make a first request to your newly created API. You might use for example :\n\nOr you might directly want to have some code doing it, you\u2019ll probably be using that anyway later on. Here are some snippets :\n\nOnce kibana is running, visit http://localhost:5601, or whatever port kibana tells you it is listening on, 5601 is the default. You\u2019ll be asked to configure an index pattern, enter the name of your index and click on \u2018Create\u2019.\n\nThen, you will be able to see the inserted documents in the \u2018Discover\u2019 tab.\n\nYou\u2019re pretty much ready to go ! The next step is to create visualizations and dashboards for your bots analytics. After some tweaking, you will be able to have something along those lines :\n\nIn the top left, the number of conversations taking place right now. In the top right, a visualization of the most common intents of the bot. We also have the number of conversations, of messages, the number of messages per length (in words), as well as the percentage of movie searches in one of the 6 most frequent languages, and the raw number of searches. One very cool thing is that we can click on a day, or on an intent, and watch the entire dashboard change as a result (everything becomes filtered based on what you clicked on). Here is a small demo :\n\nFinally as a last piece of advice, don\u2019t forget to refresh fields when you add new ones, otherwise Kibana won\u2019t know about them :\n\nPS: If you wonder where to find this cute wooden robot pencil sharpener featured in the cover, check here."
    },
    {
        "url": "https://chatbotslife.com/how-to-add-smalltalk-to-your-chatfuel-bot-in-10-minutes-with-recast-ai-5b7763d2a422?source=user_profile---------15----------------",
        "title": "How to add smalltalk to your Chatfuel bot in 10 minutes with Recast.AI",
        "text": "Chatfuel offers a great and easy to understand environment to build simple bots, really fast. Since the bot\u2019s actions are triggered with button clicks, it\u2019s incredibly easy to mock-up a conversation flow and deploy it to Messenger.\n\nYet, experienced bot builders will tell you: the actual user inputs your bot will get are impossible to predict exhaustively, sometimes absurd and quite often senseless. A pure input-output logic will sadly not get you very far.\n\nThis is precisely the reason why NLP is essential for a chatbot to be able to react to unpredictable inputs. Hence, if you ever have shipped an application to Facebook, you know that this will happen very, very often:\n\nSome people just won\u2019t click the buttons and type weird questions instead. To give you some perspective, one of the most triggered intent on one of customer support chatbot for a bank is @ask-joke. You would think people have better things to ask to their digital bank clerks \u2014 the reality is that most users want both: the facts and the fluff.\n\nKnowing this reality is one thing, handling it is another. If you fail to handle fluff in a satisfying manner, you\u2019ll leave your users deeply frustrated. The good news is that integrating Natural Language Processing with Recast.AI to your existing Chatfuel bots only takes minutes, and I\u2019ll guide you along the path.\n\nBy the end of this tutorial, your existing bot will be able to understand more than 15 different topics of small talk and answer it cleverly, and you\u2019ll have everything you need to add much more \u2014 all that in less than 10 minutes. So, without further notice, here\u2019s what on the menu today:\n\nFind a comfortable spot, and get the stopwatch ready. Now it is the time to plug a Recast.AI brain into your Chatfuel\u2019s bot!\n\nThe train tab is the default view on your bot, and it displays its intents. An intent is a \u201cbox\u201d of sentences that all carry the same meaning, even though they can be very different to one another. When a user sends some text to your bot, our algorithm compares it to the phrases in your intents. Then it checks if it\u2019s close enough to one of them and decides what the intention of the message is.\n\nBecause we started with a boilerplate you will already see a lot of intents:\n\nThis means that your bot already knows how to recognize 16 different meanings in hand typed messages. If you want to learn how to create new intents or improve the existing ones, I invite you to give a look at this tutorial.\n\nThe Build tab is where you find Bot Builder. It helps you construct the conversation flow of your bot using Skills. Each Skill represents one thing that your bot know to do, and they can interact with each other.\n\nYou can already see the two default skills, greetings and small-talk picked during the creation of the bot.\n\nThe two premade skills are very simple: they are triggered if the user message contains a certain intent and answer with a message depending on the intent. The skill greetings takes care of the intents greetings and goodbye, and the skill small-talk handles the 14 others.\n\nBy default there is no fallback message, meaning that if no intent was assigned to the message, nothing will happen.\n\nFix this by clicking on the left, and choose skill type . Give it a name of your choice.Once it's created click it to view its settings and go to the Actions tab. Click , choose action type and create a default message of your preference.\n\nIf you want to edit the default skills, go to their Actions tab and click the pen to change the content of the message.\n\nThe setup part on Recast is now done, you can test your bot by clicking the blue bubble on the right of the screen. The tab shows you what answer is configured for a message and which intent was matched.\n\nUnfortunately, Recast.AI and Chatfuel don\u2019t speak the exact same language. The JSON output from Recast\u2019s Bot Builder is not formatted exactly as Chatfuel API expects.\n\nLet\u2019s code a simple NodeJS proxy to solve this issue. We\u2019ll set up a simple HTTP server that receives events from Chatfuel, calls Recast\u2019s Bot Builder API with the message sent by Chatfuel and returns the messages configured in your Skills.\n\nThen copy the following script to a .js file.\n\nNow you should host this code on a public server so that Chatfuel send requests to your API.You can try Ngrok if you want to expose publicly a port of your local computer.\n\nFinally, we need to configure Chatfuel to send a request to the proxy when the bot receives a free-typed message.\n\nChoose the and reproduce this setup:\n\nThis will save the user message to a variable named , and send a request using block to the proxy we created with two parameters: the message and a user id, to keep track of conversation states on Recast.\n\nYour bot now understands small talk! Go test it on messenger:\n\nTalking with our bots on Messenger\n\nEven if you have a functional Smalltalk module as is, you may want to personalize the texts of your bot, create new intents or improve the detection of your bot.\n\nEverything you need to know about Intents and Skills is explained in this tutorial.\n\nTake your time to improve the quality of your bot\u2019s Smalltalk, it\u2019s a very important part of its identity, and you will notice a much stronger engagement. The personality of a chatbot is a determining factor of its user retention rate.\n\nThank you very much for following along! We would be very happy to have your feedback on how small talks impacted your existing bots.\n\nDon\u2019t hesitate to join us on Slack if you want to discuss or need any help."
    },
    {
        "url": "https://medium.com/@RecastAI/treat-your-corporate-chatbots-like-employees-not-fancy-features-e09ab7fc9540?source=user_profile---------16----------------",
        "title": "Treat your corporate chatbots like employees, not fancy features",
        "text": "Innovation is pushing your business forward. \u201cInnovate or Die\u201d is something that Blackberry and Blockbuster didn\u2019t get ten-fifteen years ago. So they died. Since then, we have all learnt the lesson. So did you. So you took the right decision and have decided to start a corporate chatbot project.\n\nI\u2019m writing these lines to urge you to push your corporate chatbot project team to bring you value for money. It is NOT a \u201cfancy feature\u201d. It is here to push your business forward by generating revenue or reducing cost. Your project team can, and ought to, get you there.\n\nDisclaimer : The probability that you would find that I\u2019m stating the obvious is not zero. I know. Personally, this kind of blogs drive me crazy. Nevertheless, in the last two years I\u2019ve seen many CDOs budgeting and launching corporate chatbot projects without guiding the team to define sharp business objectives. The result? Either a chatbot that tries to do too much, \u201cMr. know-it-all\u201d, has no identity whatsoever, where the user doesn\u2019t understand a thing, gets frustrated, and the outcome is zero traction; or, a chatbot that does a great job, but not the right one, therefore generating low ROI and killing the project.\n\nEvery chatbot project must start by fixing the business objectives of the chatbot. How would the chatbot generate a rapid ROI? Start with a high level objective and go progressively into the details.\n\nFor instance, a killer leverage point is productivity. Imagine a telecom operator operational context. The business objective definition could go down the following path :\n\nAs in any business project, to ensure the capacity to hit the business target and generate ROI, measures are to be put in place. The project team should define KPIs in order to measure the chatbot\u2019s success.\n\nA classic pitfall is to measure the conversation performance instead of the business performance. In the example used above, it is best to measure the number of inbound chats handled by human agents. That\u2019s the key number that will eventually reduce costs.\n\nI\u2019m not saying that measuring the conversation performance is not important. Knowing whether the chatbot understands users well or not, whether the user is satisfied at the end of the conversation and whether his request was answered is clearly very relevant to our exercise. It\u2019s just that these measures are not the bottom line. The bottom line is whether or not we hit the business objective. Other measures are simply indicators to guide use towards that goal! Start with the outcome in mind, and put in place your business objective KPI as the major dashboard.\n\nThe use case should be derived from the business objective, and not the other way round. So many corporate chatbot projects start with someone having a \u201cdream\u201d or a \u201cfeeling\u201d or some \u201cstrong intuition\u201d about the \u201cwinner use-case\u201d or \u201cthe coolest chatbot ever\u201d. It might indeed become an awesome chatbot with a sweet user experience with tons of likes and positive Facebook comments, but what does this chatbot do for your business?\n\nChoosing the use case is a serious challenge, and is definitely not an easy task. The use-case, also called the chatbot\u2019s identity, is one of the three factors that will determine the success of your chatbot among your users. (The other two being the user experience, and the NLP performance. If you\u2019re using Recast.AI, you\u2019ll be just fine \ud83d\ude09 ). There are many great blog posts out there explaining how to design a kick-ass corporate chatbot identity, and you might want to take a look at these:\n\nSix sigma fans usually refer to 5 majors steps to optimize business processes, often shortened as DMAIC:\n\nPutting a corporate chatbot in place is not a one-shot exercise. The business objective KPI should be regularly monitored throughout both the Build phase and the Run phase of the project. The project team should verify constantly that the KPI converges to the objective as the project goes, and that once in target, it stays there! If this doesn\u2019t happen, analyze and take action.\n\nChatbots bring a great business opportunity to introduce cost efficiencies in the Customer Service world. This is probably not coming to you as breaking news. Although it is interesting to understand why this statement is true. It is basically driven by two forces: Threat and Feasibility.\n\nLet\u2019s start with the threat. Businesses encounter in this era of digitalization a huge peak of incoming customer demands. In particular via mail and chat. It is probably because we consumers become more and more exigent and hard to please. Combine that with the fact that complaining via mail or chat requires zero effort and you get the perfect recipe for 10x inbound customer support tickets. Why is it a threat? Because businesses cannot hire 10x customer support agents to maintain the quality of their customer service.\n\nNow for the good news. It turns out that a great deal of customer care and post-sales tickets, industry cross, require a very short and simple conversation in order to provide the customer with a solution.\n\nIt gets even better. Many of the complex customer issues involve a data collection phase in the beginning of the conversation (e.g., get the customer\u2019s name and address): sounds like something a chatbot can easily handle! That\u2019s feasibility \ud83d\ude42\n\nChatbots are your new employees, they are the way to get your business successful, be demanding and set business objectives to fulfill. Do that and they\u2019ll exceed your expectations.\n\nPS: Thanks to Scott Adams for the comics, always on point. Check his work"
    },
    {
        "url": "https://chatbotsmagazine.com/bots-101-an-introduction-for-developers-d76821d391e3?source=user_profile---------17----------------",
        "title": "Bots 101: An introduction for developers \u2013",
        "text": "The tech world is currently in the middle of chatbot-craze. You know, these cranky bots you find yourself talking with before you even notice? Ever wondered about the others, those who build the chatbots?\n\nToday, you\u2019ll jump to the other side as we detail the required steps to build your own bot. What should my bot be able to do? How will the conversation flow look like? What kind of personality should I give to my bot? What are the best channels for my bot? To learn more on such matter, check this comprehensive article addressing the enterprise methodology to build chatbots.\n\nFor today\u2019s matters, we\u2019ll consider that you already answered this tough and deep questions and you\u2019re ready to B U I L D. It\u2019s finally time to code!\n\nTo that end, we\u2019ll use Recast.AI. If it\u2019s your first time on the platform, I recommend you to check this starter guide to get you up to speed.\n\nIn each part of this post, we\u2019ll improve our bot by achieving new goals to make it smarter. Here is what\u2019s on the menu:\n\nThe sample code examples are made in NodeJS (min. version 7). You can find them on the dedicated public GitHub repo.\n\nYou\u2019ll need an account on Recast.AI to follow this tutorial step by step:\n\nYour bot will be linked to one or many channels: Facebook Messenger, Kik, SMS, etc\u2026\n\nBasically, each time a user speaks to your bot, the channel platform will trigger a call to a webhook to transmit the user message. Therefore, the webhook is the main entry point of your bot.\n\nSo, a chatbot is an API!\n\nHere is an example code for a basic bot:\n\nOn this webhook, channels can send many pieces of information, such as:\n\nTo know more about information sent, you can check each channel documentations. For example, in Facebook Messenger:\n\nYou can connect your bot to many channels but be careful: each channel sends its own information format. In that code example, user input was sent through the message variable in the request.body object. This is not a convention but an example. To abstract usage of many channels, we developed Bot Connector. Bot Connector transforms channels inputs to a single JSON format sent to your bot. The format is always the same even if messages come from different channels.\n\nDifferent channels are available on Bot Connector: Facebook Messenger, Slack, Skype, Line, Twilio, Kik, Twitch and many others. You can check our dedicated Bot Connector documentation to learn how to use it.\n\nWhen users speak to your bot, they mostly want an answer to their questions:\n\nAs you can do for other projects you can trigger a call to external APIs to get answers directly in the bot code:\n\nThen, it is the developer task to use responses of these calls to answer user questions.\n\nThis is an example in which user wants to know if a McDonald\u2019s restaurant is opened:\n\nIn this code sample, starting from previous sample, we use Axios to make external calls to APIs. Don\u2019t forget to import it at the beginning of the file (line 12):\n\nYou must add your Google API key at the end of the URL of your request, with the \u201ckey\u201d parameter: https://maps.googleapis.com/XXXXX/key=YourTokenHere\n\nThere is a free plan to test Google Places API. For more information about plan and usage of Place API, you can check the Google API doc.\n\nIf bots are cool, multilingual chatbots are even better! It\u2019s a vast topic which is covered in yet another guide. This one hour tutorial details all the necessary steps to add a new language, both on the platform and in your code. Check it for an exhaustive overview of language management on Recast.AI. I will only focus on the essentials:\n\nLanguage handling is sensibly different on the two sides of your bot:\n\nLanguage switching is not just about translating all the elements of a sentence, a lot of other factors can vary. For instance, the words order: in English we say \u201ca black horse\u201d while in French it\u2019s \u201cun[a] cheval[horse] noir[black]\u201d.\n\nMoreover, if you add a new language to your bot you must consider the impact it may have on all the data types it handles. A datetime is not formatted the same way in French and English. For example, to answer to the question \u201cIs the McDonald\u2019s in Champs-Elys\u00e9es in Paris opened?\u201d in English, your bot will say \u201cYes, it\u2019s open until 4:00PM, you can go to eat a burger!\u201d. But in French, your bot will say \u201cOui, ce restaurant est ouvert jusqu\u2019\u00e0 16h00, tu peux aller manger un hamburger !\u201d\n\nHere is an overview of the languages we currently support:\n\nYou must take care of the different specifications of each language you support to make your bot smarter and understandable by humans. We support all languages, and you can find the entire list on our documentation.\n\nNow, your bot can understand simple sentences and retrieve external information in diverse languages. Its users are able to reach it on their usual channels. Now is the time to step back, and take a few seconds to appreciate the achievement.\n\nReady for your next bot upgrade? Your next goal will be to use our new Bot Builder to create the conversation flow of your bot. You can check the Bot Builder section of our documentation to start playing with it. Have fun making smart bots!\n\nHave an issue with your bot? Is something unclear in this tutorial? Feel free to comment or join our Slack to discuss it."
    },
    {
        "url": "https://medium.com/@RecastAI/turning-your-chatbot-into-an-alexa-skill-a-step-by-step-1-hour-tutorial-e3aea35e3a96?source=user_profile---------18----------------",
        "title": "Turning your chatbot into an Alexa skill: a step-by-step 1 hour tutorial",
        "text": "More and more chatbots are being created every day, basically covering every automatable use case. Most of these chatbots are textual, we can discuss with them either on Messenger, SMS, website chat, etc. They\u2019re very accessible and easy to use, but I\u2019m sure you\u2019d love to be able to speak to them as well as write to them. Sometimes, speaking is the most natural and easiest way to interact, say when you\u2019re at home cooking or reading. I\u2019ve got some news for you: you can build your own Alexa bot backed by Recast.AI! Why would you do that? Well, Recast.AI\u2019s language technology allows you to build a skill in any language much faster than any other provider. It\u2019s a great solution to become a master bot maker and pimp your home.\n\nA simple but very useful use case is the banking assistant. Wouldn\u2019t it be marvellous if you could manage your daily finances directly by speaking with your banking assistant?\n\nIn this article, I\u2019ll explain how you can create your own Alexa bot, powered by Recast.AI\u2019s NLP, like you\u2019ve seen above.\n\nTo begin, you\u2019ll need your bank to have API endpoints to have a real integration but others use cases follow the same pattern.\n\nHere is the global design of our project:\n\nUnder the \u201cSkill information\u201d tab, fill in the information as shown below:\n\nNow, the most important tab, the interaction model. Amazon doesn\u2019t allow us to get the user\u2019s input, so we have to use a little trick. We\u2019ll configure a slot (an entity) matching all the user\u2019s input.\n\n To do this, enter this JSON configuration in the \u201cIntent Schema\u201d text area:\n\nIn \u201cSample Utterance\u201d, enter this example which matches the whole input:\n\nNext, the \u201cConfiguration\u201d tab. If you\u2019ve mastered lambda, you can configure your lambda endpoint here directly, but to make things as generic as possible, we\u2019ll use a simple https endpoint using ngrok.\n\nTo do so, install ngrok and create a tunnel (we\u2019ll add the code server later) :\n\nEnter the https url provided by ngrok in the \u201cDefault\u201d input.\n\nAn \u201cSSL certificate\u201d tab should have appeared. Select \u201cMy development endpoint is a sub-domain of a domain that has a wildcard certificate from a certificate authority\u201d. This way, we tell Amazon to let us (ngrok) manage the SSL certificate.\n\nNow we can test it by entering a sample utterance. We won\u2019t get any response from our bot because we haven\u2019t configured it, but we can see the JSON sent by Amazon to our bot. The whole sentence is in the slot \u201csentence\u201d.\n\nYou won\u2019t need these details until you want to deploy your Alexa bot to the world.\n\nIf you have an Alexa device under the same account as your Amazon developer account, you can integrate your skill into Alexa.\n\nNote: The following steps come from the Amazon help page: https://developer.amazon.com/docs/custom-skills/test-a-custom-skill.html#h2_register.\n\nTo integrate your skill, go to the Alexa configuration page. This is the web versions of the mobile Alexa app. Once logged in, go to the Skills tab, and click on \u201cYour skills\u201d in the top right corner. You should see your newly created skill. Click on it and check that it\u2019s enabled for your Alexa.\n\nAt this point, you should be able to ask Alexa to open your skill using your invocation name configured in the \u201cSkill information\u201d tab. For instance: \u201cAlexa, open banking assistant.\u201d. Alexa should understand the skill and reply with an error (\u201cThere was a problem with the requested skill response\u201d). That\u2019s normal, as we haven\u2019t configured our bot yet, but it shows Alexa is now aware of the skill! Well done.\n\nFirst, create a bot on Recast.AI. If you haven\u2019t used Recast.AI in the past, this tutorial will explain how to create a bot easily.\n\nYou can also fork a sample banking chatbot here.\n\nNow that we have a trained bot, we have to code the integration between Alexa and Recast.AI. You can use this code, which is an adaptation of Recast.AI\u2019s starter kit.\n\nThis will start a server on port 3000, to which ngrok will send Alexa\u2019s requests.\n\nYou should now be able to talk to Alexa, invoking your skill and talking with it, as defined in your Recast.AI Bot Builder.\n\nCongrats! You now have a talking Alexa chatbot, backed by Recast.AI\u2019s NLP. You can now start customizing your use case and the code. It\u2019s simple and well commented so it should be easy to work with.\n\nWhen you\u2019re ready for production or if you wish to have your bot always up, deploy it to a custom server or to a lambda, either using Bot Hosting or the Alexa integration in the \u201cConfiguration tab.\u201d\n\nFinally, to submit your skill and make it available to every Alexa owner, follow the instructions on the \u201cPublishing Information\u201d and \u201cPrivacy & Compliance\u201d tabs.\n\nThat\u2019s it, you know everything! Enjoy experimenting and feel free to come and discuss it on our Slack Community. Cheers!"
    },
    {
        "url": "https://medium.com/@RecastAI/machine-learning-spotlight-i-investigating-recurrent-neural-networks-40a84067e916?source=user_profile---------19----------------",
        "title": "Machine Learning Spotlight I: Investigating Recurrent Neural Networks",
        "text": "The main advantage of RNNs resides in their ability to deal with sequential data, thanks to their \u201cmemory\u201d. Whereas Artificial Neural Networks (ANNs) have no notion of time, and the only input they consider is the current example they are being fed, RNNs consider both the current input and a \u201ccontext unit\u201d built upon what they\u2019ve seen previously.\n\nSo the prediction made by the network at timestep T is influenced by the one it made at timestep T \u2014 1. And when you think about it, that\u2019s pretty much what we do, as humans, we use our previous experience (T \u2014 1) to handle new and unseen things (T).\n\nChristopher Olah puts it very nicely in his blog post, Understanding LSTMs:\n\nAnd luckily for us, NLP is full of sequential (or temporal) data. Be it sentences, words, or characters, we always use the context to establish a more precise meaning for communication, whether it is written or oral.\n\nHere are a few examples:\n\nIt doesn\u2019t stop there: Part of Speech Tagging, Sentence Segmentation, Language Modeling, Semantic Role Labelling, Text Summarization, Spell Checking, and a whole lot of other tasks rely on the sequential nature of the data.\n\nBut RNNs are not perfect yet: the need for the last timestep result at each timestep computation makes them slow to train, and computationally expensive. Today, more and more researchers are using Convolutional Neural Networks (CNNs), because they offer speed and accuracy improvements in many tasks.\n\nStill, the phrase \u201can LSTM with an attention layer will yield state-of-the-art results on any task\u201d is not to be forgotten, and recurrent architectures will populate user-facing NLP systems and benchmark baselines for a long time.\n\nHow are recurrent neural networks different from convolutional neural networks?\n\nWhat is the difference between Recurrent Neural Networks and Recursive Neural Networks?\n\nWhat is the difference between LSTM and GRU for RNNs?\n\nWhat is masking in a Recurrent Neural Network?\n\nWhat is the attention mechanism introduced in RNNs?\n\nWhen should one decide to use a LSTM in a Neural Network?\n\nWhat is the difference between states and outputs in an LSTM?\n\nIs it possible to do online learning with LSTMs?"
    },
    {
        "url": "https://medium.com/@RecastAI/introduction-to-information-theory-and-why-you-should-care-recast-ai-blog-31a3e81e6c54?source=user_profile---------20----------------",
        "title": "Introduction to Information Theory and Why You Should Care \u2014 Recast.AI Blog",
        "text": "Congratulations on making it all the way down here! I hope I succeeded in my mission to convey these principles in an intuitive way, and that the math that I did have to include was understandable enough. Your prize for getting here is to find out \u2014 why does all of this matter for machine learning?\n\nBefore anything else, in my opinion the intuition and basic understanding of concepts that comes with knowing a little about information theory is the most valuable lesson to take into the world of machine learning. Looking at any ML problem as the problem of creating a channel from the original data-point at the input to an answer at the output, for which the information it conveys about the desired property of the data is maximized, would allow you to look at many different problems from a different angle than usual. The quantities presented above also turn out to be helpful in many different situations. Consider for example a situation where we would like to compare two unsupervised clustering algorithms over the same data, in order to check if they give similar results or not. Why not use the mutual information between the results of each of the algorithms, where X is the random variable that represents the cluster chosen for any data point by the first algorithm and Y represents the second? Another option is to use the conditioned entropy (\n\n) in order to see how much \u201cmess\u201d is left when guessing the result of clustering by one algorithm, while the result of clustering by the other is already known (these two methods of comparison are very similar but there is a difference, can you spot it?).\n\nIn the remainder of this section, let\u2019s try to take a closer look at some interesting results in ML, that were the direct result of a connection with information theory:\n\nOne of the most popular algorithms for training decision trees is based on the principle of maximizing the information gain. Although given a different name, the information gain that corresponds to each feature is exactly the mutual information between that feature and the labels of the data points (You can go see for yourself here). This actually makes a lot of sense \u2014 when trying to decide which is the best feature to split the tree on, why not choose the one that gives the most information about the result? In other words, why not choose the one that, after splitting, would dissipate as much of the \u201cmess\u201d as possible? What happens after the split? How do we continue building the tree? Each node after the split can be represented by a new random variable, and we can start the whole process again for each of the resulting nodes.\n\nConsidering this process, we may also be able to gain some understanding about another very important issue \u2014 regularization. Decision trees are one of the models that requires the most regularization, as experience tells us that completely \u201cfree\u201d trees would overfit almost every time. Let\u2019s consider this issue through the data processing theorem: What we wish to do is to increase the mutual information between the actual label of a data point (let\u2019s call the label Z to stay consistent with the data processing theorem above) and the predicted label X. Unfortunately, in order to predict the label, we can only use the attributes Y. We do our best by increasing the mutual information between X and Y, but according to the theorem this does not guarantee an increase also in\n\n, you may remember, only constitutes an upper bound over\n\n. Thus, in the first steps, the information gain is significant and there\u2019s a good chance that it contributes, at least in part, to a gain also in\n\n, which is what we really want. As the information gain becomes less and less significant as the tree grows, the hope of increasing\n\ndiminishes and instead all we get is overfitting to the data. Hence, it is better to truncate the tree when the information gain becomes insignificant.\n\nAnother interesting example is that of clustering by compression. The main idea here is to use popular compression algorithms, like the ones responsible for ZIP, RAR, Gif and more, that present good performance especially for files that have repetitive features, in order to determine which category a data point belongs to. We do so by appending the new data point to each of the files representing the classes, and choosing the one that is most performant in compressing the data point.\n\nThis approach takes advantage of the Lempel Ziv (LZ) family of compression algorithms, (see for example here). While these algorithms come in many different variations, the main idea stays the same: Going over the document to be compressed from beginning to end, at each point known passages are encoded through a reference to a previous appearance, while completely new information is added to the \u201cdictionary\u201d, in order to be available for use when a similar segment is encountered again. The way this dictionary is created and managed may differ between members of the LZ family of algorithms, but the main idea stays the same.\n\nUsing this type of algorithm to compress a file, it is clear that the type of documents that would benefit the most out of this type of compression are long, repetitive documents. That is because the Source Coding Theorem tells us that lossless compression is bounded from below by\n\nand the entropy, which represents mess, is much bigger for random files than it is for repetitive ones. For these repetitive documents, the algorithm would have enough \u201ctime\u201d to learn the patterns in them, and then use them again and again in order to save the information in an efficient manner.\n\nIt turns out that the fact that similarities in a file make for good compression can be used for classification. For supervised classification (where the classes exist and contain a significant amount of data as \u201cexamples\u201d), a new data-point can be appended to any of the existing files (where each file represents a \u201cclass\u201d), and the declared class for the data-point is the one that was successful in compressing the data-point the most, relative to its original size (in bits). Note that since we append the data-point to the end of each of the documents, all the information in the existing documents should already exist in the respective \u201cdictionaries\u201d when the compression algorithm reaches the new data-point. Thus, if there are similarities between any of the existing documents and the new data-point, they will be automatically used in order to create good compression.\n\nConsidering unsupervised classification (or clustering), a similar approach can still be helpful. Using the level of \u201csuccessfulness\u201d of joint compression of different combinations of data-points, clusters can be created such as the data-points within each class compress well together. Of course, in this case there are some more questions to answer, mainly having to do with the vast amount of combinations to test and the complexity of the final clustering algorithm, but these problems can be addressed, as was done for example in this very complete work. The advantage of this clustering approach is that there is no need to predefine the characteristics to be used. Taking for example the problem of the clustering of music files, other approaches would require us to first define and extract different characteristics of the files, such as beat, pitch, name of artist and so on. Here, all we need to do is to check which files compress well together. It is important to remember, however, the No Free Lunch Lemma: The whole magic here is contained in the compression process, thus understanding the specific compression algorithm chosen is imperative. How is the dictionary built? How is it used? What is a \u201clong enough\u201d document to be compressed by it? etc. These specificities can determine the type of similarities the compression is susceptible to use, and thus the characteristics that control the clusterization."
    },
    {
        "url": "https://chatbotsmagazine.com/ai-building-ai-how-our-bots-are-now-training-themselves-100x-faster-b033270b1a7?source=user_profile---------21----------------",
        "title": "AI Building AI: How Our Bots Are Now Training Themselves 100x Faster",
        "text": "Earlier today, I came across this awesome infographic detailing the future of AI: what will happen, what might happen, and what will definitely remain science fiction for a very long time.\n\nDespite all the hype, HAL is not yet around the corner. What is already possible today is AIs and humans working together on tasks simple enough to be automated and data-intensive applications. In fact, pattern recognition is currently one of the hottest fields in AI. It works well because it frees up time experts (doctors, traders\u2026) spend on repetitive tasks and makes them more efficient. While keeping the precision of human supervision, these AIs operate at a machine-scale. Moreover, because the AI is used as a screening method, false positives are avoided.\n\nAs an AI startup involved in the creation of human-machine interfaces, it\u2019s thrilling to think that we might be making history any day, and I feel that today, we\u2019re getting closer.\n\nPowerful AIs all have one thing in common: an extensive training based on qualified datasets. AIs are like babies; they need to learn by example.\n\nA very clear demonstration of that is Tay, Microsoft\u2019s Twitter bot who learned from what users told him. It took him only 18 hours to be disabled because he started mirroring user behavior and posting very offensive tweets.\n\nWe\u2019re well aware of the training challenge in today\u2019s AI industry. What\u2019s the difference between small AI firms and Google? Data.\n\nTo train your systems efficiently, you need a sizable dataset. How you get it is up to you! In bot building, the most common way is to type sentences by hand. But having a big dataset isn\u2019t the only thing that matters: it needs to be qualified. Having random incorrect sentences won\u2019t make your AI smarter, it might even make it dumber. That\u2019s why you should spend time making sure you have a clean set of sentences to train your conversational systems.\n\nWe\u2019ve established training is a major part of bot building and probably the most time-consuming. In real life, when things get hard, what do you do? You get help, you get collaborators.\n\nMany companies have done it over the years: AirBNB, Uber, BlablaCar have based their business on people working together.\n\nWhy can\u2019t AI do the same? Why can\u2019t you get thousands of people creating your training dataset? That\u2019s right, you can, and that\u2019s just what we\u2019ve done.\n\nRight from the start, Recast.AI was designed as a collaborative bot platform. All our users participate in the global training of our models when building their bots. Our own NLP technology, powered by deep learning, is growing stronger and smarter everyday! And because we have two years of extensive shared training behind us, we are now able to drastically increase bot time-to-market by 100 for all our developers and clients with Expression Suggestions.\n\nLet\u2019s get back to basics: when building a bot, you first create intents. Intents can be seen as boxes in your bot\u2019s brain, defining the different topics it can understand (greetings, weather, food, drinks, etc). You need to enter a certain amount of sentences in each intent to train your bot. It\u2019s a tedious process; you have to think of sentences meaning the same thing that are all different. You have to picture all the different ways a question can be asked. You sometimes have to use slang, sometimes formal speech. And you have to do that in different languages!\n\nStep back, have a coffee: now, Recast.AI can do that for you.\n\nWhen entering one sentence, our AI suggests 5 others that might match. And the more you use this feature, the sharper it\u2019ll be. This is a truly innovative way to think about bot building; what better than AI to train AI?\n\nWant to try it out? Go on Recast.AI, create a bot, an intent, and see the magic.\n\nWhat are you going to do with all this free time? Add new features to your bots? Another language? Make a whole new one? I\u2019m sure you\u2019ll figure that out on your own.\n\nIf you\u2019d like to know more, please reach out to our support team! And now that you can build bots in the blink of an eye, please send us your creations! We\u2019re always proud to promote our community\u2019s work."
    },
    {
        "url": "https://chatbotsmagazine.com/from-command-bots-to-ai-bots-a-twitch-botosphere-case-study-7bbe7a8e5969?source=user_profile---------22----------------",
        "title": "From Command Bots to AI Bots: a Twitch Botosphere Case Study",
        "text": "Bots, bots, bots, bots: the word has a different echo around the internet. On Messenger, you get cheers. On Twitter, you get anti-spam protests. On Discord, you think of mechanical command bots. Today, we feel the time is right to create a new echo for AI bots on Twitch, the n\u00b01 gaming community in the world.\n\nMany bots already exist on Twitch and are well integrated. They usually provide important information to stream viewers or manage the moderation of chat rooms. Sometimes, they\u2019re used for doomer purposes. But if bots are still used daily, it means even in their current basic form, they bring something to the Twitch community.\n\nMost Twitch bots are currently very basic: command activated, they send automatic messages when triggered. The community is open to them: they\u2019re seen as useful, even if sometimes a bit boring or unpractical. How could they evolve to further transform the world of streaming?\n\nI hear many people from all around : \u201cbut current bots are just fine! Why would we change them?\u201d. To answer that, I want to talk about 3 things that have proven their values: user experience, performance, and multilingualism.\n\nAs I\u2019m writing, a few Twitch users will be typing !uptime to know how long the streaming they just joined has been going on for. Many Twitch users don\u2019t know the command to get that information, or any other command for that matter. That makes current bots hard to reach and very, well\u2026 robotic.\n\nCreating bots with NLP (natural language processing) solves this issue very simply: it makes them understand human language in addition to commands. Experienced viewers could still type !uptime, but new ones could simply say \u201chow long have you been streaming?\u201d and get the same answer. The rules of banning could be more natural, meaning people would stop getting banned for using curse words without insulting anyone. The general chats would not be overwhelmed with basic questions but gather interesting and fun content. I could go on!\n\nGiving Twitch bots the power of understanding human language brings us the simplicity of conversing with them like we would with a friend. Imagine the things you could do!\n\nNLP is a subtopic of artificial intelligence. By using AI, you change your approach to language understanding. Bots don\u2019t base themselves on keywords, they understand the global meaning of a sentence. That makes them smoother and more adaptable, and in the end, provides a more natural experience for the user.\n\n\u201cBut what if the bot doesn\u2019t understand what the user said? That happens.\u201d\n\nThe beauty of machine learning is that bots are always learning. It doesn\u2019t understand once? It\u2019ll understand the next time. And for things the bot doesn\u2019t support, bot masters (whether a streamer making a bot for their channel or a bot-addicted viewer) can take on these questions themselves. That\u2019s what we call human fallback. So from the viewers\u2019 point of view, their questions never go unanswered.\n\nIt\u2019s important to care for your existing community. Twitch, like the majority of the internet, is English-speaking. But many viewers aren\u2019t native English speakers, and are craving for content in their own language. Multilingual bots can understand any language and provide answers in the user\u2019s tongue, making the viewers\u2019 experience smoother and closer to home. Ideal to reach out to new viewers, or treat existing ones.\n\nAnd what\u2019s in it for the streamer? A multilingual bot manages all basic questions for them, so the streamer can focus on animating a fun and insightful conversation about the stream itself. Nothing else.\n\nTwitch, as a social platform and a messaging channel, offers endless possibilities for bots. With both private messages and general chats, there are great ideas all around. Here are a few we gathered:\n\nWhen discovering a new stream, you can easily get confused: what\u2019s going on? What is this game, which version is it? How long has this stream been going on? When does it end? A bot is the perfect way to provide precise answers to these questions in a very natural ways.\n\nWhat is this streamer\u2019s setup? Where are they from? Do they often compete? What mic are they using? Many questions can be answered by a bot integrated into the streamer\u2019s channel.\n\nMajor streamers typically have a webpage where people can access their schedule to discover if and when they\u2019re going to play a certain game. Most share the information on social networks. Including this information directly in Twitch and so keeping the viewer on the stream, is a good way to increase viewing rates. A bot can easily provide the information to anyone in natural language.\n\nEver wanted instant access to all streamer rankings on Twitch? Make the ultimate Twitch ranking bot!\n\nInstead of banning people for specific keywords, why not use AI to provide sharper moderation? Language technologies allow the analysis of text and can recognize inappropriate sentences or paragraphs, even when they don\u2019t use key swear words. That way, you wouldn\u2019t get banned for using swear words in an inoffensive way.\n\nHard to follow the conversation when loads of people are chatting at the same time? It\u2019s easy to use Recast.AI to analyse the most talked about topics and provide answers to the most frequent questions. Great way to connect a community.\n\nWe could go on and on, but I\u2019ll leave this in the hands of the very creative and capable Twitch community! And if you are a bot builder, send us your Twitch bots, we\u2019ll be happy to promote them :)\n\n\u201cThat\u2019s all very well, but how can I do this?\u201d\n\nRecast.AI allows you to easily build and connect bots to Twitch through a multi-platform tool called Bot Connector. It\u2019s as easy as it gets! You\u2019ll find below a detailed process on how to launch your own bot on Twitch. Enjoy!\n\nGo to Recast.AI, create an account and start building your bot. Here\u2019s a tutorial to help you get started on Recast.AI.\n\nGo on Twitch and create an account. If you already have a Twitch account, login.\n\nGo on the connections page of your Twitch account and register a developer application. Scroll to the end of the page and click on Register your application.\n\nFill in the form on the Recast.AI Connector page. You can fill in the Redirect URL with a random url, as you don\u2019t need it. Select Chat Bot in the Application Category and click on Register to create your app.\n\nFill in the Recast.AI form with your Twitch username and with the Client ID of your app.\n\nGo on the Twitch Password Generator and click on Connect with Twitch\n\nCopy the password generated in the Token field on the Recast.AI platform (excluding the oauth:part)\n\nVerify all the information provided on the Recast.AI fields is correct and click on Connect! Your bot is now live.\n\nIf you need any assistance, don\u2019t hesitate to join our Slack Community, our support team will be happy to help. If you have other ideas, want to discuss this material, or have built a bot, please leave a comment!"
    },
    {
        "url": "https://medium.com/mobile-lifestyle/the-era-of-autonomous-cars-focus-on-pedestrian-detection-with-deep-learning-660483bcd0d3?source=user_profile---------23----------------",
        "title": "The Era of Autonomous Cars: Focus on Pedestrian Detection with Deep Learning",
        "text": "Nowadays, we see a lot of potentially disrupting technologies. Autonomous vehicles are one of the most in vogue today!\n\nLots of amazing things can come out of this revolution: fuel economy, reduction of cars on the road, decline of accident and death rates, stress reduction, reduction of parking space and a real benefit for the environment.\n\nGovernments are already thinking about it. The National Highway Traffic Safety Administration in the US provides an official self-driving car classification. Europeans have also started modifying the Vienna Convention on Road Traffic and the Geneva Convention on Road Traffic in order to be able to adapt to this new technology. So, brace yourselves, the wheels are in motion (yes, pun intended).\n\nEven though researchers have been studying the topic for years, it\u2019s thanks mainly to Google\u2019s or Tesla\u2019s investments that autonomous cars are finally gaining traction today\n\nSo, how does it all work? From a more technical point of view, autonomous driving touches many challenges in different fields, especially computer vision. It requires improvement in object detection, image classification, environment reconstruction, motion estimation, tracking, scene understanding and many others.\n\nOne of the most talked about is pedestrian detection, so let\u2019s explore this from a more technical point of view.\n\nTo welcome vehicles without drivers into our lives, we must be sure that they won\u2019t be a threat and run us over.\n\nLet\u2019s look at where object detection is since pedestrian detection is a canonical sub-problem.\n\nThe most trending methods to reach optimal performance in pedestrian detection are Integral Channel Feature detector (ICF)(from Fast Feature Pyramids for Object Detection and Integral Channel Features) with many variants and the use of a pre-trained model using a convolutional neural network (Taking a Deeper Look at Pedestrians and Pedestrian Detection aided by Deep Learning Semantic Tasks).\n\nResearch papers show impressive gains in performance, but despite this, a human still widely outperforms state of the art AI detectors.\n\nDetectors can make two types of errors. False positives (it detects something where there is nothing to detect) and false negatives (it doesn\u2019t detect where it should)\n\nThe most common errors for detectors are:\n\nThe under-representation of cyclists and side-view persons in the training sets used to train the detection algorithms could explain why partially occluded people and cyclists are not correctly detected most of the time.\n\nLooking at the datasets, we see that small people are commonly saturated and blurry, which might explain weak detection. But when this factor is studied (How far are we from solving pedestrian detection?), no correlation between low detection score and low contrast is found. This also applies to blurred cases. There, the issue must be the smaller number of pixels.\n\nOther approaches like (A Time Delay Neural Network Algorithm for Real-Time Pedestrian Recognition use a real-time algorithm for the detection and tracking of image regions that possibly contain pedestrians. It then uses a classification algorithm based on the typical motion patterns of a pedestrian\u2019s legs. These approaches assume the visibility of the legs and works for walking people only!\n\nShape-based techniques, analysing the shape of objects, here the human morphological aspects like torsos, heads and limbs, allow the recognition of both moving and stationary pedestrians but the wide variety in pedestrian appearance sometimes makes this method inaccurate.\n\nApproaches like (Shape-based Pedestrian Detection) use the morphological characteristics and the vertical symmetry of the human shape. Combined with a refinement of the stereoscopic techniques and use of the temporal correlation between subsequent frames, it appears to be robust for the differentiation of pedestrians from other objects such motorbikes, trees and traffic lights.\n\nThere are many things out there working on keeping us alive in a world of autonomous cars! While extraordinary achievements have been made, there is still work to do to get acceptable performance and see autonomous cars among us. But as with the other fields in the fields of AI, autonomous machines and computer vision are continuously improving, I feel we\u2019re almost there! Get ready to leave your driver\u2019s license at home. :)\n\nIf you want to read more on the topic, I recommend this page, as well as all sources linked in this article."
    },
    {
        "url": "https://chatbotslife.com/you-shall-not-speak-benchmarking-famous-speech-recognition-apis-for-chatbots-1c04e8ce2c66?source=user_profile---------24----------------",
        "title": "You Shall Not Speak: Benchmarking Famous Speech Recognition APIs for Chatbots",
        "text": "You Shall Not Speak\n\nUnless you are an English native speaker with a perfect British accent or a direct descendant of Uncle Sam, the future is not yet here for you. Sorry, but you cannot talk to your chatbot. You\u2019ll have to continue typing for a few more months (fingers crossed) until Google, IBM or Microsoft nail it. Yep. We share the disappointment.\n\nSo let\u2019s throw some figures in. There\u2019s this magic number everyone keeps referencing: 0.85. I don\u2019t know if it\u2019s researchers or popular science gurus, but we keep hearing that in order for a speech-to-text machine to be performing it should have a precision higher than 0.85. Google scratches this threshold and gets a \u201cpass\u201d score. No \u201csumma cum laude\u201d. Watson in English is behind. And it ends there. Watson in French is not even close (0.6) and Microsoft is in the twilight zone (somewhere between 0.7 and 0.8). Amazon, Apple, Nuance are not in the match. APIs not available, no doc, or too restrictive technical constraints.\n\nWe guess that at Recast.AI, we\u2019ll have to go with (and pay for!) Google for our collaborative bot platform. To be honest, we had better expectations before we started this exercise. Let\u2019s hope that in 6 months time, when we\u2019ll redo it, we\u2019ll encounter way better results. Until then, our 15,000 developer community will have to excuse us and wait.\n\nThis article presents results for three speech to text providers. Others are not present for several reasons detailed below.\n\nThe following services were tested in this benchmark:\n\nRegarding Microsoft, the Bing API was used instead of the Custom Speech Service because it\u2019s only available in English for now. The Bing API allows you to create custom speech models depending on your usecase and vocabulary.\n\nNuance, Houndify and Amazon services are not present in this benchmark because of some audio format limitations. They accept only some specific sampling rates, which doesn\u2019t make them production-ready for us. As we receive non-constrained audio data from our users, we cannot limit ourselves to a certain sampling rate.\n\nFor more information about frequencies and audio processing, we published an article about how developers can work with audio data.\n\nThis benchmark uses audio data and transcription from the Voxforge corpus (standard dataset highly referenced in research papers). We have used 1000 samples (from 3 to 11 seconds) for both English and French benchmarks. The whole dataset is available here. The sentences are all audible, even if the quality isn\u2019t consistent.\n\nAs we use speech recognition in a real time context, we will analyze both accuracy and speed of each provider.\n\nAccuracy is measured with two metrics:\n\nThese two metrics are computed on lowercase sentences, without punctuation. The speed is measured in milliseconds.\n\nThis metric is a binary value on all samples, whether the prediction is the same as the expected output or not. Every single letter must be the same.\n\nExample: \u201cThis sentence will be recognized\u201d doesn\u2019t match with \u201cThis sentence will be recognize\u201d.\n\nThe first thing to note is that all three providers are significantly better in English than in French.\n\nGoogle is outperforming IBM and Microsoft and has the lowest difference between the two languages. Microsoft and IBM are more than twice (!) as good in English than in French.\n\nAt a higher level, the complexity of French conjugation gives rise to a lot of mistakes that make the sentences inaccurate.\n\nHere is an example of the output the different APIs provided for the sentence \u201clls \u00e9taient quatre r\u00e9veill\u00e9s son commandant lui et deux techniciens\u201d.\n\nOn the phonetic aspect, the three outputs are quite good. Only IBM Watson got a perfect phonetic score not missing the link between \u201cils\u201d and \u201c\u00e9taient\u201d! (the \u2018s\u2019 IS pronounced). Nevertheless, none of them managed to construct a grammatically valid sentence. Note that although the error of replacing \u201cdeux\u201d (=two) par \u201cde\u201d (=of) doesn\u2019t make the sentence completely unreadable, it leads to a loss of quite valuable information.\n\nThis metric describes the percentage of errors on word recognition. An error can either be a substitution, a deletion or an addition.\n\nOnce again, Google is the best performing and the most consistent while IBM and Microsoft are acceptable in English but not in French.\n\nGoogle and Microsoft record a disappointing 11% and 31% error increase respectively while IBM\u2019s error is increased by 140% (!). We could attribute the error increase between English and French to the high level of complexity of French grammar.\n\nWhile Google and Microsoft have a very acceptable response time, IBM is quite slow (twice as slow in English, three times as slow in French).\n\nAt Recast.AI, we use speech recognition to help our users build chatbots. Therefore, we conducted a real life experiment of speech to text applied to bots!\n\nIn this test, we\u2019re comparing how the bot and NLP react to both text and voice-translated text.\n\nThe use case is a simple chatbot for customer service: it provides information about insurance records. To do that, it needs to collect the customer\u2019s name and their reference number.\n\nThe dialog is very simple and is made of 6 interactions:\n\nHere is the text input in English:\n\nFor the experiment, we recorded speech files with the content above, fed them to all APIs in both languages and used the outputs to conduct the bot conversation.\n\nThe first sentence is well recognized and translated. However, the last name Debowsky and the reference number are in the correct format and accurately detected but not spelled properly. Therefore, the insurance\u2019s information systems can\u2019t match the two pieces of information to provide the correct update. Conversation fails.\n\nThat\u2019s going well! Minus a conjugation error, the first sentence is detected and understood correctly, the name and ID record are well understood and transcribed, so the bot can go to the end of the conversation. Well done!\n\nWith Watson, there are a few mistakes in the first sentence, but the overall meaning is clearly conveyed. The name is correctly translated and recognized, but the reference number is not accurate, even if it is in the right format (4 letters and 4 digits). Therefore, the bot cannot move forward.\n\nNote that Recast.AI easily detected the reference number entity, even if Watson transcribed the values in letters and not numbers!\n\nIn the first sentence, there is a translation error that puts a name in the sentence when there isn\u2019t one: au nom de Doucet (in the name of Doucet). The bot detects this name, assumes it\u2019s the client name, and follows up directly by asking for the reference number. The bot doesn\u2019t need a very strict \u201cproblem -> name -> id\u201d structure to function properly! If it detects a name, it has what it needs and moves on to the next piece of information required: in this case, skipping the second step of our test.\n\nUnfortunately, the ID record is not understood in a valid format (4 letters and 4 digits) as the first number is understood as \u201cen\u201d instead of \u201cun (1)\u201d. Conversation has failed.\n\nWith Microsoft, the first sentence is understood correctly while both the name and reference number are detected in the correct format but inaccurately translated. The user can\u2019t get an update on his claim.\n\nIn French, the reference number is correctly detected and translated, but the name isn\u2019t! Therefore, the bot can\u2019t match them with an existing claim.\n\nAs you can see, through 6 conversations, only one has been able to correctly finish the 3-sentence exchange. Strangely, the most successful is in French! Maybe that comes from the fact that we are native French speakers and have a slight French accent in English.\n\nIn the end, speech recognition doesn\u2019t look as human-like as what we might expect!\n\nGoogle Cloud Speech seems to be the better solution as they have the most accurate and consistent results, but it is the most expensive. IBM Watson suffers a big drop in performance when working with French speech. Moreover, the response time is way too high for real-time usage. Microsoft is in the middle with a good response time.\n\nBottom line, if you are the head of IBM Watson or Microsoft Speech Bing API and you are reading this, speaking at least on behalf of our community, your users would truly appreciate an earth-shaking performance boost. As for Google Cloud speech API, keep working, make it free and we\u2019ll all say Amen :)"
    },
    {
        "url": "https://medium.com/@RecastAI/how-to-make-your-chatbot-a-huge-success-two-dimensions-and-a-tip-3da221bdf731?source=user_profile---------25----------------",
        "title": "How to make your chatbot a huge success? Two dimensions and a tip!",
        "text": "Every researcher knows that the hardest part of writing a paper is making a killer introduction. Chatbots are no exception to this rule: everything is in the first sentence they say. In around 150 characters, their destiny is determined. A good opening will create a beautiful bond between the user and the chatbot, whereas a bad opening will leave the chatbot in a dark lonely place after only 5 seconds of conversation\u2026\n\nSo what is it about the opening sentence? Why is it so crucial for the success of a chatbot? Well, just as it is with humans, first impressions are critical. To put it more scientifically, the opening defines the two dimensions of the conversation: width and depth. So let\u2019s discuss these two concepts and learn how to design great conversations!\n\nThe first dimension of the conversation is its width, or what the chatbot knows, can discuss and handle. Developers usually refer to it as the \u201cfunctional coverage\u201d of the chatbot. In this era of Artificial Narrow Intelligence, where machines know how to handle specific tasks and solve specific problems, keeping the width of the conversation narrow helps avoiding user frustration. From the very first sentence, as the chatbot engages the user, it should clearly state what it can to do, and more importantly, what it can\u2019t.\n\nA chatbot saying \u201cI\u2019m here to help you understand your last cell phone invoice\u201d is aiming too high, or rather too wide. It invites a very large spectrum of questions from the user. The probability of getting a query the bot can\u2019t handle early on in the conversation is rather high. This is likely to frustrate users and prompt them to abandon the conversation quickly.\n\nA chatbot saying \u201cI can help you pay your last cell phone bill\u201d is closing down the conversation width quite drastically. Nevertheless, it is stating the rules of the game very clearly and reduces the probability for a question it may not be able to handle.\n\nImagine, however, that at a later stage of the conversation, the user asks the chatbot something that goes beyond the declared scope, such as \u201ccould you remind me how much the last invoice was?\u201d. If the chatbot knows how to handle such a demand, the user will have a pleasant surprise. Everyone is happy.\n\nIf, however, the chatbot does not understand such a request, the user won\u2019t be overly frustrated. After all, the bot is primarily here to pay invoices, not to display past ones\u2026\n\nThe second dimension of the conversation is its length. Once again, the idea is to keep things short. Users are impatient, therefore your bot should help them quickly get to their goal. Additionally, in long conversations, the probability of diverging and expressing an idea the chatbot doesn\u2019t understand increases.\n\nEasy to say, but long conversations are sometimes necessary! What if a lot of information is to be collected to deliver what the user wants? This is where the Reward Principle saves the day!\n\nConsider the following example, a chatbot that helps you calculate your mortgage entitlement. Quite useful! To provide a good service, the bot needs to gather around six different facts about the user\u2019s real-estate project to do the math. This takes time. The Reward Principle states that the chatbot should give the user a \u201creward\u201d, an added-value, after every 2\u20133 questions asked to keep the user\u2019s interest. A reward is a piece of information that has value to the user at this point in the conversation. So even if he cuts the conversation short, the user leaves with something useful.\n\nIn our example, a good implementation of the Reward Principle will cut the conversation into two parts.\n\nAfter three questions, the chatbot would give the user a range of sums of money, but not the exact amount he could get from the bank. The chatbot will then ask to go through another three questions to calculate the exact sum the user could borrow.\n\nEven if the user doesn\u2019t play along and quits, he leaves with an idea of how much his mortgage could be. Not that bad! ;)\n\nWe are in a fast-paced world. People try to be as a efficient as possible. Chatbots should help!\n\nMaking a chatbot that helps you buy your train ticket is better than one that simply shows you the train timetable.\n\nA chatbot that helps you return a product is better than one that simply goes through a goalless conversation about the store\u2019s returns policy.\n\nA chatbot that goes all the way to ordering takeaway food is better than one that simply displays the menu and today\u2019s specials.\n\nBuilding chatbots that deliver is better, so no more FAQ chatbots! ;)"
    },
    {
        "url": "https://medium.com/@RecastAI/chatbots-have-never-made-this-much-sense-for-companies-4c19e15149b5?source=user_profile---------26----------------",
        "title": "Chatbots have never made this much sense for companies",
        "text": "Chatbots have been around for more than a year now, and companies are starting to look at them quite closely. We\u2019ve met with Clevy, a Parisian bot platform with a twist: they builds bots for corporate employees. What does that mean? It means they\u2019re experts in making conversational interfaces out of HR procedures, helpdesks, change management processes or user manuals.\n\n\u201cClevy was created during a hackathon in June 2016\u201d said Bastien Botella, co-founder and COO of the startup. \u201cIt started as a side project but quickly turned into a full-blown startup.\u201d\n\n\u201cWell, companies everywhere are facing the same issues when it comes to internal communication or shared procedures. There are too many intranets, too many email exchanges, to many loose bits of information, all mixed in a huge yearly turnover. We wanted to find a way to centralise and facilitate the access to this kind of information for employees. By creating conversational agents that centralise IT procedures, employee on-boardings, days-off counters, and other workplace usecases, companies gain time, money, and peace of mind\u201d.\n\n\u201cBots are much more accepted in the corporate world than 6 months ago, let alone a year\u201d said Fran\u00e7ois Falala-Sechet, co-founder and CTO of Clevy \u201cbut even if our clients aren\u2019t up to date with the concept, they quickly understand the benefits. When we explain that with our solution, they\u2019ll get an interactive way to deliver selected information, available 24/7, on the communication channels their employees are already comfortable with, at any scale, they understand the power of chatbots.\u201d\n\n\u201cAI is essential for bots if you want to provide an adaptable experience. Bots without AI can work fine, but reach their limits quickly: they can\u2019t manage switches in topics, can\u2019t adapt to the users\u2019 way of speaking, cannot collect information in a non-survey manner. When you use Natural Language Processing, you bring modularity to your bot, and make it very scalable.\u201d\n\n\u201cWith Recast.AI\u2019s NLP and our own technologies, we have access to different kinds of metadata: sentiment analysis, sentence polarity, type and intonation. Because we can detect if the user is happy or angry, if his sentence is positive or negative, and if he\u2019s asking a question or not, we can adapt our responses to provide the best service.\u201d\n\n\u201cWe\u2019ve worked on a bot that started as a simple client-specific Human Resources FAQ, but evolved in a global \u201cask me anything about HR\u201d agent, really valuable for employees.\n\nAnother project we loved was adapting Facebook\u2019s Safety Check feature for Workplace. Facebook\u2019s work social network doesn\u2019t allow employers to access employees\u2019 locations, something that is essential for the Safety Check. We therefore created a bot that reaches out to every workers in a company during an emergency asking \u201cis everything ok?\u201d, expecting for a yes or a no. That way, people can be marked safe without sharing private information.\n\nFinally, Wysa.io is an emotionally sensitive chatbot that accompanies patients between their therapists appointments. It provides guidance, exercices and presence to people in need, and is overall really cool.\u201d\n\n\u201cFirst, start slow. Bots aren\u2019t magic, they\u2019re logic. Start with an easy use case, where a bot does one major thing, and does it well. Then add another feature, and keep building.\n\nSecond, do not underestimate small talk. Most people expect bots to be clever and witty. If the user says \u201cI love you\u201d and the bot replies with \u201cSorry, I didn\u2019t get that\u201d, they\u2019re disappointed. Create extensive support for basic chitchat. \u201c\n\n\u201cThird, monitor, monitor, monitor! Bots are always in motion, and can always better adapt to market needs. Conversational interfaces have one great strength: people, through no intermediary, are telling you what they want! So take it, implement it, and keep improving your bot until it gets it right every single time.\n\nAnd if you need any help, give us a call ;) \u201c"
    },
    {
        "url": "https://chatbotslife.com/why-language-has-to-become-a-non-issue-for-bots-9205e6cef2e5?source=user_profile---------27----------------",
        "title": "Why language has to become a non-issue for bots \u2013",
        "text": "The way humans talk to each other has always been dependent on established codes that allow us to understand each other. Languages are a major part of our identity, because they are the gateway from our inner self to the world. They are expressed differently through slang, intonations and body language.\n\nIt is clear that if artificial conversational interfaces are going to become an important part of our society, they\u2019d better be able to adapt to each of us smoothly. And language, in its entirety, is a key factor in this success.\n\nWell, bots strive to be the most natural way of interacting with our digital world. By using natural language, we allow the user to talk just as if they were talking to a friend or a relative, on the same channels (Messenger, Slack, Kik, etc). But we can\u2019t do it only in a few languages! To allow a smooth integration on a global scale, supporting as many languages as possible is key.\n\nAnd to do that, we\u2019ve talked to a few chatbot actors to discover how they managed languages in their bot building. Citron, the chatbot that makes place recommandation as easy as asking a friend in both English and French, was designed to be multilingual.\n\nLouisa explains that they first launched Citron in French, and shortly followed with English in May 2017.\n\nMatthieu Bietry, CTO of The Chatbot Factory, followed the same pattern.\n\nLanguages are complex. Some work by the same rules, but some are constructed very differently. How do you manage the different word structure? Words that mean different things in different languages? How do you add another language to a bot that\u2019s already settled in one without derailing everything?\n\nLouisa explained that when you have a well established bot in one language, broadening its understanding to other languages is quite easy, because you don\u2019t have to recreate anything! Translating its training can be time consuming, especially the small talk, but the process is quite smooth nevertheless. However, she recognizes that Citron was lucky: the team is fully bilingual, making training way easier.\n\nMatthieu explains that with languages that are close to our own, both in their structure and their cultural heritage, the integration into a bot isn\u2019t too hard because it\u2019s just a matter of translating. However, supporting widely different languages means adapting to widely different cultures, which will impact your bot structure and flow.\n\nHe also explains that some words get tricky. French, English or German speakers casually use the word \u201cciao\u201d. It\u2019s tricky to teach a bot that \u201cciao\u201d is not only used in Italian when it has been programmed to recognize the language of a sentence and respond accordingly. The Chatbot Factory team had to develop ingenious ways to allow every non-Italian to say pizza, and every non-French to say baguette.\n\nLouisa\u2019s advice is rooted in the core of Citron: community. As we know, training your bot is essential to its success. Having a large international community is a god send when it comes to training a new language! When you start adding more than 3 languages, it becomes hard to find native speakers within your team or social circle, so a strong community is key.\n\nMatthieu\u2019s advice is to put effort into the bot\u2019s translation, from its training to its answers, but not to stop there: are the APIs you\u2019re connected to multilingual? If not, how are you going to translate their data? Is your bot dependent on time zones? Then do you want to link a particular language to a particular time zone? What about the cultural acceptance of bots and AIs?\n\nYou have to remember that a bot isn\u2019t just code and sentences, but a tool that people will only use if the experience is smooth and effective. And when we work with different languages, we\u2019re working with different expectations.\n\nSo if you\u2019re thinking about building a bot in Spanish, Japanese, Mandarin, Finnish, Dutch, Portuguese, or anything else, you\u2019re making the first step in the direction of bots adaptable to everybody, anywhere. At Recast.AI, we did it: we made language a no-brainer by supporting any language there is. Now, you have every tool you need. Good luck!"
    },
    {
        "url": "https://medium.com/@RecastAI/interview-cr%C3%A9er-mto-le-joyeux-bot-de-m%C3%A9t%C3%A9o-france-f7fea71f8092?source=user_profile---------28----------------",
        "title": "Interview \u2014 Cr\u00e9er MTO, le joyeux bot de M\u00e9t\u00e9o France",
        "text": "Livebotter \u201cbuilds state of the art, highly customized chatbots for brands. And for fun.\u201d. Une entreprise donc sp\u00e9cialis\u00e9e dans la construction de robots intelligents sur Messenger pour les marques. Fond\u00e9e en juillet 2016, l\u2019entreprise compte aujourd\u2019hui 5 personnes et a travaill\u00e9 avec des clients tels que Soci\u00e9t\u00e9 G\u00e9n\u00e9rale, Netflix, l\u2019Or\u00e9al ou La Redoute.\n\n\u201cD\u2019un c\u00f4t\u00e9, il y a 1,2 milliard de personnes qui utilisent Messenger\u201d explique Benjamin. \u201cC\u2019est colossal. Et d\u2019un autre c\u00f4t\u00e9, le march\u00e9 des apps est satur\u00e9 : les utilisateurs de smartphones consultent cinq applications par jour, et en t\u00e9l\u00e9chargent tr\u00e8s rarement de nouvelles. Un bot permet \u00e0 une marque de cr\u00e9er un nouveau canal de communication et de f\u00e9d\u00e9rer une communaut\u00e9 l\u00e0 o\u00f9 tous les utilisateurs sont pr\u00e9sents : les applications de messagerie, et tout particuli\u00e8rement Messenger.\u201d\n\n\u201cMTO est un bot que vous pouvez trouver sur Messenger en tapant M\u00e9t\u00e9o-France ou en suivant ce lien puis en cliquant sur \u201cEnvoyer un message\u201d. Aujourd\u2019hui, le bot a 50 000 utilisateurs et a trait\u00e9 plus de trois millions de messages. Il est capable de vous donner la m\u00e9t\u00e9o \u00e0 un endroit pr\u00e9cis, de vous faire un top 5 des plus belles photos de la communaut\u00e9 chaque semaine, et vous propose m\u00eame des filtres photos in\u00e9dits.\n\nDavid Tedgui, qui a d\u00e9velopp\u00e9 le bot, nous explique sa mani\u00e8re de faire : \u201cJ\u2019utilise NodeJS et Express. Ce sont deux technologies faciles d\u2019utilisation et recommand\u00e9es par Messenger. La majorit\u00e9 des bots sont aujourd\u2019hui cod\u00e9s en NodeJS, donc une personne qui d\u00e9bute aura plus de facilit\u00e9s avec ce langage.\u201d\n\n\u201cLes utilisateurs appr\u00e9cient les exp\u00e9riences guid\u00e9es par les boutons, des listes, et diff\u00e9rents \u00e9l\u00e9ments visuels. Il est donc tout \u00e0 fait possible de construire un bot sans compr\u00e9hension du language (NLP) et sans AI. Cependant, ces exp\u00e9riences restent sur des parcours d\u00e9limit\u00e9s. Dans le cas de MTO, il \u00e9tai essentiel de permettre aux utilisateurs de demander avec leurs mots \u201cquelle est la m\u00e9t\u00e9o \u00e0 Toulouse\u201d. Cette libert\u00e9 est un r\u00e9el plaisir pour l\u2019utilisateur, et fait la qualit\u00e9 du bot.\u201d\n\nSelon Benjamin, il est essentiel d\u2019identifier les utilisateurs finaux du bot, ceux qui vont lui parler au quotidien, et de cr\u00e9er un produit en phase avec leurs attentes. Un bot est un produit tr\u00e8s pr\u00e9cis et sp\u00e9cifique, et essayer de tout faire n\u2019est pas une solution.\n\nD\u2019un point de vue plus technique, David conseille de bien analyser la documentation Messenger et celle des APIs que vous utilisez, et de ne pas h\u00e9siter \u00e0 s\u2019inspirer des exemples fournis par Messenger. De nombreux projets aidant la construction de bots multiplateforme sont \u00e9galement disponibles sur Github. Certains sont tr\u00e8s int\u00e9ressants et peuvent permettre de construire un bot puissant rapidement, donc utilisez les !"
    },
    {
        "url": "https://medium.com/@RecastAI/disclaimer-19a76f7d72bf?source=user_profile---------29----------------",
        "title": "How to use Random Access Navigation (RAN) to create smarter bots",
        "text": "This tutorial focuses on explaining what Random Access Navigation (RAN) is for bots, rather than detailing the classical (if that exists) bot building process in itself. You\u2019ll also learn how to implement it within your Recast.AI bot and your code in Node JS. You can find the GitHub repository here and the Recast.AI bot associated with the project here. Let\u2019s begin!\n\nRandom Access Navigation, usually shortened RAN, was first assessed by Shane Mac of Assist on a Medium post. It is the process of allowing people to navigate through a bot based on entities more than intents (if those notions are unclear to you, you can take a look at this article). Let\u2019s take an example (that we\u2019ll use throughout our tutorial): Movie Bot (moviedbot).\n\nLet\u2019s say you want to watch a movie tonight and you want to discover a new one. You can actually browse movies by years, genres or even language/country of release. That said, if we wanted to build this bot intent based, we\u2019d need four intents : get-type, get-date, get-genre, get-language. The flow will probably look like this :\n\nGoing from greeting to get-language in a linear flow would force the user to answer one question after the other and move forward within our pre-determined flow. As you see here, we could run through different issues using this type of flow:\n\nYou\u2019ve probably caught my drift by now. An intent based flow doesn\u2019t solve our movie bot issues in this particular case. What we need is a bot that understands that we need a year, a genre, a language or a country: entities. This, regardless of the order of entities or combination of entities such as year and genre and therefore ask for the missing one.\n\nThe goal is to make your bot detects all entities required to perform an action. This process allows the user to change their mind without going back in the flow, which would complicate the logic. That way, you can make your bot smarter and quicker to provide the correct information.\n\nNow you\u2019re wondering \u201cOk I get it, but how can I do this using Recast.AI?\u201d.\n\nBuilding the Movie Bot within Recast.AI is fairly easy. Start by creating a new bot by forking the talking bot. In order to make our bot entity based we just create one intent: discover. To make the request to the movie API database, our bot needs to know a year, a genre, a nationality \u2014 country \u2014 language and if it\u2019s a movie or a TV show. Lucky for us, Recast.AI already knows what a datetime, a language, a location for the country and nationality is. We just need to teach the bot to understand the different genres and the difference between a movie and a TV show.\n\nSee below for some examples :\n\nNow we need to tag drama, romance or any other genres you want as custom entities. Once you tagged a few go back to your bot page and scroll down to find your new genre gazette. Click and add the other genres. For the purpose of this bot we are using the genres the Movie DB API provide for our entities to match directly with their genres database. You can find the full list of the Movie DB here. Close your gazette to make sure only the entities within your gazette will match as show below :\n\nNow, let\u2019s do the same for movie and TV show which are going to be standalone entities. In your gazette, provide synonyms for movie (film, movies, etc.) same apply for TV shows (shows, sitcom, tv, etc.). Click on the links to check our gazettes for movies and TV shows.\n\nNow that the training part is done, head to the Bot builder. As we just have one intent the flow is very simple, just add a greeting action and your discover action to the builder. You can add all the other intents forked from the talking bot to provide small talk intents to your customers. This is how your builder should look :\n\nNow we need to update our action discover to set notions : (genre) AND (movie OR TV) AND (datetime) AND (location OR language OR nationality) as shown below :\n\nNow that we\u2019re done with the Bot Builder, head for the bot connector and connect your bot to Messenger\n\nOur bot is now up and running with Recast.AI. The challenge now is to manage RAN through the code. The way it works is we always call the flow (Bot Builder). This means there are only two things the bot does: either small talk or looking for a movie.\n\nFirst, start by cloning the Recast.AI node.js starter kit, available on Github:\n\nThen, update the function from :\n\nOur main function, called , starts by getting all the notions we setup on the Bot Builder from the API result .\n\nNow, check which notions are set, so we can ask the user for the missing ones we need to make a request to The Movie DB API :\n\nWhether all conditions but one are fulfilled on the first request, or one by message after message, we\u2019ll go through our conditions until we have everything we need. The Bot Builder will take care of the memory management, so we don\u2019t need a database to keep track of the entities over multiple requests.\n\nOnce we have collected all information we need, we just have to send a request to themoviedb\u2019s api (you can find the documentation for the endpoint we\u2019ll be using here).\n\nWe\u2019ll be using axios, an handy Promise based http client.\n\nDon\u2019t forget to run !\n\nFinally, we format the result in a nice carousel :\n\nAt the end of our function , in , we just have to call the API and send the results :\n\nThere are many ways to improve this bot: we could handle more types entities, allow users to skip a question if they don\u2019t care about a criteria or make our bot more lively by adding some randomness to its wording.\n\nWe already tried to implement this, so go checkout the source code on Github. We would be thrilled to see what improvements you could make! You can also use the bot on Messenger :)\n\nWe hope you enjoyed this RAN tutorial, if you have any feedback, leave a comment !"
    },
    {
        "url": "https://medium.com/@RecastAI/viva-technology-and-recast-ai-are-proud-to-present-frankie-the-official-vivatech-chatbot-cf8c8b721926?source=user_profile---------30----------------",
        "title": "Viva Technology and Recast.AI are proud to present Frankie, the official VivaTech chatbot",
        "text": "Viva Technology and Recast.AI are proud to present Frankie, the talking schedule of the 2017 edition of Viva Technology, the hub for the world\u2019s innovators, tech-lovers and pioneers of the future.\n\nAvailable on Messenger by\n\nFrankie is trained to give you the schedule of events for the three days and three nights of the conference. He is also great at listing all startups and speakers attending the event, as well as guiding you to the foodtrucks or toilets.\n\nViva Technology 2016 already imposed itself as a one of the great tech conferences with 5 000 startups, 250 investors, 6 000 CEOs and 5 000 students. Viva Technology 2017 is a more precise, more focused event where major corporations (AccorHotels, Air France KLM, Cisco, TF1, LVMH, etc) can work hand-in-hand with entrepreneurs from all around the world.\n\nAnd to make Viva Technology 2017 unforgettable, the team chose to create a conversational interface for their program: Frankie.\n\nFrankie was built by Recast.AI in collaboration with Viva Technology. Created in September 2015, the startup was awarded second place in the contest Publicis90 during Viva Technology 2016, and is now the European leader in chatbots for enterprise.\n\nBy developing their own language artificial intelligence, they allow companies to build bots for customer support, product marketing or travel improvement. Desjardins bank, Transilien, SFR, Deloitte and Webhelp are now alongside Viva Technology as companies who\u2019ve worked with Recast.AI to create automated agents.\n\nIf you want to experience Viva Technology 2017, buy your pass here.\n\nTo get additional information or schedule an interview, reach justine@recast.ai.\n\nFrankie a \u00e9t\u00e9 construit par Recast.AI en collaboration avec Viva Technology. Cr\u00e9\u00e9e en septembre 2015, la startup a remport\u00e9 la seconde place de l\u2019initiative Publicis90 durant Viva Technology 2016, et est aujourd\u2019hui le leader europ\u00e9en des chatbots d\u2019entreprises. Avec sa propre technologie d\u2019intelligence artificielle et de compr\u00e9hension du langage, Recast.AI permet aux entreprises de construire des bots pour de nombreux usages tels que le support client, le marketing produit ou les assistants bancaires. La banque Desjardins, Transilien, SFR, Deloitte et Webhelp et maintenant Viva Technology sont des soci\u00e9t\u00e9s qui ont utilis\u00e9 Recast.AI pour construire des agents conversationnels performants."
    },
    {
        "url": "https://medium.com/@RecastAI/recast-ai-et-homeserve-sassocient-pour-r%C3%A9volutionner-l-assistance-d-urgence-%C3%A0-domicile-gr%C3%A2ce-%C3%A0-un-4721df2df6fa?source=user_profile---------31----------------",
        "title": "Recast.AI et HomeServe s\u2019associent pour r\u00e9volutionner l\u2019assistance d\u2019urgence \u00e0 domicile gr\u00e2ce \u00e0 un\u2026",
        "text": "Fond\u00e9e en 2015, la start up Recast.AI, qui propose une plateforme de cr\u00e9ation de bots pour les d\u00e9veloppeurs et entreprises, se sp\u00e9cialise dans les bots de supports client, a accompagn\u00e9 HomeServe, le sp\u00e9cialiste des services d\u2019assistance pour la maison, dans le d\u00e9veloppement de Tom, le premier assistant virtuel de D\u00e9pann&Moi by HomeServe, d\u00e9di\u00e9 au d\u00e9pannage d\u2019urgence \u00e0 domicile.\n\nHomeServe et Recast.AI ont lanc\u00e9 le \u00ab projet Tom \u00bb en d\u00e9cembre 2016. L\u2019enjeu \u00e9tait de d\u00e9velopper une technicit\u00e9 visant \u00e0 simplifier le traitement de l\u2019assistance d\u2019urgence pour la maison, de r\u00e9inventer l\u2019exp\u00e9rience utilisateur et de cr\u00e9er un nouvel usage. Trois mois de travaux men\u00e9s dans le cadre de cette aventure ont permis de cr\u00e9er Tom, le chatbot D\u00e9pann&Moi by HomeServe, disponible dans sa premi\u00e8re version sur Facebook Messenger.\n\nAujourd\u2019hui, de nombreux chatbots se concentrent sur la gestion du service apr\u00e8s-vente. Disponible 24h/24 et 7j/7, Tom se diff\u00e9rencie et est \u00e0 ce jour en France, le premier chatbot \u00e0 vocation commerciale. Ses missions sont de s\u2019adapter au langage de l\u2019utilisateur, de comprendre son besoin, et de lui proposer la bonne prestation qui r\u00e9pond \u00e0 son probl\u00e8me et \u00e0 son profil.\n\nGr\u00e2ce \u00e0 Tom, D\u00e9pann&Moi by HomeServe va encore plus loin dans l\u2019accompagnement de ses clients et dans la compr\u00e9hension de leur probl\u00e8me avec l\u2019int\u00e9gration de plus de 450 sc\u00e9narios de panne de plomberie. Tom d\u00e9duit ainsi les intentions de l\u2019utilisateur pour \u00e9tablir le diagnostic final et proposer la bonne prestation, que l\u2019internaute pourra ensuite finaliser sur le site www.depannetmoi.fr \u2014 le paiement int\u00e9gr\u00e9 sur Facebook Messenger n\u2019\u00e9tant pas encore disponible sur le march\u00e9 fran\u00e7ais. L\u2019utilisateur pourra ainsi se voir proposer le devis correspondant \u00e0 son besoin pr\u00e9alablement qualifi\u00e9, et planifier l\u2019intervention d\u2019un professionnel agr\u00e9\u00e9 HomeServe proche de chez lui, afin de solutionner son besoin.\n\n*En tant que pionnier, HomeServe imagine les services de la maison de demain et a cr\u00e9\u00e9, en septembre 2015, la HomeServe Innovation Factory pour accompagner son plan de transformation digitale et r\u00e9pondre aux \u00e9volutions des besoins et des usages des consommateurs. Ce d\u00e9partement innovation est d\u00e9di\u00e9 \u00e0 la recherche et la mise en place de projets innovants au service des nouveaux besoins des consommateurs, dans une dynamique intrapreneuriale. L\u2019innovation port\u00e9e par la HomeServe Innovation Factory est ax\u00e9e sur les comportements de demain et notamment sur la maison intelligente. Le tout, r\u00e9solument orient\u00e9 vers l\u2019utilisateur pour le pilotage et la gestion quotidienne de l\u2019ensemble des services de la maison.\n\nA propos de HomeServe : HomeServe est une soci\u00e9t\u00e9 de services pour la maison qui r\u00e9alise depuis 15 ans pour les foyers fran\u00e7ais des interventions d\u2019assistance (installation, r\u00e9paration, d\u00e9pannage) dans les domaines de la plomberie, du chauffage, de l\u2019\u00e9lectricit\u00e9, de l\u2019\u00e9lectrom\u00e9nager \u2026, gr\u00e2ce \u00e0 son r\u00e9seau de 3 000 professionnels pr\u00e9sents sur toute la France. Elu Service Client de l\u2019ann\u00e9e 2017 dans la cat\u00e9gorie \u00ab Services \u00e0 l\u2019habitat \u00bb, HomeServe con\u00e7oit des solutions d\u2019assistance pour le compte de diff\u00e9rents acteurs r\u00e9f\u00e9rents de la maison (eau, \u00e9nergie, banques, assurances, e-commerce) et en direct aupr\u00e8s de particuliers via ses offres contractuelles (www.homeserve.fr) ou \u00e0 la demande (www.depannetmoi.fr). HomeServe compte aujourd\u2019hui 1 million de clients en France et 2,5 millions de contrats d\u2019assistance. A ce jour, l\u2019entreprise emploie 450 collaborateurs en France. HomeServe appartient au groupe britannique du m\u00eame nom, leader mondial des services pour la maison, pr\u00e9sent dans 6 pays et cot\u00e9 en bourse au London Stock Exchange."
    },
    {
        "url": "https://chatbotsmagazine.com/chatbots-back-to-the-roots-of-user-interfaces-fbe3805325b9?source=user_profile---------32----------------",
        "title": "Chatbots: Back to the Roots of User Interfaces \u2013",
        "text": "Chatbots: Back to the Roots of User Interfaces Why such hype? Put very simply: the user experience.\n\n2016 was the year of chatbots and it seems like 2017 will be as well. The hype is growing quickly as every company now wants to interact with its customers via a bot. Why such hype? Put very simply: the user experience. Chatbots can handle human conversations, how cool is that? But what about user interfaces? This is where it gets odd; chatbots are a mixed bag of futuristic and minimalist interfaces. Let\u2019s look back to the beginnings of digital to understand why this is true.\n\nInterfaces matter a lot. They are the window to your product and directly impact your user experience. You may have developed the coolest tech in the valley, but ship it with a bad interface and your product is ruined.\n\nAt some point in their career, every developer really should study the history and evolution of user interfaces.\n\nLet\u2019s take a concrete example to illustrate our interface story: route planning. Your customers faced a simple problem: finding the shortest way from point A to point B. Lucky for them, you provided this service. Throughout the years, the service would not change but the interface and its complexity certainly did.\n\nIt was the very beginning of human-computer interactions: the command line interface. The scary, matrix-like, black screen with flashy green characters. CLIs were primitive and not user-friendly but they shared a beautiful minimalistic essence: you interacted with your computer by entering text!\n\nFor some, entering text is simpler than any other form of interaction. This simplistic design is the reason CLIs are still so popular, several decades after their introduction.\n\nIn 1973, Xerox introduces the graphical user interface (GUI) and its key component: the mouse. Apple and Microsoft follow up in the 80\u2019s and GUIs spread like wildfire. Finally a user-friendly interface, with icons and data visualization!\n\nYour route planning program just got better. Customers can scroll through potential starting points and destinations. Instead of a textual itinerary, the route is traced on a map and users can interact with this map.\n\nBut it\u2019s not all perks and no downsides: these programs are much heavier than command line ones and were often printed on dozens of floppy disks.\n\nWith each new version of HTML/CSS/Javascript and backend frameworks, it became easier for developers to build complex scalable web applications. If you can imagine it, there is a web app for it.\n\nWeb browsers were not a revolution in terms of user interface. What really improved was the user experience: as explained in the webcomic, no need to install and update dozens of applications anymore.\n\nThis had a decisive impact on the amount of data exchanged with your customers. To plan a route, users would load your webpage, post a request with point A and B and load the response: much lighter than installing a graphical program.\n\nLast but not least, mobile apps. The ultimate extension of your hand! Tap, press and swipe to interact with millions of applications. A very cool interface, but a drawback in terms of experience: users go back to installing and managing hundreds of applications. Our route planning service just got heavier and people are noticing.\n\nAfter CLIs, GUIs, web applications and mobile applications, a new kind of interface is gaining traction: chatbots. It\u2019s the future of user interfaces and you definitely want to expose your route planning service via a bot. What can you expect from this interface and how heavy would it be for your customers?\n\nDisclaimer: our choice of service was not random :p Transilien recently launched a route planning bot for the Paris train system.\n\nUsing it is pretty straightforward: start a new conversation with the bot on Messenger, enter your starting point and destination and the bot replies with possible itineraries.\n\nYour service could not get lighter! Nothing to install and update, no webpage to load, only a text exchange with your application.\n\nChatbots are futuristic and primitive at the same time. We could say bots are like command line interfaces because you interact with a service by typing commands. The commands are much easier to remember though since they can be expressed in natural language.\n\nSome bots make the interface more graphical with advanced replies made of cards and buttons.\n\nYou could say that bots are like web applications because there is nothing to install and the application is seamlessly updated.\n\nSo chatbots are an optimal mix of all previous user interfaces. It combines the best of each interface, remaining light and minimal.\n\nWhat about mobile apps? Let\u2019s be honest: apps are a pain for companies and users.\n\nEvery company has faced the challenge of maintaining a website and developing a corresponding mobile app. Going from web to mobile is extremely expensive: you have to simplify the interface, reduce the number of features and port it to several mobile OS and screen sizes.\n\nUsers on the other side have to install your app and experience a reduced version of your website.\n\nConversational UI is the next step. Chatbots are simple and minimal: perfectly suited for mobile devices. There is no maintenance cost of web and mobile versions and finally, users don\u2019t have to install anything more than a messaging application.\n\nThere is only one thing left to say: go conversational!"
    },
    {
        "url": "https://medium.com/@RecastAI/recast-ai-joins-microsoft-to-launch-a-new-ai-startup-program-at-station-f-in-paris-6a1e03290ab5?source=user_profile---------33----------------",
        "title": "Recast.AI joins Microsoft to launch a new AI startup program at Station F in Paris",
        "text": "Microsoft announces the launch of its artificial intelligence program at Station F, aiming to contribute to the development of future major players of AI in France and worldwide. Recast.AI, the leading bot platform in France, is the first one to join the program.\n\nTo democratize AI around the world, Microsoft positions itself as a catalyser in an AI dedicated community at Station F. To animate this community, Microsoft will work with 5 key startups that will federate the following 100 startups Microsoft wants to gather during the first year.\n\nMicrosoft chose Recast.AI, the collaborative platform allowing developers and companies to build bots, leading AI startup in France, as the first company of the program.\n\nThe initiative wishes to create and cultivate a startup ecosystem in the capital as well as around France and Europe to innovate in different areas of artificial intelligence. For this project, Microsoft collaborates with a major partner: INRIA, the French Institute for Research in Computer Science and Automation, one of the leading research facilities in AI worldwide.\n\nThis partnership aims to combine industry and research to offer entrepreneurs a dedicated accompaniment in both fields. Station F will open its gates by the end of June.\n\nThe first selected of these startups is Recast.AI. Founded in late 2015 by 42 graduates, Recast.AI is a collaborative platform allowing developers and companies to build chatbots. By developing their own language technology and bot building methodology, the startup has already worked with more than 15 clients such as SFR, SNCF Transilien, KLM or Viva Technology.\n\nThe team is excited to work with both INRIA and Microsoft to combine technology and business expertises. But all three actors also plan to collaborate on the many events that will take place in the incubator. Christophe Shaw wishes to host 200 events per year at Station F, and Recast.AI intends to help gather the startup ecosystem they have already connected with during their 18 months of existence.\n\nFor more information about Recast.AI, contact Justine Baron \u2014 justine@recast.ai \u2014 06 77 68 43 26 For more information about Microsoft, contact L\u00e9a Ubaldi \u2014 lubaldi@hopsctoch.fr \u2014 01 58 65 10 14\n\nLa premi\u00e8re startup s\u00e9lectionn\u00e9e, Recast.AI, a \u00e9t\u00e9 fond\u00e9e en fin 2015 par des dipl\u00f4m\u00e9s de l\u2019\u00e9cole 42. Recast.AI est la plateforme collaborative permettant aux d\u00e9veloppeurs et entreprises de construire des agents conversationnels, plus souvent appel\u00e9s \u201cchatbots\u201d. En d\u00e9veloppant leur propre technologie de langage et m\u00e9thodologie de construction de bots, la startup a d\u00e9j\u00e0 travaill\u00e9 avec plus de 15 clients tels que SFR, SNCF Transilien, KLM ou Viva Technology.\n\nL\u2019\u00e9quipe est heureuse de travailler avec Microsoft pour combiner leurs expertises technologiques et commerciales. Mais Recast.AI, Inria et Microsoft pr\u00e9voient \u00e9galement de collaborer sur les nombreux \u00e9v\u00e8nements qui seront organis\u00e9s au sein de Station F. Microsoft a pour ambition de r\u00e9aliser pr\u00e8s de 200 \u00e9v\u00e8nements par an \u00e0 Station F, et Recast.AI les aidera \u00e0 f\u00e9d\u00e9rer l\u2019\u00e9cosyst\u00e8me de startups qu\u2019elle a d\u00e9j\u00e0 solidifi\u00e9 depuis sa cr\u00e9ation il y a 18 mois."
    },
    {
        "url": "https://medium.com/@RecastAI/how-attending-viva-technology-made-us-grow-as-a-startup-7066b1b09d54?source=user_profile---------34----------------",
        "title": "How attending Viva Technology made us grow as a startup",
        "text": "Viva Technology 2017 was Viva Technology 2016, only bigger, fuller and better.\n\nAs laureates of the Publicis90 award and Webhelp challenge in 2016, we were delighted to see the second edition in Paris. It was a no-brainer to decide to come back.\n\nIn 2016, we were babies. Recast.AI wasn\u2019t even a year old, and we were only 7 people on the team. This year, we\u2019ve grown to 20 members, have a clearly defined product, strong client references and goals. As VivaTech grew stronger, we grew bigger.\n\nThe point of this new edition of the event was very clear:\n\nIf we had to remember 3 things from VivaTech 2017, they would be:\n\nWe are thrilled to have enjoyed a few minutes as one of the six startups selected to discuss the ecosystem of startups in France with our president. Here to better understand what it\u2019s like to be a startup in France working in technology, Emmanuel Macron listened to founding stories, asked what France did well and what could be improved. The exchange was rich and a wonderful opportunity for us!\n\nA thrilling project for a great event: Recast.AI was chosen to built VivaTech\u2019s chatbot, the talking schedule of the event. Bringing a conversational interface to Europe\u2019s main event gave the participants a real glimpse of the future.\n\nA new kind of event appeared in 2017: workshops! Between sessions, pitches and demos, startups and companies had the opportunity to work with interested participants on a topic of their choice. We got a full house to discuss bot building methodologies and the power of bots.\n\nViva Technology\u2019s organization, with startups hosted by labs from major companies, brings the best of both worlds: an atmosphere of true collaboration and innovation between growing startups and established powerful groups. Cisco, Air France, Airbus, LVMH, BNP Paribas: 20 brands hosted between 15 and 60 startups and organized protoyping contests, pitching contests and hackathons to federate the ecosystem and create partnerships. And an international one of that! Companies from all across Europe, but also from across all oceans moved to be part of Europe\u2019s major tech event.\n\nYou couldn\u2019t be here with us? No worries: here are three 1-min videos to give you the best of the three days.\n\nAnd to everyone we met and worked with: see you next year!"
    },
    {
        "url": "https://chatbotsmagazine.com/building-great-bots-an-enterprise-chatbot-methodology-c89aa188da2f?source=user_profile---------35----------------",
        "title": "Building Great Bots: An Enterprise Chatbot Methodology",
        "text": "How to Build Great Bots for Big Companies Our professional methodology for delivering successful bots to enterprise clients\n\nJasmine Anteunis is a co-founder of Recast.AI, a French startup which makes a bot-building platform for developers.\n\nHi! The purpose of this guide is to help you create a bot from scratch, from the first thought of its existence to its launch in production. This article focuses on the project management and bot building, more than on the coding and framework implementation. This methodology is used internally at Recast.AI, and is based on the way our bot-building platform works.\n\nThis article is a really good toolbox if you want to build a bot on your own and don\u2019t know where to start! But it is ideally for complete teams working on bot projects, whether for their own company or for external clients.\n\nThe first thing we do are bot workshops. For these, it\u2019s important to bring together all project team members (on your side and on the client side, if there is one). Take all the time you need to complete the following three tasks before jumping into the technical side. Expect an average of two to three hours for each workshop, depending the complexity of your bot.\n\nThe first step is to define what your bot will do, and what answers it should provide. To do that, we employ two activities.\n\nFirst, write conversation examples from the end-user point of view. That way, you\u2019ll see if your bot has multiple conversations on different topics. Think about any way users can reply to a question! Maybe they\u2019ll be satisfied. Maybe they\u2019ll have follow up questions. Maybe they\u2019ll be straight-up rude. Also, write down how you want users to get information: go straight to the point, or follow a procedure created by the bot?\n\nThe second exercise is to take a step back, and draw a sketch that represents the entire bot use case. Try to answer to these questions:\n\nOnly when you have the answers to these questions, write a single sentence that describes what your bot does. This should be the first sentence your bot will say to present itself. It\u2019s the same as a preparing a pitch or a kickass tweet.\n\nHere are a few good ones:\n\nNow, it\u2019s time to summarize your research to clearly identify the scope of your bot, before jumping into the construction of your conversational flow.\n\nA smart and good bot has a clear and defined scope. Here is an example sketch.\n\nName each feature, and each user intent (try to categorize what they will say). The main feature, the core of your bot, can be one to three different intents. We don\u2019t advise more \u2014 remember \u201cA bot that does everything will be good at nothing.\u201d\n\nThe extended use case, which includes more broad requests, can include different intents. But always keep your focus on the bot\u2019s core use case.\n\nThe third circle includes default questions. These are not about your bot use case, but about the company, the maker, or other thing you want to capture during a conversation.\n\nThe last one is the biggest, and contains all small talk you want your bot to understand: compliments, greetings, goodbyes, insults, questions about weather and pizza (users will ask these, guaranteed.)\n\nRemember: If you don\u2019t list what you want to understand, your bot will end up replying \u201cI don\u2019t understand.\u201d You don\u2019t have to set a reply to every possible sentence, but if you can be smarter in your answers than a simple \u201cI don\u2019t understand,\u201d do it. Saying \u201cI don\u2019t understand\u201d over and over looks like a machine, not the persona you hope to present.\n\nAt the end of this session, you will have a list of all intentions and features of your bot, from the core to the small talk.\n\nNow, let\u2019s focus on the heart of your conversation. All small talk and default questions can be put to the side for now. Let\u2019s focus on the main feature.\n\nAsk yourself this:\n\nDraw a diagram \u2014 this is actually your first conversational flow. Many tools are available to help you, such as Draw.io, Cacoon or Sketch. But trust us \u2014 start with paper and pen first.\n\nYou can have small separated flows to represent the few different actions in your main feature, e.g. \u201cget the next train from a station\u201d and \u201cget the entire itinerary.\u201d Take the first conversation example you wrote at the beginning to help you.\n\nA good conversation is not more than 2\u20133 interactions. It\u2019s similar to a website experience! UX designers will say that the number of clicks to reach the user goal is important. The same principle applies inside a conversation. The number of interactions the user has to go through to get a real answer from the bot is critical. Think of how impatient you get when you have to go through step after step with someone else\u2019s bot.\n\nHere\u2019s an example of a good, simple flow.\n\nOnce you have your main tree, think about all the possible information you need to complete the necessary actions. Have you forgotten something? Think about the limitations of your use case. In our use case above, we need to take into consideration possible wrong information from the user, (e.g. the wrong train station), and handle all potential errors.\n\nAt each step, think about all the possible errors. Write them into your flow. Your goal is to leave no possible situation unplanned for.\n\nNow, it\u2019s time to think about the most important part of your bot, the user experience (UX) and its personality.\n\nThe only interactions your users will have is through conversation, so building a rich and detailed personality makes your chatbot more believable, relevant and fun to your users. Mapping your personality out into a Bot Persona will help you translate a designed personality into a real use case.\n\nThe first exercise is to create this persona in a way that will work for who your users are and what their purpose is. If you are building a bot to help people find a bar, it may be rather young, and speak with friendly slang, emoji, and maybe make some jokes. Describe your bot persona, and focus on the tone, the friendliness and the image that represents it. This article can shed some light on giving personality to a bot.\n\nNow that you\u2019ve created quite a character, it\u2019s time to work with the UX: conversation interactions. Depending on the messaging application to which you connect your bot, you can include cards and buttons. Messenger is today the smoothest messaging app in terms of UX.\n\nYou can now write each bot interaction in detail. Pay attention to the limitations in the number of text characters you are allowed for your bot\u2019s messages. Follow your diagram, and think about how you want to represent that exchange: do you need cards? Buttons? A text entry? Specify each UX element for every reply. Again, you do not want to leave any part of the experience unplanned.\n\nIf you are developing a bot for clients, it\u2019s critically important at this point to create UATs: User Acceptance Tests.\n\nWhat\u2019s a UAT? It\u2019s a conversation set that represents the conversation flow. Write 3 or 4 different conversations: one that succeeds, one where the bot is managing false user input, and one when the user isn\u2019t talking about the bot\u2019s use case at all. Make sure that all these conversations can be handled.\n\nUATs are important for the developer who will code and train the bot, as it define the logic and behavior he will have to correctly deliver.\n\nUATs are also the success conditions of the project for the client, which you will use to declare it done and ready.\n\nOur methodology is mainly used for innovative bot projects that offer a new service to users, and not for chatbots automating existing conversations (e.g. customer support with a large history of conversations). So here you will have to focus on two things: The business logic, and the training of your bot.\n\nBots are in most cases connected to external APIs and large enterprise information systems. Therefore, a technical meeting is necessary to understand the API, its documentation, and what\u2019s possible to use in the bot. From this information, you can then begin your technical design.\n\nDepending on the tool you use to build your bot, which NLP provider, which channel connector, your design could vary widely. At Recast.AI, the first thing we do is to split the conversation flows into real intents. Define which entities will be used to retrieve important information, and then create the file architecture needed for that information. If you need a starter kit, I suggest yone on Recast.AI Github account.\n\nNext, model the bot\u2019s flow with all the intents \u2014 we of course suggest the Bot Builder on Recast.AI. It should be as close as possible to the flow you\u2019ve drawn previously \u2014 ideally, it will be identical.\n\nEach intent in Recast.AI (or whatever platform you use) must contain sentences to train your bot to understand user inputs. You will need 30 to 50 expressions for each intent \u2014 all the ways you can come up with that someone might tell you they want your bot to perform a certain action. To fill these intents, you should involve the entire project team, those close to the end-users \u2014 the business unit, who know firsthand what they will probably say. Share an Excel sheet, or give access to the platform, to everyone, so they can help add intents directly and train the bot.\n\nThis first knowledge base is necessary before you begin testing your bot. The second part of training, below, is different. It will require even more people. \ud83d\ude42\n\nTesting is very different from training, so it\u2019s important to have a clear idea of what each is.\n\nTesting and training can be done alternately: one test session followed by one train session. For each task, work by iterations. First, add 2 or 3 people to test/train your bot in your extended team, then in your client team. Then ask 5 friends, then 10 random people, and finish with 10 to 20 people who correspond to your user target \u2014 real customers, or people much like them.\n\nPlan to do this as many times as you need to provide a great experience. We have experienced training and testing times from one week to one month, depending the complexity of the bot and the target audience.\n\nTesting is about user experience. The main goal is to put testers in the shoes of the users and give them a specific goal, context or mission e.g. \u201cyou are a young worker who wants to go to Paris and you don\u2019t know when the next train will leave your station. What do you ask the bot?\u201d.\n\nTesters should try the same flow but respond differently: once explaining a lot of things in replies, once just by clicking on buttons.\n\nThe test master (overseeing all testing sessions) has to write down all remarks such as ambiguous wording, unclear images, pain points in the conversation, etc. Try to always have new testers as well as old ones to see your progress :)\n\nThe train task is focused on improving the bot\u2019s understanding. The goal is not to finish a conversation flow immediately, but rather to find sentences that the bot doesn\u2019t understand. The more unmatched sentences you find, the better your bot\u2019s training will be, and the better your end-users\u2019 experience will be. You will minimize the number of \u201cI don\u2019t understand\u201d responses, replacing each with a successful reply!\n\nThe best way for trainers to train is to ask the same thing to the bot in many different manners for each step of the conversation: How many different ways can they ask when the next train is coming? What\u2019s important at this step is to have different trainers, who use different wordings for their intents, and change them regularly. Keep them in your target audience though! Young people will not speak with the same words and phrases as seniors, nor will people from different countries, or even different neighborhoods. If you have a bot for a specific role, such as a banking assistant, young workers will not have the same bank vocabulary as a more experimented manager.\n\nWe\u2019re getting closer to the end, but one last best practice: Within two weeks after the bot\u2019s test launch, once again train the bot. Check the logs for unmatched messages you had not thought of, or have never seen before, and add these expressions to the bot\u2019s training. We find that two weeks is neither too long nor too short a period to capture a majority of sentences that will be commonly used.\n\nYou are now ready for the last step: release! Some companies start small with a pool of beta testers, and only slowly begin to advertise their new talking service. Others just launch all at once, and iterate during the following weeks to adjust! Do as you feel will be best for the client and their customers.\n\nI hope you have a better idea of a complete methodology to start building robust enterprise chatbots. If you have feedback, please don\u2019t hesitate to ping me back! \ud83d\ude42"
    },
    {
        "url": "https://chatbotsmagazine.com/the-challenge-of-data-protection-in-the-era-of-bots-3667a51cb495?source=user_profile---------36----------------",
        "title": "The Challenge of Data Protection in the Era of Bots",
        "text": "Bots are computer programs powered by AI. They understand your requests and can respond to them in human language, and they are expanding at breakneck speed. Gartner forecasts that more than 85% of customer interactions will be managed without a human by 2020.\n\nBot builders (that\u2019s what people developing those bots are called) are working hard to make their creations as friendly as possible. They want to imitate feelings to encourage users to feel empathy for their bots and create a sense of friendship. But when you talk to a bot, you behave differently. Since you know you\u2019re talking to a machine, you have no filter, no fear to be judged, and speak more freely. This explains why bots receive so many insults: you are not afraid to hurt the feelings of a program.\n\nThis led Caroline Bercegeay, a French entrepreneur, to create her first bot called \u201cPetites Questions.\u201d The bot advises inexperienced mothers and creates a safe space where they can ask whatever they want without the fear of judgement. Why would a program tell you how to live your life, right?\n\nBut sometimes, innocence is just an appearance. You could very well be giving away private and personal information to a program that collects and resells data. Have you given your approval? Is it legal? Do you have means to erase this conversation?\n\nIn a nutshell, an important question is raised: \u201cCan I trust this bot?\u201d That adds another piece to the huge data protection challenge we have today.\n\nWhat we\u2019re calling \u201cpersonal data\u201d includes your identity (name, surname, age, gender, nationality), your contact details (email, phone number, mailing address), and administrative information such as bank or insurance details.\n\nSensitive data includes ethnicity, political, philosophical or religious opinions, information about your health or your sex life as well as any offenses and criminal record.\n\nWhat are the risks of sharing such data?\n\nPersonal data can be used for two main reasons: identity theft or sending of targeting advertising.\n\nA study realized by Atlantico in July of 2015 confirmed everybody\u2019s nightmare: you can find standard kits of personal data (address, email, phone number, credit card numbers), called \u201cfullz,\u201d on the dark web. According to the journalists, these fullz are worth 19\u20ac on average, with a minimum of $1 and a maximum of $450. The price is directly linked to the quality of the profile and its profitability. It will be higher if the kit includes credit card numbers with a high limit.\n\nBut breaches of privacy aren\u2019t only in the evil dark web. Companies can buy your personal information to target their ads, as I\u2019m sure you\u2019re aware of. To figure out how much each bit of personal information is worth for marketers, the Financial Times has done an interactive simulator to show the value of your profile. In this study, general information about identity is worth $0.0005 per person, or $0.50 per 1000 people. But when you provide information about spending habits, interests, family situation or health, the value increases considerably.\n\nTo avoid data breaches, a company has to set up heavy security processes and respect them. And even then, nobody\u2019s bulletproof. Seventy percent of data breaches are caused by humans, either on purpose, like SwissLeaks, or by mistake, like the Australian Immigration Services.\n\nIn SwissLeaks, a former HSBC computer scientist, Herv\u00e9 Falciani, stole confidential fiscal documents from his employer exposing a system of fiscal fraud organized by the bank, and sent them to journalists. He had simply downloaded the data onto a USB stick and leaked it. He has been sentenced to 5 years of prison for economic spying and exchange of data for money. He wasn\u2019t recognized as a whistle blower.\n\nThe case of the Immigration Australian Services comes from a pure mistake. One of their employees disclosed personal information about 31 Heads of State and Government invited to the G20 in Brisbane by incorrectly filling the destination addresses of his email.\n\nWe won\u2019t even talk about the Ashley Madison leak that revealed the personal information of 32 million members having extramarital affairs!\n\nConsidering the importance of data protection, the European Parliament has voted a law called General Data Protection Regulation (GDPR), adopted on the April 14th, 2016 and coming into application on May 25th, 2017.\n\nThis law is directly applicable in the Member States, without transposition and will apply to any company that collects, processes and stores personal data of European citizens.\n\nBefore GDPR, European Directive 95/46/CE framed personal data protection, but contained serious loopholes, in particular concerning the data protection on the Internet and the application of the rights across the Union. In France, this Directive was in addition to the \u201cLoi Informatique et Libert\u00e9s\u201d of 1978, amended on August 6th, 2004.\n\nGDPR will start in May of 2018 and will harmonize regulatory frame applicable to all EU member states, but also spreading its application outside EU for companies processing data of European citizens.\n\nIt will also impose more important sanctions: financial penalties can cost up to 4% of a company\u2019s annual turnover or \u20ac 20 million (the highest amount retained), compared with \u20ac300,000 formerly provided in France by the Law Informatique et Libert\u00e9s, \u20ac30,000 is the average penalty in 2016.\n\nMoreover, the GDPR establishes that the subcontractor is submitted to the same expectations and sanctions than the Responsible for Traitement (the company who has collected the data in).\n\nGDPR requires the explicit consent of the data subject and gives them a better control of their personal data. In the context of collecting personal data, companies are required to inform users about the object of the data collection and the time of the data conservation. In addition, they must allow data subjects to have full control over their data, allowing them to be viewed, modified, deleted or transferred to another Responsible of Treatment by their owner. Moreover, users have the right to refuse the use of their personal data for profiling. Every person has the right not to be the subject of a decision based exclusively on automated processing.\n\nTo successfully enforce these new obligations, it\u2019s important for the company to inform the data subject about his rights and how he can contact the Data Protection Officer to make a request. That is why the companies have to establish new procedures.\n\nTo be compliant with the GDPR, companies have to nominate a Data Protection Officer to insure the respect of new data policies, to advise the company\u2019s employees on its application and to act as a point of contact with the supervisory authority. Moreover, companies have to define the correct documentation to insure the authorities of the respect of data procedures on requests.\n\nThey also have to ensure privacy by design (that means integrating data from the very beginning of the design of products or services) and implement an impact study to identify the risks of data breaches and the actions to be taken to reduce them. In case of data breaches, companies have to notify the competent authority in a short timeframe, as well as the owners of the data concerned.\n\nThe first thing to do is to appoint a DPO, responsible for the management of personal data, whatever the size of your company.\n\nThe DPO should then map the personal data of your company, determining the following:\n\nOnce the mapping has been completed, the DPO will have to put in place procedures to ensure data security. These procedures have to fix the following points:\n\nOnce the procedures have been established, the DPO will be responsible for enforcing them, including conducting audits and communicating to the team, making them aware of the procedures and the matter of personal data protection.\n\nAnd once you\u2019ve done all that, congrats! You\u2019re all set and can go for a drink.\n\nIf you\u2019re having troubles enforcing ground rules for securities, here\u2019s how we do it here: each team member leaving its laptop unattended and unlocked gets a nice message on our private Slack announcing he\u2019ll be treating everyone with croissants the next morning! I won\u2019t lie, I kind of miss the breakfasts, but croissants are becoming rarer and security is getting stronger!\n\nI hope it\u2019ll work out just fine for you as well \ud83d\ude42"
    },
    {
        "url": "https://medium.com/@RecastAI/2017-kik-bot-landscape-a-public-spreadsheet-gathering-90-kik-bots-30b576c03c41?source=user_profile---------37----------------",
        "title": "2017 Kik Bot Landscape, a Public Spreadsheet Gathering 90+ Kik Bots",
        "text": "Note: We couldn\u2019t display all Kik bots on the infographics, that\u2019s why we\u2019re sharing a public spreadsheet with 90+ Kik bots. Some bots may offer services across multiple categories on the infographics. In that case, we categorized them according to their primary use case. If you know other Kik bots not present in the spreadsheet, please comment this article and we will add them.\n\nLifestyle \u2014 These bots are all about our daily life. They help us live a pleasant and healthy life.\n\nFun with Friends \u2014 Invite your friends and let\u2019s have some fun with them! Enjoy a moment using bots with your friends and family.\n\nFashion and Beauty \u2014 These bots give a lot of insights about fashion, beauty and more generally everything to shine in society.\n\nMeet New People \u2014 Chat, debate and discover new people hanging out on Kik.\n\nEntertainment \u2014 We all work hard, why not having some fun while chatting on Kik?\n\nGames \u2014 Kik hosts a lot of games, here are few bots turned into games!\n\nYou\u2019ll find here a public spreadsheet with more than 90 different Kik bots!"
    },
    {
        "url": "https://chatbotslife.com/interview-building-la-bringue-one-of-the-best-messenger-bots-in-france-4ef64cb96d33?source=user_profile---------38----------------",
        "title": "Interview \u2014 Building La Bringue, one of the best Messenger bots in France",
        "text": "Interview \u2014 Building La Bringue, one of the best Messenger bots in France\n\nLa Bringue was founded a bit over a year ago, with the purpose of exchanging party recommendations among electro lovers. It first started as a Facebook group between close friends, but quickly reached 15 000 members through word-of-mouth. Through this growth, the team confirmed that there was a real need for guidance in the Parisian night life, especially to break the routine and discover new places.\n\nThe team decided to address that need through an app. However, they discovered the power of bots when Facebook introduced them at F8 2016. That\u2019s when they chose to create a bot instead of an app. Why is that? We talked with the founding team, and here are their insights on bot building.\n\n\u201cAs we looked into bots after their announcement at F8, we realized three things make them great for our audience :\n\n\u201cToday, 6000 people use L2-B2 per week. Users come to the bot around twice a month, which is the average amount of nights out for our target audience.\n\nOur blog brings curated information to users, in a one-way manner, much like a media.\n\nL2-B2, our bot, provides instant answers and advices to an immediate need.\n\nIt\u2019s the complementarity of these three services that creates a true satisfaction for our users, day and night.\u201d\n\n\u201cL2-B2 is developed in NodeJS, a language we didn\u2019t know before diving into bot building. It\u2019s simple and powerful. We discovered it when building our first bot on Wit.AI, by using their template bot.\n\nIt was important to us that the bot would be as adaptable to human speech as possible. We wanted to be able to talk to the bot like you talk to a friend, we wanted to create a conversational space with emotions, feelings, a sense of friendship even. To achieve that, we had to implement Natural Language Processing (NLP), or we would\u2019ve ended up with a 100% button bot.\n\nWe\u2019re now using Recast.AI\u2019s NLP, and it allows us to truly understand what our users want. That\u2019s the beauty of conversation! In an app, we\u2019d have to be restricted to pre-set fields, whereas in a bot, the user expresses his needs directly, through no intermediary. It\u2019s then essential to leverage the power of NLP to gather all information and provide an excellent service, not through predefined flows but through the liberty of human speech.\n\nHowever, to create a smooth interface for our users, we redeveloped our own version of context management based on Random Access Navigation (RAN). We needed to step out from a basic survey flow to adapt to whatever input we got. Today, no matter in what order a user gives key information such as music style, location or date to the bot, L2-B2 is capable to understand which information he got, which information it still needs, and ask the relevant questions. If all key information are provided in one sentence, he directly presents suggestions. That is something we developed from scratch.\u201d\n\n\u201cThere are three things we really want to put an emphasis on.\n\nFirst, don\u2019t create a questionnaire bot where the user has to answer 3 or 4 questions in a row to get what he wants. Strive to provide the information as quick as possible, and leverage the power of text to do so.\n\nSecond, focus on the core of your bot. It\u2019s tempting to create a bot that knows and answers everything, but rather choose to address one use-case perfectly.\n\nFinally, find the right balance between simplicity and identity. Create a user experience that is smooth and efficient but also conveys a personae that fits the values of your brand.\u201d"
    },
    {
        "url": "https://medium.com/@RecastAI/2017-messenger-bot-landscape-a-public-spreadsheet-gathering-1000-messenger-bots-f017fdb1448a?source=user_profile---------39----------------",
        "title": "2017 Messenger Bot Landscape, a Public Spreadsheet Gathering 1000+ Messenger Bots",
        "text": "Note: We couldn\u2019t display all Messenger bots on the infographics, that\u2019s why we\u2019re sharing a public spreadsheet with 1000+ Messenger bots. Some bots may offer services across multiple categories on the infographics. In that case, we categorized them according to their primary use case. If you know other Messenger bots not present in the spreadsheet, please comment this article and we will add them.\n\nAnalytics \u2014 These bots help business owners to get insights about their product right into Messenger. From performance analytics to business ones, a wide range of bots are helping teams to save time and get relevant information.\n\nCommunication \u2014 Messenger improves communications between individuals and businesses. These bots are usually adding features for these communications.\n\nCustomer Support \u2014 A lot of software help startups with customer support. These bots put those solutions right into Messenger. (not in infographics)\n\nDesign \u2014 Designer collaborate on Messenger and these bots are here to help them work more efficiently.\n\nDeveloper Tools \u2014 Many Messenger bots are built by developers for developers. From bug tracking to productivity tools, those bots are widely used among technical teams.\n\nEducation \u2014 A lot of bots educate Messenger\u2019s users and help them learn new things.\n\nEntertainment \u2014 We all work hard, why not having some fun while chatting on Messenger?\n\nFinance \u2014 These Messenger bots for business teams and employees target people interested in finance in general. (not in infographics)\n\nFood \u2014 Food lover? Check out these great bots dealing with recipes, nutrition and cooking!\n\nGames \u2014 Messenger also supports a variety of bots games. (not in infographics)\n\nHealth \u2014 These bots help you stay healthy. (not in infographics)\n\nHuman Relations \u2014 Human Relations is an important topic to keep your team motivated and get new talents coming in. These Messenger bots are designed to help the HR team keep up the good work. (not in infographics)\n\nMarketing \u2014 Marketers use a broad range of tools and some of them are integrated into Messenger thanks to these bots. (not in infographics)\n\nNews \u2014 Stay updated thanks to these bots.\n\nProductivity \u2014 Become more productive on Messenger thanks to these bots. (not in infographics)\n\nShopping \u2014 More and more bots are helping Messenger users buy anything they want. (not in infographics)\n\nSocial \u2014 Let\u2019s get social and interact with other Messenger users, friends and family. (not in infographics)\n\nSports \u2014 For those who practice sports, you should check out these sport bots. (not in infographics)\n\nTravel \u2014 These bots help you prepare and schedule your travels right into Messenger.\n\nUtilities \u2014 These Messenger bots are saving you time and efforts for a variety of everyday-life tasks.\n\nYou\u2019ll find here a public spreadsheet with more than 1000 different Messenger bots!"
    },
    {
        "url": "https://medium.com/@RecastAI/10-chatbot-tips-to-build-awesome-bots-on-recast-ai-aebbc5ed4ac7?source=user_profile---------40----------------",
        "title": "10 chatbot tips to build awesome bots on Recast.AI \u2013 RecastAI \u2013",
        "text": "Yay bot building! To make your onboarding as easy as possible, here are 10 tips to efficiently setup your bot\u2019s understanding. We\u2019ll talking intents, entities and languages.\n\n As a support to this article, we created two bots: a good assistant, and a bad assistant. Go check them out to see the dos and don\u2019ts of bot building with Recast.AI!\n\nFirst thing you need to understand are intents.\n\nAn intent is a box of expressions that mean the same thing but are constructed in different ways. You can picture it as a folder where your bot will be sorting user inputs. Intents are the heart of your bot\u2019s understanding because they each represent an idea your bot will be able to understand.\n\nThat being said, the purpose of your intents is to understand what your end users means. You don\u2019t want your bot to think that maybe you want to book a train ticket for tomorrow: you want your bot to be sure of it.\n\nIf the bot cannot understand exactly what you want, it will create a frustrating user experience. To avoid that, create very specific intents that serve one defined purpose.\n\nA bot with unbalanced intents, Recast.AI displays intents to train more\n\nIf you want Recast.AI\u2019s intent classification to be truly efficient, it\u2019s important to have a roughly equal number of expressions in each intent.\n\nEven if it usually takes more examples to train your most important intent than you second-order ones, strive to keep their number of expressions around the same amount. This helps avoid a bias towards intents with a big expression count. In the Training Analytics part of your \u201cMONITOR\u201d tab, you can find your training balance in real time!\n\nIf two of your intents are very close in terms of expressions\u2019 syntax or content, you should probably merge them.\n\nLet\u2019s take an example with an agent responsible for booking travel tickets. You could create an intent handling plane reservations, another for train tickets, and one more for bus tickets.\n\nThe problem here is that the expressions in each intent would be really similar, with only the transportation mode changing from time to time. You\u2019ll be better set with only one intent handling reservation, and an entity catching the requested vehicle (don\u2019t worry, we\u2019re getting to entities soon).\n\nThere are lots of things that all bots should do, like say hello, say goodbye, receive compliments, handle insults, get the weather\u2026 These are not a real part of the specific service your bot will provide but it greatly contributes to its sympathy quota!\n\nThese intents are very common and right now, you can easily fork them from a special bot we created: scaffolder. Scaffolder is a collection of bots and well-trained intents to help you build bots faster and focus on the core components of your agents. More, you can explore trending and new bots to get inspiration from the community.\n\nExpressions are sentences your end users send to your bot. If you can imagine an intent as folder, an expression is a file neatly stored in it.\n\nThe more expressions you have, the more precisely your bot will be able to understand users.\n\nAmongst the infinity of parameters of text classification, one of the most important is the diversity between expressions of the same intent. If you want your bot to understand a very large panel of sentences, it\u2019s paramount to train it with completely different grammatical structures and not to bias it with a single sentence pattern repeated a hundred times.\n\n To cope with that, we introduced a \u201cDiversity Indicator\u201d in the Training Analytics section of the \u201cMONITOR\u201d tab. Hopefully everything should be green!\n\nUsually, your user will tend to either over-explain their request, or under-explain it by using only keywords.\n\nAs a bot builder, you want to add expressions that can help understand both extremes. To do this, you need to keep your expressions straight to the point of what your intent is supposed to catch.\n\nDon\u2019t be afraid to remove bits of your users inputs to keep the interesting parts.\n\nEntities are important keywords extracted from expressions. We automatically detect 28 of them such as datetimes, names, locations, currencies, etc. You can find the exhaustive list here.\n\nIn addition to those gold entities, you can train your own and extract keywords specific to your use case. Simply select words and tag them.\n\nSometimes, entities can be mistaken for intents, but they don\u2019t serve the same purpose. Let\u2019s see how to use them efficiently.\n\nWhile the syntax of your sentences is important, the entities present in the sentences also have a big influence on the classification. Bear in mind that the presence of an entity in a sentence will steer the intent detected towards others with the same entity.\n\nDo not tag everything!\n\nI sometimes see intents with almost every words tagged as an entity. That\u2019s not necessary, and can even hurt the performances of your bot.\n\nThe purpose of entities is to be extracted from the sentence, allowing you to use it for a specific action. That means you should only tag information that your bot specifically needs to know and no more.\n\nRecast.AI currently supports three languages: English, French, and Spanish. You can integrate all three of them in one unique bot to make it bilingual or even trilingual!\n\nKeep in mind that if you only use one language, sending it as a parameter in your API call will make the response faster, by avoiding the process of detecting the language.\n\nIt is not mandatory to use all three languages, but if you do, you\u2019ll have to keep your intents balanced and homogeneous.\n\nThey should have nearly the same amount of sentences and contain the same entities.\n\nWith this principle applied, you can be sure that the performance of your bot in French is roughly the same in Spanish and English!\n\nAt Recast.AI, we try to release new features at the earliest. This mindset comes from two benefits: we get to release new features more frequently, and get feedback on a daily baisis.\n\nTo keep up with the most recent changes, keep an eye on the changelog section of our user manual, follow us on twitter to be notified when a new feature is coming up, and subscribe to receive our changelog via email!\n\nYou can find all tips in our developer guide here."
    },
    {
        "url": "https://medium.com/@RecastAI/host-your-slack-bot-easily-with-recast-ai-331bd259bee9?source=user_profile---------41----------------",
        "title": "Host your Slack Bot easily with Recast.AI \u2013 RecastAI \u2013",
        "text": "Bots are an inherent part of Slack. Everyday, teams across the world use Slack bots to increase their productivity, better communicate or have fun at the office.\n\nRecast.AI allows you to build, train, host, connect and monitor new bots on Slack! To show you how simple it is to build a Slack bot with Recast.AI, let\u2019s walk you through the creation of a Chuck Norris jokes bot.\n\nHere are the main steps of bot building we cover in this tutorial:\n\n1 \u2014 Create and train the bot on Recast.AI\n\n2 \u2014 Connect it to Slack using Bot Connector\n\n3 \u2014 Fork our starter kit repository on GitHub to code and customize the bot\n\nFirst, we need a bot on Recast.AI, so let\u2019s login to the platform and create a new bot:\n\nYou can see that your new bot contains greetings and goodbyes default intents:\n\nNow, let\u2019s add our main intent: get-joke. Click on the + CREATE button and type your intent name.\n\nEnter expressions you want your bot to understand. These expressions are training it to understand when a user asks for a joke.\n\nWe don\u2019t need extensive training for this tutorial, so let\u2019s move on to the next step. In the \u201cbuild\u201d tab, you can set the logic of your bot and its replies. For instance, click on the edition symbol of the \u201cgreeting\u201d block: you can consult and edit replies your bot provides when a user says \u201chello\u201d. To add a new action, click on the \u201c+\u201d button and select get-joke!\n\nGo to the \u201cRun\u201d tab, select \u201cSlack\u201d.\n\nCreate a new Slack app using this link.\n\nFill the form with your App Name and your Development Slack Team name. If you don\u2019t have a team yet, create one.\n\nGo to Settings > Basic Information, scroll down and fill the form within Bot Connector with your Client ID and Client Secret. You can find them in the App Credentials section.\n\nIn the Bot Users tab, create a new bot user.\n\nIn the OAuth & Permission tab, fill the Redirect URL with the OAuth URL provided within Bot Connector.\n\nIn the Interactive Messages tab, enable and fill the Request URL with the Events URL of your channel.\n\nIn the Event Subcription tab, enable and fill the Request URL with the Events URL of your channel.\n\nScroll down to the \u201cSubcribe to Bot Events\u201d section, and enable the following events (or others, according to the behavior you want your Slack bot to have):\n\nThat\u2019s it! You can already test your bot by hitting the button \u201cAdd to Slack\u201d and start chatting:\n\nIf you need to customize your bot by implementing an external API, you need to code the integration and deploy it. In our case, we\u2019re using https://api.chucknorris.io to get Chuck Norris facts.\n\nFirst, go to the Code tab, clone the starter kit and follow the indications to run your bot locally.\n\nThen, code your bot logic. If you want to see the code of the Chuck Norris bot, here\u2019s the GitHub repository.\n\nChange the remote URL of your code to push to your new Github repo:\n\nGo to the Run tab, then go to the Bot Hosting sub-tab.\n\n \n\n Connect your account to Github and link your repository:\n\nClick on \u201cConnect your repo\u201d to start deploying your repository. Wait 2 minutes for deployment and start talking to your bot!\n\nAgain, you can find the complete code on Github and the bot on Recast.AI.\n\nIf you have any feedback, question or suggestion, drop us an email at julien@recast.ai or join our Slack Community (https://slack.recast.ai)."
    },
    {
        "url": "https://medium.com/@RecastAI/why-and-how-you-should-test-your-new-product-with-product-hunt-and-42-45c080c8c3f?source=user_profile---------42----------------",
        "title": "Why and how you should test your new product with Product Hunt and 42",
        "text": "Launching a new product is great. It\u2019s thrilling to watch something grow week after week and it\u2019s exciting to see the days of the launch come. But the truth can be harsh: sometimes, the building team gets too focused and misses something. That happens, and that\u2019s when a community comes into action.\n\nThe world of bots is exponentially growing since April 2016. If we started in September 2015 as an natural language processing (NLP) API, we quickly grew into a bot building platform. But we wanted to go further: we wanted to be the collaborative bot platform where you find everything you need to build your bot: a truly efficient AI technology developed by our R&D teams, all bot tools seamlessly integrated, a community to share and construct with, all with a cool and easy interface.\n\nThat\u2019s what this new version focuses on! We\u2019ve developed a suite of tools to make bot building a smooth process: Bot Learning, Bot Connector, Bot Hosting and Bot Analytics, all wrapped around a core of strong AI.\n\nWell, when it comes to communities, we surely don\u2019t need to introduce Product Hunt. Started in November 2013 as a newsletter, the platform is now a reference in terms of product launching and the tech community.\n\nHaving launched a few products on Product Hunt before, we were familiar with the mechanisms of the website. We knew that a launch would bring our product a wave of new visitors, interested in new technologies and discovering new things: the best people ever to test and improve a newly launched product!\n\n42 was also a very clear choice for us. With a good knowledge of how this futuristic school works, we knew that we\u2019d find hands-on, clever and versatile developers to test our platform. So, on the evening of our launch, we hosted an event at the school, inviting our network of ambassadors and users o present the tools and gather feedback.\n\n\u201cCan we not use any of your tools but use your technology and code?\u201d\n\n\u201cCan we not code at all and simply launch a bot with your tools?\u201d\n\nOf course, people want to know if your product fits their way of working. Developers love being able to have full control of their work and being able to understand how everything works.\n\n\u201cIt\u2019s essential for me to use webchats, will you soon cover that?\u201d\n\nWhen they see your product, they imagine what they could do with it, but also start dreaming. And that\u2019s a great sign! It means your product is inspiring and people have loads of creative ideas for it. That\u2019s where the gold is. Pay much attention to what your community asks. Understand why they ask that and try to put yourself in their shoes to see what direction they want your software to take. By noting very thoroughly suggestions, frustrations, random ideas that seem crazy, you\u2019ll get a deep understand of your community to better satisfy them.\n\n\u201cCan we still tag golden entities? WE CAN\u2019T? WHY NOT?!\u201d\n\n\u201cYou moved logs on the Monitor tab? That makes sense?\u201d\n\nChanging things always create waves, especially for regular users who\u2019ve developed a routine using your software. Be prepared to explain why you decided to change, what it brings, and how old habits can be replaced and improved! Change management and openness is extremely important to bring a community together.\n\n\u201cWhat makes you better than your competitors?\u201d\n\nChoosing one software to build your projects is a committed decision. Expect your consumers to ask about you after they\u2019ve asked about your product. They\u2019re looking for a sense of digital bonding, where you can assure them of your presence if they need you. Talk about the team, how you met, how you were founded, what\u2019s the vision of your company, why brought you to create your software, etc etc. That can quickly led to questions about your competitors from users who\u2019ve analyzed the market. Be factual, be helpful, be true to your brand etiquette. That\u2019s what they want to understand.\n\nThanks to Product Hunt and 42 for their continuous help in the development of Recast.AI!"
    },
    {
        "url": "https://medium.com/@RecastAI/2017-slack-bot-landscape-a-public-spreadsheet-gathering-700-slack-bots-523e317b4e6e?source=user_profile---------43----------------",
        "title": "2017 Slack Bot Landscape: a Public Spreadsheet Gathering 700+ Slack Bots",
        "text": "Note: We couldn\u2019t display all Slack bots on the infographics, that\u2019s why we share a public spreadsheet bellow with 700+ Slack bots. Some bots may offer services across multiple categories on the infographics. In that case, we categorized them according to their primary use case. If you know other Slack bots not present in the spreadsheet, please comment this article and we will add them.\n\nAnalytics \u2014 These bots help business owners to get insights about their product right into Slack. From performance analytics to business ones, a wide range of bots are helping teams to save time and get relevant information.\n\nCommunication \u2014 Slack was built to improve communications between coworkers. These bots are usually adding features for team communication.\n\nCustomer Support \u2014 A lot of software help startups with customer support. These bots put those solutions right into Slack.\n\nDesign \u2014 Designer collaborate on Slack and these bots are meant to help them work more efficiently.\n\nDeveloper Tools \u2014 Many Slack bots are built by developers for developers. From bug tracking to productivity tools, those bots are widely used among technical teams.\n\nEntertainment \u2014 We all work hard, why not some fun at the office? (not in infographics)\n\nFile Management \u2014 Some file management tools created a Slack bot for convenience. (not in infographics)\n\nFinance \u2014 These Slack bots are designed for business teams and employees interested in finance in general. (not in infographics)\n\nHealth \u2014 These bots help you stay healthy while working. (not in infographics)\n\nHuman Relations \u2014 Human Relations is an important topic to keep your team motivated and get new talents coming in. These Slack bots are designed to help the HR team keep up the good work.\n\nMarketing \u2014 Marketers use a broad range of tools and some of them are integrated into Slack thanks to these bots. (not in infographics)\n\nNews \u2014 Stay updated thanks to these bots.\n\nOffice Management \u2014 If Slack helps team be organized, these tools focus on the organization of the office to keep everyone happy and productive.\n\nPersonal \u2014 Your coworkers sometimes have their own problems, why not helping them right into Slack?\n\nSecurity \u2014 Integrate specific bots to help you keep your product safe. (not in infographics)\n\nTravel \u2014 More and more teams are fully remote and as your startup is growing, traveling is needed to keep up the business. These bots help you prepare and schedule your travels.\n\nUtilities \u2014 These Slack bots are saving you time and efforts for a variety of everyday-life tasks.\n\nFind here a public spreadsheet with more than 700 different Slack bots. Again, if you know others, please share it in comments and we will be happy to add them to the list."
    },
    {
        "url": "https://medium.com/@RecastAI/why-you-should-master-bot-hosting-5fc7563aa212?source=user_profile---------44----------------",
        "title": "Why You Should Master Bot Hosting \u2013 RecastAI \u2013",
        "text": "In this guide, you\u2019ll learn how Bot Hosting works, how your code should be structured to run on it and what are the good and bad practices.\n\nI start this tutorial by assuming you already know how to use the platform tools: train your bot, create a conversation flow using Bot Builder, connect it to channels using Bot Connector, so if it\u2019s not the case, I invite you to check out our others tutorials.\n\nWe\u2019ll start with a quick overview of what Bot Hosting is, will move on to a description of the requirements and limitations, and conclude by building a custom code hosted on Bot Hosting! Let\u2019s roll.\n\nBot Hosting is a service that allows you to host your bots without any devops knowledge.\n\nIt is based on serverless cloud instances. Your code is triggered by a call to a https endpoint (e.g. POST https://run.recast.ai/your-bot). Once triggered, it executes and goes back to sleep until the next call. You can also easily access your logs deploy your code each time you push!\n\nOf course, it\u2019s fully integrated with other Recast.AI services, so you can host a bot using Bot Connector and made with Bot Builder.\n\nYou can find Bot Hosting on Recast.AI, in the Run/Bot Hosting tab.\n\nAs of today, only NodeJs is supported for Bot Hosting. More languages will come soon.\n\nSince we deploy your code in generic containers, there are 3 requirements.\n\nYour package.json must contain the build task. It must be present even if empty or just copying files. The default one you will find in the starter kit is \u201cbuild\u201d: \u201cbabel src -d lib\u201d to compile your Javascript. So you can code with your favorite ES6 or ES7 features.\n\nDuring the build, only the DevDependencies are installed, so be careful to put all dependencies needed by the build on the dev dependencies on your package.json.\n\nA lib directory must be present (by default it\u2019s created with the build task).\n\nThe entrypoint of your code in production must be in the lib/bot.js file. This file must contain an export of a bot function named bot. The function takes the first argument the body of the request (Bot Connector, custom curl,\u2026).\n\nYou can change all other file names, directory structures, but be sure that these three points work fine!\n\nTo be able to provide the best experience, we\u2019ve set some default limits to your instances:\n\nDescription Limit Increase possible? Code size (code + vendors) 200Mo No Maximum execution duration per request 30seconds Yes Concurrent requests 150 Yes\n\nIf you reach those limits, contact us and we\u2019ll raise them for you if it is possible.\n\nNow you\u2019ve seen the requirements of Bot Hosting, let\u2019s start with something simple. We\u2019ll create a bot getting Chuck Norris facts using the https://api.chucknorris.io/ API on Facebook Messenger.\n\nHere\u2019s how you\u2019re going to do it:\n\n1- Create the bot on Recast.AI and train it\n\n2- Connect it to Facebook Messenger using Bot Connector\n\n4- Create our code and integrate the API\n\nFirst, we need a bot on Recast.AI, so let\u2019s connect to the platform and create a new bot:\n\nYou can see that your new bot contains greetings and goodbyes default intents.\n\nFill it with expressions you want your bot to understand. Create a \u201ccategory\u201d entity and tag your sentences containing categories to give results using categories of the API\n\nThat\u2019s enough training for the purpose of this tutorial. Let\u2019s now connect it to a channel! Go to the \u201cRun tab\u201d, select your channel (here we\u2019re using Messenger), and follow the instructions. If you\u2019ve configured replies in the \u201cBuild\u201d tab, you can start talking to your bot right away.\n\nBut since we want to integrate an API to enrich the conversation, we need to add some code! First, create a new repository on Github.\n\nNow, locally, initialize your repository with a package.json:\n\n- bot.js: the file containing your bot logic\n\nthen, run npm install to install the node modules.\n\nNow, let add code to the server.js file:\n\nThis code requires the bot function in the bot file, and setups a simple express server which transfer any new request to the bot function.\n\nWe also need to fill the config.js file:\n\n- body, the body of the request\n\n- response, the response object from the server in case of a local run\n\n- callback, the object called in case of a bot hosting run\n\nat the top of your file to keep the response object globally.\n\nThe first line of the bot function assigns the response object to the global variable.\n\nIf the body contains a message object, that means the request is coming from bot connector, so we use Bot Connector SDK and pass the replyMessage as callback function.\n\nElse if it contains a text key, we consider this is a simple Curl of API call so we handle it directly through the replyMessage function.\n\nNow let\u2019s go with the function replyMessage:\n\nFirst, this function initialises the Recast.AI Request SDK and sets the content.\n\nThen, we use analyseText to analyse the sentence sent by the user.\n\nOnce we\u2019ve got the response, if there is an entity category, we request the ChuckNorris API with the category if it\u2019s an existing category and send the returned joke to the user. Otherwise we reply to the user that the category doesn\u2019t exist.\n\nIf there is no category, we simply request the ChuckNorris API for a random joke and send it to the user.\n\nEasy! You can try it locally with\n\nCool, but better if it\u2019s online!\n\nSo go back to the Run tab, then go to the Bot Hosting sub-tab.\n\nConnect your account to Github and link your repository:\n\nClick on \u201cConnect your repo\u201d to start deploying your repository! In 1 or 2 minutes, it\u2019ll be deployed and connected to your channels! Try it out on Facebook :)\n\nThat\u2019s it, congratulations you\u2019ve made it! Actually, it\u2019s rather simple, but there are some requirements and limitations to understand. Now you should be ready to code Jarvis on your own! :)\n\nOf course, you can find the complete code on Github and the train of the bot on Recast.AI.\n\nIf you have any feedback, question or suggestion for the next features, drop me an email at julien@recast.ai or chat on our Slack Community (https://slack.recast.ai \u2014 Julien)."
    },
    {
        "url": "https://chatbotsmagazine.com/facebook-f8-what-you-should-understand-about-the-future-of-messenger-428d2ff75879?source=user_profile---------45----------------",
        "title": "Facebook F8: what you should understand about the future of Messenger",
        "text": "It\u2019s F8 right now! We have two very special agents covering the event especially for you. Let\u2019s focus on how Facebook plans to develop Messenger, currently the most used bot channel, in the upcoming years.\n\nIf there\u2019s one thing that we really love from this year\u2019s F8, it\u2019s this sentence:\n\nThat\u2019s something we\u2019re very eager to see. Go Facebook! But Mark and his teams didn\u2019t mainly talk about digital furnitures.\n\nWe all noticed a camera that popped in our Messenger app a few weeks ago. Well, Mark Zuckerberg explained that Facebook is making camera the first mainstream AR platform. Why a simple camera? He explains that they\u2019re currently the best thing we\u2019ve got around and the next generation of AR/VR devices isn\u2019t quite ready yet for mainstream use.\n\nSimultaneous localization and mapping (SLAM) is used to localize objects in an image or computer vision and to understand what an image is composed of. SLAM gives us the opportunity to add custom augmented masks and stickers to our sharable moments, making them even more personalised than before. But that\u2019s not all. Facebook foresees many new uses for AR: unseen forms of art, tips, and recommendation sharing in public in (very real) places, and much more.\n\nA whole new world is upon us! By adding an in-app camera, Messenger is on its way to become the ultimate messaging platform, and maybe even the new mobile operating system altogether.\n\nAR isn\u2019t the only thing that will come and revolutionize Messenger.\n\nLast year at F8, we were all excited when Facebook opened Messenger to bots. Since then, more than 100,000 bots have been developed, according to Messenger\u2019s CEO, David Marcus. Recast.AI is proud to be one of the actors of this revolution!\n\nAs said above, people are today very fond of instant messaging. That\u2019s why companies are starting to migrate their customer support right into Messenger. Setting up a bot is crucial to save precious time for their team and to bring the right information to their customers as fast as possible.\n\nBut hey, it\u2019s also a brand new way to create a new acquisition channel! For example, Zuckerberg explained that Meetic\u2019s dating bot converts 100% more than other channels.\n\nIt\u2019s clear that bots are here to stay and that Messenger wants to be the reference platform to interact with your friends, family and favorite brands. Therefore, F8 2017\u2019s big bot announcement is the creation of a discovery tab inside Messenger.\n\nThe discovery tab allows users to easily find bots and businesses. Searching among thousands of bots made by developer, much like similar app stores, is now done right into Messenger. Exciting!\n\nFacebook then presented its new feature: chat extensions. They integrate popular services into Messenger with additional features such as payment or easy sharing. These chat extensions will be built by developers and become part of the app ecosystem around Messenger. Facebook\u2019s ambition is clear: to become the hub for interactions between companies and customers, much like WeChat in Asia. F8 2017 also focused on the development of games right into the messaging app.\n\nLast but not least, Parametric Messenger Codes let a bot dynamically generate multiple Messenger codes that provide different functionality when they are scanned. Users can also now scan codes by holding down on the main camera interface in Messenger. This is probably a new step to go further on payment directly into Messenger.\n\nFor more details about the different new features, you can read a recap by Chris Messina on Product Hunt.\n\nBut in a nutshell, Messenger is slowly becoming the all-inclusive platform we\u2019ve been waiting for."
    },
    {
        "url": "https://chatbotsmagazine.com/recast-ai-is-releasing-a-new-version-of-their-platform-integrating-a-builder-connector-host-and-d5aa5a56bd6c?source=user_profile---------46----------------",
        "title": "Recast.AI is releasing a new version of their platform integrating a Builder, Connector, Host and\u2026",
        "text": "The Recast.AI team is proud to present the newest version of their bot building platform that now integrates all tools necessary to build an efficient bot.\n\nIf we started as a startup developing its own natural language processing API, Recast.AI grew into a bot building platform, but wanted to go further. We wanted to be the collaborative bot platform where you find everything you need to build your bot : our efficient artificial intelligence technology, all bot tools seamlessly integrated, a community to share and construct with, packaged in a cool and easy interface.\n\nSo that\u2019s what we did!\n\nIn this newest version, we\u2019ve integrated new tools to make your experience seamless and provide you all keys to build a bot from A to Z ! That includes a Bot Connector, a Bot Hosting, a Bot Analytics, a stronger artificial intelligence technology, a reworked training module and an improved interface :)\n\nNow, by using Recast.AI, you can build, connect, host and launch bots powered by a strong language technology smoothly. Pretty cool, no?\n\nTeach your bot everything it needs to understand.\n\nConstruct your conversational flow with our Bot Builder or in your code.\n\nEasily connect your bot to Slack, Messenger, Kik, Callr, Telegram and more.\n\nUnderstand how people are using your bot and perfect it.\n\nYou\u2019ll soon discover our new approach to intent classification (currently in beta) that leads to a 30% accuracy improvement! It\u2019ll will be rolled out in a few days platform-wide.\n\nWe\u2019ve reworked our golden entities to improve their detection, with a focus on locations, datetimes and numbers.\n\nHola \u00bfcu\u00e1l es el tiempo en Londres? In the upcoming weeks, you\u2019ll be able to create bots in Spanish!\n\nYou can now see which entities are detected, search content or disable some of your intents.\n\nYou can analyse your text and chat with your bot in the same console!\n\nWe\u2019re smoothened the collaboration process to make your work as a team more efficient.\n\nDiscover a new section with a variety of tutorials, information and guides to accompany you on your bot building journey.\n\nWe\u2019ve build this with our growing community, and are very eager to hear your feedback and suggestions! Start building and send us an email at hello@recast.ai to collaborate!"
    },
    {
        "url": "https://chatbotsmagazine.com/here-are-the-eight-steps-youll-go-through-building-a-bot-6982433c31b3?source=user_profile---------47----------------",
        "title": "The Eight Steps You Go Through When Building A Bot \u2013",
        "text": "Building bots is no picnic, but it can become relatively easy when you know what to do. After more than a year of conversational bot building, we\u2019ve put our finger on the steps you should go through to create an efficient bot. Here it goes.\n\nA good bot isn\u2019t rushed. It\u2019s meticulously thought out. Ask question like: What\u2019s your target? What\u2019s your use case? What is the one thing you want your bot to do really well? What are things it should understand, even to give a standard answer?\n\nWhen you\u2019ve decided on your bot\u2019s purpose, you need to define who it is. Will you introduce it as a robot? As a person? Will it speak in a chilled out, familiar manner or more formally?\n\nThese are things you should precisely define before diving into the bot building process.\n\nA good bot knows what to say! That means it has a well constructed, conversational flow to support as many user queries as possible. Building a food delivery bot? The core of the conversation should be focused on getting food to people, but we\u2019ve noticed that people tend to go off rail, so always include the possibility for small talk. Your bot will only sound smarter.\n\nHere are non-bot tools to help build a big, fat chart:\n\nBot-specific tools to help you build or prototype your conversational flow:\n\nBots will keep evolving from single interaction interfaces and grow to all-understanding machines. You can already create that today with natural language processing! Today, the industry uses this area of artificial intelligence to create bots with a specific method: intents and entities.\n\nIntents are \u201cboxes\u201d of sentences that have the same meaning. If you want your bot to give you the weather, create a intent called \u201cweather\u201d and fill it with sentences such as \u201cIs it raining tomorrow?\u201d \u201cShould I take an umbrella?\u201d or \u201cWhat\u2019s the weather in Paris tomorrow?\u201d\n\nEntities are keywords detected in sentences that contain core information. Paris, in the above example, is an entity.\n\nYou can use different platforms (with their own custom technologies) to manage your language processing:\n\nWhen building a bot, coding is essential. Platforms are here to give you the right tools to make your bot development easier because it is still necessary. If you want to connect your bot to external databases or APIs or to create an extensive flow including use case specific problematics, you need to dive into your code. Luckily, the only thing you need to know is one programming language and how to handle API calls!\n\nNow that your bot is built, you can start the most exciting step: connecting it to your desired channels! An increasing number of platforms support bots: Messenger, Kik, Slack, Telegram, WeChat, as well as emails or text messages.\n\nYou can use connecting tools integrated into platforms such as:\n\nYour bot is now quite complete and can be tested by other people! That\u2019s an essential part of bot building that shouldn\u2019t be overlooked. By showing your bot to friends, family or colleagues and asking them for 10 mins of testing, you will get incredible insights on how people understand your onboarding, what they are naturally asking the bot, what kind of sentences they use, and how the user experience fits. With this data, you can easily train your bot.\n\nMost bot platforms include a Bot Training module, so keep working with the one you\u2019ve chosen for your language setup.\n\nNow that everything is ready, it\u2019s time to launch your bot on the worldwide web! Hosting can be expensive and complex to set up, but don\u2019t let that stop you because there are solutions. Here\u2019s what we learned:\n\nYou can either use your own solutions (Heroku, AWS, Azure) or take advantage of bot platforms who offer bot hosting in a click, such as:\n\nDon\u2019t think you\u2019re done when your bot is in production. Monitoring its usage is essential to understand how users talk to your bot and if your intents are used equally.\n\nTo get your analytics, either continue using a complete bot building platform:"
    },
    {
        "url": "https://medium.com/@RecastAI/build-your-first-bot-with-recast-ai-253c10517122?source=user_profile---------48----------------",
        "title": "Build your first bot with Recast.AI \u2013 RecastAI \u2013",
        "text": "Build your first bot with Recast.AI\n\nWhen you\u2019re a beginner bot builder, learning about natural language understanding, conversation flows and messaging platforms can feel a bit overwhelming.\n\nIn this guide, I\u2019m going to help you build your first bot on Recast.AI.\n\nBy the end of this tutorial, you will have a functional chatbot, and you will know how to:\n\nWith Recast.AI, you can easily design complex conversational flows fueled by a powerful artificial intelligence.\n\nYou\u2019ll need an account to follow this tutorial, click here if you don\u2019t already have one:\n\nYou are now ready to build your bot!\n\nThere are 5 phases in your bot life, represented on our platform through the use of 5 tabs:\n\nFor today we\u2019ll skip the \u201cCode\u201d part, because we won\u2019t need any external information.If you want to connect your bot with some code, I encourage you to check out this tutorial.\n\nThis is the brain of your bot, where all its understanding is gathered, divided into intents.\n\nAn intent is a \u201cbox\u201d of sentences that all carry the same meaning, even though they can be very different to one another. When a user sends some text to your bot, our algorithm compares it to the phrases in your intents. Then it checks if it\u2019s close enough to one of them and decides what the intention of the message is.\n\nare all different, but they all ask the same question that we can can sum up as: Are you a bot? Well, that would make a great intent! If your bot is able to recognize this question, you can prepare a smart reaction, like \u201cI\u2019m a robot and I\u2019m proud of it \u201c.\n\nAll bots should understand basic things such as \u2018greetings\u2019, \u2018agree\u2019, \u2018disagree\u2019, or when a user asks for help.\n\nIf you chose the pre-defined Skill \u201cGreetings\u201d when you setup your bot, you will already have two intents: goodbye and greetings.\n\nAs Recast.AI is collaborative, you do not have to recreate each intent every time! You can \u2018fork\u2019 an intent someone already created to clone it right into your bot. Since we need to understand that our user wants to be told a joke, let\u2019s find if the community has already created this intent for us.\n\nYou can click on the intention names if you want to check their full content.The first result will work just fine for me.\n\nIf you want a custom intent, you can build it from scratch. Here, we want the bot to understand when someone laughs at the joke.\n\nClick on + CREATE on the right of the search field, and choose a name for your intent:\n\nRepeat this process for intent that gathers negative reactions to your jokes:"
    },
    {
        "url": "https://medium.com/@RecastAI/nodejs-chatbot-tutorial-a-github-bot-with-recast-ai-f2df6a70735d?source=user_profile---------49----------------",
        "title": "NodeJS chatbot tutorial: A Github bot with Recast.AI",
        "text": "By the end of this tutorial, you will be able to build a fully functional Github bot! We\u2019re using the Recast.AI platform to build the bot and the Github API to let the bot dive into code repositories.\n\nHere\u2019s a conversation example your bot will be able to have when we\u2019re done:\n\nThere are 4 phases in the bot creation process, represented on our platform by 4 tabs:\n\nTo create a new bot, login and click on in the header section.\n\nAfter that, you are redirected to the main page. This is the heart of your bot, where all its comprehensive abilities are gathered, decomposed into intents.\n\n Intents are \u201cboxes\u201d of sentences (that we often call \u201cexpressions\u201d) that all mean the same thing but are phrased differently. Each intent matches one action your user potentially wants to perform.\n\nFor instance, an intent \u2018greetings\u2019 makes your bot understand when a user says \u2018Hello\u2019 or \u2018Hi\u2019.\n\nExplore each intent by clicking on their names.\n\nClick on the BUILD tab to find Bot Builder! Bot Builder is a tool to help you create your conversation flow.\n\n Now, you have two blocks, \u201cgreetings, and \u201cgoodbyes\u201d. We call them actions. An action is a step in your conversation. It is triggered by a user input and completed by a bot response. An action is always paired with an intent.\n\nHover over the greetings action and click on the pen to edit it. You will see the process of what\u2019s happening when a user says \u201chello\u201d. If you click on the button , you can see what the bot will reply when this action is done.\n\nClick on the bubble icon on the top right to make it appear. Type a sentence to test your bot training: \u201cHello\u201d.\n\nHow does that work? Well, with our Bot Connector, you can connect your bot to multiple channels. Bot Connector takes care of receiving all messages and transfers it to your bot in a uniform format.\n\nGo to the Run tab and toggle the channel you want to connect your bot to. You need to have an account on the messaging platforms and setup tokens. Follow the instruction to configure your channel.\n\nAfter completion of all steps, go to the relevant messaging app and surprise surprise, your bot is live!\n\n Now, let\u2019s focus on adding the main part of the bot: the github repository battle.\n\nThere are certain intents all bots should have in order to understand basic things such as \u2018greetings\u2019, \u2018agree\u2019, \u2018disagree\u2019, and when a user asks for help.\n\n Our platform being collaborative, you do not have to recreate each individual intent every single time! You can \u2018fork\u2019 an intent someone already created to clone it right into your bot.\n\nTo add an existing intent called \u201cHelp\u201d\n\n Write \u2018help\u2019 in the input Search and Fork from the community\n\nClick on search. Select one of the first results and just click on the button on the right.\n\nRepeat this process for \u2018agree\u2019 and \u2018disagree\u2019\n\nIf you want a custom intent, you can build it from scratch.\n\n Here, we want the bot to understand when someone asks for a battle of repos. Let\u2019s create these intents.\n\nWrite \u2018battle\u2019 in the input Search and Fork from the community\n\nNow that intents are created, we have to enter various expressions.\n\n The optimal amount of paraphrased expressions for an intent lies at around 20.\n\n Click on one intent, and add expressions you want your bot to understand. Put yourself in the shoes of the people talking to your bot. What could they possibly ask? Enter a new expression by typing in the field Add an expression.\n\nFor some expressions, you\u2019re going to need to extract some key data to use later. That\u2019s what entities are for. Entities are keywords detected in expressions. You can see them by clicking on an expression.\n\n31 entities are automatically detected (like dates, temperatures, emojis or locations) and are called gold entities.\n\n Here we need to detect repositories, so let\u2019s create a custom entity called \u201crepository\u201d. Tag all the repositories in your expressions to train your bot to understand what a repo is.\n\nAdd additional expressions and check if the entity \u201crepository\u201d is automatically tagged. If not, keep tagging, you need more examples of different expressions and repository (with caps, without, long words, small..).\n\nNow that we\u2019ve filled the mind of your bot with tons of phrases and expressions, let\u2019s test it with the console:\n\n open it (TEST tab on the right) and go into the tab (not converse). Type a sentence like \u201cIonic vs Boostrap\u201d:\n\n If your training has been effective, you can see the intent matched with your sentence and the extracted entities. If the repositories are not extracted, you need to add more sentences in your intent!\n\nClick on the \u201cSmart view\u201d toggle to switch the view to the JSON mode.\n\n The JSON contains a lot of useful information about the message you\u2019ve sent, because of the enrichments we provide for gold entities.\n\nNow that the brain of your bot is all filled up, click on the \u2018build\u2019 tab, launch the builder, and discover the magic!\n\nThe section on the left is your command panel. It allows you to create actions and link them to each other to create a flow.\n\n To create an action, click on the button and select an intent (\u201cbattle\u201d for example). Place it and create all the other actions.\n\nThere are two types of links:\n\nGreen links create an action flow where the user is guided in one direction, but remains free to start at any other step of the conversation.\n\n Red links create an action flow where the user has to follow a defined path.\n\nClick on the right end of the action you want to link.\n\n Click now on the left end of the other action you want to connect it to.\n\n Change the color of your link by clicking on it then on the right color in the toolbar.\n\nAfter the \u2018battle intent\u2019, we only have red links. Why? Because when the bot asks the user if he wants more information, the following step can only occur if we\u2019ve established a battle winner.\n\nNow that we\u2019ve set the flow, some of our actions certain pieces of information (entities) to be complete: we call them notions.\n\nClick on the small pen that appears on the \u201cbattle\u201d action.\n\nClick on the Button\n\n Search the \u2018repository\u2019 custom entity we've created earlier and set the alias as \u2018repo-1\u2019\n\nThen click on the back button on the bottom, and you will have your repo-1 notion added in your overview.\n\nYou now have your repository notion added in your overview.\n\nCreate a second notion for the second repository and name it \u2018repo-2\u2019. Now you have this overview:\n\nThere are 3 different replies you can set:\n\nYou can also add variables by using the alias of your notion like this:\n\nOpen the goodbye action and check the \u201cThis is the end of my conversation\u201d.\n\n This will delete the state and the memory of your conversation to let you restart ;)\n\nNow that the flow is complete and the replies set, we can finally test the bot!\n\n Use the console as you did earlier in the project.\n\n Say Hello and the bot will start the flow!\n\nTest your bot in the channel you\u2019ve configured before (Messenger, Kik, Slack, etc):\n\nNow, let\u2019s add the Github API to retrieve information about the two repositories. Let\u2019s start coding!\n\nGo to the tab and click on the \u201cCode\u201d menu.\n\n Follow the instructions to install the starter kit. Once your ngrok and server are running, and that your webhook url is the ngrok url, test yet again your bot on the channels you have connected to it. It still works ;)\n\nSo, what\u2019s happening here? Each message your user types is sent to your bot webhook. Here, the url is the ngrok url and it\u2019s your local server that receives the message.\n\n The file contains the server configuration and you can see that for each request received on we call\n\nIn the file, we use the Recast.AI SDK to handle the message and get the data we need from the request:\n\nThen the main function is in :\n\nEach text inside the message received is sent to Recast.AI API where it\u2019s analysed to determine where the user is in the conversation. This API call is done here:\n\nThe result of this request contains the replies you set in the Bot Builder tool, along with other necessary flow information.\n\nTo understand this data, go back to the platform and type \u201cHello\u201d in the test console.\n\n Switch to the JSON view. You can see that you have the action triggered by the sentence, \u201cgreetings\u201d, and the next action. You also see a memory object with our two notions: \u2018repo-1\u2019 and \u2018repo-2\u2019. Memory is empty for now, but if you say \u201cReact\u201d, the memory will fill up ;)\n\nand in the , import the file\n\nAdd these lines inside the then callback of the\n\nYour file will look like this:\n\nTest it to see the message appear at the right time in the conversation. Then get your Github credentials to continue.\n\nLog in on Github and go to your settings:\n\n Click on and copy this token in your :\n\nThen stop your server, and install a module to make a promise request:\n\nThen go to your file and import the request module and the config file:\n\nCreate a Github call function to get information about a repo. To do that, we\u2019ll be using the search method of the Github API since we\u2019re not sure if the user can correctly spell the repo name ;)\n\nand a function to print the winner:\n\nNow change your battle function to call the githubCall twice, with each repo, and then call the winner function to print a beautiful message ;)\n\nAt the end, your will be like this:\n\nNow, test it in your channel: you get the complete response!\n\nNow, at the end of the battle, the bot will ask if the user wants additional information.\n\n Let\u2019s add a line in the :\n\nNow we need to respond with the data we have about the winner, but save it somewhere. What we can do is save in the Bot Builder memory information about the winner! Therefore, when the action \u201cagree\u201d is triggered, you can get this information and print it ;)\n\nGo back to the interface, and add a memory notion \u201cwinner\u201d in the \u201dagree action\u201d:\n\nThen in your code, set the value of this notion when we detect who the winner is, in the getWinner function in the :\n\nAdd a result in first parameter (The Recast.AI conversation result), and call the function of the SDK (see the doc here).\n\nThen, pass the result to this function, add this parameter in the battle function:\n\nAnd change the code in to add the result parameter to the battle function. Also, add the detection of \u201cagree\u201d action to reply with information about the winner.\n\nOne last thing to make a cooler message when you give additional info is making a card with a button ;)\n\n You can send a lot of different messages, see the documentation here:\n\nChange the scope of the \u201cif action is agree\u201d:\n\nNow your file should look like this:\n\nCreate a git repository in your Github account and fill the form.\n\nIf you cloned the starter kit, change the remote url with your github url.\n\nIf you downloaded the repo:\n\nNow, go to your bot page, in the RUN tab and click on the \u201cBot Hosting\u201d menu.\n\nConnect your Github account, and accept the permission to create a hook on your repository to deploy your code.\n\n Then select your repository in the list, and click on .\n\nWait until the loader is \u201cRUNNING\u201d, and change the current webhook url of your bot:\n\n Copy the Recast.AI bot instance url in the Current webhook, so your bot is no longer running on your computer but on a server. You can chat with it when you want ;)\n\nIf you want to develop your bot in local, simply re-change the bot webhook with your ngrok url to use your laptop version.\n\n Every time you push on master, your code is deployed and your bot updated!"
    },
    {
        "url": "https://medium.com/@RecastAI/10-twitter-bots-you-should-definitely-follow-in-2017-278667daa703?source=user_profile---------50----------------",
        "title": "10 Twitter Bots You Should Definitely Follow in 2017",
        "text": "Twitter is well known to be gathering millions of fake accounts. In 2014, the company admitted that as many as 23 million of its active users were automated. As top twitter bots reach impressive volumes, it\u2019s safe to say that Twitter is one of the most popular platform for bots developers. A \u201ctwitterbot\u201d is a bot program used to produce automated tweets, replies or retweets. In total, twitterbots are estimated to create approximately 24% of tweets that are on Twitter. From \u201cbimbots\u201d (attractive lady bots) to complex AI-based bots, Twitter hosts a large diversity of bots and that\u2019s why it\u2019s interesting and a lot of fun!\n\nEven if a majority of these twitterbots are seen as spammy and annoying, some creative developers found interesting use cases for this particular social network. In 2017, new bots are getting noticed and we couldn\u2019t help but share it with you!\n\n@DearAssistant is a Twitter bot that will try to answer your questions just like Siri, Google Now or Cortana. It was built by Amit Agarwal, a computer science engineer who already developed several twitterbots.\n\n@WhatTheFare is an \u201cUber bot\u201d, also built by Amit Agarwal. You just have to tweet your pick-up and drop-off points and it will estimate your Uber fare!\n\n@dscovr_epic is the perfect Twitter bot to follow if you are passionate about space. Every day, it shares a picture of mother earth from the NASA\u2019s DSCOVR spacecraft.\n\n@pentametron is a twitterbot looking for some poetry substance in our tweets. This bot uses the Iambic pentameter metric line to find relevant tweets, and then re-tweets them one after the another to create an everlasting poem. If you like poetry, it\u2019s a no-brainer!\n\n@_grammar_ is a pretty impressive and useful bot. It automatically detects tweets that have improper usage of English grammar and then posts solutions.\n\nIn 2017, more and more people are using Netflix on a regular basis and there are many releases every week. @netflix_bot tweets new releases on Netflix Instant in order to help you stay updated.\n\n@MuseumBot is not a new bot but you should definitely follow it in 2017 if you like art. It tweets a random high-res Open Access image from the Metropolitan Museum of Art, four times a day.\n\nBecause we also like funny bots at Recast.AI, we had to share with you the @choochoobot : a bot which auto-generates emoji \u2014 tweets.\n\nBecause size matters after all, @relativebot compares every day the sizes of random things! If you are a developer, you can check their GitHub repository and fork it.\n\nAlways wondering how much time you have before the end of the year? @year_progress tweets every day a progress bar for the completion of the current year."
    },
    {
        "url": "https://medium.com/@RecastAI/git-merge-2017-what-you-missed-2d0a24a4fa97?source=user_profile---------51----------------",
        "title": "Git Merge 2017 \u2014 what you missed \u2013 RecastAI \u2013",
        "text": "Git Merge is a Git-focused conference \u201cdedicated to amplifying new voices from the Git community and to showcasing thought-provoking projects from contributors, maintainers, and community managers\u201d, as Github explains. Each year, a different city hosts the conference, and in 2017, 250 participants met in Brussel.\n\nListening conference after conference, you feel as part of one of the largest communities of developers in the world. Think about it. Developers around me use Git every day, at so many different levels. Some of us are experts, some only use a few commands, others are contributors or maintainers. But all in all, we\u2019re all users, and this conference showed me the importance and size of the Git community. And that\u2019s important, because let\u2019s be honest, our developer experience, and our lives, would really suck without it.\n\nThe event was well organized (thanks Github!), the location, place, atmosphere, goodies, beers and after party made up for a great time. But what made this event golden for me was the proximity and accessibility of all speakers and major players in the Git community.\n\nThe moment I remember as a great example of complicity is when Sid Sijbrandij (co-founder of Gitlab) joined Tim Pettersen (Bitbucket Developer) on stage, after the mediator cracked that Gitlab database incident joke. I just felt \u201coh, i\u2019m sure they meet every month to drink beer and talk about Git\u201d. Even though they represent competitor companies, they are part of the same community and need to work together, be aware of the problematics of the tool we use every day.\n\nAfter everything I learned, the only thing I wanted to do was commit and pimp my developer environment.\n\nAs many speakers talk about the complexity of Git, here are my key takeaways.\n\nSo, everybody knows that Git is complex :\n\nEveryone can remember how to use commands to commit their work, but what\u2019s difficult is understanding the concept, the logical core of the tool. Yes, Git is easy to learn, but it\u2019s more than a software. It\u2019s a primitive, a concept and the second step of understanding is really more complex. Screwing up is easy, and figuring out how to fix your mistakes is crazy impossible.\n\nBut since it\u2019s a concept, a way of thinking, you can use it outside the IT field, as Caren Garcia mentioned in her talk GIT: The tool loved and (sometimes) feared. Writers, governments, simultaneous translation, schools can successfully implement it.\n\nTo improve the developer experience, layers are developed above Git. Three speakers talked about erasing the complexity:\n\nWhat\u2019s wrong with Git? by Santiago Perez de Rosso showed the complexity of understanding concepts like stash, detached heads, and untracked files. In his experiment of improving Git usage, he presented Gitless, a version control system built on top of Git.\n\nGit aliases of the gods! by Tim Pettersen, a really sharp and funny talk about Git aliases. He used a great example with git stash command, and created a funny one called standup :\n\nScaling mercurial at Facebook: insights from the other side by Durham Goode presented the Facebook development environment composed of monorepos, no feature branches, rebases and no merges, single commits per push\u2026 They assume that all developers work online, that \u201ceveryone commits on master\u201d, and that \u201cevery commit is pushed\u201d. They therefore implemented some top level features: pushRebase, allowing the server to process a rebase of your work, and smartLog, to see only useful commits.\n\nLots of issues come from performance on crazy repos, and big companies like Microsoft and Github have to deal with this kind of problematics.\n\nTop ten worst repositories to host on Github, by Carlos Martin Nieto, explained the challenges of hosting crazy repositories at Github. What makes your repo the worst? A huge amount of files, forks, tags, contributors, or a push infinite. Here are some of the worst Carlos showcased:\n\nScaling Git at Microsoft by Saeed Noursalehi presented the GVFS (Git Virtual File System), an open-source project just released by Microsoft to solve their tough experience on the Windows repo! Before the GVFS, it took 12 hours to clone the repo\u2026\n\nGit Merge was followed by FOSDEM, two days of free conferences for software developers to meet, share ideas and collaborate. Perfect timing! All in all, this weekend reinforced and revived my motivation of being a part of this large community taking care of the future.\n\nThe last thing I want to share is the introduction talk by Karen Sandler from Software Freedom Conservancy. She has a pacemaker and was worried about what software it runs on. She asked to see the source code, but the company wouldn\u2019t let her, as the software is proprietary. So people, remember :\n\nThink about it, and let\u2019s meet next year at Git Merge"
    },
    {
        "url": "https://medium.com/chat-bots-developers/introduction-to-text-clustering-50d3718ddb01?source=user_profile---------52----------------",
        "title": "Introduction to text clustering \u2013 Chatbots Developers \u2013",
        "text": "In this article I\u2019m going to describe a pipeline for Text Clustering. I could not find any satisfactory explanation, so I decided to share my findings after a few weeks of research about this task.\n\nIn a previous article, I wrote about the value of datasets, and particular annotated (gold) datasets. But another type of data is contained in the whole internet, which is unlabelled and in overwhelming volumes.\n\nSo, the idea of learning from all this raw data is quite interesting, and lots of research has been done using two methods: semi-supervised \u2014 labelled and unlabelled data are both used, and unsupervised \u2014 labelled or unlabelled data can be both used.\n\nThe first intuition when looking at raw data is to try to find patterns. Clustering similar information together makes it easier to understand what\u2019s going on inside the data.\n\nClustering is the task of organizing unlabelled objects in a way that objects in the same group are similar to each other and dissimilar to those in other groups. In other words, clustering is like unsupervised classification where the algorithm models the similarities instead of the boundaries.\n\nIt has been widely used for various tasks, including: opinion mining on social media to detect a tendency in posts, image segmentation where the goal is to detect the boundaries of any object, customer profiling based on product purchases, and document clustering based on phrases or words. But you can also use it to label data in place of a person, allowing the human to go from a supervising role to a validating role.\n\nI\u2019m going to cover the whole process of text clustering, from actual clustering to data visualization, through data preprocessing. In the end, you should be able to build a solid pipeline, using state-of-the-art techniques to further improve your datasets\u2019 usage!\n\nTo start off, we need to meet three requirements. First of all, we need a distance measure to define whether or not two documents are similar, a criterion function to compute the quality of our clusters and finally an algorithm to optimize this criterion.\n\nA distance measure can help us define the proximity of two points in our dataset. It should be large if documents 1 and 2 are similar and small if they differ.\n\n The criterion function will inform us when we find the best clusters, and stop the pipeline. As an example, an approach would be to try to maximize the similarity between each document and the center of the cluster the document has been assigned to. Another approach could be to try to maximize the difference between each cluster of document, instead of their internal similarities.\n\nFinally, we need an algorithm to optimize this criterion function. This algorithm can have several stages. A common way is to use a greedy approach consisting of two steps: initial clustering, and refinement.\n\nThe initial phase will select random documents of our corpus and assign them to clusters. Then the refinement phase will iterate over random documents, and compute the criterion function when this document is moved to another cluster. If the score is improved we continue to iterate, if not that means we found the best clusters on the given data.\n\nThose three requirements are the baseline of a clustering task, and the criterion function depends on the approach you selected for your clustering experiment. From now on, clustering methods will only be branching out, and covering each algorithm would be too tedious. Instead, we are going to look at three algorithms distributed over three major approaches: partitional, hierarchical and density-based.\n\nClusters obtained with K-means on a toy dataset, courtesy of Leland McInnes, John Healy, Steve Astels\n\nK-means is THE go-to clustering algorithm. Fast, available and easy to wrap your head around, it requires you to know the number of clusters your expect. One downside is that K-means tends to assume that your clusters will be simple, due to it\u2019s partitional approach: it tries to decompose the dataset into non-overlapping subsets. Expect quick results, but with noise.\n\nClusters obtained with Agglomerative Clustering on a toy dataset, courtesy of Leland McInnes, John Healy, Steve Astels\n\nOn the other hand, hierarchical clustering tends to model the dataset into clusters organized as a tree, where you can go up from one document to the whole corpus. This can be done from top to bottom (divisive) or bottom to top (agglomerative). Agglomerative clustering is an approach that yields a dendrogram (a tree diagram) of your dataset, for you to cut at the desired threshold. This leaves you with the freedom to view the assumed clusters before selecting them, but they will still be noisy.\n\nClusters obtained with DBSCAN on a toy dataset, courtesy of Leland McInnes, John Healy, Steve Astels\n\nFinally, density-based clustering will create clusters on the denser regions of your dataset. DBSCAN (and its improvement HDBSCAN) combines the best of agglomerative clustering with the capacity of removing noisy documents. The only parameter you have to select is the minimal distance to consider two documents as similar, and DBSCAN will do the rest.\n\nIf you want a more complete comparison of different clustering methods, you can find one here, with visuals too!\n\nHere we covered the basics of clustering and listed several algorithms that can be used to find the best groups in our corpus. But for the algorithms to work, it is important to feed it the data under the right light. In the next part, we\u2019re going to talk about preprocessing techniques, which will help reduce noise, and facilitate data visualisation.\n\nAs always with text, documents can be noisy, hiding information between stopwords, inflexions and sparse representations. The step of preprocessing is crucial to obtain a dataset easier to work with.\n\nTraditional approaches to text clustering tends to tokenize the documents into its component words using available tools (TreeTagger for example). This leaves us with a lower grain to work with, words instead of whole sentences. Some of those might be pluralized, conjugated or inflected. To cope with that, lemmatization and stemming can be used: the first will yield an uninflected form, keeping the sense, where the other will truncate the word, resulting in a simpler token, but sometimes meaningless. On top of that, you can remove the stopwords, to further simplify the semantics of the document and thus improve the clustering.\n\nOne last thing that can be done is to make some words stand out in our corpus. Once stopwords are removed, the semantic of a sentence depends on the theme (nouns and adjectives) and the action (verbs, auxiliaries and adverbs). Those can be enhanced by adding synonyms, hyponyms and hypernyms, whether with rules or using pre-trained word embeddings. This enrichment step can yield better results, or worsen the noise in your data.. There\u2019s no true or false here, you\u2019ll have to try!\n\nOnce the corpus is pre-processed, we need to transform our data into something the algorithm can work with: vectors. Most of the time, TF-IDF is the preferred solution, but due to their sparsity, those vectors can be neglected to leave room for more denser representations. Paragraph vectors appeared after the enthusiasm for word embeddings, and thanks to their internal composition, allow an easy computation of similarity. Doc2Vec, an implementation of this paper from Tomas Mikolov is freely available in gensim, you should give it a try!\n\nI can not end this part without talking about the curse of dimensionality. This phenomenon appears when you work with high-dimensional data, such as text where the size of the vectors is often equal to the size of the vocabulary. Put simply, the more dimensions you have, the more sparse the data will get, and computing the similarity between two points will become incrementally hard. Here\u2019s a longer explanation, explained like you\u2019re five!\n\nThe way you represent your data, and the way you present it to your algorithm can change everything, so try sparse and dense vectors on your heavy or lightly preprocessed documents.\n\nBut before jumping right into clustering, look at your data, this simple step can help you save hours of tinkering with your algorithms.\n\nYes, it\u2019s that simple! Look at the raw data you are about to process. You will probably find patterns yourself, that will help you define the number of clusters you can expect, or the amount of preprocessing your need to apply to let the clusters emerge by themselves.\n\n \n\n Keep in mind that once you\u2019ve vectorized your data, you\u2019re working with high dimensions, and it\u2019s incredibly hard to understand what\u2019s going on.\n\nA mathematician and an engineer attend a lecture by a physicist concerning theories that occur in spaces with dimensions of 9. The mathematician is sitting, clearly enjoying the lecture, while the engineer is looking puzzled. By the end the engineer has a terrible headache, and asks his friend: \u201cHow do you understand this stuff?\u201d. The mathematician answers: \u201cI just visualize the process.\u201d To that the engineer replies: \u201cHow can you POSSIBLY visualize something that occurs in 9-dimensional space?\u201d Visibly amused, the mathematician responds: \u201cEasy, first visualize it in N-dimensional space, then let N be 9.\u201d\n\nTo be able to visually analyse the data, we need to transform our N dimensional data into a 2 or 3 dimensional representation.\n\nThe goal of dimensionality reduction is to extract the principal information contained inside our data without using everything. PCA (for Principal Component Analysis) does just that.\n\nThe underlying idea behind PCA is to retain the data dimensions which contains most of the information (i.e: with the highest variance). For instance, dimensions with low variances tend to add few information value to the data and can be safely removed. Of course, most of the time, this leads to loss of information, but who cares when you can go to 300+ dimensions to only 3 while keeping more than 70 percent of the information? Well, sometimes you should care about it, but since it is an introduction, I won\u2019t hold it against you.Others approaches, which work better with high-dimensional data, tries to preserve really small distances between documents, and by bringing closer the nearest neighbors, the dissimilar documents will go away.\n\nt-SNE (for t-Distributed Stochastic Neighbor Embedding) is a technique that use this intuition to measure the similarities between close points in high-dimensional space, and then tries to lay out the points in a low-dimensional space in such a way that close points stay close. This is done by optimizing a distance measure (Kullback-Leibler divergence, for the nerds reading me) using gradient descent. t-SNE tends to yield better results than PCA for data in high dimensions, and this article explain in great details how to use it effectively. Also, here is a video from one of the two authors of t-SNE, talking about the maths behind his algorithm.\n\nOnce done, use your preferred plotting library (I personally like the availability of matplotlib, with the beauty of seaborn) or tool (Tensorflow\u2019s projector is really something to try!) and enjoy your whole dataset being displayed in front of you after a few minutes of computation!\n\nIn the end, we can define text clustering as the following pipeline: first look at your data to have an idea of what you\u2019ll be working with, then apply a preprocessing step to reduce noise, visualize your dataset to find natural patterns and/or clusters, actually cluster it, analyze the results either by a metric or by eye, and repeat!"
    },
    {
        "url": "https://medium.com/@RecastAI/10-amazing-bots-of-2016-420e609118d1?source=user_profile---------53----------------",
        "title": "10 amazing bots of 2016 \u2013 RecastAI \u2013",
        "text": "Well, 2016 was truly the year of bots! From the announcement of the opening of Google, Facebook and Microsoft\u2019s bot solutions, people went crazy over these little talkative programs. That gave birth to really cool products.\n\nYou absolutely have to remember something? Write it to wonder, and he\u2019ll remember it for you down the years.\n\nThis Star Wars bot that will take you on an adventure through space, bounty hunters, deadly creatures and possibly a few Jedi masters. Each answer matters.\n\nFriends or family up in the air? Check their flight status and current location with Instalocate.\n\nSephora brings us an effective bot to get the latest beauty tricks or to discover the best products available! It does the job well and proves to be a trusted advisor. To get it, go directly on Kik on your mobile and search for \u201cSephora\u201d.\n\nAnother RPG bot taking you in the midst of a zombie apocalypse. Based on real time, gather materials, look for food, weapons, vehicles, and try to survive!\n\nTake a picture, and WTFIT will tell you\u2026 well, what the f*** it is. Kind of awesome.\n\nGet the best of technology and startups in your Messenger inbox everyday!\n\nI call genius! Start a Connect 4 game by yourself or with a colleague directly on Slack.\n\nOld but gold, 1\u2013800 Flowers is now a well oiled machine allowing you to order and ship flower arrangements anywhere in the US.\n\nStuck in bed and need to gather all your forces to get out of bed and to the clinic? Healthtap might help you get an idea of what\u2019s wrong based on your symptoms! And the information is backed up by doctors."
    },
    {
        "url": "https://medium.com/@RecastAI/introducing-star-wars-rpg-chatbot-become-the-hero-of-your-interactive-space-adventure-b33f135818be?source=user_profile---------54----------------",
        "title": "Introducing Star Wars RPG chatbot: become the hero of your interactive space adventure!",
        "text": "As the world grows excited at the release of the newest Star Wars opus, we\u2019re very happy to introduce the first Star Wars role playing game chatbot!\n\nWhile a new Star Wars movie attracts both long-time fans and newcomers, this bot is perfect for both audiences. Either to discover a new way to interact with your favorite science-fiction world or to learn new facts, Star Wars Bot by Recast.AI takes you on a wild adventure where you, and only you, decide on the outcome.\n\nToday, Star Wars Bot speaks English and is available on Messenger 24/7 (and soon on Kik!). Powered by the Recast.AI technology, he understands, answers in natural language and the more you use it, the more it adapts to you!\n\nOh, and if you\u2019re loving it, we made a step-by-step tutorial to help you build your own. Get started!"
    },
    {
        "url": "https://medium.com/@RecastAI/build-a-star-wars-rpg-bot-with-bot-connector-by-recast-ai-b76f7d1dfa45?source=user_profile---------55----------------",
        "title": "Build a Star Wars RPG bot with Bot Connector by Recast.AI!",
        "text": "Note: This article is deprecated. Check this tutorial for the most current information.\n\nThe bot we are going to build is a role playing game (RPG) bot around the Star Wars universe. This bot will be created with Recast.AI and Bot Connector.\n\nYou will be able to use this bot on Facebook Messenger and on Kik, and you can find the finished product here!\n\nWell, it can be defined as a bot who does not just provide information, but makes you an actor in a compelling story. Each of your answers will take you on a different storyline.\n\nIf you\u2019d like to know more about where we got the idea, read this Gamesbook Wikipedia page.\n\nThis bot is developed in NodeJs, and we\u2019ll use ES5.\n\nWe\u2019re using the Recast.AI technology, Recast.AI is a collaborative platform for bot making. We provide an API that will help you understand your users, to guide the conversation.\n\nEverything we use will be explained step by step.\n\nFirst step, for any part of the tutorial, is to create your Recast.AI account!\n\nBot Connector allows you to connect your bot to multiple channels at the same time with only one API integration.\n\nLogin to Bot Connector with your Recast.AI account.\n\nLet\u2019s start by creating a new bot, pick a name you like.\n\nTo create the URL of you bot, create a webhook. That will create a tunnel from your bot to Bot Connector. We\u2019re using a ngrok webhook, but you can use any kind of webhook you like. If you don\u2019t have ngrok, check this out to get started.\n\nNice, you now have a first version of your bot! Now, let\u2019s connect it to channels.\n\n- in the orange selection, pick the channel you want\n\n- in the purple selection, configure your integration\n\nIn this tutorial, we\u2019ll cover the Messenger integration, feel free to discover Slack and Kik on your own. :)\n\nSo, you need two things: your page token and your app token.\n\nand your app token here:\n\nAfter adding your channel, the connector will send you back a url and a webhook token. Put those information in the Facebook Developer page.\n\nYou now have a bot connected to Facebook!\n\nBut we still need to code the bot :D\n\nMuch like before, we\u2019re going to start from scratch. But if you like to move faster, you can clone the code from this repo.\n\nYou will find all your bot-connector credentials on the settings tab.\n\nYou need 3 different modules for these two files:\n\n-Express will be your server,\n\n-Body-parser will parse the response from the word wide web,\n\n-Superagent will make the Post back to the server,\n\nThe following file creates a server and connects the web chat service of your choice (Kik, Slack, Messenger, \u2026.) to your bot.\n\nYou need a function to send the message back to Bot Connector. This function is really simple and will only send the message you formatted back to Bot Connector.\n\nYou should be ready to receive a message from Facebook! Let\u2019s try :)\n\nNext, we\u2019re going to see how to make your bot smarter!\n\nWe\u2019re going to create the bot from scratch, and the first step takes place on Recast.AI. If you\u2019re familiar with the platform and want to directly dive in the code, you can find the bot here and fork it. If not, let\u2019s get started!\n\nCreate your intent, An intent is a box of expressions that mean the same thing but are constructed in different ways. Intents are the heart of your bot understanding. Each one of your intents represents one thing your bot is able to understand.\n\nWe need these first three intents to initiate the conversation of the bot. In each intent, enter expressions. You should put at least 10 sentence for your bot to be able to understand, and we advise you to put around 20 sentences for a really good classification.\n\nGreetings: any possible way to say \u201chello\u201d\n\nThe next intent will be a little different: you will need to tag a entity!\n\nAn entity is a keyword extracted from an expression. We automatically detect 31 different entities such as datetimes, names, locations, etc. We call them Gold entities. But you are not limited to these Gold entities: you can also tag your own custom entities to detect keywords depending on your bot context, such as metro stations if you are building a transport assistant. To bring you a precise service with a true added value, we are enriching each of our Gold entities with core information.\n\nWhich-space-ship: simple sentences with the name of a Star Wars spaceship.\n\nAll spaceship names need to be tagged with your custom entity \u201cspaceship\u201d\n\nWhere-are-you-from: same as the previous intent, but with custom entity \u201cplanet\u201d.\n\nThese three intents are the initiation of the conversation. Now, to create a unique experience and story for the user, let\u2019s jump into Bot Builder!\n\nEach intent becomes an action. Put your three actions on the map, and connect them to each other. Use a green link between greetings and where-are-you-from and use a red link between where-are-you-from and which-space-ship. That means that while greetings is an action that can be skipped, where-are-you-from is necessary to continue to the next action.\n\nAfter adding your first 3 actions, you need to set up notions and replies in where-are-your-from and which-space-ship. Notions match entities, and are keywords your bot needs to know at this point of the conversation to move forward. Replies are specific answers your bot should give after the action is completed or when a notion is missing. In this case, set up a reply if \u201cPLANET\u201d is missing, but don\u2019t set up one when the action is done. This stands for the entire tutorial.\n\nNow that your architecture is all good on the platform, let\u2019s dive into the code.\n\nYou will need to add the Recast.AI module for your code to run.\n\nThe following file is your state machine. It decides what to answer according to the user reply and the conversation advancement.\n\nThe function handleMessage() will send the text to Recast.AI.\n\nRecast.AI will send back a JSON with key informations (intent and matching ratio, entity and matching ratio, sentiment analysis, etc). This data helps you decide what you should reply.\n\nAfter getting the response, check if the action has an answer setup on Bot Builder. If it doesn\u2019t, call a engineFunction()\n\nThis function will call a function for each state of conversion and will format the message, to send back to the user.\n\nYou file should look like this:\n\nWe are going to have a look at the the files in formatServices:\n\ninitConversation(), carouselSpaceShip() are really simple. These two functions only return a array of a preformatted message example:\n\nType is what kind of message you will send.\n\nContent is the body of your message, have a look at this doc :)\n\nThis function gets really long, so I created two gists on Github. Have a look:\n\nIn the files, you will find the response your bot sends to the user. Don\u2019t forget to put this file in your formatServices!\n\nBefore running the bot, you need to change your server.js\n\nYour new server.js will look like this:\n\nNow, you should be able to have your first conversation! :)\n\nLet\u2019s create new intents! You can fork all of them to skip this step here.\n\nName of intent Type of sentence to trigger the intent entities you need to tag space-battle\n\nThe last intent you make is not used in the classification, it\u2019s simply here to create two new files in the memory of your bot.\n\nLet\u2019s jump back in the Builder and start building the end of the flow. It\u2019s really easy, simply create a conversation flow like this one. We only focus on the orange path here, but take the time to create the rest :)\n\nAdd 4 new actions : training, riddle-response, battle-vs-monster and memory. Put the memory on top left, and connect the 3 other with a red link.\n\nAdd two notions to the action \u201cmemory\u201d:\n\nLet\u2019s go back to the bot.js file and add a few functions:\n\nMuch like before, engineFunction() checks what action is called and triggers the right function:\n\nThe function handleMessage() does not change.\n\nYour file bot.js should look like this:\n\nJust like initConversation() and carouselSpaceShip(), I created github gists, go and check them out!\n\nPay specific attention to the three new functions:\n\nLet\u2019s start by initMemory(). This function sets the memory of your bot at an init stat each time that the user says hello.\n\nEven if this function is asynchronous, we will not set a promise because we don\u2019t need this information yet.\n\nThis functions takes care of the riddle action. It detects which entities are present in the sentence and allows you to see if the user guessed right or wrong.\n\nSo here\u2019s how the fighting system works: the player has 10-HP, the opponent has 20-hp. During each attack, the player has 1 chance out of 2 to miss his shot. If his attack is successful, he does 5 to 9 damage. The opponent can not miss but can only inflict 1 to 3 damage. To make the game more interactive, we\u2019ll make a different message for each attack.\n\nFirst, find what the name of the attack is and the damage it does:\n\nThen get the memory from the Bot Builder. This is the same function than reset memory, but you need to add a promise because we need this information for the rest of this function:\n\nNow the rest of the function is only wording to send the right message to the user:\n\nthe file should look like this :\n\nRun the v2 of your bot\n\nTalk to your bot, and enjoy the magic!\n\nYour bot is running, it\u2019s now up to you to create a compelling story for your users!\n\nTo help you in your bot building quest, you\u2019ll find some other resources on our blog, such as a complete tutorial on our Bot Builder, our best practices for bot building, or this ultimate channel cheat sheet to help you pick the best one for your use case!"
    },
    {
        "url": "https://medium.com/@RecastAI/introducing-bot-connector-by-recast-ai-your-one-api-to-connect-bots-to-any-channel-afa52271803?source=user_profile---------56----------------",
        "title": "Introducing Bot Connector by Recast.AI, your one API to connect bots to any channel!",
        "text": "If you\u2019ve ever made a bot, you are aware that channels (Messenger, Kik, Slack, Skype, SMS, emails,etc) don\u2019t all work the same, and that you cannot possibly manage to write code that takes full advantage of each platform\u2019s features.\n\nThat\u2019s why Recast.AI created Bot Connector. With only one integration in your code to reach any channel, and a standard message format, you\u2019ve never saved this much time in your bot development.\n\nBot Connector is a free-to-use open-source project where you have the entire control of the channels supported. Missing one? Create it. Want to improve one? Good ahead. On the other side, the Recast.AI teams make sure the API is always on top of it\u2019s game.\n\nToday, Bot Connector supports Messenger, Kik and Slack. You can register here and get started. If you want to add your own channel, you\u2019ll find the procedure here!\n\nToday live on Product Hunt, Bot Connector joins the Recast.AI Bot Creation Suite, alongside Bot Understanding and Bot Builder, to bring the startup one step closer to its goal: make complex bot development easy and intuitive for developers. It is by developing a natural language and machine learning technology that the startup is leading the conversational interfaces sector.\n\nAbout Recast.AI Founded in September 2015, Recast.AI is a collaborative artificial intelligence platform allowing developers to easily create conversational interfaces such as chatbots. With more than 5,000 developers using the platform who have created more than 8,000 bots in less than 10 months, Recast.AI capitalizes on this technological and user experience expertise by assisting businesses wishing to implement new interfaces powered by conversation. Having received 2 millions euros in funding from business angels and the Banque Publique d\u2019Investissement (BPI) in its first year of existence, Recast.AI is working to demonstrate the considerable potential of conversational interfaces such as bots through highly efficient language, artificial intelligence (AI) and machine learning technologies. More information can be found at https://recast.ai"
    },
    {
        "url": "https://chatbotsmagazine.com/ever-wished-you-could-make-bot-connection-easier-introducing-bot-connector-api-by-recast-ai-70f056360ffd?source=user_profile---------57----------------",
        "title": "Ever wished you could make bot connection easier? Introducing Bot Connector API by Recast.AI",
        "text": "So, you\u2019ve reached the point in your bot development where you\u2019d like to connect your bot to multiple channels. You select 3 of them, read their documentation, create 3 different versions of your code and manage the integration to each channel separately. One of your friends likes your bot and wants to have it on another channel. That means another duplication. And as it so happens, the API of a channel has changed, so you have to modify your code. By now, you have four different connections to manage, all with different structures, and what happens if you find out something\u2019s wrong? You\u2019d have to change it everywhere?\n\nHell no. You know what you need ? You need Bot Connector by Recast.AI.\n\nToday, connecting to different channels means reading each channel\u2019s doc, making one API call to each, and differentiating your code. That\u2019s a pain.\n\nWith Bot Connector, you only have one API integration to manage. Monitored and updated by the Recast.AI team, we\u2019ve grouped different channels into one API to rule them all. No more duplicating, only one documentation to read, and no more countless \u201cifs\u201d in your code.\n\nBut wait, that\u2019s not all.\n\nOnly having one API call to manage is sweet, but you still have to adapt your code to each channel, since they don\u2019t all offer the same features. That\u2019s an issue we wanted to tackle! Therefore, Bot Connector supports a standard message structure and is then capable of spreading it to all the different channels, taking advantage of each one\u2019s features.\n\n\u201cWell, Bot Connector gets a message from a channel, parses it in a uniform format and transfers it to the bot. Then, the bot sends back its answer, Bot Connector flattens the message and broadcastes it to all relevant channels. That\u2019s why we decided to illustrate Bot Connector a an octopus: one brain, reaching many places at once.\u201d J\u00e9rome Houdan \u2014 Developer full stack\n\nIt\u2019s all good and nice up to here, but what if you need a channel that Bot Connector doesn\u2019t support? Today, we\u2019ve integrated Messenger, Slack and Kik. We\u2019re aware that there are a lot more. You want another one? Bot Connector is a fully open-source project. That means you can develop a channel connection yourself and add it to our API. It\u2019s as simple as it gets. And don\u2019t worry, we\u2019ve written a guide to adding your own channel to Bot Connector to help you get started.\n\n\u201cWe founded Recast.AI in a true collaborative state of mind. Our goal to provide the technology allowing developers to innovate. It\u2019s by giving them the keys that they\u2019ll be able to create amazing things, and that\u2019s exactly what we\u2019re doing with an open-source Bot Connector.\u201d \u2014 Jasmine Anteunis, Recast.AI co-founder and Bot Connector lead developer\n\nIt is our mission to provide the best technologies for you to develop bots in the easiest way. That\u2019s why Bot Connector is included in the Recast.AI Bot Tools Suite, alongside Bot Understanding, our natural language processing tool, and Bot Builder, our conversation flow creator. With intricate synergies between platforms, using Recast.AI is your best shot at creating bots fueled by a powerful technology, very easily.\n\nBot Connector is free to use and will remain so. It\u2019s your tool. Make the most of it."
    },
    {
        "url": "https://medium.com/@RecastAI/webhelp-signs-partnership-with-recast-ai-to-develop-chatbot-and-artificial-intelligence-offering-eca9d3767e16?source=user_profile---------58----------------",
        "title": "Webhelp signs partnership with Recast.AI to develop chatbot and artificial intelligence offering",
        "text": "Leading global business process and customer experience outsourcer Webhelp, has announced a new partnership with Recast.AI that will allow the customer experience outsourcer to develop its ChatBot and artificial intelligence capabilities.\n\nThe partnership will bring together two leaders in their respective fields to ensure the power of artificial intelligence is harnessed and exploited to drive forward the customer experience industry.\n\nThe partnership between Webhelp and Recast.AI will make customisable ChatBots and AI powered customer experience solutions more widely accessible. This will enable Webhelp\u2019s clients to easily implement highly personalised ChatBots, software that simulates human-like conversations through either voice or text based interactions. ChatBots can be deployed into multiple channels such as Messenger, SMS, In-App, Skype, Slack to improve convenience and customer experience.\n\nWebhelp\u2019s existing ChatBot offering will be accelerated as a result of this partnership.\n\n\u201cWebhelp\u2019s position as a technology enabler is incredibly important to us. The time and resources we are investing in the development of new technologies, such as chatbots, as well as establishing relationships with best-in-breed technology startups is what sets us apart from other customer experience and business process outsourcers.\u201d\n\n\u201cWe have been very impressed by the product Recast.AI has created, which they demonstrated when they won our \u2018March of the Bots\u2019 challenge at Viva Technology in the summer. We are excited about the prospect of working with them to disrupt customer experience expectations with the expert application of artificial intelligence technologies.\u201d\n\n\u201cWebhelp is a leading global customer experience outsourcing business and has a huge experience as well as a fantastic reputation in this sector. We are delighted to work alongside Webhelp and add our expertise in artificial intelligence to expand their already impressive offer to conversational interfaces. I am confident that joining the relevant expertise and resources of both companies will lead to the development of new initiatives that will drive forward the potential of ChatBots and artificial intelligence in customer experience.\u201d\n\nHeather Astbury, head of PR at Webhelp, on +44(0)7825 593242, at heather.astbury@uk.webhelp.com\n\nJustine Baron, press relations at Recast.AI, on +33 6 77 68 43 26, at justine.baron@recast.ai\n\nAbout Webhelp Webhelp is a global business process outsourcer (BPO), specialising in customer experience and payment management in addition to sales and marketing services across voice, social and digital channels. From 26 countries with a 35,000-strong team, our focus is on engineering performance improvements and delivering a real and lasting transformation in our clients\u2019 operating models to generate financial advantage. We partner with some of the world\u2019s most progressive brands including Sky, Shop Direct, Bouygues, Direct Energie, KPN, Vodafone, La Redoute, Michael Kors and Valentino. Headquartered in Paris, France, the company has grown its revenues by more than 250% in the last 4 years by investing in its people, the environment they work in and developing its analytical and operating capability to deliver a transformational outsourcing proposition that addresses the challenges of an omni-channel world. Webhelp is owned by its management and KKR, a leading global investment firm, as of February 2016. More information can be found at www.webhelp.com About Recast.AI Founded in September 2015, Recast.AI is a collaborative artificial intelligence platform allowing developers to easily create conversational interfaces such as chatbots. With more than 5,000 developers using the platform who have created more than 8,000 bots in less than 10 months, Recast.AI capitalizes on this technological and user experience expertise by assisting businesses wishing to implement new interfaces powered by conversation. Having received 2 millions euros in funding from business angels and the Banque Publique d\u2019Investissement (BPI) in its first year of existence, Recast.AI is working to demonstrate the considerable potential of conversational interfaces such as bots through highly efficient language, artificial intelligence (AI) and machine learning technologies. More information can be found at https://recast.ai\n\nLe partenariat entre Webhelp et Recast.AI rendra les solutions d\u2019exp\u00e9rience client bas\u00e9es sur l\u2019intelligence artificielle et les chatbots plus largement accessibles. Il permettra aux clients de Webhelp de mettre facilement en \u0153uvre des chatbots personnalis\u00e9s, \u00e0 savoir des logiciels qui simulent des conversations humaines par le biais d\u2019interactions vocales ou \u00e9crites. Les chatbots peuvent \u00eatre utilis\u00e9s sur de nombreux canaux de communication tels que Messenger, SMS, In-App, Skype ou Slack pour am\u00e9liorer l\u2019exp\u00e9rience client.\n\n\u00ab Webhelp est un leader mondial de l\u2019externalisation de l\u2019exp\u00e9rience client avec une solide exp\u00e9rience ainsi qu\u2019une excellente r\u00e9putation dans ce secteur. Nous sommes ravis de travailler \u00e0 leurs c\u00f4t\u00e9s et d\u2019apporter notre expertise pour \u00e9largir leur offre d\u00e9j\u00e0 impressionnante. Je suis certain que la mise en commun de l\u2019expertise et des ressources de nos deux entreprises d\u00e9veloppera le potentiel des chatbots et de l\u2019intelligence artificielle dans le cadre de l\u2019exp\u00e9rience client. \u00bb\n\nA propos de Webhelp Webhelp est un acteur global de l\u2019externalisation des processus m\u00e9tiers (BPO), sp\u00e9cialiste de l\u2019exp\u00e9rience client, de la gestion des paiements, des ventes et des services marketing \u00e0 travers les canaux voix, sociaux et digitaux. Pr\u00e9sent dans 26 pays avec plus de 35 000 collaborateurs, notre ambition est d\u2019am\u00e9liorer la performance de nos clients en concevant des solutions qui vont transformer durablement leurs mod\u00e8les op\u00e9rationnels et apporter un avantage comp\u00e9titif. Nos clients sont parmi les entreprises les plus dynamiques au monde comme Sky, Shop Direct, Bouygues Telecom, Direct Energie, KPN, Vodafone, La Redoute, Michael Kors ou Valentino. Bas\u00e9e \u00e0 Paris, l\u2019entreprise a vu ses revenus progresser de pr\u00e8s de 225% au cours des 4 derni\u00e8res ann\u00e9es : principalement en investissant sur l\u2019humain, et en proposant \u00e0 ses clients un accompagnement \u00e0 valeur ajout\u00e9e pour r\u00e9pondre aux d\u00e9fis d\u2019un monde multicanal. Webhelp est d\u00e9tenu par son management et depuis f\u00e9vrier 2016 par KKR, un fond d\u2019investissement d\u2019envergure mondiale. Plus d\u2019informations sur www.webhelp.com A propos de Recast.AI Fond\u00e9e en septembre 2015, Recast.AI est une plateforme collaborative d\u2019intelligence artificielle permettant aux d\u00e9veloppeurs de facilement cr\u00e9er des interfaces conversationnelles telles que des chatbots. Avec plus de 8 000 bots cr\u00e9\u00e9s par plus de 5 000 d\u00e9veloppeurs sur cette plateforme en moins de 10 mois, Recast.AI tire parti de son expertise technologique pour accompagner les professionnels souhaitant mettre en \u0153uvre de nouvelles interfaces bas\u00e9es sur la conversation. Recast.AI, qui a re\u00e7u 2 millions d\u2019euros de financement de la part de business angels et de la Banque Publique d\u2019Investissement (BPI) au cours de sa premi\u00e8re ann\u00e9e d\u2019existence, s\u2019efforce de d\u00e9montrer le potentiel consid\u00e9rable des interfaces conversationnelles telles que les bots gr\u00e2ce \u00e0 des technologies de langage, d\u2019intelligence artificielle (IA) et de machine learning hautement efficaces. Pour plus d\u2019informations, rendez-vous sur https://recast.ai/"
    },
    {
        "url": "https://medium.com/@RecastAI/making-the-most-of-web-summit-8-tips-for-2017-6c62ca71c65f?source=user_profile---------59----------------",
        "title": "Making the most of Web Summit \u2014 8 tips for 2017 \u2013 RecastAI \u2013",
        "text": "Web Summit is the biggest tech conference in Europe, and this year, it brought together more than 50 000 people in the MEO Arena of Lisbon. We were lucky enough to be there and part of the START Track of the event for the first time, and boy was it exciting.\n\nThanks Paddy Cosgrave for this great event, and a big thanks to craft.ai, Mailjet, Gitlab, FrenchTech and Coding Game for those few days together!\n\nHere are some tips that we gathered after our experience there.\n\nWith tens of thousands of people around, the ones you want to talk to won\u2019t just show up and engage with you. You need to make contact with them a few weeks before the event (VCs, potential clients, partners, journalists, etc). Some, you can contact via email, others through the WebSummit app, a really well thought out tool that will be your lifesaver during the event itself. Check on social media for influencers who will be present and drop them a line to schedule a meeting!\n\nThere aren\u2019t enough minutes in your days to see everything WebSummit has to offer. Now that you\u2019ve listed and made appointments with people you want to meet, figure out what your priorities for the event are. We compiled lists of:\n\n- Twitter lists of influencers and Web Summit celebrities to keep up to date with the latest news\n\nAdd the relevant events to your calendar with a twenty-minute notification and you\u2019ll be good to go.\n\nWhen you\u2019re exhibiting at WebSummit, it\u2019s only for one day. So it\u2019s worth planning how you\u2019re going to make the most of the other two days. Test different approaches: go through the booths, hand out flyers, try and catch speakers after conferences or work only with meetings? These two days are time for you to see what works and what doesn\u2019t. Don\u2019t hesitate to be creative, because people will notice.\n\nBooth day is intense. You don\u2019t have a minute to yourself, people are queuing to talk to you or see your demo, and switching between languages can be confusing and tiring.\n\n- the internet is tricky, it works but you shouldn\u2019t rely on it for live demos. Instead, take screenshots or videos of your products. Be careful, independent routers using wifi are forbidden. Bluetooth ones are fine.\n\n- snacks, I cannot emphasise this enough, stock up on snacks.\n\n- make yourself available to avoid people moving along when kept waiting. If your entire team is busy, make eye contact with a waiting attendee, or include them in your ongoing conversation.\n\n- don\u2019t be afraid to dress up your stand, very few are actually decorated, and it really makes you stand out!\n\nAs mentioned above, the WebSummit develops an app for the event. With this app, you can scan the QR codes that are on every participants\u2019 badge. By scanning this code, you get all relevant information about your interlocutor (company, position, email, phone number, interests, etc) and can engage with them later. It\u2019s easy, environment-friendly and hassle free, so do it and don\u2019t ever stop.\n\nThis is really the core of WebSummit. Managing your sleep is key because you cannot afford to miss the night events. WebSummit organizes Pub Crawls and get togethers, but what you should be looking for are private dinner parties organized by companies or sponsors. Use your network, reach out to your embassy or to national startup associations to discover the place to be. It\u2019s during those events that\u2019ll you\u2019ll meet the most amazing people.\n\nOn the logistics side, get snacks for those events too. You\u2019ll have eaten at noon, and won\u2019t eat after the first hour of cocktails, at around 9pm, even later. Drinking cocktails on an empty stomach and sleep deprivation is not what you want at a business event. Also, think of extra socks and strategic positioning next to chairs and couches because yes, you feet will be killing you, and yes, you\u2019ll be begging to sit down.\n\nWe chose four Recast.AI people to attend. We thought that an even number would be a good thing, because being paired up has many advantages. Set up teams: flyer team, press team, business unit, discovery gang, and agree on a meeting point later in the day to regroup, discuss and adjust.\n\nThe more of you there are, the less tired and more efficient you\u2019ll be.\n\nYou will be meeting a great deal of different people, and no matter how hard you try, you cannot remember them all. Add notes on business cards directly after meeting people. Make time in the evening or at the end of Summit to compile a list of all your business cards or scanned contacts in a mastersheet (really fast, like at the airport or in the plane fast). Make really specific notes. Yes, you might not care right now that you talked about this person\u2019s last trip to Hawaii and the industry of minigolfs there, but it will truly help you remember them a few days later, back in the office.\n\nIn the sweet chaos that WebSummit was, we spent an hour going around meeting great startups. I\u2019d like to leave you with a selection of our favorites:\n\nCodacy checks your code\u2019s style, security, duplication, complexity and coverage on every change while tracking code quality throughout your sprints.\n\nFlow.ai develops bots and creates great customer experiences and services with artificial intelligence\n\nguh is an open source IoT server, which allows to control a lot of different devices from many different manufacturers.\n\n4Gifters is the first e-gifting platform that enables to send and receive gifts in different cities around the world.\n\nGlassup \u2014 Everything you need in a lens\n\nThe GlassUp eyeglasses report incoming e-mails, text messages, tweets, Facebook updates, and other messages, so that you can keep abreast with what is going on in this big world.\n\nLusovu \u2014 Improve life by connecting people beyond the human senses\n\nLusovu is developing Lisplay technology that will help achieve the ultimate augmented reality headset, one that is as light, comfortable and elegant as a normal pair of glasses.\n\nSee you next year!"
    },
    {
        "url": "https://chatbotsmagazine.com/build-you-first-bot-with-bot-builder-by-recast-ai-b655e2a29686?source=user_profile---------60----------------",
        "title": "Build you first bot with Bot Builder by Recast.AI! \u2013",
        "text": "By the end of this tutorial, you will have built a fully functional food ordering bot using our new feature: the Bot Builder. Bot Builder helps you design complex flows for your bots quickly and easily. There are 4 phases in your bot life on our platform:\n\nAfter that, you are redirected to the main page of your bot, where everything it knows is gathered, divided in intents. Intents are boxes including expressions that mean the same thing but are constructed differently. Each intent corresponds to one action your user want to perform.\n\nThere are common intents that you should create in each of your bot. Your bot has to understand basic things such as \u2018greetings\u2019 , \u2018agree\u2019, \u2018disagree\u2019, and when a user asks for help. Luckily, our platform is collaborative, and you can \u2018fork\u2019 an intent someone already created to clone it right into your bot. It\u2019s very useful for basics functions. To fork these intent:\n\nThis is how to create intents you cannot find in the community. We need the bot to understand when someone is ordering food, and if they want it to be delivered or take-away. To create these intents:\n\nNow that intents have been created, we have to fill them with various expressions that mean the same thing. Just click on the \u2018Add an expression\u2019 field and write your expressions. Let me give you some:\n\nIn some expressions, you need to extract important data. That\u2019s why we have entities. They\u2019re keywords detected in expressions. Some of them are automatically detected, like location and name: we call them gold entities and they\u2019re marked with a little star. You can see them by clicking on an expression.\n\nYou can also create your own custom entities. We\u2019ll use them here to get the type of food the user orders.\n\nNow that we\u2019ve created everything your bot is supposed to know, let\u2019s test it:\n\nNow that you bot is considered smart and effective, we can start building the conversation. Click on the \u2018Build\u2019 tab and then on \u2018Launch the builder\u2019 to discover the magic of Bot Builder. Read the guide that pops on the screen and you\u2019ll enter into the Bot Builder playground.\n\nLet\u2019s take some time now to think of what the flow will look like:\n\nHere is the drawing of the bot flow. Each step on this chart is an action. An action, as we call it in Bot Builder, is one step in your conversation flow that is associated with an intent (you can have several actions for the same intent). To put an action on your playground:\n\nReproduce this in the BotBuilder, without taking care of the connections for now.\n\nThere are two types of links:\n\nSince \u2018order\u2019 action need the user to choose between delivery and take away, the only red links we have to make are:\n\nNow that we\u2019ve set the flow, some of our actions need specific informations (entities) to be complete: we call them notions.\n\nAs we need a name for take away and an address for delivery, set these 2 notions the same way your did the first one.\n\nAt this point, the hardest part is done. Let\u2019s now give some spirit to our bot! There are 3 different replies you can set:\n\nNow that the flow is complete and the replies set, we can finally test the bot!\n\nWe\u2019re now done setting up the bot. The last thing you have to do is to connect it to a channel so users can use it! This part is taking place in the \u2018Run\u2018 tab of your bot. Here you can find all the tools we provide to connect your bot easily. The easiest way today is to use our starter-kits. Each of them has its own complete documentation.\n\nWhen your bot is launched and starts to have some users, go to the \u2018Train\u2018 tab, and manage your logs:\n\nHope this tutorial will help you launch plenty of wonderful bots. Please ask if you need help!"
    },
    {
        "url": "https://chatbotsmagazine.com/build-the-most-advanced-bots-in-the-simplest-way-49e8bb8df69f?source=user_profile---------61----------------",
        "title": "Build the most advanced bots in the simplest way! \u2013",
        "text": "Building bots isn\u2019t always an easy task. Under hundreds of lines of codes, between APIs, frameworks and tools, language technologies get tricky. We know this. That\u2019s why we decided to create a tool that will allow you to build the most advanced bots in the simplest way: Bot Builder!\n\nBots have established their potential. Today, we need use cases, we need applications, we need people to unleash their creativity on this new medium. That\u2019s why we\u2019re allowing you to put all the conversation coding behind you, to focus on bringing exceptional bots to life.\n\nBy using Bot Builder, you can now:\n\nDefine which actions have specific requirements and which can be activated at any time!\n\nEntities create notions that are shared throughout the conversation\n\nMissing information to continue? Ask the user directly. Got everything you need? Keep moving.\n\nChat directly with your bot on the improved test console.\n\nWith our system of actions, links and notions, it now literally can take less than 15 minutes to create a bot with our machine-learning technology, tools and community. Oh, and it\u2019s free!\n\nSo, you want to know more? We\u2019re on Product Hunt!\n\nAnd check out our tutorial on how to build a bot from A to Z with Recast.AI and Bot Builder."
    },
    {
        "url": "https://medium.com/@RecastAI/build-your-first-bot-with-bot-builder-80d1ec19d2d1?source=user_profile---------62----------------",
        "title": "Build your first bot with Bot Builder \u2013 RecastAI \u2013",
        "text": "Note: This article is deprecated. It uses Recast.AI API version 1. You can find an updated tutorial here: Build your first bot with Recast.AI.\n\nBy the end of this tutorial, you will have built a fully functional food ordering bot using our new feature: the Bot Builder. Bot Builder helps you design complex flows for your bots quickly and easily. There are 4 phases in your bot life on our platform:\n\nAfter that, you are redirected to the main page of your bot, where everything it knows is gathered, divided in intents. Intents are boxes including expressions that mean the same thing but are constructed differently. Each intent corresponds to one action your user wants to perform.\n\nThere are common intents that you should create in each of your bots. Your bot has to understand basic things such as \u2018greetings\u2019 , \u2018agree\u2019, \u2018disagree\u2019, and when a user asks for help. Luckily, our platform is collaborative, and you can \u2018fork\u2019 an intent someone already created to clone it right into your bot. It\u2019s very useful for these basics functions. To fork these intents:\n\nThis is how to create intents you cannot find in the community. We need the bot to understand when someone is ordering food, and if they want it to be delivered or take-away. To create these intents:\n\nNow that intents have been created, we have to fill them with various expressions that mean the same thing. Just click on your intent then on the \u2018Add an expression\u2019 field and write your expressions. Let me give you some:\n\nHere is one of our articles giving you tips about how to optimize your intents, with lots of tips and good practices.\n\nIn some expressions, you need to extract important data. That\u2019s why we have entities. They\u2019re keywords detected in expressions. Some of them are automatically detected, like location and name: we call them gold entities and they\u2019re marked with a little star. You can see them by clicking on an expression.\n\nYou can also create your own custom entities. We\u2019ll use them here to get the type of food the user orders.\n\nNow that we\u2019ve created everything your bot is supposed to know, let\u2019s test it:\n\nNow that your bot is considered smart and effective, we can start building the conversation. Click on the \u2018Build\u2019 tab and then on \u2018Launch the builder\u2019 to discover the magic of Bot Builder. Read the guide that pops on the screen and you\u2019ll enter into the Bot Builder playground.\n\nLet\u2019s take some time now to think of what the flow will look like:\n\nHere is the drawing of the bot flow. Each step on this chart is an action. An action, as we call it in Bot Builder, is one step in your conversation flow that is associated with an intent. (You can have several actions for the same intent). To put an action on your playground:\n\nReproduce this in the BotBuilder, without taking care of the connections for now.\n\nThere are two types of links:\n\nSince \u2018order\u2019 action need the user to choose between delivery and take away, the only red links we have to make are:\n\nNow that we\u2019ve set the flow, some of our actions need specific informations (entities) to be complete: we call them notions.\n\nAs we need a name for take away and an address for delivery, set these 2 notions the same way you did for the first one.\n\nAt this point, the hardest part is done. Let\u2019s now give some spirit to our bot! There are 3 different replies you can set:\n\nDon\u2019t forget to also set a reply when the bot doesn\u2019t understand the input. You can do this by using the module \u2018default reply\u2019 located on the bottom-left of the playground.\n\nNow that the flow is complete and the replies set, we can finally test the bot!\n\nWe\u2019re now done with setting the bot. The last thing you have to do is to connect it to a channel to allow users to use it! This part is taking place in the \u2018Run\u2019 tab of your bot. Here you can find all the tools we provide you with to connect your bot easily. The easiest way today is to use our starter-kits. Each of them has its own complete Documentation. That\u2019s why i\u2019d recommend.\n\nWhen your bot is launched and starts to have some users, go to the \u2018Train\u2019 tab, and manage your logs:\n\nHope this tutorial will help you launch plenty of wonderful bots. Don\u2019t hesitate to ask if you need help in your bot building"
    },
    {
        "url": "https://medium.com/@RecastAI/ai-and-space-exploration-the-age-of-adaptability-66f7a0d84e49?source=user_profile---------63----------------",
        "title": "AI and space exploration: the age of adaptability \u2013 RecastAI \u2013",
        "text": "Artificial intelligence (AI) is quite a trendy topic these days, especially sinceGoogle Alphago\u2019s victory over the world champion Lee Sedol has given a bright illustration of the potential of machine-learning. Today, everyone seems to focus on the conversational branch of AI (bots, like the ones we build at Recast.AI, or chatbots), but tons of other applications remain mostly unknown. This is why I\u2019ve decided to dedicate this paper to a subject I\u2019m passionate about: space exploration.\n\nIndeed, it appears that AI can be an extraordinary boost to the discovery of our universe, for instance when it comes to navigation systems, situation analysis or even data transmission. So let\u2019s try to anticipate some of the big chances that lie ahead! I\u2019ve listed some of the most obvious, but if you want to go deeper into the matter, you can refer to Daniela Girimonte and Dario Izzo\u2019s great paper on Artificial Intelligence for Space Applications or browse the NASA\u2019s Jet Propulsion Laboratory webpage to check out the latest releases.\n\nActually, space exploration already benefits hugely from AI. For instance, have you ever wondered how data is transmitted from one planet to another?\n\nUntil a few years ago, it used to be managed with a scheduling software operated by humans, but there were so many constantly changing variables such as the orientation of the spacecraft, the space-ground communication bandwidth, \u2026 that losing data, sometimes forever, happened all the time. Now, AI has been doing the job since 2005: the MEXAR2 system created by ESA is able to determine which data packets can be lost in case of memory conflicts, so that you never find yourself missing the most important piece of the puzzle.\n\nThere\u2019s another key aspect when it comes to dealing with data collected in space: the sheer volume. A satellite like ESA\u2019s ENVISAT produces 400 terabytes of data per year. If you want to process such a vast quantity of data the usual way, you might not even be able to use it before the next space exploration\u2026 this is why scientists have created a network of computers, each one of them receiving a small pack of data and processing it with AI, before regrouping all the pieces together.\n\nThink 400 terabytes a year is a lot? Wait till the Square Kilometre Array telescope is working: it will be producing 720 terabytes a day! If we don\u2019t invest a lot in AI programs capable of processing such amounts of data, the telescope will just be useless!\n\nOne of the main difficulties when it comes to spacefaring is that \u2014 at least for now \u2014 many operations are still driven from earth. As most of you have probably seen Matt Damon\u2019s Martian, let\u2019s take the example of the red planet.\n\nDepending on the relative positions of the planets, Earth is between 6,5 and 44 light-minutes away from Mars; I\u2019ll let you imagine how long it can take to transmit one single message and wait for the instructions to come back. Of course, engineering teams are doing a great job anticipating every possibility and its appropriate response, but what if something unexpected happens? You can\u2019t just rely on a message to be sent to Earth and come back with the answer you desperately and urgently need.\n\nConsequently, the space industry will tend to look for more autonomy in the devices they use, which is where AI can be a powerful tool. For instance, we often use AI to detect and learn from patterns: in this case, you could apply these techniques to the analysis of sandstorms on Mars, in order to predict their evolution and adapt directly, without waiting for a command coming from Earth.\n\nThe NASA has already begun to work on that path: for instance,thanks to an AI software called AEGIS, the Mars Rover can select targets on its own for its laser and telescopic camera. This feature is \u201cparticularly useful at times when getting the science team in the loop is difficult or impossible \u2014 in the middle of a long drive, perhaps, or when the schedules of Earth, Mars and spacecraft activities lead to delays in sharing information between the planets\u201d according to Tara Estlin, the leader of AEGIS development at NASA\u2019s Jet Propulsion Laboratory. The NASA alsoequipped the Mars Rover Curiosity with autonomous navigation systems.\n\nESA\u2019s recent International Rosetta Mission gave a good example on how space exploration could benefit from more adaptable systems: the mission almost failed due to a lack of adaptability.\n\nIn short, a device called Philae was sent to land on the comet 67P/Churyumov\u2013Gerasimenko (nicknamed as \u201cTchouri\u201d) in order to conduct a study. As you can imagine, landing on a fast-moving comet is not an easy task, and in that case it almost ended very badly: unfortunately, the comet\u2019s gravity was slightly different from what it was supposed to be according to the preparatory calculations (with all the irregularities of the comet, a proper estimation of its gravity is particularly difficult).\n\nThe consequences were enormous: Philae hit the surface of Tchouri too strongly, bounced twice before eventually touching the ground (as a comparison, gravity on Tchouri is about one ten-thousandth of that on Earth). At the end of the day, on top on the damages caused by the shock, Philae found it had landed very uncomfortably on a 30% slope. As a result, some of the samples it was supposed to collect could not be harvested, and it was stuck in a part of the comet where it did not have enough sunlight to operate: only 1h30 every 12 hours. This reduced Philae\u2019s autonomy, and also its ability to communicate with its bigger sister Rosetta, orbiting 200 kms above Tchouri.\n\nWe can very well imagine how AI could plug into space missions like Rosetta: by introducing a part of adaptability to the calculations and processes defined on Earth, based on what the spacecraft could directly observe. These things may seem obvious to you, but you need to know that most of the currently flying satellites are built on technologies more than 20 years old\u2026\n\nI\u2019ve listed a few examples of the ongoing efforts in this field:\n\nThanks to AI, the time when an organization would dedicate millions \u2014 even sometimes billions \u2014 of dollars for a system that couldn\u2019t evolve during its use is over. NASA already relies on unmanned spacecrafts and devices to explore the farthest space. Even Elon Musk, who wants to inhabit Mars, has defined AI as probably the \u201cbiggest threat\u201d to humanity, but will have to resort to it in order to fulfill his dreams. So whether you like it or not, until we find another and better solution, you\u2019ll have to make do with AI for a while\u2026\n\nI\u2019d like to thank the Space Generation Advisory Council Team for their help, along with Sourav Karmakar, for suggesting me lectures and papers without which I couldn\u2019t have written this article."
    },
    {
        "url": "https://medium.com/@RecastAI/9-tips-to-get-started-with-our-bot-platform-51df295835c?source=user_profile---------64----------------",
        "title": "9 tips to get started with our bot platform \u2013 RecastAI \u2013",
        "text": "With all the recent buzz around chatbots and conversational apps, the world is divided between those who think a pure conversational interface is doomed to fail and everybody else. Obviously, at Recast.AI we\u2019re definitely part of everybody else! In case you don\u2019t already know, we\u2019re building a collaborative bot platform powered by a custom natural language processing technology. We want it to be accessible to everybody, so allow me to share my secrets to help you on your way.\n\nI made two bots for you to see what you should do or avoid during the creation of your bots: here is a good assistant, and here\u2019s a bad one.\n\nBefore you start using the platform, you need to be absolutely clear about intents. What is an intent?\n\nIntents are boxes that include different expressions with the same meaning but different grammatical constructions.\n\nThis collection of sentences will allow your bot to understand an action you want to perform. You want your intents to be made well enough for the bot to understand you. Here are some ideas about how to achieve this on Recast.AI.\n\nAs the purpose of your intents is to understand what you mean, you want them to be truly different. You don\u2019t want your bot to think that maybe you want to book a train ticket for tomorrow: you want your bot to be sure of it. If the bot cannot understand exactly what you want, it will lead to the worst thing ever: frustration.\n\nIf you want Recast.AI\u2019s text classification to be efficient, it\u2019s very important to have a roughly equal number of expressions inside each intent. Even if it sometimes takes more examples to correctly train an intent and its entity recognition, aim to keep your intents as balanced as possible to ensure an efficient classification.\n\nAmongst the infinity of parameters of text classification, one of the most important is the diversity inside an intent. If you want your bot to understand a very large panel of sentences, it\u2019s paramount to train it with completely different grammatical structures and not to bias it with a single sentence pattern repeated a hundred times:\n\nYou can also take a look at this bot or this one to understand everything we\u2019ve just covered.\n\nAs we said, if your intents are too similar, your bot might not understand the real meaning of your input. If two of your intents are very close in terms of expressions\u2019 syntax or content, you should probably merge them.\n\nLet\u2019s say you want your bot to book your travel tickets. To do that, you could create an intent for plane tickets, one for train tickets and one last for bus tickets, and done! But wait. What if the transport type is not explicitly expressed in the sentence? Your bot couldn\u2019t match anything. That means you should only have one intent called \u201cbooking a ticket\u201d, and manage the transportation type with an entity.\n\nEntities are pieces of information you want to extract from your input and use to trigger an action.\n\nThe key information here is the place. The name of the place is an Entity. Entities are often mistaken for intents, but they don\u2019t serve the same purpose. Let\u2019s see how to use them efficiently.\n\nWhile the syntax of your sentences is important, the entities present in the sentences also have a big influence on the classification. Bear in mind that the presence of an entity in a sentence will steer the intent detected towards others with the same entity.\n\nI sometimes see intents with every single word tagged as an entity. That\u2019s not necessary, the purpose of entities is to be extracted from the sentence, allowing you to use it for a specific action. That means you should only tag information that your bot specifically needs to know and no more.\n\nEven if it seems obvious, adding some weird but used sentences is a good thing, because your users won\u2019t always say nice and perfectly structured sentences. The purpose is to make your bot understand complete and correct sentences as well as short and direct sentences containing almost only keywords.\n\nThere are a few things that all bots should do, like say hello, goodbye, receive compliments, receive insults\u2026 These are not a real part of the specific service your bot will provide but it contributes to its sympathy quota!\n\nThese intents are very common and right now, you can easily find a good one to fork on Recast.AI by looking at the explore section. Soon, they will be provided as primary blocks, so stay tuned.\n\nRecast.AI currently supports both English and French. These languages can be integrated in one unique bilingual bot!\n\nYou\u2019re not obligated to use both languages, but if you do, you\u2019ll have to keep your organisation balanced and homogeneous. To use both languages, you need to create and train your intents both in English and French. Intents in different languages should have nearly the same amount of sentences and contain the same entities. Keep in mind that if you only use one language, sending it as a parameter in your API call will actually make the response faster.\n\nThese are not absolute life or death rules, but general recommendations that \u2014 I hope \u2014 will help you have a enjoyable start on Recast.AI and bot building. Keep in mind that the platform is designed to be open and collaborative, so don\u2019t hesitate to take a look at what other people do and get inspired!"
    },
    {
        "url": "https://medium.com/react-weekly/angular-to-react-tips-on-a-smooth-migration-aafb57589995?source=user_profile---------65----------------",
        "title": "Angular to React: tips on a smooth migration \u2013 React Weekly \u2013",
        "text": "AngularJS is a pretty cool framework by Google \u2014 it provides many great features, like routing and two-way data binding. We used it to create the first version of our platform, but today, we see its limits and want to migrate our platform to ReactJS.\n\nAngular helps creating single page applications and renders the content on the client-side, but is utterly bad in terms of SEO referencing. We want to have something that renders our content on the server-side at the first load, but provides the experience of the SPA applications after that: an isomorphic app. We also want to come back to Javascript, pure javascript, not an Angular abstraction, and further control our data stream.\n\nReact is an open source library built by Facebook.\n\nReact provides a high performance client and server side rendering with a one-way flow for data binding. It\u2019s not a framework, that\u2019s why we\u2019re talking about React and all of its environnement friends.\n\nWe chose Redux, as a flux implementation, a predictable state container for JavaScript apps.\n\nWebpack takes modules with dependencies and generates static assets representing those modules.\n\nHow do we refactor our entire platform? Several methods are available. To prepare, we often go to React and JS meetups. One of them is exactly on our topic: how to migrate your website to React. The conclusion of the speaker is to migrate little by little, for months, and maintain all this crazy stack.\n\nWhile that\u2019s great advice, we decide against it. We use the summer to recode the entire platform in a rush and start form zero. We keep no files from the previous version, we create this entire new project. It takes four developers, and three weeks later here we are! Here\u2019s how we made it work.\n\nBefore we started coding, we \u201cprinted\u201d all of our current website to have a global view. That allowed us to easily analyse what we want to redo. This second version was going to be built on the UI foundations of the old one, with lot of little changes in UI-components to make a better user experience. So the key idea was to abstract website pieces in order to make re-usable multiple component.\n\nTo make all of this more readable, we drew the component hierarchy. In React documentation, they call this \u201cBreak the UI into a component hierarchy\u201d. The first thing you want to do is to draw boxes around every component (and subcomponent) in the mock and name them.\n\nAfter the component hierarchy was set up, we took the time to work on our redux store.\n\nThe redux store holds the whole state of your application. We have to think about how our data will be structured and how our cache will work.\n\nThe first step was to migrate our stylesheets and in the same time to start a real web-styleguide. We took the opportunity to restructure our whole style, and to only keep some global component: typography, layout, buttons, input, etc. All other component will have their own stylesheet attached to them.\n\nIn order to have a great project structure, we based our architecture on one of our friends boilerplate: minus a \u201cReact / Redux isomorphic starter, focused on minimalism and beauty\u201d.\n\nAfter that, the coding begins\n\nWe split the tasks between the four of us. It was important that each member could move forward without the work of the others. Some of us focused on dumb components and others on smart components.\n\nOne very important thing in our project was authentication. Due to an isomorphic app, backend and frontend share the same code, but some code had to be specific, like the cookie handle. So an isomorphic authentication was not really easy.\n\nThanks to the isomorphic app, we have an increased performance, mainly thanks to the initial pageload speed. The SEO problem is no more, single page app is crawlable. If you want other benefits due to isomorphic app, you can check this: http://nerds.airbnb.com/isomorphic-javascript-future-web-apps/. It\u2019s a beautiful world.\n\nWith this second version, we\u2019ve set up an advanced smooth rendering and navigation of our pages.\n\nTo do so, we\u2019ve rendered content as quickly as possible, so we\u2019re never stuck on a page waiting for data.\n\nTo achieve this, you need to flush async fragments. For instance, on this page, the structure loads first, then bloc number 1, and finishes with bloc number 2. Users can navigate smoothly and are never blocked on a page:\n\nBut one of the greatest benefit of our migration are the improved micro-interactions. All micro-interactions are easy to code with this new stack and really smooth for the user. You can fork a bot on the explore page. There is always an indicator of forking on the bot, wether you navigate on the explore or go back to your profile.\n\nAnd that\u2019s about it. So if you\u2019re looking to migrate from Angular to React, go for it. It\u2019ll be worth it.\n\nWe are working now on a big feature on the platform for October, and the front developers team is growing up, so if you want to know more, drop us a mail!"
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-3-8d598c344e74?source=user_profile---------66----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 3 \u2013 RecastAI \u2013",
        "text": "Here are the last steps to the creation of an awesome natural language understanding bot!\n\nThe bot is nearly done. But you still can add some cool features like buttons to make navigation easier inside the conversation.\n\nAnd what if you misspell the pokemon name? That gets you an error. By using fuzzy-matching, you can avoid this.\n\nOur bot is starting to have a lot of features, but memory is one of the most important: it makes the conversation much more \u2018human\u2019. To handle memory, Microsoft Bot Framework has something sweet: session.userData. You can store all the datas you want about the current user in this object to retrieve them later.\n\n\u2013 \u201cshow me its stats\u201d \n\n\u2013 \u201cits Stats\u201d\n\n\u2013 \u201cShow me informations about it\u201d\n\n\u2013 \u201cShow info\u201d\n\netc\u2026 without any pokemon to tag!\n\nThere you go! You should now have a well functioning bot, and it\u2019s only the beginning: you can add as many intents as you like (comparing stats between two pokemons, determining the localisation of pokemons, and much more). The world of bot is in your hands! Try lots of APIs, read lots of docs, and have fun with Recast.AI!\n\nCheers,"
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-2-5255881897b8?source=user_profile---------67----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 2 \u2013 RecastAI \u2013",
        "text": "Want to build an awesome natural language understanding bot? Here\u2019s how to connect it to an API.\n\nPokeBot answers to the greetings intent just fine, but we can\u2019t do the exact same thing for \u2018infopokemon\u2019: it\u2019s a dynamic intent where answers will differ based on the request. In that case, we use an external API: PokeApi.\n\nTo make a request to PokeApi, and get your pokemon informations, you have to make a GET request to this url: \u2018https://pokeapi.co/api/v2/pokemon/:your_pokemon\u2019\n\nAs a request is Asynchronous, we cannot just return a String and send the result in pokebot.js: we have to wait. That\u2019s why we change the code a little bit: modules function will return a Promise instead of a String.\n\nResolve something and it will be caught in .then\n\nReject something and it will be caught in .catch\n\nNow you have the datas, you have to use the doc and build a nice answer for the user with all this data.\n\nFor now the only thing we send is the url of the image. That\u2019s why we\u2019ll create a message object with a type and a content: the type will be either image or text.\n\nNow you have 2 intents working: a basic one, Greetings, and a dynamic one, Infopokemon, but we have 2 more intents to do!\n\n-What moves does bulbasaur learn?\n\n-What can pikachu learn?\n\n-What are venusaur moves?\n\n-Show me charizard moves.\n\n\u2026\n\n\u2013 What are bulbasaur stats?\n\n\u2013 What are venusaur statistics?\n\n\u2013 Show me charizard stats.\n\n\u2013 Show me stats of pikachu.\n\n\u2026\n\nCongrats, your bot can now have dynamic replies! Try some Pokemons to see the results. In the 3rd and last part of this tutorial, we\u2019re going to add some sweet features to our bot ;)."
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-1-a2abd1b1c715?source=user_profile---------68----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 1 \u2013 RecastAI \u2013",
        "text": "Want to build an awesome natural language understanding bot? Here\u2019s how.\n\nFacebook recently opened up their Messenger platform to enable bots to chat with users through Facebook Apps and on Facebook Pages. With Recast.AI you will be able to create a conversational bot that will understand natural language.\n\nHere is a tutorial on how to create your own messenger bot with Recast.AI and Microsoft bot connector in one hour.\n\nIn this tutorial, we\u2019ll use the example of our latest bot: Pok\u00e9bot. He is a smart Pok\u00e9dex and gives you information about Pok\u00e9mons, their moves, resistance and weakness, the way they evolve etc\u2026 You can find further informations here.\n\nAs you can see on the graph below, we\u2019ll have to make 2 connections: one between the bot and Microsoft, and one between Microsoft and Messenger.\n\nWhenever the bot receives a message on Messenger, it will be sent to the server running on the endpoint url specified on Microsoft Bot Platform.\n\nProblem: the server will be running locally (no url)\n\nThat\u2019s why you will use ngrok which make a local server run online.\n\nBy using Recast.AI you will hear some specific terms:\n\nEach intent is a function that returns the appropriate answer. It\u2019s really important to keep that kind of architecture because that makes it easier to work and add new intents.\n\nYou just achieved the basics! Now your bot is connected to Messenger, to recast, and answer to Greetings. In the next part we\u2019ll start the development of dynamics intent using PokeApi."
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-1-8fe9ac9780a5?source=user_profile---------69----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 1 \u2013 RecastAI \u2013",
        "text": "Facebook recently opened up their Messenger platform to enable bots to chat with users through Facebook Apps and on Facebook Pages. With Recast.AI you will be able to create a conversational bot that will understand natural language.\n\n Here is a tutorial on how to create your own messenger bot with Recast.AI and Microsoft bot connector in one hour.\n\n In this tutorial, we\u2019ll use the example of our latest bot: Pok\u00e9bot. He is a smart Pok\u00e9dex and gives you information about Pok\u00e9mons, their moves, resistance and weakness, the way they evolve etc\u2026\n\nAs you can see on the graph below, we\u2019ll have to make 2 connections: one between the bot and Microsoft, and one between Microsoft and Messenger.\n\nWhenever the bot receives a message on Messenger, it will be sent to the server running on the endpoint url specified on Microsoft Bot Platform.\n\n Problem: the server will be running locally (no url)\n\n That\u2019s why you will use ngrok which make a local server run online.\n\nBy using Recast.AI you will encounter some specific terms, that you can get familiar with here with a crystal-clear guide of the platform\u2019s good practices.\n\nEach intent is a function that returns the appropriate answer. It\u2019s really important to keep that kind of architecture because that makes it easier to work and add new intents.\n\nYou just achieved the basics! Now your bot is connected to Messenger, to recast, and answer to Greetings. In the next part we\u2019ll start the development of dynamics intent using PokeApi."
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-2-5ffd8d61bf08?source=user_profile---------70----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 2 \u2013 RecastAI \u2013",
        "text": "PokeBot answers to the greetings intent just fine, but we can\u2019t do the exact same thing for \u2018infopokemon\u2019: it\u2019s a dynamic intent where answers will differ based on the request. In that case, we use an external API: PokeApi.\n\nTo make a request to PokeApi, and get your pokemon informations, you have to make a GET request to this url: \u2018https://pokeapi.co/api/v2/pokemon/:your_pokemon'\n\nAs a request is Asynchronous, we cannot just return a String and send the result in pokebot.js: we have to wait. That\u2019s why we change the code a little bit: modules function will return a Promise instead of a String.\n\n Resolve something and it will be caught in .then\n\n Reject something and it will be caught in .catch\n\nNow you have the datas, you have to use the doc and build a nice answer for the user with all this data.\n\nFor now the only thing we send is the url of the image. That\u2019s why we\u2019ll create a message object with a type and a content: the type will be either image or text.\n\nNow you have 2 intents working: a basic one, Greetings, and a dynamic one, Infopokemon, but we have 2 more intents to do!\n\n-What moves does bulbasaur learn?\n\n -What can pikachu learn?\n\n -What are venusaur moves?\n\n -Show me charizard moves.\n\n \u2026\n\n- What are bulbasaur stats?\n\n \u2014 What are venusaur statistics?\n\n \u2014 Show me charizard stats.\n\n \u2014 Show me stats of pikachu.\n\n \u2026\n\nCongrats, your bot can now have dynamic replies! Try some Pokemons to see the results. In the 3rd and last part of this tutorial, we\u2019re going to add some sweet features to our bot ;)."
    },
    {
        "url": "https://medium.com/@RecastAI/a-nodejs-chatbot-tutorial-part-3-63e43d36bef7?source=user_profile---------71----------------",
        "title": "A NodeJS chatbot tutorial \u2014 Part 3 \u2013 RecastAI \u2013",
        "text": "The bot is nearly done. But you still can add some cool features like buttons to make navigation easier inside the conversation.\n\nAnd what if you misspell the pokemon name? That gets you an error. By using fuzzy-matching, you can avoid this.\n\nOur bot is starting to have a lot of features, but memory is one of the most important: it makes the conversation much more \u2018human\u2019. To handle memory, Microsoft Bot Framework has something sweet: session.userData. You can store all the datas you want about the current user in this object to retrieve them later.\n\n- \u201cshow me its stats\u201d \n\n \u2014 \u201cits Stats\u201d\n\n \u2014 \u201cShow me informations about it\u201d\n\n \u2014 \u201cShow info\u201d\n\n etc\u2026 without any pokemon to tag!\n\nThere you go! You should now have a well functioning bot, and it\u2019s only the beginning: you can add as many intents as you like (comparing stats between two pokemons, determining the localisation of pokemons, and much more). The world of bot is in your hands! Try lots of APIs, read lots of docs, and have fun with Recast.AI!"
    },
    {
        "url": "https://medium.com/@RecastAI/connecting-a-bot-on-kik-a-nodejs-tutorial-97b9fdd6ba0b?source=user_profile---------72----------------",
        "title": "Connecting a bot on Kik, a NodeJS tutorial ! \u2013 RecastAI \u2013",
        "text": "Note: This article is deprecated. It uses Recast.AI API version 1.\n\nIn this tutorial we are going to see, step by step, how to integrate Kik and Recast.AI in a Nodejs application.\n\nAt the end of this tutorial, you will be able to use Kik for every bot you ever want to build. This is a simple tutorial, so even if you don\u2019t have an extensive knowledge of NodeJS, you can do this.\n\nFirst of all, what is Kik?\n\nFor those of who don\u2019t know, Kik is a messaging app, much like Facebook Messenger or Whatsapp. The company has a solid base of 240 millions register users. You can browse the Kik botshop to find inspiration for your bot!\n\nJust follow the steps on the kik app in order to create your account\n\nNow that your Kik account is created, we have one last thing to do before jumping into the code, and that\u2019s creating your Recast.AI account. Recast.AI is a Natural Language Processing platform allowing you to create truly adaptable bots. If you\u2019re already using another Natural Language Processing platform, you can skip to the third part directly.\n\nTo allow your bot to understand you, you need to create (or fork) your first \u2018intent\u2019. An intent In each intent, you\u2019ll input different expression the user could use daily.\n\nEven if one example can be enough, the more examples your provide, the better the classification will be. And easier will it be for your bot to understand the sentence.\n\nOn the right side, use the console to see how your bot reacts to a sentence.\n\nHere, you find everything you need to manage the bot. In this tutorial, you\u2019re mostly interested in the \u2018Request access token\u2019 , as we need it for the next part!\n\nThe entire tutorial code is on this repo. Feel free to have a look, and go over our SDKs as well here, they can help.\n\nI am listening on 8080 because it\u2019s the config of our server in bot.js, feel free to change that if needed.\n\nLeave your server running and keep this uri in mind. You will need it for the rest of the tutorial. Be careful, as each time you restart the server, the address changes.\n\nI like to separate all my login details in a config.js file, but you can do as you wish.\n\nGreat! You now know how to integrate a Recast.AI bot on Kik. :)\n\nFeel free to ask any question in the comment section or join us on our Slack Community ! You\u2019ll find the rest of our bot tutorials here."
    },
    {
        "url": "https://medium.com/@RecastAI/how-our-infrastructure-has-evolved-since-the-beginning-of-recast-ai-part-1-5ab1aaa7a6b?source=user_profile---------73----------------",
        "title": "How our infrastructure has evolved since the beginning of Recast.AI \u2014 Part. 1",
        "text": "Recast.AI is almost 1 year old! And the infrastructure changed a lot since we\u2019ve started. We started with Kimsufi, then ran with DigitalOcean and we are now on Azure and AWS. The always growing need of availability, performance and security is the main reason of these evolutions. As a former student without knowledge in DevOps and infrastructures, I had to learn everything from a single-server infrastructure to a tens-servers infrastructure. I\u2019ll expose here how we evolved, made technologic choices and build a scalable, High Availability infrastructure at Recast.AI!\n\nAt the beginning, we had all the applications, both development and production environments on the same Kimsufi KS-4 which costs us 22$ a month. We used it for 6 months, developing our product, testing a lot. After the first 3 months, we\u2019ve started using Docker with Rancher. This way, our production and development environments were split and not impacting each other. This was great for our first users. But when some containers started randomly crash at the filesystem level in production, we had a problem. We dug, searched for real use case of big compagnies running with Docker in production but after some time not finding any solution we\u2019ve concluded that Docker is currently not viable for production.\n\nThat\u2019s why we searched for a hosting company allowing us to create instances in the cloud to entirely separate the different elements of the platform.\n\nEven if we started with a single server, we\u2019ve always designed our code to be scalable. In fact, every single part of the platform is API-oriented, split in microservices. As a result, it was easy for us to move to a cloud architecture with many instances.\n\nTo find the hosting company we needed, we first designed the infrastructure. Here is what we needed:\n\nConsidering these informations, we established the features our new hosting provider must have:\n\nAfter some researches, DigitalOcean seems to be the most interesting option. AWS and Azure were yet too complicated options for our needs, Heroku is too high-level and we needed to create an on permise infrastructure. OVH, 1and1 and others companies mainly provides hardware servers, which is not agile enough for us.\n\nDigitalOcean provides a really simple solution to move to a basic cloud infrastructure: Public ip addresses, private network, resizable instances (when shut down), snapshots and a big community and blog to help!\n\nHere is the new infrastructure made with DigitalOcean:\n\nEverything is in a single private network, except a reverse proxy which serves the platform and tools to the users and developers. We moved our Jira and Prerender to their PAAS services, our blog to a simple OVH web hosting, and added StatusCake and Newrelic to monitor the platform. On top of the Production and Development environments, the log, backup and monitoring system took care of the platform.\n\nSo we had a fresh new infrastructure able to handle our growth and we kept it for almost 4 months. But now we are coming to its limitations: there is no internal DNS server, so no service discovery. We can\u2019t pop new instances automatically. The infra was hard to update and to maintain because the servers were managed manually. With new business contracts, we need to be able to instantiate the platform for companies easily. Bot hosting is coming, meaning auto deployments and auto scale. We also have a lot of traffic now, so we have to scale and provide a High Availability service, which means duplicate all instances and have them in a physical different location (different network and power switches). Last but not least, we need more computational power to compile our datasets.\n\nHence, all of these needs brings us to the next level: a new infrastructure running on Azure, Google Cloud Platform or AWS.\n\nWe\u2019ll describe our migration to a new IAAS service in the next article, coming in a week! We\u2019ll talk about our infrastructure choices, its design and deployment, along with the challenges we came through and the use of Ansible. See you next week! :)"
    },
    {
        "url": "https://chatbotsmagazine.com/exploring-dialog-management-for-bots-cbb8665a2fd3?source=user_profile---------74----------------",
        "title": "Exploring dialog management for bots \u2013",
        "text": "When you work on conversational bots, you get to explore how robots best interact with people. Bots are meant to be a new way to communicate with machines. We can think of human-machine interaction as an input-output system. The keyboard and webcam are like the human senses, the screen is like the human face. When two entities send each other messages, they build a conversation, they communicate. For effective communication we need to introduce the importance of Dialog Management.\n\nImagine a world where machines are everywhere and interactions with them are systematic. What would be the most efficient way to communicate with them? Machines talk to each other in their own way: they use binary protocols at the speed of light, they use their own language. They can share hundreds of Gigabits of information per second. In this kind of environment, wouldn\u2019t it to be easier to learn to speak the machine\u2019s language? Humans, while polyvalent and adaptative living beings, are used to talking to each other in their own language. Human languages are adapted to our societies, our environment and they are most probably the best languages for our brains. Could we use our own languages to interact with machines? In a world of two factions, humans and machines, one side has to learn other side\u2019s language in order to grow. Learning a new language is time consuming and the human\u2019s time is precious, let the machines learn our languages.\n\nLet\u2019s say machines could understand human sentences and convey information in our languages. Would language processing be enough to meaningfully communicate with us?\n\nJohn : Hello, I\u2019d like a pizza.\n\nRobot : I ordered you a pizza, it will be delivered in one week in Shanghai Shi, Xuhui Qu, China.\n\nJohn : Hello.\n\nRobot : Hi.\n\nJohn : I am with four friends at Grand Boulevard, how do we get to La Defense?\n\nRobot : Go west and walk for two hours.\n\nThe Robot in the examples achieved what it was made for, but not in a useful way. We would like to have a pizza at home, maybe in 15 minutes. We would like to go to La Defense as soon as possible. Here the Robot is lacking information about John to fulfil his request, and John is lacking information about the robot to phrase his request better.\n\nFor the Robot to be useful to John, it has to discover what John is looking for. A better scenario would be :\n\nJohn : Hello, I\u2019d like a pizza.\n\nRobot : Hello, are you in Paris? May I ask you where you want the pizza to be delivered?\n\nJohn : At 45 bis rue du Pont.\n\nRobot : At what time would you like to eat please?\n\nJohn : At 8 o\u2019clock.\n\nRobot : What pizza would you like? Today\u2019s specials are Four Cheese Premium, Veggie Avocado and Norwegian in your area.\n\nJohn : I\u2019d like a pizza with beef.\n\nRobot : Here are three pizzas with beef : BestBeef Pizza from Pizza Minute 9\u20ac, BeefForever from Sergio 12\u20ac and Carnivore from Pizze Chef.\n\nJohn : I would like the pizza from Pizze Chef please.\n\nRobot : Let me summarize your order : one Carnivore from Pizze Chef, at 45 bis rue du Pont for 8 o\u2019clock. Do you want to add any delivery instructions? If not, we will call you at this number.\n\nJohn : Ok call me on this number.\n\nRobot : Your order has been confirmed by Pizze Chef.\n\nJohn : How do I get to La Defense?\n\nRobot : Could you tell me your location?\n\nJohn : We are at Grand Boulevard.\n\nRobot : If you want to go now, you can use the subway : Ligne A for about 2\u20ac, it will take around 30 minutes.\n\nJohn : Is there a faster way?\n\nRobot : I advise you to look at the Uber service, I can help you to book one.\n\nThe robot is trying to understand what the user wants. Ideally, the robot would read our mind which would save a lot of time. Time is a rare resource, if there are two paths to achieve the same result, the quickest path is preferable. How does this principle apply to conversation ? Let\u2019s play the Pizza order example again for the same result, John ordered a pizza he likes, but following a different path :\n\nJohn : Hello, I\u2019d like a pizza.\n\nRobot : Hello, are you in Paris?\n\nJohn : Yes.\n\nRobot : May I ask you where you want the pizza to be delivered?\n\nJohn : At 45 bis rue du Pont.\n\nRobot : At what time would you like to eat please?\n\nJohn : At 8 o\u2019clock.\n\nRobot : What pizza would you like?\n\nJohn : What are today\u2019s pizza?\n\nRobot : The today chef\u2019s pizzas are Four Cheese Premium, Veggie Avocado and Norwegian in your area.\n\nJohn : I\u2019d like a pizza with beef.\n\nRobot : Here is one pizza with beef in your area : BestBeef Pizza from Pizza Minute.\n\nJohn : How much is it?\n\nRobot : 9\u20ac.\n\nJohn : Are there other beef pizzas?\n\nRobot : BeefForever from Sergio.\n\nJohn : Is there a beef pizza from Pizze Chef?\n\nRobot : Yes, the Carnivore from Pizze Chef.\n\nJohn : I would like the pizza from Pizze Chef please.\n\nRobot : Let me summarize your order : one Carnivore from Pizze Chef, at 45 bis rue du Pont for 8 o\u2019clock. Do you want to add any delivery instructions?\n\nJohn : Should I give you my phone number or the door code?\n\nRobot : You can give me the door code, if not we will contact you on this phone number.\n\nJohn : Ok call me on this number.\n\nRobot : Your order has been confirmed by Pizze Chef.\n\nIn this example, there are many more exchanges for the same result. Some users may prefer it, some users might find the discussion too long. External factors influence the type of conversation you have with an interlocutor : Is it the first time you\u2019ve spoken to that interlocutor? Is your environment noisy? Are there any distractions? Is the conversation by text or over the phone? Are you in a crowded place? Do you trust your interlocutor? Did you just move to a new city?\n\nA new field of AI is born (again)\n\nThe instance described in the previous section is formalized in dialog management theory and our bots are dialog systems. Dialog Management is responsible for describing the flow inside a conversation and it is a growing research field in computer studies. One can think about Dialog Management as finite state machines, where the state transitions are based on the acquired information and the messages from the interlocutors.\n\nThe term Dialog Management isn\u2019t new though, the paper \u201cCombining Expression and Content in Domains for Dialog Managers\u201d from 1998 already tried to introduce a generalization of dialog managers in order to implement dialog manager development tools. More recently, a paper from A. Hunter discusses the process of debating, arguing and persuasion usingpropositional executable logic. Other works propose Machine Learning algorithms in order to build more complex state machines.\n\nIn dialog systems, bots are described with different roles, such as Information Providers, Advisors, Tutors, Conversational Partners and can be used for decision-making, multi-party interaction, persuasion andconflict resolution. Likewise, parts of dialog can be abstracted :\n\nQuestion then Answer\n\nPropose then Accept/Reject/Challenge\n\nOffer then Accept/Decline\n\nCompliment then Refusal/Thanks\n\nGreeting then Greeting\n\nFurthermore, global structures can emerge from the dialogs, for exampleOpening with greetings, Body with topics then Closing with farewells. Finally, understanding Topic Transitions, the ability to switch contexts and subjects, is a crucial part in developing more friendly conversations.\n\nWhen you\u2019ve played a video game, you might have chosen to engage Non-Player Characters or NPC. They are so-called because they look like human players, but they behave in a scripted manner. In essence, they are simple bots created for one specific task. Narrative video games, which are text-based video games, offer many decision paths to the player. A good narrative game should feel coherent and unpredictable, the illusion of a virtual world actually unfolding in front of the player should be total. Often, the path taken by the player is guided by the Game Designer. They use tricks to influence players\u2019 choices to control the path they take while maintaining the illusion of freedom of choice.\n\nTo represent the path a user can take, the dialog is compiled into a Dialog Tree. Dialog Trees are compact representations of the message sequence inside a dialog. Image from Roblox.\n\nWhen you build a Bot for the actual world, you face new challenges : a) the world and people are complex, it may be difficult to predict all the paths they may take and b) you cannot save checkpoints to go back in time."
    },
    {
        "url": "https://medium.com/chat-bots-developers/how-i-built-my-first-chatbot-d82e16e30482?source=user_profile---------75----------------",
        "title": "How I built my first chatbot \u2013 Chatbots Developers \u2013",
        "text": "As a new trainee in the Recast.AI team, the first thing I did was to build a Chatbot. Let\u2019s dive into it!\n\nFor my first week in the dev team, I was asked to build a little Chatbot, to handle the Recast.AI techno to help me really get to know what we were doing: an NLP platform for developers.\n\nFirst things first, what is a Chatbot?\n\nIt\u2019s important to understand that a bot is not an app, it\u2019s a bunch of code running somewhere that you can plug into existing apps, whatever they are. Alright! Let\u2019s plug our bot into Slack!\n\nIt has to be interactive, and much more than that, useful. It didn\u2019t take me long to come up with something. What if I made a bot that connects people to each other?\n\nThanks to Recast.AI NLP, I will make my program understand what the team is saying and make some suggestions.\n\nNow, let\u2019s make it answer their questions. Easy, I just have to know what they are talking about and provide a random answer! No way, that\u2019s not good enough, we have to make it interactive.\n\nLet\u2019s do this, what do we need? First, our bot has to be able to have simple interactions, like saying hello or goodbye. Easy, just create the corresponding intents on the Recast.AI platform and write some generic answers.\n\nThat\u2019s a good start, but we now need more interactions. The purpose of the bot is to connect people with each other, so let\u2019s make him ask people for their hobbies and things they like to do.\n\nAs we want it to connect people, we will make our bot able to retrieve information about activities people like or don\u2019t like to do, give them information about other people\u2019s hobbies, and suggest some activities they can do with other people in their Slack team.\n\nNow we\u2019re diving into a much more interesting and complicated part of a Chatbot: it has to remember things. Who is it talking with? What does it know about this person?\n\nFor this we will just add a little database to our bot to remember what each person likes or doesn\u2019t like to do.\n\nOf course we also need to train our bot to understand what people are telling it. We do this by adding an intent with a few corresponding sample sentences. We\u2019ll create an intent: activities and an entity: action.\n\nNow our bot will be able to understand what people like or hate to do, but it can also remember these for the next time they will talk to him.\n\nThat\u2019s great but let\u2019s go back to what we want him to do for us? What can we ask him? We could for example ask him what we can do with a specific person, to suggest something to do or, why not, what a person likes or hates.\n\nNice but how can we do that? Don\u2019t panic and keep coding, Recast.AI will provide us all the information contained in our users\u2019 sentences. What is he talking about, what type of sentence is it? Is he talking about a person, or an activity in particular? Well let\u2019s ask Recast after giving some examples to our bot.\n\nWell, someone wants to do something with Jerome, let\u2019s find them a shared hobby and inform him of their mutual interest. It may look limited, but the possibilities are infinite, we can now know if our user is asking for some general advice, or something more specific.\n\nWe just have to focus on what type of sentence it is and what it contains. If the input is Who can I play soccer with?, we\u2019ll know that the sentence is a \u201cwho question\u201d, and that the user is talking about playing soccer. Starting there, we can look in our memory for the users that like to play soccer and tell the user.\n\nIf the sentence is What can I do with Visjar? we\u2019ll know that the sentence is a \u201cwhat question\u201d and that the user is talking about someone. It now has to find out what Visjar and our user have in common.\n\nThe power of Recast is that it doesn\u2019t tell you about the words in the sentence, but much more than that: about their meanings. This allows us to deal with a wide range of sentences just by knowing the meanings of their contents and not the words themselves. The next thing is that Who can I play soccer with? and Who can I meet friends with? will be the same sentence for our bot. Recast.AI allows us to generalize by providing us abstraction of the sentence \u2014 e.g activities, enabling us to focus on the topic of the sentence. That said, let\u2019s code this.\n\nNice! Now our bot is able to understand different types of sentences, and gives information to people about people around them based on what they like to do, whatever that is.\n\nAs we said before, the fact that we are talking about soccer is not important. What is important is that we are talking about something, whatever this thing is. The Machine Learning inside Recast.AI allows us to give a few examples, and understand endless sentences, because what is important is not the word itself, but the construction of the sentence and the place of the word inside it.\n\nMaking this bot was given to me as an onboarding task at Recast, and it allowed me to understand what NLP and Machine Learning are, and even to get a foothole in the complexity of conversation management."
    },
    {
        "url": "https://medium.com/@RecastAI/a-language-a-day-keeps-the-boredom-away-d4180630c27e?source=user_profile---------76----------------",
        "title": "A language a day keeps the boredom away \u2013 RecastAI \u2013",
        "text": "It\u2019s been a month now since I joined Recast.AI on a mission to programSDKs for our community. Along with improving my Nerf shooting skills(they\u2019re really useful to turn the lights on from the other side of a room) and competing in the best salad competition, there have been so many amazing discoveries in a short time.\n\nSDKs \u2014 software development kits, are an interface between us here at Recast.AI and the developers who use our technology.\n\nWhat I absolutely love about them is that they come in different languages.Although I had experience in some of them, many were absolutely new to me.\n\nMastering the overall logic of a language makes the others easier to learn, even though it\u2019s always thrilling to discover a fresh new one. Because it\u2019s notjust a question of syntax. There is also the philosophy behind it. And a community, or the lack of it, ready to engage you in a never\u00adending war between this or that other language. Yes, kind of like Vim versus Emacs, spaces versus tabs or Hooli versus Raviga\u2026 To be a developer is to be a person of strong convictions!\n\nSo let\u2019s have a look at the highs and lows of writing a program in a new language.\n\nSo here I am, me and my new best-ever-beautiful and elegant language, ready to write some code of high efficiency and of great importance!\n\n\u201cHello, world\u201d, those two words became the symbol of programming tutorials. Each time I try a new language, the very first thing I do is print out those two famous words. It is not a question of tradition or of convention, and it doesn\u2019t really showcase the programming language it\u2019s written in. But each time I see this lovely couple, it brings me right back to my very first lines of code, and that incredible sense of pride and excitement I felt when it popped up in my terminal. And I still feel that way whenever I come across a new technology.\n\n\u2018Hello, world\u2019 represents the very first step into the unknown, when there is this strong attraction to dive a little bit deeper to uncover some more exciting secrets. Kind of like the discovery of the entry to an ancient temple for Indiana Jones\u2026\n\nAt this stage I am usually half\u00adway through my program, either reading somemanuals, or fighting against execution errors. It is the frustrating momentwhere I think I understand the language until something goes wrong, or not as I expected.\n\nAnd this is when you make contact with the community and get to find out how active it is. If the language is widely used, it\u2019s easy to find the answers to your questions. Two or three searches on your favourite search engine and you find yourself with plenty of links to stack overflow, where amazing people share their knowledge with those in need.\n\nBut if you are learning a really new or a more obscure language, and you don\u2019t know anyone who uses it, you have no choice but to start on the highly rewarding quest of finding your answers by yourself\u2026\n\nAaaaaand.. it\u2019s done ! You put in your last coma, everything is working fine, doesn\u2019t throw any errors, and it does exactly what you want it to do. Now that you have a better view of the language, it\u2019s time for the conclusion. I rarely go for \u2018why not\u2019. After writing a decent length program, it\u2019s usually either\n\nIf I don\u2019t like it, it\u2019s not a big deal. I\u2019ve still learned something new, and somehow improved my understanding of programming. It may even havegiven me some new insight into other languages.\n\nAnd if I like it, then it\u2019s just the first step of a long journey. It is a humblingquest: it doesn\u2019t matter how well you know a language, there will always besomething new to learn, a subject to master. And at that time, trust me, nothing feels better than having a great Team ready to share their experience with you!\n\nNow I\u2019m trying out Scala. And will definitely dive a bit deeper!"
    },
    {
        "url": "https://medium.com/chat-bots-developers/bots-sure-but-what-do-they-do-25d9eed40153?source=user_profile---------77----------------",
        "title": "Bots, sure, but what do they do? \u2013 Chatbots Developers \u2013",
        "text": "One of the questions I get the most is \u201cWhat is a bot?\u201d. It might seem obvious for tech guys but for the majority working in non-technical fields a bot is just a 3 letters word. A bot is a powered by Artificial Intelligence, usually software, that can converse with you. It is designed to automate tasks that you would usually do yourself, like booking a table at a restaurant, a flight ticket or finding out what is is showing at the local cinema. The most common form of bots are chatbots, they simulate conversation. They can live inside an app, a website or messaging app.\n\nIt\u2019s Saturday afternoon and you phone vibrates. \u201cAccording to your calendar, you have nothing planned tonight. The Garnier Opera says they have last minute seats for this ballet. What do you think?\u201d. You\u2019re not entirely opposed to some culture tonight but ballet isn\u2019t your cup of tea. \u201cWhy not, but are they any operas instead?\u201d. Your bot suggests an opera at The Bastille that suits you perfectly. Reservation and payment are made with your previously configured information. Your Saturday night is booked.\n\nThat is just one of many use cases where bots can be useful. One of the most interesting ones is the nurse bot. Lots of people in hospitals have disabilities. Sometimes they can\u2019t talk, see or move due to injuries or illnesses. This is where a bot could actually help them feel more secure. Imagine one of your relatives is staying in a hospital and is a tetraplegic. By just talking to a bot saying \u201cThis part of my body hurts\u201d the bot can provide support by choosing to call either the doctor or the nurse depending on the needs.\n\nSome bots handle a variety of simple service requests but as bot technology improves, they will be able to automate very complex tasks and understand the underlying intention of complex sentences.\n\nI guess now you\u2019re wondering how bots differ from apps. Couldn\u2019t we have bots within apps? Sure we could, but the purpose of a bot is to be decentralised. You do not install a bot, it will just be there within your contacts on your phone and you could just talk to it anytime you want. Let\u2019s take an example, why would you need an app for Deliveroo, Uber or your favourite airline? Wouldn\u2019t it be simpler to have a concierge bot within your contacts, Messenger, WhatsApp or any other messaging platform? You could just ask it whatever you want, whenever and wherever and it will get back to you. From a budget point of view building an app is quite expensive. You need to have Android and iOS development teams with a strong UX & UI designer. You need to test the app and submit it to app stores for approvals. And repeat the whole process for every update. Building a bot is way cheaper and allows you to reach way more people, because you are leveraging the fact that messaging apps are built by someone else.\n\nAnother very important thing to consider is the power of language, until now the domain of human beings. Language has evolved to become powerful, nuanced, and flexible. It allows humans to connect better, convey emotions and feelings. Good news \u2014 bots are catching up very fast."
    },
    {
        "url": "https://medium.com/@RecastAI/towards-an-augmented-dataset-cdf3b9b605ec?source=user_profile---------78----------------",
        "title": "Towards an augmented Dataset \u2013 RecastAI \u2013",
        "text": "In my previous blog, I wrote about the importance of dataset in Machine Learning (If you haven\u2019t read it yet, go check it out here!) and I succinctly outlined solutions and sources for you to build your own.\n\nBut one question remained: How can we simply create a trustworthy source of specialized knowledge that suits our needs?\n\nIn a recent post, spacemachine.net posted an interesting article comparing the importance of datasets and algorithms in the most notable breakthroughs in AI:\n\nThe take-away of this study is that even though progress in AI is considerable, the key solution to most of our problems resides in structured, qualified and valuable data.\n\nAs I said earlier, an algorithm provided with enough pre-treated and certified data will spot the underlying characteristics more easily and thus perform better, thanks to better data modeling.\n\nBut sometimes, we can\u2019t have a large database. We\u2019re limited to a small amount of data and we\u2019re forced to come up with a model based on it.\n\nThere\u2019s a field related to Machine Learning which does just that: data augmentation.\n\nThe principle behind data augmentation is simple: from already qualified data, we can generate more by modifying our base.\n\nThe main benefit or data augmentation is quite obvious: you get more data, and your training and/or testing set gets better.\n\nThe second one is that since we\u2019re adding noise, we get closer to real data, and can improve the measurement of a real-world behavior of our machine learning technique.\n\nData augmentation is most commonly used is image recognition, where deep learning shines. Let\u2019s take and example:\n\nLet\u2019s imagine a classification task where we need to classify an image as either our logo or an orange.\n\nLet\u2019s say, for the sake of simplicity, that we have one example in each class.\n\nThe goal here is to build a model capable of distinguishing the key observations (or features) we need to differentiate the pictures. With deep learning, we need to have a considerable amount of example for the algorithm to learn the model.\n\nObviously, such a small number of examples will lead to considerable overfitting, making our solution non-viable.\n\nThe reason overfitting occurs is because you\u2019re trying to learn distinctions from a limited dataset.\n\nWhen the algorithm will have control over the input, it will make sure it satisfies each and every one of the features, which is not what we want: we want it to generalize from a set of examples.\n\nBy rotating, mirroring, adjusting contrast, grayscale or randomly cropping our training sample, we can easily multiply our algorithm knowledge base: it is possible to generate new images from the original ones.\n\nImagining ways to do data augmentation with images is quite straightforward but what if we want to augment something like trading datapoints?\n\nWell the fact is, there\u2019s no defined way to create augmented data, but I\u2019ll propose some ways to enhance a text dataset:\n\nThe same scheme applies to text. We need to find ways to slightly modify the corpus we work with to have an augmented dataset whilst keeping the key points our algorithm needs.\n\nThe intuitive approach is to replace words with their closest synonyms: and even there, there\u2019s a few ways to do it:\n\nHere comes our old friend: WordNet (which I talked about in a previous article). WordNet is an ontology built at Princeton University, which models relationships between words, like synonyms, antonyms, hyponyms, and so on. For the record, lots of sites like thesaurus.com internally use WordNet as their knowledge base.\n\nHow can you beat that? Word embedding!\n\nWord embeddings are words represented as vectors, basically an array of variable dimensions, holding semantic information meant for computers to understand.\n\nThose mappings are meaningless on their own, but semantically similar words have similar vectors, and vector similarities are easy to compute. This can lead us to perform calculation with words:\n\nIf you want to go deeper about word vectors, I suggest this article from Christopher Olah\u2019s blog.\n\nIf you take a single word, you can retrieve closely related synonyms easily:\n\nUsing one of these databases requires a system to disambiguate the word we want to find the synonym for, which can be quite tedious, but we can imagine just generating data from non-ambiguous words.\n\nAnother fun approach would be to invert part of sentences which are opposed by words like \u201cbut\u201d, \u201ceven though\u201d, \u201calthrough\u201d to create a whole new formulation, while keeping the underlying meaning of the phrase.\n\nMoreover, we can even just strip away embellishments like adjectives, adverbs and so on.\n\nAnother benefit of data augmentation is to evaluate the quality of the model you just built.\n\nThe usual way of testing the model your created is to take the whole dataset and split it in 80\u201320. Then we use the former as training set and the latter as testing set. This leads to problems if the original dataset is shallow, because we end up by training our model with 80% of our already small dataset.\n\nFurther along the road comes what\u2019s called cross-validation, which aims to ensure that every example from the original dataset has the same chance of appearing in the training and testing set. This allows a complete evaluation the quality of the model trained with our data.\n\nThanks to data augmentation, we can thus compensate for our lack of entries, and do testing and validation without fear of losing important examples for the generalization to happen.\n\nIn short, data augmentation is a wonderful approach to solve several problems we might encounter whilst working with machine learning.\n\nSometimes, small datasets are all we got, and generating data can be a life-savior for both training and testing our model."
    },
    {
        "url": "https://medium.com/@RecastAI/subway-work-and-bed-or-startup-c40d5c9978c4?source=user_profile---------79----------------",
        "title": "Subway, work and bed\u2026 or startup! \u2013 RecastAI \u2013",
        "text": "\u00ab Subway, work and bed \u00bb is a very common French expression (We say \u00ab Metro, Boulot, Dodo \u00bb). It symbolizes the humdrum routine of people who are either unhappy with their work or spend their time doing nothing but work. At Recast.AI, it\u2019s much more exciting!\n\nWhen I started to work, I was hired by a small-sized company. It was exciting because we were all together, making the company develop.\n\nI was an IT guy, and involved in all aspects of the company. We were all in the same office and our days were dynamic and enjoyable. Everyone made decisions fast and effectively. We did the job and our boss was happy with that.\n\nBut, it was an e-commerce company and growth was difficult because of the business market. Despite that , they were some of my best ever years. And then :\n\nI decided to work for a big company in the pharmaceutical area, with about 7000 employees. Being an IT engineer, nothing I did had any impact on the decisions at the top.\n\nIt was disheartening for me every time I made a suggestion to increase IT efficiency or improve tools. It took weeks and weeks for it to be deployed on the websites or integrated into the office environment.\n\nMy boss was very understanding but when I asked him if the company could reduce the long delay between my proposals and their implementation, he answered : No. Why? Those are the rules\u2026. Boring.\n\nMy job was secure but I just didn\u2019t feel motivated enough so I decided to stop working there.\n\nAfter going back to school to increase my programming skills , the time came to search for an internship, as part of the training.\n\nRecast.AI sounded interesting and I had never worked for a startup. I applied, and here I am.\n\nIt was easy to adapt to the team\u2019s routine. There is a lot of work and the days are short but the ambiance is one of the best I have ever seen.\n\nWe can take breaks when we need them, there are no clocking in or out times, as long as the work gets done. The team is becoming bigger and bigger but the team spirit is always friendly, and the work is very exciting.\n\nToday, I\u2019m proud to be part of Recast.AI. As well as having all the advantages of the small company, we are in a very exciting market and things move fast! As a developper, I can see my work increasing the impact and visibility of the company, which is very rewarding.\n\nI think I\u2019m in the right place at Recast.AI: a company which is growing quickly, where the work you do is recognized and where you can put forward ideas and be part of the debate. Definitely, a startup is the place for me.\n\nMaybe you don\u2019t agree with me. If so, let me say one thing :\n\n\u00ab It doesn\u2019t matter where you work or what company you work for. Just be happy to wake up the morning, go back to work and do your favorite exciting job \u00bb. All the Recast.AI team feels that way every morning and that\u2019s why instead of being in the \u00ab Subway, work and bed \u00bb mode, we\u2019re definitely in the startup groove."
    },
    {
        "url": "https://medium.com/@RecastAI/working-with-developers-when-you-know-nothing-about-code-c5443ba2443f?source=user_profile---------80----------------",
        "title": "Working with developers when you know nothing about code",
        "text": "This is a story all about how my life got flipped-turned upside down and I\u2019d like to take a minute just sit right there and tell you how I became\u2026 the only non-tech person in a team of seven developers.\n\nArriving at 9am on my first day, I enter a room and to my disappointment it isn\u2019t overwhelmed by computer screens and laptops. The first morning was very pleasant and consisted of my new team helping me get set up and briefing me on the ongoing actions. They warned me that it was going to be very different from what I was used to. And boy were they right.\n\nIt was only after day four that I began to understand what they were talking about. Adjusting to a new job, new colleagues, new missions and a new environment always takes time but this was on a new level. The daily talks they had during breaks, over lunch or in the open space were utterly incomprehensible.\n\nLuckily, my colleagues were very helpful and explained everything on the spot. Not wanting to appear too clueless, I had to restrain myself from asking millions of questions and only focused on the things that really seemed to matter.\n\nDays pass. I learn what GitHub is, what machine learning is. I distinctly remember a coffee break where two colleagues had to use teabags, spoons and sugar cubes to explain how an API works.\n\nMore days pass. I occasionally whisper to my neighbor \u201chey, what does that mean?\u201d and as I\u2019m learning, my initial confusion turns to the utmost respect for the team. Coming from one of the great programming schools in France, I realize that my colleagues are extremely skilled at what they do. Their aura of technical expertise and exciting discussions keep feeding my admiration: the questions come flooding out.\n\n\u201cCan you do this?\u201d \u201cAnd that?\u201d \u201cYou can? That\u2019s INSANE\u201d. I see them type and go about their day working on what is like magic to me. And as I realize the world of possibilities that they are dealing with, I fully grasp the complexity and impact of our project.\n\nEven more days pass. I dive into this Artificial Intelligence and Machine Learning. My everyday tasks keep me in the real world, and training sessions with my colleagues start enlightening me on how Recast.AI works, what it truly does, how I should talk about it, pitch it, what it is, what it isn\u2019t.\n\nLunches remain blurred but thankfully, a little less so. I pick up terms and expressions and even understand what they mean. As my understanding of the team grows, my involvement in their daily brainstormings grows stronger. Until one day.\n\nIt all began with \u201cJustine, this week you should tell our users that we\u2019ve opened all our API endpoints\u201d"
    },
    {
        "url": "https://medium.com/@RecastAI/how-our-unpredicted-launch-on-product-hunt-happened-576d012dee1?source=user_profile---------81----------------",
        "title": "How our unpredicted launch on Product Hunt happened",
        "text": "Last week, we launched on ProductHunt! It was a huge boost for Recast.AI, but it didn\u2019t happen quite as we expected. Here\u2019s our story.\n\nA month ago, we got an invite from another cool company we know well: Craft.ai. We started planning our ProductHunt launch: what to do, how to do it, when, where, and why. We were planning to launch on Tuesday, 19th.\n\nWe registered our entire team on PH and joined the community. We upvoted cool projects, asked questions and there was generally a lot of excitement. What started as a need to bond with the community ended up being a real pleasure, and our team members are still active today on the platform.\n\nWe had joined Slack communities to get insights from companies who had already launched, we\u2019d read tons of articles on \u201cBeing in the top 5 of Product Hunt in 5 minutes\u201d. We combined actions to create more reach.\n\nOne question came up (among millions of others, rest assured): should we keep our waiting list or should we open up our platform entirely? By keeping the waiting list up, you risk loosing valuable users, but letting users test the platform right away, you risk a server overload. We chose the latter with a backup instance for the infrastructure, in case of emergency.\n\nWe set up our Intercom and our Slack Community to handle users\u2019 requests and allow them to reach us easily. We finally wrote down our introduction text, prepared visuals, tweets, people to reach out to, emails and lots and lots of candies.\n\nWe knew it\u2019d be hard and exhausting. We knew, as a French company in a different timezone, that we\u2019d spend the night in the office. But that was quite exciting.\n\nOn ProductHunt, when you submit a product, it goes to the \u201cnewest\u201d tab, and when you have enough upvotes, you\u2019re pushed onto the frontpage. At least that\u2019s what we assumed. With our friends and families ready, and faith in our product\u2019s quality, we were quite positive. We expected a true intellectual debate in the comment section, real insights about the future of bots and artificial intelligence, and so on.\n\nWe saw ourselves, tired but happy, the next morning, trending on PH\u2019s front page, and masters of the world. Well\u2026..\n\nIt didn\u2019t happen quite that way. Last Thursday 14th, we launched a new feature and posted Recast.AI on HackerNews. That brought us a lot of traffic. Out of the blue, one of our team spotted a \u201c?ref=producthunt\u201d on Google Analytics.\n\n\u201cWow. That\u2019s odd. Maybe they came from PH but by clicking on one of our comments.\u201d\n\nThen another user came from PH. Then three, then four. Then we had to face the exciting reality: somebody had posted us on Product Hunt!\n\nEverybody went into hardcore mode. I checked the status of our infrastructure, our communication manager finalised all our texts, tweets and emails, our designer updated our homepage, and others monitored PH and Google Analytics.\n\nIt boomed so quickly we were sure our servers wouldn\u2019t hold it together. They did. We quickly reached 50 people on the website simultaneously, with thousands of visitors per hour from all over the world.\n\nWe spent the night doing shifts, eating candy, and answering questions.\n\nIt wasn\u2019t quite the intellectual debate we expected, but we got great feedback from both PH and via e-mail. By the end of the night, we\u2019d reached 300 upvotes on PH, were #1 in Artificial Intelligence, on the front page as the 8th project, and got a growth of 250%.\n\nProductHunt was a great experience and team building opportunity for everyone. It was a terrific boost for us, now we have a real community engagement, lot of bots in development on the platform and great feedback and feature requests, so we work hard to deliver as fast as possible and keep this powerful dynamic going!"
    },
    {
        "url": "https://medium.com/chat-bots-developers/are-you-chatting-with-a-human-or-a-bot-df0826a5324b?source=user_profile---------82----------------",
        "title": "Are you chatting with a human or a bot? \u2013 Chatbots Developers \u2013",
        "text": "My story begins one week ago. At Recast.AI, the startup where I work, we opened up a Slack to welcome our community, so they could ask questions and give feedback. Last week one of our interns, Marian, started welcoming all the users arriving on our Slack, by saying \u201cHello\u201d at every first connection \ud83d\ude0a\n\nAnd very quickly the first jokes started appearing: \u201cMarian, the bot\u201d.\n\nThe day after, some users even asked us for the link to install \u201cMarian the bot\u201d\u2026\n\nMaybe you\u2019ve heard about chatbots, and maybe more so in these last few weeks. Microsoft released its bot framework, Facebook opened itsMessenger platform to custom bots, and so many startups have been popping up in this incredible bot world.\n\nBefore going further, let me briefly explain what a chatbot is. It\u2019s a service powered by artificial intelligence, that you interact with via a chat or messaging interface.\n\nThis service fits into your daily life and responds to many different needs, ranging from very precise and useful things to fun things. It can live in any major messaging application like Facebook Messenger, Slack, Telegram, Text Messages, etc\u2026\n\nWhat\u2019s happening with our intern is that in people\u2019s minds, bots are not so smart; they only understand what you are saying if you say the right command. They respond with the same sentence and they don\u2019t do humour or irony.\n\nSo when Marian started to repeat the same expression in the same context, people detected the pattern, the automation. And when you think automation, you think machine and bots.\n\nRemember the first chatterbot, a program that gives the impression of conversing like a human. It only works with some keywords extracted from the user input but doesn\u2019t understand or analyse the user\u2019s input to provide an authentic conversation.\n\nToday, real conversational bots exists, those which are powered by artificial intelligence.\n\nNo need for particular syntax or words when you interact with them.\n\nThanks to artificial intelligence, bot conversation has come very close to human conversation. It\u2019s more natural for the user, and the gap between bot and human conversation is closing.\n\nSo at this stage, I have a question for you. Would you prefer to know if you chatting with a bot or not? What impact will this issue have on the service and the user experience?\n\nMany services and startups provide assistants or bots with this headline: Human-supervised artificial intelligence. This begs the question: am I speaking with a bot, or a human? These services always arouse suspicion and it\u2019s exciting to solve the mystery. The user\u2019s emotion at this point is really interesting, and in itself is a factor that contributes to a great user experience.\n\nWhat if you know you\u2019re chatting with a bot? You will probably be more demanding, it\u2019s a process, a service. You are likely to have less empathy than when you talk with a human, and maybe you will be more frustrated if it makes mistake. But the bot is still learning, and I think people are willing to forgive. It\u2019s like a child, he\u2019s allowed to make mistakes, he will learn. This image of a smart funny child is really important.\n\nBots can, with a touch of humor, and with great conversation, impress users. Like a child who suddenly did something very smart and whose parents are very proud.\n\nOn the other hand, a bot that tricks us into thinking its a human, by adopting human characteristics and not revealing its true identity, will seriously disappoint the user and ultimately provide a poor experience.\n\nWhat happens when you speak with other humans?\n\nYou share your feelings, your wishes, your understanding of the world. If you chat with someone you think is human but in fact isn\u2019t, or a bot with a human \u201cappearance\u201d, like a little avatar with a human name, you will be extremely frustrated.\n\nBots must adapt to humans, but should definitely not pretend to be one."
    },
    {
        "url": "https://medium.com/chat-bots-developers/understanding-words-to-understand-language-1aba98a97764?source=user_profile---------83----------------",
        "title": "Understanding words to understand language \u2013 Chatbots Developers \u2013",
        "text": "At Recast.AI, we use Natural Language Processing (NLP) as a way to enrich input from users, and context is an important part of the process. When we handle a user\u2019s request, we decide whether or not it matches an intent, which is the general meaning of a sentence. In order to do that, we need to understand what the user is saying by analyzing the context and the meanings of each word.\n\nOne day, I came across a sentence our software couldn\u2019t categorize correctly. It was a simple sentence, only 7 words:\n\n\u201cThe workers at the plant were overworked.\u201d\n\nOur current program wasn\u2019t capable of understanding the meaning of plant, failing over and over to understand it as an industrial facility.\n\nAfter a few searches, we found lots of papers on the problem, and from here we began to explore one of the oldest unresolved issues of NLP.\n\nThe task of Word Sense Disambiguation (WSD) consists of selecting the best sense for an occurrence of a word in a given context. In our case, we had to find the correct sense for the word plant.\n\nThis issue was discovered at the creation of Machine Translation (roughly in the 40s), and is still unresolved now.\n\nResearchers tried various approaches, from rule-based to probabilistic systems, through fine grained knowledge base and automated knowledge extraction. All these efforts weren\u2019t enough to solve this problem.\n\nTo give you an idea, let me show you a list of algorithms and Machine Learning techniques used in WSD:\n\nEvery solution has its pros and cons, but the state-of-the-art in theSupervised Machine Learning field is achieving more than 90% accuracy.\n\nOur goal was to find the best compromise between simplicity and efficiency as our first implementation.\n\nThe underlying problem resides in the fact that every word can have really different meanings. Finding and selecting the right meaning for the right context is decisive for the comprehension of natural language.\n\nHere come WordNet, a lexical database for English. It groups words into synonym sets, providing short definitions and examples, and records the relationships between those groups.\n\nThe differents meanings of plant in WordNet\n\nWordNet allows us to retrieve synonyms, antonyms, and different forms ot a word. For each of these, we get a definition.\n\nOnce we have collected all the definitions of each word in the sentence, we use the Lesk algorithm to compare their similarity.\n\nThe Lesk algorithm (Michael E. Lesk, 1986) is based on the assumption that words in a sentence will share a common topic. The idea is simple: We take all the possible definitions of each word in a sentence and select the definitions which overlap the most.\n\nWe can represent this in a simple diagram, see below:\n\nWhat\u2019s really interesting with this diagram, is that it shows the similarities between the Lesk algorithm and the way our brain works.\n\nBy using a knowledge base and this crafted \u201cbrain\u201d, we can now select the best sense for the word plant in the context of our sentence, allowing us to generate its synonyms, antonyms and so on.\n\nWord Sense Disambiguation is used to know the sense of a word thanks to a given context. And it allows us to perform automatic translation, and even the the first stages of language generation.\n\nToday, bots and AIs have proven they\u2019re on the way to understanding language, but the next step \u2014 and most important one \u2014 is for them to be able to answer us by themselves!"
    },
    {
        "url": "https://medium.com/@RecastAI/how-can-a-developer-work-with-audio-files-97e98ee9d579?source=user_profile---------84----------------",
        "title": "How can a developer work with audio files? \u2013 RecastAI \u2013",
        "text": "I bet you all used to have an mp3 player. And after buying it, the first thing you did, was copy your favorite music file into it. You know, these files ending in \u201c.MP3\u201d or \u201c.WAV\u201d on your computer.\n\nBut what are these files and what are their contents? Before explaining what a sound/audio file is, I need to explain what sound is! You remember those boring physics lessons at school? Now, words like \u201cWavelength\u201d, \u201cfrequencies\u201d, \u201cintensity\u201d might be coming back to you, so let\u2019s get started!\n\nFor humans, sound is something you can hear. Good. But for scientists, sounds are much more.\n\nIn physics, a sound is a vibration which moves through a medium. It\u2019s amechanical wave like those produced when you skim a stone.\n\nBut to travel through this medium, it must be a \u201cmedium with internal forces\u201d.\n\nThis is a medium in which things can move : air and water are good examples. A vacuum is not this kind of medium because here things can neither move nor be moved.\n\nSo, we know that a sound is a vibration which moves through a medium. But how?\n\nThink about the stone skimming again. First you see the ripples the stone makes. Then they become thinner over time, and the distance between peaks \u2014 wavelength \u2014 increases. In this case, the wavelength increases with time.\n\nSo, wavelength modifies wave and so sound. But there are the other things that can modify sound, such as \u201cIntensity\u201d or \u201cAmplitude\u201d. Back to our stone skimming.\n\nWith time, the human eye cannot see the wave anymore. This is because of the wave intensity, which over time, decreases. It\u2019s like a car on a straight road, eventually it will come to a stop when you stop accelerating. It\u2019s the same fact for a wave. Intensity naturally decrease over time and then stone bounce wave can not be seen. So, sound wave can not be heard over time.\n\nMy next question is : What is the difference between a treble sound and a bass sound? To keep it simply, a bass sound has a low frequency and a treble sound has a high frequency. This difference is called \u201cpitch\u201d. Humans can hear sounds between 20Hz and 20 000Hz. But dogs can hear sounds from 64Hz to 44 000Hz and cats from 55Hz to 77 000Hz!\n\nBack to mp3 player and mp3/wav files. These files contain sound data, and we can think frequencies and intensities are moving while the audio track is playing. Let\u2019s see it in more detail.\n\nAt the beginning, I talked to you about \u201c.MP3\u201d or \u201c.WAV\u201d files. Let me explain what is the difference between these two audio files types.\n\nFirst, let\u2019s have a look at \u201c.RAW\u201d files.\n\n\u201c.RAW\u201d files, created in the 20th century, are audio files which contain audio data \u201cas-we-hear\u201d. Data are uncompressed and rawed (good choice). To play audio data from these files, user must specify many properties: bits per sample, sample rate or number of channels (mono vs. stereo). It\u2019s not very convenient for daily users.\n\nAfter many years, in 1991, \u201c.WAV\u201d file was released, by Microsoft and IBM. Real name is \u201cWaveform Audio File Format\u201d. The file size is around 10 Megabits per minutes of sound with uncompressed data, which was huge in the 90\u2019s. This file contains audio data but at the top of the file, there are some \u201cheaders\u201d to indicate the music player software all properties : data type, bits per sample, sample rate or number of channels (mono vs. stereo), etc\u2026\n\nWith this, the end user does not need to specify them like he must do with RAW files.\n\nIf we think for a minute, we can say : \u00ab Okay, so if I can specify the data type in \u201c.WAV\u201d file, can I put some others formatted data in a \u201c.WAV\u201d file? \u00bb The answer is : \u00ab YES \u00bb. You are allowed to put mp3 audio data in a \u201c.WAV\u201d file! The only thing you should take care of is to modify file headers to indicate the music player software it\u2019s a mp3 data file.\n\nAt the beginning of the 21st Century, with the advent of the Internet and File Sharing, we looked for some other data format to reduce file size. Now it\u2019s time to talk about compression!\n\n\u201cMP3\u201d means \u201cMPEG, audio layer 3\u201d. \u201cMPEG, audio layer 3\u2033 is a scheme for the compression of audio signals. The MP3 audio file contains headers, like\u201d.WAV\u201d file, but the audio data are \u201ccompressed\u201d.\n\n\u201cMPEG, audio layer 3\u201d compression detects sound data that are inaudible for humans (you know, sound data not below 20Hz and above 20 000Hz) and removes them of the file. We now have a file with one-tenth the size of an equivalent \u201c.WAV\u201d file (eg. 1MB per minutes of sound). Today it\u2019s the most used audio data format.\n\nBy clicking \u201cplay\u201d on your mp3 player, sound data can be heard by humans. Your mp3 player analyzes the sound file and make headsets or speakers vibrate. Many sounds can be emitted from a speaker and the difference between a treble sound and a bass sound is the vibration produced by the speaker. So, signals transmitted to the speaker are not the same for a treble sound and a bass sound. Let\u2019s check our file data!\n\nI want to talk about audio in programming, not in terms of playing sounds but recording sounds. At Recast.AI, we can use audio files or sound streaming to perform Natural Language Processing on your voice. What we have to do when you press our streaming button is: record your voice, transmit data and then analyze your speech to give you back the result.\n\nIn our time, almost all devices have built-in microphone (smartphones, tablets, computers, and even your car!). The deal is to manage the connection between hardware and software. For many of these devices, brands implement software facilities for manipulating the hardware and receiving data from it (called Libraries, Frameworks or SDKs).\n\nTo explain how developer can work with files, let\u2019s take the computer example. Did you ever seen this pop-up while navigating in the Internet?\n\nBy clicking on the \u201cAllow\u201d button, you authorize the website to capture the built-in microphone data. So, at this time, your voice and ambient sounds are temporarily saved in an array, until you click on \u201cStop record\u201d or until the website stops recording. The developer now has, an array with many data. The array looks like this :\n\nThis array is called a \u201cbuffer\u201d. If you look at each values of this array, we can see all values are greater than -1 and smaller than 1. By convention, a float number is an audio sample and the value of a float number is the amplitude of the audio signal.\n\nWhen recording is stopped, your buffer is filled. To finish the process, and create a real \u201c.WAV\u201d file, you just need to set the \u201cheaders\u201d, that match the recorded data format.\n\nFor real, the data part of the file is not a human readable array but a sequence of these numbers, converted to binary format.\n\nAll those processes and values of the array depend on hardware and audio specifications. Bitrate, bits per sample, number of channels and other sound properties make headers and data buffer change.\n\nMany apps work with this data manipulation. All audio players, like iTunes and VLC, all audio editor softwares, like Audacity or Adobe Audition, and usually, all softwares playing or recording audio files can read file with PCM.\n\nBy the way, manipulating audio data in programming is easier than most of developers can think! At Recast.AI, we now use audio file and speech streaming to perform NLP on your voice."
    },
    {
        "url": "https://medium.com/chat-bots-developers/are-we-ready-to-further-integrate-technology-in-our-lives-411732022e05?source=user_profile---------85----------------",
        "title": "Are we ready to further integrate technology in our lives?",
        "text": "Today\u2019s tech companies all agree: Artificial Intelligence is the next big thing. Google has opened up its machine learning platform, Microsoft has experimented with conversational bots, the Internet of Things has started to boom. They are all striving to reduce the distance between humans and machines. Why?\n\nWe\u2019ve come a long way from Turing\u2019s first computer to today\u2019s laptops. Back then, interactions with computers were reserved for trained scientists. Through the years, devices have become more approachable. When I turned six, my father bought the first computer for his company. We discovered uses for software we had never dreamed of; we started playing increasingly advanced games, and now the computer that used to take up a whole room fits into our hands. But do you know what hasn\u2019t changed at all over the past sixty years? It\u2019s the way we communicate with the devices. The keyboard has been going strong for decades and today, we cannot replace it: nothing matches its simplicity and efficiency.\n\nI am not a developer. I\u2019m not an engineer. I am just a 22 year-old who learned to use a laptop growing up and went with the technological flow. And when I heard I could wear a cellphone on my wrist and easily tell it what to do for me, I was sold. For real. Or so I thought.\n\n\u201cOk Google, remind me to buy some bread at 6p.m\u201d. The watch sets up a reminder with the title \u201cbuy bread\u201d at 6p.m, fantastic. Then it vibrates on your wrist as expected and reminds you to buy some bread. As a user, that is the best I could get out of my watch. Why ? Because it\u2019s natural. Apart from the \u201cOk Google\u201d, the sentence is basic and intuitive enough for humans to do without too much thought, and clear enough for the watch to understand.\n\nIt is the only vocal command I use, because it truly saves time compared to getting my phone out of my pocket, and it works well.\n\nOther commands require preparation. During the first week, all excited, I tried \u201cOk Google, send a message to Lucy saying that I\u2019m on my way\u201d. Doesn\u2019t work because \u201cmessage\u201d is not specific enough. My second try was \u201cOk Google, send a SMS to Lucy saying that I\u2019m on my way\u201d. That worked to a point, but then I was asked \u201cwhich Lucy?\u201d and had to use the touchscreen to select the right person. If you want it to work flawlessly, you need to add the person\u2019s surname. Then yes, it will work most of the time.\n\nBut just think about what actually happens. Before sending a text, you need to remember to specify the kind of message, then you need to use the full name in your contacts, you need to make sure that you\u2019re in a quiet place, don\u2019t mumble or mispronounce anything. Quite the mission!\n\nWhat\u2019s missing? Real conversation. And we can\u2019t really blame the manufacturers! It\u2019s a hard task to create a machine that easily understands you. Preparing the sentence in your head beforehand might be fun for the first week, but you quickly lose interest, go back to your old habits and get your phone out.\n\nWe have evolved with technology, and now expect immediacy. Everything has to fit into our lives naturally and rapidly, and that\u2019s what\u2019s lacking here. I have no doubt that in the future, smart objects and voice controls will be the norm. But right now, they are not. We don\u2019t need voice controls, we need conversation, or at least natural understanding. I don\u2019t mind if my device can\u2019t speak back to me yet. What I do want is for it to understand everything that I ask.\n\nNow, let\u2019s take a trip down future lane.\n\nJust imagine a world where phones are even more integrated in our lives. And take a step further: imagine a world with no phones where we can communicate and share even better than now?\n\nMultinationals agree that AI and smart devices are the future, and they\u2019re right. Wearables will create an aura of connection around everybody and will provide human-machine interaction in its most natural form. No more keyboards, no unique device that links us to the internet, but a multitude of devices that all interact with us and each other. This means important improvements in the world of science and goes beyond what we have today in terms of UX, miniaturization, battery life and data storage. \n\nA very common criticism of wearables comes from the idea that stronger integration of the digital will completely cut us off from reality. I disagree. This brilliant article from H\u00e9ctor L. Carral gives you great insights.\n\nWe already feel like we have access to the world\u2019s entire knowledge and history on the internet. That might be true. It is a beautiful tool. But anybody present on the social media scene can agree that we are in a content-flooded era. There are so many things to see, read, and learn about that you end up ignoring it all. What is starting to happen is personalized content. Websites in future won\u2019t be generic anymore. Everybody will have a different version, based on likes, dislikes, interests, opinions.\n\nAt home, you\u2019ll have it all: sensors at your doors, live health monitoring with wearables, automatic grocery shopping from your fridge, and so much more.\n\nSome of these products are already available but lack integration because of the traditional way we design houses. Unless we\u2019re talking about your alarm system or your internet box, nothing is connected: not your bathtub, not your fridge, not your lights. This will change. Nest is already making changes by connecting your heating and security systems. Multimedia brands are creating interconnected entertainment units: for instance, Apple has the sound (iPod), television (Apple TV), computer (Macbooks) and mobile (iPhones) all transversal. This will only go further, and you can read about it in another one of our articles.\n\nAnd it won\u2019t stop at the walls of your house. Your city will be upgraded: imagine a traffic sensor at every traffic light for live updates, or no more traffic lights in quiet areas, just \u201cgo\u201d and \u201cstop\u201d smart signs adjusting to the situation in real time. All of this linked to our driverless smart cars. Streetlights will be automatic and speech activated for emergencies on the streets. Public transportation will change: grocery shopping in the subway, \u201choverboards\u201d everywhere, augmented reality GPS. That\u2019ll involve trains and planes too. And so much more.\n\nAre you excited yet? Can\u2019t wait to experience this hassle free life? I know I can\u2019t.\n\nToday\u2019s tech companies all agree: Artificial Intelligence is the next big thing. Keyboards will be replaced by natural communication. And you know what?I couldn\u2019t be happier.\n\nStart talking to your microwave. It will soon talk back.\n\nThis post was originally published on our blog."
    },
    {
        "url": "https://medium.com/@RecastAI/github-8-things-you-didn-t-know-it-could-do-af721f17737c?source=user_profile---------86----------------",
        "title": "Github: 8 things you didn\u2019t know it could do \u2013 RecastAI \u2013",
        "text": "Due to a great Readme.md viewer, Github inspires lots of users to use this file format to publish content, and not just use it as part of the documentation repository. We have a great example here with the French Civil Code: https://github.com/steeve/france.code-civil.\n\n\u201cIf we consider the laws as a collection of texts modified by the various assemblies of the State, they can be considered as a set of text files created collaboratively. [\u2026]\n\nGit not only allows viewing sources at a particular point in time (snapshot), but allows you to easily view changes in these sources (commits)\u201d.\n\nThis means you can navigate through the Civil Code and through time :). Their clear interface shows the changes in each line for each commit, like this one for the \u2018wedding code\u2019: b805ecf05a86162d149d3d182e04074ecf72c066"
    },
    {
        "url": "https://medium.com/@RecastAI/ai-natural-evolution-to-a-brighter-future-efd3507289f2?source=user_profile---------87----------------",
        "title": "AI \u2014 natural evolution to a brighter future \u2013 RecastAI \u2013",
        "text": "\u200bBeware this article may contain spoilers! Here is a list of AI movies you should definitely watch.\n\nI guess I first realised what AI meant when I was watching A.I. Artificial Intelligence: a small boy could technically be replaced by a robot, expressing his feelings, thinking and learning things like a real human. What struck me in the movie, was that no matter what the robot did to be like a real boy, it seemed to stop him from being accepted as a son. It seemed inevitable: Humans & AI could not coexist in the same Universe.\n\nThis actually happened in a lot of movies like HER where Samantha can no longer stay within our human world and all the OSes need to go away in order to evolve.\n\nApart from being incompatible with humans, AI is also often portrayed as dangerous for humanity.\n\nIn 2001 : A Space Odyssey, HAL 9000 needs to be shutdown by the crew to prevent more serious malfunctions. HAL starting to see the crew as a threat, plan to kill the astronauts.\n\nIn Terminator, Skynet \u2014 a self-conscious AI \u2014 assumes that humanity would try to destroy it. In order to prevent its destruction Skynet seeks to destroy the human race.\n\nThe list goes on and on: Ex Machina, TRON, The Matrix, I Robot, etc.\n\nAI is like the new car back in the 20\u2019s when people were perfectly happy with their horses and afraid that this new machine would crash doing 30 miles an hour.\n\nLet\u2019s try to clarify some misconceptions about what AI is, can and can\u2019t do:\n\nFor now, no one is trying to build a self-conscious AI, mainly because we don\u2019t know how to do it yet; also it\u2019s not the point. Self-consciousness is more about neuroscience that it is about programming.\n\nAI will most likely have emotions but that may not always be the case, as stated by Yann LeCun Facebook\u2019s Artificial Intelligence Research Director:\n\nThe point is AI doesn\u2019t wake up the morning and want to rule the world, destroy humanity or be the next Matrix and use humans as a power source! It\u2019s not because it\u2019s AI and it\u2019s learning that it will learn how to be selfish, destructive, etc. We shouldn\u2019t assume that AI will evolve the way we did asits needs will be different.\n\nHopefully it\u2019s not all bleak! A few movies show AI as it should be: I personally loved TARS & CASE in Interstellar, two brilliant AI robots endowed with a sense of humour helping Cooper\u2019s team through the whole story. They are just very good at what they do, they have this little something extra that humanises them. They are still robots and their main focus is to make the mission a success while taking care of everyone on board.\n\nIn a different way there is WALL-E, the lovely waste-collecting robot capable of falling in love with another robot and willing to save humanity. Its only concern at the beginning of the movie is its job, even if it is the only survivor and all the other waste-collecting robots are now inactive.\n\nProminent and well respected figures like Elon Musk, Bill Gates, and Stephen Hawking have endorsed the thesis that AI poses an existential risk. These concerns have led to the creation of Open AI a non-profit research company that aims to promote open-source and friendly AI. Lots of big tech companies open sourced their AI or their technologies like Google with TensorFlow, Amazon with Alexa, Facebook\u2019s M or Microsoft using Minecraft to train their AI. Even the military with DARPA making a big push toward open-source machine learning with forge.mil.\n\nThese initiatives are based on our fear of AI becoming so powerful that it can harm and endanger humanity. This is why we need to control it. But AI is simply a natural and inevitable evolution and it doesn\u2019t need control: it needs education.\n\nWe\u2019re building a collaborative, caring and sharing AI community. In that way everybody can contribute, monitor and play a role in building a scalable AI for everyone. I\u2019ll end with an quote from Stuart J. Russell, a professor of computer science at the University of California, Berkeley:\n\nAI at its best could be omniscient and powerful, the question is: will it be used for good or evil? Like a child that learns values from its parents, that\u2019s up to us developers to teach values in the best interest of humanity. That is our goal at Recast.AI so hop on board with us and help us build the future of AI!"
    },
    {
        "url": "https://medium.com/chat-bots-developers/datasets-the-gold-of-machine-learning-17bea3a70ef1?source=user_profile---------88----------------",
        "title": "Datasets, the gold of Machine Learning \u2013 Chatbots Developers \u2013",
        "text": "In this article I\u2019m going to explore Machine Learning, but if you\u2019re completely new to this, I recommend you take a look at @ageitgey\u2019s \u201cMachine Learning is fun!\u201d\n\nIn the connected era, data we can collect from users is internet gold.\n\nCompanies and advertisers are exchanging parts of our lives in the form of cookies, preferences, browsing habits and logs.\n\nAfter the emergence of buzzwords like Big Data, Data Mining, Data Analytic the last few years, we now have Machine Learning and Deep Learning.\n\nHere are two quick definitions, so we\u2019re sure we speak about the same things:\n\nBig Data has been defined by McKinsey Global Institute as\n\nMachine Learning, as defined by Tom M. Mitchell is\n\nThe relationship between Big Data and Machine Learning is simple, if you have data (be it a robot\u2019s sensors outputs, users\u2019 queries, photos, sounds\u2026) you can learn to recognize patterns in it and thus predict or classify those patterns.\n\nSo, in the previous definition of Machine Learning, the experience E is in fact data.\n\nThere\u2019s two types of data, unlabeled and labeled.\n\nUnlabeled data (the kind we talk about with Big Data) is generally processed through Unsupervised Machine Learning (UML) to cluster it, or find patterns which will be helpful to further take advantage of this kind of information. In other words, UML uses unlabeled data to tell us where to look in it, and what can we get from it.\n\nOn the contrary, labeled data is.. well, labeled, meaning that we already know what we want from it, and how to use it. In this case, the Supervised Machine Learning (SML) will help us classify an unknown request we receive.\n\nApart from the type of dataset they require, Unsupervised and Supervised Machine Learning differ in the amount of information they need to perform well.\n\nIn fact, since UML does not have access to tagged data, it require huge amounts of information to spot and analyze patterns.\n\nAnd since the SML has already labeled data, thus making it more valuable as a trusted source, it needs a lot less knowledge.\n\nI\u2019ll make a pause here, to properly illustrate my point. Imagine two people learning a new skill, like glass-blowing:\n\nOn one hand, the first decided to learn on his own, using his tools. He will spend a lot of time practicing, failing and retrying to be able to create a well-manufactured glass.\n\nOn the other hand, the second one is helped by a master glass-blower, who is teaching him all the proper ways to craft a glass.\n\nIt is quite obvious that learning from the master himself is faster than learning alone, because you need a lot more time to learn from your own mistakes.\n\nA SML algorithm needs a trustful source of knowledge to create his model: the gold dataset. It is called \u201cgold dataset\u201d because all of the entries in it should be valid, and are used to architecture the representation of the data the algorithm has.\n\nYou understood it, the better the gold dataset, the better the result.\n\nThe main problem is that the process of transforming raw data into labeled datasets is really time and resource-consuming, because you need to go through every line of your data and label it manually.\n\nThus, everyone is keeping his own dataset secret, in order to keep an advantage over its concurrent.\n\nAnd it is a huge problem for developers who want to try and play with Machine Learning, because most of the datasets you will need are either expensive, or just inaccessible.\n\nHowever, it is still possible to find specific purposed dataset, coming from Conferences and Shared Task such as CONLL or MUC. There is also community efforts to create formatted databases: DBpedia or Freebase.\n\nTo us, the way we need to create the perfect gold dataset is to allow everyone to use it and build it. By bringing together developers, using different languages, and from different cultures, we can build a community willingly participating at the creation of tomorrow\u2019s AI.\n\nWikipedia disrupted the sharing of knowledge by allowing people to add, update and consult knowledge for free. 42 (a French school teaching developers) decided to encourage its students to work in group via a method called \u201cpeer-learning\u201d, completely at the opposite of the the current educational model, where sharing is cheating.\n\nThat\u2019s what we offer, let\u2019s all cheat to create the best conversational AI!"
    },
    {
        "url": "https://medium.com/@RecastAI/ui-and-ai-the-next-interface-is-conversation-43400caa1b1a?source=user_profile---------89----------------",
        "title": "UI and AI: the next interface is conversation \u2013 RecastAI \u2013",
        "text": "Yesterday, my mom, my little brother and I, went on a trip from Paris to Brussels . My mom was excited to show off our new car \u201cIt\u2019s even got heated seats\u201d! Fine, the car was well equipped for the long journey, but we started having problems very soon. When we tried to do little things like defog the windscreen, everyone was very confused!\n\nEverything can be controlled through a touch screen. This is an evolution, after the dashboard with all those buttons. But the screen isn\u2019t really either natural or instinctive. Yes, they have removed the multitude of buttons and the \u201cone button, one action\u201d system, but they\u2019ve added the complexity of understanding the interface. Now you have to remember the path to find your button, use the right pressure on the screen to get what you want and all of this when you\u2019re driving.\n\nSo when my mom wanted to defog the windscreen, she needed my little brother to help. He had read the whole manual the day before. After a few attempts at navigating the interface, he finally managed to trigger the air in the right place.\n\nI don\u2019t blame the graphic interface or the touch screen, it was no easier with the last car and all its buttons.\n\nBut evolution and innovation are supposed to make our lives simpler, right? And remove daily frustrations between humans and machines.\n\nMachines are complex, but interfaces shouldn\u2019t be.\n\nIt\u2019s difficult to imagine a future totally without GUIs (Graphical User Interface), but this will come to an end. With Conversational User Interfaces (CUI), human-machine interaction will be changed forever.\n\nIn CUI, conversations means natural conversations, those everyday human exchanges. The CUI is more than just speech recognition, it\u2019s an intelligent interface.\n\n\u201cIntelligent\u201d because it\u2019s a real process with an input, a memorization, a true comprehension and a final decision; it doesn\u2019t just recognize the words as a text transcription. It\u2019s not like talking slowly to Siri, or another app, it\u2019s about talking to the interface.\n\nThis is going to be the next big innovation, for one simple reason: human nature.\n\nCUI will know that when you say, \u201cI would like to see the Doctor tomorrow,\u201d that what you need is to find a doctor, book an appointment and add the event to your calendar. No more devices, new apps, or keyboards, just natural speech. This will change people\u2019s lives!\n\nWith these interfaces we won\u2019t have to adapt to the machine anymore. Machines will learn and understand our natural language, they will adapt to us.\n\nSo, let\u2019s just imagine my Mom\u2019s next car with its conversational user interface.\n\nNo time consuming manual reading. No frustration when she\u2019ll need to defog or turn the heater on.\n\nShe will just ask her car, and the car will not only do what she wants, it will learn and remember her preferences.\n\nDriving will be safer, interacting with a screen is like using your phone: dangerous, and ridiculously tempting.\n\nMy little brother won\u2019t have to teach my mom how to use tech anymore, it will be \u201cnatural\u201d. She will interact with her car like all other devices, her phone, her watch, her home.\n\nTomorrow we will have more time to spend on more creative things.\n\nSee you there!"
    },
    {
        "url": "https://medium.com/@RecastAI/new-ai-powered-devices-we-ve-tried-them-e8742069142e?source=user_profile---------90----------------",
        "title": "New AI-powered devices \u2014 We\u2019ve tried them! \u2013 RecastAI \u2013",
        "text": "At Recast.AI, we love AI-powered devices for everyday life and we\u2019re always testing new ones.\n\nOur latest tests were on the Amazon Echo, the Apple Watch and the Apple TV.\n\nThe Amazon Echo is basically a speaker which can answer an awful lot of your questions. At first sight, it\u2019s well designed and built. The blue light on the top which knows where your voice comes from, is really cool.\n\nWhen you turn it up the first time, simply connect it to the Wifi, add your Amazon account and you\u2019re ready to enjoy it.\n\nThen we got to the interesting part. AI\u2019s name is Alexa, what it mainly does is set a timer, play music and get information (especially about sports and geography). One thing we liked is that it uses the context: if you don\u2019t like the current song, tell it and it\u2019ll say \u201cok\u201d, memorize it and change the song!\n\nYou must have a good English accent but it understands well. The sound is great and it\u2019s always in listen mode! So you just have to say \u201cAlexa\u201d before your request! Very useful, and makes up for the fact that it doesn\u2019t have a battery, and you can\u2019t carry it around with you.\n\nThe use may be limited for now, because your Google Voice or Siri already plays the smart assistant, they\u2019re always listening too (Siri \u2014 iPhone 6S), and always with you. Moreover, all functionalities are not available worldwide. Amazon Music is available only in the US, and Alexa without the music (yep, it\u2019s only with Amazon Music) is less interesting. The Amazon Echo has an API. We tried it quickly, it\u2019s quite complete, but complicated and boring to setup.\n\nWe had lower expectations than for the Google Voice or Siri, but we were pleasantly surprised and had a good feeling about it. Let\u2019s see when all functionalities will be available worldwide!\n\nThe new Apple TV is our second test. Once plugged-in (3 wires, easy), you have a 5-minute setup, so faster than the Amazon Echo. Then the interface is really cool, but not really different than the older one. It does have the App Store now, which allows you to download numerous and various apps. Then, Siri is what interested us the most. At first, we were a bit frustrated because you have to keep your finger pressed on the remote to talk to Siri! Strange for a device plugged into AC power while the iPhone 6S is always listening to you even on battery mode. So that makes it impossible to use your Apple TV as a smart assistant like the Amazon Echo. But the integration is pretty good: you can ask for search, suggestions, movies, musics, games and control your AppleTV by voice. It\u2019s more like voice-enabled navigation. We expected more cool things like switching to various TV channels depending on the topic you ask for or the current program schedule.\n\nSo we had high expectations for this Apple device, mainly because of all the marketing, and were disappointed by a beautiful but not so useful TV device. The future of the TV? Not really for now.\n\nOur last acquisition was an Apple Watch Sport Edition (blue and gold). The watch is beautiful, and after 1 month of everyday use, there is not a single scratch on it. It comes with nice surprises like the auto activation of the screen when you look at it or the 2 day battery life! The configuration is really fast, it offers you to just mirror your iPhone configurations. After some days using it, we had to adjust some settings because some notifications we used to have on the iPhone are too intrusive on the Apple Watch (Amazon emails, some apps notifications). Even if an app is not compatible with the Apple Watch, every notification you receive on your iPhone will pop up on the Apple Watch. There are more and more compatible apps, the useful ones are for traveling, sports and chatting. Many other ones are cool but a watch is small and more intimate than a phone or a computer so you end up using it only for things that are really important and essential to you.\n\nThe handling of chat is pretty cool: you don\u2019t have a keyboard so you can either dictate your sentences (it understands well) or use dynamically defined replies. These are really impressive. As an example, if you receive a sms from a friend: \u201cIndian or sushi for lunch?\u201d, it\u2019ll suggest \u201cIndian\u201d, \u201cSushi\u201d, \u201cnone\u201d and other pre-defined replies. It also detects the context. If you receive \u201cI have an issue with my car\u201d, it\u2019ll suggest \u201cWhat\u2019s happening?\u201d. Cool.\n\nUnlike the Apple TV, we were sceptical about the usefulness and ease of use of the Apple Watch, but it was a nice surprise and it\u2019s a very cool device!\n\nAfter trying these 3 new AI-powered devices, we found good and bad points but we are sure that AI-powered devices will increase and improve in the future. For now on, they are only made by big companies which put lots of money into them. At Recast.AI, we think that everybody will soon be able to create their own AI-powered devices and that\u2019s why we\u2019re building a collaborative AI platform to help developers achieve this goal!\n\nThis post was originally published at https://blog.recast.ai/new-ai-powered-devices-tried/"
    },
    {
        "url": "https://medium.com/@RecastAI/a-natural-language-slackbot-19ca5b0fc64b?source=user_profile---------91----------------",
        "title": "A Natural Language Slackbot \u2013 RecastAI \u2013",
        "text": "Visjar is a slackbot powered by Natural Language Understanding, which means that unlike other bots, this one is not only aware of simple unix-like commands, but can also understand sentences and complex requests.\n\nDuring its development, we tried to create this slackbot in a way people could easily install, configure and customize it. The first, and obvious, thing to do was to offer the possibility to install Visjar in on click, thanks to the Slack button (here). And the second, was to open source Visjar, and produce a detailed README, for the developers to use (there).\n\nOr just click on the button below to install it on your slack from our servers!\n\nThe workflow inside Visjar is as follows:\n\nHere\u2019s the list of the currently implemented commands:\n\nMost of the configuration must be done in the parameters.yml file in order to have a default visjar working.\n\nVisjar is relying on many APIs to provide you those commands, and you can view the dependencies in the code, because if any of them is not satisfied, the command won\u2019t load.\n\nAll the actions Visjar can perform ainsidere situated in lib/commands/ and are loaded during boot by the file config/environment.rb.\n\nYou can easily add a new command by creating a new file in the commands folder and add a requiring line in the environment file:\n\ndaemon-kit and safely are used to provide an easy daemon setup.\n\nslack-ruby-client, faye-websocket, HTTParty and forecast_io are used to consume the APIs (RecastAI, Slack, Forecast.io, Google Places, Google Maps, etc.).\n\nactivesupport, chronic and time_difference are used to do data processing.\n\nawesome_print is used for debugging.\n\nThis post was originally published at https:/blog.recast.ai/a-natural-language-slackbot/"
    },
    {
        "url": "https://medium.com/@RecastAI/when-your-users-are-developers-d79adb6a2336?source=user_profile---------92----------------",
        "title": "When your users are developers \u2013 RecastAI \u2013",
        "text": "To provide a great User Experience, you have to understand your users, what they think, they do, they imagine. You can then create the model of your product and give them access to it.\n\nWe tend to forget that the visible part of the product, the link with your users is a copy of your core product: the logic and the database.\n\nIt\u2019s clearly visible when your target audience is developers.\n\nA mental model refers to the representation of something, of how a thing works in a person\u2019s mind. They refer to it to predict how the product will work and what they should do with it.\n\nPeople create a mental model very quickly and often before their utilisation of a product. Their mental models are based from past experience, so not everyone has the same mental model.\n\nYou have to understand the mental model of your target audience to design an intuitive user experience where the conceptual model match as much as possible with it.\n\nThe conceptual model is the actual model that is given to the user through the design and the interface.\n\nYou can easily superpose those two sketch and see that the visual part is just a layout above the database schemas. So the layout, the conceptual model of your blog is a copy of your database schemas.\n\nIt is not new, it\u2019s called a (Graphical) User Interface, a type of interface that allows users to interact with electronic devices through (visual) indicators.\n\nThe root of your Interface is a database schemas and some logic, we tend to forget that. But developers are the creators, and when your target audience is developers too, their mental models (impregnated with their experiences, skills and expertises) fits perfectly with your conceptual model.\n\nAt Recast.AI, a young French startup, we are working to create a platform of Artificial Intelligence for developers.\n\nHow create our conceptual model for our audience in order to provide a great user experience?\n\nOur platform is organized around applications held by our users, and they can add folders and files. Our users could have some of this mental models:\n\nThey are developers, so their mental model will undoubtedly be inspired byGitHub, and by the term, the first interface human-computer.\n\nThe command line tools (CLI) is one of the possible interfaces, an API (application programming interface) too, even of a graphical interface.\n\nAll of these interfaces are layers on the database schemas, the root never change. So which one do we need to implement?\n\nMaybe there\u2019s not even a choice to make, because \u201cdevelopers\u201d are a broadaudience, and some of them don\u2019t use command line tool or API, we can\u2019t keep focus on one interface. So our service of Artificial Intelligence have to be usable on different supports, and we have included the API, the GUI and the CLI in our roadmap.\n\nCurrently, we have implemented 2 of those 3 interfaces and you will be able to use them soon \ud83d\ude0a ."
    },
    {
        "url": "https://medium.com/@RecastAI/real-time-architecture-anticipation-is-the-key-190f3e4afcf1?source=user_profile---------93----------------",
        "title": "Real Time Architecture: Anticipation is the key \u2013 RecastAI \u2013",
        "text": "We expect a lot from Artificial Intelligence: it needs infinite knowledge and the ability to perform infinite tasks, in real time. Real time doesn\u2019tnecessarily means instant, like x milliseconds as we often want in systems architecture.\n\nIn fact in a normal conversation it takes on average 1 second for people to respond. When we are talking, we have to understand the other person\u2019ssentence, search for the relevant data in our brain, and generate an answer.This takes time. According to Pr Paul Reber,\n\nAnd we want AI to have the knowledge of 7 billion humans !\n\nThat\u2019s why we should talk talk about real time rather than instant, and in order to process such a huge amount of data in no more than a second, we can use a microservices architecture. But we need more. We also need toidentify \u201crequest intents\u201d, get data ready, and even anticipate user requests.\n\nWhen one or more of our services are running out of resources (I/O, memory, disk space\u2026), we need to add more power to this specific service without being forced to scale the whole application. That means each of our services needs to be independent and gives rise to the need for microservices architecture.\n\nA microservices architecture enables us to scale our architecture in theminimum amount of time. Each service has different resource needs, for example data querying will take more power than grammatical analysis. If we put all the application in a monolithic architecture, booting a new instance of the app when traffic suddenly rises will take longer than booting new smaller instances of services which need more power. Also, if an instance of a service goes down (intentionally or unintentionally), it doesn\u2019t cause the whole application to go down.\n\nA real time architecture is what we need. It\u2019s quite common to use such architecture, but we need AI-specific optimisations.\n\nWe need to know what the user is talking about as fast as possible. An idea is to use a sift system: we analyse the sentence deeper and deeper until we have identified all the details of it.\n\nFor instance, let\u2019s take the sentence \u201cWho is the president of the United States?\u201d\n\nTo identify precisely the intent(s) of the request, we can use Xin Li and Dan Roth\u2019s work (check out page 5). Let\u2019s apply this to our sentence:\n\nNow we know that we aren\u2019t talking about the weather nor or sports. We will find the key in the presidents of the United States.\n\nNow, a structured database is essential to determine an answer fast.\n\nTo be able to answer this question we need to have anticipated it and compiled/structured a list of country presidents.Thus, once the sentence is filtered and interpreted, we can access the to data that matters directly. We can access the presidents of the USA, then the one that matches the current date. That will lead us to Barak Obama.\n\nThis process helps us lower the search time through the database, and therefore the response time.\n\nWe can do even more by anticipating user requests.\n\nThe goal is to reduce the range of possibilities according to the context in which the user in interacting. In the near future, when you will be in a meeting, your smart agent will select and prioritize data that matches the topic of the meeting. This way, it will be ready to process a request faster, and also be more accurate, because the dataset is relevant. If your request doesn\u2019t match the topic of the meeting, your smart agent will resume the normal process (request targeting and searching through structured data).\n\nWith requests targeting and anticipation, Artificial Intelligence can understand a request very quickly. With a structured database, it finds the data it needs efficiently and can then start to answer or determine the action to take. That\u2019s how a microservices architecture enables the user to get an answer in real time !\n\nThis post was originally published at https://blog.recast.ai/real-time-architecture-anticipation-key/"
    },
    {
        "url": "https://medium.com/@RecastAI/ux-and-ai-the-new-best-friends-e1336a2c3e6b?source=user_profile---------94----------------",
        "title": "UX and AI: The new best friends \u2013 RecastAI \u2013",
        "text": "The recent explosion of Artificial Intelligence (AI) was caused by the convergence of the Big Data and the augmentation of computational power. In this article, we are going to talk about AI in the broad sense: including Machine Learning, Natural Language Processing and Speech Recognition. We will take a look at a few examples of how AI is being used today and why it might be User Experience\u2019s new best friend (UX) when it comes to humanizing the customer experience and building a smart product.\n\nToday, when we speak of AI, we tend to imagine a cyborg from the latest sci-fi movie. A good example would be Ava in Ex-Machina.\n\nGiven this image we have of AI, we\u2019re right to say : \u201cOh God! Siri or Google now are so far from this\u2026\u201d.\n\nIntelligence in computer science is directly associated with speech and conversation. So, yes our smartphones may be a long way from having the discussion of our dreams, but they are definitely\u2026 smart.\n\nAI is in all your electronic devices: your phone, your tablet, your watch, your TV, even your fridge is probably smart. It is just not smart the way you expect it. It exists through microinteractions which make the difference between a product we love and one we just use.\n\nIt personalizes recommendations of applications or movies. You have a news feed created specially for you. Your likes, comments, clicks, even how long you spend on a specific post are fed into Facebook\u2019s artificial brain. All those interactions are powered with some level of AI. Facebook analyzes those patterns, preferences, and behaviors to show you more of what it thinks you\u2019ll like.\n\nFacebook learns your habits, your preferences, your tastes \u2026 to simplify all the actions you have to take and give you a unique User Experience.\n\nA great UX continually learns from its users to give them a more human experience, intuitive and as positive as possible. It tends to minimize all errors and frustrations in an experience with a product or interface. Just like AI. It\u2019s the main base for an intelligence, learning from mistakes. It will not make the same mistake again, it memorizes experiences.\n\nIt can thus reduce frustration, avoid errors and plan actions. This is not AI for the sake of it, but AI as a part of a UX strategy for business, for users and for developers.\n\nIntelligent machines fed with Big Data will get good at anything involving the processing of large amounts of information. We need a lot of information and research when we build a new process, a new product. We need clarity when we seek our future users, because we need to find those who love our product, which will return and become ambassadors. To accomplish this we need a killer UX and some AI interactions. Only then will we succeed in making our users and developers happy!\n\nFor now we can only make small parts of a product intelligent by iterating and collecting data on specific interactions. But we can hope that tomorrow the entire product will be smart enough to provide a unique experience for each user.\n\nA product that is built thanks to you and learns at the same time as you.\n\nThis post was originally published at https://blog.recast.ai/ux-and-ai-the-new-best-friends/"
    },
    {
        "url": "https://medium.com/@RecastAI/from-context-to-user-understanding-a692b11d95aa?source=user_profile---------95----------------",
        "title": "From context to user understanding \u2013 RecastAI \u2013",
        "text": "At Recast.AI, we use Natural Language Understanding (NLU) as a way to enrich input from users, and context is an important part of the process. During the handling of our inputs, we are led to decide whether or not a sentence given is corresponding to a specific meaning (we call it Intention). In order to do that, we need to understand what\u2019s the user is saying by using the context and the sense of each words.\n\nOne day, we stumbled upon a sentence our software wasn\u2019t able to categorize. It was a simple sentence, counting exactly 7 words:\n\nOur current program wasn\u2019t capable of understanding the meaning of plant, failing over and over to categorize it as an industrial facility.\n\nAfter a few searches, we found out lots of papers describing and trying to solve our problem, and from here began our trip into the depths of one of the oldest open problems of NLU.\n\nThe task of Word Sense Disambiguation (WSD) consists of selecting the best sense for an occurrence of a word in a given context. In our case, we had to find the correct sense for the word plant.\n\nThis issue was discovered at the creation of Machine Translation (1940s) and at first, people argued about the solubility of such an issue, declaring that it was impossible to model all the knowledge for a computer to understand.\n\nThree decades later, linguists started to create rule-based systems to try to solve WSD, relying on hand-crafted knowledge bases, such as OALD, LDOCE and Roget\u2019s Thesaurus.\n\nThe next step (1980s) was to replace the rules by a knowledge extraction from those sources, thus automatizing a part of the process.\n\nIn the 1990s, probabilistic models appeared, and WSD was applied Machine Learning techniques, which have really convincing results.\n\nThe 2000 century brought to WSD the knowledge from the Web. This created an emulsion, researchers tried to mix Machine Learning and knowledge bases, by creating Unsupervised Machine Learning methods, and others hybrids algorithms.\n\nBelow, you can find a non-exhaustive list of the algorithms and Machine Learning techniques used in WSD:\n\nEvery solution has its perks and flaws, but the state-of-the-art in the Semi-Supervised Machine Learning field is achieving more than 90% accuracy.\n\nOur goal was to get our hands dirty with a first implementation of a solution, and we wanted a good compromise between simplicity and efficiency.\n\nSo, after a few days of research and thinking, we finally decided to stick with the traditional approach of a Knowledge-based algorithm.\n\nThe Lesk algorithm (Michael E. Lesk, 1986) is based on the assumption that words in a sentence will share a common topic. The idea is simple: given a sentence, the algorithm selects the senses whose definitions have the maximum overlap (the highest number of common words).\n\nWe can represent this by a simple picture, see below:\n\nWhat\u2019s really interesting with this schema, is that it shows the resemblances between the Lesk algorithm and our brain\u2019s process. Yes, that\u2019s right, Lesk saw the way we analyze a sentence in real-time, and implemented a solution copying that operation. Moreover, we posses and use a lot of information to disambiguate a word, which come mainly from our education.\n\nSince our solution is knowledge-based, we needed a dictionary constructed in a way a computer could use it: we had to find an education model for our algorithm.\n\nWe decided to use the Princeton University\u2019s WordNet, created in 1995 by George A. Miller. WordNet is a lexical database for the English language: It groups English words into synsets (synonyms sets), provides short definitions and usage examples, and records a number of relations among these synonym sets or their members.\n\nAfter 8 releases and 20 years, WordNet contains 117 954 nouns, 21 500 adjectives, 11 541 verbs and 4 476 adverbs. That\u2019s huge!\n\nHere\u2019s what the different meanings of plant look like in WordNet:\n\nUnfortunately the original interface is written in C, thus we built a custom Ruby API, that we called Omniscient.\n\nOmniscient allows us to retrieve most of the semantic relation a word has. For example, every synset of plant will be linked to synonyms, antonyms, hyponyms (children), hypernyms (parents), meronyms (part of), holonyms (whole of), etc. Those relations are used to create a glossbag, a bag of definitions related to a word\u2019s sense.\n\nOnce the glossbag is done for every word in the sentence, we use the Lesk algorithm to compare their similarity, and we choose the best score of all the comparisons.\n\nAt first, the results were quite disappointing, but after a few tweaks and improvements, here\u2019s what we had:\n\nWe can try with another sense, see:\n\nWord Sense Disambiguation can seem trivial, but it is the first step towards an automation of the understanding, or even the generation, of natural language.\n\nIn this article, we looked at the technical part of understanding the user, but is it the only thing required for an AI to be considered good ?\n\nAn Adapted Lesk Algorithm for WSD Using Wordnet, Banerjee and Pedersen\n\nWSD using Wordnet and the Lesk Algorithm, Ekedahl and Golub"
    },
    {
        "url": "https://medium.com/@RecastAI/introduction-to-natural-language-understanding-c7443373b670?source=user_profile---------96----------------",
        "title": "Introduction to Natural Language Understanding \u2013 RecastAI \u2013",
        "text": "There is a big gap between our expectations and the reality concerning Artificial Intelligence. We can put the blame on Natural Language. Which is more difficult to master than we tend to believe.\n\nHowever, the computer still represents a docile and powerful assistant and we want it to be smarter. A large number of people are pushing forward the research thanks to worldwide challenges or competitions, for example the Allen AI Science challenge (which aims to prove that an AI can be smarter than an 8th grader).\n\nOne of the most famous examples of a realistic intelligence came from the movie director Stanley Kubrick in his 1968 movie 2001: A space Odyssey.\n\nHow far are we from a fictional assistant similar to HAL-9000, capable of helping David Bowman in his mission? How far are we from this fictional assistant?\n\nLet\u2019s compare HAL-9000 with SIRI (from the dialogue with Stephen Colbert in 2011 on the Colbert report, an American TV show).\n\nHAL-9000 gives the feeling that it fully grasps the situation in its complexity, whereas Siri doesn\u2019t even understand a simple request\u2026 :-)\n\nIn Computer Science, we call the process of \u201cunderstanding\u201d the meaning behind a sentence as Natural Language Understanding (NLU).\n\nEx: Should I take an umbrella today? => Will it rain today?\n\nIt is different from Natural Language Processing (NLP) which is the process of determining the grammatical role of every word in a sentence and their relations.\n\nLet\u2019s start with a brief history of NLU and we will see afterwards what are the main problems related to this field of Artificial Intelligence.\n\nTuring addressed the problem of artificial intelligence, and proposed an experiment which became known as the Turing test, an attempt to define a standard for a machine to be called \u201cintelligent\u201d.\n\nAt the beginning, developers evaluated a user\u2019s input with a few rules of pattern-matching.\n\nExample: if \u201cHello <-VARIABLE->\u201d then greetings.\n\nLinguistics experts started to contribute to NLU, by \u201ccoding\u201d all grammar and semantic rules. That produced realistic software like:\n\nBoth were linguistically rich and logic-driven.\n\nWe can be more critical and say that the questions came from a sandbox of easy questions, but it was 35 years ago.\n\nOne of the biggest problems at the time was the grammatical interpretation of a sentence (NLP). The error rate was important.\n\nThe statistical revolution in Natural Language Processing led to a decrease in the NLU research:\n\nThe majority of the models in NLP now include what is called today \u201cMachine Learning\u201d. It is a probability model. The more you give data, the more efficient the model is. Today, results are pretty amazing: we can process a sentence with more than 98% of accuracy.\n\nFirst of all, NLU is an ungrateful field, we have to admit it: we are very demanding when it comes to computers\u2019 understanding and knowledge.\n\nDo we really need today a personal robot that we can have a philosophical discussion with? Or do we just need to automate daily tasks, like creating a shopping list?\n\nTechnically, there are two main problems:\n\nWe have multiple ways to express a same idea.\n\nExample: When you want to make an appointment with your doctor, you may say:\n\n\u25cf I need to make an appointment.\n\n\u25cf I need to see the doctor.\n\n\u25cf When is the doctor free?\n\n\u25cf I need to renew my prescription.\n\n\u25cf Do you think the doctor could squeeze me in today?\n\n\u25cf I need to make an appointment for my husband.\n\n\u25cf My child needs to come in for a check-up.\n\n\u25cf The doctor wants to see me again in two week\u2019s time.\n\nTo ask for a \u201crendez-vous\u201d, you can do it in multiple ways.\n\nIn order to understand the whole sentence, we have to link together a lot of concepts by creating associations between words. (prescription <=> doctor <=> cold <=> check-up)\n\nAll these words lead us to the second main problem.\n\nBut first of all, we need to define what the context is: we can say that it is something that helps us to understand of something else, be it a text, a joke, an event\u2026\n\nIn other words: context is the circumstances of something happening.\n\nIt can be a story lived by a two persons from a group of ten (private joke) which may create a specific meaning for both of them, different from the one understood by the rest of the group.\n\nIt can also depend on a situation.\n\nLet\u2019s take an example: if you read somewhere \u201c\u2026 and bacon\u201d, what is the meaning of these two words?\n\nWe begin with the first word \u201cand\u201d, it defines the end of a list; regarding the second word \u201cbacon\u201d, it is a meat product.\n\nDoes it imply ordering something? Does it imply listing all pork recipes? Does it imply completing a shopping list?\n\nWe cannot guess the point of such sentence without context. This is exactly what we expect a computer to do.\n\nActually, I think we are not approaching the problem from the right way.\n\nEven a human cannot understand what is the meaning behind random words without a context, and the only one who can give enough data when he is talking to the computer is the user, it cannot be only based on \u201cprobabilistic model\u201d.\n\nWe have to find a way to help developers to add more intelligence in their softwares, and to do so, everybody has to contribute to Artificial Intelligence.\n\nTogether, we will crack Natural Language Understanding and build a better Artificial Intelligence !"
    }
]