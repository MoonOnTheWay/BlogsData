[
    {
        "url": "https://medium.com/@Aj.Cheng/hyperparameter-b78bb1951632?source=user_profile---------1----------------",
        "title": "Hyperparameter \u2013 Long \u2013",
        "text": "Training iteration. In the training process , weights will update in every iteration, Under normal circumstances\uff0closs is decrease meanwhile prediction accuracy increase.\n\nIf u find loss and accuracy trend are abnormal through many training iteration, u should stop and adjust hyperparameter or network architecture."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/backpropagation-80269655aeaf?source=user_profile---------2----------------",
        "title": "Backpropagation \u2013 Long \u2013",
        "text": "ok, now ,how to update weight w to minimums value of error\n\nwe should derivate weights to get \u0394w\u200b then w += \u0394w\u200b to update weight.\n\ncalculate method is almost same, if neural network has hidden layer between input layer and output layer, we need update multiple weights,\n\nNow, let\u2019 see the process of update weighs.\n\nfirst derivate dwH ,then derivate (dwH)dwX, dwH is weight of hidden layer\n\nBecause sigmoid derivate is sigmoid(1-sigmoid),and backpropagation process will generate more and more sigmoid, and sigmoid value range in (0,1), so more numbers of hidden layer ,value decrease sharper, the first layer update weight is very small:\n\nHere is full code of gradient descent & backpropagation, u can run it by urself."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/autoencoder-ef621c5b749?source=user_profile---------3----------------",
        "title": "Autoencoder \u2013 Long \u2013",
        "text": "The purpose of autoencoder is compress data\uff0cbut the compress effect is worse than .jpeg,mp3 or other video compress format, and it can not compress dataset. It often use to denoise image or dimensionality reduction.\n\nThere will show two example of Autoencoder:\n\ncompress a image to a narrow vector, and reconstruct it,the network has encoder, hidden layer and a decoder.\n\nThe encoder part of the network will be a typical convolutional pyramid. Each convolutional layer will be followed by a max-pooling layer to reduce the dimensions of the layers. The decoder though might be something new to you. The decoder needs to convert from a narrow representation to a wide reconstructed image. For example, the representation could be a 4x4x8 max-pool layer. This is the output of the encoder, but also the input to the decoder. We want to get a 28x28x1 image out from the decoder so we need to work our way back up from the narrow decoder input layer. A schematic of the network is shown below.\n\nyou will see there use a api tf.image.resize_nearest_neighbor, this api use to upsampling a small image to a large one .In this Distill article from Augustus Odena, et al, the authors show that these checkerboard artifacts can be avoided by resizing the layers using nearest neighbor or bilinear interpolation (upsampling) followed by a convolutional layer."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/seq2seq-18a0730d1d77?source=user_profile---------4----------------",
        "title": "Seq2Seq \u2013 Long \u2013",
        "text": "Seq2Seq is often focus on solve language translation problem, it\u2019s based on RNN architecture.\n\nThe main process of Seq2Seq is input a sequence and output a sequence, it consist of Encoder and Decoder.\n\nNotice that the inference decoder feeds the output of each time step as an input to the next.\n\nThe training decoder does not feed the output of each time step to the next. Rather, the inputs to the decoder time steps are the target sequence from the training dataset (the orange letters).\n\nThere are four symbols, however, that we need our vocabulary to contain. Seq2seq vocabularies usually reserve the first four spots for these elements:\n\nNote: Other tags can be used to represent these functions. For example I\u2019ve seen <s> and </s> used in place of <GO> and <EOS>. So make sure whatever you use is consistent through preprocessing, and model training/inference."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/word2vec-3b2cc79d674?source=user_profile---------5----------------",
        "title": "Word2Vec \u2013 Long \u2013",
        "text": "word2vec is a method that use a vector to represent a word, because calculate word in the network directly is difficult.\n\nhow to use number vector to represent a word?\n\none-hot coding is a very start method to make word digitized, it just represent a word but no meaningful, u can get it from nothing.\n\nThe destination of Wrod2Vec is to train to embedding model,not predict some result.\n\nthe below example shows some of the training samples ,word pairs(input, target), we would take from the sentence \u201cThe quick brown fox jumps over the lazy dog.\u201d I\u2019ve used a small window size of 2 just for the example. The word highlighted in blue is the input word.\n\nevery word represented by word pair,same word pair frequency of occurrence is high, nearby word probability is high, vice versa.\n\nembedding model establish process is use statistic frequency to back adjust the embedding matrix.\n\nSo, if two words have similar contexts, then our network is motivated to learn similar word vectors for these two words!\n\nThere have some tricks in real train process:"
    },
    {
        "url": "https://medium.com/@Aj.Cheng/lstm-61a890768e98?source=user_profile---------6----------------",
        "title": "LSTM \u2013 Long \u2013",
        "text": "CNN is aimed to solved one purpose problem, like image classification, it doesn\u2019t need context information.This neural network shortcoming is obviously, when do some complicate task need persist previous information.\n\nLanguage translation,image caption is implemented by RNN, there are networks with loop in them, allowing information to persist.\n\nCNN is often to train model on fixed input and fixed output situation,but RNN is for sequence to sequence.\n\nLSTM cell has two kind of output: cell state and prediction, cell state is key factor for prediction.\n\nThe first step in our LSTM is to decide what information we\u2019re going to throw away from the cell state.\n\nConcatenate previous cell prediction and present cell input,suqash the value to 0~1 and multiply with pre-cell state\n\nSecond step is to decide what information need to update the cell state.\n\naccording to the previous LSTM step by step:\n\nThere is a simplest way to implement LSTM by tensorflow\n\nHere is full simple LSTM code example by tensorflow"
    },
    {
        "url": "https://medium.com/@Aj.Cheng/gradient-descent-8c9864e1c2cb?source=user_profile---------7----------------",
        "title": "Gradient Descent \u2013 Long \u2013",
        "text": "Gradient descent is a method that how to find the optimal model.\n\nthe basic concept is: iterate every direction -> compare every loss -> chose the minimal one -> iterate next step -> and so on.\n\nHere is Tensorflow training method, it includes common algorithms, such as: Adam,Momentum..\n\nThis is an awesome blog ,that introduce gradient descent, and architecture of distribution , some train tricks and conclusion."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/how-to-use-tensorboard-resource-1165f9fe590a?source=user_profile---------8----------------",
        "title": "How to Use Tensorboard (Resource) \u2013 Long \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/convolutional-neural-network-d9f69e473feb?source=user_profile---------9----------------",
        "title": "Convolutional Neural Network \u2013 Long \u2013",
        "text": "Training ConNet model is train the weights and bias through various type of layers:Conv layer,Pooling layer,Normalization Layers and Fully-Connected Layers to aggregation the value ,take the value into loss function (usually softmax), and back forward backpropagation update weights, loop the process.\n\nThe whole training process is non-linearity, from the raw image pixels on one end to class scores at the other.\n\nBelow is the normal NetConv process:\n\nIn the real training, there should be an activation function insert into two layers,except fully-connected layer . so the process is :Conv-> ReLU -> Pool -> ReLU -> Conv -> ReLU -> Pool -> FullCon -> FullCon\n\nThe layers of a ConvNet have neuron arranged in 3 dimensions:width,height and depth. E.g. the input images in CIFAR-10 are an input volume has dimension:32*32*3, depth represents RGB.The final output layer have dimensions 1*1*10,bacause by the end of the ConvNet arthitecture we will reduce the full image into a single vector of class scores,arrange along the depth dimension.\n\nThis layer is the core layer of ConvNet, here is a visual demo to show how this layer work.\n\nThe Conv Layer parameters consist of a set of learnable filters:\n\nEvery filter slice the layer into special dimension, e.g. input layer(10*10*3), if the filter is (2*2*10:means 1o*(2*2*3)), multiple them, output layer is 9*9*10.\n\nThis layer is an activation layer, click this blog activation chapter to see detail,the layer won\u2019t change dimension of matrix, but amplify the positive value,reduce negative value.\n\nThere have two types of pooling layers: max pooling,average pooling, when we mention pooling layer, max pooling is by default,this layer is downsampling operation along the spatial dimensions(width,height).\n\nThis is the final layer, that aggregate the previous layer and weight into range of classification.\n\nThis layer is rare to use...\n\nKernel is also called filter, that can extract image features, but what types of feature we want to get is unknown, our purpose is input the datasets and train the filter, adjust filter on every epoch.\n\nHere are some simple kernels:\n\nI have already add comment to the code,Click & check detail."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/simplest-neural-network-without-tensorflow-3537918f44e3?source=user_profile---------10----------------",
        "title": "Simplest Neural Network & Activation \u2013 Long \u2013",
        "text": "there has hundreds of billion neurons in human brain, every neuron transfer information through axon, when one or many neuron get single, they will process the single and judge which axons can send the processed info to the next one, and so on.\n\nDL is one of the best implementation of ML(Machine learning) so far, and neural network is best method to implement DL.\n\nlet\u2019s see how these neural work in DL, what the neural network like the below picture shows:\n\nThere are three types of layer : input layer ,hidden layer and output layer.\n\nInput layer is source of input data, we need normalize the data in the specific type or dimensions. hidden layers like dark magic region, data flow through the region, boom~ a bird is flying out(kidding ^^)\uff0coutput layer is final result that we want to get, e.g.we want the neural network to predict the picture of cat or dog?\n\nOk, this time, we implement a simplest neural network , it consist of one input layer, one hidden layer and one output layer.\n\nThe previous blog, we use a linear formulation :y = mx + b, every variable is a number, this blog\u2019s demo , we will do matrix operation, if u unfamiliar with matrix, click this URL.\n\nBefore we get start of our demo, let\u2019s see it in high level:\n\nThe datasets contains of input data and output data, what we need to calculate is two weights. This is the core code of neural network:\n\nWe used numpy lib in the code ,in order to simplify matrix operation.\n\nhere is some reference\uff1a\n\nbecause activation is non-linear, linear function are simple but limit, we want implement it at any function, any function means u can't use a linear function to represent , must use non-linear .if we just use linear function ,no matter how many layers we make ,we also get a linear:f(w1 * x1 + w2 * x2 + w3 * x3)\n\nwe often mentioned activation function is non-linear function.\n\nwhen we train the model, we don\u2019t want every value through into the next layer, because some value is useless, to a certain extent it will affect the accuracy of model, so filter the negative value , amplify the positive value not only can accelerate the training process , but also promote accuracy.\n\nthe function is \u03c3(x) = 1/(1+exp(-x)), it squashes real-value into range between[0,1],In particular, large negative numbers become 0 and large positive numbers become 1.\n\nbut sigmoid has two major drawbacks:\n\nthe function is tanh(x) = 2\u03c3(2x) - 1, it squashes value to the range[-1,1]. the drawback is same with sigmoid , but it is a zero-centered.Therefore, in practice the tanh non-linearity is always preferred to the sigmoid nonlinearity.\n\nthe function is f(x) = max(0,x), this function is simply thresholded at zero.\n\nhere is the drawback:\n\nReLU units can be fragile during training and \u201cdie\u201d. e.g.a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again.(large gradient update make the weight value negative?). With a proper setting of the learning rate this is less frequently an issue.\n\nthe function is f(x) = max(ax , x) ,this activation is attempt to fix the \u201cdying ReLU\u201d problem, instead of the function being zero, when x is negative , we give a very small value a ."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/linear-regression-by-gradient-decent-bb198724eb2c?source=user_profile---------11----------------",
        "title": "Linear Regression by gradient decent \u2013 Long \u2013",
        "text": "I have already finish DL(Deep Learning) Nanodegree of Udacity .Write the blog cause i wanna summary these huge knowledge from the course and i will be very happy if someone can learn from theses.\n\nThese are series of blogs intro about DL, this is the series of #1.\n\nClassification is often as an example by using Linear regression.\n\nThink below the process to classify green dot and red dot:\n\nevery step, line is closer to the optimal position.It\u2019s like magic, the computer can implement it automatically.\n\nThere are some terms before we get start the code.\n\n^Y is a vector of n predictions, and Y is the vector of observed values corresponding to the input to the function which generated the predictions, then the MSE of the predictor can be estimated by\n\nThis is an easily computable quantity for a particular sample.\n\nthis blog is assume that u understand the concept of derivative, here is formulation that will be use in our code:\n\nlinear regression formulation is very simple: y = mx + b, partial derivative use in backpropagation stage which is to update weight(m) and biase(b), we will intro some detail of it later.\n\nhere is core code(whole code file in the blog end):\n\nMaybe u wondering the line 23 ~ 24 is different with formula Partial derivative, then i rewrite the code below, the result is same:\n\nThis is my result:\n\nthe purpose of backpropagation is only one: update weights.\n\nOk, let\u2019s look in-side the one update step.\n\nThe formulation is : y = mx + b, and initial current_m=0, current_b=0, next when we get the point(x1,y1), fill in the formulation: y1 = m * x1 + b, according to the partial derivative:\n\nfirstly, we calculate the gradient of m and b:\n\nsecondly, update the weight(m) and bias(b):\n\nthrough hundreds of thousands iteration, the algorithm will the optimal m and b."
    },
    {
        "url": "https://medium.com/@Aj.Cheng/write-list-to-do-e223850ab2d?source=user_profile---------12----------------",
        "title": "Write list(to do) \u2013 Long \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    }
]