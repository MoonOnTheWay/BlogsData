[
    {
        "url": "https://medium.com/data-science-group-iitr/word-embedding-2d05d270b285?source=---------0",
        "title": "Word embedding \u2013 Data Science Group, IITR \u2013",
        "text": "What are word embeddings? Why we use word embeddings? Before going into details. lets see some example :\n\nso how do they do this. Actually these things are application of Text processing. we use text to do sentiment analysis, clustering similar word, document classification and tagging.\n\nAs we read any newspaper we can say that what is the news about but how computer will do these things? Computer can match strings and can tell us that they are same or not But how do we make computers tell you about football or Ronaldo when you search for Messi?\n\nFor tasks like object or speech recognition we know that all the information required to successfully perform the task is encoded in the data (because humans can perform these tasks from the raw data). However, natural language processing systems traditionally treat words as discrete atomic symbols, and therefore \u2018cat\u2019 may be represented as and 'dog' as . These encodings are arbitrary, and provide no useful information to the system regarding the relationships that may exist between the individual symbols.\n\nThere are many different types of word embeddings:\n\ncount vector model learns a vocabulary from all of the documents, then models each document by counting the number of times each word appears. For example, consider we have D documents and T is the number of different words in our vocabulary then the size of count vector matrix will be given by D*T . Let\u2019s take the following two sentences:\n\nDocument 2: \u201cThe dog ate the cat and the hat\u201d\n\nFrom these two documents, our vocabulary is as follows:\n\n{ the, cat, sat, on, hat, dog, ate, and }\n\nNow, we count the number of times each word occurs in each document. In Document 1, \u201cthe\u201d appears twice, and \u201ccat\u201d, \u201csat\u201d, \u201con\u201d, and \u201chat\u201d each appear once, so the feature vector for documents is:\n\n{ the, cat, sat, on, hat, dog, ate, and }\n\nso the count vector matrix is :-\n\nNow, a column can also be understood as word vector for the corresponding word in the matrix M. For example, the word vector for \u2018cat\u2019 in the above matrix is [1,1] and so on.Here, the rows correspond to the documents in the corpus and the columns correspond to the tokens in the dictionary. The second row in the above matrix may be read as \u2014 Document 2 contains \u2018hat\u2019: once, \u2018dog\u2019: once and \u2018the\u2019 thrice and so on.\n\nThere is a problem related to dimensions of the matrix for a large corpus of text so we can use stop words (remove common words like \u2018a, an, this, that\u2019) or we can extract some top words from vocabulary based on frequency and use as a new vocabulary or we can use both methods.\n\nIn a large text corpus, some words will be very present (e.g. \u201cthe\u201d, \u201ca\u201d, \u201cis\u201d in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n\nIn order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf\u2013idf transform. This method takes into account not just the occurrence of a word in a single document but in the entire corpus. lets take a business article this article will contain more business related terms like Stock-market, Prices, shares etc in comparison to any other article. but terms like \u201ca, an, the\u201d will come in each article with high frequency. so this method will penalize these type of high frequency words.\n\nTF = (Number of times term t appears in a document)/(Number of terms in the document)\n\nIDF = log(N/n), where, N is the total number of documents and n is the number of documents a term t has appeared in.\n\nWords co-occurrence matrix describes how words occur together that in turn captures the relationships between words. Words co-occurrence matrix is computed simply by counting how two or more words occur together in a given corpus. As an example of words co-occurrence, consider a corpus consisting of the following documents:\n\nLetting count(w(next)|w(current)) represent how many times word w(next) follows the word w(current), we can summarize co-occurrence statistics for words \u201ca\u201d and \u201cpenny\u201d as:\n\nThe above table shows that \u201ca\u201d is followed twice by \u201cpenny\u201d while words \u201cearned\u201d, \u201csaved\u201d, and \u201cwise\u201d each follows \u201cpenny\u201d once in our corpus. Thus, \u201cearned\u201d is one out of three times probable to appear after \u201cpenny.\u201d The count shown above is called bigram frequency; it looks into only the next word from a current word. Given a corpus of N words, we need a table of size NxN to represent bigram frequencies of all possible word-pairs. Such a table is highly sparse as most frequencies are equal to zero. In practice, the co-occurrence counts are converted to probabilities. This results in row entries for each row adding up to one in the co-occurrence matrix.\n\nBut, remember this co-occurrence matrix is not the word vector representation that is generally used. Instead, this Co-occurrence matrix is decomposed using techniques like PCA, SVD etc. into factors and combination of these factors forms the word vector representation.\n\nLet me illustrate this more clearly. For example, you perform PCA on the above matrix of size NXN. You will obtain V principal components. You can choose k components out of these V components. So, the new matrix will be of the form N X k.\n\nAnd, a single word, instead of being represented in N dimensions will be represented in k dimensions while still capturing almost the same semantic meaning. k is generally of the order of hundreds.\n\nSo, what PCA does at the back is decompose Co-Occurrence matrix into three matrices, U,S and V where U and V are both orthogonal matrices. What is of importance is that dot product of U and S gives the word vector representation and V gives the word context representation.\n\nThe frequency based methods are easy to understand and their are many applications of them like text classification, sentiment analysis and many more. Because they extract positive and negative words from the text so we can easily classify them with the help of any good machine learning algorithms.\n\nCBOW is learning to predict the word by the context. A context may be single word or multiple word for a given target words.\n\nlets see this by an example \u201cThe cat jumped over the puddle.\u201d\n\nSo one approach is to treat {\u201cThe\u201d, \u201ccat\u201d, \u2019over\u201d, \u201cthe\u2019, \u201cpuddle\u201d} as a context and from these words, be able to predict or generate the center word \u201cjumped\u201d. This type of model we call a Continuous Bag of Words (CBOW) Model.\n\nBefore going in detail in CBOW lets talk about one hot representation of words : One way to represent a word as a vector is one-hot representation. One-hot representation is a representation method in which only one element is 1 and the other elements are 0 in the vector. By setting 1 or 0 for each dimension, it represents \u201cthat word or not\u201d.\n\nLet\u2019s say, for example, we represent the word \u201cpython\u201d as one-hot representation. Here, the vocabulary which is a set of words is five words(nlp, python, word, ruby, one-hot). Then the following vector expresses the word \u201cpython\u201d:\n\nAlthough one-hot representation is simple, there are weak points: it is impossible to obtain meaningful results with arithmetic between vectors. Let\u2019s say we take an inner product to calculate similarity between words. In one-hot representation, different words are 1 in different places and the other elements are 0. Thus, the result of taking the dot product between the different words is 0. This is not a useful result.\n\nAnother weak point is the vector tend to become very high dimension. Since one dimension is assigned to one word, as the number of vocabularies increases, it becomes very high dimension.\n\nWe breakdown the way this model works in these steps:\n\nWi = weight matrix between input layer and hidden layer of size [V * N]\n\nWj= weight matrix between hidden layer and output layer of size [N * V]\n\nThe loss function used is Cross entropy.\n\nand then we use gradient descent or any good optimizer to train this network. After training the weight between the hidden layer and the output layer (Wj) is taken as the word vector representation of the word. where each column represent a word vector of size [1 * N].\n\nAnother approach is to create a model such that given the center word \u201cjumped\u201d, the model will be able to predict or generate the surrounding words \u201cThe\u201d, \u201ccat\u201d, \u201cover\u201d, \u201cthe\u201d, \u201cpuddle\u201d. Here we call the word \u201cjumped\u201d the context. We call this type of model a SkipGram model.\n\nSkip-gram model reverses the use of target and context words. Skip-gram take a word and predict the context word from it.\n\nWe breakdown the way this model works in these steps:\n\nWi = weight matrix between input layer and hidden layer of size [V * N]\n\nWj= weight matrix between hidden layer and output layer of size [N * V]\n\nOne can ask that all the y\u02c6 are same so how will they help?\n\nyeah, y\u02c6 are all same but their target vectors are different so they all give different error vectors and Element-wise sum is taken over all the error vectors to obtain a final error vector. after that we use the back-propagation algorithm and gradient descent to learn the model.\n\nThere are various NLP based tasks where these word embeddings used in deep learning have surpassed older ML based models. There are various NLP applications where they are used extensively. Eg. Automatic summarization, Machine translation, Named entity resolution, Sentiment analysis, Chat-bot, Information retrieval, Speech recognition, Question answering etc.\n\nWe can visualize the learned vectors by projecting them down to 2 dimensions using for instance something like the t-SNE dimensionality reduction technique. When we inspect these visualizations it becomes apparent that the vectors capture some general, and in fact quite useful, semantic information about words and their relationships to one another. It was very interesting when we first discovered that certain directions in the induced vector space specialize towards certain semantic relationships, e.g. male-female, verb tense and even country-capital relationships between words, as illustrated in the figure below .\n\nThis explains why these vectors are also useful as features for many canonical NLP prediction tasks, such as part-of-speech tagging or named entity recognition.\n\nAs we can see all the similar words are in together. We can perform some amazing tasks from word embeddings of Word2Vec.\n\nWord Embeddings is an active research area trying to figure out better word representations than the existing ones. But, with time they have grown large in number and more complex. This article was aimed at simplying some of the workings of these embedding models without carrying the mathematical overhead.\n\nOne suggestion is that do not miss out references, by reading them only you can understand algorithm properly.\n\nHit \u2764 if this makes you little bit more intelligent."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c?source=---------1",
        "title": "Loss Functions and Optimization Algorithms. Demystified.",
        "text": "The choice of Optimisation Algorithms and Loss Functions for a deep learning model can play a big role in producing optimum and faster results. Before we begin, let us see how different components of a deep learning model affect its result through the simple example of a Perceptron.\n\nIf you are not familiar with the term perceptron, it refers to a particular supervised learning model, outlined by Rosenblatt in 1957. The architecture and behavior of a perceptron is very similar to biological neurons, and is often considered as the most basic form of neural network. Other kinds of neural networks were developed after the perceptron, and their diversity and applications continue to grow. It is easier to explain the constitutes of a neural network using the example of a single layer perceptron.\n\nA single layer perceptron works as a linear binary classifier. Consider a feature vector [x1, x2, x3] that is used to predict the probability (p) of occurrence of a certain event.\n\nWeighing factors: Each input in the feature vector is assigned its own relative weight (w), which decides the impact that the particular input needs in the summation function. In relatively easier terms, some inputs are made more important than others by giving them more weight so that they have a greater effect in the summation function (y). A bias (wo) is also added to the summation.\n\nActivation function: The result of the summation function, that is the weighted sum, is transformed to a desired output by employing a non linear function (fNL), also known as activation function. Since the desired output is probability of an event in this case, a sigmoid function can be used to restrict the results (y) between 0 and 1.\n\nOther commonly used activation functions are Rectified Linear Unit (ReLU), Tan Hyperbolic (tanh) and Identity function.\n\nError and Loss Function: In most learning networks, error is calculated as the difference between the actual output and the predicted output.\n\nThe function that is used to compute this error is known as Loss Function J(.). Different loss functions will give different errors for the same prediction, and thus have a considerable effect on the performance of the model. One of the most widely used loss function is mean square error, which calculates the square of difference between actual value and predicted value. Different loss functions are used to deal with different type of tasks, i.e. regression and classification.\n\nBack Propogation and Optimisation Function: Error J(w) is a function of internal parameters of model i.e weights and bias. For accurate predictions, one needs to minimize the calculated error. In a neural network, this is done using back propagation. The current error is typically propagated backwards to a previous layer, where it is used to modify the weights and bias in such a way that the error is minimized. The weights are modified using a function called Optimization Function.\n\nOptimisation functions usually calculate the gradient i.e. the partial derivative of loss function with respect to weights, and the weights are modified in the opposite direction of the calculated gradient. This cycle is repeated until we reach the minima of loss function.\n\nThus, the components of a neural network model i.e the activation function, loss function and optimization algorithm play a very important role in efficiently and effectively training a Model and produce accurate results. Different tasks require a different set of such functions to give the most optimum results.\n\nThus, loss functions are helpful to train a neural network. Given an input and a target, they calculate the loss, i.e difference between output and target variable. Loss functions fall under four major category:\n\nRegressive loss functions:\n\nThey are used in case of regressive problems, that is when the target variable is continuous. Most widely used regressive loss function is Mean Square Error. Other loss functions are:\n\n1. Absolute error \u2014 measures the mean absolute value of the element-wise difference between input;\n\n2. Smooth Absolute Error \u2014 a smooth version of Abs Criterion.\n\nClassification loss functions:\n\n The output variable in classification problem is usually a probability value f(x), called the score for the input x. Generally, the magnitude of the score represents the confidence of our prediction. The target variable y, is a binary variable, 1 for true and -1 for false. \n\nOn an example (x,y), the margin is defined as yf(x). The margin is a measure of how correct we are. Most classification losses mainly aim to maximize the margin. Some classification algorithms are:\n\n1. Binary Cross Entropy \n\n2. Negative Log Likelihood\n\n3. Margin Classifier\n\n4. Soft Margin Classifier\n\nEmbedding loss functions:\n\nIt deals with problems where we have to measure whether two inputs are similar or dissimilar. Some examples are:\n\n1. L1 Hinge Error- Calculates the L1 distance between two inputs.\n\n2. Cosine Error- Cosine distance between two inputs.\n\nWe performed the task to reconstruct an image using a type of neural network called Autoencoders. Different results were obtained for the same task by using different Loss Functions, while everything else in the neural network architecture remained constant. Thus, the difference in result represents the properties of the different loss functions employed. A very simple data set, MNIST data set was used for this purpose. Three loss functions were used to reconstruct images.\n\nWhile the Absolute error just calculated the mean absolute value between of the pixel-wise difference, Mean Square error uses mean squared error. Thus it was more sensitive to outliers and pushed pixel value towards 1 (in our case, white as can be seen in image after first epoch itself).\n\nSmooth L1 error can be thought of as a smooth version of the Absolute error. It uses a squared term if the squared element-wise error falls below 1 and L1 distance otherwise. It is less sensitive to outliers than the Mean Squared Error and in some cases prevents exploding gradients.\n\nOptimisation Algoritms are used to update weights and biases i.e. the internal parameters of a model to reduce the error. They can be divided into two categories:\n\nConstant Learning Rate Algorithms:\n\nMost widely used Optimisation Algorithm, the Stochastic Gradient Descent falls under this category.\n\nHere \u03b7 is called as learning rate which is a hyperparameter that has to be tuned. Choosing a proper learning rate can be difficult. A learning rate that is too small leads to painfully slow convergence i.e will result in small baby steps towards finding optimal parameter values which minimize loss and finding that valley which directly affects the overall training time which gets too large. While a learning rate that is too large can hinder convergence and cause the loss function to fluctuate around the minimum or even to diverge.\n\nA similar hyperparameter is momentum, which determines the velocity with which learning rate has to be increased as we approach the minima.\n\nAdaptive Learning Algorithms:\n\n The challenge of using gradient descent is that their hyper parameters have to be defined in advance and they depend heavily on the type of model and problem. Another problem is that the same learning rate is applied to all parameter updates. If we have sparse data, we may want to update the parameters in different extent instead.\n\nAdaptive gradient descent algorithms such as Adagrad, Adadelta, RMSprop, Adam, provide an alternative to classical SGD. They have per-paramter learning rate methods, which provide heuristic approach without requiring expensive work in tuning hyperparameters for the learning rate schedule manually.\n\nWe used three first order optimisation functions and studied their effect.\n\nGradient Descent calcultes gradient for the whole dataset and updates values in direction opposite to the gradients until we find a local minima. Stochastic Gradient Descent performs a parameter update for each training example unlike normal Gradient Descent which performs only one update. Thus it is much faster. Gradient Decent algorithms can further be improved by tuning important parametes like momentum, learning rate etc.\n\nAdagrad is more preferrable for a sparse data set as it makes big updates for infrequent parameters and small updates for frequent parameters. It uses a different learning Rate for every parameter \u03b8 at a time step based on the past gradients which were computed for that parameter. Thus we do not need to manually tune the learning rate.\n\nAdam stands for Adaptive Moment Estimation. It also calculates different learning rate. Adam works well in practice, is faster, and outperforms other techniques.\n\nStochastic Gradient Decent was much faster than the other algorithms but the results produced were far from optimum. Both, Adagrad and Adam produced better results that SGD, but they were computationally extensive. Adam was slightly faster than Adagrad. Thus, while using a particular optimization function, one has to make a trade off between more computation power and more optimum results.\n\nWe worked with Torch7 to complete this project, which is a Lua based predecessor of PyTorch.\n\nThe github repo of the complete project and codes is- https://github.com/dsgiitr/Visualizing-Loss-Functions\n\nThanks for reading and keep following our blog series on Deep Learning."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/artificial-neural-network-for-text-classification-b7aa5994d985?source=---------2",
        "title": "Artificial Neural Network for Emotion Recognition \u2013 Data Science Group, IITR \u2013",
        "text": "SVM is all about creating optimal hyperplanes between different classes in an n-dimensional space (n -> features) w.r.t. support vectors. A good way to exploit the prowess of SVM for our problem statement would be to utilize Tf-Idf (Term frequency, inverse document frequency) vectorization.\n\nA bag of words representation would simply count the instances of a unique word in every document. Simple and comprehensive, right? Well, you\u2019re missing the point. Every unique word in the whole corpus (combination of all sentences in our text data) would be given equal weight during the classification process. Our machine\u2019s a baby, it won\u2019t differentiate between the importance of words, like \u2018is\u2019 and \u2018Java\u2019, on its own!\n\nA solution to this problem could be decreasing the weights of words pretty common to all the sentences, and increasing the weights of uncommon words during our evaluation process. Scikit Learn\u2019s feature extraction library provides a Tf-Idf function to accomplish this task of re-weighting all the words in a certain sentence and creating a modified bag of words.\n\nSimple bag of words would be adequate, the complexity arrives further down!\n\n2. NBC -> Naive Bayes Classifier demands to be fed directly with text and the corresponding label. It naively assumes no interrelation between the words of a sample sentence. So the task boils down to simply associating an emotion to a sentence based on the number of words and frequency of unique words. The textblob library provides a comprehensive Naive Bayes Classifier for this function.\n\nA 3 layer neural network has been built to address this purpose. The reason behind going for a deep learning solution is to get a deeper understanding of the sentences or, in other words, the association between vectors we created out of the sentences and the mapped emotion. We want the machine to understand the arrangement of words that leads sentence/s conveying a meaningful emotion. Over here, a very basic neural network has been created in an attempt to better the classification provided by SVM and NBC. Let\u2019s take a look at the different layers of the constructed neural network.\n\n2. Data is fed to the hidden layer where it gets transformed into a logistic classifier (WX + b). However, the bias vector \u2018b\u2019 isn\u2019t added to the matrix dot product \u2018WX\u2019 in this layer. The loss function and the (W, b) parameter matrices are stored in the form of a matrix called synapse, \u2019cause after all, it\u2019s an artificial neural network we\u2019re talking about, we ought to come up with at least some sort of analogy!\n\n3. The logistic classifier matrix is then scaled to sigmoid non-linearity (to counter scaling issues). This completes our second/hidden layer, \u2018l1 = sigmoid_matrix_multiplication(l0, weight_parameters)\u2019.\n\n4. The loss function is minimized using SGD (Stochastic Gradient Descent), by iterating a specific number of times over the training data, resulting in optimal parameter matrix W and b.\n\n5. The third/output layer serves to add the SGD optimized bias term \u2018b\u2019 to the matrix dot product \u2018WX\u2019. Learn why bias is necessary for classification here.\n\n6. The final step is to convert the logistic scores (logits) to probabilities using the softmax function. These probabilities will give us the idea of the closest feeling associated with a particular sentiment.\n\nThe optimization iterates over the complete data for a specified number of times. If a local number of iterations don\u2019t do any difference to the error reduced, the iteration stops.\n\nBelow is the result obtained after training on 15% of the complete data."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/artistic-style-transfer-with-convolutional-neural-network-7ce2476039fd?source=---------3",
        "title": "Artistic Style Transfer with Convolutional Neural Network",
        "text": "We all have used apps like Prisma and Lucid, but ever wondered how these things works? Like we give a photo from our camera roll and select a design to mix both the images and we get a new image which has the content of our input image and style of the design image. In the world of deep learning this is called style transfer.\n\nStyle transfer is the technique of recomposing images in the style of other images. It all started when Gatys et al. published an awesome paper on how it was actually possible to transfer artistic style from one painting to another picture using convolutional neural networks..\n\nHere are some examples :\n\nConvolutional Neural Networks (CNNs) are a category of Neural Network that have proven very effective in areas such as image recognition and classification. CNNs have been successful in computer vision related problems like identifying faces, objects and traffic signs apart from powering vision in robots and self driving cars.\n\nCNN is shown to be able to well replicate and optimize these key steps in a unified framework and learn hierarchical representations directly from raw images.If we take a convolutional neural network that has already been trained to recognize objects within images then that network will have developed some internal independent representations of the content and style contained within a given image.\n\nHere is an example of CNN hierarchy from VGG net where shallow layers learns low level features and as we go deeper into the network these convolutional layers are able to represent much larger scale features and thus have a higher-level representation of the image content.\n\nAll winning architectures of ImageNet Large Scale Visual Recognition Challenge in recent years have been some form of convolutional neural network \u2014 with the most recent winners even being able to surpass human level performance!\n\nIn 2014, the winner of the ImageNet challenge was a network created by Visual Geometry Group (VGG) at Oxford University, achieving a classification error rate of only 7.0%. Gatys et. al use this network \u2014 which has been trained to be extremely effective at object recognition \u2014 as a basis for trying to extract content and style representations from images.\n\nWe can construct images whose feature maps at a chosen convolution layer match the corresponding feature maps of a given content image. We expect the two images to contain the same content \u2014 but not necessarily the same texture and style.\n\nGiven a chosen content layer l, the content loss is defined as the Mean Squared Error between the feature map F of our content image C and the feature map P of our generated image Y.\n\nWhen this content-loss is minimized, it means that the mixed-image has feature activation in the given layers that are very similar to the activation of the content-image. Depending on which layers we select, this should transfer the contours from the content-image to the mixed-image.\n\nWe will do something similar for the style-layers, but now we want to measure which features in the style-layers activate simultaneously for the style-image, and then copy this activation-pattern to the mixed-image.\n\nOne way of doing this, is to calculate the Gram-matrix(a matrix comprising of correlated features) for the tensors output by the style-layers. The Gram-matrix is essentially just a matrix of dot-products for the vectors of the feature activations of a style-layer.\n\nIf an entry in the Gram-matrix has a value close to zero then it means the two features in the given layer do not activate simultaneously for the given style-image. And vice versa, if an entry in the Gram-matrix has a large value, then it means the two features do activate simultaneously for the given style-image. We will then try and create a mixed-image that replicates this activation pattern of the style-image.\n\nIf the feature map is a matrix F, then each entry in the Gram matrix G can be given by:\n\nThe loss function for style is quite similar to out content loss, except that we calculate the Mean Squared Error for the Gram-matrices instead of the raw tensor-outputs from the layers.\n\nAs with the content representation, if we had two images whose feature maps at a given layer produced the same Gram matrix we would expect both images to have the same style, but not necessarily the same content. Applying this to early layers in the network would capture some of the finer textures contained within the image whereas applying this to deeper layers would capture more higher-level elements of the image\u2019s style. Gatys et. al found that the best results were achieved by taking a combination of shallow and deep layers as the style representation for an image.\n\nWe can see that the best results are achieved by a combination of many different layers from the network, which capture both the finer textures and the larger elements of the original image.\n\nUsing a pre-trained neural network such as VGG-19, an input image (i.e. an image which provides the content), a style image (a painting with strong style elements) and a random image (output image), one could minimize the losses in the network such that the style loss (loss between the output image style and style of \u2018style image\u2019), content loss (loss between the content image and the output image) and the total variation loss (which ensured pixel wise smoothness) were at a minimum. In such cases, the output image generated from such a network, resembled the input image and had the stylist attributes of the style image.\n\nThe total loss can then be written as a weighted sum of the both the style and content losses.\n\nwe will minimize our total loss by Adam optimizer. As our loss go down we will go close to our goal of producing a style transfer image Y.\n\nAudio/Music style transfers have already made some progress and several more use cases pertaining to unique human tasks like the style of playing chess etc. are also being explored, using more generalized frameworks of style transfer.\n\nOne suggestion is that do not miss out references, by reading them only you can understand algorithm properly.\n\nHit \u2764 if this makes you little bit more intelligent."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/building-a-convolutional-neural-network-in-python-with-tensorflow-d251c3ca8117?source=---------4",
        "title": "Convolutional Neural Network with TensorFlow implementation",
        "text": "Originally developed by Yann LeCun decades ago, better known as CNNs (ConvNets) are one of the state of the art, Artificial Neural Network design architecture, which has proven its effectiveness in areas such as image recognition and classification. The Basic Principle behind the working of CNN is the idea of Convolution, producing filtered Feature Maps stacked over each other.\n\nA convolutional neural network consists of several layers. Implicit explanation about each of these layers is given below.\n\nThe Conv layer is the core building block of a Convolutional Neural Network. The primary purpose of Conv layer is to extract features from the input image.\n\nThe Conv Layer parameters consist of a set of learnable filters (kernels or feature detector). Filters are used for recognizing patterns throughout the entire input image. Convolution works by sliding the filter over the input image and along the way we take the dot product between the filter and chunks of the input image.\n\nPooling layer reduce the size of feature maps by using some functions to summarize sub-regions, such as taking the average or the maximum value. Pooling works by sliding a window across the input and feeding the content of the window to a pooling function.\n\nThe purpose of pooling is to reduce the number of parameters in our network (hence called down-sampling) and to make learned features more robust by making it more invariant to scale and orientation changes.\n\nReLU stands for Rectified Linear Unit and is a non-linear operation. ReLU is an element wise operation (applied per pixel) and replaces all negative pixel values in the feature map by zero.\n\nThe purpose of ReLU is to introduce non-linearity in our ConvNet, since most of the real-world data we would want our ConvNet to learn would be non-linear.\n\nOther non linear functions such as tanh or sigmoid can also be used instead of ReLU, but ReLU has been found to perform better in most cases.\n\nThe Fully Connected layer is configured exactly the way its name implies: it is fully connected with the output of the previous layer. A fully connected layer takes all neurons in the previous layer (be it fully connected, pooling, or convolutional) and connects it to every single neuron it has.\n\nAdding a fully-connected layer is also a cheap way of learning non-linear combinations of these features. Most of the features learned from convolutional and pooling layers may be good, but combinations of those features might be even better.\n\nTensorFlow is an open source software library created by Google for numerical computation using data flow graphs.\n\nNodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) that flow between them. This flexible architecture lets you deploy computation to one or more CPU's or GPU\u2019s in a desktop, server, or mobile device without rewriting code.\n\nIn this article, we will be using MNIST, a data-set of handwritten digits (The \u201chello world\u201d of image recognition for machine learning and deep learning).\n\nIt is a digit recognition task. There are 10 digits (0 to 9) or 10 classes to predict. Each image is a 28 by 28 pixel square (784 pixels total). We\u2019re given a total of 70,000 images."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/baby-steps-with-tensoflow-2-88fc83205262?source=---------5",
        "title": "Baby steps with Tensoflow #2 \u2013 Data Science Group, IITR \u2013",
        "text": "In this blog we will understand how to use Tensoflow for Linear and Logistic Regression. I hope you have read 1st blog of this series, if not please give it a read.\n\nNo. you will not. Though to understand each function of Tensorflow properly I suggest you go through this.\n\nEquation of Y in terms of X_data\n\nNow, to start with we need to define Place holders for the data feeding while training. We have seen what placeholders do in the last blog.\n\nHere shape is [None, 4]. What does this mean? It means we can provide any value in place of None. So while feeding we can provide as many examples we want. This is very useful in mini batch training, which we will see in the subsequent blogs. So, basically we feed training data through placeholders.\n\nNow we will define weight variable and intercept term. This will be tf.Variable because we need to find the value of W and b. So, we will initialize it randomly and then using optimization algorithm we will reach to the true value.\n\nNext we generate our hypothesis. Read more about more matrix functions like matmul here.\n\nNow we will define our loss function. We will be using RMSE (reduced mean squared error) loss.\n\nNext we will use Stochastic Gradient Optimizer to minimize this loss. If you don\u2019t know how this optimization is carried out, I strongly suggest you to read this great blog on gradient descent optimization.\n\nNow as we\u2019ve seen in previous blog, tensorflow is Static graph. We need to start Tensorflow session to pass data through this graph.\n\nNow everything is set. We need to feed data to the graph and find the optimal values for W and b\n\nNow here you need to understand what sess.run() does? It basically computes the values of the quantities you specified (in our case Loss, hypothesis, W, b, train). But look train is not a quantity, it\u2019s just an optimizer trying to minimize error. So, based on the current error when you run train, it will update values of W and b. This will continue for all 20000 epochs.\n\nAs you can see at the end W and b values are very close to its original values.\n\nYou can find a full code here.\n\nWe will use iris data for logistic regression. Iris data has three classes (setosa, versicolor and virginica). I used setosa as class \u201c0\u201d and versicolor and virginica as class \u201c1\u201d.\n\nHere is how you import data using tensorflow. We have two files iris_training.csv and iris_test.csv\n\nNow to import data from these csv. More about reading data in tensorflow here.\n\nNow logistic regression is useful can do binary classification only! So, we need to merge two classes.\n\nAgain it\u2019s the same as before. Define placeholders, variables, Hypothesis, Loss function and Optimizer.\n\nThis all steps are self explaining. Here loss in categorical cross entropy loss, you can read about it here\n\nIf hypothesis value is > 0.5, class \u20181\u2019 otherwise class 0. And accuracy is simple classification accuracy.\n\nCheck the accuracy on test data. It is about 0.73\n\nBoth accuracies are comparable, but sklearn is surprisingly fast. I have to look into it.\n\nIn my full code here, I have even tried regularization at the end, but it didn\u2019t improve accuracy.\n\nNote: I strongly suggest to go deep into references. Whatever I\u2019ve written here is just to make you feel comfortable with tensorflow, but all the magics lie in References.\n\nHit \u2764 if this was useful."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/baby-steps-with-tensorflow-1-b29091d502fd?source=---------6",
        "title": "Baby steps with Tensorflow #1 \u2013 Data Science Group, IITR \u2013",
        "text": "Yes, Deep learning is a next big thing. Yes, AI is changing the world. Yes, It will take over your jobs. All fuss aside, you need to sit down and write a code on your own to see things working. Practical knowledge is as much important as Theoretical knowledge.\n\nThere are many deep learning frameworks which make it really easy and fast to train different models and deploy it. Tensorflow, PyTorch, Theano, Keras, Caffe, Tiny-dnn and list goes on. Here is the great comparison for those want to know pros and cons of each one.\n\nWe will focus on Tensorflow. (For all the great debaters out there, I\u2019m not a supporter of anyone. Turns out tensorflow is relatively new with really great resources to learn and most of the industries seems to use it.) I\u2019m learning tensorflow from other resources, so I will try to merge them here in best way possible. This will surely help those who haven\u2019t used Tensorflow before, I can not say anything for others. Though it is assumed that you all have basic under standing of Neural Networks, Loss functions, Optimization techniques, Backpropagation, etc. If not I suggest you go through this great book by Michael Nielsen. I will also be mentioning more often other libraries like numpy, sklearn, matplotlib, etc.\n\nConstants: Here constants has same meaning as in any other programming language. They stores constant value. (Integer, float, etc.)\n\nWhere will you be using constants? Value which are not supposed to change! Like number of layers, shape of the weight vectors, shape of each layer, etc. Some of the great constant initializers are here (most like numpy). Thing to notice is that you can not even get a value of tensor until you initialize a session. What is session? We will get to it.\n\nVariables are those, which will be updated in Tensorflow graph. For example: Weights and biases. More about variables here.\n\nPlaceholders are as name suggest reserve space for the data. So, while feed forwarding you can feed data into network through placeholders. Placeholders have defined shape. If your input data has n-dimensions, you need to specify n-1 dimensions and then while feeding, you can feed data into batches in the network. More about placeholders here.\n\nOperation are basic function we define on variables, constants and placeholders. More about operations here\n\nSession is a class implemented in Tensorflow for running operations, and evaluating constants and variables. More about session here.\n\nWhat are the main steps of any machine learning algorithm in Tensorflow?\n\nHere is vary simple example for multiply operation on two constants.\n\nAnd here is other simple computation graph.\n\nThat\u2019s it for now!\n\nYou can find source code for this assignment on my github repo.\n\nNext we will see Linear and Logistic Regression.\n\nHit \u2764 if you find this useful. :D"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/singular-value-decomposition-elucidated-e97005fb82fa?source=---------7",
        "title": "Singular Value Decomposition. Elucidated. \u2013 Data Science Group, IITR \u2013",
        "text": "Mathematics is building block of Machine learning. I know math is hard to understand but it is much needed as well. Singular value decomposition (SVD) is one mathematical method used in various applications.\n\nSingular Value Decomposition is a matrix factorization method which is used in various domains of science and technology. Furthermore, due to recent great developments of machine learning, data mining and theoretical computer science, SVD has been found to be more and more important. It is not only a powerful tool and theory but also an art.\n\nMatrix Factorization: It is a representation of a matrix into a product of matrices. There are many different matrix factorization and each used for different class of problems.\n\nFor a m \u00d7 n matrix(M) there exists a singular value decomposition of M, of the form\n\nConjugate Transpose: The conjugate transpose of a matrix interchanges the row and column index for each element.\n\nIdentity matrix: It is a square matrix in which all the elements of the principal diagonal are ones and all other elements are zeros.\n\nDiagonal Matrix: It is a matrix in which the entries outside the main diagonal are all zero.\n\nUnitary matrix: Matrices whose conjugate transpose is also its inverse, that is UU*=I.\n\nSingular Values: Basically it denotes the square root of the eigenvalues of XX* where X is a matrix.\n\nThe above process describes is the inverse of SVD.\n\nThe expression U\u03a3V* can be interpreted as a composition of three geometrical transformations: a rotation, a scaling, and another rotation. SVD is generally used for data compression in various fields. Other than data compression the resultant matrices has lots of wonderful properties.\n\nif M is symmetric positive definite its eigenvectors are orthogonal and we can write M= Q\u03a3Q*. This is a special case of a SVD, with U = V = Q\n\nPrincipal components analysis is a procedure for identifying a smaller number of uncorrelated variables, called \u201cprincipal components\u201d, from a large set of data. The goal of principal components analysis is to explain the maximum amount of variance with the fewest number of principal components. For more details, go through this blog.\n\nLet M be m \u00d7 n matrix where m is the number of samples and n is the number of features\n\nThe covariance matrix of M is C\n\nNote : The above is correct only if M is centered(scaled). Only then is covariance matrix equal to M*M/(m\u22121). That is why we need to center the intial dataset M for PCA.\n\nThe right singular vectors V are principal directions and Principal components are given by MV=U\u03a3V*V=U\u03a3. To reduce the dimensionality of the data from m to k where k<m, select the first k columns of U\u03a3.\n\nThis blog tries to aware you about the basic mathematics of singular value decomposition and different application of singular value decomposition. Go through the references to understand it thoroughly.\n\n\u2764 if this was good read."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/data-science-congress-something-legendary-271df010677b?source=---------8",
        "title": "Data Science Congress. Something legendary. \u2013 Data Science Group, IITR \u2013",
        "text": "I know. You know. Everybody knows. What?\n\nIn such a scenario, finding a place where there\u2019s a good intermix of World-class Professionals with astounding backgrounds and open platforms for discussion is tough. Very tough.\n\nThis is what DSC website says. As far as I am concerned, it\u2019s the must-attend event for any Data Science or ML Enthusiast. Whether you are a Beginner, or Advanced, I can bet you won\u2019t regret being a part of this!\n\nIf you don\u2019t agree already, read till the end. You\u2019ll be packing bags for Mumbai after that.\n\nBeing the country\u2019s largest Data science meet, it caters to impress the audience with a variety of approaches. From Key Notes to Research Paper presentations, from Technology exhibition to Idea propagation, DSC has all the bases covered in desirable proportions.\n\nFor anyone beginning Data Science or wanting to explore, there can be nothing better than active participation in DSC\u201917!\n\nThis post talks about the great keynote speeches and talks lined up for the event. Just try and appreciate the diversity that shall be covered within a span of 3\u20134 days. Commendable effort by the organisers!\n\nTo put things in perspective, the entire panel consists of 54 speakers belonging to different countries, ethnicities and professional pasts. Without exposure to Industry and actual market conditions, excelling in any field is strenuous.\n\nFor detailed coverage of every speaker in other domains, keep following this space.\n\nOther aspects of the Congress i.e. workshops and start-up pitches shall be discussed after the keynote description!\n\nP.S. - This is my personal division and opinion of DSC\u201917. :)\n\nDo try and be a part for your own benefit. DS Community needs opportunities like these for extensive knowledge.\n\nAnd, \u2764 if this was a good read. Enjoy!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/regularization-a-smooth-trick-to-increase-robustness-of-regression-models-a5e8a91737ff?source=---------9",
        "title": "Regularization. Clarified. \u2013 Data Science Group, IITR \u2013",
        "text": "Before explaining this property, let\u2019s look at another way of writing minimisation objective. One can show that the lasso and ridge regression coefficient estimates solve the problems respectively.\n\nIn other words, for every value of \u03b1, there is some \u2018s\u2019 such that the equations (old and new cost functions) will give the same coefficient estimates. \n\nWhen p=2, then (6.8) indicates that the lasso coefficient estimates have the smallest RSS out of all points that lie within the diamond defined by |\u03b21|+ |\u03b22|\u2264s. \n\nSimilarly, the ridge regression estimates have the smallest RSS out of all points that lie within the circle defined by (\u03b21)\u00b2+(\u03b22)\u00b2\u2264s\n\nNow, the above formulations can be used to shed some light on the issue.\n\nThe least squares solution is marked as \u03b2\u02c6, while the blue diamond and circle represent the lasso and ridge regression constraints as explained above. \n\nIf \u2018s\u2019 is sufficiently large, then the constraint regions will contain \u03b2\u02c6, and so the ridge regression and lasso estimates will be the same as the least squares estimates. (Such a large value of s corresponds to \u03b1=0 in the original cost function). However, in figure, the least squares estimates lie outside of the diamond and the circle, and so the least squares estimates are not the same as the lasso and ridge regression estimates. The ellipses that are centered around \u03b2\u02c6 represent regions of constant RSS.\n\nIn other words, all of the points on a given ellipse share a common value of the RSS. As the ellipses expand away from the least squares coefficient estimates, the RSS increases. The above equations indicate that the lasso and ridge regression coefficient estimates are given by the first point at which an ellipse contacts the constraint region.\n\nSince, ridge regression has a circular constraint with no sharp points, this intersection will not generally occur on an axis, and so the ridge regression coefficient estimates will be exclusively non-zero. \n\nHowever, the lasso constraint has corners at each of the axes, and so the ellipse will often intersect the constraint region at an axis. When this occurs, one of the coefficients will equal zero. In higher dimensions, many of the coefficient estimates may equal zero simultaneously. In figure, the intersection occurs at \u03b21=0, and so the resulting model will only include \u03b22."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/logistic-regression-simplified-9b4efe801389",
        "title": "Logistic Regression. Simplified. \u2013 Data Science Group, IITR \u2013",
        "text": "It\u2019s a classification algorithm, that is used where the response variable is categorical. The idea of Logistic Regression is to find a relationship between features and probability of particular outcome.\n\nE.g. When we have to predict if a student passes or fails in an exam when the number of hours spent studying is given as a feature, the response variable has two values, pass and fail.\n\nThis type of a problem is referred to as Binomial Logistic Regression, where the response variable has two values 0 and 1 or pass and fail or true and false. Multinomial Logistic Regression deals with situations where the response variable can have three or more possible values.\n\nWith binary classification, let \u2018x\u2019 be some feature and \u2018y\u2019 be the output which can be either 0 or 1. \n\nThe probability that the output is 1 given its input can be represented as:\n\nIf we predict the probability via linear regression, we can state it as:\n\nLinear regression model can generate the predicted probability as any number ranging from negative to positive infinity, whereas probability of an outcome can only lie between 0< P(x)<1."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/linear-regression-back-to-basics-e4819829d78b",
        "title": "Linear Regression. Back to Basics. \u2013 Data Science Group, IITR \u2013",
        "text": "Yes, we are complicating it for you. Be open to new stuff. :D\n\nThis method uses a single independent variable to predict a dependent variable by fitting a best linear relationship.\n\nThis method uses more than one independent variable to predict a dependent variable by fitting a best linear relationship.\n\nIn case of Multiple Regression, the parameters can be found in the same way as that in the case of simple linear regression, by minimising the cost function using:\n\nNote: It works best when multicollinearity is absent. It\u2019s a phenomenon in which two or more predictor variables are highly correlated.\n\nSometimes, Linear splines is used to reduce the problem to Linear Regression. In this method, we fit the data with a piece-wise linear function. Let us suppose that the knots are at at k1 and k2 in the scatter plot as shown in the figures below. You may be thinking that we can divide the data into three groups using k1 and k2 and solve three regression problems (blue lines in left figure). But as you can see, it does not assure continuity!\n\nTo make the curve continuous , we can use the fact that any linear spline can be a linear combination of basis functions. Thus, the objective of the linear splines is to fit the red lines in the data (as shown in left figure). So, we can build a piece-wise linear function step by step.\n\nThis regression model is used when we have more than one independent variable. It uses automatic procedure to select important independent variables and there is no human intervention.\n\nSo you can see, Stepwise Linear Regression is applying Multiple Linear Regression multiple times and selecting the important variables or removing the least significant predictors each time.\n\nNote 1: For Backward Stepwise Linear Regression or Multiple Linear Regression to work fine, the number of observations (n) should be more than the number of variables(p). It is because we can do least squares regression only when n is greater than p. For p greater than n, least squares model is not even defined.\n\nNote 2: Automatic procedures may not choose the right significant variables from practical point of view as they don\u2019t have the special knowledge the analyst might have."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/naive-bayes-unfolded-b2ab036b42b1",
        "title": "Naive Bayes. Unfolded. \u2013 Data Science Group, IITR \u2013",
        "text": "As indicated, the objects can be classified as either or . Our task is to classify new cases as they arrive, i.e., decide to which class label they belong, based on the currently existing objects.\n\nSince there are twice as many objects as , it is reasonable to believe that a new case (which hasn't been observed yet) is twice as likely to have membership rather than . \n\nIn the Bayesian analysis, this belief is known as the prior probability. Prior probabilities are based on previous experience. In this case, the percentage of and objects, are often used to predict outcomes before they actually happen.\n\nSince, there are a total of objects, of which are and 20 , our prior probabilities for class membership are:\n\nHaving formulated our prior probability, we are now ready to classify a new object ( circle in the diagram below).\n\nTo measure this likelihood, we draw a circle around X which encompasses a number (to be chosen apriori) of points irrespective of their class labels. Then, we calculate the number of points in the circle belonging to each class label:\n\nFrom the illustration above, it is clear that Likelihood of given is smaller than Likelihood of given , since the circle encompasses object and ones. Thus:\n\nAlthough the prior probabilities indicate that may belong to (given that there are twice as many compared to ) the likelihood indicates otherwise; that the class membership of is (given that there are more objects in the vicinity of than )."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/association-rule-mining-deciphered-d818f1215b06",
        "title": "Association Rule Mining. Deciphered. \u2013 Data Science Group, IITR \u2013",
        "text": "In our 12A12D series, we are trying to be as diverse as possible. I can bet that 90% of you are unaware of ARM Techniques, even though they are basics of Data Mining.\n\nNow, let\u2019s try to understand this:\n\nThe concept used above is what ARM is all about \u2014 Associating things/objects by using some rules."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/clustering-described-63e62833099e",
        "title": "Clustering. Described. \u2013 Data Science Group, IITR \u2013",
        "text": "After Supervised Learning algorithms, it\u2019s time to have a look at the most popular Unsupervised method. Here, we present to you - Clustering, and it\u2019s variants.\n\nLet\u2019s look at it\u2019s simplicity here:\n\nIn our daily life, we group different activities according to their utility. This grouping is what you need to learn."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/dimensionality-reduction-untangled-5fe391f6aeae",
        "title": "Dimensionality Reduction. Untangled. \u2013 Data Science Group, IITR \u2013",
        "text": "Most of the time, we deal with datasets having lots of redundant parameters that don\u2019t provide significant amount of new information to us. Using these parameters in building our model won\u2019t help in increasing our accuracy for prediction and may decrease too!\n\nOne way to deal with it could be by deleting these parameters but this would lead to significant data loss if there are many such parameters.\n\nHence, dimensionality reduction comes into the picture."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/support-vector-machines-svm-unraveled-e0e7e3ccd49b",
        "title": "Support Vector Machines. Unwinded. \u2013 Data Science Group, IITR \u2013",
        "text": "Mathematics of SVM is little bit tricky. And I can not avoid it. Sorry for little bit more maths for this Blog. But then one should remember,\n\nThe goal of SVM is to identify an optimal separating hyperplane which maximizes the margin between different classes of the training data.\n\nHyperplane: It is basically a generalization of plane.\n\nWe can define margin in two ways.\n\nNow functional margin of an ith observation is defined by:\n\nNow functional margin of classifier is smallest of the functional margins of individuals training examples.\n\nOptimal Separating Hyperplane: Idea is to choose the hyperplane which is at maximize margin from both the classes of training data. Maximizing the distance between the nearest points of each class (minimum of functional margins of all the examples) and the hyperplane would result in an optimal separating hyperplane.\n\nSupport Vectors: Support Vectors are simply the co-ordinates of data points which are nearest to the optimal separating hyperplane.\n\nSo, basically what we want to do is\n\nBut now, for us we can set functional margin to 1. Because it\u2019s nothing but a scaling which should not affect optimization problem. So, this maximization problem converges to minimization problem. Which is,\n\nI know by now you\u2019ll be feeling\n\nOkay I admit it. This was too much, but much needed as well. After this you can read Andrew Ng\u2019s notes on SVM.\n\nIn practice, real data is messy and cannot be separated perfectly with a hyperplane. Now in this case there are no two hyperplanes which separate the data with no points between them.\n\nSo, the constraint of maximizing the margin of the line that separates the classes must be relaxed. This is called the soft margin classifier. This allows some points in the training data to violate the separating line. A tuning parameter is introduced called C which defines the amount of violation of the margin allowed.\n\nSo, now relaxed constraint looks like this:\n\nWhere C is a penalty parameter. This is called a soft margin classifier, because we allow that data of one class can be in the region of the other class but we\u2019ll put a penalty on that. The smaller the value of C, the more sensitive the algorithm is to the training data (higher variance and lower bias). The larger the value of C, the less sensitive the algorithm is to the training data (lower variance and higher bias).\n\nIn the case of non-linearly separable data points SVM uses the kernel trick. The idea stems from the fact that if the data cannot be partitioned by a linear boundary in its current dimension, then projecting the data into a higher dimensional space may make it linearly separable.\n\nHere, controlling parameter is gamma for all the kernels, except linear. From my experience, RBF is the most popular kernel choice in SVM.\n\nWe have talked about binary classification problem using SVM. But, how to extend it for multiclass classification problem is still an ongoing research.\n\nMainly there are two methods for Multiclass classification in SVM."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/what-does-samsung-india-vp-has-to-say-about-data-science-9e1e5df21dc8",
        "title": "What Samsung India VP has to say about Data Science?",
        "text": "Cognizance, IIT Roorkee invites many good speakers during their event.\n\nThis time, I got a chance to listen to Mr. Balaji Holur, senior Vice President of Android Platform and Multimedia System Division at Samsung Research India. And, it turned out to be one of the best talks I have attended so far.\n\nThis is what we were focusing from the beginning. As senior members of DSG, IITR, we have advised all our juniors to strengthen their Statistics and Probability concepts. Everything else shall follow.\n\nThis somehow give us a relief that we were right all this while.\n\nAccording to him, all of us are on the same page in the world of AI and Machine Learning because these are relatively new fields and it is possible that you know more about AI than your company VP. And I second that. When you are learning from same Coursera course as your senior, why would there be a knowledge gap.\n\nWhen you are diving in a new line of study, it is always better to see a bigger picture. And, listening to VP of one of the BIG BOYS of Silicon Valley will give you a rough estimate(gotta cope anyway).\n\nIn his presentation, he briefed about all the technologies which Samsung is working on currently. Not surprisingly, they are centered around Advanced Machine Learning and Applied Artificial Intelligence. \n\nAnd these skills are going to be most important for at least next 50 Years. Deep Learning which has evolved rapidly in last 5 years is going to stay and those who excel in it will be the one who\u2019ll succeed.\n\nApart from business side, all the products use Advance Machine Learning capabilities to understand and serve their users best. Intelligent Apps, Internet of Things, Chat bots and even simple simple photo storing tech like Google photos use ML and AI technologies to serve you better at every step.\n\nIn a nutshell, next 30 Years are going to be the best for Data Economy. Those who can use Data well are going to win. Simple. \n\nAnd if you want to remain competitive in technical field, it is high time that you start learning about Data Science. Noobs can start with Machine Learning Coursera course or you can follow our 12A-12D series!\n\nThis gave me more enthusiasm than ever to work in this field and work for other juniors who are seeking help through DSG.\n\nThank you for reading!\n\nHit \u2764 if this clears some of your doubts."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/bagging-unraveled-8141ca078ccc",
        "title": "Bagging. Unraveled. \u2013 Data Science Group, IITR \u2013",
        "text": "In our previous post on Decision Trees, we introduced the world of Tree-Based Modeling to you. Here, we extend that to explain a new concept known as Bagging or Bootstrap Aggregating.\n\nTo start off, here are some bags for you:\n\nIt is as simple as putting things in a bag. Of course, with some technicalities."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/boosting-a0ab852754f2",
        "title": "Boosting. Decrypted. \u2013 Data Science Group, IITR \u2013",
        "text": "A family of machine learning ensemble meta-algorithms in supervised learning that improve the accuracy of ML algorithms.\n\nFirst original boosting technique: highly accurate prediction rule by combining many weak and inaccurate rules. \n\nClassic use case: Face Detection\n\nAbove shown is the sample space we shall use for classification.\n\nBox1 : Equal weights are assigned to all observations and a decision stump is applied to classify + or - . S1 has generated a vertical line on the left side to classify the data points. This decision stump incorrectly predicted three +. So, we\u2019ll assign more weight to these three data points in our next decision stump.\n\nBox2 : The size difference between those three incorrectly predicted and the rest of the data points is clearly visible. Another decision stump (S2) is applied to predict them correctly on the right side of the box. But, this time three - are classified incorrectly. Repeat.\n\nBox3 : Here, three - are given higher weights. S3 is applied to predict these misclassified observations correctly. This time, a horizontal line is generated to classify - and +.\n\nBox4 : Here, we combine S1, S2, and S3 to form a strong prediction having a complex rule as compared to the individual weak learners. Evidently, this algorithm has classified these observations accurately as compared to any of the individual weak learners.\n\nMostly, we use decision stumps with AdaBoost. But, any machine learning algorithm can be used as base learner if it accepts weights on the training data set. (Both Classification and Regression)\n\nHere, the essential params are explained. Rest can be mugged from Sklearn."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/decision-trees-decoded-c70b4f7ff542",
        "title": "Decision Trees. Decoded. \u2013 Data Science Group, IITR \u2013",
        "text": "It\u2019s time to give the Algorithm series, an informative start. Here, we start with one of the most famous category i.e. Tree Based Models, which consists of Decision Trees, Random Forest and Boosting methods.\n\nTo initiate the learning with a basic example, here\u2019s a decision tree for you:\n\nYes, you may be thinking that ML can\u2019t be this easy. Frankly, it is. Trust me."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/k-nearest-neighbors-knn-500f0d17c8f1",
        "title": "k Nearest Neighbors. Explained. \u2013 Data Science Group, IITR \u2013",
        "text": "The kNN algorithm is associated with a similar amount of laziness as above. When a lot of training data samples along with their independent features and labels are fed, it stores all of it in the memory, or, rather plots the data in an n-dimensional space on the basis of its features. Hence, every sample is represented by a certain point in this plot, and colored or marked in a way to indicate its label.\n\nWhen this algorithm is faced by a test sample, it plots that sample in the same n-dimensional space as the training data and then searches for its k nearest neighbors based on any of these distance measures from the training samples. Yes, it goes through the complete training data every time it needs to predict a test sample\u2019s classification label! This is why it\u2019s called a Lazy learning technique.\n\nSelecting which measure to use where, is experience based and depends on the type of data to be processed. In the real data set we can have Categorical, Numerical or mixed type (both numerical and categorical) of attributes, based on which distance measures may change.\n\nThe nearest neighbor search doesn\u2019t necessarily mean that the algorithm would linearly compare the test sample to the training data as if it were a list. Certain optimized searching algorithms exist for this purpose, like KDTree, and BallTree.\n\nThe distance measures lose accuracy while dealing with higher dimensions. For instance, read this answer to understand why euclidean distance in higher dimensions is a problem.\n\nWhile calculating distance we assume that all the attributes have same effect. However, it\u2019s a general intuition that they don\u2019t. The similarity metrics (or distance measures) we use generally do not consider the relations of the attributes, which results in an incorrect classification. This is termed as the curse of dimensionality.\n\nWe can assign weights to the attributes which are more relevant to our classification than the others. The weight assignment is random initially, and can be changed later on the basis of classification error.\n\nOnce the nearest neighbors are spotted, weights are assigned to all of them so as to register their vote on the label of the test sample. The weights can either be uniform (equal dominance of all neighbors) or inversely proportional to the distance of the neighbor from the test sample. You can also devise your own weight assignment algorithm. This is comprehensively what kNN classification is all about."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/algos-algos-everywhere-f4e684473f14",
        "title": "Algos! Algos everywhere! \u2013 Data Science Group, IITR \u2013",
        "text": "\u201cAn apple a day keeps the doctor away\u201d dates back to 19th century. It\u2019s 21st century already, and time to move on!\n\nHere, we intend to brief all of you about the most common machine learning algorithms, and help you with the understanding.\n\nOn the mentioned dates, a blogpost shall be released.\n\nThe randomness in the order is not random, but has been purposely intended. :)\n\nKeep following this space for better learning!\n\n\u2764 it so that everyone can get better at DS."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/stop-thinking-start-applying-d607241e309e",
        "title": "Stop Thinking. Start Applying. \u2013 Data Science Group, IITR \u2013",
        "text": "It\u2019s already the end of February, and for those of you who are looking for internships or jobs in Data Science, there can\u2019t be a better time to start the daily routine of applying to 50 Companies! Just kidding.\n\nEven if you haven\u2019t started, it is not late. But, it\u2019s not too early also. As you are reading this, there are people who are giving interviews for those companies that you seek to target.\n\nAfter my last post where I urged you to start learning, here, I request you to start applying, because industrial exposure matters.\n\nWhen you apply for a position, you are basically selling yourself to the company. This is is the place where you get maximum opportunities to market your capabilities.\n\nFor the second yearites who haven\u2019t done much till now but want to apply, mention courses that you have completed, or data science problems as projects. Here\u2019s Elon Musk with his one-page brief:\n\nSpend 4\u20135 days in building the resume. Ask for suggestions from people near you. Perfection isn\u2019t achieved in one go.\n\nDrafts after drafts, you\u2019ll get the right one!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/my-journey-from-a-noob-to-getting-selected-in-data-science-group-iit-roorkee-95ae9fe1ae32",
        "title": "Journey from a noob to DSG. 3rd Year. \u2013 Data Science Group, IITR \u2013",
        "text": "I was 10 days away from my end term examinations for 3rd year first semester. I had already tried hands on Udacity and Coursera for learning python, pursued a handful of sites for web development and tried questions on sites like HackerEarth. But I never felt interested enough and hence, lost my motivation just in a couple of months.\n\nMany people recommended various courses on basic statistics and Machine Learning algorithms such as Coursera ML by Andrew Ng, Analytics Edge on EdX etc. I finally singled out CS 109 by Harvard as it is python based and not as long as the one by Andrew Ng, and trust me, it was the decision that actually directed my interest towards data science.\n\nAmidst constant mind tussling between whether to focus on my end terms or continue CS 109 , I finally got a call for an interview from Culture Machine, a data based media company on 19th November. I had completed a couple of starting lectures that gave me the basic idea of statistics and basic ML algorithms such as Linear and Logistic Regression. Luckily I got selected and got to spend my vacations seeing the real power of data, how data science is the driving force in the business world nowadays.\n\nAfter joining college late on 11th January, I attended an intro talk of DSG and got to know about its entrance exam. Having left the course of CS 109 midway, I decided to continue it. Nearly week after, I was taking lectures, doing kaggle problems and reading data related blogs extensively. I was spending like 10 hours of my day in all this and I was really, really enjoying it (This rarely happened to me in college).\n\nAll thanks to this guy , Joseph K. Blitzstein. His statistical and intuitive approach towards any ML algorithm is phenomenal."
    },
    {
        "url": "https://medium.com/data-science-group-iitr/data-science-group-iitr-my-recruitment-experience-553ba6891178",
        "title": "Recruitment Experience. 2nd year. \u2013 Data Science Group, IITR \u2013",
        "text": "I\u2019m Ankush Raut, a 2nd year undergraduate student at IIT Roorkee, and here\u2019s how the recruitment process of the Data Science Group, IITR went for me.\n\nIt all started with a zeal to accomplish innovative projects across Machine Learning, Data Visualisation, and Big Data with and under the supervision of the prominent data science enthusiasts of the college. I\u2019d been following data science for a really long time and was quite well acquainted with how data is being exploited every now and then to fantastically optimize results and decisions, when I came to know about the recruitment.\n\nIt tested my prowess in Statistics, Machine Learning, Analytics, and Coding Aptitude to a certain level necessary. While I didn\u2019t do any good in either of Analytics and Coding Aptitude (and I knew it before the results!), I was shortlisted on the basis of my good score in the Machine Learning and Statistics sections. And that exactly was the criteria, adequate prowess in at least 2 of the 4 sections across which we were tested.\n\nNext to come, was the interview round. I was tested to even a deeper extent in ML and Stats, since the interviewers desired to know about the amount of thought I gave to the questions I attempted and how much I knew about the concepts involved in them. Nervousness is just a natural thing to come whenever you appear for an interview of some sort, and I am no different than you!\n\nAt first I couldn\u2019t believe the way I was misinterpreting some really simple questions and messing them up, but gradually I took control and the interviewers happened to be satisfied with me, though I wasn\u2019t in position to classify the result as either a 0 or a 1! Finally, I was again shortlisted for the final interview along with 11 other candidates from 2nd year.\n\nThis time it was different, it wasn\u2019t my knowledge that they wanted to talk to me about. The interviewers rather wanted to know about me personally, the way I perceive data science, the amount of interest I have in it, how I\u2019d affect the group dynamics and so on. Since data is all that\u2019d been going in my mind then, I felt like I did convince them about the amount of dedication I\u2019d be showing in the activities of the group.\n\nI was absolutely delighted to find my name in the list of the 10 students who made it to this group. Now I just can\u2019t wait for the mid term exams to end and the projects to commence!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/why-dsg-why-not-something-else-6d428baedc78",
        "title": "Why DSG. Why not something else. \u2013 Data Science Group, IITR \u2013",
        "text": "People often doubt the reason I give when they ask me \u201cWhy did you start the Data Science Group in IITR?\u201d. \n\nPersonal motive. NO.\n\nFree time. Definitely NO.\n\nIt\u2019s all about spreading what you have for the greater good of the people near you. This post covers my journey through competitive coding, and ends with a DSG team of 27!\n\nYou enter first year of college. You have no idea which group to join.\n\nYou see a notice which reads \u201cAptitude Test for 1st yearites\u201d. You go because you have all the time in the world. You do surprisingly good. You become part of a legendary family.\n\nThis is where I was introduced to the field of Software and IT. I toiled hours on SPOJ, CodeChef and Codeforces. I dedicated my entire freshman year and a good part of the sophomore year to \u201cCompetitive Coding\u201d. I was involved in problem-setting teams of some of the biggest coding competitions like Insomnia.\n\nI even qualified for the ACM-ICPC Regionals in my junior year, but all this while, there was a voice inside my which said \u201cNot this. Something else.\u201d\n\nAfter devoting two full years, it was tough for me to think beyond this but in the end, it\u2019s all worth it!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/how-not-to-crack-the-gre-f2aaf7f0b2ba",
        "title": "How not to crack the GRE. \u2013 Data Science Group, IITR \u2013",
        "text": "I emphasise again on the word not. Unless otherwise stated, please do not take any part of my experience/preparation as advice. You\u2019ll see why, please read on. :)\n\nLike most people serious about applying for MS in the USA, I too am fairly good at math and English (not exceptional in any way), and believe that this post should be relatable to you.\n\nI\u2019ll start with a brief introduction to what this post is about.\n\nTo those who don\u2019t know, ETS conducts a standardised test called the Graduate Record Examination (GRE), which is a prerequisite for Master\u2019s/Ph.D. applications to almost any good college abroad.\n\nThe GRE contains 6 sections \u2014 2 Quantitative, 2 Verbal, 1 dummy (from either), and an Analytical Writing (AWA) section. The maximum and minimum scores for both Quant and Verbal are 170 and 130 each, while AWA is scored on a scale of 0\u20136. Quant is relatively elementary (mostly limited to 10th grade math syllabus), while Verbal has you mugging up English words for the most part. The latter has a diverse format, including questions on reading comprehension, text completion, and sentence equivalence.\n\nA cumulative score above 320 (Q+V) and 4 (AWA) is good; it really doesn\u2019t matter much whether it\u2019s 321 or 340. In terms of distribution, for anyone intending to go for engineering / science, 170 in Quant is a must, even if that means a lower score in Verbal. While AWA is not as important, you\u2019ll invariably hear people say the former is absolutely crucial to your getting an admission to any college. They\u2019re wrong. At 325\u2013330, any college will give you a maximum of 5% head start, while for 330+, it can go up to 10%. However, I will go out on a limb and say that < 320 might be a little disadvantageous in the top colleges. But no reputed college will ever grant an admit or reject you solely on this basis.\n\nWith a modest aim of 320+, I would recommend anyone good at math and decent at English to prepare for about 2 months. If you have a good analytical background, brushing up the Quant concepts should not take more than 15 days. The remaining time should be invested entirely in solving practice tests and learning English words. With some presence of mind, avoidance of silly mistakes, and a little luck, you should manage to get at least ~325.\n\nNow coming to how I prepared for the exam. Since I had been extended a pre-placement offer from the company I interned at in my penultimate year, I was relatively free and was contemplating applying for MS in Data Science.\n\nWith a 2-month preparation in mind, in August \u201916, I booked an exam date for October, and like all others taking the GRE/CAT, bought a book called \u2018Word Power Made Easy\u2019 by Norman Lewis. So should you. The importance of this book cannot be overstated. Remember I said you need to mug up words? That\u2019s not entirely true. This book\u2019s approach is completely scientific; by the end, you would be in a position to deduce and derive meanings of ~20 new words from just 1 word, with an exhaustive bag of about 1500\u20132000 words at your fingertips. That is if you actually sit down and write your way through all the exercises, not just read them.\n\nOwing to mid-terms and my lack of seriousness, by the time I was done with this book, just over 2 weeks were left for this exam despite putting in only about 15\u201320 hours into this book. I knew I was doomed when even the coaching institute advertisements on the internet said, \u201cHow to Crack the GRE in under 45 days\u201d! I immediately started giving practice tests to see where I stood, and to my shock, I managed a 320+ just once in 3 tests. This, together with immense pressure from friends and my conscience about paying $205 for this exam, is what made me truly serious about the exam. I was acing Quant, but falling short on Verbal. I decided to mug up the remaining ~1000 words on the unofficial GRE word list, which took me about 2 weeks. The remaining 3\u20134 days were spent giving 4\u20135 tests (Kaplan, Princeton Review, and official GRE practice tests).\n\nSame as here, I completely forgot about the AWA section while preparing. The night before the exam, I was reminded of the existence of this section by my brother. I browsed through the official GRE guide for about half an hour to avoid any surprises pertaining to the type of questions it comprised, which was just 2 essays to my relief.\n\nI attempted all 3 sections from Quant flawlessly, and 1 from Verbal too. The last Verbal section had me scratching my head, and I ended up getting 7 questions wrong. With a little over 3 weeks of effective preparation, managing a combined score of 332 (170 Q + 162 V) is probably as lucky as I will ever get. This is where I stress again; it is as unreliable a way to crack this exam as it gets.\n\nApart from GRE, you need to give the TOEFL (if aiming for the US) or IELTS (UK) if you live in a non-English speaking nation. TOEFL has a maximum of 120 points (anything > 100 is good; I got 113), while IELTS has a 10-point scale (0\u20139; anything > 6.5 is good).\n\nI would recommend just getting these tests getting done with as soon as possible (preferably in student-life and before September if you\u2019re aiming for Fall next year) and dig into the actual and much more important process of applying, which generally requires you to send a r\u00e9sum\u00e9 / CV, academic transcripts, 3 letters of recommendation, and a statement of purpose (SoP) for each university. The SoP is single-handedly the most important thing in applications. I\u2019ve seen people with < 300 in GRE get through to Stanford (although such people tend to have an exceptional profile; for others, I recommend getting 320+), and > 330 not make it to a mediocre college.\n\nSince this is not meant as a blog on how to go about applying for Master\u2019s, I\u2019ll limit myself here. For anybody interested in it, I strongly recommend reading this blog by me and this one on Analytics Vidhya for getting familiar with the process of applying, and this one for a list of good programs in Data Science. As a last resort, you may contact me; I\u2019ll be glad to help!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/a-tale-of-two-companies-1f7463ba22f7",
        "title": "A Tale of Two Companies. \u2013 Data Science Group, IITR \u2013",
        "text": "Nothing can compare to campus placements when it comes to sheer randomness in this chaotic world. Happening AF. You never know where you\u2019ll end up. :D\n\nThose random shortlists, sudden calls and moody interviews were enthralling in a way \u2013 as it is said about IITs, you don\u2019t realise but they are preparing you for the worst. Admire the system all you want.\n\nFor me, it was different. Yes. Different and easy. Read entire post to understand why I say easy.\n\nAs the title suggests, this first-hand account talks about my experience with two companies belonging to different domains and offering different profiles.\n\nAs it is customary, resume is verified by TPO in September and company notices start pouring in October. As a Production and Industrial engineer, I have to rely on non-core sector (nobody realises our importance in India). WAP was the first company for me, offering a whopping salary of 6 million yen p.a. I saw BigData Analytics and Artificial Intelligence in their job description. I applied.\n\nBy the time you reach final year, you are already aware of 1cr packages that IIT rolls out to 20% of undergraduate students by a lucky draw! Parents have expectations. You are heavily under pressure. You give in. You shouldn\u2019t. Never ever!\n\nOwing to past good deeds, i.e. being a part of ACM ICPC Regionals, earned me some brownie points. WAP allowed me to sit for interviews directly.\n\nComing to the day of interview, WAP visited R on the much-hyped DAY 1. I entered the placement complex and got a warm welcome by the Japanese HR. The next thing I knew, my name was first on the list. It was a 1-on-1 affair. Coding round. Yes. It was a live coding round where I was given a Codeblocks interface and a set of questions pertaining to Linked list implementation using Classes. I knew the answer, but wanted to do ML. Conveyed that to the interviewer in a subtle manner. He said we want people who can deliver codes like machines for clients. I understood that job description was just a way of glorifying the work. He understood my disinterest and said \u201cI guess we both understand that this doesn\u2019t fit well.\u201d I abided by his conclusion and walked out with a smile.\n\nI was proud of myself that day. I had conquered it what I expect all of you to fight and overpower \u2013 the rapacity. Because, it\u2019s all about doing what you want to do, and not what people want you to do.\n\nCore data science company open for all disciplines. Tailor-made for me. So I thought. So my friends thought.\n\nJust to put things in perspective, I WANT to do data science. Without a second thought, I applied. They were offering almost one-third of what WAP was shelling out.\n\nAfter I didn\u2019t get placed on Day 1, and couldn\u2019t update it on social media, I had immense pressure for Dec 2. FL was coming, right in the morning. Data Science was coming.\n\nOn a cold winter morning, I walked from my room to the complex, controlling all random thoughts. My name was not first on the list. Some relief!\n\nAround 10.05 AM, I was called in for the interview. It was a two-membered panel. I walked with conviction and shook their hands. They introduced themselves as CMO of the firm and senior data scientist and asked me to give a brief introduction. I started with general details and hobbies followed by my slightly-significant contributions to the world of Data Science. Then, they started reading my resume and asking practically everything that was written on those 2 pages. (Go for a 1 page resume if you go off-campus)\n\nFrom internships to projects to extra curricular, everything was talked about in detail. When you are in that room, time passes away very quickly. CMO was chipping in between the tech talks with HR questions like \u201cWhere do you see yourself in 5 years\u201d, \u201cWhat is success for you\u201d and \u201cHow will you be a good fit for the company\u201c. It\u2019s all about convincing the person in front of you. \n\nFor technical questions, even if you are not aware of the answer, never go plain blank. Tell them whatever you know or the closest you can reach. The perseverance and zeal to try is what matters. \n\nThe interviewers were quite impressed, atleast that\u2019s what I judged that time. I thanked them and left the room. Again with a SMILE.\n\nIf an interview goes too long, it\u2019s generally in favor of the candidate. I repeat generally. The first doubt when I came out was how long was my interview. I was told, it was 45 minutes. But, you know the diverse and negative nature of human brain, maybe that was non-general.\n\nAfter a wait of around 4 hours, the result was declared and my name was there. I felt satisfied. Happiness wasn\u2019t the first reaction, but satisfaction. Satisfaction of doing what I always wanted to do. I had defeated campus placements. This is why I said easy. It clicks, always, in the end.\n\nI don\u2019t want this post to be about my placement experience, but what you should always keep in mind:\n\nAlso, placements are over-hyped. At the end of the day, self-contentment and inner peace is what matters.\n\nI didn\u2019t grab a 1cr package. I didn\u2019t get placed on coveted day 1. I didn\u2019t get selected in a giant company. But, am happy. This tale for me was a life lesson in itself. Everybody has theirs!\n\nThanks for reading. :)\n\nAnd, \u2764 if this was a good read. Enjoy!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/interview-experience-1-ab7a7aa8a0a1",
        "title": "Placement Experience. \u2013 Data Science Group, IITR \u2013",
        "text": "My first advice is that give your best, and do not get disheartened. This is just a beginning of your professional career.\n\nPlacement process has two parts. First, you need to give a test to be shortlisted for an Interview. This test is generally basic coding+ Aptitude test (for IT field) and core questions (for others). So, it is must that you learn coding, if you decide to go for an IT company. (be it SDE, Data Science or Analyst)\n\nI was shortlisted for four Interviews, out of which I had PPI (Pre Placement Interview) in two. For the interviews, be clear about what you are interested in. I was shortlisted in Citi Group. Interviewer asked me questions on Data Structure and Algorithms. I am not good in this, so I requested him to ask me about Machine Learning (after all that\u2019s all it was on my resume). The profile offered did not require any ML knowledge. I was out of the room in five minutes, but believe me I didn\u2019t feel bad about it at all. The next morning I got an offer from ZS. So, be patient and wait for an Interview where you need to hit hard.\n\nFor ZS, I had three interview rounds (I had a PPI in this, so no test). First round was technical. Interviewer was a Manager of Data Science team. He asked me about my internship (I did my intern in Data Science). I described my work and things I could complete and the ones I could not. And then he started grilling me on my Machine Learning knowledge. The questions were not that hard but you need to understand ML basics very well. We had conversation for an hour starting from Logistic Regression to Convolution Neural Nets.\n\nThe next round was practical implementation round. Interviewer (he was a member of Advance Data Science team) gave me a dataset and I needed to analyze it in half hour. I did my best with different strategies on imbalanced handling, missing value imputation, feature engineering and selection, model selection etc. Then we had discussion on each of this for half an hour. Here, your EDA skills are tested. The one key thing about interview is \u201cnever lie\u201d. Be confident to say \u201cNO\u201d if you don\u2019t know something.\n\nThe last round was HR. He asked me about my interests and motivation for Data Science field. When you are a student from non-circuit branch you need to find a solid reason that why you are not pursuing career in your core field. So, give them your true motivation. It need not be any big project, but be honest in this.\n\nAstute understanding of ML is a must. Participate in various competitions to get understanding of EDA and ML model selection. You need to give your time to crack an Interview. For the beginners, read this great post by Akhil Gupta.\n\nAll the best for your future endeavors. \n\nHit \u2764 if this was worth a read for you!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/stop-thinking-start-learning-cb74629bca3a",
        "title": "Stop Thinking. Start Learning. \u2013 Data Science Group, IITR \u2013",
        "text": "Being the fad that Data Science already is, there exist innumerous resources for learning it and turning you into a Data Scientist. But, some are unreal i.e. expect a lot from a beginner, and some are way too simple to make you robust to complex challenges.\n\nHere, I propose a learning path for all the enthusiasts out there, who want to make a name in this field and are interested in learning and not just using ML.\n\nBefore I start with the path in detail, make it clear to yourself that this will demand effort and time from your end.\n\nIf both the languages given are new to you, I\u2019d suggest you to start with Python. If you already know R, first follow this path in R. You can shift to Python later.\n\nSpend 5\u20137 days in mastering one of these two!\n\nThis is the most important and tough phase in becoming a Data Scientist. 90% people give up midway. Just stay determined and if you complete this, there\u2019s no stopping you!\n\nThese books are self-sufficient, and would take up around 2\u20133 months to complete. Don\u2019t just read, implement side-by-side!\n\nCS109 Data Science by Harvard: This is the best course available on Data Science on the web. Trust me when I say this, if you complete this course, you can solve any DS problem. Beginner to Advanced, it\u2019s a must for everyone.\n\nFor those who want to go more in detail, they can also look into CS229 Machine Learning by Stanford.\n\nCS109 shall also eat up a good part of 2\u20133 months. Don\u2019t leave it in between if you get irritated. Take a break, and finish it. But do complete it!\n\n^Either go for Books or Courses at first. That decision can be yours.\n\n\u201cWithout vision you don\u2019t see, and without practicality the bills don\u2019t get paid.\u201d\n\nIt\u2019s important to start working on some standard Kaggle problems: (attempt them in the given order)\n\nOnce you complete all of this, you are a Data Scientist! :D\n\nOkay, wait. Don\u2019t get carried away that easily. This is just the start of the beginning. It\u2019s a very vast field. You can always explore more and more.\n\nFocus on learning and understanding concepts. It will take a long way always!\n\nIf you have more links, don\u2019t hesitate in sharing. :)\n\nAnd, \u2764 if this was a good read. Enjoy!"
    },
    {
        "url": "https://medium.com/data-science-group-iitr/reading-is-imperative-so-is-data-science-1da630f17444",
        "title": "Reading is imperative. So is Data Science. \u2013 Data Science Group, IITR \u2013",
        "text": "It is important to get a feel of what you are going to dive into. These books will help you to motivate you for this field. If you have some time on your hands, do go through them, otherwise jump to the real deal!\n\nNote that the above mentioned books are my personal favourite, and have been tested by professionals also. You can safely follow them for preliminary studies in this field. And, always remember that people who say they don\u2019t have time to read simply don\u2019t want to.\n\nOpen to suggestions and comments. :)\n\nAnd, \u2764 if this was a good read. Enjoy!"
    }
]