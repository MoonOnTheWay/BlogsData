[
    {
        "url": "https://labs.bawi.io/deep-learning-convolutional-neural-networks-7992985c9c7b?source=user_profile---------1----------------",
        "title": "Deep Learning: Convolutional Neural Networks \u2013",
        "text": "In this publication, we will continue the Introduction to Deep Learning and Deep Learning: Word2Vec and Embedding, talking about the concepts behind Convolutional Neural Networks.\n\nIt is an artificial neural network where the neurons are represented by filters (matrices or weight tensors) present in Convolutional Layers (CL), widely used in the classification and identification of patterns in images or texts.\n\nThe convolution process generates a deepening of the network, so that the depth of the output is the depth of the input multiplied by the number of filters present in the convolution layer. For example, an RGB image has depth 3, when passing through a CL with 5 filters, an output with depth 15 will be generated.\n\nThe width and height of the exit depends on the dimensions of the entrance, the padding and the strides used.\n\nBelow we have two figures with examples of convolution with the formula for the dimensions of the output.\n\nWe can see in Figure 1 that even with a stride = (1,1), the output did not maintain the dimensions of the input.\n\nIn figure 2, we can see that the output has maintained the dimensions of the input, this runs due to filling with zeros.\n\nLayer similar to Convolutional Layer, the difference is that instead of applying an array of weights, the Pooling Layer applies a maximum, minimum or average function.\n\nWith this it is possible to make their image classification models more efficient, being able to determine the most features present in them.\n\nI hope this article helps you understand a few more concepts of Deep Learning!"
    },
    {
        "url": "https://labs.bawi.io/deep-learning-word2vec-and-embedding-3b00ff571cc1?source=user_profile---------2----------------",
        "title": "Deep Learning: Word2Vec and Embedding \u2013",
        "text": "In this publication, we will continue the Introduction to Deep Learning talking about the concepts behind Word2vec and Embedding.\n\nThis is a technique used in neural networks to classify texts, such as positive or negative reviews of a film.\n\nIn this technique, words are transformed into feature vectors, that is, each word becomes a vector of weights that define its characteristics.\n\nTo use Word2Vec you need to implement Embedding.\n\nEmbedding increases network agility by limiting its inputs so that only the words used in a given input pass through the network.\n\nIts implementation is to transform the words into indexes according to their vocabulary and to pass the matrix containing all the indexes of the words used in their input text by the embedding layer.\n\nThe Embedding Layer is a layer composed of an array with a number of rows equal to the number of words in the vocabulary and with a number of columns equal to the number of features of the words.\n\nIt is in this layer that the words are finally represented by the vectors of weights.\n\nFrom this point, the words that make up the text are already transformed into resource vectors, allowing numerous possibilities of implementations related to the interpretation or classification of texts.\n\nI hope this article helps you understand a few more concepts of Deep Learning! Until the next!"
    },
    {
        "url": "https://labs.bawi.io/introduction-to-deep-learning-3f8ce3006648?source=user_profile---------3----------------",
        "title": "Introduction to Deep Learning \u2013",
        "text": "Continuing the topic presented in the article Desmitificando Machine Learning, some important concepts about Deep Learning will be presented here. Do not worry, we will not enter much into the math of the subject :P\n\nFirst, let\u2019s talk about the data set, which represents the data that will be used during training and evaluation of the network. The data set is divided into the training set, validation set, and test set.\n\nThe training set represents the data that will be used in the training step. In this step, a certain input passes through the network generating a response that will be compared with the expected result, allowing to estimate the error and the correction on the network weights through backpropagation (keep calm, we will define this term!).\n\nThe validation set entries are also used in the training step, but their output is not used to perform the network correction, it determines if the training is being performed efficiently and if it is occurring overfitting in training.\n\nFinally, unlike the training set and the validation set, the test set is not used in the training stage. In fact, it should NEVER be used during training because it will be used as input only for the evaluation of the network\u2019s accuracy.\n\nThis layer represents the network input. It is important to understand that each node in this layer represents a feature of the input that will pass through the network. As an example, we can imagine a network that tries to determine the personality of a person, so the input would be a set of data about the person. In this way, each feature of this person would be a feature of that entry. In an array of network inputs, we have that each row represents an input and each column represents a feature.\n\nIn fact, this is not just one layer, because the structure of your network may have N hidden layers. This layer is responsible for abstracting the information contained in the inputs, in order to allow the network to interpret the data when applying weights to the inputs.\n\nEach hidden layer is represented by an array of weights. This array has one column for each node of this layer and one row for each entry of this layer. In this case, the inputs can be the features of the input layer or the outputs of an earlier hidden layer.\n\nThis is the output layer of your network, in which the forecast or evaluation performed by your network is obtained. The number of nodes depends on the architecture of your network, and may be only a node in the case of a simple quantitative or binary evaluation, or have N nodes, so that each node represents a possible evaluation of its input.\n\nThis layer is also represented by an array of weights, having one column for each output node and one line for each input (remembering that in this case the Output Layer inputs are the outputs of a Hidden Layer).\n\nBoth the hidden layer and the output layer nodes can have an activation function. This function has as inputs: a bias and the sum of the multiplication of each input with its respective weight.\n\nThere are several types of activation functions, for example, the sigmoid, which is an exponential function whose output is limited between 0 and 1. Thus, if a node has an activation function, its output will be the result of this function.\n\nDuring training, your network makes the predictions according to the input features. This prediction is compared to the expected result in order to analyze whether the network was successful or not. With this, we make use of a quadratic error function, which performs the sum of the square of the errors. That way, we have the cost of the network, which means how good or bad the network predictions are. The next step is to use the error to perform the backpropagation.\n\nThis is the training step in which the weight corrections are performed in each of the weight matrices, both the output layer and the hidden layers.\n\nIt is this correction of the weights that performs the learning of the network, in this way, the network adapts to the context. This correction occurs with the propagation of the error in the opposite direction, that is, from the output layer to the first hidden layer, hence the name backpropagation. In this step, a variation for the weights is calculated through a technique called Descending Gradient.\n\nHere is a partial derivative of the network error function related to the weights. That is, the variation of the network error is measured based on the weights, thus a vector is obtained to correct the weights that points to the minimum error region. Simply put, this technique allows the weights to be updated in the correct direction, avoiding corrections with random values. The downward gradient greatly increases the capacity of the network to converge to more satisfactory results.\n\nIn short, your network is represented by a series of input arrays and weights. During the training phase of your network, the learning takes place through the backpropagation and the descending gradient, which performs the correction of the weights present in the matrices of the hidden layers and the output layer. As training generations go through, the weights are being adjusted and the network adapts to the scenario. Finally, the network efficiency is analyzed by passing its test set by it.\n\nI hope this article helps you understand a few more concepts of Deep Learning! Until the next!"
    },
    {
        "url": "https://labs.bawi.io/introdu%C3%A7%C3%A3o-ao-deep-learning-a9aa7fe04fbd?source=user_profile---------4----------------",
        "title": "Introdu\u00e7\u00e3o ao Deep Learning \u2013",
        "text": "As entradas do validation set tambem s\u00e3o utilizadas na etapa de treinamento, por\u00e9m sua sa\u00edda n\u00e3o \u00e9 utilizada para realizar a corre\u00e7\u00e3o da rede, mas sim para determinar se o treinamento est\u00e1 sendo eficiente e se est\u00e1 ocorrendo overfitting no treinamento.\n\nCada hidden layer \u00e9 representada por uma matriz de pesos. Essa matriz possui uma coluna para cada n\u00f3 desta camada e uma linha para cada entrada desta camada. Neste caso, as entradas podem ser as features da input layer ou as sa\u00eddas de uma hidden layer anterior.\n\nEsta camada tamb\u00e9m \u00e9 representada por uma matriz de pesos, possuindo uma coluna para cada n\u00f3 de sa\u00edda e uma linha para cada entrada (lembrando que neste caso as entradas do Output Layer s\u00e3o as sa\u00eddas de uma Hidden Layer).\n\nDurante o treinamento, sua rede faz suas previs\u00f5es de acordo com as features das entradas. Essa previs\u00e3o \u00e9 comparada com o resultado esperado, a fim de analisar se a rede acertou ou errou. Com isso, fazemos uso de uma fun\u00e7\u00e3o de erro quadr\u00e1tica, a qual realiza a somat\u00f3ria do quadrado dos erros. Dessa forma, passamos a ter o custo da rede, que significa o qu\u00e3o boas ou ruins est\u00e3o as previs\u00f5es da rede. O pr\u00f3ximo passo \u00e9 usar o erro para realizar o backpropagation.\n\n\u00c9 essa corre\u00e7\u00e3o dos pesos que realiza o aprendizado da rede, deste modo, a rede vai se adaptando ao contexto. Essa corre\u00e7\u00e3o ocorre com a propaga\u00e7\u00e3o do erro no sentido contr\u00e1rio, ou seja, da output layer at\u00e9 a primeira hidden layer, da\u00ed o nome backpropagation. Nesta etapa \u00e9 calculada uma varia\u00e7\u00e3o para os pesos atrav\u00e9s de uma t\u00e9cnica chamada Gradiente Descendente.\n\nAqui \u00e9 feita uma derivada parcial da fun\u00e7\u00e3o de erro da rede com rela\u00e7\u00e3o aos pesos. Ou seja, \u00e9 medida a varia\u00e7\u00e3o do erro da rede com base nos pesos, deste modo \u00e9 obtido um vetor para corre\u00e7\u00e3o dos pesos que aponta para a regi\u00e3o de erro m\u00ednimo. Simplificando, essa t\u00e9cnica permite que os pesos sejam atualizados para uma dire\u00e7\u00e3o correta, evitando a realiza\u00e7\u00e3o de corre\u00e7\u00f5es com valores rand\u00f4micos. O gradiente descendente aumenta muito a capacidade da rede convergir para resultados mais satisfat\u00f3rios.\n\nResumindo, sua rede \u00e9 representada por uma s\u00e9rie de matrizes de entrada e de pesos. Durante a etapa de treinamento de sua rede, o aprendizado se d\u00e1 atrav\u00e9s do backpropagation e do gradiente descendente, que realiza a corre\u00e7\u00e3o dos pesos presentes nas matrizes das hidden layers e da output layer. A medida que as gera\u00e7\u00f5es (em ingl\u00eas, epochs) de treinamento v\u00e3o passando, os pesos v\u00e3o sendo ajustados e a rede vai se adaptando ao cen\u00e1rio. Por fim, analisa-se a efic\u00eancia da rede passando o seu test set por ela."
    }
]