[
    {
        "url": "https://hackernoon.com/how-to-train-your-neural-network-cb5a36e91072?source=user_profile---------1----------------",
        "title": "How to train your neural network \u2013",
        "text": "Imagine you live in the mountains. One of your kin has fallen sick and you volunteer to get medicine.\n\nYou stop by your house to grab the necessities \u2014 a map of the city along with a marble-shaped rock you claim brings you good fortune. You hop onto your dragon and fly north.\n\nAll that matters initially is a general sense of direction. The details on the ground are barely visible and you cover distance quickly.\n\nAs is widely known, dragons need a lot of space to land. You pick a nice landing spot just outside of a city and rent a horse from a nearby tavern.\n\nYou have to be more careful now \u2014 the horse is fast but if you want to get to the pharmacy before it closes you have to chose your direction more heedfully.\n\nOnce in the city, you take out the map and taking big strides you run towards the main street. When finally there, you stop to catch breath and look around.\n\nYour objective is within sight and you casually stroll towards the entrance.\n\nThe journey you have just undertaken is very much like training a neural network. In order to converge to a good solution as quickly as possible we utilize different modes of movement by varying the learning rate.\n\nThe dragon is by far the fastest but it is also the least precise. While flying, the terrain looks roughly the same and you can only pick out major landmarks to use for navigation. This corresponds to training with a high learning rate.\n\nThe other extreme is walking slowly. You can observe all the details and pick your path nearly perfectly. This is our lowest learning rate.\n\nIf walking is so precise, why don\u2019t we do it from start till finish? Because there is too much ground to cover and we would never get to the city in reasonable time.\n\nWhy not fly all the way then? We would not be able to pinpoint our destination precisely from the air. Also, as our dragon is of considerable size, it might not be able to land close by to the target. The terrain in a city is quite rugged and the best we could probably do is pick a nice, flat rooftop to land on. Still, that would put us at some distance away from where we would like to be.\n\nOur only hope is to combine training with a high and low learning rate to optimize both for speed and precision.\n\nBut how to go about it while training a neural network is not obvious. Below we will consider two ways of approaching this problem.\n\nThe most common way of decaying the learning rate is by hand. You train the network for some time and based on the results you make a decision whether to increase or decrease the learning rate. Rinse and repeat.\n\nThe whole process relies on intuition and it takes time to try things out.\n\nRecently however a new method of decaying the learning rate was proposed[1]. In it we provide an initial learning rate and over time it gets decayed following the shape of part of the cosine curve. Upon reaching the bottom we go back to where we started, hence the name \u2014 cosine annealing with restarts.\n\nThe diagram below contrasts using cosine learning rate decay with a manual, piece-wise constant schedule.\n\nThe new method has nice properties. First and foremost, we no longer have to worry about handcrafting a learning rate decay schedule. This saves us considerable amount of time that we can spend elsewhere.\n\nFurthermore, via jumping between lower and higher values of the learning rate in a non-linear fashion we hope to make it easier to navigate out of parts of the weight space that are particularly unfriendly to our optimizer.\n\nAre those reasons good enough to warrant switching to the novel way of decaying the learning rate? Probably. But what about other important parameters like the training time or training accuracy?\n\nLet\u2019s look at both.\n\nWe would like to measure how long it takes to fully train a model. But what does it mean for a network to be fully trained?\n\nIs it something that you arrive at after training a model for some number of epochs? Or maybe when you achieve some validation set performance? Does it mean that with additional training we would not be able to achieve better results?\n\nThere are no easy answers to these questions. To have something more concrete I arbitrarily declare the finishing line to be an accuracy of 85% on the validation set.\n\nTo perform the experiment I train 40 resnet-20[2] models on CIFAR-10, 20 for each method of decaying the learning rate.\n\nI use default parameters[2] that have been picked to work well with fixed learning rate decay. In many ways I feel I am making life particularly hard for our automated annealing schedule.\n\nAnd yet when I run the experiment, I get results as below.\n\nCosine annealing wins the race by a significant margin. Also, quite importantly, there is a greater consistency to our results. This translates to greater confidence in the schedule to be able to produce consistently good results.\n\nIt might be quicker, but can it run the full distance? Is it able to get us to where we would like to be?\n\nThe promise of cosine annealing is that it should converge to solutions that generalize well to unseen data.\n\nTo perform an evaluation we can compare the results we get with the results achieved in the ResNet paper[2]. The authors trained for an equivalent of 182 passes through the training set achieving a test error of 8.75%.\n\nWe will perform 10 training runs with cycle length of 7 and 14 (both divide 182 cleanly).\n\nWhat is the significance of the results that we get? Does cosine annealing manage to deliver on its promise?\n\nIn my analysis I have run cosine annealing with parameters that have been tuned over many years worth of experiments to work well with decaying the learning rate manually.\n\nTraining all the way to completion with a starting learning rate of 0.1 is also undeniably not the right approach.\n\nProbably the greatest concern is that I have not demonstrated how cosine annealing enriches the day to day workflow of a machine learning practitioner.\n\nRunning experiments is much quicker. I have more time I can spend on value add activities and do not have to occupy myself with chaperoning the training of a model.\n\nIt would be interesting to see how well cosine annealing can perform with settings devised specifically for it. But among all the unknowns I feel I have found the answer I have been looking for.\n\nGiven its inherent ability to save time and robustness to parameter values cosine annealing with restarts will most likely be my technique of choice across a wide range of applications.\n\n[1] Stochastic Gradient Descent with Warm Restarts by Ilya Loshchilov and Frank Hutter\n\n[2] Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n\n[3] Cyclical Learning Rates for Training Neural Networks by Leslie N. Smith \u2014 a seminal paper that introduced the idea of cyclically varying the learning rate between boundary values\n\nYou can find the code I wrote to run the experiments in my repository on github."
    },
    {
        "url": "https://towardsdatascience.com/why-take-the-log-of-a-continuous-target-variable-1ca0069ee935?source=user_profile---------2----------------",
        "title": "Why take the log of a continuous target variable? \u2013",
        "text": "\u201cHi, my name is Bob and I\u2019ll be your instructor. I\u2019ll teach you how to drive a car. Open your books on page 147 and let\u2019s learn about different types of exhaust manifolds. Here is the formula for the essential Boyle\u2019s Law\u2026\u201d\n\nThis would never happen, right?\n\nAnd yet in teaching data science elaborating on complex topics is common place whereas no love is given to the fundamentals. We are not told when to accelerate and when to slow down. But nearly everyone seems to be ready to walk us through the construction of real numbers.\n\nIn this article we\u2019ll look at a simple but useful concept that often gets overlooked. But first let us consider an intriguing property of logarithms.\n\nImagine you are a bubble in the World of Bubbles. You just started out and you are of meager size 0.69 which is equivalent to natural log of 2.\n\nYou complete a quest for an NPC wizard who gives you a potion that will double your size, no matter how big you are.\n\nThat is nice. All the potion has to do is multiply your size by 2 to get your new size of 4. If you were of size 3, you would grow to 3 times 2 which is 6.\n\nBut what if the only operation a potion could do was addition? Now things become trickier. The wizard gives you a potion which grows your size by 2 from 2 to 4. But what if you drink the potion the next day, when you are already of size 3? 3 plus 2 is 5 and so the potion fails to deliver on its promise!\n\nSeems like there is no solution to this. Luckily the wizard is very old and very wise. Instead of giving you a potion that adds 2 to your size, she gives you a potion that adds log(2).\n\nYou weigh the tiny flask in your hand not looking convinced. The wizard beams a bright smile at you and heads north-east.\n\nYou take the potion on the same day \u2014 you grow to size 4, as expected.\n\nNot trusting the wizard, you load a save from before drinking the potion. To see what will happen you make a decision to drink it only once you reach size 3.\n\nMhmm, maybe the wizard anticipated that this is what you might do and set some timing mechanism into the potion, where after some time it would add 3 and not 2 to your size. You decide to throw the wizard a curve ball.\n\nImagine you look at a sword that your bubble can equip and would like to predict the power modifier based on its color and shape.\n\nIf sword blue -> add +2 to predicted power. If sword round, add -3.\n\nA random forest can neither add nor subtract but what it learns has an effect like the rule above. When a tree is grown, it looks at the features of examples and selects which one to split on.\n\nIt attempts to group examples with similar values of the target variable together. The greater the similarity within a branch, the better the chance the tree will be able to make good predictions.\n\nBut how do we measure similarity? One way of going about it would be to consider how much the values differ in absolute terms \u2014 a 20$ bottle of wine is 20$ away from its 40$ counterpart. A 100$ bottle of whiskey is 100$ away from its 200$ counterpart.\n\nLooking at the prices in this way, the difference between the bottles of whiskey is 5 times as big. But if we look at them in relative terms, the distances are the same! In both pairs the second bottle is twice as expensive as the first one.\n\nNeither way of measuring the similarity is universally better or worse. Depending on the situation, one might be more useful than the other.\n\nLet\u2019s imagine we would like to learn something about cars.\n\nWhat might we want to know? Maybe for instance \u2014 how much will the value of a car increase if we fit it with AC?\n\nAs it turns out, we are very lucky \u2014 our dataset is simple and consists only of Lamborghinis and Fiats.\n\n\u201cSeems adding an AC to a Fiat on average will increase it\u2019s price by 307$ and to a Lamborghini by 12 000$ so let me do the only reasonable thing here and predict that fitting AC to a car will increase its price by (12 000$ + 307$) / 2 = 6 153.50$\u201d\n\nBut this would mean that if we equip a Fiat 126p with AC it will appreciate by multiples of its base price! Now that is a business I would like to be in.\n\nNot a very good answer to say the least.\n\nAlternatively, what if we ask by how much a car\u2019s value will increase relative to its base price? This might be a more useful piece of information to have.\n\nBut our model is unable to answer this question! All it has are the absolute distances to go by.\n\nEnter the wise wizard. After a single incantation of the numpy variety, our target variable becomes a logarithm.\n\nOur model can now learn by what amount relative to a base price a car\u2019s value will change based on adding or removing this or that feature."
    },
    {
        "url": "https://hackernoon.com/how-to-stop-worrying-and-start-tweeting-a22f84e1cebb?source=user_profile---------3----------------",
        "title": "How to stop worrying and start tweeting \u2013",
        "text": "There are many good reasons why you might want to start using Twitter. Rachel Thomas lists some of the more important ones in \u201cMaking Peace with Personal Branding\u201d.\n\nFor me, the appeal is simple. I get to listen and occasionally talk to people doing amazing things in the field I care about (Machine Learning with a focus on Deep Learning). I also sometimes fantasize that what I write is helpful to others. Mostly that is just me dreaming things up.\n\nBut Twitter is not without quirks and some things are not what they appear.\n\nBelow I present the missing manual \u2014 the one I wished I had when I was starting out with the platform.\n\nAre you already on Twitter? Or maybe you are thinking of signing up?\n\nThese are the things you need to think about:\n\nAnd then all you have to do is follow the people from #2.\n\nFrom now on they will be able to share their thoughts with you. They might also introduce you to other people you might find interesting.\n\nIsn\u2019t this great? Never before have there existed an easy and open way such as this to tune in to what a person has to say.\n\nUsing Twitter in this fashion has a lot of positives and avoids nearly all of its troublesome parts.\n\nBut you are right to point out that Twitter at its core is a social network. There is value in speaking out and allowing other people to get to know you.\n\nAnd that is where problems start. Twitter made a lot of design decisions that make this really hard.\n\nBelow I share the strategy I use. It works for me quite well. But before we go further let\u2019s take a closer look at the platform itself.\n\nIf you are a human, chances are social networks have not been designed with you in mind.\n\nLet me be more specific. Over many years many billions of dollars have been poured into optimizing social networks for one thing and one thing only \u2014 maximizing profits.\n\nThis goal often stands in stark opposition to maintaining the well-being of users.\n\nA lot has been written on this subject. You might for instance find it quite interesting to learn why the social media bosses do not use social media.\n\nMost of this boils down to the fact that keeping users happy and relaxed doesn\u2019t drive engagement. And you want to be happy, right? You want to have peace of mind.\n\nAnd so we need to proceed with caution as we are about to start using a platform that has goals that are not aligned with what is good for us.\n\nSo how do we start talking?\n\nWant your voice to make it through the noise and be heard? Pick a single theme to speak to.\n\nThere is not enough time for a person who is interested in skateboarding to pick out that you have something interesting to say when your feed is flooded with pictures of your cat. Or your breakfast.\n\nThere will come a time for an occasional personal tweet but only as people get to know you better.\n\nWhy do you need more followers in the first place? Unless you are trying to sell something \u2014 in which case stay away from me \u2014 you don\u2019t.\n\nRemember the times when not everyone wanted to be a celebrity? When people just wanted to meet people?\n\nYou now open FB and everyone is The Most Successful Person Ever Living the Perfect Live\u00ae. That is just wrong.\n\nIt is even worse with Twitter. The appeal to grow your audience is very strong. But it is a path that leads to suffering.\n\nFind a couple of people, maybe 3 or 4, who are doing something interesting. Start talking to them. Maybe they will talk back to you. Once you have 2\u20133 people who are happy to talk to you, you are set.\n\nBe content and thankful. You\u2019ve made it.\n\nIf a person you admire shares some of your work with their followers, or talks back to you, that is a cherry on top. And there are some genuinely good people out there who will help you be heard if you have something interesting to say.\n\nBut this cannot be your goal. If you want to chase popularity, this will be high school all over again. You will go crazy.\n\nThe first rule of social networks is to disable push notifications. Nothing should be able to interrupt your thoughts whenever it pleases.\n\nEspecially if it has algorithms baked in to make you addicted.\n\nBut even if you disable push notifications the situation is still not straightforward.\n\nI could tell you all about B.F Skinner. The American scientist who claimed free will didn\u2019t exist and who made animals do his bidding. It\u2019s intriguing to what extent his work influenced the design choices of large social platforms.\n\nInstead let me refer you to an article by an insider who makes a great point. Care to learn how a slot machine was put in a billion pockets?\n\nIt depends and sometimes it might be wise to seek professional help. If the use is moderate maybe you can hack the habit and change it into something useful.\n\nI often find myself taking the phone out of my pocket and either about to press or pressing the Twitter icon. But luckily I have a very slow mobile phone.\n\nEven if I do press on the icon, there is a second or two of white screen before the app loads.\n\nIn that brief moment I reclaim my freedom. I got you Twitter.\n\nI quickly cancel out and press on Mendeley. This is an application that I use for organizing scientific papers I want to read.\n\nI take a deep breath. Congratulate myself. And I then enjoy reading something that is good for me.\n\nThe point is not to not use social media. The point is to not use it all the time.\n\nGive yourself the time to think and breath.\n\nWhat is your Mendeley?\n\nTwitter works best when you talk to people and exchange ideas. When you receive helpful advice and learn from others.\n\nBut to put the advice to good use, you need to give it attention. And that will not happen while you have the Twitter client open.\n\nOr while you care whether someone liked what you wrote.\n\nMore importantly, your loved ones might or might not be on Twitter. This doesn\u2019t matter.\n\nYou cannot look into their eyes through the screen of your phone. You cannot hug them or go for a walk with them.\n\nFight for your attention and give it to the people and the things you love.\n\nYour ability to do so will not last forever."
    },
    {
        "url": "https://hackernoon.com/doing-machine-learning-efficiently-8ba9d9bc679d?source=user_profile---------4----------------",
        "title": "How to do machine learning efficiently \u2013",
        "text": "I have just come out of a project where 80% into it I felt I had very little. I invested a lot of time and in the end it was a total fiasco.\n\nThe math that I know or do not know, my ability to write code \u2014 all of this has been secondary. The way I approached the project was what was broken.\n\nI now believe that there is an art, or craftsmanship, to structuring machine learning work and none of the math heavy books I tended to binge on seem to mention this.\n\nI did a bit of soul searching and went back to what Jeremy Howard mentioned in the wonderful Practical Deep Learning for Coders MOOC by fast.ai and that is how this post was born.\n\nWe sit in front of a computer to do things. To make a dent in the universe. To lower the cost of our predictions or decrease the run time of our model.\n\nThe key word here is doing. That entails moving code around. Renaming variables. Visualizing data. Smashing away on your keyboard.\n\nBut staring blankly at a computer screen for two minutes while it performs calculations so that we can run them again and again but with slightly modified parameters is not doing.\n\nThis also leaves us open to the greatest bane of machine learning work \u2014 the curse of the extra browser tab. So easy to press ctrl+t, so easy to lose track of what we have been doing.\n\nThe solution might sound ridiculous but it works. Do not ever allow calculations to exceed 10 seconds while you work on a problem.\n\nBut how can I tune my parameters then? How can I learn anything meaningful about the problem?\n\nAll it takes is to subset your data in a way that can create a representative sample. This can be done for any domain and in most cases requires nothing more than randomly choosing some percentage of examples to work with.\n\nOnce you subset your data work becomes interactive. You enter a flow state of uninterrupted attention. You keep running experiments and figuring out what works and what doesn\u2019t. Your fingers never leave your keyboard.\n\nTime stretches and the hour of work that you do is not equal to the hour of work you would have done, not even 5 hours of work, had you allowed yourself to be distracted.\n\nHow to structure your code to facilitate this workflow? Make it very simple to switch to running on the full dataset.\n\nWhen about to finish your coding session, uncomment the cell and run all.\n\nThis supplements the above. But it is also so much more.\n\nThere are orders of magnitude of gains in performance that can be attained based on how you structure your code. It is good to know how long something runs and how long it will run if you make this or that change. You can then try to figure out why the difference and it will immediately make you a better programmer.\n\nOn top of that, this goes hand in hand with the commitment to never run anything that takes more than 10 seconds.\n\nOnce you make a mistake in your data processing pipeline and it goes unnoticed, it is nearly impossible to recover. To a large extent this also applies to model construction (particularly if you develop your own components such as layers, etc).\n\nThe key is to inspect the data as you go along. Look at it before and after transformation. Summarize it. If you know there should be no NAs after a merge, check that there indeed are not.\n\nThe only way to maintain your sanity in the long run is to be paranoid in the short run.\n\nWhat is the very second thing you should focus on when working on a problem (I will speak to the first thing to do in just a second)? Create any model, any end to end data manipulation pipeline, that is better than random chance.\n\nIt can and should be the simplest model you can think off. Very often this will mean a linear combination. But you want to start getting a feel for the problem. You want to start forming a baseline of what is possible.\n\nSay you spend 3 days on constructing a super elaborate model and it doesn\u2019t work at all, or doesn\u2019t work remotely as well as you suspected it should. What do you do?\n\nYou know nothing at this point. You do not know if you made a mistake with processing your data, you do not know if your data is garbage. You have no clue if maybe there is something wrong with your model. Good luck untangling this mess without having components you can rely on.\n\nAlso, getting a simple model in place will allow you to get a bird\u2019s eye view of the situation. Maybe there is missing data? Maybe the classes are imbalanced? Maybe the data is not properly labeled?\n\nIt is good to have this information before starting to work on your more complex model. Otherwise you risk building something very elaborate that might objectively be great while at the same time being completely unsuited to the problem at hand.\n\n\u201cOh if I just maybe add this single linear layer, I\u2019m sure the model will sing to me\u201d\n\n\u201cMaybe adding 0.00000001 more dropout will help, seems like we are fitting our train set a little bit too well here\u201d\n\nEspecially early on, it is absolutely counter productive to tune hyperparameters. Yet it is beyond tempting to do so.\n\nIt requires little to no work, it is fun. You get to see numbers on your computer screen change and it feels like you are learning something and making progress.\n\nThis is a mirage. Worse yet, you might be overfitting your validation set. Every time you run your model and make changes based on validation loss, you incur a penalty on your model\u2019s ability to generalize.\n\nYour time is better invested in exploring architectures. You learn more. Suddenly ensembling becomes a possibility.\n\nHow long are you planning on using the computer? Even if I were to accidentally become well off to the point where I don\u2019t have to work another day, I would still use the computer daily.\n\nIf you play tennis, you practice each move. You might even go as far as paying someone to tell you how to position your wrist for a specific shot!\n\nBut realistically, you will only play this many hours of tennis. Why not be similarly conscious about how you use the computer?\n\nUsing the mouse is unnatural. It is slow. It requires complex and precise movements. From any context you can only access a limited set of actions.\n\nUsing the keyboard sets you free. And I will be honest with you \u2014 I do not know why it makes such a difference. But it does.\n\nNothing that you do will have any meaning unless you have a good validation set.\n\nMay I refer you to the ultimate resource on this. An article that holds no punches and that is based in practice.\n\nHow (and why) to create a good validation set by Rachel Thomas."
    },
    {
        "url": "https://towardsdatascience.com/a-practitioners-guide-to-pytorch-1d0f6a238040?source=user_profile---------5----------------",
        "title": "A practitioner's guide to PyTorch \u2013",
        "text": "I started using PyTorch a couple of days ago. Below I outline key PyTorch concepts along with a couple of observations that I found particularly useful as I was getting my feet wet with the framework (and which can lead to a lot of frustration if you are not aware of them!)\n\nTensor \u2014 (like) a numpy.ndarray but can live on the GPU.\n\nVariable \u2014 allows a tensor to be part of a computation by wrapping itself around it. If created with requires_grad = True, will have gradients calculated during the backwards phase.\n\nYou perform calculations by writing them out, like this:\n\nOnce you are done, all you need to do is call #backward() on the result. This will calculate the gradients and you will be able to access them for Variables that were created with requires_grad = True.\n\nThe solution is to zero the gradients manually between runs.\n\nLast but not least, I would like to recommend the official tutorials \u2014 regardless of your level of experience they are a great place to visit.\n\nI hope this will be helpful to you and will save you some of the struggle I experienced when setting out to learn PyTorch. Best of luck to the both of us as we continue to master this amazing framework!"
    },
    {
        "url": "https://medium.com/@radekosmulski/do-smoother-areas-of-the-error-surface-lead-to-better-generalization-b5f93b9edf5b?source=user_profile---------6----------------",
        "title": "Do smoother areas of the error surface lead to better generalization?",
        "text": "In the first lecture of the outstanding Deep Learning Course (linking to version 1, which is also superb, v2 to become available early 2018), we learned how to train a state of the art model using very recent techniques (for instance, the optimal learning rate estimation as described in the Cyclical Learning Rates for Training Neural Networks paper from 2015).\n\nWhile explaining stochastic gradient descent with restarts, Jeremy Howard made a very interesting point \u2014 upon convergence, we would like to find ourselves in a part of the weight space that is resilient, meaning where small changes to the weights do not cause big changes to the loss.\n\nThis led to a very interesting discussion on the forums, which was prompted by me wondering why we care for the surrounding area of the weight space to be resilient \u2014 after all, isn\u2019t low loss the only thing that we really care about?\n\nJeremy Howard made a comment that left me pondering for quite a while and ultimately blew my mind when I grokked it:\n\nA-ha! The presupposition is that by looking at the error surface surrounding our solution we can tell something about it\u2019s ability to generalize! And all of this happens by looking only at the train set!\n\nIntuitively, this makes a lot of sense. But can we indeed demonstrate this effect? Let us run an experiment (accompanying keras code) and find out.\n\nI trained 100 simple neural networks (each consisting of a single hidden layer with 20 units) on the MNIST dataset achieving on average 95.4% accuracy on the test set. I then measured their ability to generalize by looking at the difference between the loss on the train set and the test set.\n\nOnce a model was trained, I randomly altered its weights by small amounts and I evaluated it on the entire training set again. The idea is that should the surrounding weight space be smooth, the difference in loss will be small. On the other hand, if we find ourselves in an area that is spiky, the difference will be large. I took 20 such measurements for each model that I trained.\n\nWhat I am hypothesizing is a linear relationship between the smoothness of the surrounding area and the ability of a model to generalize.\n\nUnfortunately, this is not the story that the data is telling me:\n\nCan we safely conclude that the relationship we hypothesized does not hold? By all means, we cannot do this either!\n\nThere is a lot of other things that could be interfering here. For instance, it could be the case that the dataset is so big relative to its complexity that when a simple model is nearly completely trained all the solutions are equivalent and the differences in their ability to generalize become meaningless.\n\nOr it might be that the measure that I use for estimating the spikiness of the surrounding area is inadequate \u2014 the step size might be too small or too big or the number of measurements taken per each model might be too small to capture anything but noise.\n\nI also wonder what batch normalization does to an error surface on a simple dataset such as this \u2014 it might be effectively flattening it out to the point where observing significant differences in smoothness becomes infeasible.\n\nAll of this is nothing but interesting food for thought at this point as I have no data to back any of the notions. Now that I see how rich this area can be, I wonder if there is any literature that would explore this further.\n\nI am also tempted to run a couple more experiments. But first things first! I cannot express how valuable the material shared by Jeremy Howard and Rachel Thomas is. Till the course is in session, that is where my energy should be. Who knows how many thought provoking ideas like the one that prompted this inquiry still remain to be uncovered? There is only one way to find out."
    },
    {
        "url": "https://towardsdatascience.com/beating-the-state-of-the-art-from-2013-with-5-of-data-without-using-transfer-learning-301faf624fb6?source=user_profile---------7----------------",
        "title": "Introduction to data augmentation and pseudo-labeling",
        "text": "In this article we will take a look at two ideas that can help you make the most of your training data.\n\nIn order to get a better feel for the techniques we will apply them to beating the state of the art from 2013 on distinguishing cats and dogs in images. The plot twist is that we will only use 5% of the original training data.\n\nWe will compete against an accuracy of 82.37% achieved using 13 000 training images. Our train set will consist of 650 images selected at random.\n\nModels will be constructed from scratch and we will not use transfer learning nor pretraining.\n\nYou can find the code I wrote working on this in my repository on github.\n\nThe first model has to be very simple \u2014 650 images is a really small amount of data.\n\nI go for the CNN architecture which limits the number of weights by exploiting the fact that similar shapes can be found in nearly any position in the image.\n\nI also skip the fully-connected classifier and instead decide on a fully convolutional network. The hopes are that this will give our model a better chance to generalize.\n\nAbove all, I experiment a lot. The final architecture contains 28,952 trainable parameters across 6 convolutional blocks. With a small amount of l2 regularization, the model achieves 74.38% accuracy on the 23,750 images in the test set.\n\nHow can we make a model perform better? Training it on more examples while ensuring it has capacity to learn is generally the right approach.\n\nBut in practice, more training data is often not easy to come by. Obtaining or annotating additional examples can be tedious or expensive.\n\nAnother thing we could do is use what we know about images to emulate having more of them.\n\nWould a picture look much different if it was taken from a smaller distance? Not really. Can we emulate this? Absolutely! Blow the picture up and crop the center.\n\nWhat about making it seem as if a picture was taken with a camera positioned slightly to the right? No problem at all. Shift the image a tiny bit to the left.\n\nThis sounds easy enough and can be very powerful. The only minor detail to add here is that we will not be transforming the images ourselves \u2014 we will tell an algorithm what transformations it is allowed to do and it will take some random combination of them.\n\nUnfortunately, to learn from augmented data I need to construct a much bigger model. It ends up containing many more feature maps bumping the trainable parameter count to 1 003 682.\n\nThis seems a bit off. Maybe the architecture I have chosen has not been that great to start with. At this point however I chose to stick with it and continue the experiment.\n\nWith data augmentation the model improves on earlier results by 35% and achieves an accuracy of 83.43% on the test set.\n\nCould we somehow use the model itself to again emulate having more data?\n\nTheoretically we could take all the unlabeled data that we have, including our validation set, run the model on it and add the images where our model feels most confident about it\u2019s predictions to our train set.\n\nAren\u2019t we risking reinforcing the mistakes that our model is already making? By all means this will happen to some degree.\n\nBut if things go as intended the benefits of doing this will outweigh the aforementioned effect.\n\nWhat we are hoping for is that by being presented with more data our model will learn something about the underlying structure shared by all the images that potentially it could see. And that this will be useful to it for making predictions.\n\nTo learn from pseudo-labeled images I construct a model that is 1.5 times bigger then the previous one. We are now at 1 566 922 trainable parameters.\n\nI run the old model on the 24,350 unlabeled examples. I pick 1000 images where it feels most confident it is right. I train our bigger model on a mix of pseudo-labeled and original train set images using proportions of roughly 1 to 4.\n\nWith no experimentation with the model architecture and no tweaking of the mixing ratio, the new model achieves an accuracy of 85.15% on the test set and quite confidently beats the SOTA from 2013.\n\nI wrote this article before completing the Practical Deep Learning for Coders course by fast.ai. I now would approach this challenge differently. I would go for the Densenet architecture which seems to do extraordinarily well with small amounts of data. I would also not resize the images but instead would blow them up and crop to the shorter side. This loses some information but it keeps the aspect ratios intact which generally works better."
    },
    {
        "url": "https://medium.com/@radekosmulski/can-we-beat-the-state-of-the-art-from-2013-with-only-0-046-of-training-examples-yes-we-can-18be24b8615f?source=user_profile---------8----------------",
        "title": "Can we beat the state of the art from 2013 with only 0.046% of training examples?",
        "text": "I fine tuned a VGG19 model on a total of 6 randomly selected images (you can find the pictures of our protagonists below).\n\nI applied transfer learning which is a technique where you take a model trained to carry out some other though similar task and you retrain it to do well on the task at hand.\n\nAt that time, as stated on the competition website , the state of the art algorithm was able to tell a cat from a dog with an accuracy of 82.7% after having been trained on 13 000 cat and dog images.\n\nIn 2013 Kaggle ran the very popular dogs vs cats competition. The objective was to train an algorithm to be able to detect whether an image contains a cat or a dog.\n\nI achieved an accuracy of 89.97% after 41 epochs of training. The validation set size was 24 994.\n\nBeing a fan of reproducible research, please find everything you need to run the experiment yourself in my repository on github.\n\nThis is thoroughly unexpected. The technique that I used is covered in the first lecture of Practical Deep Learning for Coders, part 1. In the Jupyter notebook provided with the course, it takes 7 lines of code to perform transfer learning.\n\nThis means that anyone who can move files around on a computer can apply this cutting-edge technology to a problem of their choosing. Medical diagnosis, anomaly detection, industrial applications of image recognition, you name it. Yes, you still need some data and you still need to have some high level understanding of what supervised learning is and how it works, but that\u2019s about it.\n\nThe results are staggering. I didn\u2019t have to apply data augmentation, didn\u2019t adjust the learning rate nor had to care about regularization. I didn\u2019t even test different architectures \u2014 this is literally the first one I tried.\n\nAnd yes, one could say that telling a cat from a dog in a picture is not rocket science. But let me remind you that we managed to land a man on the moon and still 40 years later we were unable to tell our computers how to perform on this seemingly simple task with above 85% accuracy. And yes, it is true that the model I picked to fine tune was trained to perform well on visual recognition tasks.\n\nBut wait a second \u2014 think on the first two paragraphs of this post for a second please. We are beating state of the art results from 4 years ago and doing so effortlessly. I am running a supercomputer in the cloud at a cost of ~ $0.20 an hour (that is how much I pay Amazon for renting out the virtual machine). And state of the art means literally the best technique in the world applied to a specific problem. This is very significant.\n\nThis demonstrates that the limits of applications of Deep Learning today are no longer driven by technology \u2014 we have the hardware and the software needed. And yes, for some tasks we will need even faster processing units, even more data, even better algorithms. But there exists a universe of applications of Deep Learning today that is waiting to be discovered and the limiting factor is how quickly the knowledge of this technology spreads.\n\nSo coming from a person who quit college after a year and a half of majoring in sociology, who learned to program on his own as an adult and is by no means a programming guru, and who with just one afternoon\u2019s worth of work beat the state of the art results from 4 years ago with only 1/2166th the data, my question to you today is this \u2014 what application of this technology will you invent to make the world a better place?\n\nPS. Machine Learning Attacks Against the Asirra CAPTCHA by Phillipe Golle is the paper on the state of the art solution from 2013.\n\nPS. 2 The winning entry to the Kaggle dogs vs cats competition had an accuracy of 98.914% and was achieved after carefully training a machine learning system on 25 000 images.\n\nFurther discussion of results: After I shared the article on Twitter, it led to a very interesting discussion that you can find here.\n\nOne very valuable comment was made with regards to the original VGG19 model being trained on classes that contained cat and dog breeds. I was hoping to only use the convolutional layers for essentially shape and low level feature detection, but quite likely they also contain higher level information. If that were to be the case, than the fully connected layers I added might not be doing a lot of original work and could just be learning to listen to the original convolutional layers providing them the answers."
    },
    {
        "url": "https://medium.com/@radekosmulski/automated-aws-spot-instance-provisioning-with-persisting-of-data-ce2b32bdc102?source=user_profile---------9----------------",
        "title": "Howto: Automated AWS spot instance provisioning with persisting of data",
        "text": "After following this guide, you will be able to spin up an AWS EC2 spot instance by executing a single command from your terminal. The instance will have a volume attached that will be persisted across shutdowns.\n\nI use this to work on the outstanding MOOC Practical Deep Learning for Coders, Part 1. I keep whatever data I need on the persisted volume, ssh into the instance upon booting and start jupyter notebook. I then follow a bookmark in my browser to access it.\n\nTeardown also happens via a single command.\n\nThis tutorial is fairly lengthy but I try to explain everything as clearly as possible and the convenience this setup affords is quite good. I invite you to give it a shot!\n\nYou need to be running any flavor of Linux. Most likely most of this will also work on Mac OS but I haven\u2019t had a chance to try.\n\nYou need to have the AWS CLI installed and configured (I don\u2019t cover this in this guide but if you would have questions on how to set this up let me know please and I\u2019ll try to help).\n\nWithout further ado, let\u2019s get started!\n\n2. Bring up the VPC along with all the necessary pieces (Internet gateway, subnet, security group, etc).\n\nThat\u2019s it! Now onto spinning up our first spot instance!\n\nWe will now spin up a brand new instance and configure it to our liking. We will then take an image of it and will use it as a blueprint for instances for continued use.\n\n3. Spin up a p2.xlarge spot instance. First argument is the instance type, second is the spot price you are willing to pay.\n\n4. Add the newly created directory in your home (~/aws_scripts) to your path. I do this by appending the following to my .profile in my home directory\n\nYou will need to log out and log in for this to take effect. This will allow you to manage your cloud workstation from anywhere in your file system!\n\n5. Connect to your spot instance. In your terminal execute:\n\n6. Configure the instance to your liking. Even if you are not planning on using the instance for the fast.ai MOOC, a good starting point is running the slightly modified setup script provided for the course:\n\n8. Log into AWS console and navigate to EC2\n\nGo to Instances, click Actions and take the image of your running instance\n\nSide note: It can take a while for the image creation to complete. You can check progress under EC2 > Images > AMIs. Till the creation of the AMI completes, you will not be able to boot from it.\n\n9. (Optional) You can now take your workstation for a spin and see if everything is set up correctly. You could for example try running the jupyter notebook.\n\nYou can find the public IP of your instance by executing the following in the terminal of your local computer:\n\nThe IP will be the dot separated numbers at the end of the displayed line after ubuntu@\u2026\n\nYou can connect to the jupyter notebook via navigating to the following URL in your browser\n\nThe password for your notebook will be jupyter. The browser might warn you that the connection is not secure but do not worry about this \u2014 we are using our own SSL certificate to enable connecting over HTTPS, but that actually is a good thing!\n\nWe now need to create the volume that we will be attaching when we spin up a new spot instance and detaching before termination.\n\n10. To do that, go to EC2 > Elastic Block Store > Volumes and click the Create Volume button\n\n11. On the next screen specify the size of the volume you\u2019d like to create (I am going with 20 GB here) and hit create.\n\n12. When the creation completes, select the volume and click Actions again and Attach Volume\n\n13. On the pop-up screen, click on the Instance input field, select the spot instance and hit attach.\n\n14. Go back to your ssh session. You can verify that everything went okay by running lsblk. You should see an entry at the bottom for the new volume with a name of xvdf.\n\n17. The partition is now created. We need to create a file system on it to be able to use it.\n\n18. Now that the file system is created let\u2019s go ahead and mount it and grant ourselves the permissions to write to it.\n\n19. And we are all set! Now that we have saved our blueprint and set up our detachable workspace, we can go ahead and tear down the spot instance we were using. From inside the aws-setup repository we cloned in step 1, execute\n\nMost of the set up is complete. All we need to do now is create a network interface with a public IP and tag things appropriately so that our script can use them.\n\n20. First, let\u2019s create the network interface. Under Network & Security > Network Interfaces click Create Network Interface. Click the subnet dropdown and select the only available subnet.\n\n21. Select SG for main-env and click Yes, Create.\n\n22. Go to Network & Security > Elastic IPs and click Allocate new address\n\n23. Hit Allocate on the next screen without making any changes.\n\n24. Close down the dialogue window, select the newly created Elastic IP address and associate it with the network interface created earlier.\n\n25. Select Network Interfaces, click on the input field and select the only network interface from the dropdown and click Associate.\n\nWe are nearly there. Now all that remains is tagging all the individual pieces. Let\u2019s start with our blueprint, the AMI.\n\n26. Under Images > AMI click on the name field and enter main-compute-instance.\n\n27. Take a similar action for the volume\n\nAssuming everything worked, this is it! You are now ready to enjoy your new setup!\n\nRequest the main-compute-instance from the cloned aws-setup repository\n\nGo to https://<public IP address of your network interface>:8888 in your browser. You can find the IP address under Elastic IPs\n\nAccess the notebook using the jupyter as the password. (You can bookmark the URL as the public IP address will not change across shutdowns).\n\nDo whatever you want to do and save your work to the workspace directory.\n\nWhen done, terminate the instance. From aws-setup directory, run\n\nWhen you boot up the main-compute-instance again, you will be able to mount the workspace volume and gain access to your data.\n\nIMPORTANT: If you don\u2019t authorize your local machine\u2019s IP address, main-compute-instance-connect will time out. In such a situation, just run authorize-current-ip. Ideally, you should be deauthorizing your IP address after every use via running deauthorize-ip."
    }
]