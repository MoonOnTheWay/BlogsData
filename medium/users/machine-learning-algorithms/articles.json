[
    {
        "url": "https://medium.com/machine-learning-algorithms/machine-learning-roadmap-cbbd9858774a?source=---------0",
        "title": "Machine Learning Roadmap \u2013 Machine Learning Notes \u2013",
        "text": "For latest update of this roadmap, please refer to my Github. I will only update over there.\n\nTo get some insights for subsequent processing and modeling. Check list:\n\n(1) Many search terms / products appeared several times.\n\n(2) Text similarities are great features.\n\n(3) Many products don\u2019t have attributes features. Would this be a problem?(4) Product ID seems to have strong predictive power. However the overlap of product ID between the training set and the testing set is not very high. Would this contribute to overfitting?\n\n(5) Check the distribution of features with continuous data.\n\n(1) Features are linear related -> heat map plot -> Pearson correlation coefficient\n\n(2) Outliers:\n\n- scatter plot -> manual remove outliers\n\n- Use OneClassSVM, EllipticEnvelope, IsolationForest, LocalOutlierFactor from sklearn to identify outliers and remove them.\n\n(3) Classification -> scatter plot with colour labels\n\n(1) Stack train & test -> Do feature transformation together.\n\n(2) Distribution of features -> box plot -> box-cox transformation.\n\n(3) Missing data -> mean, medium, delete, decision tree predict it, fill with specific value, \u2026etc\n\n(4) Categorical variables -> one-hot encoded\n\n(5) Noise -> less regularized, more iterations or depth of trees or deeper networks\n\n(6) Mixed features -> add, minus, multiply, divide by, \u2026etc\n\n(7) Count attributes. Find those frequent and easily exploited ones.\n\n(8) Unbalanced data:\n\n- Data augmentation (generate new data, such as rotation and shift in image data)\n\n- Give different weights to different classes.\n\n- Up sampling \u2014 increase the sampling rate\n\n- Down sampling \u2014 decrease the sampling rate\n\n(9) Use unsupervised learning algorithms such as PCA, LDA to reduce feature dimensions.\n\n(10) Standardize data \u2014 mean = 0, std = 1\n\nNote: Tree-based models don\u2019t depend on standardization, but boosting, neural networks do care.\n\n(11) Split data into training and testing data. Shuffle the training data.\n\nUse machine learning as baseline to optimize deep learning.\n\nDeep learning is not suitable for solving:\n\n- Data is too small\n\n- Data doesn\u2019t have local related features.\n\n(a) Search for papers to know the approximate values\n\n(b) Grid Search\n\n(c) Bayesian Optimization\n\n(a) eta: Step size used in updating weights. Lower eta means slower training but better convergence.\n\n(b) num_round: Total number of iterations.\n\n(c) subsample: The ratio of training data used in each iteration. This is to combat overfitting.\n\n(d) colsample_bytree: The ratio of features used in each iteration. This is like max_features in RandomForestClassifier.\n\n(e) max_depth: The maximum depth of each tree. Unlike random forest, gradient boosting would eventually overfit if we do not limit its depth.\n\n(f) early_stopping_rounds: If we don\u2019t see an increase of validation score for a given number of iterations, the algorithm will stop early. This is to combat overfitting, too.\n\n(h) Steps:\n\nStep 1. Reserve a portion of training set as the validation set.\n\nStep 2. Set eta to a relatively high value (e.g. 0.05 ~ 0.1), num_round to 300 ~ 500.\n\nStep 3. Use grid search to find the best combination of other parameters.\n\nStep 4. Gradually lower eta until we reach the optimum.\n\nStep 5. Use the validation set as watch_list to re-train the model with the best parameters. Observe how score changes on validation set in each iteration. Find the optimal value for early_stopping_rounds.\n\n(a) Try mini-batch gradient descent.\n\n(b) Try small learning rate at first.\n\n(c) Try ReLU activation function and Adam optimizer at first.\n\n(d) Under-fitting (high bias):\n\n- Deeper Neural Network (more neurons and more layers)\n\n- Decrease L2 Regularization\n\n- More Features\n\n(e) Overfitting (high variance):\n\n- L2 Regularization\n\n- Dropout\n\n- Batch Normalization\n\n- Data Augmentation\n\n- Pruning\n\n- Gradient Clipping / Early Stopping\n\n- Esemble Models\n\n- Reduce Features\n\n- More Data\n\n- Check model\u2019s coefficient, overfitting often associated with large estimated coefficient.\n\n(a) (Kaggle) Public leader board scores are not consistent with local CV scores due to noise or non ideal distribution. Local CV > public leader board.\n\n(b) 5-fold CV is good enough.\n\n(c) Implement stratified cross validation instead of basic cross validation on large number of classes or imbalance distribution for each classes.\n\n(6) Evaluation Metric\n\nUse the correct metric to evaluate the scores.\n\nIt reduces both bias and variance of the final model. Base models should be as unrelated as possibly. This is why we tend to include non-tree-based models in the ensemble even though they don\u2019t perform as well. The math says that the greater the diversity, and less bias in the final ensemble. Also, performance of base models shouldn\u2019t differ to much.\n\n(a) Bagging:\n\nUse different random subsets of training data to train each base model. Then all the base models vote to generate the final predictions. This is how random forest works.\n\n(b) Boosting:\n\nTrain base models iteratively, modify the weights of training samples according to the last iteration. This is how gradient boosted trees work. (Actually it\u2019s not the whole story. Apart from boosting, GBTs try to learn the residuals of earlier iterations.) It performs better than bagging but is more prone to overfitting.\n\n(c) Blending:\n\nUse non-overlapping data to train different base models and take a weighted average of them to obtain the final predictions. This is easy to implement but uses less data.\n\n(d) Stacking:\n\nTake 5-fold stacking as an example. First we split the training data into 5 folds. Next we will do 5 iterations. In each iteration, train every base model on 4 folds and predict on the hold-out fold. You have to keep the predictions on the testing data as well. This way, in each iteration every base model will make predictions on 1 fold of the training data and all of the testing data. After 5 iterations we will obtain a matrix of shape #(samples in training data) X #(base models). This matrix is then fed to the stacker (it\u2019s just another model) in the second level. After the stacker is fitted, use the predictions on testing data by base models (each base model is trained 5 times, therefore we have to take an average to obtain a matrix of the same shape) as the input for the stacker and obtain our final predictions."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/image-style-transfer-740d08f8c1bd?source=---------1",
        "title": "Image Style Transfer \u2013 Machine Learning Notes \u2013",
        "text": "Measuring low level features would not be able to capture perceptual defferences between output and ground truth images. Gatys et al proposal using high level features to obtain the style of the image and therefore reduce the perceptual differences. Moreover, Johnson et al improves Gatys et al\u2019s work by training a feed forward transformation networks ahead. A new faster architecture proposed by Johnson et al is shown below.\n\nThe idea is first presented by Gatys et al . Basically, you\u2019ll have two input images, a content image and a style image. And we wanna produce a mixed image which contains style (such as texture, colour) from style image and content from content image. In convolutional neural network, the feature maps in lower layers captures the low level features (i.e. content) and vice versa, the feature maps in higher layers captures the high level features (i.e. style). The image shown below illustrates the idea. During style reconstructions, the higher feature levels capture the style of the painting. On the other hand, during content reconstructions, the lower feature levels capture the content.\n\nWe are going to use VGG19, a per-trained model, to build our algorithm.\n\nIf you are interested, the code (jupyter notebook with tutorial) of this post is available below.\n\nSo, let\u2019s build an algorithm to do style transfer! First, we define the layers that we are going to extract.\n\nWhen calculating loss function for style features, we want to measure which features in the style layers activate simultaneously for the style image, and then copy this activation pattern to the mixed image.\n\nOne way of doing this, is to calculate the so called Gram matrix for the tensors output by the style layers. The Gram matrix is essentially just a matrix of dot products for the vectors of the feature activations of a style layer.\n\nIf an entry in the Gram matrix has a value close to zero then it means the two features in the given layer do not activate simultaneously for the given style image. And vice versa, if an entry in the Gram matrix has a large value, then it means the two features do activate simultaneously for the given style image. We will then try and create a mixed image that replicates this activation pattern of the style image.\n\nAbove is a style target flow through VGG19 net. We\u2019ll need an input image to flow through image transform net and VGG19 net in order to calculate style loss function.\n\nMoreover, let\u2019s create a loss function for denoising the mixed-image. The algorithm is called Total Variation Denoising and essentially just shifts the image one pixel in the x and y axis, calculates the difference from the original image, takes the absolute value to ensure the difference is a positive number, and sums over all the pixels in the image. This creates a loss function that can be minimized so as to suppress some of the noise in the image.\n\nTherefore, the total loss function is to add all of them.\n\nThe main optimization algorithm for the style transfer algorithm is basically just gradient descent on the loss functions. We use Adam as our optimizer.\n\nAfter training, we save the session as a ckpt file for evaluation. Now let\u2019s play with it! In this demo, I am going to use Taipei 101 building as a content image."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/mnist-using-recurrent-neural-network-2d070a5915a2?source=---------2",
        "title": "MNIST Using Recurrent Neural Network \u2013 Machine Learning Notes \u2013",
        "text": "If you are interested, the code (jupyter notebook and python file) of this post can be found here.\n\nIn this tutorial, I am going to demonstrate how to use recurrent neural network to predict the famous handwritten digits \u201cMNIST\u201d.\n\nThe original dataset can be downloaded here:\n\nHowever, We are going to directly use the same MNIST dataset from TensorFlow.\n\nEach image is 28 pixels (rows) by 28 pixels (cols). We treat each image as a sequence of data, that is, the first row is the first step; second row is the second step and so on. Therefore, n_steps = number of rows and n_inputs = number of columns.\n\nThe mnist dataset from TensorFlow assumes that you are using one-hot encoding, however, we are not going to do that. Therefore, we need to reshape the dataset from [num_data, 28*28] to [num_data, n_steps, n_inputs]. Since there are many outputs from the RNN, we only care about the last one. As a result, \u201cstate\u201d in the code is considered as our output.\n\nNow, go ahead and train the model!\n\nThe output is pretty good! The test accuracy is 97.2% without further optimization.\n\nIt is always nice to plot train loss vs epoch, therefore you could know if the train loss has converged."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/basic-recurrent-neural-network-tutorial-4-88872597421c?source=---------3",
        "title": "Basic Recurrent Neural Network Tutorial \u2014 4 \u2013 Machine Learning Notes \u2013",
        "text": "If you are interested, the code (jupyter notebook and python file) of this post can be found here.\n\nPreviously we only build the RNN with one hidden layer, however with deeper neural network comes great performance.\n\nAgain with our same input sequence of data\n\nNote that MultiRNNCell only accepts the list of BasicRNNCell, therefore we will create a list of 5 BasicRNNCell. Here I prefer to use \u201clayers\u201d in the code instead of \u201ccells\u201d, because hidden layers are the exact things that we are talking.\n\nThe state is different from what we have seen in single hidden layer.\n\nIf you like these series, don\u2019t hesitate to give me a clap below!"
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/build-basic-rnn-cell-with-dynamic-rnn-8cf388889156?source=---------4",
        "title": "Basic Recurrent Neural Network Tutorial \u2014 3 \u2013 Machine Learning Notes \u2013",
        "text": "If you are interested, the code (jupyter notebook and python file) of this post can be found here.\n\nDetailed explanations can be found previously using static_rnn. Here basically I\u2019ll just replace static_rnn with dynamic_rnn."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/build-basic-rnn-cell-with-static-rnn-707f41d31ee1?source=---------5",
        "title": "Basic Recurrent Neural Network Tutorial \u2014 2 \u2013 Machine Learning Notes \u2013",
        "text": "If you are interested, the code (jupyter notebook and python file) of this post can be found here.\n\nWe have three data to input per step (X0, X1, X2), therefore in placeholder we introduce a new dimension \u2018n_steps\u2019 to do that. BasicRNNCell will handle the matrix multiplication and use tanh() as default.\n\nThe input of static_rnn must be shape of [batch_size, n_inputs], so we need to unstack our X. Unstack along axis=1 will pull n_steps out, and the meaning here will become in i\u2019s step, the output of the shape is [batch_size, n_inputs] just like the previous example. Below is quoted from TensorFlow\u2019s description:\n\n\u201cGiven a tensor of shape (A, B, C, D). If axis == 1, then the i\u2019th tensor in output is the slice value[ : , i , : , : ] and each tensor in output will have shape (A, C, D).\u201d\n\nAfter static_rnn, we\u2019ll have to use tf.stack.\n\nSince tf.nn.static_rnn will have two results, let\u2019s see the difference.\n\nIn this case, the output will look like [X0, X1, X2] and the shape of X0, X1, X2 is [batch_size, n_neurons]\n\nIn this case, the output is [X2] with shape [batch_size, n_neurons].\n\nHere is the output:\n\nSince we\u2019ll have to unstack and stack the data, we could use dynamic_rnn to avoid that. So next I\u2019ll show you how to do that."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/basic-recurrent-neural-network-tutorial-5ea479ac6f82?source=---------6",
        "title": "Basic Recurrent Neural Network Tutorial \u2014 1 \u2013 Machine Learning Notes \u2013",
        "text": "If you are interested, the code (jupyter notebook and python file) of this post can be found here.\n\nLet\u2019s play with simple sequence to sequence RNN without using TensorFlow built-in API. We have a sequence of data, named X0, X1, X2. Each of the data has 2 input data. There are three batches of data ready to run.\n\nThe i \u2019s batch of sequence of data goes into the first hidden layer (only one hidden layer here). The shape is [i, n_inputs]. For example, the first batch (i = 0) of data is [1 2] [7 8] [13 14]. Each cell contains 8 neurons, and the shape of the cell is [n_inputs, n_neurons]\n\nThe shape of i \u2019s batch of y0, y1, y2 is [i, n_neurons]\n\nIn order to output a single value, we add a dense layer. Therefore the shape of i \u2019s output is [i, 1]\n\nNext, let\u2019s build a RNN model or in other terms, let\u2019s draw a graph with TensorFlow.\n\nGreat! Go and train our model!\n\nThe output looks like this.\n\nBy playing with this, you should get a good intuition of what sequence to sequence recurrent neural network is doing. Next, we\u2019ll use TensorFlow API to implement the same scenario."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-support-vector-machines-720fd795f304?source=---------7",
        "title": "What is Support Vector Machines? \u2013 Machine Learning Notes \u2013",
        "text": "Let\u2019s say we have the wights and the bias for a label of panda. When we apply the wights and the bias on a panda image, it will have a very high score. On the other hand, when we apply other image (let\u2019s say a dog image), the score is low. In order to distinguish a panda and others, we hope the score of a panda is higher by at least a margin. Let\u2019s give an example.\n\nWe apply the wights and the bias on an unknown image. When the score is higher than the score of panda, it is classify as panda. However, we don\u2019t wanna miss out some scores which can also classify as panda. Therefore we add a margin and have a wider range of score to classify the image as panda."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/some-intuitions-of-relu-activation-function-fc51c39cf328?source=---------8",
        "title": "Some Intuitions of ReLU Activation Function \u2013 Machine Learning Notes \u2013",
        "text": "ReLU can be written as f(x) = max(0, x). And this is what ReLU (Rectifier Linear Unit) function looks like:\n\nFirst, ReLu is fast because its function is very simple. Therefore the computation of stochastic gradient descent is inexpensive.\n\nSecond, the gate remains close when x < 0 in back propagation, because the derivative is zero. This implies that ReLU will filter out the negative values and so these neurons are deactivate or in other words, the neurons are dying. Since these neurons are not going to work in the future iteration, you should be careful of your learning rates.\n\nThird, the gate remains open when x > 0 in back propagation, because the derivative remains constant. Since the derivative remains constant, it does not saturate like sigmoid function."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-activation-function-in-convolutional-neural-network-d55154c2bdba?source=---------9",
        "title": "What is Activation Function in Neural Network? \u2013 Machine Learning Notes \u2013",
        "text": "There are two perspectives to look at the activation function by either forward propagation and back propagation.\n\nFirst, activation function is also called \u201ctransfer function\u201d. From the name, we can know that the function try to transfer the input data into a different output in forward propagation. Let\u2019s say we use sigmoid as our activation function. Now we have a dataset from -inf to inf. After we apply the activation function, the dataset is squeezed from -1to 1. Therefore the input data has been transferring (or squashing) into a different one. Why we wanna do that? Well, different activation functions have different reasons. But, in this case, it helps us to squeeze the data into a specific range which is great for predicting probability. If we apply ReLU as our activation function, we could get rid of the negative data. OK! Let\u2019s take a look at the second perspective.\n\nSecond, activation function, just like what it is called, is used for activating the neurons in neural network. In back propagation, we need to update the weights and the biases, so that the neural network can \u201clearn\u201d. In order to do that, the derivative of the activation function should be non-zero. Therefore the neural network can update the weights and the biases. However, if the derivative of the activation function is zero, the weights and the biases won\u2019t update. This is like the neurons are dead. As a result, activation function serves as a threshold."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-padding-in-convolutional-neural-network-c120077469cc",
        "title": "What is \u201cpadding\u201d in Convolutional Neural Network? \u2013 Machine Learning Notes \u2013",
        "text": "Let\u2019s see some figures. The black color part is the original size of the image.\n\nIf zero padding = 1, there will be one pixel thick around the original image with pixel value = 0.\n\nEvery time we use the filter (a.k.a. kernel) to scan the image, the size of the image will go smaller and smaller. We don\u2019t want that, because we wanna preserve the original size of the image to extract some low level features. Therefore, we will add some extra pixels outside the image!"
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-stride-in-convolutional-neural-network-e3b4ae9baedb",
        "title": "What is \u201cstride\u201d in Convolutional Neural Network? \u2013 Machine Learning Notes \u2013",
        "text": "How does a computer read an image? Basically a computer read an image from left to right and from top to bottom. Therefore it starts from the top-left corner all the way to bottom-right corner. Moreover, it reads the image with a definite size. Image this scenario: A man is reading a newspaper by using magnifier. Every time the man could only read parts of the newspaper and the size of the magnifier decides how many words the man could read. Back to our discussion, the computer is taking a filter to read the image.\n\nThen we define how far the filter moves from one position to the next position by \u201cstride\u201d. Let\u2019s look at an example. The red square is a filter. The computer is going to use this filter to scan the image.\n\nIf stride = 1, the filter will move one pixel.\n\nIf stride = 2, the filter will move two pixels."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-linear-regression-b6fe44d47e0c",
        "title": "What is Linear Regression? \u2013 Machine Learning Notes \u2013",
        "text": "Let\u2019s say we have a dataset like this:\n\nEvery input has its corresponding output. We suppose that the relation between the input and the output is linear, so we draw a random blue line. We measure the distance between the data and the blue line. In order to predict a great relationship between the input and the output, every distance between the data and the blue line should be as short as possible.\n\nTherefore, we try different direction of the blue line in order to fit the requirement. The blue line that fits the requirement is our model. Based on this model, we can use it to predict a new input!\n\nTo be more specifically, in an ordinary least squares linear regression, we calculate the square of the distance and sum all of them. Then we try to find the min value by gradient descent. Therefore, we acquire the slope and the intercept of the equation. As a result, this is our linear regression model!\n\nHere is a demo code for linear regression using Scikit-learn.\n\nhttp://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-reinforcement-learning-5f34733402e5",
        "title": "What is Reinforcement Learning \u2013 Machine Learning Notes \u2013",
        "text": "Let\u2019s tear up the sentence. \u201cLearn\u201d means that the computer have no idea how the environment works in advance. \u201cmake\u201d means that the computer needs to take action to do something. \u201cgood\u201d means that the computer will receive some rewards, so it will know whether its action is good or bad. \u201csequences of decisions\u201d means that the computer will repeatedly interact with the environment. It\u2019s basically like a trial-and-error learning.\n\nReinforcement learning is basically just the same as how human learn in an unknown environment. Let\u2019s see a simple example. A child\u2019s parents are not at home. The child wants to play video games, but he hasn\u2019t finished his homework. In scenario 1, he chooses to play video games. After his parents return, they punish him. So the child learns that if he plays video games, he would get punishment. In scenario 2, he chooses to finish his homework. After his parents come back, they give him a lollipop. Therefore, next time if the same scenario happens again, he would choose to finish his homework.\n\nLet\u2019s take a look at Markov Decision Process which is the basic decision process of reinforcement learning:\n\nThe agent (a.k.a. the computer) takes action toward the environment. The environment will give you some feedbacks. So the agent will observe the feedback and maybe it will receive some rewards. Don\u2019t you think this is very similar to supervised learning. In supervised learning, the computer receives the true labels. In reinforcement learning, the computer receives the rewards. However, some differences are the feedback is delayed, and agent\u2019s actions affect the feedback it receives. Since the computer needs to take actions by trial-and-error, it takes time. Also, the goal of the agent is to take actions in an environment to maximize the cumulative rewards. Therefore, sometimes the agent will sacrifice immediate reward to gain more long term reward."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-unsupervised-learning-d0a30b1d618a",
        "title": "What is Unsupervised Learning? \u2013 Machine Learning Notes \u2013",
        "text": "Let\u2019s say we have a dataset, but there is no labels on it.\n\nHowever, when observing the dataset, we can find out that there are two clusters in the figure. Some data points are very close to each other and some of them are not. Therefore, we can label these data by how close they are. Now we have a dataset with two labels on it.\n\nAs a result, the dataset is given by some new labels based on what approaches we deal with the dataset. A well-known approach is to use k-means clustering. However, the choice of an approach is highly regard to what your data looks like.\n\nUnsupervised learning is quite interesting and very helpful. Why is that? First, unsupervised learning could tell something that we don\u2019t know. Second, we know that supervised learning needs a lot of data with true labels, but it is hard to have these data. With unsupervised learning, it can help us to label the dataset and throw into the computer to train it! Moreover, dealing with a dataset with both labeled and unlabeled data is called \u201cSemi-supervised Learning\u201d."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-supervised-learning-8022822f11e4",
        "title": "What is Supervised Learning? \u2013 Machine Learning Notes \u2013",
        "text": "Supervised learning is a type of machine learning and try to deal with the problem which has the right answer with every data. Let\u2019s say we have lots of panda\u2019s photos. We throw these photos into a computer and tell the computer that every photo is panda. Therefore, the computer generates a model to recognize a panda.\n\nNext, if we have a new panda\u2019s photo and a dog\u2019s photo, we throw these two photos into the model. Let\u2019s see what happens!\n\nThe model can tell that the new panda\u2019s photo is truly a panda; on the other side, the model can tell that the dog is not a panda.\n\nAlso, we could throw many photos with different labels (cat, dog, horse,\u2026etc) into a computer, and tell the computer what that photo is. Hence, the computer will generate different patterns respect to the labels.\n\nBy giving the right answer, the computer could learn from it. Moreover, in order to recognize perfectly, we will have to throw as much data as we can to train the computer. This is quite intuitive because, as a human, we also need to see many photos in order to recognize an object.\n\nNowadays, most of the machine learning question is to deal with supervised learning. Since we need to throw lots of data to computer, we will need a powerful computing capability."
    },
    {
        "url": "https://medium.com/machine-learning-algorithms/what-is-machine-learning-e18ea1a29049",
        "title": "What is Machine Learning? \u2013 Machine Learning Notes \u2013",
        "text": "Normally, we will have to hard-code every details to let the program work. For example, if we want to describe what a panda looks like, we will have to fully describe the characteristic appearance of a panda, such as ears, hands, feet are all black and a black spot on both their eyes. However, this is hard, since there are still some exceptions. Unfortunately, hard-code is not great to describe what a panda looks like.\n\nNow, let\u2019s discuss how human learn how to recognize a panda. Human learn to recognize what a pandas looks like by looking at many panda\u2019s photos and telling you that this is a panda. While you are looking at these panda\u2019s photos, the neurons in your brain are making some connections all the way to somewhere in your brain and memorize the appearance of a panda. So next time you see a new photo of a panda, the pulse will go through the same path of those neurons and arrive the same destination telling you that this photo is a panda.\n\nThanks to the born of machine learning, we could train the computer to learn just like human do. By giving lots of panda\u2019s photos to a computer, the computer can learn from these photos and automatically come out a pattern to help itself to recognize the panda.\n\nFor the panda sake, now we don\u2019t have to hard-code a program to recognize an object. Moreover, we could simply use the same algorithm to train a computer to recognize different objects."
    }
]