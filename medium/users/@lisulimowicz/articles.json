[
    {
        "url": "https://medium.com/algorithms-and-leetcode/data-structures-introductions-and-implementation-with-python-1c9088f19420?source=user_profile---------1----------------",
        "title": "Data Structures: Introductions and Implementation with Python",
        "text": "Many applications require a dynamic set that supports only the dictionary operations INSERT, SEARCH, DELETE. Under reasonable assumptions, the average time to search for an element in a hash table is O(1). The worst case is O(n) when there are as many as n collision when we are doing searching.\n\nA hash table typically uses an array of size proportional to the number of keys actually stored. Instead of using the key as an array index directly, the array index is computed from the key using a hash function. When more than one key maps to the same array index, this is called \u201ccollision\u201d, which is usually handled by \u201cChaining\u201d that we store a linked list in the collide index position.\n\nHash function maps the universe U of keys into the slots of a hashtable T[0..m-1]. With hash function the element is stored in h(k).\n\nwhere the size of the hash table is much less than . With hash function, the range of array indices and the size of the array is reduced.\n\nWhen two keys hash to the same slot, this situation is called collision. The idea to solve collision is to avoid collisions.\n\nOne idea is to make appear to be \u201crandom\u201d, thus avoiding collisions or at least minimizing their number. Because , there must be at least two keys that have the same hash value; avoiding collisions altogether is therefore impossible. Thus, we use a well-designed, \u201crandom\u201d-looking hash function to minimize the number of collisions. However, we still need a method for resolving the collisions that do occur.\n\nIn chaining, we place all the elements that hash to the same slot into the same linked list.\n\nA good hash function satisfied the condtion of simple uniform hashing: each key is equally likely to has to any of the slots.\n\nStep 1: interpreting keys as nature numbers N = {0,1,2, \u2026}. For string or character, we might translate pt as the pair of decimal integers with their ASCII character; then we express it as a radix-128 integer, then the number we get is (112*128)+116 = 14452.\n\nThe set classes are implemented using dictionaries. Accordingly, the requirements for set elements are the same as those for dictionary keys; namely, that the element defines both and . As a result, sets cannot contain mutable elements such as lists or dictionaries. However, they can contain immutable collections such as tuples or instances of . For convenience in implementing sets of sets, inner sets are automatically converted to immutable form, for example, is transformed to .\n\nStandard dictionaries are unordered, which means that any time you loop through a dictionary, you will go through every key, but you are not guaranteed to get them in any particular order.\n\nThe OrderedDict from the collections module is a special type of dictionary that keeps track of the order in which its keys were inserted. Iterating the keys of an orderedDict has predictable behavior. This can simplify testing and debugging by making all the code deterministic.\n\nDictionaries are useful for bookkeeping and tracking statistics. One problem is that when we try to add an element, we have no idea if the key is present or not, which requires us to check such condition every time.\n\nThe defaultdict class from the collections module simplifies this process by pre-assigning a default value when a key does not present. For different value type it has different default value, for example, for int, it is 0 as the default value.\n\nSearch, Insert, Delete: O(1). Check here for more details.\n\nStacks and queue are dynamic lists in which the element removed from the list by the DELETE operation is prespecified. The operation of PUSH and POP takes O(1) time complexity. These two structure are good for problems that we deal with element in either FIFO or LIFO manner.\n\nqueue: it is first in, first out, FIFO, which can be used to implement iterative BFS. The following code is the basic implementation with Python.\n\nstack: the element deleted is the most recently inserted, Last in first out, LIFO, which can be used to implement iterative DFS. The following code is the basic implementation with Python.\n\nDeque (operation from both side): In Python, the deque class from the collections module is a double-ended queue. It provides constant time opearations for inserting ore removing items from its beginning or end. It can be used to implement both stack and queue structure we mentioned above and usually is more time efficient than the above implementation. Mainly because inserting or removing elements from the head of a list takes linear time.\n\nThe (binary) heap data structure is an array that we can view as a nearly complete binary tree. The tree is completely filled on all levels except possibly the lowest, which is filled from left up to a point.\n\nAs we can see we can implement either the max-heap or the min-heap as an array. Because the tree is complete, the left child of a parent (at position p) is the node that is found in position 2p in the list. Similarly, the right child of the parent is at position 2p+1 in the list. To find the parent of any node in the tree, we can simply use Python\u2019s integer division. Given that a node is at position n in the list, the parent is at position n/2.\n\nThere are two kinds of binary heaps: max-heaps and min-heaps. In both kinds, the values in the nodes satisfy a heap property. For max-heap, the property states as for every node other than root.\n\nThus, the largest element in a max-heap is stored at the root.\n\nFor a heap of elements the height is theta(logn) because it is a complete binary tree.\n\nHeap can be used into heapsort and a priority-queue data structure. Operations include:\n\nheapq: heapq from collections is an implementation of heap, which can be used to maintain a priority queue. Operations include heappush, heappop, and nsmallest. heapq in python to maintain a priority queue with O(logn)\n\nItems are removed by the highest priority or say the lowest number first. Also, accessing the 0 index of the heap will return the smallest item.\n\nMore materials can be found here.\n\nMonotonous Stack: For monotonous increasing stack, which only allow the increasing element to be put in the stack, smaller one came will kick out the larger one in the previous position, untill we found one that is smaller than the current element. For the monotonous decreasing stack, the larger elements will force the stack to kick out the previous smaller element untill larger one found. In monotonous stack, we only operate at the end of the stack. To summarize, monotonous stack has two features:\n\nLike arrays, Linked List is a linear data structure. Unlike arrays, linked list elements are not stored at contiguous location; the elements are linked using pointers.\n\nWhy Linked List?\n\n Arrays can be used to store linear data of similar types, but arrays have following limitations.\n\n 1) The size of the arrays is fixed: So we must know the upper limit on the number of elements in advance. Also, generally, the allocated memory is equal to the upper limit irrespective of the usage.\n\n 2) Inserting a new element in an array of elements is expensive, because room has to be created for the new elements and to create room existing elements have to shifted.\n\nDrawbacks:\n\n 1) Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do binary search with linked lists.\n\n 2) Extra memory space for a pointer is required with each element of the list.\n\nFor Linked List, we can only iterate over elements, for python code example:\n\nBinary Tree and Binary Search Tree, please see my following post.\n\n[2] G\u00e9ron, Aur\u00e9lien. Hands-on machine learning with Scikit-Learn and TensorFlow: concepts, tools, and techniques to build intelligent systems. \u201c O\u2019Reilly Media, Inc.\u201d, 2017."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/hard-problems-c52ae31cdb5e?source=user_profile---------2----------------",
        "title": "Hard problems \u2013 Algorithms and Leetcode \u2013",
        "text": "Now, optimize it, if size 2 not satisfied, then no need to check size 3, now the code is accepted. 868ms\n\nMore optimization: use because when we check size 3, we recheck size 2 area, that is repeation. So we can only check the last col and the last row. 564ms\n\nNow to compute the sum\n\nThe time complexity of the following is O(n\u00b3)\n\nFor the upper case: if we use row+1 and col+1 then we dont need to think about col 0 and row 0. This will solve the problem in O(n\u00b2)\n\nNow, the same as before, use the sums\n\nStill can not be AC. So we need another solution. Now use the largest rectangle in histogram.\n\nGiven n non-negative integers representing the histogram\u2019s bar height where the width of each bar is 1, find the area of largest rectangle in the histogram.\n\nAbove is a histogram where width of each bar is 1, given height = .\n\nThe largest rectangle is shown in the shaded area, which has area = unit.\n\nSolution: brute force. O(n\u00b2) to track the min height and width.\n\nNow, try the BCR. the thought is find the maximum area that use each height as rectangle height.\n\n0 ``6 [-1, 0] #becuase the area that use 6 as height is growing\n\n1 ``7 [-1, 0,1] #the area that use 6 and 7 as height is growing\n\n2``5 because 5<7, the growing of 7 ends here, pop(7), the width is current-index- index of 0 -1 = 1, the area is 7*width = 7\n\nbecause 5<6, the growing of 6 ends here, the width is current_index-(-1)-1=2, and the area = 2*6=12\n\nhow to deal if current number equals to previous, 6,6,6,6,6, we need to pop previous, and append current. The structure we use here is called Monotonic Stack, which will only allow the increasing elements to get in the stack, and once smaller or equal ones get in, it kicks out the previous smaller elements.\n\nSolution: for this problem, at first, I try to find the difference of all the peaks and bottoms, get the different, sort them and return the first k. passed 200/211. This case gave me the wrong answers: [1,2,4,2,5,7,2,4,9,0]. k=2, my answer is 12, the right is 13\n\nA different approach, save the bottoms and peaks [1,4,2,7,2,9]. Find at most k pairs that has the maximum accumulated differences.\n\n(0,0) to build a tree, (1,4) (1,7),(1,9) another level (2,7) (2,9) \u2026. The subproblems. However this subproblems are still pretty hard to resolve."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/dp-c6797e0618a?source=user_profile---------3----------------",
        "title": "DP \u2013 Algorithms and Leetcode \u2013",
        "text": "Top-down: in this article, most of the time, we use top-down\n\nGiven a sequence of integers, find the longest increasing subsequence (LIS).\n\nYou code should return the length of the LIS.\n\nFunction: L(i) = 1 + max( L(j) ) where 0 < j < i and arr[j] < arr[i]; or\n\n L(i) = 1, if no such j exists.\n\nGiven a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path.\n\nNote: You can only move either down or right at any point in time.\n\nGiven the above grid map, return . Because the path 1\u21923\u21921\u21921\u21921 minimizes the sum.\n\nAs can be seen, each time when we update , we only need (at the current column) and (at the left column). So we need not maintain the full matrix. Maintaining two columns is enough and now we have the following code.\n\nFurther inspecting the above code, it can be seen that maintaining is for recovering , which is simply before its update. So it is enough to use only one vector. Now the space is further optimized and the code also gets shorter.\n\nNow, we use O(1) space by reusing the original grid.\n\nA robot is located at the top-left corner of a m x n grid (marked \u2018Start\u2019 in the diagram below).\n\nThe robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked \u2018Finish\u2019 in the diagram below).\n\nHow many possible unique paths are there?\n\nAbove is a 3 x 7 grid. How many possible unique paths are there?\n\nNote: m and n will be at most 100.\n\nSolution: The difference here is to get all the possible solutions.\n\nGiven a sequence of integers, find the longest increasing subsequence (LIS).\n\nYou code should return the length of the LIS.\n\nFunction: L(i) = 1 + max( L(j) ) where 0 < j < i and arr[j] < arr[i]; or\n\n L(i) = 1, if no such j exists.\n\nYou are a professional robber planning to rob houses along a street. Each house has a certain amount of money stashed, the only constraint stopping you from robbing each of them is that adjacent houses have security system connected and it will automatically contact the police if two adjacent houses were broken into on the same night.\n\nGiven a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.\n\np[i] : take i or not to take i, we can get the maximum money\n\nNote: This is an extension of House Robber.\n\nAfter robbing those houses on that street, the thief has found himself a new place for his thievery so that he will not get too much attention. This time, all houses at this place are arranged in a circle. That means the first house is the neighbor of the last one. Meanwhile, the security system for these houses remain the same as for those in the previous street.\n\nGiven a list of non-negative integers representing the amount of money of each house, determine the maximum amount of money you can rob tonight without alerting the police.\n\nThere are a row of n houses, each house can be painted with one of the three colors: red, blue or green. The cost of painting each house with a certain color is different. You have to paint all the houses such that no two adjacent houses have the same color.\n\nThe cost of painting each house with a certain color is represented by a cost matrix. For example, is the cost of painting house 0 with color red; is the cost of painting house 1 with color green, and so on... Find the minimum cost to paint all houses.\n\nSolution: state: 0, 1, 2 colors\n\nminCost[i] = till i the mincost for each color\n\nfor color 0: paint 0 [0] = min(minCost[i-1][1], minCost[i-1][2])+costs[i][0]\n\nThere are a row of n houses, each house can be painted with one of the k colors. The cost of painting each house with a certain color is different. You have to paint all the houses such that no two adjacent houses have the same color.\n\nThe cost of painting each house with a certain color is represented by a cost matrix. For example, is the cost of painting house 0 with color 0; is the cost of painting house 1 with color 2, and so on... Find the minimum cost to paint all houses.\n\nFollow up:\n\n Could you solve it in O(nk) runtime?\n\nSolution: this is exactly the same as the last one:\n\nThere is a fence with n posts, each post can be painted with one of the k colors.\n\nYou have to paint all the posts such that no more than two adjacent fence posts have the same color.\n\nReturn the total number of ways you can paint the fence.\n\nGiven a string s, partition s such that every substring of the partition is a palindrome.\n\nReturn all possible palindrome partitioning of s.\n\nFor example, given s = ,\n\n Return\n\nSolution: here we not only need to count all the solutions, we need to record all the solutions.\n\n\u9898\u76ee:Word Break \n\n Given a string s and a dictionary of words dict, determine if s can be break into a space-separated sequence of one or more dictionary words.\n\nReturn true because \u201clintcode\u201d can be break as \u201clint code\u201d.\n\nGiven an array of scores that are non-negative integers. Player 1 picks one of the numbers from either end of the array followed by the player 2 and then player 1 and so on. Each time a player picks a number, that number will not be available for the next player. This continues until all the scores have been chosen. The player with the maximum score wins.\n\nGiven an array of scores, predict whether player 1 is the winner. You can assume each player plays to maximize his score.\n\nThere is a stone game. At the beginning of the game the player picks n piles of stones in a line.\n\nThe goal is to merge the stones in one pile observing the following rules:\n\nAt each step of the game,the player can merge two adjacent piles to a new pile.\n\n The score is the number of stones in the new pile.\n\n You are to determine the minimum of the total score.\n\n Example\n\n For [4, 1, 1, 4], in the best solution, the total score is 18:\n\nGiven balloons, indexed from to . Each balloon is painted with a number on it represented by array . You are asked to burst all the balloons. If the you burst balloon you will get coins. Here and are adjacent indices of . After the burst, the and then becomes adjacent.\n\nFind the maximum coins you can collect by bursting the balloons wisely.\n\nNote: \n\n (1) You may imagine . They are not real therefore you can not burst them.\n\n (2) 0 \u2264 \u2264 500, 0 \u2264 \u2264 100\n\nGiven a string s, find the longest palindromic subsequence\u2019s length in s. You may assume that the maximum length of s is 1000.\n\nOne possible longest palindromic subsequence is \u201cbbbb\u201d.\n\nOne possible longest palindromic subsequence is \u201cbb\u201d.\n\nSolution: for this problem, we have state dp[i][j] means from i to j, the length of the longest palindromic subsequence. dp[i][i] = 1. Then we use this range to fill in the dp matrix (upper triangle.)\n\nOr else, we can say, i need to be from i+1 to i, from big to small, j need to from j-1 or j to j, from small to big.\n\nNow to do the space optimization:\n\nGiven two words word1 and word2, find the minimum number of steps required to convert word1 to word2. (each operation is counted as 1 step.)\n\nYou have the following 3 operations permitted on a word:\n\nGiven two words word1 and word2, find the minimum number of steps required to convert word1 to word2. (each operation is counted as 1 step.)\n\nYou have the following 3 operations permitted on a word:\n\nInsert a character\n\n Delete a character\n\n Replace a character\n\n Have you met this question in a real interview? Yes\n\n Example\n\n Given word1 = \u201cmart\u201d and word2 = \u201ckarma\u201d, return 3.\n\nGiven two words word1 and word2, find the minimum number of steps required to make word1 and word2 the same, where in each step you can delete one character in either string.\n\nSolution: pretty much the same as the last question\n\nGiven two strings , find the lowest ASCII sum of deleted characters to make two strings equal.\n\nGiven two strings, find the longest common subsequence (LCS).\n\nYour code should return the length of LCS.\n\nhttps://en.wikipedia.org/wiki/Longest_common_subsequence_problem\n\n http://baike.baidu.com/view/2020307.htm\n\n Example\n\n For \u201cABCD\u201d and \u201cEDCA\u201d, the LCS is \u201cA\u201d (or \u201cD\u201d, \u201cC\u201d), return 1.\n\nFor \u201cABCD\u201d and \u201cEACB\u201d, the LCS is \u201cAC\u201d, return 2.\n\nOn a staircase, the -th step has some non-negative cost assigned (0 indexed).\n\nOnce you pay the cost, you can either climb one or two steps. You need to find minimum cost to reach the top of the floor, and you can either start from the step with index 0, or the step with index 1.\n\nSolution: similar as the way to get the state change function:\n\naCost[i] =min( aCost[i-2]+cost[i-2] , aCost[i-1]+cost[i-1] ), which means to get floor i (1,..,n), we can get from floor i-2, or floor i-1, the final result is the minimum one. you can either start from the step with index 0, or the step with index 1, can be translated into aCost[0] = 0, aCost[1] = 0\n\nfor example 1, aCost[2] = min(aCost[0]+10, aCost[1]+15) =10, aCost(3)=min(aCost(1)+cost(1), aCost(2)+cost(2)=min(15,10+20) = 15. The following code saved space."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/greedy-algorithms-18170ccffe7?source=user_profile---------4----------------",
        "title": "Greedy Algorithms \u2013 Algorithms and Leetcode \u2013",
        "text": "Analysis: this is a typical activity selection problem in greedy algorithms.\n\nFirst step: DP to determine the optimal substructure\n\nLet Sij be set activities inside (ai, aj), Aij, is the solution and ak is one, then Aij=Aik+ak+Akj. If we think about the size, then c(i,j)=c(i,k)+c[k,j)+1.\n\nc(i,j)=0 if Sij is empty, else c(i,j)=max ak(c(i,k)+c[k,j)+1). T(n)=T(n-1)+T(1) + T(n-2)+T(2)+\u2026T(1)+T(n-1)+O(n), 3^n.\n\nThen if we use memo, we can get n subproblems, and each takes O(n) to resolve, so the time complexity become O(n\u00b2).\n\nShow that if we make the greedy choice, then only one subproblem remains\n\nwhat if we can choose an activity to add to our optimal solution wihout having to first resolve all the subproblems?\n\nThe greedy choice here is: we choose an activity that will leave resources for others with an earliest finish time (smallest finish time). So we sort the activities by finish time incrementally. Thus, all the other activity will start after a1\u2019s finish time(s_i\u2265f_1)\n\nProve that it is always safe to make the greedy choice\n\nconvert the recursive algorithms to an iterative algorithm\n\nGiven an array of non-negative integers, you are initially positioned at the first index of the array.\n\nEach element in the array represents your maximum jump length at that position.\n\nDetermine if you are able to reach the last index.\n\nMore solutions: that we use greedy\n\nTop-down to bottom-up conversion is done by eliminating recursion. In practice, this achieves better performance as we no longer have the method stack overhead and might even benefit from some caching. More importantly, this step opens up possibilities for future optimization. The recursion is usually eliminated by trying to reverse the order of the steps from the top-down approach.\n\nThe observation to make here is that we only ever jump to the right. This means that if we start from the right of the array, every time we will query a position to our right, that position has already be determined as being GOOD or BAD. This means we don\u2019t need to recurse anymore, as we will always hit the table."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/bit-manipulation-4-of-leetcode-problems-e67db88598d1?source=user_profile---------5----------------",
        "title": "Bit Manipulation 4% of LeetCode Problems \u2013 Algorithms and Leetcode \u2013",
        "text": "Two\u2019s complement and negative number: The binary representation of -k as a N-bit number is concat(1, 2^(N-1)-k) ==representation in positive, flip each bit, and +1.\n\nArithmetic right shift: shift to the right side, but fill in the new bits with the value of the sign bit, the same result as divide 2^N, for shifting N bits\n\nLogical right shift, we shift values and put a 0 in the most significant bit. It is indicated with a >>> operator.\n\nClear Bit: First create a 1110111 by creating the reverse of 0001000 and negating it. Then perform AND with num, then we will clear the ith bit and leave the remainder unchanged. mask = ~(1<<i), num&mask.\n\nTo clear all bits from the most significant bit till i, we create a mask with a 1, 1<<i. Then we subtract 1 from it, i=4, 00010000->00001111, we left 4 bits untouched. mask = (1<<i)-1, num&mask\n\nTo clear all bits from i through 0. mask = (-1<<(i+1)) ,-1 is all 1s, then we have a sequence of 1s followed by i 0 bits. num & mask\n\nUpdate Bits: mask = ~(1<<i), use this to clear at first, (num&mask) | (value<<i)\n\nXOR: Bitwise XOR ( ^ ) like the other operators (except ~) also take two equal-length bit patterns. If both bits in the compared position of the bit patterns are 0 or 1, the bit in the resulting bit pattern is 0, otherwise 1. (to detect difference)\n\nExample: For 1010, you should perform some operations to give 0010 as the output. For 1100, you should give 0100. Similarly for 0001, you should return 0001.\n\nTry finding the solution yourself. The biggest hint you have is you can do it using ( ^ ) operator. After you\u2019re done, scroll down.\n\nFor this problem, you need to know a property of binary subtraction. Check if you can find out the property in the examples below,\n\nThe property is, the difference between a binary number n and n-1 is all the bits on the right of the rightmost 1 are flipped including the rightmost 1. Using this amazing property, we can get our solution as\n\nYou can refer the example above. You will need to return 6.\n\nThis one is kinda straightforward. You\u2019ll need to know the following properties\n\nSo, for my final question, i would like to give you a problem that is quite challenging. This one do not require the use of any new property of XOR other than the ones mentioned above.\n\na XOR b = c => c XOR b= a, eg. a=00111011, b=10100000 , c= 10011011, c ^b= a\n\nGiven an array of integers, every element appears twice except for one. Find that single one.\n\nGiven two strings s and t which consist of only lowercase letters.\n\nString t is generated by random shuffling string s and then add one more letter at a random position.\n\nFind the letter that was added in t.\n\nSolution: Using bit manipulation and with O(1) we can find it in O(M+N) time, which is the best BCR:\n\n421. Maximum XOR of Two Numbers in an Array\n\nGiven a non-empty array of numbers, a0, a1, a2, \u2026 , an-1, where 0 \u2264 ai < 231. Find the maximum result of ai XOR aj, where 0 \u2264 i, j < n. Could you do this in O(n) runtime?\n\nExplanation: suppose a^b = max, then a^max = b, so we just need to prob the possible max, and check if the value we need to get the possible max is in the list. We can get the max with the previous answer^ 1 = possible max (keep the result from other digit, just to check the lowest digit, or answer+1). We visit the highest position to the lowest, start with the possible answer= 0, so that the possible max is answer+1 =1, when we go to the next position, answer =0, possible max is 1, the following process is showed as follows:\n\nFirst let\u2019s think what does bitwise AND do to two numbers, for example ( 0b means base 2)\n\nThe operator & is keeping those bits which is set in both number.\n\nFor several numbers, the operator & is keeping those bits which is 1 in every number.\n\nIn other word, a bit is 0 in any number will result in 0 in the answer\u2019s corresponding bit.\n\nSolution: The first solution is a O(n), it almost passed all the test, however, still with LTE\n\nhere xyzpacdrst all are digits in base 2.\n\nWe can find two numbers that are special in the range [m, n]\n\nThe bitwise AND of all the numbers in range [m, n] is just the bitwise AND of the two special number\n\nThis tells us, the bitwise and of the range is keeping the common bits of m and n from left to right until the first bit that they are different, padding zeros for the rest."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/sorting-and-searching-12e88583ee5d?source=user_profile---------6----------------",
        "title": "Sorting and Searching \u2013 Algorithms and Leetcode \u2013",
        "text": "For this problem, we just standardalize the python coding of binary search, which takes O(logn) time complexity and O(1) space complexity without using recursion function.\n\nSuppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.\n\nYou are given a target value to search. If found in the array return its index, otherwise return -1.\n\nYou may assume no duplicate exists in the array.\n\nSolution: use binary search, the difference is we need to check if the mid is in the left range or in the right range.\n\nWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:\n\nConsider the following matrix:\n\nAlso, we can treat is as one dimensional, and the time complexity is O(lg(m*n)), which is the same as O(log(m)+log(n)).\n\nWrite an efficient algorithm that searches for a value in an m x n matrix. This matrix has the following properties:\n\nConsider the following matrix:\n\nSolution: the simplest solution we can find is to try try each row, and do a binary search there. O(mlogn).\n\nHowever, we can do it better. More Solutions here.\n\nYou are a product manager and currently leading a team to develop a new product. Unfortunately, the latest version of your product fails the quality check. Since each version is developed based on the previous version, all the versions after a bad version are also bad.\n\nSuppose you have versions and you want to find out the first bad one, which causes all the following ones to be bad.\n\nYou are given an API which will return whether is bad. Implement a function to find the first bad version. You should minimize the number of calls to the API.\n\nSolution: we keep doing binary search till we searched all possible area.\n\nThere are two sorted arrays nums1 and nums2 of size m and n respectively.\n\nFind the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).\n\nSolution: the requirement log(m+n) means we need to use binary search. Suppose it is combined and sorted, then k=(n1+n2+1)/2=7 (the middle), m1 comes from the lst1 and m2 comes from lst2. If we found m1 then m2 we can get from k-m1, so we do binary search in the shorter lst.\n\nSuppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.\n\nYou may assume no duplicate exists in the array.\n\nCompute and return the square root of x.\n\nHave you met this question in a real interview? Yes\n\n Example\n\n sqrt(3) = 1\n\nCompute and return the square root of x.\n\nYou do not care about the accuracy of the result, we will help you to output results.\n\nHave you met this question in a real interview? Yes\n\n Example\n\n Given n = 2 return 1.41421356\n\nGiven n pieces of wood with length L[i] (integer array). Cut them into small pieces to guarantee you could have equal or more than k pieces with the same length. What is the longest length you can get from the n pieces of wood? Given L & k, return the maximum length of the small pieces.\n\nIf you couldn\u2019t get >= k pieces, return 0.\n\nHave you met this question in a real interview? Yes\n\n Example\n\n For L=[232, 124, 456], k=7, return 114.\n\nGiven an array nums containing n + 1 integers where each integer is between 1 and n (inclusive), prove that at least one duplicate number must exist. Assume that there is only one duplicate number, find the duplicate one.\n\nYou must not modify the array (assume the array is read only).\n\n You must use only constant, O(1) extra space.\n\n Your runtime complexity should be less than O(n\u00b2).\n\n There is only one duplicate number in the array, but it could be repeated more than once.\n\n Have you met this question in a real interview? Yes\n\n Example\n\n Given nums = [5,5,4,3,2,1] return 5\n\n Given nums = [5,4,4,3,2,1] return 4\n\nGiven an interval list which are flying and landing time of the flight. How many airplanes are on the sky at most?\n\nIf landing and flying happens at the same time, we consider landing should happen at first.\n\nA city\u2019s skyline is the outer contour of the silhouette formed by all the buildings in that city when viewed from a distance. Now suppose you are given the locations and height of all the buildings as shown on a cityscape photo (Figure A), write a program to output the skyline formed by these buildings collectively (Figure B).\n\nThe geometric information of each building is represented by a triplet of integers , where and are the x coordinates of the left and right edge of the ith building, respectively, and is its height. It is guaranteed that , , and . You may assume all buildings are perfect rectangles grounded on an absolutely flat surface at height 0.\n\nFor instance, the dimensions of all buildings in Figure A are recorded as: .\n\nThe output is a list of \u201ckey points\u201d (red dots in Figure B) in the format of that uniquely defines a skyline. A key point is the left endpoint of a horizontal line segment. Note that the last key point, where the rightmost building ends, is merely used to mark the termination of the skyline, and always has zero height. Also, the ground in between any two adjacent buildings should be considered part of the skyline contour.\n\nFor instance, the skyline in Figure B should be represented as: .\n\nGiven an array of n integer with duplicate number, and a moving window(size k), move the window at each iteration from the start of the array, find the maximum number inside the window at each moving.\n\nHave you met this question in a real interview? Yes\n\n Example\n\n For array [1, 2, 7, 7, 8], moving window size k = 3. return [7, 7, 8]\n\nAt first the window is at the start of the array like this\n\nthen the window move one step forward.\n\nthen the window move one step forward again.\n\nSolution: to use the brute force we need O(nk). IF we further optimize it, we can use heap, the way we sort the k elements takes log(k) instead. If we want to do it in linear time? because this is a sliding window, we only use the maximum of the current window, which makes us to use liner data structure, queue, stack, dequeue. If we try the stack,\n\nso, this is a monotonic queue, each time, when we add the new element, we kick out all the previous smaller elements.\n\nThe python code for the deque is\n\nBFS and DFS, in graph, use visited, or cycle detection, or topological sort with DFS.\n\nGiven an array of meeting time intervals consisting of start and end times (si < ei), find the minimum number of conference rooms required.\n\nSolution: this is typical activity selection problem, which we can be resolved using greedy algorithms which derived from the divide and conquer, then iterative, then greedy.\n\nAt first, sort the start times (nlogn), then go through the intervals one by one O(n), each time we need to find the smallest end time (logn), if it is overlap, then we add another room, otherwise, we merge it. The whole time complexity is O(nlogn) and space complexity is O(n).\n\nGiven a collection of intervals, merge all overlapping intervals.\n\nSolution: different from the last one, we merge the overlap one. if we have [1,3], [3,4], it is merged to be [1,4], so even if s\u2264e_before: it is overlap, then we merge, replace the original by Interval(s_before, max(e_before, e)). We doesnt really need a heapq here"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/math-related-problems-on-leetcode-9537df481fbe?source=user_profile---------7----------------",
        "title": "Math related problems on LeetCode \u2013 Algorithms and Leetcode \u2013",
        "text": "GCD (Greatest Common Divisor) or HCF (Highest Common Factor) of two numbers is the largest number that divides both of them.\n\nBasic Euclidean Algorithm for GCD\n\n The algorithm is based on below facts.\n\nA prime number is a whole number greater than 1, which is only divisible by 1 and itself. First few prime numbers are : 2 3 5 7 11 13 17 19 23 \u2026..\n\nPrime Number Theorem : The probability that a given, randomly chosen number n is prime is inversely proportional to its number of digits, or to the logarithm of n.\n\nHow we check whether a number is Prime or not?\n\nWe can do following optimizations:\n\nAn interesting solution to get all prime numbers smaller than n\n\nWilson theorem says if a number k is prime then ((k-1)! + 1) % k must be 0.\n\nBelow is Python implementation of the approach. Note that the solution works in Python because Python supports large integers by default therefore factorial of large numbers can be computed.\n\nto generate a list of primes. It works by recognizing that all non-prime numbers are divisible by a prime number. An optimization is to only use odd number in the primes list, so that we can save half space and half time. The only difference is we need to do index mapping.\n\nWrite a program to check whether a given number is an ugly number.\n\nUgly numbers are positive numbers whose prime factors only include . For example, are ugly while is not ugly since it includes another prime factor .\n\nSolution: num =2^i3^j5^k, keep divide [2,3,5], if the remainder is==0, or else stop. return False\n\nUgly numbers are positive numbers whose prime factors only include . For example, is the sequence of the first ugly numbers.\n\nNote that is typically treated as an ugly number, and n does not exceed 1690.\n\nTwo solutions: 1. use a list to save all the first 1690 numbers and sort the list. 2. to generate in time, use three pointers, to record the last result to use each pointer.\n\nSuper ugly numbers are positive numbers whose all prime factors are in the given prime list of size . For example, is the sequence of the first 12 super ugly numbers given = of size 4.\n\nNote:\n\n (1) is a super ugly number for any given .\n\n (2) The given numbers in are in ascending order.\n\n (3) 0 < \u2264 100, 0 < \u2264 106, 0 < < 1000.\n\n (4) The nth super ugly number is guaranteed to fit in a 32-bit signed integer.\n\nSolution:the same as the last, except that the primes different\n\nFor an integer n, we call k>=2 a good base of n, if all digits of n base k are 1.\n\nNow given a string representing n, you should return the smallest good base of n in string format.\n\nSolution: For questions like return the smallest, find, we use binary search. we need the base to be [2,n-1], if base we take the smallest, then the size of \u2018111\u2019 should be the biggest, [2, log(num+1,base)+1]. So, we can numerate the size [2, log(num+1,base)+1], and set l=2, r = n-1, start the binary search. If with math background n = 1 + k + k\u00b2 + k\u00b3 + \u2026 + k^(m-1) > k^(m-1) => k < n^(1 / (m-1)), so the base become [2, n^(1 / (m-1))+1].\n\nGiven a grid where each entry is only 0 or 1, find the number of corner rectangles.\n\nA corner rectangle is 4 distinct 1s on the grid that form an axis-aligned rectangle. Note that only the corners need to have the value 1. Also, all four 1s used must be distinct.\n\nSolution: we would have four positions (i,j), (i,j+n),(i+m,j) , (i+m,j+n), then we can form a rectangle. If we use brute force, we need to enumerate i, j and m,n, which is for i in rows, for j in cols, for m in (1,rows-i) for n in (1, cols-j). The complexity is going to be O(m*n*m*n). If we just enumerate the start row and end row, and go through the cols to check if grid[start_row][col]==1 and grid[end_row][col]==1. Then we can find how many cols that we can use to form a rectangle. The combination formulation is C(cnt,2)=cnt*(cnt-1)/2.\n\nThe expression string may contain open and closing parentheses , the plus or minus sign , non-negative integers and empty spaces .\n\nYou may assume that the given expression is always valid.\n\nSolution: use stack to save results inside of the parathese, and use sign to track the sign. stack [previous_Result, the sign]"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/backtracking-e001561b9f28?source=user_profile---------8----------------",
        "title": "Backtracking \u2013 Algorithms and Leetcode \u2013",
        "text": "Another recursive algorithm strategy other than divide and conquer called backtracking. A backtracking algorithm tries to build a solution to a computational problem incrementally. Whenever the algorithm needs to decide between multiple alternatives to the next component of the solution, it simply tries all possible options recursively.\n\nBacktracking is an algorithmic paradigm that tries different solutions until finds a solution that \u201cworks\u201d. Problems which are typically solved using backtracking technique have following property in common. These problems can only be solved by trying every possible configuration and each configuration is tried only once(every node one time). A Naive solution for these problems is to generate all configurations and \u201cpick\u201d a configuration that follows given problem constraints. Backtracking works in incremental way and is an optimization over the Naive solution where all possible(possible still with constraints) configurations are generated and tried.\n\nFrom my understanding, backtracking is similar to the DFS. The difference is when that path does not work, we \u201cbacktrack\u201d the path record, and set it back to the original.\n\nWe see backtracking in problems: Permutation, needed to be used and only be used for one time.\n\nRecursive (DFS and BFS), divide and conquer (divide into subproblems)\n\nGiven a digit string, return all possible letter combinations that the number could represent.\n\nA mapping of digit to letters (just like on the telephone buttons) is given below.\n\nNote:\n\n Although the above answer is in lexicographical order, your answer could be in any order you want.\n\nSolution: this is not exactly backtracking problem, however, we recursively add the next digit to the previous combinations. Time complexity will be O(3^n), which came from O(3+3\u00b2+3\u00b3+\u2026+3^n). The difference is we know it is possible solution, if we keep searching the graph, it works (no constraint)\n\nGiven a set of distinct integers, nums, return all possible subsets (the power set).\n\nNote: The solution set must not contain duplicate subsets.\n\nFor example,\n\n If nums = , a solution is:\n\nSolution: because we dont care about the order, it is a combination (not a permutation). here we just use index+1 to pointer to the beignning of the possible paths. temp refers the curr: to record what we use, but when we return after the recursive call, we need to pop out. and keep adding the next element.\n\nGiven a collection of distinct numbers, return all possible permutations.\n\nFor example,\n\n have the following permutations:\n\nSolution: The permutation is similar as the last power set, the difference is we use each element at least and only one time, and we dont care about the order. So for the remaining elements, it is different.\n\nGiven a collection of numbers that might contain duplicates, return all possible unique permutations.\n\nFor example,\n\n have the following unique permutations:\n\nSolution: The difference with the other permutation is, each time, we only append the unique element to temp.\n\nRemove the minimum number of invalid parentheses in order to make the input string valid. Return all possible results.\n\nNote: The input string may contain letters other than the parentheses and .\n\nSolution: at the beignning, check the number of left parathese and the right parentheses need to be removed. Then use DFS (try all possible ways) with back tracking to get all possible solutions (when l, r decrease to zero, check if it is valid). To be noted: we need to avoid duplicates"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/elegant-coding-style-for-python-5cd07cae9612?source=user_profile---------9----------------",
        "title": "Elegant Coding Style for Python \u2013 Algorithms and Leetcode \u2013",
        "text": "This serves as a note and a summary on my journey to become a coder who writes very elegant python code. Python is very different compared with most of other language; it is not like C/C++, which only has some basic key words support and takes a lot effort to import and integrate with other non-built in libraries. Python has large amount of built-in functions that can ease your coding life and tons of third party libraries which you can easily install with just pip install command and import them in one second. So, there is flexibility.\n\nCurrently, I am studying how to balance the amount of using built-in functions and third party libraries. Which one is better, and which one is more important? I would prefer to know both. But, anyway, this is not my final conclusion, going to learn more and come back to re-conclude.\n\nUsing filter to get rid of irrelevant character which can be used as a pre-processing or used in algorithms. As the name suggests filter extracts each element in the sequence for which the function returns True. The reduce function is a little less obvious in its intent. This function reduces a list to a single value by combining elements via a supplied function. The map function is the simplest one among Python built-ins used for functional programming.\n\nHere is another use case for filter(): finding intersection of two lists:\n\nThe reduce is in the functools in Python 3.0. It is more complex. It accepts an iterator to process, but it\u2019s not an iterator itself. It returns a single result:\n\nAt each step, reduce passes the current product or division, along with the next item from the list, to the passed-in lambda function. By default, the first item in the sequence initialized the starting value.\n\nLet\u2019s make our own version of reduce.\n\nWe can concatenate a list of strings to make a sentence. Using the Dijkstra\u2019s famous quote on bug:\n\nWe can get the same result by using join :\n\nWe can also use operator to produce the same result:\n\nThe built-in reduce also allows an optional third argument placed before the items in the sequence to serve as a default result when the sequence is empty.\n\nPython is known for its powerful general purpose built-in data types like list, dict, tuple and set. But Python also has collection objects like Java and C++. These objects are developed on top of the general built-in containers with additional functionalities which can be used in special scenarios.\n\nThe objective of this article is to introduce python collection objects and explain them with appropriate code snippets. The collections library contains the collections objects, they are namedtuples (v2.6), deque (v2.4), ChainMap(v3.3), Counter(v2.7 ), OrderedDict(v2.7), defaultdict(v2.5) .\n\nA Counter is a container that keeps track of how many times equivalent values are added. It can be used to implement the same algorithms for which bag or multiset data structures are commonly used in other languages.\n\nAn empty Counter can be constructed with no arguments and populated via the update() method.\n\nOnce a Counter is populated, its values can be retrieved using the dictionary API.\n\nCounter does not raise KeyError for unknown items. If a value has not been seen in the input (as with e in this example), its count is 0.\n\nThe elements() method returns an iterator that produces all of the items known to the Counter.\n\nThe order of elements is not guaranteed, and items with counts less than zero are not included.\n\nUse most_common() to produce a sequence of the n most frequently encountered input values and their respective counts.\n\nThis example counts the letters appearing in all of the words in the system dictionary to produce a frequency distribution, then prints the three most common letters. Leaving out the argument to most_common() produces a list of all the items, in order of frequency.\n\nEach time a new Counter is produced through an operation, any items with zero or negative counts are discarded. The count for a is the same in c1 and c2, so subtraction leaves it at zero.\n\nPython Set; Python List; Python list copy: this is very important, especially if we need to copy a two dimensional list or even higher, use deepcopy() from copy module.\n\nA solution to the described problems is to use the module \u201ccopy\u201d. This module provides the method \u201ccopy\u201d, which allows a complete copy of a arbitrary list, i.e. shallow and other lists.\n\nThe following script uses our example above and this method:\n\nIf we want to put string or tuple in set, it should be like this:"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/python-coding-numpy-973955c6d537?source=user_profile---------10----------------",
        "title": "Python Coding \u2014 Numpy \u2013 Algorithms and Leetcode \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/array-problems-on-leetcode-bb892201dd7f?source=user_profile---------12----------------",
        "title": "Array problems on LeetCode \u2013 Algorithms and Leetcode \u2013",
        "text": "Like arrays, Linked List is a linear data structure. Unlike arrays, linked list elements are not stored at contiguous location; the elements are linked using pointers.\n\nWhy Linked List?\n\n Arrays can be used to store linear data of similar types, but arrays have following limitations.\n\n 1) The size of the arrays is fixed: So we must know the upper limit on the number of elements in advance. Also, generally, the allocated memory is equal to the upper limit irrespective of the usage.\n\n 2) Inserting a new element in an array of elements is expensive, because room has to be created for the new elements and to create room existing elements have to shifted.\n\nDrawbacks:\n\n 1) Random access is not allowed. We have to access elements sequentially starting from the first node. So we cannot do binary search with linked lists.\n\n 2) Extra memory space for a pointer is required with each element of the list.\n\nFor Linked List, we can only iterate over elements, for python code example:\n\nHere array means one dimension list. For array problems, math will play an important role here. For this type of question, it is hard to generalize the types, but I will try my best.\n\nFor simple questions, basic math and data structure can solve the problems. For more difficult problems:\n\nT1: If you see in the problem that you can do comparison and it is always one type of satisfactory element is in ahead of the other, this could be resolved by two pointers (slower and faster). Note: when the while loop stops, is there operations you need?\n\nTwo pointers is a superset of the sliding window algorithm, prefix sum too.\n\nT2: Or one starts from the beginning, one from the end and going to the middle (sliding window).\n\nFor the problems that need to sum up subarray, sum(i,j)=sum(0,j)-sum(0,i).\n\nIf we want the sum==k, sum(j,i)=sum(0,i)-sum(0,j) =k, when i=1, j=0. so for the loop, index i-> sum[i+1]. we save prefix sum, at the same time, we check if we can find a sum(0,j) ==sum(0,i)-k, j locates in front of index i, and from j to i would have sum k. For a lot of subarray problems, we just need to differentiate the dict[sum_i]=**.\n\nExamples: 122. Best Time to Buy and Sell Stock II (multiple transaction, accumulate sectional profit), 26, 27, 283. Move Zeroes, 121. Best Time to Buy and Sell Stock (keep track of min_price and max_profit, single pass, one transaction), 88. Merge Sorted Array, 167. Two Sum II \u2014 Input array is sorted(t2), 11. Container With Most Water (t2, move with greedy programming)\n\nWe can use divide and conquer (see the merge sort) and the priority queue.\n\nWithout this we detect cycle with the following code:\n\nTraverse linked list using two pointers. Move one pointer by one and other pointer by two. If these pointers meet at some node then there is a loop. If pointers do not meet then linked list doesn\u2019t have loop. Once you detect a cycle, think about finding the starting point.\n\nIn this section, to get sum we can choose to use hashmap to save the original list so that for the last element, we only check the hashmap, we can lower the complexity by one power of n. However, a better solution is to use two pointers or three pointers. for three pointers, the first one is to make sure the starting point. Also, we can think about divide and conquer.\n\nGiven an array S of n integers, are there elements a, b, c in S such that a + b + c = 0? Find all unique triplets in the array which gives the sum of zero.\n\nNote: The solution set must not contain duplicate triplets.\n\nSolution: Should use three pointers, no extra space. i is the start point from [0,len-2], l,r is the other two pointers. l=i+1, r=len-1 at the beignning. The saving of time complexity is totally from the sorting algorithm.\n\nThe following code uses more time\n\nGiven four lists A, B, C, D of integer values, compute how many tuples there are such that is zero.\n\nTo make problem a bit easier, all A, B, C, D have same length of N where 0 \u2264 N \u2264 500. All integers are in the range of -228 to 228\u20131 and the result is guaranteed to be at most 231\u20131.\n\nSolution: if we use brute force, use 4 for loop, then it is O(N\u2074). If we use divide and conquer, sum the first half, and save a dictionary (counter), time complexity is O(2N\u00b2). What if we have 6 sum, we can reduce it to O(2N\u00b3), what if 8 sum.\n\nIn this section, we have maximum subarray and minimum subarray. For the maximum, we can use math and prefix_sum, for the minimum subarray, we use sliding window solution. For subarray the most important feature is contiguous. Here, we definitely will not use sorting.\n\nFind the contiguous subarray within an array (containing at least one number) which has the largest sum.\n\nFor example, given the array ,\n\n the contiguous subarray has the largest sum = .\n\nSolution: Brute force is to use two for loops, first is the starting, second is the end, then we can get the maximum value. To optimize, we can use divide and conquer, O(nlgn) vs brute force is O(N\u00b2)\n\nGiven an array nums and a target value k, find the maximum length of a subarray that sums to k. If there isn\u2019t one, return 0 instead.\n\nNote:\n\n The sum of the entire nums array is guaranteed to fit within the 32-bit signed integer range.\n\nGiven nums = , k = ,\n\n return . (because the subarray sums to 3 and is the longest)\n\nGiven nums = , k = ,\n\n return . (because the subarray sums to 1 and is the longest)\n\nFollow Up:\n\n Can you do it in O(n) time?\n\nSolution: using prefix_sum and hashmap, to just need to reformulate dict[sum_i]. For this question, we need to get the maximum size of subarray, so dict[i] =min(idx), the earliest that the value appear. which means every time we just set the dict[i]=current_idx,only if the key doesnt exist. dict[0]=-1. Here we have sum_i, to check if there is a j in front of i that makes sum(j,i)=k, sum(j,i)=sum_i-A Value in Dict = k, so the value need to be sum_i-k, so that we need to check if it is in the dictionary.\n\nGiven an array of integers and an integer k, you need to find the total number of continuous subarrays whose sum equals to k.\n\nSolution 3: using prefix_sum and hashmap, to just need to reformulate dict[sum_i]. For this question, we need to get the total number of subsubarray, so dict[i] =count, which means every time we just set the dict[i]+=1. dict[0]=1\n\nGiven a binary array, find the maximum length of a contiguous subarray with equal number of 0 and 1.\n\nNote: The length of the given binary array will not exceed 50,000.\n\nSolution: the problem is similar to the maximum sum of array with sum==0, so 0=-1, 1==1.\n\nGiven an array of n positive integers and a positive integer s, find the minimal length of a contiguous subarray of which the sum \u2265 s. If there isn\u2019t one, return 0 instead.\n\nFor example, given the array and ,\n\n the subarray has the minimal length under the problem constraint.\n\nCredits:\n\nSpecial thanks to @Freezen for adding this problem and creating all test cases.\n\nFor the product: we need to record the min_ending_here, for the max_ending_here, can only be [1, +infinity), min_ending_here (-infinity, 1]\n\nGiven an unsorted array of integers, find the length of longest increasing subsequence (subarray).\n\nNote: Length of the array will not exceed 10,000.\n\nSolution: The brute force solution is use two for loops with O(n\u00b2). The first loop is the start number, the second loop is the nums[j]>nums[j-1] or else stop. Or we can use two pointers. i,j start from 0,1 respectively.\n\nGiven an unsorted array of integers, find the length of longest increasing subsequence.\n\nFor example,\n\n Given ,\n\n The longest increasing subsequence is , therefore the length is . Note that there may be more than one LIS combination, it is only necessary for you to return the length.\n\nYour algorithm should run in O(n^2) complexity.\n\nFollow up: Could you improve it to O(n log n) time complexity?\n\nSolution: Compared with the last question, this one loose the restriction that need to be continuous. For this problem, we need to understand it is not going to work with two for loops. It is not a brute-force O(n\u00b2) problem. It is a typical combination problem in recursive functions. So, at first, put the standard combination algorithm code here:\n\nSo, we use the backtracking \u2014 combination to enumerate all possible subsequence. The difference is here we do not unconditionally use this nums[i] in our result, only if nums[i]>tail, and the final length is the maximum of them all. T(n) = max(T(n-1)+1, T(n-k)+1, \u2026). So, the time complexity is O(2^n). It passed 21/15 test cases with TLE. In this process, we transfer from the combination problem to dynamic programming.\n\nNow, we know we are doing dynamic programming, if we already know the ans(idx), meaning the max length from somewhere, we do not need to do it again. With memoization: The time complexity is n subproblem, top-down recursive+memo.\n\nNow, we use dp and bottom-up iterative. For [10,9,2,5,3], the length array is [1,1,1,2,2], for [4,10,4,3,8,9], we have [1, 2, 1, 1, 2, 3]. To find the rule, T(0)=1, idx, max(memo[i]),0\u2264i<idx, nums[idx]>nums[i]. Now the time complexity is O(n\u00b2).\n\nstate: f[i] record the maximum length of increasing subsequence from 0-i.\n\nfunction: f[i]: choose or not to choose\n\nWe can even speedup further by using binary search, the second loop we can use a binary search to make the time complexity O(logn), and the dp array used to save the maximum ans. Each time we use binary search to find an insertion point, if it is at the end, then the length grow.\n\nGiven an unsorted array of integers, find the number of longest increasing subsequence.\n\nNote: Length of the given array will be not exceed 2000 and the answer is guaranteed to be fit in 32-bit signed int.\n\nSolution: Another different problem, to count the number of the max subsequence. Typical dp:\n\nUsing dynamic programming, the difference is we add a count array.\n\nGiven an unsorted array of integers, find the length of the longest consecutive elements sequence.\n\nFor example,\n\n Given ,\n\n The longest consecutive elements sequence is . Return its length: .\n\nYour algorithm should run in O(n) complexity.\n\nSolution: Not thinking about the O(n) complexity, we can use sorting to get [1,2,3,4,100,200], and then use two pointers to get [1,2,3,4].\n\nHow about O(n)? We can pop out a number in the list, example, , then we use while first-1 to get any number that is on the left side of 4, here it is 3, 2, 1, and use another to find all the bigger one and remove these numbers from the nums array.\n\nWe define a harmonious array is an array where the difference between its maximum value and its minimum value is exactly 1.\n\nNow, given an integer array, you need to find the length of its longest harmonious subsequence among all its possible subsequences.\n\nNote: The length of the input array will not exceed 20,000.\n\nSolution: at first, use a Counter to save the whole set. Then visit the counter dictionary, to check key+1 and key-1, only when the item is not zero, we can count it as validate, or else it is 0.\n\nGiven a group of two strings, you need to find the longest uncommon subsequence of this group of two strings. The longest uncommon subsequence is defined as the longest subsequence of one of these strings and this subsequence should not be any subsequence of the other strings.\n\nA subsequence is a sequence that can be derived from one sequence by deleting some characters without changing the order of the remaining elements. Trivially, any string is a subsequence of itself and an empty string is a subsequence of any string.\n\nThe input will be two strings, and the output needs to be the length of the longest uncommon subsequence. If the longest uncommon subsequence doesn\u2019t exist, return -1.\n\nSolution: if we get more examples, we could found the following rules, \u201caba\u201d,\u201daba\u201d return -1,\n\nGiven a string that consists of only uppercase English letters, you can replace any letter in the string with another letter at most k times. Find the length of a longest substring containing all repeating letters you can get after performing the above operations.\n\nNote:\n\n Both the string\u2019s length and k will not exceed 104.\n\nSolution: the brute-force recursive solution for this, is try to replace any char into another when it is not equal or choose not too. LTE\n\nTo get the BCR, think about the sliding window. The longest repeating string we can by number of replacement = `length of string \u2014 max(numer of occurence of letter i), i=\u2019A\u2019 to \u2018Z\u2019. With the constraint, which means the equation needs to be \u2264 k. So we can use sliding window to record the max occurence, and when the constraint is violated, we shrink the window. Given an example, strs= \u201cBBCABBBAB\u201d, k=2, when i=0, and j=7, 8\u20135=3>2, which is at A, we need to shrink it, the maxCharCount changed to 4, i=1, so that 8\u20131\u20134=3, i=2, 8\u20132\u20133=3, 8\u20133\u20133=2, so i=3, current length is 5.\n\n395. Longest Substring with At Least K Repeating Characters\n\nFind the length of the longest substring T of a given string (consists of lowercase letters only) such that every character in T appears no less than k times.\n\nSolution: use dynamic programming with memo: Cons: it takes too much space, and with LTE.\n\nNow, use sliding window, we use a pointer mid, what start from 0, if the whole string satisfy the condition, return len(s). Otherwise, use two while loop to separate the string into three substrings: left, mid, right. left satisfy, mid unsatisfy, right unknown.\n\nGiven a list of strings representing an English Dictionary, find the longest word in that can be built one character at a time by other words in . If there is more than one possible answer, return the longest word with the smallest lexicographical order.\n\nIf there is no answer, return the empty string.\n\nSolution: Sort the words and then save a set of it to check the parent of it.\n\nRecursive (DFS and BFS), divide and conquer (divide into subproblems)\n\nSolution: For this combination, we can use each element one to all possible number of times. We recursively try call possible. The set is like a graph, at the beiginning, we start from 2, the next 3,6,7 are adjacent. Then for 3, nodes 6,7 are its possible next steps. T(n) =kT(n-1)\n\nGiven a non-empty array containing only positive integers, find if the array can be partitioned into two subsets such that the sum of elements in both subsets is equal.\n\nSolution, for this problem we just need to find see if any of the subproblems return true. So, it is important to use any()\n\nSolution 1: we have k groups, each time we try to deal with one element from nums, see which group we should put them inside. Then we try to put them in any group that might fit in. Time Complexity: O(kN\u2212kk!)O(k^{N-k} k!)O(k\u200bN\u2212k\u200b\u200bk!), where NNN is the length of , and kkk is as given. As we skip additional zeroes in , naively we will make O(k!)O(k!)O(k!) calls to , then an additional O(kN\u2212k)O(k^{N-k})O(k\u200bN\u2212k\u200b\u200b) calls after every element of is nonzero. Space Complexity: O(N)O(N)O(N), the space used by recursive calls to in our call stack. More solutions.\n\nBrute force is to get all the element values in a list, sort it and build a LinkedList. Others could be divide and conquer. O(nlogk)\n\nPython Set; Python List; Python list copy: this is very important, especially if we need to copy a two dimensional list or even higher, use deepcopy() from copy module.\n\nGiven a string S, we can transform every letter individually to be lowercase or uppercase to create another string. Return a list of all possible strings we could create."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/note-for-divide-and-conquer-algorithms-c8bcffcd4440?source=user_profile---------13----------------",
        "title": "Solve Problems on LeetCode using Divide and Conquer, Dynamic Programming, and Backtracking",
        "text": "Now, finally understood the difference of these three. Let use see how they are applied to different types of questions.\n\nT(n) = op(T(left),T(right)), where op usually starts after we get the return result from T(left), T(right). op means the operation we need to \u201cmerge\u201d the result, if the cost for this merge operation is f(n). For this type of divide and conquer, most time, it has smaller running time complexity compared with the brute-force.\n\nNote: get more examples to testify if this actually work.\n\nThe example is merge sort (T(n) = 2T(n/2)+n for merge the return), maximum subarray,\n\nFind the contiguous subarray within an array (containing at least one number) which has the largest sum.\n\nFor example, given the array ,\n\n the contiguous subarray has the largest sum = .\n\nT(n)= T(n/2)+O(1), the complexity is the same as the binary search, O(logn).\n\nIf we use brute force is O(2^n). Use divide and conquer, here because we use half and half, so memo is useless.\n\nGiven two arrays of length and with digits representing two numbers. Create the maximum number of length from digits of the two. The relative order of the digits from the same array must be preserved. Return an array of the digits. You should try to optimize your time and space complexity.\n\nSolution: First use DP + memo: LTE, 70/120 passed. We should use greedy and solve each array to find i,j, i+j = k, then we combine them.\n\n121. Best Time to Buy and Sell Stock\n\nSay you have an array for which the ith element is the price of a given stock on day i.\n\nIf you were only permitted to complete at most one transaction (ie, buy one and sell one share of the stock), design an algorithm to find the maximum profit.\n\nSolution: Step 1: convert it to the maximum subarray problem. The first example is, [7\u20137=0,1\u20137=-6,5\u20131=4,3\u20135=-2,6\u20133=3, 4\u20136=-2],set the first element to 0, then the second is nums[i]-[nums[i-1], [0,-6,4,-2,3,-2] =>[0+6, 6\u20136=0, 0+4=4, 4\u20132=2, ] Set the first to 0+6, nums[i-1]+nums[i].\n\nr = max(left_subarray, right_subarry, max(right_subarry)-min(left_subarray)), Thus, the real operation is max(right_subarry)-min(left_subarray). The time complexity would be decreased to O(nlgn) from the brute force(n\u00b2). So this example shows the divide and conquer. However, it might not be the best solution. Try the BCR with O(n).\n\nFor this type of divide and conquer, it is more common for problems that hard to resolve with other non DP or recursive methods. For this type of problems, if we did not use the memorization to save us from computing subproblems repeatly, we might end up with the same time complexity compared with the brute-force.\n\nYou are climbing a stair case. It takes n steps to reach to the top.\n\nEach time you can either climb 1 or 2 steps. In how many distinct ways can you climb to the top?\n\nNote: Given n will be a positive integer.\n\nSolution: if we enumerate the number of ways to climb for each n, we can find out that this is a fibonacci number T(n)=T(n-1)+T(n-2)\n\nGiven a string of numbers and operators, return all possible results from computing all the different possible ways to group numbers and operators. The valid operators are , and .\n\nSolution: to add a parenthese is the same as splitting there. T(n)=T(1)+T(n-1)+T(2)+T(n-2)+\u2026+: T(n)=T(0,i-1)optT(i+1,n) (i=[1,n])\n\nImplement regular expression matching with support for and .\n\nSolution: it is important to understand that if .* means we can match any preceding elements from len 0 to any. c* means we can match zero or more c. My solution is to reverse the string, and with memorization, the running became half of it.\n\nGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, determine if s can be segmented into a space-separated sequence of one or more dictionary words. You may assume the dictionary does not contain duplicate words.\n\nReturn true because can be segmented as .\n\nSolution: T(n) = T(n-1)+T(n-2)+\u2026+T(1)+O(n). Without memoriazation, it is O(2^n). With it, then the time complexity is the same as the subproblems, which means the size of the memo. O(n\u00b2).\n\nGiven a non-empty string s and a dictionary wordDict containing a list of non-empty words, add spaces in s to construct a sentence where each word is a valid dictionary word. You may assume the dictionary does not contain duplicate words.\n\nReturn all such possible sentences.\n\nSolution: the difference compared with the first one is we need to find all possible solutions, compared with (any). And we need to record the results. split into \u2018cat\u2019+dp(sanddog), because the return of dp could be [\u2018sand dog\u2019, \u2018s and dog\u2019 ] if s is in dictionary, so that we need to connect the result and return.\n\nThe space complexity is the height of the tree\n\nIn a recursion tree, each node represents the cost of a single subproblem somewhere in the set of resursive function invocations. We sum the costs within each level of the tree to obtain a set of per-level costs, and then we sum all the per-level costs to determine the total cost of all levels of the recursion.\n\nThe master method provides a \u201ccookbook\u201d method for solving recurrences of the form:\n\nwhere a\u22651 and b>1 are constants and f(n) is an asymptotically positive function. It describes the running time of an algorithms that divides a problem of size n into a subprolems, each of since n/b"
    },
    {
        "url": "https://medium.com/@lisulimowicz/notes-for-image-synthesis-38398c4c50b7?source=user_profile---------14----------------",
        "title": "Notes for Image Synthesis and Editing \u2013 Li Yin Sulimowicz \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/computer-vision-application-dc8412d9d392?source=user_profile---------15----------------",
        "title": "Computer Vision Application \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "All categories are benefiting from deep learning. And deep learning is continuingly creating beyond of imagination applications.\n\nImage classification, object detection, semantic segmentation, instance segmentation. For this categories, mostly the non-GANs network.\n\nPersonally I think image denosing can benefit from super-resolution.\n\nSome of the following content come from https://machinelearningmastery.com/inspirational-applications-deep-learning/\n\nImage colorization is the problem of adding color to black and white photographs.\n\nTraditionally this was done by hand with human effort because it is such a difficult task.\n\nDeep learning can be used to use the objects and their context within the photograph to color the image, much like a human operator might approach the problem.\n\nThis capability leverages of the high quality and very large convolutional neural networks trained for ImageNet and co-opted for the problem of image colorization.\n\nGenerally the approach involves the use of very large convolutional neural networks and supervised layers that recreate the image with the addition of color.\n\nColorization of Black and White Photographs\n\nImage taken from Richard Zhang, Phillip Isola and Alexei A. Efros.\n\nImpressively, the same approach can be used to colorize still frames of black and white movies\n\nThis is a task where given a corpus of handwriting examples, generate new handwriting for a given word or phrase.\n\nThe handwriting is provided as a sequence of coordinates used by a pen when the handwriting samples were created. From this corpus the relationship between the pen movement and the letters is learned and new examples can be generated ad hoc.\n\nWhat is fascinating is that different styles can be learned and then mimicked. I would love to see this work combined with some forensic hand writing analysis expertise.\n\nThis is an interesting task, where a corpus of text is learned and from this model new text is generated, word-by-word or character-by-character.\n\nThe model is capable of learning how to spell, punctuate, form sentiences and even capture the style of the text in the corpus.\n\nLarge recurrent neural networks are used to learn the relationship between items in the sequences of input strings and then generate text. More recently LSTM recurrent neural networks are demonstrating great success on this problem using a character-based model, generating one character at time.\n\nAndrej Karpathy provides many examples in his popular blog post on the topic including:\n\nAutomatic Text Generation Example of Shakespeare\n\nExample taken from Andrej Karpathy blog post\n\nAutomatic image captioning is the task where given an image the system must generate a caption that describes the contents of the image.\n\nIn 2014, there were an explosion of deep learning algorithms achieving very impressive results on this problem, leveraging the work from top models for object classification and object detection in photographs.\n\nOnce you can detect objects in photographs and generate labels for those objects, you can see that the next step is to turn those labels into a coherent sentence description.\n\nThis is one of those results that knocked my socks off and still does. Very impressive indeed.\n\nGenerally, the systems involve the use of very large convolutional neural networks for the object detection in the photographs and then a recurrent neural network like an LSTM to turn the labels into a coherent sentence.\n\nThese techniques have also been expanded to automatically caption video.\n\nThis is a task where a model learns how to play a computer game based only on the pixels on the screen.\n\nThis very difficult task is the domain of deep reinforcement models and is the breakthrough that DeepMind (now part of google) is renown for achieving.\n\nThis work was expanded and culminated in Google DeepMind\u2019s AlphaGo that beat the world master at the game Go.\n\nBut some algorithms excel humans. For example, could you tell his pulse rate, by looking at these images only?\n\nBut magnifying subtle changes in color [5] reveals his blood flow:\n\nThat is impressive to me! http://people.csail.mit.edu/mrub..."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/solving-matrix-graph-problems-on-leetcode-using-python-48d27fd74548?source=user_profile---------16----------------",
        "title": "Solving Matrix/Graph Problems on LeetCode using Python",
        "text": "There are cities connected by flights. Each fight starts from city and arrives at with a price .\n\nNow given all the cities and fights, together with starting city and the destination , your task is to find the cheapest price from to with up to stops. If there is no such route, output .\n\nMatrix can be expanded to a graph related problem. The steps are:\n\nAccording to this order, the above example is resolved with the following python code:\n\nAnother example focusing about python code: 399. Evaluate Division\n\nAdjacency list: [[1,2,3],[3,1],[4,6,1]], node 0 connects to 1,2,3, node 1 connect to 3,1, node 2 connects to 4,6,1\n\nIf you need a \u201cname\u201d for each node, and before the graph is complete, you do not know how many nodes you might get, use dictionary, for example, we are given a list of edges[[\u201ca\u201d,\u201dc\u201d],[b,c],[b,e]\u2026.]\n\nIf we need weights for each edge, use dictionary from the default dictionary to represent:\n\nFunction to generate the list of all edges:\n\nOr we use the library Queue:\n\nExample of how to wait for enqueued tasks to be completed:\n\nTopological Sorting vs Depth First Traversal (DFS):\n\n In DFS, we print a vertex and then recursively call DFS for its adjacent vertices. In topological sorting, we need to print a vertex before its adjacent vertices. For example, in the given graph, the vertex \u20185\u2019 should be printed before vertex \u20180\u2019, but unlike DFS, the vertex \u20184\u2019 should also be printed before vertex \u20180\u2019. So Topological sorting is different from DFS. For example, a DFS of the shown graph is \u201c5 2 3 1 0 4\u201d, but it is not a topological sorting\n\nIn DFS, we start from a vertex, we first print it and then recursively call DFS for its adjacent vertices. In topological sorting, we use a temporary stack. We don\u2019t print the vertex immediately, we first recursively call topological sorting for all its adjacent vertices, then push it to a stack. Finally, print contents of stack. Note that a vertex is pushed to stack only when all of its adjacent vertices (and their adjacent vertices and so on) are already in stack.\n\nIn some cases, we need to detect cycles:\n\nEquations are given in the format , where and are variables represented as strings, and is a real number (floating point number). Given some queries, return the answers. If the answer does not exist, return .\n\nThe input is: , where , and the values are positive. This represents the equations. Return .\n\nAccording to the example above:\n\nSolution: first to convert it into a graph, this is a path search, then do a DFS to find solution for this. Time complexity is O(k*(V+E)), k is the total number of queries, space complexity is O(V+E).\n\nGiven a matrix of m x n elements (m rows, n columns), return all elements of the matrix in spiral order.\n\nFor example,\n\n Given the following matrix:\n\nThere are a total of n courses you have to take, labeled from to .\n\nSome courses may have prerequisites, for example to take course 0 you have to first take course 1, which is expressed as a pair:\n\nGiven the total number of courses and a list of prerequisite pairs, is it possible for you to finish all courses?\n\nThere are a total of 2 courses to take. To take course 1 you should have finished course 0. So it is possible.\n\nThere are a total of 2 courses to take. To take course 1 you should have finished course 0, and to take course 0 you should also have finished course 1. So it is impossible.\n\nSolution: This is a cycle detect algorithm, also used topological sort, if we need to get the result.\n\nGiven a list of airline tickets represented by pairs of departure and arrival airports , reconstruct the itinerary in order. All of the tickets belong to a man who departs from . Thus, the itinerary must begin with .\n\nExample 2:\n\n = \n\n Return .\n\n Another possible reconstruction is . But it is larger in lexical order.\n\nSolution: for this one, we use DFS with backtracking. We add the current in the route, we remove the element from the adjacency list, if we found an itinerary that used all of the tickets, then we return True. If the recursive call failed, we recover the route and the ticket to try the next possible step.\n\nHere you will learn about difference between BFS and DFS algorithm or BFS vs. DFS.\n\nBreadth First Search (BFS) and Depth First Search (DFS) are two popular algorithms to search an element in Graph or to find whether a node can be reachable from root node in Graph or not. And these are popular traversing methods also.\n\nWhen we apply these algorithms on a Graph, we can see following types of nodes.\n\nS. No. Breadth First Search (BFS) Depth First Search (DFS)\n\nNeed to cover more graph related algorithms"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/solve-string-problems-on-leetcode-ce868728efa4?source=user_profile---------17----------------",
        "title": "Solve String Problems on LeetCode \u2013 Algorithms and Leetcode \u2013",
        "text": "(a) Knuth Morris Pratt ( Exact Pattern Matching ): The KMP matching algorithm uses degenerating property (pattern having same sub-patterns appearing more than once in the pattern) of the pattern and improves the worst case complexity to O(n). The basic idea behind KMP\u2019s algorithm is: whenever we detect a mismatch (after some matches), we already know some of the characters in the text of next window. We take advantage of this information to avoid matching the characters that we know will anyway match. Let us consider below example to understand this. The core is to find the failure lookup table. The lookup table saves the prefix is the same as the suffix.\n\nThe difference of brute force and KMP is, when the matching failed, KMP would keep the i in the string in the same position(brute force, go back i-j+1). The j pointer in the pattern would not go back to start position 0, and it goes to next[j]\n\nThe problems can be generalized to find pattern in a string, you would be given two strings. (1) If we do not care the order of the letters in the pattern, then it is the best to use Sliding Window; (2) If we care the order matters (identical to pattern), we use KMP.\n\nThe first type is to do operations that meet certain requirements on a single string. Including palindrome ( sequence of characters read the same forward and backward), anagram ( An anagram is a word or phrase formed by rearranging the letters of a different word or phrase), valid number (difficult with a of of cases to consider), Valid Parentheses\n\n(b) Rabin-Karp algorithm(Exact or anagram Pattern Matching): used to find the exact pattern, because different anagram of string would have different hash value.\n\n(c) Sliding window algorithm(Exact or anagram Pattern Matching): used to find any anagram of the pattern inside the string. Here is a summary that sliding window algorithm can solve pretty much all the string pattern matching problems.\n\n(d) longest common substring: Suppose we have string A and B, each with m and n chars. If we use brute force, then in A, there could be M\u00b2 substring, and to locate these substring in B, we spend O(n) for each substring, which makes the total complexity to be O(n*M\u00b2). Note: it is the same if its two arrays\n\nBut now, if we use the LCS method, the time and space complexity will be O(n*m) . LCS is DP method that we can use bottom-up with memorization.\n\nUsing filter to get rid of irrelevant character.\n\nGiven a string, determine if it is a palindrome, considering only alphanumeric characters and ignoring cases.\n\nFor example,\n\n is a palindrome.\n\n is not a palindrome.\n\nNote:\n\n Have you consider that the string might be empty? This is a good question to ask during an interview.\n\nFor the purpose of this problem, we define empty string as valid palindrome.\n\nGiven a non-empty string , you may delete at most one character. Judge whether you can make it a palindrome.\n\nSolution: use two pointers, one in the front, one at the end, if s[i]!=s[j], then we check if s[i+1:j] or s[i:j-1] is a palindrome or not.\n\nGiven a string S, you are allowed to convert it to a palindrome by adding characters in front of it. Find and return the shortest palindrome you can find by performing this transformation.\n\nSolution: reform the problem to be s+\u2019#\u2019+s[::-1], we find the longest prefex sufrex table, result = s[::-1][len(s)-lps[-1]]+s\n\nGiven a string which consists of lowercase or uppercase letters, find the length of the longest palindromes that can be built with those letters.\n\nThis is case sensitive, for example is not considered a palindrome here.\n\nNote:\n\n Assume the length of given string will not exceed 1,010.\n\nSolution: we can take maximum one single string in the middle, the others need to be even.\n\nThe following counting palindrome we can use DP+iterative.\n\nGiven a string, your task is to count how many palindromic substrings in this string.\n\nThe substrings with different start indexes or end indexes are counted as different substrings even they consist of same characters.\n\nSolution: O(N\u00b2). We search for each position, expand the odd length and the even length to see if it is a palindrome. For example, aaa, for i =0\u20132: i=0, a(odd, l==r=0), aa(r=l+1), i=1, a, aaa, aa, i=2, a, so totally 6.\n\nGiven a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.\n\nSolution: we can either use dp or the greedy expansion:\n\nWhen we use dp, we have dp[i,j], if i==j or abs(i-j)==1, then dp[i,j]==(s[i]==s[j]), if the distance is three, id depends on the value of dp[i+1,j-1]\n\nTo program iteratvely, i need to from big to small, j neeed to from small to big\n\nIf we want to put string in set, it should be like this:"
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/solving-tree-problems-on-leetcode-d0b7a9b4a7a4?source=user_profile---------18----------------",
        "title": "Solving Tree Problems on LeetCode \u2013 Algorithms and Leetcode \u2013",
        "text": "Part of this great node comes from blog:\n\nTo make it easier to understand, the queue has a target, then we assign it to two workers A and B to collect the result from left subtree and the right subtree, which we get A=[2,4,5], B=[3]. Then the final result = the result of the queue + left + right = [1,2,4,5,3].\n\nFor this way, because traverse is a DFS method, which makes us think about using stack to save the result. Note: because the stack is FILO, if we want to visit left subtree at first, we need to push the right subtree at first. This iterative implementation is better than the recursive version, because the memory we use here is the heap memory = memory size. While for the recursive version, it uses the stack memory = processing memory, so it is easier to run out of memory.\n\nIn this section I will include examples to illustrate how to use traverse and what does it mean with divide and conquer.\n\nSolution: the conventional way is to use the preorder, it is DFS, so that we need to use a global variable to save the maximum height. However, it is a lot easier to use divide and conquer to do it, we get the left and right height, then we use max(left,right)+1 to combine the result. Also, we can use BFS level-by-level to traverse and get the maximum height of the last level.\n\nWe just need to see the difference of the height of left subtree and the right subree>1: return False. return (True, 0) for the base case.\n\nGiven a binary tree, find the subtree with minimum sum. Return the root of the subtree.\n\nLintCode will print the subtree which root is your return node.\n\nSolution: we need to get the value of the whole tree, = helper(left)+helper(right)+current val. It\u2019s guaranteed that there is only one subtree with minimum sum and the given binary tree is not an empty tree.\n\nHowever, if we have negative value, this is not going to work\n\nSolution: this one is slightly different, for each node, we can return the sum of current node +left subtree, or current node+ right subtree, or we just return current node, which means the path ends here.\n\nFor the divide and conquer\uff1a\n\n2.Divide\uff1adivide the tree into the result of the left subtree and right subtree\n\n3.Conquer\uff1amerge the result from the divide.\n\nSolution: The difference compared with before is the result is not the current value plus either the left, or the right, or 0, it is the maximum sum of these (except for the current node, the left, the right we only add if it is larger than 0), which equals to max(val, val+left, val+right,left+val+right,val). Also, in this process, we need a global variable to save the maximum value.\n\nGiven preorder and inorder traversal of a tree, construct the binary tree.\n\nNote:\n\n You may assume that duplicates do not exist in the tree.\n\nFor example, given\n\nSolution: we use divide and conquer, first find the current node as the first node in preorder, and then cut the inorder into two halves beside the current node. According to the result to separate the preorder into two halves.\n\nHowever, the previous code has problem as 203 / 203 test cases passed.\n\nStatus: Memory Limit Exceeded. So instead of passing new array, I use index.\n\nIf we spent O(n) to convert T(n) to 2T(n/2)\n\n=nlogn (the same as merge sort)\n\nIf it is O(1)\n\nF1: For a BST, the left subtree are all smaller than the current node, and the right subtree are all bigger than the current node. This concept is useful in trimming BST, see example,669. Trim a Binary Search Tree.\n\nFor this type of trees, the most common way is to do it recursively with BFS or DFS. Or sometimes, if we just need to find an element, we can use WHILE to do it iteratively."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/notes-for-image-denoise-346718b2fce8?source=user_profile---------20----------------",
        "title": "Notes for Image Denoise \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "The most investigated domain in denoising using Wavelet Transform is the non-linear coefficient thresholding based methods. The procedure exploits sparsity property of the wavelet transform and the fact that the Wavelet Transform maps white noise in the signal domain to white noise in the transform domain. Thus, while signal energy becomes more concentrated into fewer coefficients in the transform domain, noise energy does not. It is this important principle that enables the separation of signal from noise.\n\nPerformance of denoising algorithms is measured using quantitative performance measures such as peak signal-to-noise ratio (PSNR), signal-to-noise ratio (SNR) as well as in terms of visual quality of the images. Many of the current techniques assume the noise model to be Gaussian. In reality, this assumption may not always hold true due to the varied nature and sources of noise."
    },
    {
        "url": "https://medium.com/@lisulimowicz/graph-cut-in-map-inference-72959ad016e7?source=user_profile---------21----------------",
        "title": "Graph-cut in MAP inference \u2013 Li Yin Sulimowicz \u2013",
        "text": "Min-cut which is equivalently a max-flow problem can be transferred to the energy minimization of MAP inference for submodular pairwise MRF.\n\nWhen it is not binary, then we need to use alpha-expansion or alpha-beta swap."
    },
    {
        "url": "https://medium.com/probabilistic-graphical-models/mean-field-densecrf-86adce433c02?source=user_profile---------22----------------",
        "title": "Mean-field DenseCRF \u2013 Probabilistic Graphical Models \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@lisulimowicz/higher-order-crfs-59767d1fa302?source=user_profile---------23----------------",
        "title": "Higher order CRFs \u2013 Li Yin Sulimowicz \u2013",
        "text": "The problem of inferring the most probable solution of a higher order CRF is equivalent to minimizing an energy function. In general, the energy minimization problem is NP-hard.\n\nHowever, there exist classes of functions which can be solved exactly in polynomial time. Two well known classes of tractable functions are: submodular functions, and functions defined over graphs with bounded tree width. However, most energies encountered in practical problems do not belong to these families. They are instead solved using algorithms for approximate energy minimization. These algorithms can be divided into two broad categories: messing passing algorithms such as belief propagation and its variants, and move making algorithms such as the graph cut based alpha-expansion and alpha beta-swap. Message passing algorithms have been shown to produce excellent results for many energy functions. However, their runtime complexity increases exponentially with the size of the largest clique in the random field, making them inapplicable to functions defined over large cliques. Efficient graph cut based alpha expansion and a-beta-swap move algorithms have been successfully used to minimize energy functions composed of pairwise potential functions. This paper shows how they applied these algorithms to a large and useful class of higher order energy functions.\n\nThe following survey paper gives a good summarization:\n\n[1] Kohli, Pushmeet, and Philip HS Torr. \u201cRobust higher order potentials for enforcing label consistency.\u201d International Journal of Computer Vision 82.3 (2009): 302\u2013324."
    },
    {
        "url": "https://medium.com/algorithms-and-leetcode/want-to-crack-leetcode-problems-easily-dc825e27e423?source=user_profile---------24----------------",
        "title": "Want to Crack Leetcode Problems Easily? \u2013 Algorithms and Leetcode \u2013",
        "text": "Till right now, I have only mastered four types of problems: DFS, BFS, string. Thanks to sourabreddy\u2019s medium post about these types of problems, they have become so much easier. Please check his website for these types of questions. Like he said, geeksforgeeks have very good and easy understanding tutorials about basic algorithms.\n\nThe steps to crack these problems. (1) The first and foremost is to be patient, to understand the question well. (2) Then, analyze a toy example, figure out how would you solve this problem without programming, what type of knowledge or tactics you have used (math, the algorithms you have mastered before), what is the logic behind this. Make sure to put all the possible situations in the example (From simple to more complex).(3) After the main problem is resolved, think about special cases, twit your pseudo-code a little to solve the special cases. (4) To convert this thinking process to coding should be an easy step.\n\nNote: DFS can be used to:\n\nNote: Understanding the application situation of each basic algorithm is the key step to figure out which algorithm to use in order to solve a problem you met.\n\nBased on the above tutorials, for String categories, it missed the type of two strings:\n\nFind common sub strings (longest) between two string. Using longest common substring DP. Note: it is the same if its two arrays\n\nSuppose we have string A and B, each with m and n chars. If we use bruteforce, then in A, there could be M\u00b2 substring, and to locate these substring in B, we spend O(n) for each substring, which makes the total complexity to be O(n*M\u00b2).\n\nBut now, if we use the LCS method, the time and space complexity will be O(n*m) . LCS is DP method that we can use bottom-up with memorization.\n\nFor array problems, math will play an important role here. For simple questions, basic math and data structure can solve the problems."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/graph-based-computer-vision-algorithm-e2df06a2fe66?source=user_profile---------25----------------",
        "title": "Graph-based Computer Vision Algorithm \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "In computer vision, an image is usually modeled as a graph wherein each pixel or superpixel is a vertex and each vertex is connected to other defined neighbors (the most commonly is 4, up, down, left, right, there is also fully connected). Based on different tasks, it can be formulated as either energy minimization problem (with coarse-to-fine converging method or graph-cut in unsupervised image segmentation task) or as a probabilistic graphical models (which maximize the probability ). And, these two types could finally come to one problem: optimization problem.\n\nIntroduction of the graph and energy minimization.\n\nA survey of graph models in image segmentation. https://www.cs.cornell.edu/~rdz/Papers/FZ-survey.pdf. and http://www4.comp.polyu.edu.hk/~cslzhang/paper/PR_2012_review.pdf."
    },
    {
        "url": "https://medium.com/probabilistic-graphical-models/likelihood-weighting-fe9b39d76b81?source=user_profile---------26----------------",
        "title": "Likelihood Weighting \u2013 Probabilistic Graphical Models \u2013",
        "text": "(Currently it is just a simple note). LW is used to compute the posterior distribution, it is more like a sampling method based on evidence to cut down the computational complexity compared with of Gibbs Sampling. The following content includes one LW example from http://www.eng.utah.edu/~mccully/cs5300lw/.\n\nThe purpose of this webpage is to provide a detailed example of likelihood weighting. Prepared by Duane A. McCully, University of Utah, Spring 2009.\n\nA simple description of the likelihood-weighting algorithm described on page 515 (Figure 14.14) is as follows:\n\nAt the time that the network is sampled, the state of some nodes will be known and others will not. The nodes whose values are known are referred to as evidence variables. So, given the evidence, we need to query the remaining nodes to determine the state of the entire network. When this is complete a likelihood weight is assigned to this sample by multiplying together the probabilities of each evidence variable given its parents. This result is stored in a map, that we will name W, that associates all of the variables in the network with its weight. In slightly more detail:\n\n7. After the entire network is examined for this sample, we will be left with x and w, representing the state of the network and the likelihood weight to be associated to that state, respectively. This is added to W using x as the key and w as the data value. If x already exists in W, then w is added to the data value associated to x in W.\n\nWe will now generate a set of samples for the above Alarm network:\n\nFor this example, the weighted sample is Burglary=false, Earthquake=false, Alarm=false, JohnCalls=false, MaryCalls=false with a weight of 0.997. Now the book speaks of \u201cW, a vector of weighted counts over X.\u201d So pursuant to this terminology, we think of a map in C++ whose key is the tuple (~b,~e,a,j,m) and whose mapped value is the weight. Or, in python, a dict() object. Any weight that is computed through the above algorithm is added to any existing weight that matches the key in W. Since this is our first sample, there is no such key in W so the existing weight is effectively zero. Here is what W looks like so far (the sample column is for our referencing convenience): W SampleKeyWeight 1~b~e~a~j~m0.997\n\nBased on the above we now add (~b,~e,~a,j,~m) to W with a weight of 0.05: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.05\n\nBased on the above we now add (~b,~e,a,j,m) to W with a weight of 0.63: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.05 3~b~eajm0.63\n\nBased on the above we now add (~b,~e,~a,j,~m) to W with a weight of 0.05. However, note that (~b,~e,~a,j,~m) matches the key for sample 2. Therefore, the weight of 0.05 is added to the existing weight of 0.05 giving 0.10: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.10 3~b~eajm0.63\n\nBased on the above we now add (b,~e,~a,~j,~m) to W with a weight of 0.001. W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.10 3~b~eajm0.63 4b~e~a~j~m0.001\n\nWe will now use the sampling data collected above to compute some probabilities.\n\nArtificial Intelligence \u2014 A Modern Approach\n\n Second Edition\n\n Stuart J. Russel and Peter Norvig\n\n Prentice Hall, Pearson Education, Inc., NJ\n\n 2003\n\n ISBN 0\u201313\u2013790395\u20132"
    },
    {
        "url": "https://medium.com/@lisulimowicz/likelihood-weighting-586c774f0e80?source=user_profile---------27----------------",
        "title": "Likelihood Weighting \u2013 Li Yin Sulimowicz \u2013",
        "text": "(Currently it is just a simple note). LW is used to compute the posterior distribution, it is more like a sampling method based on evidence to cut down the computational complexity compared with of Gibbs Sampling. The following content includes one LW example from http://www.eng.utah.edu/~mccully/cs5300lw/.\n\nThe purpose of this webpage is to provide a detailed example of likelihood weighting. Prepared by Duane A. McCully, University of Utah, Spring 2009.\n\nA simple description of the likelihood-weighting algorithm described on page 515 (Figure 14.14) is as follows:\n\nAt the time that the network is sampled, the state of some nodes will be known and others will not. The nodes whose values are known are referred to as evidence variables. So, given the evidence, we need to query the remaining nodes to determine the state of the entire network. When this is complete a likelihood weight is assigned to this sample by multiplying together the probabilities of each evidence variable given its parents. This result is stored in a map, that we will name W, that associates all of the variables in the network with its weight. In slightly more detail:\n\n7. After the entire network is examined for this sample, we will be left with x and w, representing the state of the network and the likelihood weight to be associated to that state, respectively. This is added to W using x as the key and w as the data value. If x already exists in W, then w is added to the data value associated to x in W.\n\nWe will now generate a set of samples for the above Alarm network:\n\nFor this example, the weighted sample is Burglary=false, Earthquake=false, Alarm=false, JohnCalls=false, MaryCalls=false with a weight of 0.997. Now the book speaks of \u201cW, a vector of weighted counts over X.\u201d So pursuant to this terminology, we think of a map in C++ whose key is the tuple (~b,~e,a,j,m) and whose mapped value is the weight. Or, in python, a dict() object. Any weight that is computed through the above algorithm is added to any existing weight that matches the key in W. Since this is our first sample, there is no such key in W so the existing weight is effectively zero. Here is what W looks like so far (the sample column is for our referencing convenience): W SampleKeyWeight 1~b~e~a~j~m0.997\n\nBased on the above we now add (~b,~e,~a,j,~m) to W with a weight of 0.05: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.05\n\nBased on the above we now add (~b,~e,a,j,m) to W with a weight of 0.63: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.05 3~b~eajm0.63\n\nBased on the above we now add (~b,~e,~a,j,~m) to W with a weight of 0.05. However, note that (~b,~e,~a,j,~m) matches the key for sample 2. Therefore, the weight of 0.05 is added to the existing weight of 0.05 giving 0.10: W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.10 3~b~eajm0.63\n\nBased on the above we now add (b,~e,~a,~j,~m) to W with a weight of 0.001. W SampleKeyWeight 1~b~e~a~j~m0.997 2~b~e~aj~m0.10 3~b~eajm0.63 4b~e~a~j~m0.001\n\nWe will now use the sampling data collected above to compute some probabilities.\n\nArtificial Intelligence \u2014 A Modern Approach\n\n Second Edition\n\n Stuart J. Russel and Peter Norvig\n\n Prentice Hall, Pearson Education, Inc., NJ\n\n 2003\n\n ISBN 0\u201313\u2013790395\u20132"
    },
    {
        "url": "https://medium.com/@lisulimowicz/sorting-algorithms-304d0b1817ab?source=user_profile---------30----------------",
        "title": "Sorting Algorithms \u2013 Li Yin Sulimowicz \u2013",
        "text": "Like QuickSort, Merge Sort is a Divide and Conquer algorithm. It divides input array in two halves, calls itself for the two halves and then merges the two sorted halves. The merge() function is used for merging two halves. The merge(arr, l, m, r) is key process that assumes that arr[l..m] and arr[m+1..r] are sorted and merges the two sorted sub-arrays into one. See following C implementation for details.\n\nThe following diagram from wikipedia shows the complete merge sort process for an example array {38, 27, 43, 3, 9, 82, 10}. If we take a closer look at the diagram, we can see that the array is recursively divided in two halves till the size becomes 1. Once the size becomes 1, the merge processes comes into action and starts merging arrays back till the complete array is merged.\n\nTime Complexity: Sorting arrays on different machines. Merge Sort is a recursive algorithm and time complexity can be expressed as following recurrence relation.\n\n T(n) = 2T(n/2) + \u0398(n)\n\nThe above recurrence can be solved either using Recurrence Tree method or Master method. It falls in case II of Master Method and solution of the recurrence is \u0398(nlogn). Time complexity of Merge Sort is \u0398(in all 3 cases (worst, average and best) as merge sort always divides the array in two halves and take linear time to merge two halves.\n\nSorting In Place: No in a typical implementation\n\nLike Merge Sort, QuickSort is a Divide and Conquer algorithm. It picks an element as pivot and partitions the given array around the picked pivot. There are many different versions of quickSort that pick pivot in different ways.\n\n10 80 30 90 40 50 70 i=-1, j =0, swap i=0 with j=0, 10 with 10\n\n10 80 30 90 40 50 70 i=0, j =1, no action\n\n10 80 30 90 40 50 70 i=0, j =2, 30<=70, swap i=1 with j=2, 80 with 30\n\n10 30 80 90 40 50 70 i=1, j=3, no action\n\n10 30 80 90 40 50 70 i=1, j=4, 30<=70, swap i=2 with j=4, 80 with 40\n\n10 30 40 90 80 50 70 i=2, j =5, swap i=3 with j=5, 90 with 50\n\n10 30 40 50 80 90 70, i=3, so finnaly swap the i=4 with high \n\n10 30 40 50 70 90 80, return i=4"
    },
    {
        "url": "https://medium.com/@lisulimowicz/https-www-programiz-com-python-programming-operators-84107d1453e1?source=user_profile---------31----------------",
        "title": "Operations \u2013 Li Yin Sulimowicz \u2013",
        "text": "Bitwise operators act on operands as if they were string of binary digits. It operates bit by bit, hence the name.\n\nFor example, 2 is in binary and 7 is .\n\nIn the table below: Let x = 10 ( in binary) and y = 4 ( in binary)"
    },
    {
        "url": "https://medium.com/@lisulimowicz/learning-python-list-cc59b6851b41?source=user_profile---------32----------------",
        "title": "Learning Python \u2014 List \u2013 Li Yin Sulimowicz \u2013",
        "text": "List slices can also have a third number, representing the step, to include only alternate values in the slice.\n\nNegative values can be used in list slicing (and normal list indexing). When negative values are used for the first and second values in a slice (or a normal index), they count from the end of the list.\n\nIf a negative value is used for the step, the slice is done backwards.\n\nUsing [::-1] as a slice is a common and idiomatic way to reverse a list.\n\nIf you\u2019re going to be doing lots of array operations, then you will probably find it useful to install Numpy. Then you can use ordinary arithmetic operations element-wise on arrays, and there are lots of useful functions for computing with arrays.\n\nList as Stack: FILO, like stack it in a bottle\n\nHowever, it is not efficient, so we use the package, Queue, include Queue(), LifoQueue(), and PriorityQueue()\n\n2. There are three built-in functions that are very useful when used with lists: , , and .\n\nreturns a sequence for which is true. If sequence is a , or , the result will be of the same type; otherwise, it is always a .\n\ncalls returns a list of the return values of function. To\n\nMap could be replace by a more powerful library: Numpy\n\nreturns a single value constructed by calling the binary function function on the first two items of the sequence, then on the result and the next item, and so on.\n\nMore with the list:\n\nList comprehensions are a useful way of quickly creating lists whose contents obey a simple rule.\n\nTrying to create a list in a very extensive range will result in a MemoryError.\n\nThis code shows an example where the list comprehension runs out of memory.\n\nFor example, we can do the following:\n\nIn the real world, you should prefer built-in functions to complex flow statements. The function would do a great job for this use case:\n\nA tuple consists of a number of values separated by commas. Tuple is immutable, it is just like the list except it uses parenthesis instead of brackets. Tuple can contact mutable elements. for instance:\n\nTuples are faster than lists, but they cannot be changed.\n\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses eliminating duplicate entries. Set objects also support mathematical operations like union, intersection, difference, and symmetric difference.\n\nset can have elements of tuple, string, but not list(convert it to tuple),\n\nHere is a brief demonstration:\n\nAnother useful data type built into Python is the dictionary (see Mapping Types \u2014 dict). Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You can\u2019t use lists as keys, since lists can be modified in place using index assignments.\n\nIt is best to think of a dictionary as an unordered set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: .\n\nThe main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also possible to delete a key:value pair with . If you store using a key that is already in use, the old value associated with that key is forgotten. It is an error to extract a value using a non-existent key.\n\nThe method of a dictionary object returns a list of all the keys used in the dictionary, in arbitrary order (if you want it sorted, just apply the function to it). To check whether a single key is in the dictionary, use the keyword.\n\nHere is a small example using a dictionary:\n\nThe constructor builds dictionaries directly from sequences of key-value pairs:\n\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using the function.\n\nTo loop over two or more sequences at the same time, the entries can be paired with the function.\n\nTo loop over a sequence in reverse, first specify the sequence in a forward direction and then call the function.\n\nTo loop over a sequence in sorted order, use the function which returns a new sorted list while leaving the source unaltered.\n\nA string is a sequence of characters. A character is simply a symbol. For example, the English language has 26 characters. Computers do not deal with characters, they deal with numbers (binary). Even though you may see characters on your screen, internally it is stored and manipulated as a combination of 0\u2019s and 1\u2019s. This conversion of character to a number is called encoding, and the reverse process is decoding. ASCII and Unicode are some of the popular encoding used.\n\nLike above, python string can be indexed, counted, sliced, sorted, but cant assign new value. What if we want to change a string?\n\nWe can test if a sub string exists within a string or not, using the keyword ."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/gaussian-filtering-for-computational-photography-c734c91d3f11?source=user_profile---------33----------------",
        "title": "Gaussian Filtering for Computational Photography \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "Because the Gauss transform can express a rich and useful family of image processing algorithms, but its use has been hindered by its computational complexity; instead, approximate algorithms plays vital role in the application of GF into real use.\n\nThe first data structure is permutohedral lattice, which has O(d\u00b2n) time and space complexity; The second one is the Gaussian kd-tree, which has O(dnlogn) space and time complexity. For the dimensions are between 3\u201312, PL > KDT, when the d>12, then we go for the KDT."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/dense-conditional-random-field-dfdeb6655005?source=user_profile---------34----------------",
        "title": "Dense Conditional Random Field \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "The purpose of this article is to fully understand two classical papers: Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials, and Conditional Random Fields as Recurrent Neural Network.\n\nAt first, I did a little bit math deduction to help me understand this CRF probabilistic graphical model.\n\nThe inference is the process of maximum a posteriori (MAP).\n\nThis process is about the inference of CRF. So, for the inference process we need to give the optimal parameters. How to get the optimal parameters? This is the process of learning.\n\nFor CRFs that only have simple hyperparameters that is only in R space, we can use grid search that trained on a training dataset to get the optimal hyperparamters.\n\nFor CRFs that choose to use higher dimentional parameters, we need optimize an objective function to estimate the parameters. The learning algorithm we have the gradient descent.\n\nAt first the problem of the inference and learning are optimization problems."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/conferences-and-journals-a3f0854b6ad6?source=user_profile---------35----------------",
        "title": "Conferences and Journals for Computer Vision Area \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "This website do publicize the review from the top conference, which can help a lot for people without experience.\n\nThe following content is cited from here.\n\nHere is a link for all. This article includes the top conferences and journals.\n\nConference Series : British Machine Vision Conference\n\n Link: http://bmvc2017.london/ When Sep 4, 2017 \u2014 Sep 7, 2017 Where London Submission Deadline May 2, 2017 Notification Due Jul 4, 2017 Final Version Due Jul 18, 2017\n\nMain conference: paper Submission Deadline 2016 November 15, 6:00 p.m. Pacific Standard Time (Los Angeles), same time of day as above deadline."
    },
    {
        "url": "https://medium.com/@lisulimowicz/advice-on-writing-a-paper-for-researchers-a6c1af76d987?source=user_profile---------36----------------",
        "title": "Advice on Writing a Paper for Researchers \u2013 Li Yin Sulimowicz \u2013",
        "text": "Write a draft at first: no need of abstract and introduction. Because you usually need a draft before you know what you can introduce.\n\n3. what is still not known\n\nThe readers read this part with expectation; some then bring with them, others you must create. The most important expectations you create are in the research problem that you propose. In your first sentences, you must convince your readers that you have discovered a research problem that worth their consideration and that you may even have found its solution. An introduction should never leave them wondering, why I am reading this?\n\nThe common structure includes at least these two elements, in this predictable order:\n\nAnd depending on how familiar readers are with the problem, they may also expect to see before these two elements one more:\n\nThus the structure of a typically explicit introduction looks like this:\n\nSince the center of your introduction must be the statement of your problem, we start with that, then discuss the context, and finally turn to your choice of responses.\n\nBefore you articulate any of the problem, however, you might first open with a context that locates your problem in a relevant background. In that way, you help your readers understand how your problem fits into a bigger picture, how it related to other research. Do not write an introduction that only the experts in your research area understand.\n\nA full statement of a research problem has two parts:"
    },
    {
        "url": "https://medium.com/@lisulimowicz/linux-commands-523c7706894f?source=user_profile---------37----------------",
        "title": "Linux commands \u2013 Li Yin Sulimowicz \u2013",
        "text": "Commands to count the total number of files in one directory\n\nYou can easily rename all the files in current directory typing (assuming you are using bash):\n\nWrite all the files in a directory in a text file\n\nCompare two files and find the command elements to save in a file\n\nRandom Shuffle contents in one file and save it to another\n\nNow, I want to move files listed in text file to another directory:"
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/scale-invariant-feature-transform-sift-detector-and-descriptor-14165624a11?source=user_profile---------38----------------",
        "title": "Scale Invariant Feature Transform (SIFT) Detector and Descriptor",
        "text": "In last couple of chapters, we saw some corner detectors like Harris etc. They are rotation-invariant, which means, even if the image is rotated, we can find the same corners. It is obvious because corners remain corners in rotated image also. But what about scaling? A corner may not be a corner if the image is scaled. For example, check a simple image below. A corner in a small image within a small window is flat when it is zoomed in the same window. So Harris corner is not scale invariant.\n\nSo, in 2004, D.Lowe, University of British Columbia, came up with a new algorithm, Scale Invariant Feature Transform (SIFT) in his paper, Distinctive Image Features from Scale-Invariant Keypoints, which extract keypoints and compute its descriptors. *(This paper is easy to understand and considered to be best material available on SIFT. So this explanation is just a short summary of this paper)*.\n\nThere are mainly four steps involved in SIFT algorithm. We will see them one-by-one.\n\nThe Laplacian of Gaussian (LoG) operation goes like this. You take an image, and blur it a little. And then, you calculate second order derivatives on it (or, the \u201claplacian\u201d). This locates edges and corners on the image. These edges and corners are good for finding keypoints.\n\nBut the second order derivative is extremely sensitive to noise. The blur smoothes it out the noise and stabilizes the second order derivative.\n\nThe problem is, calculating all those second order derivatives is computationally intensive. So we cheat a bit.\n\nTo generate Laplacian of Guassian images quickly, we use the scale space. We calculate the difference between two consecutive scales. Or, the Difference of Gaussians. Here\u2019s how:\n\nThese Difference of Gaussian images are approximately equivalent to the Laplacian of Gaussian. And we\u2019ve replaced a computationally intensive process with a simple subtraction (fast and efficient). Awesome!\n\nThese DoG images comes with another little goodie. These approximations are also \u201cscale invariant\u201d. What does that mean?\n\nJust the Laplacian of Gaussian images aren\u2019t great. They are not scale invariant. That is, they depend on the amount of blur you do. This is because of the Gaussian expression. (Don\u2019t panic ;) )\n\nSee the \u03c32 in the demonimator? That\u2019s the scale. If we somehow get rid of it, we\u2019ll have true scale independence. So, if the laplacian of a gaussian is represented like this:\n\nThen the scale invariant laplacian of gaussian would look like this:\n\nBut all these complexities are taken care of by the Difference of Gaussian operation. The resultant images after the DoG operation are already multiplied by the \u03c32. Great eh!\n\nOh! And it has also been proved that this scale invariant thingy produces much better trackable points! Even better!\n\nYou can\u2019t have benefits without side effects >.<\n\nYou know the DoG result is multiplied with \u03c32. But it\u2019s also multiplied by another number. That number is (k-1). This is the k we discussed in the previous step.\n\nBut we\u2019ll just be looking for the location of the maximums and minimums in the images. We\u2019ll never check the actual values at those locations. So, this additional factor won\u2019t be a problem to us. (Even if you multiply throughout by some constant, the maxima and minima stay at the same location)\n\nHere\u2019s a gigantic image to demonstrate how this difference of Gaussians works.\n\nIn the image, I\u2019ve done the subtraction for just one octave. The same thing is done for all octaves. This generates DoG images of multiple sizes.\n\nFrom the image above, it is obvious that we can\u2019t use the same window to detect keypoints with different scale. It is OK with small corner. But to detect larger corners we need larger windows. For this, scale-space filtering is used. In it, Laplacian of Gaussian(LoG) is found for the image with various \u03c3 values. LoG acts as a blob detector which detects blobs in various sizes due to change in \u03c3. In short, \u03c3 acts as a scaling parameter. For eg, in the above image, gaussian kernel with low \u03c3 gives high value for small corner while guassian kernel with high \u03c3 fits well for larger corner. So, we can find the local maxima across the scale and space which gives us a list of (x,y,\u03c3) values which means there is a potential keypoint at (x,y) at \u03c3 scale.\n\nBut this LoG is a little costly, so SIFT algorithm uses Difference of Gaussians which is an approximation of LoG. Difference of Gaussian is obtained as the difference of Gaussian blurring of an image with two different \u03c3, let it be \u03c3 and k\u03c3. This process is done for different octaves of the image in Gaussian Pyramid. It is represented in below image:\n\nOnce this DoG are found, images are searched for local extrema(maxima or minima) over scale and space. For eg, one pixel in an image is compared with its 8 neighbours as well as 9 pixels in next scale and 9 pixels in previous scales. If it is a local extrema, it is a potential keypoint. It basically means that keypoint is best represented in that scale. It is shown in below image:\n\nOnce this is done, the marked points are the approximate maxima and minima. They are \u201capproximate\u201d because the maxima/minima almost never lies exactly on a pixel. It lies somewhere between the pixel. But we simply cannot access data \u201cbetween\u201d pixels. So, we must mathematically locate the subpixel location.\n\nThe red crosses mark pixels in the image. But the actual extreme point is the green one.\n\nUsing the available pixel data, subpixel values are generated. This is done by the Taylor expansion of the image around the approximate key point.\n\nWe can easily find the extreme points of this equation (differentiate and equate to zero). On solving, we\u2019ll get subpixel key point locations. These subpixel values increase chances of matching and stability of the algorithm.\n\nHere\u2019s a result I got from the example image I\u2019ve been using till now:\n\nThe author of SIFT recommends generating two such extrema images. So, you need exactly 4 DoG images. To generate 4 DoG images, you need 5 Gaussian blurred images. Hence the 5 level of blurs in each octave.\n\nIn the image, I\u2019ve shown just one octave. This is done for all octaves. Also, this image just shows the first part of keypoint detection. The Taylor series part has been skipped.\n\nRegarding different parameters, the paper gives some empirical data which can be summarized as, number of octaves = 4, number of scale levels = 5, initial \u03c3=1.6, k=2^(1/2) etc as optimal values.\n\nOnce potential keypoints locations are found, they have to be refined to get more accurate results. They used Taylor series expansion of scale space to get more accurate location of extrema, and if the intensity at this extrema is less than a threshold value (0.03 as per the paper), it is rejected. This threshold is called contrastThreshold in OpenCV\n\nDoG has higher response for edges, so edges also need to be removed. For this, a concept similar to Harris corner detector is used. They used a 2x2 Hessian matrix (H) to compute the pricipal curvature. We know from Harris corner detector that for edges, one eigen value is larger than the other. So here they used a simple function,\n\nIf this ratio is greater than a threshold, called edgeThreshold in OpenCV, that keypoint is discarded. It is given as 10 in paper.\n\nSo it eliminates any low-contrast keypoints and edge keypoints and what remains is strong interest points.\n\nNow an orientation is assigned to each keypoint to achieve invariance to image rotation. A neigbourhood is taken around the keypoint location depending on the scale, and the gradient magnitude and direction is calculated in that region. An orientation histogram with 36 bins covering 360 degrees is created. (It is weighted by gradient magnitude and gaussian-weighted circular window with \u03c3 equal to 1.5 times the scale of keypoint. The highest peak in the histogram is taken and any peak above 80% of it is also considered to calculate the orientation. It creates keypoints with same location and scale, but different directions. It contribute to stability of matching.\n\nNow keypoint descriptor is created. A 16x16 neighbourhood around the keypoint is taken. It is devided into 16 sub-blocks of 4x4 size. For each sub-block, 8 bin orientation histogram is created. So a total of 128 bin values are available. It is represented as a vector to form keypoint descriptor. In addition to this, several measures are taken to achieve robustness against illumination changes, rotation etc.\n\nKeypoints between two images are matched by identifying their nearest neighbours. But in some cases, the second closest-match may be very near to the first. It may happen due to noise or some other reasons. In that case, ratio of closest-distance to second-closest distance is taken. If it is greater than 0.8, they are rejected. It eliminaters around 90% of false matches while discards only 5% correct matches, as per the paper.\n\nSo this is a summary of SIFT algorithm. For more details and understanding, reading the original paper is highly recommended. Remember one thing, this algorithm is patented. So this algorithm is included in the opencv contrib repo\n\nSo now let\u2019s see SIFT functionalities available in OpenCV. Let\u2019s start with keypoint detection and draw them. First we have to construct a SIFT object. We can pass different parameters to it which are optional and they are well explained in docs.\n\nsift.detect() function finds the keypoint in the images. You can pass a mask if you want to search only a part of image. Each keypoint is a special structure which has many attributes like its (x,y) coordinates, size of the meaningful neighbourhood, angle which specifies its orientation, response that specifies strength of keypoints etc.\n\nOpenCV also provides cv2.drawKeyPoints() function which draws the small circles on the locations of keypoints. If you pass a flag, cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS to it, it will draw a circle with size of keypoint and it will even show its orientation. See below example.\n\nSee the two results below:\n\nNow to calculate the descriptor, OpenCV provides two methods.\n\nWe will see the second method:\n\nHere kp will be a list of keypoints and des is a numpy array of shape Number_of_Keypoints\u00d7128.\n\nSo we got keypoints, descriptors etc. Now we want to see how to match keypoints in different images. That we will learn in coming chapters."
    },
    {
        "url": "https://medium.com/machine-learning-for-li/install-caffe-a198c400f1cb?source=user_profile---------42----------------",
        "title": "Install caffe \u2013 Machine Learning for Li \u2013",
        "text": "If we need to install a certain version of caffe, we need to compile it.\n\nThere could have two ways to install caffe: conda or without conda\n\nNot sure if the correct solution but seemingly works:\n\n add the second line in the Makefile:"
    },
    {
        "url": "https://medium.com/@lisulimowicz/basic-operations-for-github-d700a81aae7a?source=user_profile---------44----------------",
        "title": "Streamlining the usage of Github with Commands \u2013 Li Yin Sulimowicz \u2013",
        "text": "Now we have shown the github which file we want to track and submit.\n\nYou\u2019ve now got a local git repository. You can use git locally, like that, if you want. But if you want the thing to have a home on github, do the following.\n\nNow, follow the second set of instructions, \u201cPush an existing repository\u2026\u201d, to use ssh connection, (if you set up ssh in \u201cYour first time\u201d, then you won\u2019t have to type your password every time you push things to github)\n\nTo use https connection, you\u2019ll have to type your github password every time you push to github.\n\nTo definitely be able to login using protocol, you should first set your authentication credential to the git Remote URI:\n\nThen you\u2019ll be asked for a password when trying to . If this error pop out, error: src refspec master does not match any.\n\nAll I had to do was:\n\nIf we remote github is different comprared with local, push with \u2014 force\n\nIf error prompts out, As the error message indicates, there is already a remote configured with the same name. So you can either add the new remote with a different name or update the existing one if you don\u2019t need it:\n\nyou can do a to see what that which already exists is, If you think this is there by some error, you can update it like so:\n\nOr another option is to do it in the config files.\n\ncalled for example instead of (which obviously already exists in your system), do the following:\n\nRemember though, everywhere in the tutorial you see \u201corigin\u201d you should replace it with \u201cgithub\u201d. For example should now be .\n\nChange the current working directory to your local project.\n\nList your existing remotes in order to get the name of the remote you want to change.\n\nChange your remote\u2019s URL from SSH to HTTPS with the command.\n\nVerify that the remote URL has changed.\n\nThe next time you , , or to the remote repository, you'll be asked for your GitHub username and password.\n\nChange the current working directory to your local project.\n\nList your existing remotes in order to get the name of the remote you want to change.\n\nChange your remote\u2019s URL from HTTPS to SSH with the command.\n\nVerify that the remote URL has changed.\n\nWe need this if we forked a branch from others\u2019 github, we might have the origin already existed.\n\nThis command will build a branch and get into this branch. Then we do"
    },
    {
        "url": "https://medium.com/@lisulimowicz/code-link-8dac705bd167?source=user_profile---------46----------------",
        "title": "Code link \u2013 Li Yin Sulimowicz \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@lisulimowicz/information-theory-a9db8058e2df?source=user_profile---------47----------------",
        "title": "Information Theory \u2013 Li Yin Sulimowicz \u2013",
        "text": "There is a book called Information Theory, Inference, and Learning Algorithms written by a formerly professor in Department of Physics of University of Cambridge. This book could be downloaded from http://www.inference.org.uk/mackay/itila/. Also, he taught a class, the resource is here: http://www.inference.org.uk/mackay/itprnn/. It includes videos and slides for this book.\n\nThis book helped me understand basic concept of variational method and mean-field variational which could be used as an inference approximation for probabilistic graphical models in Computer Vision. For example, Fully connected CRF used the mean-field approximation."
    },
    {
        "url": "https://medium.com/@lisulimowicz/summarization-of-linux-error-378c05dd1979?source=user_profile---------48----------------",
        "title": "Summarization of Linux Error \u2013 Li Yin Sulimowicz \u2013",
        "text": "Found that the root has no the directory , /home/liyin/anaconda/lib/. Now add it in this PATH\n\nOr we can try to rewrite the /etc/basrc"
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/discrete-inference-and-learning-in-artificial-vision-cca4f6359fec?source=user_profile---------49----------------",
        "title": "Discrete Inference and Learning in Artificial Vision",
        "text": "This article will be about the probability graphical models. At first, I will just gain resources link:\n\nwhere the energy (or cost, objective) function E(x, D; w) can be regarded as a quality measure of a parameter configuration x in the solution space given the observed data D, and w denotes the model parameters\n\nvisual perception involves three main tasks: modeling, inference and learning. The modeling has to accomplish: (i) the choice of an appropriate representation of the solution using a tuple of variables x; and (ii) the design of the class of energy functions E(x, D; w) which can correctly mea- sure the connection between x and D. The inference has to search for the configuration of x leading to the optimum of the energy function, which corresponds to the solution of the original problem. The learning aims to select the optimal model parameters w based on the training data.\n\nFully-connected CRFs: this includes codes in python. This could be a good start to combine CRF to TensorFlow"
    },
    {
        "url": "https://medium.com/@lisulimowicz/virtual-environment-in-linux-a3d2cd50b333?source=user_profile---------50----------------",
        "title": "Virtual Environment in Linux \u2013 Li Yin Sulimowicz \u2013",
        "text": "If you are using conda, refer https://conda.io/docs/using/envs.html#create-an-environment to see how to build a virtual environment here.\n\nThe original address if from:\n\nA Virtual Environment is a tool to keep the dependencies required by different projects in separate places, by creating virtual Python environments for them. It solves the \u201cProject X depends on version 1.x but, Project Y needs 4.x\u201d dilemma, and keeps your global site-packages directory clean and manageable.\n\nFor example, you can work on a project which requires Django 1.10 while also maintaining a project which requires Django 1.8.\n\nvirtualenv is a tool to create isolated Python environments. virtualenv creates a folder which contains all the necessary executables to use the packages that a Python project would need.\n\nwill create a folder in the current directory which will contain the Python executable files, and a copy of the library which you can use to install other packages. The name of the virtual environment (in this case, it was ) can be anything; omitting the name will place the files in the current directory instead.\n\nThis creates a copy of Python in whichever directory you ran the command in, placing it in a folder named .\n\nYou can also use the Python interpreter of your choice (like ).\n\nor change the interpreter globally with an env variable in :\n\nThe name of the current virtual environment will now appear on the left of the prompt (e.g. to let you know that it\u2019s active. From now on, any package that you install using pip will be placed in the folder, isolated from the global Python installation.\n\nInstall packages as usual, for example:\n\nThis puts you back to the system\u2019s default Python interpreter with all its installed libraries.\n\nTo delete a virtual environment, just delete its folder. (In this case, it would be .)\n\nAfter a while, though, you might end up with a lot of virtual environments littered across your system, and its possible you\u2019ll forget their names or where they were placed.\n\nRunning with the option will not include the packages that are installed globally. This can be useful for keeping the package list clean in case it needs to be accessed later. [This is the default behavior for 1.7 and later.]\n\nIn order to keep your environment consistent, it\u2019s a good idea to \u201cfreeze\u201d the current state of the environment packages. To do this, run\n\nThis will create a file, which contains a simple list of all the packages in the current environment, and their respective versions. You can see the list of installed packages without the requirements format using \u201cpip list\u201d. Later it will be easier for a different developer (or you, if you need to re-create the environment) to install the same packages using the same versions:\n\nThis can help ensure consistency across installations, across deployments, and across developers.\n\nLastly, remember to exclude the virtual environment folder from source control by adding it to the ignore list.\n\nvirtualenvwrapper provides a set of commands which makes working with virtual environments much more pleasant. It also places all your virtual environments in one place.\n\nTo install (make sure virtualenv is already installed):\n\nFor Windows, you can use the virtualenvwrapper-win.\n\nTo install (make sure virtualenv is already installed):\n\nIn Windows, the default path for WORKON_HOME is %USERPROFILE%Envs\n\nAlternatively, you can make a project, which creates the virtual environment, and also a project directory inside , which is -ed into when you .\n\nvirtualenvwrapper provides tab-completion on environment names. It really helps when you have a lot of environments and have trouble remembering their names.\n\nalso deactivates whatever environment you are currently in, so you can quickly switch between environments.\n\nList all of the environments. Navigate into the directory of the currently activated virtual environment, so you can browse its , for example. Like the above, but directly into directory. Shows contents of directory.\n\nWith virtualenv-burrito, you can have a working virtualenv + virtualenvwrapper environment in a single command.\n\nWhen you into a directory containing a , autoenv automagically activates the environment.\n\nInstall it on Mac OS X using :"
    },
    {
        "url": "https://medium.com/machine-learning-for-li/how-to-use-tensorflow-on-tacc-supercomputer-827e7aaa9992?source=user_profile---------51----------------",
        "title": "How to use TensorFlow on TACC supercomputer \u2013 Machine Learning for Li \u2013",
        "text": "Then use the following command to check the status\n\nUsing the command with the and options can provide an estimate of when a particular job will be scheduled:\n\nEven more extensive job information can be found using the \u201c \" command. The output shows quite a bit about the job: job dependencies, submission time, number of codes, location of the job script and the working directory, etc. See the man page for more details.\n\nThe command is used to remove pending and running jobs from the queue. Include a space-separated list of job IDs that you want to cancel on the command-line:\n\nExample job scripts are available online in . They include details for launching large jobs, running multiple executables with different MPI stacks, executing hybrid applications, and other operations.\n\n4. Copy Model and Data, you may copy the test dir to other places\n\n7. Run the program there, use the screen, which means the data is saved to the $WORK\n\n8. We can use command to check the submitted queue\n\nThen we try to connect on the working nodelist\n\nIf we use top on each of the working node, it showes the same PID running. All the tasks submitted from the terminal will be working under $WORK directory, and that is where the result is saved.\n\nThus, we can copy the result from $WORK to HOME that we can visualize the data with jupyter notebook easily from the visualization portal tool. It would be even nicer if the $WORK directory is visible to all the users on the jupyter notebook too.\n\nWe can run program in the $WORK directory from jupyter notebook\n\nIf we are running deep neural network that takes hours or days to finish, we can just close the visualization portal website but do not hit the log out. The job will keep running till it is done.\n\nData transfer from any Linux system can be accomplished using the utility to copy data to and from the login node. A file can be copied from your local system to the remote server by using the command:\n\nNotice I used the same port number (6006) that I was told to connect to by the tensorboard. Also note I used the compute node host name (c224\u2013202) in that command. Your node will likely have a different name. Use whatever node you land on. \n\n \n\n I then pointed my browser to login2.maverick.tacc.utexas.edu:6006 and was able to connect.\n\n2. A easier solution is to go to TACC Visualization Portal to start a VNC .\n\nThen go to the application menu to choose browser:\n\nAnd then navigate to the given address:"
    },
    {
        "url": "https://medium.com/machine-learning-for-li/restricted-boltzmann-machines-rbms-d355c4b5ebfa?source=user_profile---------52----------------",
        "title": "Restricted Boltzmann Machines (RBMs) \u2013 Machine Learning for Li \u2013",
        "text": "RBMs have been used as generative models of many different types of data include labeled and unlabeled. In their conditional form they can be used to model high-dimensional temporal sequences such as video or motion capture data (Taylor et al., 2006) or speech (Mohamed and Hinton, 2010). Their most important use is as learning modules that are composed to form deep belief nets (Hinton et al., 2006a).\n\nIn recent years Restricted Boltzmann Machines has attracted growing attention in the computer vision community. Restricted Boltzmann Machine and its variants have been used to many computer vision applications including object recognition, facial expression generation, human motion generation and activity recognition. The increased popularity of Restricted Boltzmann Machines for computer vision is due partly to their excellent ability in feature extraction.\n\nRestricted Boltzmann Machines have been exploited in many computer vision applications. The following subsections summarize these applications including object recognition, human motion generation, facial expression generation.\n\nObject recognition is one of the fundamental challenges in computer vision. Its objective is efficiently detecting and classifying objects in an image or video sequence into generic categories such as \u201canimals\u201d, \u201cvehicles\u201d, \u201cflowers\u201d, etc. Object recognition in images and videos is very challenging due to high intra-class variety and viewpoint variants.\n\nBRBM employs binary hidden and visible units, which is applicable to quasi-binary images (e.g., handwritten digits). The extension of RBMs such as the GBRBM, the mcRBM and the ssRBM are more suits to the continuous data. The characterization of object recognition using RBM has been a recent focus in the computer vision community as summarized in Table 3.1. and more please refer the following papers."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/why-360-video-is-the-next-big-thing-in-tech-1e6c030b537?source=user_profile---------53----------------",
        "title": "Why 360 video is the next big thing in tech \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "LAS VEGAS \u2014 The world is one big round place, and the problem is, we\u2019ve been looking at a cropped view of it for way too long.\n\nBut thanks to new technology advancements in cameras and online algorithms, we can now zap open our smartphones and see all around us \u2014 in front, back, to the left and right, above and below, in full spherical, 360 view.\n\nAt the Consumer Electronics Show, which ended Saturday, 360 video and virtual reality (VR) was the big talk of the show, from huge concerns like YouTube and corporate parent Google, to Facebook\u2019s Oculus Rift and camera makers GoPro, Ricoh and 360fly. VR and 360 are here \u2014 and set for bigger things in 2016.\n\n\u201cIt\u2019s like everything else, you want to see everything, you want to hear everything,\u201d says Matt Sailor, the CEO of ICrealtech.com, which introduced three ALLie-brand 360 cameras at CES.\n\nWith 360, viewers \u201cget to be completely engrossed, and go to places they\u2019ve never been,\u201d adds Andy Peacock, product head at camera start-up 360fly. (360 is often used interchangeably with virtual reality, though the latter typically indicates you\u2019re using goggles for an immersive experience.)\n\nThe biggest news of the show was the introduction of the $599 Oculus Rift VR headset, which went on sale Wednesday with pre-orders that won\u2019t be filled until June. With the Rift, gamers will get a much wider and expansive view of their worlds than they\u2019ve ever seen before.\n\nBeyond VR for gaming, much talk at CES also concerned 360 for photography.\n\nIn a speech Thursday night, YouTube\u2019s Chief Business Officer Robert Kyncl talked about how VR was going to dramatically change the mobile viewing experience.\n\nDigital video to surpass TV by 2020, says YouTube\u2019s Kyncl\n\nWe currently watch 1.5 hours a day of digital video, he said, compared to five hours daily for TV. But he sees digital video surpassing TV within four years, with VR being a huge driver for the shift.\n\n\u201cOn YouTube, we made a big, early bet on 360-degree video because it is the first type of video that actually gives you a better experience on mobile than you can have on desktop or on your TV,\u201d said Kyncl. \u201cAnd since we know mobile video is exploding, formats that lend themselves to mobile storytelling will grow along with them.\u201d\n\nWhat\u2019s been holding back both filmmakers and the average Joe from diving into 360 in a big way is the limitations of how 360 video gets made. To get the full view, you usually need to use a bunch of cameras tapped together, and then \u201cstitch\u201d or piece the views together in video editing. That process can take hours, days, even weeks.\n\nSeveral camera manufacturers looked to solve that issue here, with small, consumer-grade cameras that are easier to use, can be toted around, and promise to eliminate the stitching issues.\n\nThe Ricoh Theta S, released in late 2015, won the CES 2016 Innovation award, and the new 360fly company showed a new model at the show, a compact spherical camera in the shape of a little ball, that expands the category by shooting 360 video in 4K resolution.\n\n\u201cNo longer are you limited to these very expensive complicated rigs that use multiple cameras,\u201d says Jim Malcolm, president of Ricoh Imaging, which makes the Theta. \u201cNow you have a simple product you can put in your pocket and push a button and join the revolution.\u201d\n\nThe Theta costs $369, and is so popular, Ricoh is having a hard time keeping them in stock.\n\nThe 360fly 4K model hasn\u2019t announced pricing, but is expected to sell in the $500 range later this year. The company also showed up a new helmet cam for serious cyclists and motorcycle riders, with a built-in 360 camera. Longtime camera maker Nikon also announced a new 360 cam here at CES, the KeyMission 360, with two lenses. No pricing or availability was revealed.\n\nThe cameras are easier than the multiple rig set-ups, but there are still editing issues and apps to download to process the files. They offer one-click instant uploads to Facebook and YouTube\u2019s 360 channel, where they can be viewed as is, with the user moving the image around to see more, or via a viewer, like Google\u2019s Cardboard.\n\nThese 360 cams \u201chave the potential of bringing VR to consumers sooner than later,\u201d says Tim Bajarin, an analyst with Creative Strategies and \u201callow anyone to create content for VR.\u201d\n\nHe sees real estate, sports, travel and advertising as great potential markets for 360.\n\nWith a 360 cam, \u201ca cruise line could shoot a room a person might want to book and put them in the room so that they can walk in the room, see what it looks like and perhaps even walk the ship to see how it looks and what amenities it offers.\u201d Real estate agents could offer virtual tours, and advertisers could use 360 to put customers directly into the action, or use it to explain a product or service more fully, he adds.\n\nGoPro CEO Nick Woodman spoke in the YouTube presentation, explaining how he saw 360 as the next chapter in GoPro\u2019s evolution.\n\nThe company will release a super rig aimed at pros this year. A 15-camera GoPro unit, the $16,000 Odyssey, in partnership with YouTube-owner Google, promises \u201cJump\u201d software that will eliminate stitching.\n\nWoodman says he hopes to follow up shortly afterward with a consumer grade, one-camera GoPro 360 setup.\n\nVR \u201cis what\u2019s next,\u201d Woodman said. With VR \u201cyou can teleport people into a new experience and blow their minds. It\u2019s not a question of if, but when it will become adopted by consumers. This is the same type of content that\u2019s made GoPro so successful. If we\u2019re not innovating, we cease to be relevant.\u201d\n\nIs 2016 the year virtual reality becomes a reality? You can bet on it."
    },
    {
        "url": "https://medium.com/machine-learning-for-li/how-to-calculate-the-number-of-parameters-in-cnns-5aa08d0edd55?source=user_profile---------54----------------",
        "title": "How to calculate the number of parameters in CNNs? \u2013 Machine Learning for Li \u2013",
        "text": "This post comes from https://stackoverflow.com/questions/28232235/how-to-calculate-the-number-of-parameters-of-convolutional-neural-networks.\n\nIf you refer to VGG Net with 16-layer (table 1, column D) then refers to the total number of parameters of this network, i.e including all convolutional layers, but also the fully connected ones.\n\nLooking at the 3rd convolutional stage composed of 3 x layers:\n\nThe convolution kernel is 3x3 for each of these layers. In terms of parameters this gives:\n\nAs explained above you have to do that for all layers, but also the fully-connected ones, and sum these values to obtain the final 138M number.\n\nIn particular for the fully-connected layers (fc):\n\n(x) see section 3.2 of the article: the fully-connected layers are first converted to convolutional layers (the first FC layer to a 7 \u00d7 7 conv. layer, the last two FC layers to 1 \u00d7 1 conv. layers).\n\nAs precised above the spatial resolution right before feeding the fully-connected layers is 7x7 pixels. This is because this VGG Net uses spatial padding before convolutions, as detailed within section 2.1 of the paper:\n\n[\u2026] the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1 pixel for 3\u00d73 conv. layers.\n\nWith such a padding, and working with a 224x224 pixels input image, the resolution decreases as follow along the layers: 112x112, 56x56, 28x28, 14x14 and 7x7 after the last convolution/pooling stage which has 512 feature maps.\n\nThis gives a feature vector passed to with dimension: 512x7x7."
    },
    {
        "url": "https://medium.com/@lisulimowicz/tensorflow-summary-d4160304a6f1?source=user_profile---------55----------------",
        "title": "TensorFlow Summary \u2013 Li Yin Sulimowicz \u2013",
        "text": "From the TensorBoard, we can see ability of TensorFlow\u2019s data visualization is really beyond so many other deep learning tools.\n\nWe can use the image to add the image samples used for visualization. e.g.\n\ntf.cast is used to cast a tensor into a new data type.\n\nuse this operation to merge all the summary variables.\n\nThis can really write the data into the even files, which will be used to generate statistics in tensorboard.\n\nAfter the running the process, we can add more statistics, not necessarily to be a tensor. It could just be any variable using summary.value.add()"
    },
    {
        "url": "https://medium.com/@lisulimowicz/install-tensorflow-d8821ca60584?source=user_profile---------56----------------",
        "title": "Install TensorFlow \u2013 Li Yin Sulimowicz \u2013",
        "text": "While Tensorflow has a great documentation, you have quite a lot of details that are not obvious, especially the part about setting up Nvidia libraries and installing Bazel as you need to read external install guides. There is also a CROSSTOOL change to make to fix an include directory issue. So here is a guide, explaining everything from scratch in a single page.\n\n(I have tried so many ways to install a nvidia driver, not working at all except this one, because we need to find the right driver. For example, for NVIDIA GRID v2, the 375 is not working but 367 does)The first step is to get the latest Nvidia driver. While you can use to install the driver and CUDA, this causes a lot of issues with automatic updates and you need to purge everything to reinstall a new version. It is simpler to do everything manually.\n\nGo to Nvidia\u2019s download website and download the latest version of the driver, here for Linux 64-bit. In my case, .\n\nAs drivers for graphic devices are running at a low level, you must exit the GUI with and set the RunLevel to 3 with the program .\n\nThen, move to the directory where you downloaded the .run file and run it. You will be asked to confirm several things, the pre-install of something failure, no 32-bit libraries and more. Just continue to the end. Once it is done, reboot.\n\nNow, try nvidia-smi, see if it is working\n\nOr we can just directly disable the GUI: systemctl disable lightdm.service\n\nDue to the manual installation, it seems that when you do Ubuntu updates, they may install the version of the driver. This causes a failure when you start the computer and login, you will get a black screen and go back to the login screen.\n\nThe solution is to enter the terminal with and reinstall the driver just like before. Note that you can get back to the GUI with when you are in the terminal.\n\nIt\u2019s now time for CUDA. Go to the Nvidia CUDA website and create an account if you don\u2019t already have one and log in (I think this is only required for RC versions of CUDA, which is the case currently for CUDA 8.0RC, an account is also required to download cuDNN).\n\nChoose Linux > x86_64 > Ubuntu > 16.04 > runfile (local) and download the base installer and the patch. Ubuntu 16.04 uses GCC 5.4.0 as default C compiler, which caused an issue with CUDA 8.0RC, this is fixed with the patch.\n\nThe installer has 3 parts, a Nvidia driver, CUDA Toolkit and CUDA code samples. The Nvidia driver is usually outdated, that\u2019s why we installed it before, say no when asked if you want to install the driver (in Nvidia\u2019s install guide, they tell us to enter RunLevel 3, but this isn\u2019t necessary if we don\u2019t install the driver). Then, let everything as default, install the code samples to check your CUDA installation. To avoid an error about GCC 5.4.0, add . Then, once the installation is over, run the patch.\n\nIf we have already installed some other drivers, we can use this command\n\nNow try command to see if its working\n\nThe next part is to update CUDA_HOME, PATH and LD_LIBRARY_PATH. Move to your home folder and update then reload with the command . For those who are not Linux experts, is a file with user parameters that is launched when you login, you must reload it or restart the session for the changes to be active.\n\nAt the bottom of the file, add the following lines and save:\n\nYou can then reload and check that the paths have been properly modified.\n\nThen, you can check is CUDA is working by checking the version of the CUDA compiler and also by moving to the sample directory and compiling .\n\nYou should get an output that looks like this:\n\nGo to the Nvidia cuDNN website, login and download Download cuDNN v5.1 (August 10, 2016), for CUDA 8.0 RC > cuDNN v5.1 Library for Linux. Unzip the .tgz file and copy the files to the cuda-8.0 folder. Note that some of the .so files are links to the \u201creal\u201d .so file, by copying it, we duplicate the file, that way, when building Tensorflow from source, any cuDNN version will give libcudnn.so.5.1.5.\n\nThat\u2019s it. As you see, it is quite easy to add or remove cuDNN and replace it by another version of the library.\n\nIt\u2019s now time to install Tensorflow from source as the official binaries are only for CUDA 7.5. We will install it for Python2.7.\n\nFirst, you need to download and install JDK 8.\n\nIt\u2019s now time to get Bazel.\n\nFirst, you must get the code from Github. You can either take the most recent master branch (lots of new commits) or the latest release branch (should be more stable, but still updated every few days). Here, we get branch r0.10.\n\nEdit the text file tensorflow/third_party/gpus/crosstool/CROSSTOOL and add as below.\n\nIf you don\u2019t do this, you will get an error that looks like this:\n\nYou can now run the configure script. If you have only cuda 8.0, then leaving everything as default should be fine. I just provided the compute capability of my GPU, in my case 6.1.\n\nYou can then run Bazel. The build will take quite a lot of time, 900s on my PC. Then, create the pip package and install it with pip. The name of the pip package may be different depending of Tensorflow\u2019s version.\n\nYou can create a test.py file with the following code and run it to check that everything is working and that the GPU is recognised.\n\nYou can now start having fun."
    },
    {
        "url": "https://medium.com/lis-computer-vision-blogs/generative-adversarial-network-d1fbc4ce4499?source=user_profile---------57----------------",
        "title": "Generative Adversarial Network \u2013 Li\u2019s Computer Vision Blogs \u2013",
        "text": "To explain how the generative adversarial works, this article did a very good job explain it.\n\nAnother good and newer one.\n\nTo build a DCGAN, we create two deep neural networks. Then we make them fight against each other, endlessly attempting to out-do one another. In the process, they both become stronger.\n\nLet\u2019s pretend that the first deep neural network is a brand new police officer who is being trained to spot counterfeit money. It\u2019s job is to look at a picture and tell us if the picture contains real money.\n\nSince we are looking for objects in pictures, we can use a standard Convolutional Neural Network for this job. If you aren\u2019t familiar with ConvNets, you can read my earlier post. But the basic idea is that the neural network that takes in an image, processes it through several layers that recognize increasingly complex features in the image and then it outputs a single value \u2014 in this case, whether or not the image contains a picture of real money.\n\nThis first neural network is called the Discriminator:\n\nNow let\u2019s pretend the second neural network is a brand new counterfeiter who is just learning how to create fake money. For this second neural network, we\u2019ll reverse the layers in a normal ConvNet so that everything runs backwards. So instead of taking in a picture and outputting a value, it takes in a list of values and outputs a picture.\n\nThis second neural network is called the Generator:\n\nSo now we have a police officer (the Discriminator) looking for fake money and a counterfeiter (the Generator) that\u2019s printing fake money. Let\u2019s make them battle!\n\nIn the first round, the Generator will create pathetic forgeries that barely resemble money at all because it knows absolutely nothing about what money is supposed to look like:\n\nBut right now the Discriminator is equally terrible at it\u2019s job of recognizing money, so it won\u2019t know the difference:\n\nAt this point, we step in and tell the Discriminator that this dollar bill is actually fake. Then we show it a real dollar bill and ask it how it looks different from the fake one. The Discriminator looks for a new detail to help it separate the real one from the fake one.\n\nFor example, the Discriminator might notice that real money has a picture of a person on it and the fake money doesn\u2019t. Using this knowledge, the Discriminator learns how to tell the fake from the real one. It gets a tiny bit better at its job:\n\nNow we start Round 2. We tell the Generator that it\u2019s money images are suddenly getting rejected as fake so it needs to step up it\u2019s game. We also tell it that the Discriminator is now looking for faces, so the best way to confuse the Discriminator is to put a face on the bill:\n\nAnd the fake bills are being accepted as valid again! So now the Discriminator has to look again at the real dollar and find a new way to tell it apart from the fake one.\n\nThis back-and-forth game between the Generator and the Discriminator continues thousands of times until both networks are experts. Eventually the Generator is producing near-perfect counterfeits and the Discriminator has turned into a Master Detective looking for the slightest mistakes.\n\nAt the point when both networks are sufficiently trained so that humans are impressed by the fake images, we can use the fake images for whatever purpose we want.\n\nOur Spongebob metaphor only goes so far in helping actually build a GAN. To actually implement one, we need to get a little more formal. The generator (G) and discriminator (D) are both feedforward neural networks which play a min-max game between one another. The generator takes as input a vector of random numbers (z), and transforms it into the form of the data we are interested in imitating (G(z)). The discriminator takes as input a set of data, either real (x) or generated (G(z)), and produces a probability of that data being real (P(x)). We would have the objective function min_G max_D L_GAN(G,D)\n\nThe discriminator is optimized in order to increase the likelihood of giving a high probability to the real data and a low probability to the generated data. max(log(p(x_i)+log(1-p(x\u2019_i))). Because p(x_i) in (0, 1] so the log(p(x_i)) is negative, in the code, we define loss_d =reduced_mean(-log(p(x_i)-log(1-p(x\u2019_i))), so we just need the optimizer to find the lowest possible loss.\n\nThe generator is then optimized in order to increase the probability of the generated data being rated highly. min(log(1-P(x\u2019_i))). In code, this is equivalent to define loss_g =reduce_mean(-log(p(x\u2019_i)).\n\nBy alternating gradient optimization between the two networks using these expressions on new batches of real and generated data each time, the GAN will slowly converge to producing data that is as realistic as the network is capable of modeling. If you are interested, you can read the original paper introducing GANs here for more information.\n\nA more and complete explanation is available here.\n\nCheck out the DCGAN for converting deep neural network into the adversarial models.\n\nHowever, although we have a sketchy idea how does GAN works and how to make up a DCGAN, the training process is still very difficult. Not a lot of paper has told you what do you specifically need to expect of the generator and the discriminator\u2019s loss change.\n\nThe possible training loss graph of generator and semgentor is at the beginning, both networks\u2019 loss will decrease. As time goes by, before the equilibrium, the direction of the loss change is counterpart. Finally both of them could get equilibrium (stable), and the p_real and p_fake is going to keep around 0.5.\n\nSometimes you can see the generated images seems all the same no matter what input you gave. Which means the generator is just to generate the mean distribution of the real data, this happened in the face synthesis. From my understanding, this is because the faces are quite similar since they all belong to the same categories. We can try to decrease the learning rate for this problem. Other ways we can try is early stopping and a more appealing solution is to address the problem directly by giving the discriminator the ability to examine multiple examples at once.\n\nFor example, when I was using Conditional Adversarial Autoencoder, the learned latent vector Z from the original images is a very narrow distribution.\n\nFor the with dz: and learning rate to be 0.0002, 2*10^-4.\n\nIn TensorFlow that translates to something like:\n\nWe implemented the proposed minibatch discrimination technique to see if it would help with the collapse of the generator output distribution in our toy example. The new behaviour of the generator network during training is shown below.\n\nWhen you get trash images what could potentially be happening is that either the Discriminator or the Generator has become overpowered, the nash equilibrium has collapsed.\n\nThe other network is then unable to improve as there is no varying gradient to guide it.\n\nThe most intuitive way to enforce nash equilibrium(i.e. a constantly fair game for both networks) is to only update the current worst of the two networks at each iteration, in exchange for this throwing away of half of your potential weight updates you ensure that neither of the two networks can become too powerful. Why cant we get the nash equilibrium by finetune it? This could be useful for tasks that we could come up with a explicit loss function and\n\nAnother potential way of enforcing nash equilibrium that has not been explored is having multiple D and G networks where each network\u2019s score is a weighed sum of its performance against all of its adversaries. Aside from being bigger and more interesting than standard GAN it will be harder for nash equilibrium to fall as all of a network\u2019s adversaries have to become overpowered before gradient variation vanishes."
    },
    {
        "url": "https://medium.com/@lisulimowicz/regularization-in-deep-neural-network-training-5d3f8eb09e95?source=user_profile---------58----------------",
        "title": "Regularization in Deep Neural Network Training \u2013 Li Yin Sulimowicz \u2013",
        "text": "These methods do not confer a significant reduction in a model\u2019s vulnerability to adversarial examples\n\nIt was recently revealed that neural networks are easily tricked by adversarial examples. In the example below, the image on the left is correctly classified as a goldfish. However, if we apply the noise pattern shown in the middle, resulting in the image on the right, the classifier becomes convinced this is a picture of a daisy. The image is from Andrej Karpathy\u2019s blog post \u201cBreaking Linear Classifiers on ImageNet\u201d, and you can read more about it there.\n\nThe noise pattern isn\u2019t random though \u2014 the noise is carefully calculated, in order to trick the network. But the point remains: the image on the right is clearly still a goldfish and not a daisy.\n\nApparently strategies like ensemble models, voting after multiple saccades, and unsupervised pretraining have all failed against this vulnerability. Applying heavy regularisation helps, but not before ruining the accuracy on the clean data.\n\nIan Goodfellow presented the idea of training on these adversarial examples. They can be automatically generated and added to the training set. The results below show that in addition to helping with the adversarial cases, this also improves accuracy on the clean examples.\n\nFinally, we can improve this further by penalising the KL-divergence between the original predicted distribution and the predicted distribution on the adversarial example. This optimises the network to be more robust, and to predict similar class distributions for similar (adversarial) images."
    },
    {
        "url": "https://medium.com/@lisulimowicz/tensorflow-cpus-and-gpus-configuration-9c223436d4ef?source=user_profile---------59----------------",
        "title": "TensorFlow CPUs and GPUs Configuration \u2013 Li Yin Sulimowicz \u2013",
        "text": "I try to load two neural networks in TensorFlow and fully utilize the power of GPUs. However, my GPUs only have 8GBs memory, which is quite small. So I need to use GPUs and CPUs at the same time. This article is mainly training to resolve this problem.\n\nAt first, basics about the resource configuration.\n\nTo find out which devices your operations and tensors are assigned to, create the session with configuration option set to .\n\nYou should see the following output:\n\nIf you would like a particular operation to run on a device of your choice instead of what\u2019s automatically selected for you, you can use to create a device context such that all the operations within that context will have the same device assignment.\n\nYou will see that now and are assigned to .\n\nBy default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to ) visible to the process. This is done to more efficiently use the relatively precious GPU memory resources on the devices by reducing memory fragmentation.\n\nIn some cases it is desirable for the process to only allocate a subset of the available memory, or to only grow the memory usage as is needed by the process. TensorFlow provides two Config options on the Session to control this.\n\nThe first is the option, which attempts to allocate only as much GPU memory based on runtime allocations: it starts out allocating very little memory, and as Sessions get run and more GPU memory is needed, we extend the GPU memory region needed by the TensorFlow process. Note that we do not release memory, since that can lead to even worse memory fragmentation. To turn this option on, set the option in the ConfigProto by:\n\nThe second method is the option, which determines the fraction of the overall amount of memory that each visible GPU should be allocated. For example, you can tell TensorFlow to only allocate 40% of the total memory of each GPU by:\n\nThis is useful if you want to truly bound the amount of GPU memory available to the TensorFlow process.\n\nIf you have more than one GPU in your system, the GPU with the lowest ID will be selected by default. If you would like to run on a different GPU, you will need to specify the preference explicitly:\n\nIf the device you have specified does not exist, you will get :\n\nIf you would like TensorFlow to automatically choose an existing and supported device to run the operations in case the specified one doesn\u2019t exist, you can set to in the configuration option when creating the session.\n\nIf you would like to run TensorFlow on multiple GPUs, you can construct your model in a multi-tower fashion where each tower is assigned to a different GPU. For example:\n\nYou will see the following output.\n\nIt looks like we need the multi-tower fashion. CIFAR-1o is a good example. The reason CIFAR-10 was selected was that it is complex enough to exercise much of TensorFlow\u2019s ability to scale to large models.\n\nModern workstations may contain multiple GPUs for scientific computation. TensorFlow can leverage this environment to run the training operation concurrently across multiple cards.\n\nTraining a model in a parallel, distributed fashion requires coordinating training processes. For what follows we term model replica to be one copy of a model training on a subset of data.\n\nNaively employing asynchronous updates of model parameters leads to sub-optimal training performance because an individual model replica might be trained on a stale copy of the model parameters. Conversely, employing fully synchronous updates will be as slow as the slowest model replica.\n\nIn a workstation with multiple GPU cards, each GPU will have similar speed and contain enough memory to run an entire CIFAR-10 model. Thus, we opt to design our training system in the following manner:\n\nHere is a diagram of this model:\n\nNote that each GPU computes inference as well as the gradients for a unique batch of data. This setup effectively permits dividing up a larger batch of data across the GPUs.\n\nThis setup requires that all GPUs share the model parameters. A well-known fact is that transferring data to and from GPUs is quite slow. For this reason, we decide to store and update all model parameters on the CPU (see green box). A fresh set of model parameters is transferred to the GPU when a new batch of data is processed by all GPUs.\n\nThe GPUs are synchronized in operation. All gradients are accumulated from the GPUs and averaged (see green box). The model parameters are updated with the gradients averaged across all model replicas.\n\nPlacing operations and variables on devices requires some special abstractions.\n\nThe first abstraction we require is a function for computing inference and gradients for a single model replica. In the code we term this abstraction a \u201ctower\u201d. We must set two attributes for each tower:\n\nAll variables are pinned to the CPU and accessed via in order to share them in a multi-GPU version. See how-to on Sharing Variables.\n\nA good example is here: https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py\n\nCan try this out at first, see if it works."
    },
    {
        "url": "https://medium.com/@lisulimowicz/visualization-in-tensorflow-summary-and-tensorboard-86d5a12660e8?source=user_profile---------60----------------",
        "title": "Visualization in TensorFlow: Summary and TensorBoard",
        "text": "This article is going to discuss some basic methods and functions in tensorflow used to visualize and monitor the training process. I believe visualization is top priority for the research. Because the deep learning itself is a \u201cblack box\u201d. So, if the visualization could help us analyze why the final result is successful or failed. My another article will address the summary with more specific usages.\n\nThe visualization tool in Tensorflow is TensorBoard. The following introduction of TensorBoard is from the official website.\n\nIf we are running tensorflow using remote ssh, ssh -L 16006:127.0.0.1:6006 olivier@my_server_ip, then go to local brower: http://127.0.0.1:16006/.\n\nWhen looking at TensorBoard, you will see the navigation tabs in the top right corner. Each tab represents a set of serialized data that can be visualized."
    },
    {
        "url": "https://medium.com/machine-learning-for-li/a-walk-through-of-cost-functions-4767dff78f7?source=user_profile---------61----------------",
        "title": "A Walk-through of Cost Functions \u2013 Machine Learning for Li \u2013",
        "text": "This is one of the simplest and most effective cost functions that we can use. It can also be called the quadratic cost function or sum of squared errors.\n\nThe title pretty much spells out the equation for us:\n\nWe can see from this that first the difference between our estimate of y and the true value of y is taken and squared. This square isn\u2019t there for no reason, as it allows are result to be quadratic.\n\nYou may know that a quadratic function when plotted will always have a sort of \u2018u\u2019 shape making it convex, like so:\n\nThis shows us that in the future when we need to use something like gradient descent, we won\u2019t run into the major problem of getting stuck in a local optimum.\n\nWe then sum each of the results and find the average.\n\nLets say we have the following dataset and want to predict the following label \u2018happiness_scale\u2018:\n\nWe run the features through our neural network (the specifics are unimportant for now), and we get the following estimates of our labels:\n\nThese estimates look pretty wrong to me, but how wrong exactly? Lets use the mean squared error to tell us how wrong our neural network actually is:\n\nThis can guide us in our gradient descent process which will eventually reduce the cost function to its minimum.\n\nThis means that our neural network would be able to accurately predict the answers if we give it the same data and hopefully predict them if we give it data it hasn\u2019t seen before.\n\nGradient descent isn\u2019t something I want to go into too much detail about today in terms of the mathematics and how it\u2019s performed, but I will in the near future in a different post.\n\nAs mentioned above, if you want to learn more about gradient descent then I have provided some resources at the end of this article!\n\nThis cost function originally stems from information theory with the transfer of bits and how much bits have been lost in the process.\n\nWe can define cross entropy as the difference between two probability distributions p and q, where p is our true output and q is our estimate of this true output.\n\nThis difference is now applied to our neural networks, where it is extremely effective because of their strong usage of probability.\n\nWe can see above that p is compared to log-q(x) which will find the distance between the two.\n\nCross entropy will work best when the data is normalized (forced between 0 and 1) as this will represent it as a probability. This normalization property is common in most cost functions.\n\nWe should also note another common cost function used that is very similar to cross entropy, called KL Divergence. In fact, it\u2019s pretty much a mutated cross entropy, and can also be referred to as relative entropy:\n\nThe KL divergence will still measure the difference between probability distributions p and q.\n\nHowever, the difference to note is that in information theory it focuses on the extra number of bits needed to encode the data.\n\nThis means that when applied to our data, the KL divergence will never be less than 0. It is only equal to 0 if p = q. Also note that the KL divergence is not a distance, whereas the cross entropy is.\n\nThe function is called the hinge loss function. It is equal to 0 when . Its derivative is if and 0 if . It is not differentiable at . but we can still use gradient descent using any subderivative at t=1."
    },
    {
        "url": "https://medium.com/@lisulimowicz/commonly-used-activation-functions-9821ed348217?source=user_profile---------62----------------",
        "title": "Commonly used activation functions \u2013 Li Yin Sulimowicz \u2013",
        "text": "This article is directly from http://cs231n.github.io/neural-networks-1/\n\nEvery activation function (or non-linearity) takes a single number and performs a certain fixed mathematical operation on it. There are several activation functions you may encounter in practice:\n\nUp: Sigmoid non-linearity squashes real numbers to range between [0,1]\n\nDown: The tanh non-linearity squashes real numbers to range between [-1,1].\n\nSigmoid. The sigmoid non-linearity has the mathematical form \u03c3(x)=1/(1+e\u2212x)\n\nand is shown in the image above on the left. As alluded to in the previous section, it takes a real-valued number and \u201csquashes\u201d it into range between 0 and 1. In particular, large negative numbers become 0 and large positive numbers become 1. The sigmoid function has seen frequent use historically since it has a nice interpretation as the firing rate of a neuron: from not firing at all (0) to fully-saturated firing at an assumed maximum frequency (1). In practice, the sigmoid non-linearity has recently fallen out of favor and it is rarely ever used. It has two major drawbacks:\n\nTanh. The tanh non-linearity is shown on the image above on the right. It squashes a real-valued number to the range [-1, 1]. Like the sigmoid neuron, its activations saturate, but unlike the sigmoid neuron its output is zero-centered. Therefore, in practice the tanh non-linearity is always preferred to the sigmoid nonlinearity. Also note that the tanh neuron is simply a scaled sigmoid neuron, in particular the following holds: tanh(x)=2\u03c3(2x)\u22121\n\nUp: Rectified Linear Unit (ReLU) activation function, which is zero when x < 0 and then linear with slope 1 when x > 0. Down: A plot from Krizhevsky et al. (pdf) paper indicating the 6x improvement in convergence with the ReLU unit compared to the tanh unit.\n\nReLU. The Rectified Linear Unit has become very popular in the last few years. It computes the function f(x)=max(0,x). In other words, the activation is simply thresholded at zero (see image above on the left). There are several pros and cons to using the ReLUs:\n\nLeaky ReLU. Leaky ReLUs are one attempt to fix the \u201cdying ReLU\u201d problem. Instead of the function being zero when x < 0, a leaky ReLU will instead have a small negative slope (of 0.01, or so). That is, the function computes f(x)=\ud835\udfd9(x<0)(\u03b1x)+\ud835\udfd9(x>=0)(x)where \u03b1 is a small constant. Some people report success with this form of activation function, but the results are not always consistent. The slope in the negative region can also be made into a parameter of each neuron, as seen in PReLU neurons, introduced in Delving Deep into Rectifiers, by Kaiming He et al., 2015. However, the consistency of the benefit across tasks is presently unclear.\n\nLeaky ReLUs allow a small, non-zero gradient when the unit is not active.\n\nMore like Parameter ReLUs, it makes the coefficient of leakage into a parameter that is learned along with the other neural network parameters.\n\nMaxout. Other types of units have been proposed that do not have the functional form f(wTx+b)\n\nwhere a non-linearity is applied on the dot product between the weights and the data. One relatively popular choice is the Maxout neuron (introduced recently by Goodfellow et al.) that generalizes the ReLU and its leaky version. The Maxout neuron computes the function max(wT1x+b1,wT2x+b2). Notice that both ReLU and Leaky ReLU are a special case of this form (for example, for ReLU we have w1,b1=0). The Maxout neuron therefore enjoys all the benefits of a ReLU unit (linear regime of operation, no saturation) and does not have its drawbacks (dying ReLU). However, unlike the ReLU neurons it doubles the number of parameters for every single neuron, leading to a high total number of parameters.\n\nThis concludes our discussion of the most common types of neurons and their activation functions. As a last comment, it is very rare to mix and match different types of neurons in the same network, even though there is no fundamental problem with doing so.\n\nTLDR: \u201cWhat neuron type should I use?\u201d Use the ReLU non-linearity, be careful with your learning rates and possibly monitor the fraction of \u201cdead\u201d units in a network. If this concerns you, give Leaky ReLU or Maxout a try. Never use sigmoid. Try tanh, but expect it to work worse than ReLU/Maxout."
    },
    {
        "url": "https://medium.com/@lisulimowicz/dcgan-79af14a1c247?source=user_profile---------63----------------",
        "title": "DCGAN \u2013 Li Yin Sulimowicz \u2013",
        "text": "DCGAN is a class of CNNs called deep convolutional generative adversarial networks, that have certain architectural constrains, and the paper demonstrated that DCGAN is a strong candidate for unsupervised learning. Because when the discriminator can distinguish the fake and real, features extracted could well represent the data itself. How about the generator? Let us see what the paper tells us.\n\nHistorical attempts to scale up GANs using CNNs to model images have been unsuccessful (Generate high-resolution images). After extensive model exploration the author in this paper identified a family of architectures that results in stable training across a range of datasets and allowed for training higher resolution and deeper generative models. The architecture guidelines for stable Deep Convolutional GANs:\n\nThe other basic about the structure is, the first layer of the GAN, which takes a uniform noise distribution Z as input, could be called fully connected as it is just a matrix multiplication, and the result is then shaped into a 4-dimensional tensor and used as the start of the convolution stack. For the discriminator, the last convolution layer is flattened and then fed into a single sigmoid output.\n\nMore details about the parameters and training of the network:\n\nOne common technique for evaluating the quality of unsupervised representation learning algorithms is to apply them as a feature extractor on supervised datasets and evaluate the performance of linear models fitted on top of these features.\n\nThe DCGAN is trained on Imagenet-1k and then use the discriminator\u2019s convolutional features from all layers, maxpooling each layers representation to produce a 4*4 spatial grid. These features are then flattened and concatenated to form a 28672 dimensional vector and a regularized linear L2-SVM classifier is trained on top of them. It has gained impressive performance, however, it still can do better.\n\nPrevious work has demonstrated that supervised training of CNNs on large image datasets results in very powerful learned features. Additionaly, supervised CNNs trained on scene classification learn object detectors. The authors demonstrated that an unsupervised DCGAN trained on a large image dataset can also learn a hierarchy of interesting features. Using guided backpropagation, it shows that the features learned by the discriminator activate on typical parts of a bedroom, like beds and windows.\n\nThis section is trying to explore the answers to question of what representations the generator learns.\n\nFrom the quality of the generated samples, it suggests that the generator learns specific object representations for major scene components such as beds, windows, lamps, doors, and miscellaneous furnitures. They conducted an experiment to remove windows from the generator.\n\nSo, they did a simple classification experiments (logistic regression, windows or not, inside the bounding box of the windows are positives, outside of it is negative) with features drawn from the second highest convolution layer. All feature maps with weights being positive were dropped from all spatial locations.\n\nThey showed that by averaging the Z vector generated for three examples showed consistent and stable generations that semantically obeyed the linear arithmetic. Including object manipulation and face pose.\n\nThis is to the knowledge of authors the first demonstration of the purely unsupervised models can learn to convincingly model object attributes like scale, rotation, and position."
    },
    {
        "url": "https://medium.com/@lisulimowicz/comparison-between-deep-learning-tools-42560e61a5d5?source=user_profile---------64----------------",
        "title": "Comparison between Deep Learning Tools \u2013 Li Yin Sulimowicz \u2013",
        "text": "If you are an AI engineer or a researcher, you would know the pain of choosing different DL tools, from caffe, mxnet, to tensorflow and so on. So I decided to gather their comparison here, it could be a very useful guidance. Because, in your research lifetime, you will deep on them only only about one, but multiple.\n\nCaffe is the flagship of deep learning libraries for both industry and research. It is the first successful open-source implementation with very solid but simple foundation. You do not need to know code to use Caffe. You define your network with a description files and train it.\n\nCaffe is good to do computer vision tasks, Caffe is not intended for other deep-learning applications such as text, sound or time series data. Like other frameworks mentioned here, Caffe has chosen Python for its API.\n\nMxNet is a machine-learning framework with APIs is languages such as R, Python and Julia which has been adopted by Amazon Web Services. Parts of Apple are also rumored to use it after the company\u2019s acquisition of Graphlab/Dato/Turi in 2016. A fast and flexible library, MxNet involves Pedro Domingos and a team of researchers at the University of Washington. In sum, in mxnet, it\u2019s probably true more academics port models\n\nThis paragraph is from http://www.erogol.com/comparison-deep-learning-libraries-years-use/. This is the library of my choice for many of my old projects (before torch), mostly due to run-time efficiency, really solid Python support and efficient GPU memory use.\n\nSome critics, MxNet mostly support Vision problems and they partially start to work on NLP architectures. You need to convert all data to their data format for the best efficiency, it slows the implementation time but makes things more efficient in terms of memory and hard-drive use. Still for small projects, it is a pain. You can convert your data to numpy array and use it but then you are not able to use extensive set of data augmentation techniques provided by the library.\n\nMxNet also supports mobile platforms with its densely packaged version. I experimented couple of times on Android. It gives acceptable run-times unless you keep the model size small. (Torch has similar support but it is not actively maintained).\n\nI decided to leave it due to three main reasons. It gives (by that time) insufficient support to RNN models which is important for NLP. It is a very flexible library but sometimes this flexibility makes simple things hard. Its computation is not consistent in different platforms and hardwares. The difference is subtle but such as in case of feature extraction in creates difference and degrades performance.\n\nHowever, Mxnet could be a great tool for computer vision person."
    },
    {
        "url": "https://medium.com/@lisulimowicz/dilated-convolutions-and-kronecker-factored-convolutions-b42ed58b2bc7?source=user_profile---------65----------------",
        "title": "Dilated Convolutions and Kronecker Factored Convolutions",
        "text": "It is already supported on Torch/Tensorflow.\n\nThese are my notes on an ICLR paper from this year:\n\nWhilst I wrote this note I also became aware of this paper:\n\nI think the two are related, but coming at the same thing from two different directions.\n\nThe key application the dilated convolution authors have in mind is dense prediction: vision applications where the predicted object that has similar size and structure to the input image. For example, semantic segmentation with one label per pixel; image super-resolution, denoising, demosaicing, bottom-up saliency, keypoint detection, etc.\n\nIn many such applications one wants to integrate information from different spatial scales and balance two properties:\n\nTo address this problem, people often use some kind of multi-scale convolutional neural networks, which often relies on spatial pooling. Instead the authors here propose using layers dilated convolutions, which allow us to address the multi-scale problem efficiently without increasing the number of parameters too much.\n\nA KxK convolution with stride S is the usual sliding window operation, but at every step you move the window by S elements. The elements in the window are always adjacent elements in the input matrix. For S=1, you have the standard convolution. For S>1 you obtain a down-sampling effect. You can also generalize this operation to 0<S<1 (fractionally strided convolution); in this case, you obtain an up-sampling effect.\n\nA D-dilated KxK convolution is different. It is even called \u201cconvolution with dilated filter\u201d, because it is equivalent to dilating the filter before to do the usual convolution. Dilating the filter means expanding its size filling the empty positions with zeros. In practice, no expanded filter is created; instead, the filter elements (the weights) are matched to distant (not adjacent) elements in the input matrix. The distance is determined by the dilation coefficient D. The image below shows how the kernel elements are matched to input elements in a D-dilated 3x3 convolution (when the center of the kernel is aligned to the center of the input matrix). Note that for D=1 you obtain the standard convolution.\n\nIn D-dilated convolution, usually the stride is 1, but nothing prevents you to use other strides.\n\nFor plain old convolution this would be ft\u2212\u03c4. In the dilated convolution, the kernel only touches the signal at every lth entry. This formula applies to a 1D signal, but it can be straightforwardly extended to 2D convolutions.\n\nWhat this figure doesn\u2019t really show is the parameter sharing and parameter dependencies across the receptive field (frankly, it\u2019s pretty hard to visualise exactly with more than 2 layers). The receptive field grows at a faster rate than the number of parameters, and it is obvious that this can only be achieved by introducing additional constraints on the parameters across the receptive field. The network won\u2019t be able to learn arbitrary receptive field behaviours, so one question is, how severe is that restriction?\n\nkernels that result from taking the Kronecker product of three random 3\u00d73 kernels:\n\nThese look somehow natural, at least to me. They look like pretty plausible texture patches taken from some pixellated video game. You will notice the repeated patterns and the hierarchical structure. Indeed, we can draw cool self-similar fractal-like filters if we keep taking the Kronecker product of the same kernel with itself, some examples of such random fractals:\n\nI would say these kernels are not entirely unreasonable for a ConvNet, and if you allow for multiple channels (C>1) they can represent pretty nice structured patterns and shapes with reasonable number of parameters.\n\nCompare these filters to another common technique for reducing parameters of convolution tensors: low-rank decompositions (see e.g. Lebedev et al, 2014). Spatially, a low-rank approximation to a square 2D convolution filter can be understood as subsequently applying two smaller rectangular filters: one with a limited horizontal extent and one with limited vertical extent. Here are a few random samples of 27\u00d727\n\nfilters with a rank of 1. These can be represented using the same number of parameters (27) as the Kronecker samples above.\n\nTo me, these don\u2019t look so natural. Notice also that for low-rank representations the number of parameters has to scale linearly with the spatial extent of the filter, whereas this scaling can be logarithmic if we use a Kronecker parametrisation. This is the real deal when using Kronecker products or dilated convolutions.\n\nHere is another cool illustration of the naturalness of the Kronecker approximation, taken out of the Kronecker layer paper:\n\nSo in general, parametrising convolution kernels as Kronecker-products seems like a pretty good idea. The dilated convolutions paper presents a more flexible approach than just Kronecker-factors. Firstly, you can add nonlinearities after each layer of dilated convolution, which would now be different from Kronecker products. Secondly, the Kronecker analogy only holds if the dilation factor and the kernel size are the same. In the paper the authors used a kernel size of 3and dilation factor of 2.\n\nThis dilated convolutions idea is pretty cool, and I think these papers are just scratching the surface of this topic. The dilated convolution architecture generalises Kronecker-factored convolutional filters, it allows for very large receptive fields while only growing the number of parameters logarithmically. [Zhou at al.] shows how you can use a similar idea in classification to achieve 3.6\u00d7parameter reduction with only 1drop of accuracy.\n\nThe composite kernels one obtains via Kronecker products look sensible and seem to have meaningful parameter-sharing assumptions (hierarchical organisation, self-similarity). Plus, the networks using only diluted convolutions are fully equivariant under translation, which is great for dense prediction applications.\n\nOn the negative side, CNNs have a problem at the edges of the image where the convolution needs to be padded. This often causes headaches in dense prediction. Dilated convolutions have an even bigger problem. I wonder how well these methods would do in applications like superresolution, particularly how well they would deal with borders of the image compared to the middle."
    },
    {
        "url": "https://medium.com/@lisulimowicz/region-based-convolutional-networks-for-accurate-object-detection-and-segmentation-243fe155406?source=user_profile---------66----------------",
        "title": "Region-based Convolutional Networks for Accurate Object Detection and Segmentation",
        "text": "In this paper, it tried to move from image classification to object detection as simply as possible. Since then, this design choice has proved valuable because R- CNNs are straightforward to implement and train (com- pared to sliding-window CNNs) and it provides a unified solution to object detection and segmentation.\n\nOur object detection system consists of three modules. 1) The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. 2) The second module is a convolutional network that extracts a fixed-length feature vector from each region. The third module is a set of class-specific linear SVMs. These steps seem very standard, nothing special.\n\nThey used category-independent region proposals. From objectness, selective search, category-independent and so on, While R-CNN is agnostic to the particular region proposal method, we use selective search to enable a controlled comparison with prior detection work.\n\nIt has used TorontoNet and OxfordNet, with 4096-dimensional feature vector extracted from each proposal.\n\nTo convert the region proposal to the fixed-size input, theywarp all pixels in a tight bounding box around it to the required size.\n\nAt test time, we run selective search on the test image to extract around 2000 region proposals (we use selective search\u2019s \u201cfast mode\u201d in all experiments). We warp each proposal and forward propagate it through the CNN in order to compute features. Then, for each class, we score each extracted feature vector using the SVM trained for that class. Given all scored regions in an image, we apply a greedy non-maximum suppression (for each class independently) that rejects a region if it has an intersection-over-union (IoU) overlap with a higher scoring selected region larger than a learned threshold."
    },
    {
        "url": "https://medium.com/@lisulimowicz/different-layers-in-caffe-8b49fd6fb493?source=user_profile---------67----------------",
        "title": "Different Layers In Caffe \u2013 Li Yin Sulimowicz \u2013",
        "text": "The purpose of this layer is to divide input values by their standard deviation in order to have a variance of approximately 1. This is used to avoid activations from saturating. If you reduce the learning rate to e.g. 0.0001 you should notice that your network is able to learn even without the scale layer.\n\nIt can do element wise SUM/MAX/PROD operation. You can also set coefficient to it\n\nWhen the kernel-size is 1 and the pad size is 0, M input channels and output channel is 1. It is weighted sum of M filters.\n\nWhen this happens, it might become the initialization of the convolutional layer is wrong, try to leave it to 0. Also, we can decrease the learning rate till it is not happening.\n\nThe parameter choice could be the follow. could be used to realized the dilation layer. The traditional deconvolution layer could be one subtype of dilation layer when this parameter is set to 1.\n\nIf using the transform_param, and you want to do data augmentation with semantic segmentation,which might has multiple data input layers, plus a label layer. Since the scale and mirror is doing randomly, there is no way to do it automatically using the original caffe. The choice could be: 1) Using python to write a separate data processing layer. 2) Add another layer in the caffe code, example could be https://github.com/kevinlin311tw/caffe-augmentation.\n\nAbout Resuming from the Snapshot State\n\nThe solver.prototxt is going to resume from the solverstate file. However, we can still do change in the prototxt file with the neural network parameters."
    },
    {
        "url": "https://medium.com/@lisulimowicz/cnn-model-residual-net-e82b6a0a379d?source=user_profile---------68----------------",
        "title": "CNN model -Residual Net \u2013 Li Yin Sulimowicz \u2013",
        "text": "Residual networks are easier to optimize and can still gain accuracy from considerably increased depth.It is especially helpful for image recognition, image detection, image localization, and segmentation.\n\nEvidence reveal that the network depth (16 to 60 layers) is of crucial importance.\n\nTime to ask a question, is learning better networks as easy as stacking more layers? One obstacle to answer it, is the notorious problem of vanishing/ exploding gradients, which hamper convergence from the beginning. This problem has been largely addressed by normalized initialization and intermediate normalized initialization layers, which enable networks with tens of layers to be capable of convergence.\n\nHowever, even if it would converge, we face another problem: degradation. With the network depth increasing, accuracy gets saturated and then degrades rapidly. Such degradation is not caused by overfitting, and adding more layers to a suitably deep model leads to higher training error.\n\nThe degradation indicates that not all systems are easy to optimize. The usual way to add more layers is: the added layers are identity mapping (F=2p+1?), and the other layers are copied from the learned shallower model. There might be a problem, that our current solvers on hand are unable to find solutions that are better than the solution before.\n\nThis paper tried to address the degradation problem by introducing a deep residual learning framework. Instead of using the identity mapping, this paper use a residual mapping. p.2: Formally, denoting the desired underlying mapping as H(x), we let the stacked nonlinear layers fit another mapping of F (x) := H(x) \u2212 x. The original mapping is recast into F(x)+x. We hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping. To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers. \u2014 Highlighted Jan 4, 2017\n\np.3: Let us consider H(x) as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers. (input x, output H(x), the original goal is to optimize the H(x))\n\nTo hypothesize that they can asymptotically approximate the residual functions, i.e., H(x) \u2212 x (assuming that the input and output are of the same dimensions). So rather than expect stacked layers to approximate H(x), we explicitly let these layers approximate a residual function F(x) := H(x) \u2212 x. The original function thus becomes F(x)+x. Although both forms should be able to asymptotically approximate the desired functions (as hypothesized), the ease of learning might be different.\n\nIt is kind of a normalization.\n\nThe back logic in this is that: If the optimal function is closer to an identity mapping than to a zero mapping, it should be easier for the solver to find the perturbations with reference to an identity mapping, than to learn the function as a new one. We show by experiments (Fig. 7) that the learned residual functions in general have small responses, suggesting that identity mappings provide reasonable preconditioning.\n\nWe adopt residual learning to every few stacked layers. A building block is shown in Fig. 2. Formally, in this paper we consider a building block defined as:\n\nHere x and y are the input and output vectors of the layers considered. The function F (x, {Wi }) represents the residual mapping to be learned. For the example in Fig. 2 that has two layers, F = W2\u03c3(W1x) in which \u03c3 denotes ReLU [29] and the biases are omitted for simplifying notations.\n\nThe operation F + x is performed by a shortcut connection(ReLU layer) and element-wise addition. We adopt the second nonlinearity after the addition (i.e., \u03c3(y), see Fig. 2).\n\nThe shortcut connections in Eqn.(1) introduce neither extra parameter nor computation complexity. This is not only attractive in practice but also important in our comparisons between plain and residual networks. We can fairly compare plain/residual networks that simultaneously have the same number of parameters, depth, width, and computational cost (except for the negligible element-wise addition).\n\nThe dimensions of x and F must be equal in Eqn.(1). If this is not the case (e.g., when changing the input/output channels), we can perform a linear projection Ws by the shortcut connections to match the dimensions:\n\nWe can also use a square matrix Ws in Eqn.(1). But we will show by experiments that the identity mapping is sufficient for addressing the degradation problem and is economical, and thus Ws is only used when matching dimensions.\n\nThe form of the residual function F is flexible. Experiments in this paper involve a function F that has two or three layers (Fig. 5), while more layers are possible. But if F has only a single layer, Eqn.(1) is similar to a linear layer: y = W1 x + x, for which we have not observed advantages.\n\nWe also note that although the above notations are about fully-connected layers for simplicity, they are applicable to convolutional layers. The function F(x,{Wi}) can represent multiple convolutional layers. The element-wise addition is performed on two feature maps, channel by channel.\n\nThe convolutional layers mostly have 3\u00d73 filters and follow two simple design rules: (i) for the same output feature map size, the layers have the same number of filters; and (ii) if the feature map size is halved, the number of filters is doubled so as to preserve the time complexity per layer. We perform downsampling directly by convolutional layers that have a stride of 2."
    }
]