[
    {
        "url": "https://blog.goodaudience.com/using-convolutional-neural-networks-for-image-segmentation-a-quick-intro-75bd68779225?source=user_profile---------1----------------",
        "title": "Using convolutional neural networks for image segmentation \u2014 a quick intro.",
        "text": "Lets say you have a convolutional layers which outputs a volume of size 7\u00d77\u00d7512 and this is followed by a FC layer with 4096 neurons i.e. the output of the FC layers is 1x4096 for a single image input.\n\nYou can replace this FC layer with a convolutional layer with filter size 7x7, padding of zero, stride of 1 and output depth of 4906. You can do a quick calculation to see that the output will simply be 1x1x4096, equivalent to the output of the FC layer.\n\nLets consider the a network architecture, which takes a 224 x 224 x 3 image and then uses a series of CONV, POOL and FC layers to reduce the image to an activations volume of size 1000 i.e. classification scores for 1000 object classes.\n\nIn the above architecture you can observe that the output of layer Conv5 is a volume of size 7x7x512. It is followed by 2 FC layers having 4096 neurons each. At the end of the 5th layer, the above architecture downsamples the input spatially by a factor of 2\u2075, making the final spatial size 224/2/2/2/2/2 = 7.\n\nWe can convert each of these three FC layers to CONV layers as described above:\n\nFor example, if 224x224 image gives a volume of size [7x7x512] \u2014 i.e. a reduction by 32, then forwarding an image of size 384x384 through the converted architecture would give the equivalent volume in size [12x12x512], since 384/32 = 12. Following through with the next 3 CONV layers that we just converted from FC layers would now give the final volume of size [6x6x1000], since (12\u20137)/1 + 1 = 6. Note that instead of a single vector of class scores of size [1x1x1000], we\u2019re now getting an entire 6x6 array of class scores across the 384x384 image.\n\nHow do you interpret this output of size 6x6x1000 for each image? One can think of each of the 6x6 slices as downsampled heatmap for each of the 1000 object classes!!! You can re-size this downsampled heatmap, using interpolation, to the size of the original image.\n\nYou can overlay this heatmap on top of the original image to observe the location of that object in the image. Above you can see one such heatmap for the class \u2018dog\u2019. If you would like to look at a code example for this, please have a look at this implementation.\n\nAlthough a good start, the heatmap produced using the technique described above is quite coarse. We need a way to efficiently upsample the coarse heatmap. This is where transposed convolutional layers come into play.\n\nTransposed convolution works exactly the opposite of a normal convolution, i.e. from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\nHere is an example of a transposed convolution which upsamples the input by 2x.\n\nThe input is 2x2 while the output is 4x4. This is achieved by heavily zero padding the input. This is just one of the ways to perform this upsampling. There are other transposed convolutional techniques, here is a good source on this \u2014 Transposed Convolution Arithmetic.\n\nYou can use such transposed convolutional layers to upsample the coarse heatmap to the size of the original input. Then you can train this neural network end to end so that it learns to output a pixel level segmented image. But how does the training label data look like?\n\nLets say you want to train such a network to segment the road area from given a image, like the one posted above. The label looks something like the image below.\n\nYou need to pre-process the label image so that each pixel value is equal to the object class number, so that you can use the softmax entropy loss function for training."
    },
    {
        "url": "https://medium.com/@subodh.malgonde/teaching-a-car-to-mimic-your-driving-behaviour-c1f0ae543686?source=user_profile---------2----------------",
        "title": "Teaching a car to mimic your driving behaviour \u2013 Subodh Malgonde \u2013",
        "text": "This post is about a very interesting project I did as a part of Udacity's Self Driving Car Nano Degree. The task was to train a car to drive by itself in a simulated environment (like a video game). The idea is to first use the simulator in the manual mode, where the simulator records data like camera images, steering angle, speed, etc. as you drive down the track. Then use this data to train a deep neural network to drive the car when provided with a new input feed from the cameras. To keep things simple only the steering angle needed to be predicted.\n\nIf you just want to jump straight to the demo video- here is the YouTube link.\n\nThe car is equipped with 3 cameras at the front. One each on the left, right and center. The left and right cameras point straight, along the length of the car.\n\nEach image is a 160 by 320 color image. Here are some sample images recorded by the cameras.\n\nAs you can imagine, if you record the training data driving through the center of the track, then most of your recorded steering angles will be close to zero. This data will have bias for driving straight. Since the training track has more left turns than right, it also had a slight bias for turing left.\n\nTo overcome this bias you could employ 2 approaches. One of the approach is to deliberately drive towards the edge of the track and record the data while you make the car recover to the center of the track. This requires high precision. One needs to ensure that only the recovery is recorded and not the part where you drive towards the edge. Sounds easy but is very difficult to execute in practice. I tried recording recovery data multiple times but could only manage to make the car wobble and veer off the track.\n\nThe other approach is to use the images from the left and right cameras to simulate recovery. You can do this because the left and right camera images are like parallel transformations of the car. The main idea being the left camera has to move right to get to the center, and right camera has to move left. So you could take the left camera image and add a constant value to steering (positive steering implies turing right) and do the opposite for the right camera image. The second approach is well demonstrated in this paper by NVIDIA. This approach is simple, can be implemented in code and it worked really well for me!\n\nOne of the issues with working on deep neural networks is that they require a lot of training data. For complex problems it could be millions of data points. When trained on a small data the network tends to overfit i.e. it fails to generalise the solution to new data. To get more data one could either record more training data by driving more laps on the track or generate new data by augmenting the existing data.\n\nThe first approach has its limitations since a human can only drive so many laps without introducing errors in the dataset. The second approach -augmentation- is simple, can be implemented in code and one can practically generate an infinite amount of training data. I have to thank this fantastic blog post for providing ideas for augmentation techniques for this problem.\n\nI used only 2 augmentation techniques, since they were sufficient for this problem:\n\nThe sub-image on the top left in the above image, is from the center camera. The one to its right is from the left camera with an adjusted steering angle. The one on the bottom left if the horizontally flipped version of the center camera, with its steering angle reversed. The last one is a brightness adjusted image (random brightness adjustment).\n\nI used a 5 layer neural network for this project. The technical details of my neural network and code can be found in this github repository.\n\nBefore starting this project I had imagined that I would need powerful hardware, with GPUs and lots of RAM, to train my neural network but as it turned out I could just use my Macbook to train it. It took only 15 minutes for my network to converge to a solution.\n\nHere is the video of the car driving itself on the track. The numbers you see on the right are the steering angles and throttle values sent by the code to the car.\n\nThe true test of a neural network is how well it performs on unseen data i.e. data not used in training. To evaluate this the simulator had a second track which was very different from the one used for training. It was darker, had slopes while the first track was more or less flat, had sharper turns and more right turns as compared to the first track. The network had never seen data from this track. However some of these differences were accounted for in the network due to image augmentation techniques described above.\n\nHere is a video of the car driving itself on the second track."
    },
    {
        "url": "https://medium.com/@subodh.malgonde/how-to-get-started-with-machine-learning-4edec16f5160?source=user_profile---------3----------------",
        "title": "How to get started with machine learning? \u2013 Subodh Malgonde \u2013",
        "text": "March 2016, there was a lot of buzz around Google\u2019s AlphaGo program taking on world champion Lee Se-dol at the game of Go, a board based game that I had no idea about. AlphaGo won a series of 5 games 4\u20131 against Se-dol. \u2018What is all the fuss about?\u2019, I thought to my programmer self, \u2018Code the rules of the game into a program and make the best possible decision on every move\u2019. But this was different. Go was considered to be one of the toughest games to teach to a computer. Computers match or surpass top humans in a wide variety of games: Othello, Scrabble, backgammon, poker, even Jeopardy. But not Go. As recently as 2014, the automation of expert-level Go remained one of AI\u2019s greatest unsolved riddles.\n\nApparently folks at Deep Mind, which developed AlphaGo and they were later acquired by Google, had trained a computer program to teach itself Go. They had apparently not explicitly coded the rules of the game into the program, but had programmed it to learn the game by trial and error. They called it deep reinforcement learning. This was considered to be a huge event. Everything sounded like rocket science to me.\n\nThere was a sudden surge in articles about artificial intelligence and machine learning. There was talk of super intelligent bots taking away all our jobs. Elon Musk even termed AI as the biggest existential threat to humanity!! Was it true? How had the world come to this? What else can be achieved through machine learning? Can I make use of it in my work? I had so many questions. Hence I resolved to teach myself sufficiently to be able to understand all this.\n\nDon\u2019t waste any time looking further and take this course on Coursera. It is a introductory level course on machine learning. Starting with linear regression, the course gradually introduces you to advanced machine learning topics. The course contents are divided in 10 `weeks`. Each \u2018week\u2019 has video lectures of about 2 hours and an assignment, which can take up to 3 hours to be done depending on your understanding of course materials . The course is self paced and you don\u2019t have to stick to the \u2018week\u2019 schedule. I completed the course in 2 weeks (I was not working and as a result I had a lot of free time).\n\nThe course is not mathematically rigorous and is only designed to give you a flavor of various machine learning algorithms and topics. However one could feel a bit lost without knowledge of linear algebra, statistics and probability. If you have studied these topics before you can quickly brush up your knowledge here\u2014 linear algebra review, probability review and statistics review. I had studied these topics as a part of my undergrad, which was 4 years prior to taking this course, and yet I could understand the course contents without revising these topics. I only occasionally needed to google some concepts from these topics.\n\nTo complete the assignments you would be using Octave or MATLAB. You will do fine if you have used either of these software packages before. Don\u2019t sweat if you haven\u2019t, the course only makes use of very basic functionality and you can quickly learn to use these from online tutorials. I had used MATLAB before (again while pursuing my undergrad) but I decided to use Octave since it is free.\n\nDefinitely. At least now everything doesn\u2019t sound like rocket science to me. I can understand research papers and publications. Blog posts and news articles make more sense to me. At the startup, where I am working, I have already deployed a binary classification system, based on supervised learning, in production. In the machine learning universe it is fairly \u201chello world\u201d-ish but it serves our purpose.\n\nThis question on Quora serves as a very useful guide on more advanced topics which can be pursued after the introductory course.\n\nIf you are a python developer and are interested in seeing the machine learning algorithms in action you can start with scikit-learn. Its an open source python library and provides a lot of machine learning algorithms out of the box. DataQuest has courses on using python for data science.\n\nIf you\u2019re interested in a career in data science, many people go on from the introductory machine learning course to take the Data Science specialization. According to Andrew Ng, the professor for this course, many students are successfully using this combination to start off data science careers.\n\nKaggle is a community for data scientists and hosts data science competitions. If you are not sure what project to work on, Kaggle competitions can be a great way to start. Before working on Kaggle competitions you will have to understand and learn things like exploratory data analysis, preparing and cleaning your data. DataQuest is a good place to get started with all this."
    },
    {
        "url": "https://medium.com/@subodh.malgonde/communication-between-components-in-android-part-1-79eca2fd7895?source=user_profile---------4----------------",
        "title": "Communication between components in Android \u2014 Part 1",
        "text": "This post was originally posted here.\n\nPassing data between various components in Android is one of the most common and cumbersome requirements in almost all projects. There can exist multiple components in an app that need to update their states based on changes happening elsewhere. At the very least one needs to exchange data between\n\nIn this post, I try and illustrate, through an example of a fragment to activity communication system, why the traditional methods ofInterface and listener patterns and calls to the containing activity via getActivity(), are messy, complicated and a downright maintenance nightmare.\n\nBoth the traditional methods of Interface and listener patterns and calls to the containing activity via getActivity(), create strong dependencies between components, making it difficult to change one part of the application without affecting another.\n\nThis blog post by Jake from Square describes the challenges of creating unmanageable dependencies with the current Android framework.\n\nThe listener pattern introduces boilerplate with its interface and activity implements interface declarations. Here is an illustration of the boilerplate introduced by the interface-listener pattern both in the activity as well as the fragment classes.\n\nActivity to fragment communication is butt ugly. One has to first find the fragment using the fragment manager, check if it is being shown or not and then call methods on that fragment.\n\nWhen it comes to passing data between fragments, things get out of hand really quickly. At the very least it involves dealing with the combined complexity of fragment to activity and activity to fragment communication.\n\nOne of the more common development scenarios is the use of a database. In such cases one wants the read/write to happen on a separate thread and updates on the UI to be done when the read/write has been completed. This would involve even more boilerplate if one uses AsyncTask, or worse, ones own thread management to perform the asynchronous operation.\n\nPublish/subscribe models, also known as pub-sub models, try to avoid this tight integration by relying on an event bus. An extremely detailed post describing the use of an event bus for communication is availableon github.\n\nPublishers are responsible for posting events in response to an action, while subscribers respond to these events. The event acts as an intermediary for exchanging information, isolating and minimizing the dependencies between each side. In this way, message buses create a communication pipeline that is intended to help make app codebases more maintainable and scalable.\n\nCommunication between components in the event bus pattern boils down to these four simple steps.\n\nIn a typical e-commerce application here\u2019s how one would go about using event bus for the simple case of adding items to cart.\n\nThere are many Android libraries that help you implement the event bus pattern. Some of the popular ones are EventBus, RxJava and Otto. At PepperTap we use EventBus, which we found the easiest to setup and use. The number of forks and number of people watching its repo on github gave us the confidence to go ahead with it.\n\nYou can read more about EventBus on their website or github project or this slideshow.\n\nIn Part 2 of this post, we\u2019ll illustrate the use of EventBus using a real world example from our very own Android app. Stay tuned."
    }
]