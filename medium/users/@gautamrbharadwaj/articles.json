[
    {
        "url": "https://hackernoon.com/generative-adversarial-networks-a-deep-learning-architecture-4253b6d12347?source=user_profile---------1----------------",
        "title": "Generative Adversarial Networks \u2014 A Deep Learning Architecture",
        "text": "Generative Adversarial Networks (GANs)Generative Adversarial Nets, or GAN, in short, are neural nets which were first introduced by Ian Goodfellow in 2014. The algorithm has been hailed as an important milestone in Deep learning by many AI pioneers. Yann Le Cunn (father of convolutional neural networks) told that GANs is the coolest thing that has happened in deep learning within the last 20 years. Many versions of GAN have since come up like DCGAN, Sequence-GAN, LSTM-GAN, etc.\n\nGANs are neural networks composed up of two networks competing with each other. The two networks namely generator \u2014 to generate data set and discriminator \u2014 to validate the data set. The goal is to generate data points that are similar to some of the data points in the training set. The following shows a picture where GANs were able to generate images based on the text caption. The algorithm was given a text \u201cA white bird with a black crown and yellow beak\u201d. And the GAN was able to generate the image by itself based on the text given.\n\nGANs have also been used in predicting future frames in a video\n\nApart from generating images GANs are also used to perform various abstract operations like removing of glasses from the image of a face, adding of glasses etc as shown below.\n\nThe above figure which demonstrates that GANs can learn a representation that separates the concept of gender from that of wearing glasses. If we begin with the representation of the concept of a man with glasses, then subtract the vector representing the concept of a man without glasses, and finally add the vector representing the concept of a woman without glasses, we obtain the vector representing the concept of a woman with glasses. The generative model correctly decodes all of these representation vectors to images.\n\nLet\u2019s take a simple example to relate how GANs work. Consider the scenario of what happened during demonetization in India, between a money counterfeiting criminal who has fake notes and the banks. What\u2019s the objective of the criminal and what\u2019s the objective of the banks in terms of counterfeited money? Let\u2019s enumerate:\n\nHere, we see we have a clash of interest. This kind of situation could be modeled as a minimax game in Game Theory. And this process is called Adversarial Process.\n\nGANs is a special case of Adversarial Process where the components (the IT officials and the criminal) are neural nets. The first net generates data and the second net tries to tell the difference between the real and the fake data generated by the first net. The second net will output a scalar [0, 1] which represents the probability of real data.\n\nThe basic idea of generative modeling is to take a collection of training examples and form some representation that explains where this example came from. Generative adversarial networks (GAN) is something where samples are generated rather than finding a function. There are two basic things that can be done with the generative model. One is to take a collection of points and infer a function that describes the distribution that generated them. The second way is to build a generative model which is to take a machine that observes many samples from a distribution and is able to create more samples from the same distribution.\n\nThe generator will try to generate fake images that fool the discriminator into thinking that they\u2019re real. And discriminator will try to distinguish between a real and a generated image. They both get stronger together until the discriminator cannot distinguish between the real and the generated images anymore. After this, the GANs will be able to produce realistic images.\n\nZhu and others (2016) developed an interactive application called interactive generative adversarial networks (iGAN). A user can draw a rough sketch of an image, and iGAN tries to produce the most similar realistic image. In this example, the user has scribbled a few green lines that iGAN has converted into a grassy field, and the user has drawn a black triangle that iGAN has turned into a detailed mountain. Applications that create art are one of many reasons to study generative models that create images. A video demonstration of iGAN is available in the following video.\n\nThe training process consists of sampling data from the training set after which we run the discriminator on those inputs. The discriminator is any kind of differentiable function that has parameters that we can learn with gradient descent. So we usually represent it as a deep neural network but in principle, it could be other kinds of models.\n\nWhen the discriminator is applied to images that come from the training set, its goal is to output a value that is near 1. Representing a high probability that the input was real rather that fake. But half the time we also apply the discriminator to examples that are in fact fake. In this case, we begin by sampling the vector z from the prior distribution. So z is essentially a vector of unstructured noise. It\u2019s a source of randomness that allows the generator to output a wide variety of different vectors. We then apply the generator function to the input vector z. The generator function is a differentiable function that has parameters that can be learned by the gradient descent similar to the discriminatory function.\n\nUsually, the generator will be represented as a deep neural network. After G is applied to z, we obtain a sample from the model. And ideally, this will resemble actual samples from the data set similar to that showed in the above examples. After the sample is obtained the discriminator function D is applied again. This time the goal of the discriminator D is to output a value D of G of z that is near to value 1. The discriminator wants to make value zero and the generator would like to make it to near 1. The discriminator would like to reject these samples as being fake, while the generator would like to fool the discriminator into thinking that they are real.\n\nIn simple words, the generator must ask for suggestions from the discriminator and intuitively, the discriminator tells how much to tweak each pixel in order to make the image a little bit more realistic.\n\nIn conclusion, GANs are generative models that use supervised learning to approximate an intractable cost function ( a function that minimizes the error). Also, it can simulate many cost functions including the one used for maximum likelihood. GANs are key ingredients to various algorithms which are able to generate compelling high-resolution samples from diverse image classes. Although there are algorithms that are like GANs like variational autoencoder, WaveNet etc, they have various disadvantages. In variational encoders the samples generated are poor in quality. In WaveNet even though the generated data quality is good, the time taken to synthesize is very high. For example to generate 1 second of audio signal the Variational auto-encodes takes 1 minute to synthesize the signal. So GANs have a serious advantage as compared to other algorithms. It\u2019s an amazing algorithm that is being used not only in images but also in cyber security and others."
    },
    {
        "url": "https://medium.com/@gautamrbharadwaj/generative-adversarial-networks-85900be25425?source=user_profile---------2----------------",
        "title": "Generative Adversarial Networks \u2013 Gautam Ramachandra \u2013",
        "text": "In Artificial Intelligence applications such as natural images, audio signals, speech signals, symbols etc the goal is to find the models that represent the probability distributions of these data. Hence the deep learning is a promising field that exactly helps us to do this in various applications as mentioned. These striking successes have primarily been based on the backpropagation and dropout algorithms, using piecewise linear units which have a particularly well-behaved gradient. Deep generative models have had less of an impact, due to the difficulty of approximating many intractable probabilistic computations. A new generative model estimation procedure known as Generative Adversarial Nets that sidesteps these difficulties is proposed.\n\nGenerative Adversarial Nets, or GAN, in short, are neural nets which was first introduced in a NIPS 2014 paper by Ian Goodfellow and others. The algorithm has been hailed as an important milestone is Deep learning by many AI pioneers. This paper has literally sparked a lot of interest in the adversarial training of neural net, proved by the number of citation of the paper. Later, many versions of GAN came up: DCGAN, Sequence-GAN, LSTM-GAN, etc.\n\nLet\u2019s consider the example of what happened during demonetization in India, between a money counterfeiting criminal who has fake notes and Income Tax department. What\u2019s the objective of the criminal and what\u2019s the objective of the Income Tax (IT) department in term of counterfeited money? Let\u2019s enumerate:\n\nGenerative Adversarial Nets (GAN), is a special case of Adversarial Process where the components (the IT officials and the criminal) are neural net. The first net generates data, and the second net tries to tell the difference between the real data and the fake data generated by the first net. The second net will output a scalar [0, 1] which represents a probability of real data.\n\nThe basic idea of generative modeling is to take a collection of training examples and form some representation of probability distribution that explains where this trending example came from. Generative adversarial networks (GAN) is something where samples are generated rather than finding a density function. There are two basic things that can be done with the generative model. One is to take a collection of points and infer a density function that describes the probability distribution that generated them as shown in the above figure. The second way is to build a generative model which is to take a machine that observes many samples from a distribution and then is able to create more samples from the same distribution. Below shows the architecture of GANs.\n\nThe generator will try to generate fake images that fool the discriminator into thinking that they\u2019re real. And the discriminator will try to distinguish between a real and a generated image as best as it could when an image is fed. They both get stronger together until the discriminator cannot distinguish between the real and the generated images anymore. It could do nothing more than guessing with a probability of 0.5 for both choices because the generator generates really realistic face images.\n\nThere are several ways that Generative models can be applied once they have many. For example, we could use a generative model to simulate possible futures of reinforcement learning. Another is that an agent that is able to imagine future states of the world, using a generative model can plan for the future by simulating many different ideas of plans that it could execute and testing as to which of them works as best as possible.\n\nZhu et al. (2016) developed an interactive application called interactive generative adversarial networks (iGAN). A user can draw a rough sketch of an image, and iGAN uses a GAN to produce the most similar realistic image. In this example, the user has scribbled a few green lines that iGAN has converted into a grassy field, and the user has drawn a black triangle that iGAN has turned into a detailed mountain. Applications that create art are one of many reasons to study generative models that create images. A video demonstration of iGAN is available in the following video.\n\nThe framework is that it has two models and they are adversaries of each other in the sense of game theory, there is a game that has well-defined payoff functions. And each of the two players tries to determine how they can get the most payoff possible. I mean game theory as equivalent to Nash Equilibrium, for example when you are in traffic, you stop for some time and other vehicles will go after which you can go so being in the traffic and wait is the is equilibrium point. Here both of them will have the maximum payoff and don\u2019t obstruct the traffic as opposed to traffic without traffic lights. So within this game there are two different networks, one of them is called the generator and it is the primary model for learning. The generator is the model that actually generates samples that are intended to resemble those that were in the training distribution. The other model is the discriminator. The discriminator is not necessary after the training process is completed. The basic idea of discriminator can be thought of as a tool that we use during training which can be discarded later. The role of the discriminator is to inspect a sample and say whether that sample looks real or fake.\n\nThe training process consists of sampling images or other kinds of data from the training set after which we run the discriminator on those inputs. The discriminator is any kind of differentiable function that has parameters that we can learn with gradient descent. So we usually represent it as a deep neural network but in principle, it could be other kinds of models. When the discriminator is applied to images that come from the training set, its goal is to output a value that is near one, representing a high probability that the input was real rather that fake. But half the time we also apply the discriminator to examples that are in fact fake. In this case, we begin by sampling the latent vector z from the prior distribution over latent variables. So z is essentially a vector of unstructured noise. It\u2019s a source of randomness that allows the generator to output a wide variety of different vectors. We then apply the generator function to the input vector z. The generator function is a differentiable function that has parameters that can be learned by the gradient descent similar to the discriminatory function. Usually, the generator will be represented as a deep neural network. After G is applied to z, we obtain a sample from the model. And ideally, this will resemble actual samples from the data set similar to that showed in the above examples. After the sample is obtained the discriminator function D is applied again and this time the goal of the discriminator D, is to output a value D of G of z, that is near one. The discriminator wants to make value zero and the generator would like to make it be near zero. Hence the discriminator would like to reject these samples as being fake, while the generator would like to fool the discriminator into thinking that they are real.\n\nAs explained in an intuitive way it can be thought of as something like counterfeiters trying to make money that looks realistic and the Income Tax (IT) department trying to correctly identify counterfeit money and reject it without accidentally rejecting the real money. As the two adversaries are forced to compete against each other the counterfeiters must become better and better if they want to fool the IT department.And eventually, they are forced to make counterfeit money that is identical to real money. The discriminator has to teach the generator by giving tweak suggestions to the generated data during the entire training process. While it also learns to be a better teacher overtime. They both get stronger together and hopefully reach an equilibrium. In conclusion, GANs are generative models that use supervised learning to approximate an intractable cost function and can simulate many cost functions including the one used for maximum likelihood. GANs are key ingredients to various algorithms which are able to generate compelling high-resolution samples from diverse image classes. Although there are algorithms that are like GANs like variational autoencoder, wavenets etc but then they have disadvantages like in variational encoders the samples generated are poor in quality and also in wavenets thought the generated data quality is good, the time taken to synthesize is very high. So GANs have a serious advantage as compared to other algorithms and it\u2019s an amazing algorithm that is being used not only in images but also in cyber security and others."
    },
    {
        "url": "https://medium.com/@gautamrbharadwaj/demystifying-deep-learning-62ce95a6550c?source=user_profile---------3----------------",
        "title": "Demystifying Deep Learning \u2013 Gautam Ramachandra \u2013",
        "text": "Machine learning models power the modern society from image recognition to recommendation in websites, from web searches to helping people navigate in short time. They are increasingly becoming popular and are a must in smartphones, cameras, automobiles etc. Traditional machine learning algorithms were limited in their ability to process raw data. For many decades the design of machine learning algorithms required hand coded and meticulous engineering with high expertise in various subjects.\n\nDeep learning is the branch of machine learning that allows computational models consisting of multiple layers to learn patterns of data with multiple levels of abstraction. These models have dramatically improved the efficiency in speech recognition, visual object recognition, object detection and many other domains including healthcare, drug discovery, computational neuroscience, and genomics. Deep learning discovers insatiable structures in large data sets by using algorithms such as backpropagation algorithm to indicate how the machine should change its internal parameters used to compute the representation in each layer from the representation in the previous layer. They have brought breakthroughs in the processing of images, videos, and audio.\n\nThe deep learning consists of neural network models that are based loosely on how we think brain works; it\u2019s an abstract version of the behaviour of the brain. An artificial neural network may have single of multiple inputs and outputs. The input is fed into the neural network consisting of many layers having multiple neurons and the output is given. Based on the output the network tries to learn by itself, here the learning is done by the weights present in the neurons. So these weights adjust itself after each iteration to satisfy the output. This is called learning; the neurons strengthen itself every time the predicted is different from the actual. In our Brain, the real neurons take in some combination of their inputs and decide to fire or not to fire and we call this as spikes. Here in Artificial Neural Networks, the neurons do emit a spike but instead gives out a real number value. The function of these neurons is the weighted sum of the inputs along with a bias. A bias is a function that is added to improve the neural network performance.\n\nNeural networks have been there from the 70s. There were invented in the early 70s but became popular in the late 80s but they became absolute in 90s when Dr. Marvin Minsky form MIT showed that the neural networks cannot learn the XOR output gate. The other major problems were the lack of computational power necessary to train large models meant neural nets couldn\u2019t be applied to larger problems on larger interesting data sets and there was a lack of large, interesting data sets. Pioneers of neural networks like Dr Rosenblatt, Dr Geoffrey Hinton, Dr Yann Le Cunn, Dr Yoshua Beningo, Dr David Rulehemart, Dr Andrew N G kept on working and made breakthroughs in the field. Dr. Hinton is known as the father of Artificial Neural Networks whose contributions were instrumental in designing algorithms such as back propagation, dropout, deep belief nets etc which we will be telling you about in our future posts.\n\nThe reason deep learning can be applied across such a diverse set of fields is because they have the same concepts or building block that can be applied to different areas such as audio, video, robotics, web searches etc. The most amazing part of the deep learning idea is that we don\u2019t have to tell what feature to learn, the neural nets themselves learn them. Like all machine learning algorithms there are three learning approaches, 1)Supervised Learning 2)Unsupervised Learning 3)Reinforcement Learning.\n\nFor example, we train a neural network model to learn Gandhiji image which is called training the network, then we show the neural network model a new set of images, which is known as test data and tell the network to recognise Gandhiji, the network identifies Gandhiji\u2019s images. This we call it as Supervised Learning.\n\nSometimes we will have multiple images of Gandhiji, say when you type in the google search as Gandhiji you get many photos of Gandhiji so how does the machine to group different Gandhiji photos under the name of Gandhiji. This is called clustering of data. When there are a group of images a centroid is taken and then images with same structures are grouped together. This is called Unsupervised Learning.\n\nThe other kind of learning is the Reinforcement Learning which is a reward-based learning. The output gets refined with respect to the rewards. For example when a robot tries to move its arm to target position (x,y), it might come to some position nearby (x1,y1), now for that position reward will be given based on its performance, and if it does not reach the target the reward will be less based on the distance between the target and the position of the arm. It is like scoring marks in the exam. If you solve an equation completely you will get the maximum marks and if you solve half the equation you get half the marks. Here reward is the marks. So based on the reward the arm keeps changing its position to reach the target position. Reinforcement learning takes a lot of data and time but they are currently the most advanced in learning methods. Reinforcement learning is used in Self Driving cars, chess playing robots.\n\nDeep learning uses the above learning models for different problems, depending on its objective and complexity.\n\nTensor flow Playground from Google gives you an interactive visualization of neural networks and Deep Learning. It gives an insight on how neural networks work. Below is the URL to unleash for the understanding of the power of neural networks. Tensorflow Playground."
    }
]