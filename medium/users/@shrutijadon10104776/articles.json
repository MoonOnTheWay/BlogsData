[
    {
        "url": "https://medium.com/@shrutijadon10104776/tutorial-transfer-learning-using-keras-98f2e98a5442?source=user_profile---------1----------------",
        "title": "Tutorial: Transfer Learning Using Keras \u2013 Shruti Jadon \u2013",
        "text": "Transfer learning refers to the technique of using knowledge of one domain to another domain.i.e. a Neural Network model trained on one data-set can be used for other data-set by fine-tuning the former network.\n\nIn this Tutorial, we will do Dog Breed Classification Task.\n\nThis is a function of several factors, but the two most important ones are the size of the new dataset (small or big), and its similarity to the original dataset (e.g. ImageNet-like in terms of the content of images and the classes, or very different). Dog Breed Classification Case is:\n\nNew dataset is small and somewhat similar to original dataset. Since the data is small, it is not a good idea to fine-tune the ConvNet due to overfitting concerns. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n\nLets Preprocess Data, make a label.csv file to keep track of id, breed and encoded value. Our Data Consists of 133 Classes.\n\nWe will use the VGG16 architecture, pre-trained on the ImageNet dataset. Because the ImageNet dataset contains several \u201cDog\u201d classes among its total of 1000 classes, this model will already have learned features that are relevant to our classification problem.\n\nWe don\u2019t need any form of pre-processing on our image data, that has been handled by preprocess_input function of VGG.\n\nIn fact, it is possible that merely recording the softmax predictions of the model over our data rather than the bottleneck features would be enough to solve our dogs breed classification problem well.\n\nIn this We were able to get around 92% Accuracy, which is far better than VGG16 Net.\n\nThis has improved very little accuracy, but have reduced loss. So, may be because we had small dataset, that\u2019s why we are not getting significant difference but if we had huge dataset we would have been able to get better accuracy and reduced loss.\n\nYou can find full code at this github repository:"
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092?source=user_profile---------2----------------",
        "title": "Introduction to Different Activation Functions for Deep Learning",
        "text": "The Idea of Neural Networks was first introduced way back in 1950s, but it wasn\u2019t until 2012 that they come to action. Even application of Optimization Algorithm(Gradient Descent) in 2006 by Hinton, wasn\u2019t giving good results, it was introduction and usage of Activation functions, which revolutionized Deep Learning Research.\n\nThere are various kind of Activation Functions that exists, and Some Researchers are still working on finding better functions, which can help networks to converge faster or use less layers etc. Lets go through each of them:\n\nThe Main Problem we face is because of Saturated Gradients, as the Function ranges between 0 to 1, the values might remain constant, thus the gradients will have very less values. Therefore, no change during gradient descent.\n\n2. Hyperbolic Tangent Activation Function(tanh): Hyperbolic Tangent also have the following properties:\n\ntanh can be considered as a good example in case when input>0, so the gradients we will obtain will either be all positive or negative, which can led to explosion or vanishing issue, thus usage of tanh can be a good thing.but this still faces the problem of Saturated Gradients.\n\n3. Rectified Linear Unit Activation Function (ReLU): ReLU is the most commonly used Activation Functions, because of its simplicity during backpropagation and its not computationally expensive. It has following properties:\n\n(b.) It converges faster than some other activation functions.\n\nBut we can face an issue of dead ReLU, for Example if:\n\n4. Leaky ReLU: Leaky ReLU can be used as improvement over ReLU Activation function. It has all properties of ReLU, plus it will never have dead ReLU problem.\n\nWe can consider different multiplication factor to form different variations of Leaky ReLU.\n\n5. ELU(Exponential Linear Units): ELU is also a variation of ReLU, with better value for x<0. It also have same properties as ReLU along with:\n\n(b.) Closer to Zero mean Outputs than Leaky ReLU.\n\n(c.) More Computation because of Exponential Function.\n\n6. Maxout: Maxout has been introduced in 2013. It has property of Linearity in it. So, it never saturates or die. But is Expensive as it doubles the parameters.\n\n7. KAFNETS: Most neural networks work by interleaving linear projections and simple (fixed) activation functions, like the ReLU function. A KAF is instead a non-parametric activation function defined as a one-dimensional kernel approximator:\n\nKAFNETS (Link) gives promising Results, we have tested them for One shot Learning as mentioned in Article.\n\nMostly, Neural Networks go for different variations of RELU for its simplicity and easy computation both during forward and backward. But, in certain Cases Other Activation Functions gives us better results, Like Sigmoid is used at end layer, when we want our outputs to be squashed between [0,1], or tanh is being used in RNNs and LSTMs."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/how-to-initialize-weights-in-neural-networks-4081486ec09e?source=user_profile---------3----------------",
        "title": "How to Initialize Weights in Neural Networks? \u2013 Shruti Jadon \u2013",
        "text": "Weight Initialization is an important step in Neural Networks, It can make Network to converge faster, and make better predictions. There are some methods that exists, and has been implemented by Deep Learning Libraries as well, but the question still remain, which one to use? as sometimes we don\u2019t have cost and time to experiment with everything.\n\nOne can also think of initializing weights with random uniform initialization as: W=0.01*np.random.random(D,H), centered at 0.\n\nWorks ~okay for small networks, but can lead to non-homogeneous distributions of activation across the layers of a network.\n\n2. Random Normal Initialization: In this we initialize the weights of the neurons to small numbers in symmetric fashion. The idea is that the neurons are all random and unique in the beginning, so they will compute distinct updates and integrate themselves as diverse parts of the full network. We use Gaussian Distribution varying from (-1,1), with mean=0, and deviation=0.1. With this formulation, every neuron\u2019s weight vector is initialized as a random vector sampled from a multi-dimensional Gaussian, so the neurons point in random direction in the input space.\n\nOne problem with the above approach is that the distribution of the outputs from a randomly initialized neuron has a variance that grows with the number of inputs. This can be solved via using Xavier Initialization.\n\n3. Xavier Initialization: It also helps signals reach deep into the network.\n\nXavier initialization makes sure the weights are proper, keeping the signal in a reasonable range of values through many layers.\n\n4. Lasange Initialization: This approach also deals with variance issue, but via using Uniform Distribution instead of Gaussian like Xavier do. Here,\n\nThis Method is mainly used for Sigmoid and Hyperbolic Tangent Layers. For RELU, Xavier works best."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/video-summarization-an-survey-of-existing-algorithms-10b92a53e0a8?source=user_profile---------4----------------",
        "title": "Video Summarization: An survey of existing algorithms",
        "text": "There are many Algorithms that exists in market, which claim to summarize videos. In this blog, I will go through some of common methods that are used, and discuss outcomes that are obtained.\n\nCode to this, can be obtained at Github Repository.\n\nFor this project I used both keyframe extraction Methods. For static keyframe extraction, we extract low level features using uniform sampling, image histograms, SIFT and image features from Convolutional Neural Network (CNN) trained on ImageNet. We also use different clustering methods including K-means and Gaussian clustering. We use video skims around the selected keyframes to make the summary fore fluid and comprehensible for humans. We take inspiration from the VSUMM method which is a prominent method in video summarization."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/how-to-write-application-for-grace-hopper-scholarship-d6417c062d0d?source=user_profile---------5----------------",
        "title": "How to write application for Grace Hopper Scholarship.",
        "text": "I was chosen as one of Anita Borg Institute Grace Hopper Scholar for 2017 conference. It was a good feeling, but it required some effort to make your application stand out. [If you are not aware of ABI Grace Hopper Scholorship, please click on link]\n\nHere, In this blog I will discuss how to write application for ABI GHC scholarship. There are few points that your statement of purpose should have:\n\nIncluding this, I also wrote some issues I faced being a women in tech, such as being the only women in team.\n\nThe main thing, application reviewers see is how encouraged/dedicated you are towards your goal, and your enthusiasm to help your colleagues in field.\n\nAs part of application, you will be asked to submit 1 Letter of Recommendation, I will suggest to go for recent professor/experience one, as it will have more impact. Apart from this, write your resume showing your current work, GPA, Accomplishments so far, your research work, projects, with links provided. I will also suggest you to make a personal website, so as to make a good impression on reviewer.\n\nLast but not least, Enjoy!!! Its a good platform to get job opportunities, meeting accomplished women, feeling encouraged, plus speaking about what you have achieved so far.\n\nI hope everyone makes to it, and even if you don\u2019t get ABI GHC scholorship, there are plenty other options by companies such as Google, Microsoft, Facebook, Disney\u2026 just to name few. Apply to them.\n\n\u201cThose who try, never fails\u201d.\n\nALL THE BEST!!!!\n\nHere are some pictures of GHC17, in Orlando, Florida."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/why-we-dont-use-bias-in-regularization-5a86905dfcd6?source=user_profile---------6----------------",
        "title": "Why we don\u2019t use Bias in Regularization? \u2013 Shruti Jadon \u2013",
        "text": "Bias comes in to picture when we want our decision boundaries to be separated properly. just consider an example of\n\nwhen the values of X comes close to zero, there could be a case when its a tough deal to separate them, here comes bias into role.\n\nnow, via learning, the decision boundaries will be clear all the time.\n\nLet\u2019s consider why we use regularization now.\n\nSo that we don\u2019t over-fit, and smoothen the curve. As you can see the equation, its the slopes w1 and w2, that needs smoothening, bias are just the intercepts of segregation. So, there is no point of using them in regularization.\n\nAlthough we can use it, in case of neural networks it won\u2019t make any difference. But we might face the issues of reducing bias value so much, that it might confuse data points. Thus, its better to not use Bias in Regularization."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/gradient-descent-why-we-dont-use-on-bias-or-regularization-parameter-696507ad5335?source=user_profile---------7----------------",
        "title": "Gradient Descent and Some Doubts!!! \u2013 Shruti Jadon \u2013",
        "text": "While Studying Gradient Descent for Neural Networks, we always study about Regularization and then a lot of question arises. Why we chose this parameter only? So, when I was first introduced I had 2 questions in my mind.\n\nFirst, why we didn\u2019t use bias in regularization?\n\nWell, if we consider case of linear regression, we didn\u2019t took it, because if we do so, we will end up making bias almost equal to 0, and we took bias at first hand because we wanted to have better decision boundaries, and if we take bias in regularization, then we penalize the decision boundary separation too.\n\nSecond, why we don\u2019t determine Regularization parameter via gradient descent like we do for other parameters?\n\nSince the regularization term only adds the cost during learning, the optimal value of lambda under the MLE and MAP will be 0. One, thus need some other method to choose it\u2019s value. Under MAP, you are supposed to use prior knowledge. Under MLE, cross-validation methods are typically used to pick lambda to optimize an approximation to the generalization loss (not the training loss)."
    },
    {
        "url": "https://medium.com/@shrutijadon10104776/why-i-feel-sad-being-woman-in-tech-3de052ba4fa1?source=user_profile---------8----------------",
        "title": "How to do One Shot Learning using Siamese Networks?",
        "text": "Humans learn new things with a very small set of examples \u2014 e.g. a child can generalize the concept of a \u201cDog\u201d from a single picture but a machine learning system needs a lot of examples to learn its features. In particular, when presented with stimuli, people seem to be able to understand new concepts quickly and then recognize variations on these concepts in future percepts. Machine learning as a field has been highly successful at a variety of tasks such as classification, web search, image and speech recognition. Often times however, these models do not do very well in the regime of low data. \u2018\n\nThis is the primary motivation behind One Shot Learning; to train a model with fewer examples but generalize to unfamiliar categories without extensive retraining.\n\nOne-shot learning cane be used for object categorization problem in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training images.\n\nOne way of addressing problems in One Shot learning is to develop specific features relevant to the domain of the problem; features that possess discriminative properties particular to a given target task. However, the problem with this approach is the lack of generalization that comes along with making assumptions about the structure of the input data. In this project, we make use of an approach similar to while simultaneously evaluating different activation functions[KAFNETS] that may be better suited to this task. The overall strategy we apply is two fold; train a discriminative deep learning model on a collection of data with similar/dissimilar pairs. Then, using the learned feature mappings, we can evaluate new categories.\n\nSince One Shot Learning focuses on models which have a nonparametric approach of evaluation, we came across Kafnets(kernel based non-parametric activation functions) that have shown initial promise in this domain of training neural networks using different forms of activation functions; so as to increase non-linearity, therefore decreasing the number of layers, and increasing the accuracy in a lot of cases. This paper(https://arxiv.org/abs/1707.04035) has proposed two activation functions KAF and KAF2D, and focuses on their nature of continuity and differentiability. We have taken help of implementations of these activation functions and compared their effectiveness against traditional ones when used in the context of One Shot learning.\n\nFull Code can be found at my github respository here:\n\nWe tried to test Non-Linear Activation functions for datasets including MNIST and Face AT&T Dataset. We were able to see a huge difference in terms of clusters being formed at the end.\n\nWe Evaluated our results based on silhouette score, to see if our clusters have improved or not. Below are the actual statistics we obtained.\n\nThis project proves that a parametric machine learning algorithm can be converted to a non-parametric one, which can learn with fewer examples, with help of proper activation functions."
    }
]