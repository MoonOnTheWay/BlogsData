[
    {
        "url": "https://medium.com/synaptech/august-brings-exciting-news-for-synaptech-c9c7c52c452f?source=---------0",
        "title": "August brings exciting news for Synaptech | Innovators and leaders of the AI field are joining the\u2026",
        "text": "Synaptech continues the journey of building the newest AI community in Europe, one step at a time. Wishing to better understand the real applicability of Artificial Intelligence, we`ve gathered around our event brilliant minds from all over the world. We like to think that Synaptech will be a stepping stone, at least a small one, into the evolution of AI in Europe.\n\nAt the end of April, we announced the first Synaptech speakers, as a short glimpse into our upcoming event. All of them and many more, from passionate researchers, to innovative CEO`s and university professors will help to decipher and better understand the usage of Artificial Intelligence.\n\nDid you know that between 34% and 44% of global companies are using AI in their IT departments to resolve employees\u2019 tech support problems or enhance production? A survey on Harvard Business Review shows that by 2020 AI will be a crucial part in every company. Basically, AI will have the biggest impact on the back-office functions of IT and finance & accounting in over 50% of the companies that have already embedded AI into their business.\n\nAccording to Atomico\u2019s 2016 report on the state of technology, the European tech industry is increasingly focused on deep tech. If in September 2015 there were just 146 articles reporting on AI, just one year later the number rose to 1.112 mentions (almost 8 times higher). This shows an increased interest in the field of AI all around Europe.\n\nAs AI is expanding in an accelerated way, so we intend to do with our event. We invited leaders, professors and dedicated innovators to shed a light on the implications of AI in the real world. We are enthusiastic to announce:\n\nSebastian Wieczorek, Head of SAP Machine Learning Foundation. Sebastian is leading a team of data scientists and developers in Berlin, Walldorf and Singapore to build SAP\u2019s machine learning platform for delivering Application Intelligence.\n\nCyrus Moazami-Vahid, Principal Deep Learning Solutions Architect at Amazon. In the past 20 years, Cyrus has delivered innovative solutions with track-record of success stories mostly in entrepreneurial environment. In The past 3 years he has dedicated his work to generating Big Data initiatives and solutions.\n\nManuel Koelman \u2014 Co-Founder of PIRATE.global. In 2010, he launched \u201cThe Pirate Summit\u201d, Europe\u2019s largest invitation-only conference for early-stage startups, investors and corporate executives.\n\nAlexa Gorman, Global VP SAP.io Fund at SAP. With years of experience at SAP, Alexa has great experience in the fields of Corporate Strategy and Business Development\n\nArnaud Muller, Founder & CEO of Saagie. Muller founded Saagie, an end-to-end data platform that boosts your business with artificial intelligence in 2013.\n\nYou can find out more about the speakers joining Synaptech on our website.\n\nOn the first day of Synaptech we\u2019ve prepared four workshops. The first one, STM Networks in MXNet for sentiment analysis will be held by Cyrus Moazami-Vahid, Principal Deep Learning Solutions Architect at Amazon. This talk gives a general description of a network that provides sentiment analysis for IMDB movie reviews, network architecture, and implementation in Apache MXNet.\n\nOur goal is to discover and comprehend the newest AI developments. Thus, we\u2019ve also developed a startup competition, in partnership with Axel Springer Plug and Play, dedicated to AI-focused startups. Our call for subscriptions attracted 50 applicants from countries all over Europe: UK, Netherlands, Belarus, Poland, France, Norway, Israel and of course, Germany. Keep an eye on our Social Media channels to find out which startups will pitch on the Synaptech stage!\n\nWith just a little over a month until the event, this is the perfect moment to reserve your ticket. You can choose from three types of tickets: Basic \u2014 199.00 \u20ac, Premium \u2014 499 \u20ac and VIP \u2014 849 \u20ac.\n\nThe Basic ticket offers access to 2 out of 4 Machine Learning Workshops on September 21st. For a full Synaptech experience, try the Premium and VIP options. Both assure access to the Machine Learning Workshops, AI Startups Competition and Conference. This type of tickets will be available until 12.09.2017. Afterwards, the prices will rise for the \u201cLast Minute\u201d tickets: Basic \u2014 249.00 \u20ac, Premium \u2014 599 \u20ac and VIP \u2014 999 \u20ac.\n\nFind out more about Synaptech taking place between September 21 and 22, at K\u00fchlhaus Berlin by following us on Facebook and Twitter. For the latest news on speakers and tickets sign-up for the newsletter."
    },
    {
        "url": "https://medium.com/synaptech/understanding-algorithms-a-short-introduction-to-machine-learning-1d6cefd08e?source=---------1",
        "title": "Understanding algorithms: a short introduction to Machine Learning",
        "text": "Welcome, AI enthusiasts! Our series of articles, which we like to call \u201cAI for everyone\u201d, continues this week. Today, we chose Machine Learning.\n\nThe term \u201cMachine Learning\u201d has become so common in the field of AI, that most of the time people mistake it as a synonym for AI. But if we were to imagine AI as a vehicle, we could say that Machine Learning is more or less its engine.\n\nMachine Learning is a type of AI which enables software applications to become better at predicting outcomes, without programming them explicitly to do so. To receive the desired results, you have to build algorithms that can receive data and use statistical analysis to offer their output within a requested range of probabilities. For instance, if you want a program to tell you 10 dystopic scenarios based on 100 movies or books, it will do so.\n\nThere are two types of algorithms present in Machine Learning:\n\nMachine Learning is focused on Data, like any AI sub-type. Thus, ML searches through data and looks for patterns and adjusts its activity accordingly. To be more exact, do you know how when you are watching some new cool series, Netflix offers you another movie or series suggestion? Or when you are shopping, you can find new recommendations? Oh well, blame it on ML!\n\nAll of this is happening because recommendation engines use ML to personalize their ad delivery in real time. Apart from convincing you to buy new interesting stuff, Machine Learning is used for fraud detection, to filter spam, to identify any network security threat and also to build the newsfeed we all know and love (or not) on Facebook.\n\nThis is what Machine Learning means, on short. There are plenty of other things we could mention about it. If we missed something, please drop us a line on Twitter, Facebook or in a comment. And if you are passionate and you want to learn more about AI, register for Synaptech\u2019s hands-on Machine Learning workshops and conference where thriving thought leaders will share their experience with AI! More details you can find here.\n\nSee you next time in our newest article about Natural language processing!"
    },
    {
        "url": "https://medium.com/synaptech/from-sketches-to-photo-realistic-images-an-introduction-to-image-synthesis-d2b0ff4fb4da?source=---------2",
        "title": "From sketches to photo realistic images: an introduction to image synthesis",
        "text": "Hi there AI enthusiast! So glad you could join us! Here we gather the major terms in Artificial intelligence and try to define them as simple as possible. Today, we chose Image Synthesis as our next subject.\n\nWhat if you could become an artist in less time than it would require, let\u2019s say approximately 3 years? All you had to do is to make a simple sketch, press some buttons and then poof, you have created a piece of artwork. Does this sound Impossible? Not anymore.\n\nThanks to the great evolution of Computer Vision and all other cool algorithms that were developed afterward, AI is now slowly, but surely, learning how to design images, based on input. The process evolves with heavy steps, since the major problem with computers is the way they understand images, and also because human appreciation to what looks good is subjective and personal.\n\nNow, let\u2019s see a few of the algorithms that can help you turn your black and white sketch into a full image:\n\nThis can be achieved by a transformation of GoogLeNet architecture into a triplet network. Thus, it allows the network learn across both the sketch and the image domain, and also a shared feature space between the two.\n\nUsing deep Convolutional Neural Networks (dCNN) for more productive tasks, such as texture synthesis. They could be used with a VGG-19 network, to transform the texture features of the \u201cstyle\u201d image within each layer of the network into a set of Gram metrics whilst capturing high-level of the content image.\n\nAnother option is to use Generative Adversarial Networks. As we presented them in the past article, there are two networks, one that plays the role of creation and the other of the discriminator. Thus, if trained enough, they could be able to generate more accurate image than the dCNN one.\n\nThis type of method implies the use of generative Markov random field models, where dCNNs would work both for photorealistic and non-photorealistic image synthesis. Instead of using Gram matrices, the MRF maintains local patterns of the specified style, while using the same VGG-19 network, but trained only on images.\n\nSo, as we can see, image synthesis still has a long way to go. Or not, varying on each one\u2019s opinion. But AI makes great progresses and, maybe sooner than we expect, we could see a remake of Star Wars with puppies instead of Jedis. The entertainment industry will certainly have a bright future.\n\nWe will continue our series of cool AI-terms article next week with \u201cMachine Learning\u201d. Until then, drop us a line on Synaptech\u2019s Facebook or Twitter. See you!"
    },
    {
        "url": "https://medium.com/synaptech/counterfeits-beware-these-new-neural-networks-will-catch-you-37a7e73072ff?source=---------3",
        "title": "Counterfeits, beware! These new neural networks will catch you",
        "text": "Before we dive deep into the world of \u201cMachine Learning and the terms I never heard about and if I did, I may or may not know what they mean \u2014 just like Schrodinger\u2019s cat\u201d, we want to ask you a short question: do you think AI will prevail in every domain, even counterfeit? Let\u2019s picture this for a moment.\n\nImagine that you are a painter. Not any kind of painter, but one that is specialized into, how to put it gently, not creating new things, but forging things. Let\u2019s call you G. Now, imagine opposed to you, there is this guy, D, who is an art critic \u2014 a very talented one, that can spot a fake painting from miles away. Now, let\u2019s imagine you want to show him some of your \u201cMonet\u2019s\u201d.\n\nAt the beginning, G\u2019s whole purpose is to create fake Monets. Sometimes, D falls for them, sometimes he doesn\u2019t. But, as time passes by and D starts to see more and more original examples, he becomes better at detecting fakes. Since G starts having a harder time to, let\u2019s say, fool D, he has to become better. Thus, he slowly starts to provide better forges. On short, this is the idea behind Generative Adversarial Networks or GANs.\n\nGANs is a new type of generative model, which are a branch of unsupervised learning techniques in Machine Learning.\n\nGANs contains two networks that live in a constant conflict \u2014 thus the adversarial term, a generator (G) and a a discriminator (D). As in anything related to Machine Learning, GANs can be trained with examples, such as images, and there is an underlying distribution (x) that governs them. Thus, G will generate outputs \u2014 or create new stuff, and D will decide if they come from the same distribution of the training set or they are, you guessed, fake.\n\nGenerative Adversarial Networks are like this: G, will start from some noise (z), and the images it generates are G(z). D, on the other hand takes from the real images (x) and the fake ones, from G, and classifies them as D(x) and D(G(z)).\n\nWhat\u2019s interesting about them is that both are learning at the same time. Once you train G with enough input, it will know enough about the distribution and it will be able to generate new samples that share very similar properties. And as you train D, it will sense if the objects from the image are real or not.\n\nUntil the release of our next article, which will be about image synthesis, you can check our Facebook and Twitter accounts, where we will post other great things about AI. In case we have missed some important piece of info about GANs, do not hesitate to leave us a comment."
    },
    {
        "url": "https://medium.com/synaptech/will-computers-be-smarter-than-us-possible-through-deep-learning-e30c81e5b99?source=---------4",
        "title": "Will computers be smarter than us? Possible, through deep learning",
        "text": "Hi there, AI enthusiast! Long time, no see. We continue our series of \u201chey, I heard about this AI term, but I vaguely know what it means\u201d article series. The previous one was about Decision Tree and today\u2019s article is about Deep Learning.\n\nImagine that, at some point in life, scientists gather together to create the ultimate weapon to save humanity: an artificial brain. A product so complex that it can mimic everything a human brain can do, but it\u2019s artificial instead of organic.\n\nNow, dream no more! This whole concept is one step away from becoming real, through Deep Learning. Maybe more than a step away, more like a few. But, close, nonetheless.\n\nDeep learning is also known as deep structured learning or hierarchical learning, and it uses artificial neural networks, or ANNs for short. ANNs are basically nothing else but a pair of hidden layers, with a design inspired by the neurons in the central nervous system of our brain. For short, ANNs are nothing else but artificial neurons.\n\nArtificial Neural Networks are presented as a system of interconnected points, with the purpose of exchanging messages between each other. These connections carry numeric values, which can be tuned based on experience, thus becoming capable of learning.\n\nFor instance, as a biological neuron has dendrites, axons and synapses, an artificial one is composed of nodes, inputs, outputs and weights. For instance, like in this photo.\n\nYou can stack layers of neurons on top of each other. For example, the lowest layer takes the raw data \u2014 the background image. The next layer will find more details, since it can learn more data from the previous layer. And so on, until you re-create another image.\n\nHow will this help me in the future?\n\nLet\u2019s say you\u2019re a graphic designer and you really need to know all the hex codes presented in an image. Since your time is short and the idea of colour-picking every single pixel in the image is a hassle, you can design an ANN to pick them for you. All you have to do is to feed it with the raw image.\n\nIn the near future, ANNs will be able to pick different kind of datasets, such as raw text and numbers. If you are interested in learning how to develop Machine Learning algorithms, ANNs will prove to be useful in creating them.\n\nThis all about Deep Learning, for the moment. But our article series doesn\u2019t end here. Stay tuned for our next article about Generative Adversarial Networks. Meanwhile, if you are tempted to learn more about AI from thriving experts, reserve your ticket to the newest AI-conference based in Berlin, Synaptech!"
    },
    {
        "url": "https://medium.com/synaptech/decision-tree-the-smartest-tree-we-know-597746bfcbdb?source=---------5",
        "title": "Decision Tree \u2014 the smartest tree we know \u2013 Synaptech \u2013",
        "text": "AI enthusiasts, we have great news for you! Our article series based on Synaptech\u2019s glossary continues! Today\u2019s topic is Decision Tree, a tree unlike any other, while our latest was about Convolutional Neural Networks.\n\nA decision tree is a predictive algorithmic model that goes from the observations of an object (branches) to the conclusions about the object\u2019s value (leaves). Its purpose is to predict modelling approaches in statistics, data mining and machine learning.\n\nRegarding the types the decision tree is used, the way it is implemented can vary. For instance, for a decision analysis, the decision tree can be chose to represent in a visual and explicit manner the decisions, while in data mining, a decision tree describes data. In the resulting classification, the tree can be justified as an input for decision making.\n\nJust like any other ML algorithm, the decision tree has plenty of types. There are two main types managed in data mining:\n\nIf you want to add some details or share your opinion this algorithm, feel free to share them with us in a comment. Meanwhile, stay tuned for our next article about AI terms, Generative adversarial networks."
    },
    {
        "url": "https://medium.com/synaptech/do-you-have-an-ai-product-apply-to-synaptechs-startup-competition-6c40113a46ab?source=---------6",
        "title": "Do you have an AI product? Apply to Synaptech\u2019s Startup Competition!",
        "text": "AI enthusiasts, we have great news for you! Since Synaptech is an AI-focused event, addressed to the startup community, we added a new layer to help promoting the cool tech ecosystem from the region: an AI competition for startups who redefine innovation, in partnership with Axel Springer, Plug and Play.\n\nIf you have an AI-focused tech startup, we want to let you know that the application form is now live on F6S and the deadline for registration is August 16. The proper competition will take place in September 21\u201322, at K\u00fchlhaus, in Berlin.\n\nYou will have 4 minutes to pitch your product and 2 minutes for live demo, in front of investors, experts and VIP guests.\n\nBoth applications and pitching need to be in English.\n\nBe bold, be brave and apply!\n\nMore details will be added on our website, later on. For any question, feel free to e-mail us at contact@synaptech.ai or DM us on Twitter or Facebook."
    },
    {
        "url": "https://medium.com/synaptech/do-computers-silently-judge-your-photos-7203a99fa597?source=---------7",
        "title": "Do computers silently judge your photos? \u2013 Synaptech \u2013",
        "text": "Welcome, AI enthusiasts! For the fifth article in a series we like to call \u201cwhat\u2019s\u2019 up with all these AI and ML related terms\u201d, we will discuss Convolutional Neural Networks. CNNs are strongly linked to Computer Vision, which is the subject our previous article.\n\nConvolutional Neural Networks (or CNN) are mainly used for Image Classification and are the core of Computer Vision. With their help, technology has made major breakthroughs, such as allowing self-driving cars to analyze and predict pedestrians\u2019 movements. CNNs are also used for simpler tasks, such as Facebook\u2019s auto-tagging.\n\nConvolutional Neural Networks are comprised of convolutional layers, followed adjacently by connected layers \u2014 similar to a multilayer neural network. A CNN has the capability to understand 2D input, an image or a speech signal.\n\nThey are built with local connections, where each region of the input is connected to a neuron in the output. Because there are so many layers, each of them has a different filter and combine their result, or pooling (subsampling). What\u2019s even cooler about Convolutional Neural Networks is that in the training phase, they automatically learn the values of their filters on the task you want them to perform.\n\nFor instance, if you program a CNN to detect something inside an image, it will learn to detect the corners from raw pixels in the first layer, then use them to detect simple shapes in the second layer. Afterwards, in higher layers they use shapes to understand fine features, such as a facial shape in higher layers. The last ones act as classifiers that use these features.\n\nCNN has in composition two aspects worthy of your attention: Location Invariance and Compositionality. The easiest way to explain them is this: let\u2019s say you want to classify whether there is a tiger or not in an image. Since you are sliding your filters all over the image, you don\u2019t care where (location) in the image the tiger is positioned. Why? Because pooling does not change your composition when it translates, rotates or scales it, therefore it communicates the exact shape. Afterwards, each filter which helps composing the output, registers each pixel from the lower-level feature and transports it into the high-level representation (compositionality). Think about it as a very attentive Xerox that doesn\u2019t miss anything when it copies your paper.\n\nAll in all, a CNN helps Computer Vision to be more intuitive and to build shapes from corners and complex objects from shapes.\n\nHow can they be used?\n\nAs we have seen, CNN are at the core of Facebook\u2019s auto-tagging images. Of course, they can be used for more things, such as to analyze what beings and objects are in a photo, for educational, research or other purposes.\n\nIf you have this great idea of improving Machine Learning algorithms or if your startup does this already, book your seat for Synaptech this autumn. We have AI experts and a cool competition for startups, all in the same place. Also, you can stay tuned for our next article in the series: Decision Tree \u2014 a tree like no other."
    },
    {
        "url": "https://medium.com/synaptech/dystopian-or-not-computer-vision-will-help-humanity-38e7b465182d?source=---------8",
        "title": "Dystopian or not, Computer Vision will help humanity",
        "text": "The series of articles that describe AI-related terms continues! Previous article was written about Autoencoders, and today\u2019s one is about Computer Vision.\n\nDoes the thought of being watched by machines make you quiver? Knowing that out there, hiding beneath a tree\u2019s branch is a camera, recording every step you take, having knowledge of who you are and what you have done. It does seem like an adaptation of 1984 or other dystopian novels, but it might become reality through Computer Vision.\n\nFirst of all, don\u2019t worry and please don\u2019t start throwing rocks at software developers for implementing it. Although this is the dark side of it, Computer Vision will be helpful to humanity in the upcoming years. Until then, let\u2019s see what it is and what can it be used for.\n\nIt is the digitized version of the human vision. Computer vision is an algorithm that teaches a computer to reconstruct, interpret and understand a 3D scene from its 2D images as present structures in the scene. More exactly, how to tell the difference between a person, an animal and an object, through a camera lense, and it can be implemented in robots which are in the control of automatic lines and more.\n\nAlthough the human vision is difficult to replicate, because it needs to replicate the visual cortex, the retina and the brain itself, it is somehow limited to the visible spectrum, while the one generated on computer can see further. But, the main problem is some images might be noisy and not offer enough information.\n\nWhat and who are using it?\n\nWe know now what Computer vision is and on what basis its implementation can be made. But what companies do use it and on what exactly are they focusing the algorithm?\n\nEye tracking. What if you would have another eye in your own eye? Smart Eye offers that, a non-invasive eye, eyelid and head-tracking technology for a wide range of industries, but mostly for automotive, aviation and aerospace.\n\nObject Recognition. One cool startup that developed a software that can recognize thousands of categories, tags, objects and images is Clarifai. The technology\u2019s core is a deep learning API used in the development of a new generation of intelligent apps, including advertising, eCommerce and more.\n\nPeople tracking. There it is, the shiver down the spine. Sighthound\u2019s purpose is not to spy of humanity, but to be aware of the happening events. It can distinguish humans from objects and also has the ability of analyzing videos, in case of accidents, crimes, fights and more.\n\nMedical imaging. Mirada Medical\u2019s new development is changing the way diagnosis is offered through images. Their software is highly used in radiology, radiation oncology and other medical fields.\n\nFace recognition. Goodbye, door keys! Thanks to Chui, the intelligent IoT doorbell that uses facial recognition to offer a secure, keyless door, now you don\u2019t have to worry about getting locked outside.\n\nOther domains where Computer Vision can be used are agriculture, AR, autonomous vehicles, biometrics, forensics, industrial quality inspection, gesture analysis, image restoration, pollution monitoring, remote sensing, process control and security and surveillance.\n\nThe next article regarding Artificial Intelligence glossary terms is convolutional neural networks. Until then, you can be kept up-to-date with Synaptech\u2019s new speakers and other news, on our Twitter and Facebook account."
    },
    {
        "url": "https://medium.com/synaptech/from-applied-researchers-to-ceos-passionate-about-ai-a-glimpse-of-synaptechs-first-speakers-ec0794bbfd29?source=---------9",
        "title": "From applied researchers to CEOs passionate about AI: a glimpse of Synaptech\u2019s first speakers",
        "text": "From the brinks of university laboratories to becoming integrated in objects used in real life, Artificial Intelligence is going mainstream. Not in the pop culture per se, but because it grows into a widely-used technology and mundane objects are already influenced by it. Because there are new programs and developments that help humanity towards its evolution. Although AI is the hottest topic of the year, its development is still incipient.\n\nSynaptech is focused on the real applicability of Artificial Intelligence. Its aim is to connect the most prolific-AI based startups with investors around the world, and corporations to the latest innovation, in 21\u201322 September.\n\nA great event cannot take place without enlightened minds. Do you know what Jean-Francois Gagne, David Kelnar, Luming Wang, Friederike Sch\u00fc\u00fcr, Holger Weiss and Peter Yared have in common? Apart for being the first confirmed speakers for Synaptech, they are experts in the field of Artificial Intelligence, where they worked for years and nonetheless, they want to share their valuable experience with you.\n\nJean-Francois Gagn\u00e9 has co-founded with Yoshua Bengio, Element AI the world\u2019s biggest applied research lab that develops AI-first solutions and technology to solve company challenges and boost productivity. Being a seasoned entrepreneur, he also founded and successfully exited two AI and operations research companies.\n\nFriederike Sch\u00fc\u00fcr is the Director of Data Science at Fast Forward Labs, an applied machine intelligence and advising company in Brooklyn, NY. Their capabilities include diving into machine learning, building fully functioning prototypes exploring state-of-the-art technology and advising companies on how to get ready for the future (ML and AI).\n\nLuming Wang is the Head of Deep Learning at Uber where he leads the development of the world\u2019s leading Deep Learning platform, that supports Uber\u2019s rapid growth.\n\nHolger Weiss is the CEO of German AutoLabs and has 15 years track record in managing technology-driven companies with focus on consumer-centric services. Currently he is building an AI digital co-driver, in order to create a safer and smarter mobility experience.\n\nDavid Kelnar is the Investment Director & Head of Research at MMC Ventures, where he made an in-depth research on UK\u2019s AI startups landscape. He has 8 years of entrepreneurial leadership experience in early stage companies, and is an advisor to a range of early stage ventures.\n\nPeter Yared is the Founder & CTO at Sapho, the Google Now for the Enterprise. Previously, he was the CTO/CIO of CBS Interactive and the founder of 4 enterprise infrastructure companies. He is also the inventor of several patents on core Internet infrastructure including federated single sign on and dynamic data requests.\n\nDuring Synaptech, apart from the conference, where the presented thought leaders will discuss about the latest developments and share their valuable insights, you will also be able to attend hands-on machine learning workshops and an international competition, featuring AI startups with disruptive products.\n\nEmbark in the world of AI and book your ticket for Synaptech now! For our first attendees we have a special offer: 2 tickets at the price of 1, available until April 30."
    },
    {
        "url": "https://medium.com/synaptech/autoencoders-what-are-they-good-for-48bd21a49dc7",
        "title": "Autoencoders \u2014 what are they good for? \u2013 Synaptech \u2013",
        "text": "Hey there, AI enthusiasts! As you probably know already, we take each word from the glossary and define it. The definitions are written in such ways that those who are not software developers, but are interested in AI and Machine Learning, can understand a bit of what\u2019s going out there. Our previous article was about Artificial Superintelligence which can be found here, and today\u2019s word is Autoencoders.\n\nHave you ever noticed that when you are beginning to learn something new, be it a new language or how to play an instrument, after you have practiced enough it becomes something similar like a reflex? It\u2019s like your muscles have memorized every move you want to make! Well, this is not what autoenconding is, but it works on the same principles.\n\nWhat is an Autoencoder?\n\nThe autoencoder is a neural network that tries the best way it can to reconstruct its input. More exactly, if you feed the autoencoder the vector (1,0,1,0) it will try to replicate it identically (1,0,1,0). But how does it work?\n\nIn this picture, the information runs from left to right. The black squares take input from the programmer, and tries to encode it in a convenient form. This happens with the help numerical data from a computer or artificial neural network. Now, the encoded information travels to the second layer of neurons, the circles. The latter, send it to the effector neurons (not presented in the photo) which take the information and deliver them to the computer terminals, or the output layer.\n\nHow does it look?\n\nBecause the hidden layers do not have contact with the outside world, they only act with other neurons, the final effect is a bit different than expected. For example:\n\nHere is an autoencoded image from the famous sci-fi movie Blade Runner. As you can see, the pictures are blurrier and paler. You can read more about this project, here.\n\nIf you have more information you want to share about autencoders, please don\u2019t forget to leave it in the comments. The next article in the series will be about Computer Vision. Meanwhile, Synaptech, the AI-based event is growing, presenting new speakers, and if you\u2019d like to find out more about the event \u2014 the competition, workshops, conference or our new articles, you can subscribe to our newsletter here."
    },
    {
        "url": "https://medium.com/synaptech/artificial-superintelligence-the-upgraded-ai-d09591edf11f",
        "title": "Artificial Superintelligence \u2014 the upgraded AI \u2013 Synaptech \u2013",
        "text": "Hi there AI enthusiasts, it\u2019s nice to have you back. We told you in our past article that we are going to take each term from the glossary and define it. Today\u2019s term as you guessed, Artificial Superintelligence. Let\u2019s see what this is.\n\nArtificial Superintelligence, or ASI for short means that computers become so smart you say they could escape by acting like humans \u2014 mimicking human cognition and knowledge and everything. To be more precise like the replicants from Blade Runner.\n\nThe short answer is not yet. According to Quora, we have not reached yet the ability to build such a performant system. Today, Artificial Intelligence is narrow and can focus only on one thing, like winning at Jeopardy, poker and chess, playing podcasts, tweeting and answering questions. However, the idea of Artificial Superintelligence is anything but new. In the \u201950s, Alan Turing designed the infamous Turing Test, which went from the premise that Artificial Intelligence can think by itself, and one could not discern between it and a human mind.\n\nUnfortunately, in the present we can talk about Artificial Superintelligence only in hypothetical terms and situations. Probably, after AI will become something mundane as electricity, ASI could be perceived as an upcoming reality."
    },
    {
        "url": "https://medium.com/synaptech/what-is-ai-actually-a9c95d69001",
        "title": "What is AI, actually? \u2013 Synaptech \u2013",
        "text": "Every scientific field has attached to it a long, heavy and not-very-understandable vocabulary. Complicated words that make you frown. The computer science field, such as Artificial Intelligence makes no exception to this rule. The good part is that there are plenty of articles defining it. The bad news is that many of them treat you like some sort of scientist. Therefore, when trying to find out more about AI, you find yourself into a loophole of the internet, looking for the meaning of every term.\n\nWe know how unreliable Wikipedia can be, that is why we, here at Synaptech we will start a series of articles. We will take each word from the glossary, to define and offer relevant examples of companies and products that use this kind of technology. We want to make it easier to understand and to help the community to learn more about AI.\n\nArtificial Intelligence means the study of intelligent agents \u2014 any device that can perceive a certain environment and can be programmed to understand it and take actions consequently. Fortunately, they cannot do it by themselves.\n\nThe things AI can already do is to play poker or making recommendations. As books, movies and even a real experiment, already taught us, they can mimic human cognition, but this is not very advanced.\n\nIn a nutshell, they can do everything a human mind can, from performing complicated calculations to predicting patterns and even play mind games better. No, they cannot read your mind, at least not for now.\n\nBesides poker, in 1997, a chess-playing computer developed by IBM, called Deep Blue defeated Garry Kasparov, who is considered the world\u2019s best chess player. However, a year before, Deep Blue lost, but then they upgraded it heavily and it won.\n\nWeak AI, also known as Narrow AI, is a system created and designed to do a particular task. The most relevant example in this context is Amazon\u2019s personal assistant, Alexa, which is designed to play music or audio books, set alarms, stream podcasts, provide weather information in real-time and other information at request. Alexa can also interact with different smart devices, making it a smart home hub. But its actions are limited and it cannot grow a sudden conscience and go against the laws of robotics.\n\nStrong AI or True AI, is a system constructed with general cognitive abilities. When a device uses this type of intelligence can understand and solve unfamiliar tasks because it is supposed to have enough knowledge to find a solution. This AI type is at the beginning, although Google\u2019s robots become more human-like \u2014 greedy, aggressive and learn quickly.\n\nTo create Artificial Intelligence, you need plenty of algorithms, frameworks, complicated calculations and a deep knowledge of different codes. We will write about them in our future articles. Until then, don\u2019t forget to subscribe to our newsletter!"
    },
    {
        "url": "https://medium.com/synaptech/synaptech-the-newest-european-community-on-ai-68793976078",
        "title": "Synaptech \u2014 the newest European community on AI \u2013 Synaptech \u2013",
        "text": "Artificial Intelligence is going mainstream \u2014 this is the short, but comprehensive description of Synaptech, the newest event, which will take place this autumn, in Berlin. Of course, when we say mainstream, we do not mean it in the pop culture per se, but to highlight the ascension of AI technology in the worldwide usage.\n\nThe team behind Synaptech, is the same brilliant people who created Techsylvania, as the name says so, an event based on technology. Set in the heart of Transylvania, Romania, Techsylvania lasts four days, with a 24 hours connected-devices hackathon, a two-day conference, a startup competition and various workshops oriented to the latest technologies.\n\n\u201cTechsylvania was born out of the desire to bring to the amazing software developers in Cluj truly inspirational people who made it on their own, to share the know-how with the community we have nurtured over the years.\u201d says co-founder Oana Petrus.\n\n\u201c Right from the start, one of our key goals was to connect the local community with some of the best entrepreneurs, investors and experts in the tech scene so that we enable collaborations and knowledge exchange between ecosystems.\u201d mentions Vlad Ciurca, co-founder of the event.\n\nDuring four challenging years, the founders are happy with the impact of the event. \u201cAfter more than 100 speakers, 55 projects developed during our connected devices hackathon and 2500 attendees, we feel we achieved that and we\u2019re continuing to go strong this year.\u201d\n\n\u201cArtificial Intelligence is one of the hottest topics of the year, according to Forbes, and something we\u2019ve been following very closely in the past few months.\u201d says Vlad. As we all know, AI has evolved so much in the past years, growing from smart chat bots like CleverBot, to amazing Machine Learning like IBM\u2019s Watson and personal shopping assistants like Amazon\u2019s Alexa. But still, why did they chose Berlin?\n\nAccording to Atomico\u2019s 2016 report on the state of technology, Europe has a vibrant deep tech startup ecosystem. Since 2014, approximately 1,000 deep tech startups have been founded. When thinking about the amount of dollars invested in these startups, it is approximated to $2.3B since 2015, $1B only in 2016. To be more precise, these startups are world tech leaders in deep field technologies like Artificial Intelligence, Virtual Reality, Augmented Reality and autonomous vehicles.\n\nThe top 15 hubs of AI talent in Europe, according to a search made on LinkedIn, are:\n\n1. Berlin, Germany\n\n2. Munich, Germany\n\n3. Zurich, Switzerland\n\n4. Stockholm, Sweden\n\n5. Frankfurt, Germany\n\n6. Copenhagen, Denmark\n\n7. London, UK\n\n8. Barcelona, Spain\n\n9. Paris, France\n\n10. The Hague, The Netherlands\n\n11. Amsterdam, The Netherlands\n\n12. Antwerp, Belgium\n\n13. Lisbon, Portugal\n\n14. Cologne, Germany\n\n15. Madrid, Spain\n\n\u2018Berlin has had a massive transformation in the last 10 years as a hotbed for innovation and startups in Europe and I have personally seen it to transform in a vibrant technology ecosystem. Especially in the field of AI Berlin is at the forefront and I am excited that Synaptech will help to further bring great ideas and innovators to the German capital\u2019 explains Philipp Kandal, angel investor and VP of Engineering at Telenav.\n\nUS tech giants didn\u2019t let these startups go unnoticed. On the contrary, big companies like Alphabet, Amazon, Facebook, IBM, Magic Leap and Microsoft develop products in Europe, on technologies like: drones, Internet of Things, Virtual Reality, 3D Mapping, Robotics and of course, Artificial Intelligence.\n\nBesides this, Amazon, Apple, Alphabet, Microsoft and Facebook purchased European tech companies. From January 2014 until September 2016, 37 acquisitions were made.\n\nWe can say Synaptech is well placed where it is, in an international city, filled with AI enthusiasts. Keeping our fingers crossed for this marvelous event."
    }
]