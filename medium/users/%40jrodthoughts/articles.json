[
    {
        "url": "https://medium.com/datadriveninvestor/technology-fridays-this-has-to-be-one-of-the-craziest-most-exciting-blockchain-projects-ive-ever-e0c9ed4a6d4?source=user_profile---------1----------------",
        "title": "Technology Fridays: This Has to Be One of the Craziest, Most Exciting Blockchain Projects I\u2019ve Ever\u2026",
        "text": "Welcome to Technology Fridays! A few weeks ago, I came across Fetch.ai and I was blown away by the ambitions and innovative concepts behind this project. Since them, I\u2019ve found myself re-reading their whitepaper over and over again to try to grasp( and copy \ud83d\ude09 ) some the ideas from their architecture for my own work. Today, I thought I use this small article to give you an initial exposure to this fascinating project.\n\nFetch.ai sits at the intersection of two of my passions: artificial intelligence(AI) and blockchain technologies. However, Fetch.ai is not simply (if that term applies here) another platform trying to enable decentralized AI. The company is trying to provide the foundation for a world in which autonomous, intelligent AI agents can work and collaborate together under the right economic and regulatory incentives. You can think about Fetch as the first virtual world for AI agents. How cool is that?\n\nAs AI evolves and we get closer to self-learning, autonomous agents, we should ask ourselves, what type of environment will those agents require? As humans, we live in under a combination of economic, social, biological dynamics that allow us to evolve as species. If we want AI to evolve semi-organically, we need to provide autonomous agents with a virtual environments that combine the right mechanisms for them to collaborate and evolve. This is where Fetch.ai comes in.\n\nIf you want to summarize Fetch in a single term, you can think of the platform as a decentralized digital representation of the world in which autonomous software agents perform useful economic work. Ok, I agree that wasn\u2019t very simple \ud83d\ude09 Imagine a platform that allows AI programs to perform tasks such as collecting data or providing a prediction and they receive crypto tokens as a result. Fetch leverages blockchain technologies to complement unsupervised AI agents with the right economic incentives and execution environment in order to perform their tasks.\n\nTechnologically, the Fetch platform has three fundamental building blocks: The Fetch Smart Ledger, The Open Economic Framework and Autonomous Economic Agents. Each one of the components abstracts a fundamental part of society: citizens, economics and rules.\n\nThe Fetch Smart Ledger is a new type of decentralized ledger that includes a new consensus model called Useful Proof of Work(uPoW). The role of the ledger is to keep track of the activities performed by autonomous agents and process the economic transactions between them. To enable that, the Fetch platform has created uPoW, a new consensus model that addresses some of the limitation of traditional PoW algorithms and allows participants with less computing power to benefit from solving computation puzzles. uPoW will be used in tasks such as training new autonomous agents or exchanging rewards between AI programs.\n\nThe Open Economic Framework(OEF) is the component of the Fetch platform that provides life-support for autonomous software agents. These agents live in an environment that is constantly changing and they see a different world from its perspective: a world that is reorganized for its perceived and declared needs. The OEF is the high-level node functionality: the layer on top of the raw protocol and ledger that delivers this environment and all the other operations agents need in order to go about their day-to-day work. The OEF is responsible for abstracting services such as the provisioning of data for decisioning, the trading of excess capacity, energy, computation, or the storage, transfer and transportation of digital or physical assets.\n\nThe main elements populating the Fetch.ai world are know as Autonomous Economic Agents(AEA). These are digital entities that can transact independently of human intervention and can represent themselves, devices, services or individuals. The platform includes different types of agents such as Inhabitants (which represent hardware to exist in the real world ), Digital Data and Sales(which are attached to data sources in different marketplaces) or Representatives(which represent an individual in the Fetch world). The different types of agents can be seen as the first role in the brand new Fetch society.\n\nIn addition to the three main building blocks, the Fetch platform includes plenty of interesting ideas for the constructions of decentralized, economically viable environments. For instance, the platform introduces the notion of geography in a decentralized digital world using the concept of Domain Spaces to assign regions based on proximity. Similarly, Fetch.ai introduces a basic protocol for conducting business transaction between AEAs that mimics many of the dynamics of the real world.\n\nThe Fetch.ai platform is one of the most ambitious projects I\u2019ve heard of. However, the work is not only theoretical. The platform is currently being used today across a number of scenarios in transportation, energy and IOT industries."
    },
    {
        "url": "https://medium.com/coinmonks/proof-of-work-or-proof-of-stake-how-about-both-27ff19b73f51?source=user_profile---------2----------------",
        "title": "Proof of Work or Proof of Stake? How About Both? \u2013 Coinmonks \u2013",
        "text": "The debate between proof of work(PoW) and proof of stage(PoS) consensus models have been front and center on the cryptocurrency market for the last few years. The debate has been even more visible recently with all the controversy surrounding Ethereum\u2019s performance issues and the uber-anticipated released of Casper. The PoW vs. PoS debate have rapidly contributed to improve the innovation in terms consensus protocols in distributed ledger architectures. While both sides of the debate have mostly driven by purist that passionately evangelize the advantages of one approach vs. the other, there is a third emergent trend in the crypto community that has been advocating for a Solomonic solution: combining PoW and PoS in a single governance-consensus model.\n\nA lot has been written about PoW vs. PoS so I don\u2019t plan to bore you repeating the same arguments. A good way to generalize the PoW vs. PoS argument is think about it as the friction between two major economic dilemmas: \u201cthe tragedy of the commons\u201d and the \u201cnothing at stake challenges\u201d.\n\nIn PoW systems, miners are compensated for solving computational puzzles in the network. Miners aren\u2019t able to cheat the system because it takes real-world resources to work out these solutions.\n\nAs a PoW network grows, the cost of mining will become significantly less lucrative when the block reward subsidy becomes negligible, and the reward consists (almost) entirely of transaction fees. The rationale behind this stems from an economic phenomenon known as the \u201cTragedy of the Commons\u201d, which is a prevalent problem in the study of economics and game theory. In its most purist form, the tragedy of the commons describes a system in which participants have an opportunity to act selfishly, taking action to benefit themselves at the cost of harming their peers. A selfish rational agent will always take such action because she is interested only in her own well-being; but if everyone acts selfishly, everyone will be worse off than if everyone cooperates.\n\nHow is this relevant to PoW? Well, in a PoW network, rational miners will be encouraged to only process transactions that pay a high-fee so the cost of transaction can be manipulated by a small group of miners. What is even worse, miners can compromise the security of the entire PoW network by not validating transactions in order to avoid the computation fees.\n\nIn a Proof-of-Stake system, the coin holders get paid transaction fees for validating transactions. Therefore, Proof-of-Stake creates a clear and unambiguous economic incentive to hold coins for the long term. Proof of Stake isn\u2019t about mining, it\u2019s about validating, it happens by a miner putting up a stake, or locking up an amount of their coins, to verify a block of transactions. Each validator owns some stake in the network, that they bond. Bonding stake means you keep you coins in the network, and in some sense use it as collateral to vouch for a block.\n\nPoS systems suffer from another economic challenge known as the \u201cNothing at Stake\u201d problem. In a PoS network, there are only rewards, and no penalties, for validating transactions. As a result, participants in a transaction can start producing blocks on top of each other in a way that causes the network to never reach consensus.\n\nA new wave of consensus models have been created to take advantage of the benefits of both PoW and PoS systems. Arguably, Dash is the most active cryptocurrency that uses a hybrid PoW-PoS approach. Another project that I like a lot in this space is Decred, which combines the benefits of PoW and PoS in a very clever lottery system.\n\nIn the Decredworld, a transaction is first processed by PoW miners which create the blocks in the blockchain. After that, the stakeholders will use a PoS model to confirm if the block is indeed valid. They do so by buying voting tickets in a lottery system. Decred\u2019s mantra can be summarized as \u201cmining the transaction is hard but validating it is easy\u201d.\n\nJust like Decred, there are many other projects that are starting to combine the benefits of PoW and PoS systems. As blockchain evolves, it is likely that these hybrid models will find a way into mainstream applications that can benefit from the robustness of PoW architectures and the flexibility of PoS models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/using-deep-learning-to-understand-your-source-code-28e5c284bfda?source=user_profile---------3----------------",
        "title": "Using Deep Learning to Understand Your Source Code \u2013 Jesus Rodriguez \u2013",
        "text": "This should be a familiar experience to any programmer. You are immersed writing code in a static language like C# or Java, you have happily written a few hundred lines of this beautiful algorithm and then you press compile hoping to see the results of your great work. To your frustration, the compiler outputs an error message in bold red lines indicating that you missed a semicolon in line 17. At that point, you can\u2019t avoid thinking why the stupid compiler doesn\u2019t just add the semicolon to the end of line 17 and move on instead of telling you. Seriously, how hard could that be? Well, it turns out its pretty hard. The reason for the compiler\u2019s frustrating behavior is that code interpreters and compilers today and extremely efficient analyzing the syntactic aspects of a problem but very limited when comes to understand the semantics of the program or our intentions as a programmer.\n\nMany bugs in a program are not solely derived from the syntax of the program due to the higher level semantic aspects. Consider the following code snippet that should indicate an agent to turn right. While it is very obvious to a programmer that the code is wrong as it us using the left angle to turn right, mainstream compilers are completely incapable to detect that flaw.\n\nWhen a programmer looks at a specific source code, it seems more than instructions and functions and it starts forming an understanding of the goals and functionality of the program. Wouldn\u2019t it be great if compilers were able to formulate a similar level of understanding? The irony is that recent advancements in deep learning areas such as natural language understanding(NLU) allow artificial intelligence(AI) agents to understand highly complex communication structures such as human conversations while we still can\u2019t figure out highly structured texts such as computer programs.\n\nRecently, Microsoft Research published a paper that proposes a technique that combines NLU techniques with mathematical logic to detect semantically-related bugs in source code. The key idea of the technique is to form a semantic representation of source code that complements its syntactic structure in order to detect more abstract errors.\n\nTitled \u201cLearning to Represent Programs with Graphs\u201d, the Microsoft Research paper introduces a deep learning method that transform a specific source code into a graph structure. The nodes of the graph include the tokens of the program (that is, variables, operators, method names, and so on) and the nodes of its abstract syntax tree (elements from the grammar defining the language syntax such as If Statement). The program graph contains two different types of edges: syntactic edges, representing only how the code should be parsed, such as while loops and if blocks; and semantic edges that are the result of simple program analyses.\n\nHaving semantic edges allows the deep learning model to represent all sorts of high level knowledge constructs that resemble the way programmers analyze a specific source code. For instance, semantic edges such as \u201cLastUse\u201d connect a variable to the last time it may have been used in program execution (which in the case of loops can be later in the source code), \u201cLastWrite\u201d edges connect a variable to the last time it was written to, or as \u201cComputedFrom\u201d edges connect a variable to the values it was computed from. From that perspective, a large group of semantic edges can help to simulate the human interpretation process of a computer program.\n\nIn order to validate their technique, the Microsoft researchers focused on two specific types of semantic errors. The VARMISUSE task is focused on detecting variable misuses in code is a task that requires understanding and reasoning about program semantics. To successfully tackle the task one needs to infer the role and function of the program elements and understand how they relate. For example, given the following program, the task is to automatically detect that the marked use of clazz is a mistake and that first should be used instead.\n\nSimilarly, the VARNAMING task corrects infers the correct variable name based on a specific syntaxtic representation of a source code. For instance, the following example from the C# Roslyn compiler detected incorrect uses of the parameter filepath and the field _filePath, which are easily mistaken for each other.\n\nThe use of Program Graphs are not only an interesting theoretical exercise but it proven to be more efficient than many alternatives in the deep learning space. The Microsoft team conducted experiments analyzing over 2.9 million lines of source code and the new technique yielded substantially better results that more traditional methods such as bidirectional recurrent neural networks. Although the methods are highly experimental, program graphs seem to be a step towards making compilers are intelligent as human programmers."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-microsoft-wants-to-use-generative-adversarial-networks-with-1838f0b15741?source=user_profile---------4----------------",
        "title": "What\u2019s New in Deep Learning Research: Microsoft Wants to Use Generative Adversarial Networks with\u2026",
        "text": "Generative models are the subdiscipline of deep learning that focuses on the creation of statically accurate target data. In deep learning research, we can find different groups of generative models such as Boltzmann Machines or Directive Generative Nets. However, the popularity prize when comes to generative models in the last few years undoubtedly goes to generative adversarial networks(GANs). In just a few years, GANs have established themselves as the go to models for mission critical deep learning scenarios such as image generation.\n\nDespite its popularity, most GAN techniques today are only effective when working with continuous data. This is because GAN models, as normally formulated, rely on the generated samples being completely differentiable and thus do not work very well for discrete data. Recently, researchers from Microsoft proposed a new technique called Boundary-Seeking-GANs that enables the training of GAN models using discrete data.\n\nFor all the buzz around GANs, the generative method is a relative new technique which was proposed by deep learning Ian Goodfellow in a research paper in 2014. The main idea behind GANs is to create networks that involve two fundamental models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake.\n\nGANs are very effective when working with continuous data because the composition of the generator and discriminator is fully differentiable which beans that both networks can be trained using an algorithm like back-propagation. However, this is not true in the case of discreate data because those distributions have zero gradient nearly everywhere (and is otherwise infinite), so it is not possible to use back-propagation alone to train the generator.\n\nNow that we understand the challenges of using GAN models with discrete data the next obvious question is why is this relevant at all? It turns out that discreate GAN models that key to a large number of natural language processing scenarios such as machine translation or caption generation. Similarly, discrete generation is used in other domains such as image segmentation as it should avoid the overfitting challenges of traditional models.\n\nMicrosoft\u2019s idea behind Boundary-Seeking GANs is to introduce a new policy gradient that works effectively with discreate data. As mentioned before, GANs only work when the value function is completely differentiable. With discreate data, the gradients that would otherwise be used to train the generator of discrete variables are zero almost everywhere, so it is impossible to train the generator directly using the value function. However, what happens if we change the gradient?\n\nBoundary-Seeking GANs simply introduces a dual gradient method that works effectively with discrete data distributions. Initially, Boundary-Seeking GANs use a policy gradient based on the KL-divergence which uses the importance weights. The technique then combines that gradient with a lower-variance gradient which defines a unique reward signal for each z and prove this can be used to solve our original problem. The result is a GAN model in which the discriminator can be used to formulate importance weights which provide policy gradients for the generator.\n\nThe Microsoft team put the Boundary-Seeking GAN method to test with different discrete data generation scenarios. One of those experiments used the famous MNIST and CelebA datasets. In the case of the MNIST experiment, the results quantitatively outperform competing methods such as WGAN-GP. The following figure shows how the algorithm was able to produce realistic and highly variable generated handwritten digits.\n\nSimilarly, in the CelebA experiment, the generator trained as a BGAN produced reasonably realistic images which resemble the original dataset well and with good diversity"
    },
    {
        "url": "https://medium.com/coinmonks/these-three-projects-are-shaping-the-future-of-ethereum-778ab41b34b5?source=user_profile---------5----------------",
        "title": "These Three Projects are Shaping the Future of Ethereum",
        "text": "In the last few years, Ethereum has become the most important project in the cryptocurrency space. As the underlying layer of most tokens in the market, the health of the Ethereum network is essential to the rest of the crypto ecosystem. And yet, Ethereum has been struggling to keep up with the growth. Scalability challenges have been plaguing the Ethereum network to the point that many experts have launched side projects to create alternative blockchains that address some of the limitations from the ground up. However, the Ethereum team has not been sitting idle and there are several projects incubated as part of the Ethereum foundation that are focusing on tackling some of the foundational limitations of the current version of Ethereum.\n\nEthereum\u2019s layer-2 scaling solutions improve on some of the fundamental aspects of the Ethereum network such as the consensus protocol or its security model. Considering the size and activity of the Ethereum public blockchain, you can imagine that implementing these enhancements without disruptions is a massive undertake. While there are several layer-2 scaling projects for the Ethereum network, there are three that are close to general availability and that, I believe, are going to be pivotal in the future of Ethereum.\n\nArguably the most famous and widely expected Ethereum project, Casper presents an alternative to Ethereum\u2019s traditional proof of work(PoW) algorithm with a modern proof-of-stake(PoS) model that can drastically speed up the transaction commit times in the network. A lot has been written about Casper so I am not planning to bore you with the details but there are a couple of things that are worth recapping. First, let\u2019s take a high level at how Casper works. The PoS protocol is based on traditional Byzantine Fault Tolerance (BFT) models and can be summarize in these simple steps.\n\nIts important to understand that Casper is not a single project. Instead, Casper can be seem as a collection of projects. The Casper the Friendly Finality Gadget (FFG) is a hybrid POW/POS consensus mechanism. This is the version of Casper that is going to be implemented first. This is pretty much designed to ease the transition into proof of stake. The way it is designed is that there is a proof-of-stake protocol overlaying on top of the normal ethash proof of work protocol. So while blocks are still going to be mined via POW, every 50th block is going to be a POS checkpoint where finality is assessed by a network of validators.\n\nThe other Casper project is known as Casper CBC as it uses the correct-by-construction (CBC) protocol. Casper CBC differs in approach from traditional protocol design:\n\n(1) the protocol is partially specified in the beginning\n\n(2) the rest of the protocol is derived in a way that is proven to satisfy the desired/requisite properties (typically protocol is fully defined then tested to satisfy the said properties).\n\nEthereum Plasma is another one of the soon to be released projects that can result very influential in the future of Ethereum. The origins of Plasma date back to August 11 2017, when Vitalik Buterin and Joseph Poon released a paper titled Plasma: Autonomous Smart Contracts. The main idea behind Plasma is to provide a model that enables the execution of off-chain transactions while relying on the underlying ethereum blockchain to ground its security. The desigm of Plasma borrows some of the ideas from the Lightning Network but it expand the concept by allowing for the creation of \u201cchild\u201d blockchains attached to the \u201cmain\u201d Ethereum blockchain.\n\nIn the Plasma model, complex transactions cane be executed in child-blockchains, running entire applications with many thousands of users, with only minimal interaction with the Ethereum main-chain. A Plasma child-chain can move faster, and charge lower transaction fees, because operations on it do not need to be replicated across the entire Ethereum blockchain.\n\nMy third favorite Ethereum layer 2 scaling solution is Sharding. As it names indicates, Ethereum sharing borrows a few concepts from the scaling architectures of modern NoSQL databases. In essence, Ethereum sharing splits the entire state of the network into a bunch of partitions called shards that contain their own independent piece of state and transaction history. In this system, certain nodes would process transactions only for certain shards, allowing the throughput of transactions processed in total across all shards to be much higher than having a single shard do all the work as the mainchain does now.\n\nSo there you have it, while the scalability concerns of Ethereum are certainly serious, you can argue that the layer 2 solutions produced by the Ethereum Foundation are among the most advanced scalability solutions in the crypto space. Certainly, Casper, Plasma and Sharding and a trio that promises to address the fundamental scalability challenges of Ethereum and pave the way for more innovative and scalable protocols."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-an-overview-of-rasa-the-best-nlp-platform-you-never-heard-of-633b25f43845?source=user_profile---------6----------------",
        "title": "Technology Fridays: An Overview of RASA, The Best NLP Platform You Never Heard Of",
        "text": "Welcome to Technology Fridays! Today, I would like to talk about one of my favorite natural language processing(NLP) platforms that, inexplicably, is still flying under the radar compared to incumbents like IBM, Amazon, Google or Microsoft. I am talking about RASA.\n\nIf you are building conversational interfaces in real world solutions, you are likely to start with relatively simple dialogs that can be modeled as a one-page flow chart. For that type of scenarios, its incredibly tempting to go with the NLP stacks from cloud AI incumbents such as Microsoft Cognitive Services, AWS Lex, Watson Assistant or Google\u2019s DialogFlow. After all, those solutions seem to encompass everything you are ever going to need on a conversational solution. However, very quickly NLP scenarios start experiencing challenges that seem to fall outside the domain. Let me give you an example of my favorite challenges with this type of NLP cloud services:\n\n2) The conversations grow and start producing a large number of calls to the cloud NLP services making the cost unmanageable.\n\n3) Developers are constantly changing the dialogs to accommodate new interactions.\n\n4) The conversations grow to a level that can\u2019t be modeled as a simple flow chart.\n\nThese challenges are very common in large scale NLP solutions. Plain and simple, most developers quickly realize that most real world conversations can be modeled as a flow chart. Think about it, part of the magic of human conversations is that there are infinite ways to arrive to the same point or express the same intention. RASA is an NLP platform that tries to address these challenges.\n\nThe RASA platform is an open source, Python-based NLP stack that enables the implementation of highly sophisticated conversational interfaces. In principle, RASA moves away from the traditional flow chart model of natural language dialogs by introducing probabilistic models that control the flow in a conversation. The RASA platform is based on two fundamental components:\n\n\u00b7 RASA NLU: An open source stack for intent classification and entity extraction. RASA NLU can be seen as an alternative to popular NLP services such as Microsoft LUIS or Google\u2019s DialogFlow. The main advantage of RASA NLU over those stacks is that you have access to the entire Python processing pipeline and can extend it with your complex custom logic. RASA NLU offers infrastructure capabilities such as model persistence or HTTP access that are required on conversational solutions in the real world.\n\n\u00b7 RASA Core: This is the flow control engine of the RASA platform. Fundamentally, RASA core processes and entities, intents or context generated by RASA NLU and decides what actions to take. Those actions are not based on prescriptive instructions coded in flow chart but on probabilistic models that allow the conversations to evolve organically without requiring constant modifications. Developers can enrich dialogs by creating custom interprets, policies or other highly sophisticated elements included in the RASA Core stack.\n\nThe different between RASA and other NLP stacks is the difference between writing rules-based systems or neural networks. In traditional NLP platforms, the flow of a conversation is hardcoded in static if-then rules whether the RASA platform uses techniques such as reinforcement learning to actively train models that can guide the dialog. From that perspective, RASA leverages deep learning techniques not only to recognize entities and intents in a dialog but to also to control its flow.\n\nRASA is delivered in two fundamental modes. RASA Stack is an open source offering that includes the core capabilities of RASA Core and RASA NLU. The RASA Platform is a commercial offer that extends RASA Stack with capabilities such as model monitoring, support, etc.\n\nRASA competes with traditional NLP cloud services such as AWS Lex, Watson Assistant, Microsoft LUIS, Facebook Wit or Google DialogFlow. RASA is positioning itself as the open source, on-premise and highly extensible alternative to those incumbent platforms. At least initially, there seems to be a strong need in the market for a platform like RASA when comes to the implementation of highly sophisticated NLP solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-learning-by-playing-5287f162a47a?source=user_profile---------7----------------",
        "title": "What\u2019s New in Deep Learning Research: Learning by Playing",
        "text": "Creating agents that can learn like children is one of the ultimate goals of artificial intelligence. Disciplines such as reinforcement learning(RL) are fully devoted to create self-learning models that can use a combination of punishment and reward feedback to master a new task. However, most RL techniques suffer from two main challenges. One very well known is the exploration-explotaition dilemma in which an agent needs to decide how many resources to dedicate to exploring the environment vs. taking specific actions. The other and far less know challenge of RL methods is what I like to call the prior knowledge imbalance dynamic.\n\nIf we look at the current spectrum of RL techniques used in deep learning solutions, they tend to fit into one of two buckets:\n\na) RL agent learns a task 100% from scratch without using any prior knowledge which requires a lot of resources to master a large number of other knowledge required to learn the target task.\n\nb) RL agent require a tremendous amount of prior knowledge in order to master a new task.\n\nThat imbalance creates an environment in which none of those scenarios accurately describe how children learn. In most scenarios, children are able to learn a new task by combining a reduce level of exploration with a small number of core skills.\n\nRecently, researchers from Alphabet\u2019s subsidiary DeepMind published a research paper that proposes a technique called Scheduled Auxiliary Control (SAC-X) that seeks to overcome the challenges with exploration and prior knowledge in RL models. SAC-X is based on the idea that to learn complex tasks from scratch, an agent has to learn to explore and master a set of basic skills first. Just as a baby must develop coordination and balance before she crawls or walks \u2014 providing an agent with internal (auxiliary) goals corresponding to simple skills increases the chance it can understand and perform more complicated tasks.\n\nTo illustrate SAC-X, let\u2019s consider a scenario in which a learning agent has to control a robot arm to open a box and place an object nside. While defining the reward for this task is, the underlying learning problem is hard. For instance, the agent has to explore a long sequence of \u201ccorrect\u201d actions in order to find a configuration of the environment that produces the correct action\u2013 the block contained inside the box. Discovering this sparse reward signal is a hard exploration problem for which success via random exploration is highly unlikely. In the research paper, the DeepMind team describes SAC-X in four fundamental steps:\n\n1. Every state-action pair is paired with a vector of rewards, consisting of (typically sparse) externally provided rewards and (typically sparse) internal auxiliary rewards.\n\n2. Each reward entry has an assigned policy, called intention in the following, which is trained to maximize its corresponding cumulative reward.\n\n3. There is a high-level scheduler which selects and executes the individual intentions with the goal of improving performance of the agent on the external tasks.\n\n4. Learning is performed off-policy (and asynchronously from policy execution) and the experience between intentions is shared \u2014 to use information effectively\n\nAlthough, conceptually, SAC-X can be applied to many RL scenarios, the DeepMind team focused on several robotic scenarios such as stacking problems with different objects and \u2018tidying up a playground\u2019, which involves moving objects into a box. The auxiliary tasks defined encourage the agent to explore its sensor space. For example, activating a touch sensor in its fingers, sensing a force in its wrist, maximizing a joint angle in its proprioceptive sensors or forcing a movement of an object in its visual camera sensors. Each task is associated with a simple reward of one if the goal is achieved, and zero otherwise.\n\nThe initial results showed that utilizing simple auxiliary tasks enables SAC-X to learn complicated target tasks from rewards defined in a \u2019pure\u2019, sparse, manner: only the end goal is specified, but not the solution path. The behavior of the agents using SAC-X demonstrated a rapid proficiency to learn a new task without requiring large levels of exploration or consuming a lot of resources. In that sense, SAC-X take us closers to AI agents that can learn like children (without breaking things \ud83d\ude09 )"
    },
    {
        "url": "https://medium.com/datadriveninvestor/not-so-fat-but-key-protocols-2e4733279aea?source=user_profile---------8----------------",
        "title": "Not-So-Fat but Still Key Protocols \u2013 Data Driven Investor \u2013",
        "text": "Joel Monegro\u2019s Fat Protocols blog post has become one of those seminal essays influencing the current generation of blockchain technologies. In his thesis, Monegro explains how the protocol layer in blockchain technologies is likely to capture more value than the application layer which is a trajectory that fundamentally contradict with other technology trends. Whether you agree with Monegro or not ( I personally think that there are a series of applications in financial markets that can unlock a level of value comparable to Bitcoin when using Blockchain technologies) the idea is certainly worth exploring. However, if you are a developer building blockchain solutions in the real world, you are constantly faced with challenges that involve protocols that sit a level above Bitcoin or Ethereum smart contracts. To differentiate, let\u2019s call those stacks Not-So-Fat Protocols(NSFP) and, even they can\u2019t be compared with Tier1-Protocols in terms of value, they are and, will be, essential to the mainstream adoption of blockchain technologies.\n\nThe easiest way to understand NOT-SO-FAT PROTOCOLS is to think about the fundamental infrastructure capabilities you need in any blockchain application. Even better, if we go back to the early days of cloud computing, think about the first group of platform services that sit on top of basic infrastructure capabilities in platforms like AWS or Azure. In the same way, developers building blockchain solutions require a fundamental set of building blocks that abstract key capabilities such as data storage, identity or integration which are omnipresent on any blockchain application. These building blocks sit above Fat Tier1 Protocols like Ethereum smart contracts and below Application Protocols.\n\nIf we divide the software world between centralized and decentralized applications, technologies such as Ethereum smart contracts can be compared with low level protocols like TCPIP or SMTP. Those protocols were pivotal laying the foundation for the first generation of software applications but they slowly became less visible as a second layer of technologies was created to address some of the main requirements of mainstream applications. That evolution has continued througout the evolution of major runtimes in the history of centralized software such as web, mobile or cloud. Similarly, we should expect a second tier of Not-So-Fat Protocols to slowly start abstracting Fat Protocols such as Ethereum in mainstream applications.\n\nWith that in mind, what are the key Not-So-Fat Protocols that we should see in the mainstream blockchain applications? That list could be fairly large and certainly controversial but, in my opinion, there are five key protocols that are relevant to almost any general purpose modern blockchain application.\n\nAny blockchain application faces the need to store and access data in efficient ways. For decentralized applications to become viable, we need protocols that compare with 50 years of evolution of centralized database technologies. Platforms such as IPFS, FileCoin or BigChainDB are some of the first filling that void in the blockchain space.\n\nDistributing computation across a federation of decentralized nodes is a key capability for the scalability of blockchain applications. This will be the equivalent of building AWS EC2 for the decentralized world. Technologies like Golem and Tendermint are some of the most relevant projects in that space.\n\nAuthentication, access control, federation are some of the identity-centric capabilities that are present in any blockchain solutions. In a decentralized world, we still rely mostly on centralized platforms to address the identity management challenges. Technologies like Civic or some of the work Microsoft has been doing in decentralized identities are promising protocols in the space.\n\nCommunicating with off-chain data and services is another key requirement of mainstream blockchain applications. While it sounds conceptually trivial, the integration with off-chain applications stil results incredibly challenging in most blockchain platforms. Technologies like Oraclize provide some of the most sophisticated protocols to try to address this challenge.\n\nMonitoring and analyzing the behavior of decentralized application is nothing short of a nightmare with the current generation of blockchain platforms. Most of the interesting solutions in the space has been provided by some of the blockchain as a service stacks such as Azure, Bluemix or BlockStack.\n\nNot-So-Fat Protocols are just starting to become relevant in the blockchain market and its total addressable market represents a fraction the value created by tier 1 protocols. However, as blockchain applications become more mainstream, we can see the value of Not-So-Fat Protocols gradually increasing and taking a chunk of the market owned by the so-called Fat Protocols.\n\nThat market shift might be irrelevant as the value of Fat Protocols is also likely to increase but one thing is for sure: Not-So-Fat Protocols are here to stay."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-openai-wants-to-create-introspective-reinforcement-learning-f5d961f5760c?source=user_profile---------9----------------",
        "title": "What\u2019s New in Deep Learning Research: OpenAI Wants to Create Introspective Reinforcement Learning\u2026",
        "text": "Introspection is one of those magical cognitive abilities that differentiate humans from other species. Conceptually, introspection can be defined as the ability to examine conscious thoughts and feelings. Introspection also plays a pivotal role in how humans learn. Have you ever tried to self-learn a new skill such as learning a new language? Even without any external feedback, you can quickly assess whether you are making progress on aspects such as vocabulary or pronunciation. Wouldn\u2019t it be great if we could apply some of the principles of introspection to artificial intelligence(AI) discplines such as reinforcement learning (RL)?\n\nThe magic of introspection comes from the fact that humans have access to very well shaped internal reward functions, derived from prior experience on other tasks, and through the course of biological evolution. That model highly contrasts with RL agents that are fundamentally coded to start from scratch on any learning task relying mainly on external feedback. Not surprisingly, most RL models take substantially more time than humans to learn similar tasks. Recently, researchers from OpenAI published a new paper that proposes a method to address this challenge by creating RL models that know what it means to make progress on a new task, by having experienced making progress on similar tasks in the past.\n\nTitled Evolved Policy Gradients(EPG), the OpenAI research paper introduces new metalearning technique based on the concept of a loss function that qualifies the learning progress. When used in RL models, the EPG method does not encode the knowledge explicitly through memorized behaviors but, instead, it uses an implicitly mechanism through a learned loss function. The EPG end goal is that RL agents that can use this loss function to lean a novel task.\n\nAlgorithmically, EPG consists of two optimization loops. In the inner loop, an agent learns, from scratch, to solve a particular task sampled from a family of tasks. The family of tasks might be \u201cmove gripper to target location [x, y]\u201d and one particular task in this family could be \u201cmove gripper to position [50, 100]\u201c. The inner loop uses stochastic gradient descent (SGD) to optimize the agent\u2019s policy against a loss function proposed by the outer loop. The outer loop evaluates the returns achieved after inner-loop learning and adjusts the parameters of the loss function, using Evolution Strategies (ES), to propose a new loss that will lead to higher returns.\n\nFrom the metalearning standpoint, the loss function consists of temporal convolutions over the agent\u2019s recent history which can lead to interesting side benefits. For instance, by examining the agent\u2019s history, the loss could incentivize desirable extended behaviors, such as exploration. Further, the loss could perform a form of system identification, inferring environment parameters and adapting how it guides the agent as a function of these parameters (e.g., by adjusting the effective learning rate of the agent).\n\nMetalearning policies is nothing new in the RL field but the EPG techniques does bring some very tangible benefits compared to traditional approaches. One of the most obvious advantages of the EPG method is that it avoids the local-minima Achilles\u2019 heel of RL models. Since RL methods optimize for short-term returns instead of accounting for the complete learning process, they may get stuck in local minima and fail to explore the full search space. The EPG method allows RL models to optimize for the true objective, namely the final trained policy performance, rather than short-term returns. In initial tests, EPG seems to improves on standard RL algorithms by allowing the loss function to be adaptive to the environment and agent history, leading to faster learning and the potential for learning without external rewards.\n\nAmong the interesting tests conducted by the OpenAI researchers in order to test the generalization ability of EPG, there was an experiment focused on using the EPG loss to be effective at getting \u201cants\u201d to walk to randomly located targets on the right half of an arena. After an initial calculation of the loss function, the experiment gave the ants a new target, this time on the left half of the arena. Surprisingly, the ants learned to walk to the left! Here is how their learning curves looked (red lines on graph.\n\nThe type of knowledge generalization achieved by EPG models is very encouraging compared to traditional metalearning models because is doesn\u2019t rely on the training distribution. The OpenAI team complemented the research paper with an initial implementation of EPG available on Github. The EPG implementation is based on the Python and Anaconda which should make it relatively simple to use with other deep learning frameworks."
    },
    {
        "url": "https://cryptocurrencyhub.io/technology-fridays-tendermint-wants-to-be-the-zookeeper-of-the-blockchain-world-90bbe3c3f5aa?source=user_profile---------10----------------",
        "title": "Technology Fridays: Tendermint Wants to be the Zookeeper of the Blockchain World",
        "text": "Welcome to Technology Fridays! Today we are going back to blockchain land with one of my favorite technologies of the last year: Tendermint. The reason I like this platform so much is not only because they have one of the best names in the entire blockchain ecosystem( no offense anybody) but also because they solve one of the biggest problems in distributed systems in general and blockchain technologies specifically. In essence, Tendermint is a new protocol that leverages many concepts of blockchain architectures to enable the implementation of highly available and fault tolerant distributed systems.\n\nAt a first glimpse, the value proposition of Tendermint doesn\u2019t seem exactly unique. After all, we have plenty of well-established technologies like Zookeeper or Consul that have proven to be very effective providing the infrastructure for highly available systems. The unique differentiator of Tendermint is that leverages a principle known as the Byzantine fault tolerance (BFT) that was made popular by cryptocurrencies such as Bitcoin or Ethereum. BFT was originally created in 1999 as a solution to the famous Byzantine General\u2019s Problem but it was not formally implemented until the first release of Bitcoin in 2008. In some sense, blockchain technologies can be seen as a reformalization of BFT in a more modern setting, with emphasis on peer-to-peer networking and cryptographic authentication. Tendermint, adopts BFT models to the domain of replicated state machines (blockchains), using blocks, hash-linking, dynamic validator sets, and rotating leader election.\n\nFunctionally, Tendermint uses BFT to securely and consistently replicate the state of nodes in a network. Tendermint security model works even if up to 1/3 of machines fail in arbitrary ways. The consistency model ensures that every non-faulty machine sees the same transaction log and computes the same state. From the architecture standpoint, Tendermint consists of two chief technical components: a blockchain consensus engine and a generic application interface. The consensus engine, called Tendermint Core, ensures that the same transactions are recorded on every machine in the same order. The application interface, called the Application Blockchain Interface (ABCI), enables the transactions to be processed in any programming language.\n\nThe abstraction of the Tedermint architecture using those two fundamental components makes it relatively easy to understand. In Tendermint architectures, Tendermint Core (the \u201cconsensus engine\u201d) communicates with the application via a socket protocol that satisfies the ABCI. The communication protocol is based on three main types of messages:\n\n3. Commit to successfully signal the completion of a transaction\n\nHow are these messages being used? Well, Tendermint Core creates three ABCI connections to the application; one for the validation of transactions when broadcasting in the mempool, one for the consensus engine to run block proposals, and one more for querying the application state.\n\nThe consensus protocol is the main value proposition of the Tendermint platform. Tendermint consensus algorithm begins with a set of validators. Validators maintain a full copy of the blockchain and are identified by their public keys. They take turns proposing blocks at each new block height. There is at most one proposer per voting round. Each proposal is signed by a validator\u2019s corresponding private key so that the validator responsible for it can be identified if some failure were to occur. The rest of the validators then vote on each proposal, signing their votes with their private keys. This constitutes a single round. But it may take several rounds before a new block is committed due to network asynchrony.\n\nDevelopers can start using Tendermint by downloading the latest release from the website and running through the simple installation process. After the install, developers will be able to build a simple application that interacts with the ABCI interface to process and commits transaction. Additionally, the current release enables the addition of new nodes such as validators or non-validators to the network.\n\nTendermint is a new project in the blockchain world but it has already been adopted by major projects. Cosmos, BigChainDB and OmiseGo are some examples of blockchain projects using the Tendermint platform.\n\nTendermint is fundamentally used as a platform to ensure the high availability and fault tolerance capabilities of a distributed system. From that perspective, Tendermint competes with well-established projects such as Zookeeper or Consul. On the blockchain world, other BFT protocols such as Casper or Burrow can be seen as alternatives to Tendermint."
    },
    {
        "url": "https://medium.com/coinmonks/beyond-the-bs-the-qubit-protocol-and-why-quantum-technologies-are-not-an-existential-threat-to-4d1d862decc7?source=user_profile---------11----------------",
        "title": "Beyond the BS: The Qubit Protocol and Why Quantum Technologies are NOT an Existential Threat to\u2026",
        "text": "Yesterday was a strange day, in a matter of hours I was pulled into two different discussions about the fears of quantum computing attacks in blockchain technologies. Well, aren\u2019t all these blockchains become irrelevant with the advent of quantum computing? A friend asked me. Ironically, my friend is incredibly savvy and talented when comes to blockchain technologies but, who can blame him? His opinion is a reflection of the types of articles we find in mainstream tech media predicting a quantum apocalypse for the cryptocurrency industry. Just do a quick Google search and some of these articles are going to surface:\n\n\u00b7 How quantum computing could wreak havoc on cryptocurrency\n\nAnd the list keeps going. Most of these articles are trivializing an argument that sorts of goes like this:\n\nThis reasoning is an example of a philosophical argument called the modus ponens formal fallacy that explains a pattern of reasoning that leads to the wrong conclusions based on the lack of structure. We all heard of the formal fallacy in the form of reasoning jokes like the following:\n\nGoing back to quantum computing and cryptocurrencies, the argument is not so much that PoW blockchains can be vulnerable to quantum attacks but that those risks have been massively exaggerated by media who decided to present arguments without any mathematical rigor in order to make splashy headlines. A few months ago, I read a research paper that FINALLY presents a detailed argument about the real risks of quantum attacks in PoW blockchains.\n\nTitled \u201cQuantum attacks on Bitcoin, and how to protect against them\u201d, the paper details TWO (not two thousands) potential attacks that the current generation of blockchain technologies can see with the emergence of quantum computing. The first type of attack focuses on using quantum algorithms such as Grover search to outperform miners. Technically, a quantum computer can perform the hashcash PoW by performing quadratically fewer hashes than is needed by a classical computer so we could theoretically create miners that solve the crypto-puzzles exponentially faster than the rest of the network, right? Not so fast. While the theoretical argument is sound, the researchers look at the projected clock speeds of quantum computers in the next 10 years and compare that to the likely power of conventional hardware. Their conclusion was that most mining is done by application-specific integrated circuits (ASICs) made by companies such as Nvidia. This hardware is likely to maintain a speed advantage over quantum computers over the next 10 years or so.\n\nThe second type of attack is focused on the hash algorithms used by PoW blockchains. Technologies like Btcoin are made using the Elliptic Curve Digital Signature Algorithm based on the secp256k1 curve. The security of this system is based on the hardness of the Elliptic Curve Discrete Log Problem (ECDLP). While this problem is still believed to be hard classically, there have been signs that quantum algorithm should be able to solve it efficiently. This is also a solid theoretical argument but when researchers ran some Moore law calculations the results show that blockchain hash should remain quantum resistance for, at least, the next 20 years.\n\nEvery time I hear the exaggerated fears of quantum attacks on crypto networks I can\u2019t avoid thinking about an obvious counterargument: If quantum computing is going to become ubiquitous to the point that it can be used to attack networks like Bitcoin, shouldn\u2019t we assume that we will create quantum-resistant proof-of-work or proof-of-stake protocols using the same computing power? It seems like a good argument to me \ud83d\ude09\n\nTo not leave the risks of quantum attacks in cryptocurrency networks to chance, some of the researchers who participated in the papers recently launched an initiative called The Qubit Protocol that uses a decentralized model to make funding decisions on projects that advance quantum technologies in blockchain networks. The Qubit Protocol can be summarized as something like this:\n\nUsing blockchain technologies to advance quantum research that protects blockchain networks about quantum attacks. As far as ironies go, this is a pretty good one \ud83d\ude09"
    },
    {
        "url": "https://cryptocurrencyhub.io/crypto-coolness-homomorphic-encryption-gets-new-standards-601665ea5d7d?source=user_profile---------12----------------",
        "title": "Crypto Coolness: Homomorphic Encryption Gets New Standards",
        "text": "Recently, not a week goes by in which I don\u2019t find myself writing about homomorphic encryption in some way or another. In one of the most exciting and rapidly changing times in the tech industry, homomorphic encryption is likely to become one of the most important computer science breakthroughs of the last decade and one that is likely to become foundation to movements such as artificial intelligence(AI) or blockchain technologies. Recently, Microsoft Research hosted a workshop that included some of the most important minds in the homomorphic encryption field. The goal of the meetup was to start setting up the foundation for the first generation of standards that will enable the implementation of interoperable homomorphic encryption stacks.\n\nAs homomorphic encryption evolves, the need for interoperability is going to become more relevant for its mainstream adoption. While today we have several highly sophisticated homomorphic encryption frameworks such as HElib, SEAL, NFLlib or Palisade, the interoperability between them remains very limited. During the recent workshop, cryptographers from top academic institutions and security experts from companies such as Microsoft and IBM started collaborating to produce the first series of standards that guide the implementation of the next generation of homographic encryption libraries. Specifically, the workshop produced the following three papers:\n\nArguably the most important contribution of the workshop, this research paper outlines the main components of the homomorphic encryption platform. Specifically, the paper proposes an architecture for homomorphic encryption platforms that includes building blocks such as a storage model to identify what needs to be included to both serialize and deserialize keys, ciphertexts, plaintexts, encryption parameters, and scheme/implementation dependent data, and to support homomorphic computations. Another proposed component is an an assembly language -like representation of homomorphic encryption programs, consisting of low-level library calls. The final building block is a programming model for homomorphic encryption, representing the business logic layer, describing how application developers interact with circuit compilers, and how the compiler interacts with the libraries to perform its tasks. The following figure illustrates some details about the components of the homomorphic encryption architecture proposed in the research paper:\n\nAnother deliverable of the homomorphic encryption workshop was the applications paper that details a group of applications across several industries that can benefit greatly from the implementation of homomorphic encryption standards. The paper covers scenarios in diverse industries such as genomics, national security or healthcare.\n\nThe third and final document produced during the workshop proposes a series of security standards for the implementation of homomorphic encryption techniques. The paper outlines some of the most common homomorphic encryption schemes adopted by the first generation of frameworks in the market as well as some of the typical attacks and security vulnerabilities of these schemes."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-inside-google-s-semantic-experiences-4536d57c685?source=user_profile---------13----------------",
        "title": "What\u2019s New in Deep Learning Research: Inside Google\u2019s Semantic Experiences",
        "text": "Last week Google Research made news with the release of Semantic Experiences, a website that serves as a playground to evaluate some of the new advancements in natural language understanding(NLU) technologies. The initial release included two pseudo-games that illustrates the practical viability of some of Google\u2019s latest NLU research.\n\nThe first experience included in the new website is called Talk to Books and enables users converse with a machine learning-trained algorithm that surfaces answers to questions with relevant passages from human-written text. As described by the Google Research team, Talk to Books allows you to \u201cmake a statement or ask a question, and the tool finds sentences in books that respond, with no dependence on keyword matching.\u201d They also added that, \u201cIn a sense you are talking to the books, getting responses which can help you determine if you\u2019re interested in reading them or not.\u201d\n\nThe second initiatives included in Semantic Experiences is Semantris, a game powered by machine learning, where you type out words associated with a given prompt. The experience might seem trivial but, speaking as an end user, I can tell you it can become addictive.\n\nGoogle\u2019s Talk to Books and Semantris are both the first practical implementations of the Universal Sentence Encoder technique. This method was recently outlined in a paper published by a team of researchers at Google that includes world-renown author and futurist Ray Kurzweil. Conceptually, the Universal Sentence Encoder technique focuses on representing language in a vector space using vectors that represents large text sections such as sentences or paragraphs vs. the traditional models that focused mostly on word vectors.\n\nThe idea of using sentence embeddings as the fundamental encoding vector in a NLU model is an attempt to improve the transferability of those models to other NLU tasks. Transfer learning is becoming an essential mechanism to reuse artificial intelligence(AI) knowledge at scale but NLU models have traditionally struggle to operate in transfer learning scenarios. The main reason behind those challenges is that traditional NLU models rely on word-embedding vectorization which can result computational intensive to train and scale. Recent studies have shown that sentence-level embeddings tend to outperform word level embeddings in transfer learning scenarios.\n\nAs it names indicates, the Universal Sentence Encoder research focuses on proposing different sentence encoding mechanisms for NLU models. Specifically, the research introduces the Transformer and Deep Averaging Networks(DAN) sentence encoding methods as a way to improve the transfer learning capabilities of models.\n\nThe transformer encoder focuses on optimizing the accuracy of the model at the expense of computational resources. The technique constructs sentence embeddings using the encoding sub-graph of the transformer architecture. This sub-graph uses attention to compute context aware representations of words in a sentence that take into account both the ordering and identity of all the other words.\n\nThe Google research shows that the transformer encoder achieves the best overall transfer learning performance. However, this comes at the cost of compute time and memory usage scaling dramatically with sentence length.\n\nThe goal of the deep averaging networks(DAN) technique is to optimize efficiency trading off some accuracy. In the DAN model, input embeddings for words and bi-grams are first averaged together and then passed through a feedforward deep neural network (DNN) to produce sentence embeddings. The Google research shows that the primary advantage of the DAN encoder is that compute time is linear in the length of the input sequence.\n\nThe Google research team didn\u2019t stop at the theoretical work and published an implementation of the Universal Sentence Encoder in the TensorFlow Hub. Using the encoder doesn\u2019t require more than a handful of lines of code as shows in the following code snippet.\n\nDevelopers can start leveraging the Universal Sentence Encoder to train their own models and contribute to Google\u2019s Semantic Experiences."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-comet-ml-wants-to-be-the-google-analytics-of-the-deep-learning-world-18cdb3b418c1?source=user_profile---------14----------------",
        "title": "Technology Fridays: Comet.ML Wants to be the Google Analytics of the Deep Learning World",
        "text": "Welcome to Technology Fridays! Today we would like to explore a brand new platform that just launched to address one of the biggest challenges in machine intelligence applications. If you\u2019ve ever worked in a deep learning project in the real world, you probably found yourself tied in a virtually never ending cycle of testing, regularization, optimization and constant improvement of a model.\n\nThe continuously evolving nature of its lifecycle is one of the key characteristics that makes machine learning applications fundamentally different from other types of software systems. In machine learning scenarios, data scientists rarely stop conducting experiments targeted to optimize and improve the behavior of models. However, the toolsets for performing that level of experimentation haven\u2019t evolved at the pace of the corresponding deep learning runtimes and platforms. Recently, a new startup called Comet.ml launched with the promise of allowing data scientists to monitor and optimize machine learning models across different technology stacks.\n\nThe experience of using Comet.ml resembles the model adopted by technologies like Google Analytics that made them the standard for monitoring and testing web applications. Similar to Google Analytics, data scientists can start using Comet.ml by embedding a specific tracking code as part of their machine learning model. The scrip will track the specific behavior of the model including important elements such as hyperparameters and other relevant metrics.\n\nUsing the Comet.ml portal rapidly perform experiments on a specific model by tuning hyperparameters. The UI allows data scientists to visualize the results of experiments and compare the results based on specific hyperparameters. I can imagine this might sounds like a trivial problem but its one of the biggest nightmares in machine learning applications in the real world.\n\nThe Comet.ml platform automatically integrates with several deep learning frameworks such as Keras, TensorFlow, PyTorch, Scikit-Learn and several others. Data scientists can download the SDK for their specific runtime and start tracking any model The code for achieving this is fundamentally simple. The following example illustrates a Keras model that is being monitored using Comet.ml.\n\nComet.ml complements its robust machine learning monitoring and optimization capabilities with simple collaboration features that enable data scientists to provide feedback and cooperate on the optimization of specific machine learning programs. The platform is also capable of providing intelligent recommendations for optimizing and regularizing models based on their runtime behavior.\n\nComet.ml solves a very challenging aspect of machine learning solutions. However, the platform is not entering the market without competition. Cloud platforms such as Azure ML, AWS SageMaker or Google Cloud ML include their own toolset for monitoring and optimizing machine learning models. Simiarly, startups such as Floyd or BitFusion can also be considered as competitors."
    },
    {
        "url": "https://medium.com/datadriveninvestor/cryptonomics-understanding-the-vertifiers-dilemma-in-crypto-assets-30c65259865b?source=user_profile---------15----------------",
        "title": "Cryptonomics: Understanding the Vertifier\u2019s Dilemma in Crypto-Assets",
        "text": "Proof of Work(PoW) consensus algorithms are at the heart of the most popular cryptocurrencies in the market such as Bitcoin and Ethereum. From the economics perspective, PoW can be seen as one of the fundamental elements that drives the price of cryptoassets. Remember Jamie Dimon\u2019s unfortunate comments claiming that Bitcoin was a fraud because it didn\u2019t have any underlying mechanisms driving the price. Well, PoW can be seen as that underlying mechanism. Plain and simple, it cost money to make a Bitcoin. If you think about Bitcoin as a commodity, PoW can be seen as a metric of the production cost. Some of the classic theory in commodity pricing even states that the price of an asset should trade in relative proximity of its production cost which is an indicator of how relevant PoW can be on the economics of a cryptoassets.\n\nLike any other asset production mechanisms, PoW introduces a series of economic dynamics/rules in the crypto-asset markets. One of the most fascinating, and not-so-well-known, in PoW models is what is known as the Verifier\u2019s Dilemma which has come to play an important role in the economic and security behavior miners in PoW-based networks such as Bitcoin or Ethereum.\n\nThe concept of the Verifier\u2019s Dilemma was first introduced in a paper titled: Demystifying Incentives in the Consensus Computer published by researchers at the University of Singapore. The paper outlines this simple conflict between the economic incentives or miners and the requirements of PoW models that can result in security vulnerabilities in a crypto network.\n\nTo understand the Verifier\u2019s Dilemma, let\u2019s take a look at the miners role in a PoW network such as Bitcoin or Ethereum. As new blocks enter a PoW network, miners need to run a computation process to answer PoW puzzles that validate the transactions and maintain the integrity of the network. Miners are rewarded for their work with new crypto-assets. Typically, the first miner who successfully broadcasts a solution to the current PoW puzzle proves that she has spent the necessary computation power to merit appending her new set of transactions to the blockchain, and this step awards the miner a set of newly minted coins. This process works beautifully for simple process but creates certain friction for computational intensive puzzles.\n\nDespite its mathematical sophistication, PoW models fail to account for the rational human factor in the consensus process. PoW protocols dictates that miners should participate in the consensus process free in order to preserve the integrity of the network which, it turns, benefits all participants. However, in non-trivial computational puzzles, miners can spend a lot of resources without receiving any rewards. Consequently, many miners decide are incentivized to deviate from the protocol and reserve their limited computation resources to the next, more appropriate, block. The problem is that, by skipping the verification processes, miners open the door to serious security vulnerabilities in a PoW network.\n\nA classic attach caused by the Verifier\u2019s Dilemma is one in which a bad actor publishes a series of computational intensive transactions into a PoW network in order to exhaust the computational resources of the miners. As rational miners compete to solve the resource-intensive puzzle, the bad actor can gain an advantage to start mining the next blocks in the network. Other side effects of the Verifiers Dilemma include miners accepting invalid transactions without running the proper verification process which compromises the integrity of the network.\n\nThe Verifier\u2019s Dilemma is fundamentally a friction between the computational complexity of puzzles in a PoW consensus network, the economic incentives for solving those puzzles and the rational behavior of the miners.\n\nThe cryptocurrency industry has produced various solutions to address the Verifier\u2019s Dilemma. Among my favorites, TrueBit provides a gamified approach that shuffles the incentives among the network actors in order to solve a puzzle. Other solutions in the Ethereum network have focused on moving the mining computations off-chain."
    },
    {
        "url": "https://cryptocurrencyhub.io/cool-projects-on-the-blockchain-dfinity-envisions-a-decentralized-cloud-ada3cfef7eff?source=user_profile---------16----------------",
        "title": "Cool Projects on the Blockchain: DFINITY Envisions a Decentralized Cloud",
        "text": "I decided to start a series of blog posts that cover some of the new cool projects and protocols that have been gaining relevance in the blockchain ecosystem. Most people associate blockchain technologies with well known platforms such as Ethereum or Hyperledger but the fact is that there are hundreds of new projects that have a real shot at playing an important role in the mainstream adoption of blockchain technologies. If you work in the blockchain space, every day you encounter new technologies, tools or protocols that are solving real, pragmatic use cases in decentralized applications. In that sense, I thought I\u2019d compile some of my notes of some of the projects I\u2019ve been evaluating recently as well as my impressions about their roles in the overall blockchain market.\n\nOne of the projects that has caught my attention recently is DFINITY. I recently wrote a small article about the platform but I wanted to take a second pass at it after I\u2019ve been looking to the project in more detail. The vision behind DFINITY is nothing short of ambitious as the platform is attempting to build a completely decentralized cloud that can run mainstream applications. That doesn\u2019t sound very unique does it? After all, that\u2019s a similar vision of tier 1 blockchain platforms such as Ethereum. However, DFINITY can be seen at the same time as both a natural complement and an alternative to Ethereum.\n\nIn some context, DFINITY can be considered a sister network of Ethereum and many of its crypto protocols are applicable in the Ethereum network. However, DFINITY also challenges the fundamental \u201cThe Code is Law\u201d principle of the Ethereum network by introducing a governance model powered by decentralized intelligence: \u201cThe AI is Law\u201d.\n\nThe blockchain nervous system(BNS) is the main component of the DFINITY platform. The BNS enables a sort of \u201cliquid democracy in the DFINITY network in which it can freeze, unfreeze and modify smart contracts. The architecture of the BNS is incredibly simple. In the current design, proposals can be submitted to the BNS for a fee. The BNS acts on proposals using votes made by human-controlled \u201cneurons\u201d that automatically follow each other( hence the liquid democracy concept). The BNS adapts and learns to make better decisions as neurons respond to stimuli and feedback. Each neuron is operated using special client software run by its owner on the edge of the network and the BNS studies the behavior of neurons in order to make better decisions: The AI is Law.\n\nIf the BNS depends on neurons in order to make decisions, then the next questions is how do we create neurons? In the DFINITY network, any participant can create neurons by depositing a proprietary token known as Dfinities. The influence of a neuron in a voting process is proportional to the size of the deposit. The neuron owners can get back their deposit when dissolving the neuron but the process takes about three months which creates a strong incentive to not create neurons with the sole intent of manipulating the network.\n\nNeurons are operated by special client software that is typically installed on a user laptop or secure server and runs in the background, constantly monitoring the chain-resident portion of the BNS (which is implemented using smart contracts that have access to privileged op codes) to see if any new proposals have been submitted.\n\nDfinities are custom tokens used to enable different activities in the DFINITY platform. For starters, Dfinities are used to deploy and run smart contract software in the network. Similarly, the tokens can be used as security deposits for \u201cmining identities\u201d that allow participants to join the network or that allow neurons to participate in the voting process.\n\nScalability is, without a doubt, the main benefit of the DFINITY platform. Blockchains like Ethereum have been hammered with scalability challenges that have forced developers to build increasingly hybrid applications that avoid the use of the blockchain in many scenarios. DFINITY architecture has the potential to enable a high performance decentralize network that can run highly scalable systems without the need of relying on off-chain computations. Its not crazy to think that, in the future, we will see the equivalent of a Salesforce or Gmail running on the DFINITY network."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-microsoft-wants-machines-to-understand-what-they-read-ebe61e1853a5?source=user_profile---------17----------------",
        "title": "What\u2019s New in Deep Learning Research: Microsoft Wants Machines to Understand What They Read",
        "text": "Machine reading comprehension(MRC) is an emergent discipline in the field of deep learning. From a conceptual standpoint, MRC focuses on deep learning models that can answer intelligent questions about specific text documents. For humans, reading comprehension is a native cognitive skill developed since the early days of school or even before. At we are reading a text, we are instinctively extracting the key ideas that will allow us to answer future questions about that subject. In the case of artificial intelligence(AI) models, that skill is still largely underdeveloped.\n\nThe first widely adopted generation of natural language understanding(NLU) techniques has focused mostly on detecting the intentions and concepts associated with a specific sentence. We can think about these models as a first tier of knowledge to enable reading comprehension. However, full machine reading comprehension needs additional building blocks that can extrapolate and correlate questions to specific sections of a text and build knowledge from specific sections of a document.\n\nOne of the biggest challenges in the MRC domain is that most models are based on supervised training with datasets that contain not only the documents but potential questions and answers. As you can imagine, this approach is not only very difficult to scale but practically impossible to implement in some domains in which the data is simply not available. Recently, researchers from Microsoft proposed an interesting approach to deal with this challenge in MRC algorithms.\n\nIn a paper titled \u201cTwo-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\u201d, Microsoft\u2019s AI researchers introduced a technique called two stage synthesis networks or SynNet that applies transfer learning to reduce the effort to train a MRC model. SynNet can be seen as a two phase approach to build knowledge related to a specific text. In the first phase, SynNet learns a general pattern of identifying potential \u201cinterestingness\u201d in a text document. These are key knowledge points, named entities, or semantic concepts that are usually answers that people may ask for. Then, in the second stage, the model learns to form natural language questions around these potential answers, within the context of the article.\n\nThe fascinating thing about SynNet is that, once trained, a model can be applied to a new domain, read the documents in the new domain and then generate pseudo questions and answers against these documents. Then, it forms the necessary training data to train an MRC system for that new domain, which could be a new disease, an employee handbook of a new company, or a new product manual.\n\nMany people erroneously associate MRC technique with the more developed field of machine translation. In the case of MRC models such as SynNet, the challenge is that they need to synthesize both questions and answers for a document. While the question is a syntactically \ufb02uent natural language sentence, the answer is mostly a salient semantic concept in the paragraph, such as a named entity, an action, or a number. Since the answer has a different linguistic structure than the question, it may be more appropriate to view answers and questions as two different types of data. SynNet materializes in that theory by decomposing the process of generating question-answer pairs into two fundamental steps: The answer generation conditioned on the paragraph and the question generation conditioned on the paragraph and the answer.\n\nYou can think about SynNet as a teacher that is very good at generating questions from documents based on its experience. As it learn about the relevant questions in one domain, it can apply the same patterns to documents in a new domain. Microsoft researchers have applied the principles of SynNet to different MRC models including the recently published ReasoNet which have shown a lot of promise towards making machine reading comprehension a reality in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-understanding-progressive-neural-networks-38ef48751316?source=user_profile---------18----------------",
        "title": "What\u2019s New in Deep Learning Research: Understanding Progressive Neural Networks",
        "text": "The intersection between artificial intelligence(AI) and human cognition is one of the most fascinating areas of research in the modern technology space. Deep learning is constantly trying to emulate mechanisms of the human brain in order to improve the capabilities of AI agents. Many of those mechanisms are centered around how humans learn and build knowledge. A recent research paper from DeepMind is proposing a method that emulates the progressive nature of human learning in deep learning model. DeepMind calls this technique progressive neural networks.\n\nA fundamental difference between how humans and AI agents learn is that the latter almost always need to start from scratch while humans are phenomenal at leveraging prior experiences to acquire new knowledge. When confronted when learning a new subject, we rarely start from scratch. Instead we are constantly trying to reuse prior knowledge. Analogies, creativity, imagination are some of the cognitive skills that are enabled by our ability to correlate knowledge from different subject areas. Furthermore, as humans, we seem to completely incapable of completing forgetting knowledge acquired in our prior experiences. In the case of AI systems, that ability is still on very nascent states.\n\nIn the last few years, disciplines such as representation and transfer learning have been at the forefront of knowledge reusability. However, those techniques still have severe limitations when comes to learning similar tasks in the same model. In the transfer learning approach, a model is pretrained on a source domain (where data is often abundant), the output layers of the model are adapted to the target domain, and the network is finetuned via backpropagation. At the moment, transfer learning has tangible drawbacks which make it unsuitable for transferring across multiple tasks. For instance, if we wish to leverage knowledge acquired over a sequence of experiences, which model should we use to initialize subsequent models? This seems to require not only a learning method that can support transfer learning without catastrophic forgetting, but also foreknowledge of task similarity.\n\nThe idea of progressive neural networks is to effectively transfer knowledge across a series of tasks. Conceptually, progressive neural networks have three major goals:\n\na) The ability to incorporate prior knowledge at each layer of the feature hierarchy\n\nb) The ability to reuse old computations and learn new ones\n\nContrasting with transfer learning models that incorporates prior knowledge only at initialization, progressive networks retain a pool of pretrained models throughout training, and learn lateral connections from these to extract useful features for new tasks. The progressive approach to learning achieves richer compositionality and allows prior knowledge to be integrated at each layer of the feature hierarchy.\n\nTo see progressive neural networks in practice, lets take a neural network with some number L of layers trained to perform the initial task. In the DeepMind research, this neural network is known the initial column of the progressive network:\n\nWhen it comes time to learn the second task, the model will add an additional column and freeze the weights in the first column (to avoid catastrophic forgetting). The outputs of layer l in the original network becomes additional inputs to layer l+1 in the new column.\n\nIf a third task is needed, the model will add a third column, and connect the outputs of layer l in all previous columns to the inputs of layer l+1 in the new column:\n\nThe innovation of progressive neural networks is not so much to have come up with a brand-new learning technique but rather to combine a series of well know method into an innovative learning model. Progressive networks provide a model architecture in which catastrophic forgetting is prevented by instantiating a new neural network (a column) for each task being solved, while transfer is enabled via lateral connections to features of previously learned columns.\n\nThe goal of continuous and reusable learning is still years away in AI systems but I feel that progressive neural networks is a step in the right direction. The DeepMind team applied progressive learning to master a series of Atari games and the results, which are illustrated in the research paper, were nothing short of remarkable."
    },
    {
        "url": "https://medium.com/datadriveninvestor/why-decentralized-ai-matters-part-iii-technologies-930c3c9d10d?source=user_profile---------19----------------",
        "title": "Why Decentralized AI Matters Part III: Technologies",
        "text": "For today\u2019s Technology Fridays section we are going to take a different approach. Instead of analyzing a specific product or technology we are going to discuss a group of platforms as part of the series I\u2019ve been writing about decentralized artificial intelligence(AI) platforms. The first and second parts of this essay explored the market dynamics and technology enablers that have made possible the evolution of decentralized AI technologies. Today, I would like to focus some the main platforms in the decentralized AI space as well as some of their value proposition.\n\nAs explained in the previous post, there several technology movements such as homomorphic encryption, blockchain technologies and federated learning that combined to enable the first wave of decentralized AI platforms. As a result, this first group of technologies in the space combine traditional AI capabilities with sophisticated cryptographic features. Specifically, the initial evolution of decentralized AI platform has focused on enabling a decentralized and secure runtime to automate the lifecycle of AI applications. While the decentralized AI market is still in a very nascent state, already we can see a number of platforms that are likely to achieve a leadership position in the space.\n\nArguably the most well-known project in the decentralized AI space, SingularityNET is an open-source protocol and collection of smart contracts for a decentralized market of coordinated AI services. Conceptually, SingularityNET acts as a general-purpose, decentralized marketplace that provides a portfolio of AI agents which can be used in exchange for cryptocurrencies.\n\nThe SingularityNet platform extends AI agents with interfaces based on blockchain smart contracts that allow them to join the network and interact with third party applications or other agents. The initial version of SingularityNET smart contracts is based on Ethereum\u2019s Solidity language but other smart contract environments should be supported in the future. To execute operations, the smart contracts exchange AGI tokens as the main economic unit to pay for the services performed by an AI agent.\n\nI recently published an analysis of the SingularityNet platform.\n\nOpenMined likes to brand themselves as a decentralized AI community rather than a specific platform. From that perspective, OpenMined has been implementing a series of tools and frameworks that enable the implementation of decentralized AI applications.\n\n\u00b7 Sonar \u2014 A federated learning server running on the blockchain that handles all campaign requests, holding Bounty in trust.\n\n\u00b7 Capsule \u2014 A third-party PGP server to generate public and private keys in order to ensure that Sonar neural network stays encrypted properly.\n\nI recently published an analysis of the OpenMined platform.\n\nOcean is trying to become the ubiquitous protocol for decentralized AI applications. Conceptually, the Ocean Protocol is an ecosystem for sharing data and associated services. It provides a tokenized service layer that exposes data, storage, compute and algorithms for consumption with a set of deterministic proofs on availability and integrity that serve as verifiable service agreements. Architecturally, the Ocean Protocol includes the following components:\n\n\u00b7 Providers: \u200bThese actors have AI data or services that they make available in a cryptographically provable fashion. Services may include: data itself, storage (centralized or decentralized), compute 10 (centralized or decentralized, privacy-preserving or not), and more.\n\n\u00b7 Marketplaces: \u200bData/service marketplaces are typically how providers and consumers interact with Ocean network, for convenience. Each marketplace is expected to facilitate features such as discovery, transactability or verification\n\n\u00b7 Data commons interfaces: \u200bSide-by-side with data marketplaces that serve priced data are interfaces for data commons, for free or commons data. These interfaces might be webpages, software libraries, and so forth. Keepers. \u200bThe Ocean network itself is composed of a set of Ocean keeper nodes .\n\n\u00b7 Keeper: Keppers are responsible for collectively maintaining the network. Anyone can run an Ocean keeper node; it\u2019s permissionless. Participation is open and anonymous.\n\nThe Effect.AI platform leverages the NEO blockchain to provide a decentralized runtime to AI applications. At a high level, Effect.AI includes the following components:\n\n\u00b7 Effect M-Turk: Effect M-Turk is a workforce on demand that allows anyone in the world to request or perform tasks that teach and develop AI algorithms.\n\n\u00b7 Effect Smart Market: The Effect Smart Market is a decentralized exchange where people can offer and buy AI/ML services and algorithms.\n\n\u00b7 Effect M-Power: Effect M-Power can distribute computational power to AI models built using deep learning frameworks such as Caffe, MXNet and Tensorflow.\n\nDecentralized Machine Learning(DML) is a recent addition to the decentralized AI space. The new protocol provides a blockchain agnostic runtime to run machine learning models across different devices while also decentralizing other capabilities such as training or data sharing.\n\nAlgorithmia recently ventured into the decentralized AI space by launching their Danku, a new blockchain-based protocol for evaluating and purchasing ML models on a public blockchain such as Ethereum. DanKu enables anyone to get access to high quality, objectively measured machine learning models.\n\nYou can read my analysis about Algorithmia Danku here."
    },
    {
        "url": "https://medium.com/datadriveninvestor/why-decentralized-ai-matters-part-ii-technological-enablers-a67e3115312e?source=user_profile---------20----------------",
        "title": "Why Decentralized AI Matters Part II: Technological Enablers",
        "text": "This is the second part of an essay that explores the value proposition of decentralized artificial intelligence(AI) as one of the foundational technology trends of the next decade. In the previous part, we discussed some of the economic fundamentals of decentralized AI. Today, we will explore some of the technology trends that are enabling the first wave of decentralized AI platforms.\n\nDespite its somewhat obvious value proposition, the path to decentralized AI was plagued with very difficult technical challenges that made it completely impractical in real world applications. In our previous article, we identified four main challenges that need to be addressed for decentralized AI to become a viable architecture in modern AI applications:\n\nFrom the pure technological standpoint, many of these problems were considered unsolvable until recently. In the last few years, new technologies in the cryptography, digital currencies and AI space has come together to provide a solid foundation for the implementation of decentralized AI applications.\n\nMathematically, homomorphism is defined as \u201ca mapping of a mathematical set (such as a group, ring, or vector space) into or onto another set or itself in such a way that the result obtained by applying the operations to elements of the first set is mapped onto the result obtained by applying the corresponding operations to their respective images in the second set\u201d. Homomorphic encryption allows specific types of computations to be carried out on ciphertext which produces an encrypted result which is also in ciphertext. Its outcome is the result of operations performed on the plaintext. For instance, one person could add two encrypted numbers and then another person could decrypt the result, without either of them being able to find the value of the individual numbers.\n\nHomomorphic encryption can be considered one of the greatest breakthroughs in the cryptography space in the last decade. In the context of decentralized AI, homomorphic encryption enables participants in an AI application to contribute data to training of a model in a way that it remains encrypted to the other parties.\n\nBlockchains provide the fundamental runtime and protocols to enable true decentralized AI applications. The first generation of dencetralized AI applications are leveraging concepts such as smart contracts or DApps to model the interactions between different endpoints in an AI application.\n\nDigital tokens are also a relevant concept in decentralized AI application as it represents the main mechanism to compensate data scientists for their contributions to a model. Digital tokens also provide an economic channel to guide and influence the behavior of models in a way that benefit all the interested parties.\n\nFederated learning is a new learning architecture for AI systems that operate in highly distributed topologies such as mobile or internet of things(IOT) systems. Initially proposed by Google research labs, federated learning represents an alternative to centralized AI training in which a shared global model is trained under the coordination of a central server, from a federation of participating devices. In that model, the different devices can contribute to the training and knowledge of the model while keeping most of the data in the device.\n\nIts not hard to envision why federated learning is foundational to decentralized AI platforms. Using federated learning, multiple participants in an AI applications can independently train or optimize an AI model without having to trust each other or a centralized authority.\n\nI hope this series is keeping you engaged. In the next part, we will discuss some of the new platforms in the dencentralized AI space."
    },
    {
        "url": "https://medium.com/datadriveninvestor/why-decentralized-ai-matters-part-i-economics-and-enablers-5576aeeb43d1?source=user_profile---------21----------------",
        "title": "Why Decentralized AI Matters Part I: Economics and Enablers",
        "text": "The emerging field of decentralized artificial intelligence(AI) is becoming one of the most exciting technology trends of the last few months. A lot has been written about the potential value of the intersection of artificial intelligence(AI) and blockchain technologies and we, this year, we have even entire conferences dedicated to the subject of decentralized AI. However, I feel that a lot of the hype behind decentralized AI fails to highlight some of the key value propositions of the new technology movement that can make it one of the most foundational technology trends of this decade. If you believe in the idea that AI is going to become an increasingly influential factor in our daily lives, I believe decentralized AI will be an essential element to guide the impact that machine intelligence will have in future generations. Sounds dramatic? Let\u2019s look at some of the economic dynamics behind decentralized AI to try to clarify our point.\n\nThese days, the notion of AI systems is intuitively linked to centralization. The first thing that comes to mind when we talk about AI are companies such as Amazon, ,Facebook or Google whose machine intelligence systems are becoming part of our daily lives. The increasingly rich data assets possessed by those companies have allowed them to capitalize first on the AI revolution and create an economic dynamic that is not always aligned with the end consumer. Even the technology and methodologies we used today for building AI systems assumes a centralization model at its core.\n\nThe lifecycle of a modern AI project assumes that you have a model and a massively large, high quality dataset that you can use to train it as well as a pool of data scientists that can constantly regularize and optimize the model in order to become more intelligent. In most AI scenarios, that entire cycle is performed by a single entity that has the resources to collect large datasets, create highly sophisticated AI models and run across expensive computing resources.\n\nThe irony of all this is that, when you look deeper, the economic incentives of the large party providing the AI models are not necessarily aligned with the value creation for consumers. From an economic standpoint, there can be many scenarios in which the ability of an AI agent to increase the value of the assets of its creator in the form or revenue, data or simple outcomes is not directly correlated with the ability of creating more value for consumers.\n\nThe centralized nature of AI systems highly contrasts with the evolution of human intelligence. Knowledge exists completely scattered and federated across the world. Erudition is a novel goal in live but nobody can claim to posses all knowledge of a particular subject. Knowledge collaboration and federation is one of the key unique advantages that allow humans to evolve and dominate other species that were physically more powerful. And yet, AI remains increasingly centralized. In a world that is moving rapidly towards the creation of general AI and systems that can vastly superpass the level of intelligence of mankind, wouldn\u2019t we want that knowledge and influence to be federated instead of controlled a few organizations?\n\nThe emergence of technologies such as mobile computing or internet of things(IOT) challenged the centralized notion of AI. Today, knowledge is constantly created in the edges and flows towards centralized hubs. The pendulum has to shift to a dynamic in which aspects such as the training, optimization, testing and knowledge creation of AI model becomes federated across many participants.\n\nIn order to decentralized AI models, we need to solve a few challenges:\n\na) The Privacy Problem: Can entities train a model without having to disclose their data.\n\nb) The Influence Problem: Can third parties contribute to the behavior of knowledge of an AI model in a way that is quantitatively influential.\n\nc) The Economic Problem: Can third parties be correctly incentivized to contribute to the knowledge and quality of an AI model.\n\nd) The Transparency Problem: Can the activity of behavior of an AI model be transparently available to all parties without the need of trusting a centralized authority.\n\nOpen source today is highly rewarded and the best and most efficient way to create software but that wasn\u2019t always the case. For decades, large software companies preferred to embrace closed source delivery models in order to have an edge in terms of intellectual property(IP). Eventually, the economic dynamics proved that thousands of talented engineers regularly contributing to a project produce better code than a few engineers driven by corporate interests.\n\nIf we extrapolate the evolution of open source to the AI world, today we are somewhere in the 1990s in which the value creation of software was controlled and influenced by a few companies. What is worse, when comes to AI, we are not only talking about software or AI models, but also other expensive resources such as data science talent, data and computing power. In that world, decentralized AI is the new open source except that the impact in mankind can be order of magnitude more impactful to mankind.\n\nIn the next part of this article, we will discuss the technologies that are enabling decentralized AI architectures and some of the emerging players in the space."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-the-sentiment-neuron-4cd8ad1c6b26?source=user_profile---------22----------------",
        "title": "What\u2019s New In Deep Learning Research: The Sentiment Neuron",
        "text": "Representation learning is one of the most important techniques in modern deep learning systems. By representation learning, we are referring to models that can learn the underlying knowledge representations of a dataset in a way that can be used by other models. Transfer learning is one of the most popular forms of representation learning that can be found in most deep learning toolkits in the market. Broadly speaking, there are two main forms groups of representation learning techniques that can be found in deep learning systems.\n\nThe supervised training of high-capacity models on large labeled datasets is critical to the recent success of deep learning techniques for a wide range of applications such as image classification, speech recognition, and machine translation. There is also a long history of unsupervised representation learning which can be considered the Holy Grail in the space due to its ability to scale beyond only the subsets and domains of data that can be cleaned and labeled given resource, privacy, or other constraints. While supervised representation learning clearly dominates the current state of the market, researchers have long dreamed with unsupervised models that can learn reusable representations of knowledge. Collecting data is easy, but labeling data at scale is hard and, many time, resource prohibited.\n\nUnsupervised sentiment analysis is one of the most active areas of research in the representation learning space. Learning topics, phrases and sentiment over large amounts of unlabeled texts is one of the representation learning techniques that can yield immediate positive results in real world deep learning applications. Imagine that we can identify the specific segment of a deep neural network responsible for the sentiment knowledge and that we can reuse that across other models. Wouldn\u2019t that be great? Recently, researchers from OpenAI published a paper in which they outline the concept of a specific unit of a neural network responsible for the concept of sentiment: a sentiment neuron.\n\nThe discovery of the sentiment neuron was a little bit of a surprising coincidence. The original OpenAI research was focused on training a long-short-term-memory model to be able to predict the next character in the text dataset of Amazon product reviews. When going through the model regularization process, data scientists discovered that a single unit of the network was highly predictive of the sentiment of the text. Even when the model was trained to predict characters in a text, the sentiment neuron within the model was able to classify reviews as negative or positive.\n\nThe OpenAI researchers suspect that the sentiment neuron is not an exclusive property of their LSTM model and rather a common feature of large deep neural networks that operate on high volume text datasets. To prove that point, the OpenAI team applied the sentiment neuron against a dataset of Yelp reviews providing encouraging results.\n\nThe OpenAI sentiment neuron was not without issue and the model struggle in other setting but, nonetheless, it represents a major breakthrough in the unsupervised representation learning space. What the sentiment neuron technique teaches us is that sentiment can be expressed as an accurate, disentangled, interpretable and manipulable way. It is possible that sentiment as a conditioning feature has strong predictive capability for language modelling."
    },
    {
        "url": "https://medium.com/@jrodthoughts/sunday-book-club-skin-in-the-game-7e3bbf8da2c7?source=user_profile---------23----------------",
        "title": "Sunday Book Club: Skin in the Game \u2013 Jesus Rodriguez \u2013",
        "text": "I recently finished reading Nassim Nicholas Taleb\u2019s fifth book: Skin in the Game. The book followed international best sellers such as Antifragile, The Black Swan and Fooled by Randomness which made Taleb one of the most popular authors in topics such as modern philosophy and economics. Skin in the Game does not disappoints and becomes a natural complement to the previous titles but, this time, Taleb deviates from pop-philosophical concepts to focus on as simple idea appealing to any human being: if you have no skin in the game, you shouldn\u2019t be in the game. \u201cIf you give an opinion, and someone follows it, you are morally obligated to be, yourself, exposed to its consequences.\u201d\n\nThroughout the book, Taleb presents a series of examples how the outcome of events is radically different when the participants have \u201cskin in the game\u201d. As Taleb says \u201cHawks in the White House should not be taking decisions about bombs in Iraq when they will remain in their air-conditioned houses with their 2.2 children whatever the result\u201d. Other professions such as doctors intrinsically doctors have skin in the game, having professional pride and reputation, severe legal consequences for error.\n\nSkin in the game ensures that people learn from their mistakes and evolve their thinking. Taleb goes as far as invoking the ancient Babylonian code of Hamurabi that includes 282 laws, with scaled punishments and links actors to consequences of their action.\n\nIn my opinion, the most important takeaway from Taleb\u2019s book is that skin in the game is not only an principle in life but a central pillar of organic functioning systems and even evolution itself. As Taleb said in a recent blog post: \u201cSystems don\u2019t learn because people learn individually \u2013that\u2019s the myth of modernity. Systems learn at the collective level by the mechanism of selection: by eliminating those elements that reduce the fitness of the whole, provided these have skin in the game\u201d"
    },
    {
        "url": "https://medium.com/datadriveninvestor/chainweb-and-the-art-of-scalable-blockchains-part-ii-90efce48d885?source=user_profile---------24----------------",
        "title": "Chainweb and the Art of Scalable Blockchains Part II",
        "text": "This is the second part of an article that explores the, recently published, Chainweb architecture as a model to scale proof-of-work(PoW) systems in blockchains. The first part explored some techniques such as proof-of-stake(PoS) systems or payment channels that have been created to address the performance limitations of PoW architectures and some of the challenges that those techniques present. Today, I would like to deep dive into some of the concepts behind Chainweb that makes is a viable option for scaling PoW blockchains.\n\nAS describe in the previous article, the novel idea behind Chainweb is to combine multiple blockchains using different network topologies that can process transactions in parallel. From that perspective, Chainweb is able to scale without requiring off-chain mechanisms such as side-chains or payment channels. The architecture of Chainweb can be segmented into two main components:\n\nb) Parallel-chain binding at the hashing level via peer-chain Merkle root inclusion.\n\nChainweb borrows the concept of SPV from the original Bitcoin architecture and applies it to cross-blockchain transactions. The main idea of SPVs is to verify transactions without running a full node in a blockchain network. Chainweb uses a common currency across all blockchains in the network which posses the challenge of moving liquidity across chains in a trustless manner. The platform accomplishes that by enabling an inter-chain transfer protocol that is able to move coins by deleting it in an account on one chain and creating it in an account on the other. Every time a transaction occurs, the inter-chain protocol will use SPV proofs of deletion on one chain are provided to the creating chain to be validated by built-in functionality in the application layer.\n\nThe following figure illustrates the Chainweb process to transfer 10 coins between two people with accounts on different blockchains.\n\nThe second component of the Chainweb architecture is the PoW protocol itself. A Chainweb network can run thousands of chains simultaneously using distinct coins from the same cryptocurrency. Each chain incorporates a subset of other peers\u2019 Merkle roots in its own block hashes. Which allows a given chain to validate that its peer chains are maintaining a consistent fork by locating its own previous Merkle roots. Additionally, the mechanism also provides a trustless oracle of peer Merkle roots, which is necessary to allow application layer transfer code to validate provided Merkle proofs to guarantee cross-chain transfers of funds.\n\nOne of the most impressive capabilities of the Chainweb protocol is the ability to work across very diverse blockchain topologies which enables its adaptability to very complex scenarios. The following figure illustrates some of the common topologies in a Chainweb architecture.\n\nProtocols like Chainweb that preserve the PoW model to confirm transactions in a blockchain can be the problem to the \u201cCryptokitties problem\u201d of public blockchains. The challenge is typically associated with scenarios in which a popular application consumes a lot of the mining power in a blockchain network affecting other important applications such as ICOs. In the Chainweb model, a Cryptokitties-like application can run on several chains of its own, while a massive [initial coin offering] can happen on another chain in the network and they won\u2019t slow each other down. While the protocol still requires some battle testing, it certainly seems like a step in the right direction to scale PoW blockchains to the level they can support high performance, mission critical applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-the-impressive-research-powering-google-cloud-s-new-text-to-840570505f70?source=user_profile---------25----------------",
        "title": "What\u2019s New in Deep Learning Research: The Impressive Research Powering Google Cloud\u2019s New Text to\u2026",
        "text": "Yesterday, Google announced a new voice synthesizer service powered by some of the work of its subsidiary DeepMind. Named, Cloud Text-to-Speech(TTS), the new service can effectively operate using 32 different voices from 12 languages and variants. The result is a platform that can produce speech streams that sound more natural and realistic than other mainstream TTS technologies in the market. Cloud Text-to-Speech also represents an important milestone for the deep learning community as it\u2019s the first practical application of a lot of breakthrough research in the voice processing space. Today, I would like to give you an overview of some of the research powering Google Cloud\u2019s latest artificial intelligence service.\n\nThe first thing to understand about Cloud Text-to-Speech is that is powered by DeepMind\u2019s WaveNet, a deep learning system that is able to generate audio from scratch using a huge database of human speech and re-creates them at a rate of 24,000 samples per second. WaveNet challenges traditional TTS paradigms by directly modelling the raw waveform of the audio signal, one sample at a time. As well as yielding more natural-sounding speech, using raw waveforms means that WaveNet can model any kind of audio, including music.\n\nLast year, researchers from Google announced Tacotron2, a TTS architecture that sort of represents the latest and most advanced iteration of WaveNet.\n\nAnother important research related to Cloud Text-to-Speech is the concept of prosody embedding which was published on a research paper a few days ago. Conceptually, prosody embedding augments the Tacotron2 architecture with an additional prosody encoder that computes a low-dimensional embedding from a clip of human speech (the reference audio). The new TTS technique captures characteristics of the audio that are independent of phonetic information and idiosyncratic speaker traits \u2014 these are attributes like stress, intonation, and timing. At inference time, we can use this embedding to perform prosody transfer, generating speech in the voice of a completely different speaker, but exhibiting the prosody of the reference. The following diagram illustrates how prosody embedding works in the context of a TTS model.\n\nStyle Tokens is another deep learning technique that plays an important role in the new Google Cloud Text-to-Speech service. The idea behind Style Tokens is to complement prosody embedding with a new unsupervised algorithm for modeling latent \u201cfactors\u201d of speech such as soft, high-pitch, intense and several others. Technically, Style Tokens are a more granular representation of prosody embedding in any speech clip.\n\nGoogle\u2019s research shows that Style Tokens can model more than just speaking style. When trained on noisy YouTube audio from unlabeled speakers, a Tacotron2 architecture based on Style Tokens is able to learn to represent noise sources and distinct speakers as separate tokens."
    },
    {
        "url": "https://medium.com/datadriveninvestor/chainweb-and-the-art-of-scalable-blockchains-ed0c9ff03ab3?source=user_profile---------26----------------",
        "title": "ChainWeb and the Art of Scalable Blockchains Part I",
        "text": "The proof of work(PoW) computation model of public blockchain technologies has been one of the major breakthroughs in computer science of the last decade. However, traditional PoW-based blockchains has proven to have major limitations in terms of throughput and performance when used in large scale scenarios. Most PoW blockchains such as Bitcoin are only able to process a handful of transactions per second; a statistic that pales compared to traditional centralized payment systems. Scaling trustless, PoW based computations represents one of the biggest challenges for the current generation of blockchain technologies in order to truly become a decentralized internet. Recently, a startup called Kadena that was initially incubated by J.P Morgan published a new decentralized protocol that might be one of the cleverest solution I\u2019ve ever seen to try to address the scalability issue in PoW systems.\n\nKadena\u2019s Chainweb is a new decentralized protocol that combines multiple blockchains to achieve PoW consensus at incredibly high throughput. Some of the initial benchmark showed that the Chainweb protocol can operate across over 1000 blockchain and process about 10,000 transactions per second which is miles ahead of other PoW systems. A good way to understand the relevance of Chainweb might be to understand other approaches to scale trustless computations in modern blockchain networks. Among those, Proof-Of-Stake and the Lightning Network are becoming increasingly popular in the blockchain community.\n\nProof-Of-Stake(PoS) protocols emerged as a scalable alternative to traditional PoW systems. Essentially, PoS is an alternate way of verifying and validating the transaction or block. The method is based on a Validator (Equivalent of \u201cminer\u201d in the PoW) which selected by the amount of stake(coins) it holds and the respective age of the stake. If a Validator has 100,000 alt coins in a wallet, it will have an age attached to it on how long it has it. Here the 100,000 alt-coins is the stake. In any transaction, the aging gets reset. This amount is like the security deposit which means the Validator holds a significant stake in the alt-coin with good aging is more committed and combined with many other factors, will get a higher chance to validate a block.\n\nPoS systems are an important alternative to PoW protocols but don\u2019t come without limitations. For starters, PoS systems has been far less tested in financial transaction operations than PoW protocols which makes them a riskier alternative. More importantly, the fact that the different participants in a transaction need to stake funds in order to validate can be subjected to different regulatory controls in financial markets.\n\nPayment channels such as the popular Lightning Network are another interesting alternative to PoW protocols. The idea of Payment Channels protocols is to break down a transaction into a series of smaller payments executed through a channel. In that model, funds are sequestered from the main network and are used in a series of smaller payments (or commitments) between a specified set of actors, with the ability to net out the payments on the main network at any time.\n\nFor instance, suppose that two parties in a Lightning Network would like to engage in a transaction. They wll start by setting up multisig wallet (which requires more than one signature to enact a transaction). This wallet holds some amount of bitcoin. The wallet address is then saved to the bitcoin blockchain. This sets up the payment channel. At that point, the two parties will be able to conduct an unlimited number of transactions without ever touching the information stored on the blockchain. With each transaction, both parties sign an updated balance sheet to always reflect how much of the bitcoin stored in the wallet belongs to each.When the two parties have done transacting, they close out the channel, and the resulting balance is registered on the blockchain.\n\nPayment channels are a promising alternative to PoW but also bring new challenges to decentralized transactions. Notably, the fact that funds must be pre-allocated for a channel imposes significant liquidity constraints which limits their availability to all but the largest stakeholders or those engaged in complicated multi-party arrangements.\n\nThe novel idea behind Chainweb is that the PoW protocol achieves consensus by processing a transaction through a network of chains that it calls Chainweb. In Chainweb, each chain must, in addition to validating transactions in its own chain, validate block headers of some number of pre-specified chains in order to produce a new block. The different chains integrate their Merkle roots with each other, ensuring that while they each act as a unique blockchain, they can still share information and create a consensus among the ledgers.\n\nThe Chainweb architecture enables to organize the different blockchains in arbitrarly complex topologies which allows its adaptability to different scenarios. To my knowledge, Chainweb is the only PoW scaling proposal that doesn\u2019t require side channels and is able to preserve the security of the network as it scales.\n\nExcited about Chainweb? Good! Because, in the next part of this article, I will deep dive into the Chainweb architecture and protocol"
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-knowledge-exploration-with-parameter-noise-98aef7ce84b2?source=user_profile---------27----------------",
        "title": "What\u2019s New in Deep Learning Research: Knowledge Exploration with Parameter Noise",
        "text": "The exploration vs. exploitation dilemma is one of the fundamental balances in deep reinforcement learning applications. How much resources to devote to acquire knowledge that can improve future actions versus performing specific actions? This is one of the main heuristics that rule the behavior of reinforcement learning systems. In theory, optimal exploration should always conduce to more efficient knowledge but this is far from true in the real world. Developing techniques to improve the exploration of an environment is one of the pivotal challenge of the current generation of deep reinforcement learning models. Recently, researchers from OpenAI published a research paper that proposes a very original approach to improve the exploratory capability of reinforcement learning algorithms by nothing else than introducing noise.\n\nTo understand the challenge with exploration in deep reinforcement learning systems think about researchers that spend decades in a lab without producing results with any practical application. Similarly, reinforcement learning agents can spend a disproportional amount of resources without producing a behavior that converge to a local optimum. This happens more often than you think as the exploration model is not directly correlated to the reward of the underlying process. The OpenAI team believes that the exploratory capability of deep reinforcement learning models can be directly improve by introducing random levels of noise in the parameters of the model. Does it sounds counterintuitive? Well, it shouldn\u2019t. Consider the last time to learn a practical skill, such as a board game, by trial and error. I am sure you can recall instances in which you were challenging the conditions of the environment( such as the game rules) in order to solidify your knowledge. That\u2019s effectively introducing noise in the input dataset J.\n\nThe OpenAI approach is not the first technique that proposes to improve exploration by introducing noise in a deep learning model. However, most of its predecessors focused on what is known as Action-Space-Noise approaches which introduce noise to change the likelihoods associated with each action the agent might take from one moment to the next. In that approach, it is very likely to obtain a different action whenever that state is sampled again in the rollout, since action space noise is completely independent of the current state. OpenAI proposes an alternative, called Parameter-Space-Noise, that introduces noises in the model policy parameters at the beginning of each episode. The Parameter-Space-Noise technique almost guarantees that the same action will be applied every time the same state in sampled from the input dataset which improves the exploratory capabilities of the model.\n\nThe Parameter-Space-Noise technique works very nicely with existing exploration models in deep reinforcement learning algorithms. Like some of its predecessors, the OpenAI researchers encountered some challenges\n\nThe research paper proposes solutions to tackle these challenges using well-known optimization techniques in the deep learning space.\n\nThe initial results of the Parameter-Space-Noise model proved to be really promising. The technique helps algorithms explore their environments more effectively, leading to higher scores and more elegant behaviors. This seems to be correlated to the fact that Parameter-Space-Noise adds noise in a deliberate manner to the parameters of the policy makes an agent\u2019s exploration consistent across different timesteps. More importantly, the Parameter-Space-Noise technique is relatively simple to implement using the current generation of deep learning frameworks. The OpenAI team released an initial implementation as part of its reinforcement learning baselines."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-about-watsons-new-deep-learning-as-a-service-vision-bdd2243a03f3?source=user_profile---------28----------------",
        "title": "Technology Fridays: About Watson\u2019s New Deep Learning as a Service Vision",
        "text": "Welcome to Technology Fridays! Today, I would like to deep dive into one of the major announcements at IBM\u2019s Think conference that took place this week. At the event, big blue unveiled a new suite of artificial intelligence infrastructure and platform services under the catchy name of Deep Learning as a Service(DLaaS). The new stack extends the capabilities of Watson Studio to streamline the implementation and operationalization of deep learning solutions across different stacks.\n\nBeyond the marketing hype, IBM\u2019s DLaaS vision has some very interesting ideas that are worth exploring. From the market perspective, the release is an attempt to bridge the gap with the machine learning cloud services provided by platforms such as Microsoft Azure or Google Cloud that have been taking a leadership position as enablers of cloud deep learning solutions. However, IBM\u2019s DLaaS is not merely a replication of deep learning capabilities existing in other platforms and it provides some very unique technology components assembled in a cohesive story.\n\nI mentioned before that IBM\u2019s DLaaS enhancements live within Watson Studio. The main contribution of the new stack is a consistent cloud runtime for applications developed using different deep learning frameworks such as TensorFlow, PyTorch, Keras or IBM\u2019s favorite Caffe.\n\nThe DLaaS stack provides a series of tools and services that streamline different aspects of the lifecycle of deep learning applications. As a matter of fact, if you can visualize the typical lifecycle of a deep learning application from experimentation to optimization, you will find different DLaaS tools and services on each stage of the cycle. Let\u2019s explore some of the important elements of the IBM DLaaS suite.\n\nIBM DLaaS Experiment Assistant are a series of tools and runtime components that automate the workflows for training and evaluating deep neural networks. Data scientists can use the Experiment Assistant to configure, execute and monitor training workflows for deep learning models without having to be concerned about the underying infrastructure.\n\nAnother important addition to IBM DLaaS is the Neural Network Modeler. This new tool enables the implementation of deep learning programs by providing an intuitive drag-and-drop interface that enables a non-programmer to speed up the model-building process by visually selecting, configuring, designing and auto-coding their neural network using the most popular deep learning frameworks.\n\nAs part of the release of Watson DLaaS, IBM is open sourcing the core runtime of the platform. Named the Fabric for Deep Learning (pronouncedFfDL), the new open source package provides a scalable, resilient, and fault-tolerant runtime for the execution of deep learning programs. The Fabric for Deep Learning leverages technologies such as Kubernetes and Uber\u2019s Horovod to provide a distributed environment for the execution of deep learning models.\n\nIBM DLaaS can be seen as a series of addition to Watson Studio rather than a standalone release. From that perspective, the new stack is a competitive alternative to platforms such as Azure ML, AWS SageMaker or Google Cloud ML. If many thought that IBM was faling behind the other cloud incumbents in the race to become the preferred home for deep learning applications, the release of the DLaaS suite signals to the market that IBM has a very unique and innovative vision about the space ."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-jennifer-aniston-and-the-process-of-understanding-learning-by-d961ae2df0e3?source=user_profile---------29----------------",
        "title": "What\u2019s New in Deep Learning Research: Jennifer Aniston and the Process of Understanding Learning by\u2026",
        "text": "Have you ever heard about the Jennifer Aniston neuron? In 2005, a group of neuroscientists led by Rodrigo Quian Quiroga published a paper (pdf) detailing his discovery of a type of neuron that steadily fired whenever she was shown a photo of Jennifer Aniston. The neuron in question was not activated when presented with photos of other celebrities. Obviously, we don\u2019t all have Jennifer Aniston neurons and those specialized neurons can be activated in response to pictures of other celebrities. However, the Aniston neuron has become one of the most powerful metaphors in neuroscience to describe neurons that focus on a very specific task.\n\nThe fascinating thing about the Jennifer Aniston neuron is that it was discovered while Quiroga was researching areas of the brain that caused epileptic seizures. It is a well known fact that epilepsy causes damages across different areas of the brain but determining those specific areas is still an active area of research. Quiroga\u2019s investigation into damaged brain regions led to the discovery in the functionality of other neurons.\n\nExtrapolating Quiroga methodology to the world of deep learning, data scientists from DeepMind recently published a paper that proposes a technique to learn about the impact of specific neurons in a neural network by causing damages to it. Sounds crazy? Not so much, in software development as in neuroscience, simulating arbitrarily failure is one of the most powerful methods to understand the functionality of code. DeepMind\u2019s new algorithm can be seen as a version of chaos monkey for deep neural networks.\n\nHow does the DeepMind neuron deletion method really works? Very simply, the algorithm randomly deletes groups of neurons in a deep neural network and tries to understand their specific impact by running the modified network against the trained dataset.\n\nWhen evaluating DeepMind\u2019s new technique in image recognition scenarios , it produced some surprising results:\n\nJust like in neuroscience, deep learning models include a lot of highly specialized nodes such as the Jennifer Aniston neurons. Deep learning research has categorized many types of neurons based on their functionality. Google\u2019s famous cat neurons or OpenAI\u2019s sentiment neurons are some of the most famous specialized neurons in deep learning models. Common wisdom has suggested that the impact of those specialized neurons in a neural network is more relevant than common neurons. DeepMind\u2019s research proved exactly the opposite.\n\nSurprisingly, DeepMind\u2019s neuron deletion experiments found that there was little relationship between selectivity and importance. In other words, specialized neurons were no more important than confusing neurons. This finding echoes recent work in neuroscience which has demonstrated that confusing neurons can actually be quite informative, and suggests that we must look beyond the most easily interpretable neurons in order to understand deep neural networks.\n\nThe other big discovery by the DeepMind team is related to the correlation between the ability of a deep learning models to generalize well and its resiliency. In experiments that deleted different groups of nodes in a neural network, DeepMind researchers found out that networks which generalize well were much more robust to deletions than networks which simply memorized images that were previously seen during training. In other words, networks which generalize better are harder to break."
    },
    {
        "url": "https://medium.com/datadriveninvestor/about-salesforces-acquisition-of-mulesoft-a-market-perspective-2170c0dc99ba?source=user_profile---------30----------------",
        "title": "About Salesforce\u2019s Acquisition of MuleSoft: A Market Perspective",
        "text": "Yesterday, Salesforce announced that it has reached a final agreement to acquire MuleSoft for $6.5 billion. The news came as a surprise sending MuleSoft shares above 22% during market hours which forced the New York Stock Exchange to halt trading for a few minutes. The deal represents Salesforce biggest acquisition ever and one that should be very welcomed by its enterprise customers. MuleSoft complements the Salesforce product suite with a strong integration and API management capabilities giving a strong edge over its competitors.\n\nLooking beyond the market hype, Salesforce\u2019s acquisition of MuleSoft has major implications for different segments of the enterprise software landscape. Salesforce and MuleSoft both have strong footprints on several enterprise software markets and the deal certainly impacts the cloud, SaaS and integration landscapes. Let\u2019s explore how those market segments can be changed in the aftermath of the acquisition.\n\nLet\u2019s start with the simplest viewpoint to analyze this deal. Wall Street seems to love the Salesforce-MuleSoft combination. Shares of MuleSoft jumped on the news of the acquisition and has been trading steadily up prior to today\u2019s market opening. What\u2019s not to like? Salesforce will be paying $44.89 a share in cash and stock for a company that went public for $17 a share just a year ago.\n\nIn the case of Salesforce, the acquisition of MuleSoft is a robust building block towards its $20 billion goal. Shares of the software giant were slightly down by 2% mostly related to the fact that the company is borrowing $3 billion to complete the acquisition.\n\nThe addition of MuleSoft gives Salesforce a unique edge against cloud market leaders such as Microsoft, Amazon and Google. Integration is one of the weakest spots on the AWS, Azure and Google Cloud platforms. Azure recently ventured in the space with the launch of Logic Apps but the integration services, although innovative, its still miles behind MuleSoft\u2019s Anypoint platform. Similarly, Google Cloud has strong API management capabilities with its recent acquisition of Apigee but integration its still a weak link. By adding MuleSoft, Salesforce can bridge the gap with the cloud leaders by bringing the most sophisticated integration platform as a service(iPaaS) stack in the market to its product suite.\n\nIntegration is a key element of any SaaS implementation. The addition of MuleSoft brings differentiated capabilities to Salesforce business cloud products compared to competitors such as Microsoft, Oracle or SAP. Only Microsoft with the integration between Dynamics365 and LogicApps seems to be in a position to compete with a Salesforce-MuleSoft duo.\n\nThe acquisition of MuleSoft removes the strongest standalone company in the iPaaS market. It is only natural to think that Salesforce competitors must be evaluating options to answer to the acquisition. From that perspective, innovative iPaaS and API management startups such as SnapLogic or Mashape can become an immediate target for Salesforce competitors. I believe Microsoft is not a likely acquirer as the Redmond giant has been aggressively investing in its own stack. However, Amazon, Google and even Alibaba can soon be on the hunt for acquisitions that provides a defensive position against the Salesforce-MuleSoft joined platform."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-about-attentional-interfaces-4ef220268a18?source=user_profile---------31----------------",
        "title": "What\u2019s New in Deep Learning Research: About Attentional Interfaces",
        "text": "Trying to read this article is a complicated task from the neuroscientific standpoint. At this time you are probably bombarded with emails, news, notifications on our phone, the usual annoying coworker interrupting and other distractions that cause your brain to spin on many directions. In order to read this tiny article or perform many other cognitive tasks, you need to focus, you need attention.\n\nAttention is a cognitive skill that is pivotal to the formation of knowledge. However, the dynamics of attention have remained a mystery to neuroscientists for centuries and, just recently, that we have had major breakthroughs that help to explain how attention works. In the context of deep learning programs, building attention dynamics seems to be an obvious step in order to improve the knowledge of models and adapt them to different scenarios. Building attention mechanisms into deep learning systems is a very nascent and active area of research. A few months ago, researchers from the Google Brain team published a paper that detailed some of the key models that can be used to simulate attention in deep neural networks.\n\nIn order to understand attention in deep learning systems it might be useful to take a look at how this cognitive phenomenon takes place in the human brain. From the perspective of neuroscience, attention is the ability of the brain to selectively concentrate on one aspect of the environment while ignoring other things. The current research identifies two main types of attention both related to different areas of the brain. Object-based attention is often referred to the ability of the brain to focus on specific objects such as a picture of a section in this article. Spatial-based attention is mostly related to the focus on specific locations. Both types of attention are relevant in deep learning models. While object-based attention can be used in systems such as image recognition or machine translation, spatial-attention is relevant in deep reinforcement learning scenarios such as self-driving vehicles.\n\nWhen comes to deep learning systems, there are different techniques that have been created in order to simulate different types of attention. The Google research paper focuses on four fundamental models that are relevant to recurrent neural networks(RNNs). Why RNNs specifically? Well, RNNs are a type of network that is mostly used to process sequential data and obtain higher-level knowledge. As a result, RNNs are often used as a second step to refine the work of other neural network models such as convolutional neural networks(CNNs) or generative interfaces. Building attention mechanisms into RNNs can help improve the knowledge of different deep neural models. The Google Brain team identified the following four techniques for building attention into RNNs models:\n\n\u00b7 Neural Turing Machines: One of the simplest attentional interfaces, Neural Turing Machines(NTMs) add a memory structure to traditional RNNs. Using a memory structure allows ATM to specify an \u201cattention distribution\u201d section that describes the area that the model should focus on. A few months ago, I published an overview of NTMs that explores some of its fundamental concepts. Implementations of NTMs can be found in many of the popular deep learning frameworks such as TensorFlow and Theano.\n\n\u00b7 Attentional Interfaces: Attentional interfaces uses an RNN model to focus on specific sections of another neural network. A classic example of this technique can be found in image recognition models using a CNN-RNN duplex. In this architecture, the RNN will focus on specific parts of the images generated by the CNN in order to refine it and improve the quality of the knowledge.\n\n\u00b7 Adaptive Computation Time: This is a brand-new technique that allows RNNs to perform multiple steps of computation for each time step. How is this related to attention? Very simply, standard RNNs perform the same amount of computation of each step. Adaptive computation time techniques used an attention distribution model to the number of steps to run each time allowing to put more emphasis on specific parts of the model.\n\n\u00b7 Neural Programmer: A fascinating new area in the deep learning space, neural programmer models focus on learning to create programs in order to solve a specific task. In fact, it learns to generate such programs without needing examples of correct programs. It discovers how to produce programs as a means to the end of accomplishing some task. Conceptually, neural programmer techniques try to bridge the gap between neural networks and traditional programming techniques that can be used to develop attention mechanisms in deep learning models."
    },
    {
        "url": "https://cryptocurrencyhub.io/technology-fridays-oraclize-is-the-most-important-blockchain-technology-you-never-heard-of-1c6f77228a29?source=user_profile---------32----------------",
        "title": "Technology Fridays: Oraclize is the Most Important Blockchain Technology You\u2019ve Never Heard Of.",
        "text": "Welcome to Technology Fridays! As you know, the purpose of this section is to discuss cool and innovative technologies and that are still flying under the radar but that are playing an influential role in new technology trends. Today, we have a perfect example of that type of technology with a platform that has become a key ingredient of many blockchain applications in the real world. I am talking about Oraclize.\n\nBuilding blockchain applications sounds incredibly exciting until you have to deal with the friction between the requirements of real world solutions and the characteristics of the blockchain. There is no other example that illustrates those challenges better than the friction between the need of blockchain application to access data from external systems while maintaining the integrity of the blockchain.\n\nIn real world blockchain applications, enabling access to off-chain data can become a royal nightmare. Introducing external data implicitly requires trust to centralized systems which violates the immutability and integrity principles of the blockchain. Platforms like Ethereum introduce the concept of Oracle to address this challenge but implementing those is far from being a trivial endeavor. Oraclize is a platform that is trying to provides a solution to off-chain data access in a way blockchain agnostic way.\n\nThe idea behind Oraclize its incredibly simple and yet brilliant. The platform guarantees the integrity of off-chain data by accompanies each requested dataset with a mathematical document known as Authenticity Proofs that certifies that the data received from the original data source has not been tampered. In that model, blockchain applications don\u2019t need to trust Oraclize while data providers don\u2019t need to make modifications to their systems in order to integrate with on-chain apps.\n\nThe Oraclize Engine is the main component of the Oraclize platform. The Engine is responsible for executing specific data fetching actions is certain conditions are met and generating the correct Authenticity Proofs to complement the data. Each request to the Oraclize Engine is composed of three main elements: a data source type, a query and an authenticity proof type.\n\nThe Oraclize platform supports different types of data sources such as REST URLs, IPFS systems or even the WolframAlpha computation engine. New types of data source should be expected as the platform evolves. The specific criteria to access a data source is specified through a Query which is a series of name-value pairs that can be used to filter the target data.\n\nThe main innovation of the Oraclize platform can be considered the Authenticity Proof model that certifies the integrity of the data. The platform uses different types of Authenticity Proofs ranging from extensions to the TLS protocol to sophisticated hardware devices such as Ledger. This flexibility allows Oraclize to be adaptable to highly diverse blockchain scenarios.\n\nThe current version of Oraclize integrates with different blockchain runtimes including Bitcoin, Ethereum, R3 Corda and Rootstock. The support for new runtimes should be expected in the future as the platform evolves.\n\nOraclize is a relatively new initiative but one that is filling a key gap blockchain solutions in the real world. The integration with off-chain data systems is an omnipresent requirement of blockchain applications and that need is only likely to increase as blockchain solutions become more mainstream. From that perspective, Oraclize is uniquely positioned to play a pivotal role in the next generation of blockchain applications.\n\nA couple of years ago, I wrote about the idea that Ethereum Oracles could become a big market in the blockchain ecosystem. Two years after, we are just starting to see the need for that capability. While some blockchain platforms such as Hyperledger Fabric provide somewhat viable models for the integration with off-chain data, Oraclize remains the most relevant blockchain runtime agnostic solution in the market."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-understanding-meta-learning-91fef1295660?source=user_profile---------33----------------",
        "title": "What\u2019s New in Deep Learning Research: Understanding Meta-Learning",
        "text": "Recently I wrote about OpenAI works in the meta-learning space with the publication of the Reptile algorithm research paper and initial TensorFlow implementation. Based on the feedback received from the article, I thought it might be a good idea to review some of the fundamental concepts and history of meta-learning as well as some of the popular algorithms in the space.\n\nThe ideas behind meta-learning can be traced back to 1979 and the work of Donald B. Maudsley when he rereferred to the new cognitive paradigm as \u201cthe process by which learners become aware of and increasingly in control of habits of perception, inquiry, learning, and growth that they have internalized\u201d. A simpler definition can be found in the works of John Biggs (1985) in which he defined meta-learning as \u201cbeing aware of and taking control of one\u2019s own learning\u201d. Those definitions are accurate from the cognitive science standpoint but they seemed a bit hard to adapt to the work of artificial intelligence(AI).\n\nIn the context of AI systems, meta-learning can be simply be defined as the ability to acquire knowledge versatility. As humans, we are able to acquire multiple tasks simultaneously with minimum information. We can recognize a new type of object by seeing a single picture of it or we can learn complex, multi-task activities such as driving or piloting an airplane at once. While AI agents can master really complex tasks, they require massive amounts of training on any atomic subtasks and they remained incredibly bad at multi-tasking. So the path to knowledge versatility requires AI agents to \u201clearn how to learn\u201d or, to used a more obnoxious term, to meta-learn J.\n\nHumans learn following different methodologies tailored to specific circumstances. In the same way, not all meta-learning models follow the same techniques. Some meta-learning models are focused on optimizing neural network structures while others (like Reptile) focused more on finding the right datasets to train specific models. A recent research paper from UC Berkeley AI Lab does a comprehensive job enumerating the different types of meta-learning. Here are some of my favorites:\n\nThe idea of few shots meta-learning is to create deep neural networks that can learn from minimalistic datasets mimicking, for instance, how babies can learn to identify objects by seeing only a picture or two. The ideas of few shots meta-learning have inspired the creation of techniques such as memory augmented neural networks or one-shot generative models.\n\nOptimizer meta-learning models are focused on learning how to optimize a neural network to better accomplish a task. Those models typically include a neural networks that applies different optimizations to the hyperparameters of another neural network in order to improve a target task. A great example of optimizer meta-learning are models that focused on improving gradient descent techniques like the one published in this research.\n\nThe objectives of metric meta-learning is to determine a metric space in which learning is particularly efficient. This approach can be seen as a subset of few shots meta-learning in which we used a learned metric space to evaluate the quality of learning with a few examples. This research paper shows how to apply metric meta-learning to classification problems.\n\nThis type of meta-learning model is tailored to recurrent neural networks(RNNs) such as Long-Short-Term-Memory(LSTM). In this architecture, the meta-learner algorithm will train a RNN model will process a dataset sequentially and then process new inputs from the task. In an image classification setting, this might involve passing in the set of (image, label) pairs of a dataset sequentially, followed by new examples which must be classified. Meta-Reinforcement Learning is an example of this approach."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-things-ive-learned-about-the-quantum-computing-market-2e3a91c44ddb?source=user_profile---------34----------------",
        "title": "Some Things I\u2019ve Learned About the Quantum Computing Market",
        "text": "A few days ago, Google, yet again, made headlines by unveiling Bristlecone, a new quantum computing chip with 72 quantum bits, or qubits \u2014 the fundamental units of computation in a quantum machine. With the release, Bristlecone becomes the most powerful quantum processor in the world breaking IBM\u2019s previous record of quantum qubits. More impressively, Google believes that the new chip is pretty close to achieve \u201cquantum supremacy.\u201d That\u2019s the point at which a quantum computer can do calculations beyond the reach of today\u2019s fastest supercomputers.\n\nBeyond dissecting Google\u2019s impressive milestone with Bristlecone, I believe the new announcement shades new light about how the new quantum computing market is shaping up. With Google, IBM and Microsoft devoting large investment to their quantum initiatives, its just a matter of time before we start seeing an aggressive raise to capture the first generation of quantum computing applications. However, differently from other markets such as cloud computing, the tech giants seem to be following different paths when comes to quantum dominance.\n\nWhen comes to quantum computing, Google is doing what Google does: faster and scalable. Bristlecone didn\u2019t only exhibit impressive performance by reaching 72 quantum qubits but also an impressive low error rate. The initial tests demonstrated low error rates for readout (1%), single-qubit gates (0.1%) and most importantly two-qubit gates (0.6%) as their best result.\n\nGoogle\u2019s initial efforts in the quantum space seemed to be targeted to create processors and infrastructure that can be made available as part of their cloud platform in a way that presents a path for mainstream adoption.\n\nMicrosoft is another tech giant really invested in quantum computing. Under the leadership of bright minds such as Fields Medal award winner Michael Friedman, the Redmond giant has released the first version of their quantum computing technology and guest what? Its all about developers!. Microsoft\u2019s Quantum Development Kit includes a new programming language named Q# which is tailored to quantum algorithms. The platforms also includes drivers to languages such as C# which enables the interoperability of quantum applications with mainstream .NET libraries. Additionally, the Quantum Development Kit provides simulators that enable the execution of quantum applications in mainstream hardware. The entire stack is integrated with popular development tools such as Visual Studio and Visual Studio Code as well as the Azure platform.\n\nThe Quantum Development Kit clearly signals the market that developer adoption is a vital metric is Microsoft\u2019s approach to quantum computing. From that perspective, its not crazy to think that the Quantum Development Kit will be able to run on hardware created by Microsoft\u2019s competitors such as IBM or Google.\n\nIBM\u2019s approach to quantum computing seems to be somewhere in the middle between Microsoft and Google. The IBM Q Experience is the main umbrella that encompasses IBM\u2019s quantum initiatives such as the following:\n\nWhen comes to new technical trends such as artificial intelligence of quantum computing, China is determined to not follow the US but the lead the movement. In that context, we should expect companies such as Alibaba and Tencent to become really competitive in the quantum computing space. Recently, Alibaba announced new group of quantum computing services as part of its Alibaba Cloud platform. We should expect more initiatives like this in the near future. Similarly, advanced chip makers such as Nvidia, QUALCOMM or Intel are likely to enter the quantum computing race challenging the processors created by IBM and Google."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-new-in-deep-learning-research-openai-s-reptile-makes-it-easier-to-learn-how-to-learn-e0f6651a39f0?source=user_profile---------35----------------",
        "title": "What\u2019s New in Deep Learning Research: OpenAI\u2019s Reptile Makes it Easier to Learn How to Learn",
        "text": "Meta-Learning is one of the most fascinating areas of deep learning research. How can artificial intelligence(AI) systems learn to learn is the key focus of meta-learning models. The principles behind meta-learning are inspired by the way humans learn from a cognitive standpoint.\n\nWhen presented with any knowledge subject, humans are constantly finding the best methodology to improve their learning about it. Some people learn by writing, others used visual references while others try to repeat what they learn to other people in order to enforce the knowledge. Let\u2019s extrapolate those processes to AI agents. Typically, the learning methodology of an AI program is intrinsically tied to its underlying algorithm. In modern AI scenarios, data scientists spend quite a bit of time performing regularization and optimization tasks in order to improve the learning process. But what if AI programs were able to detect the best path to learn a specific knowledge subject? In other words, can AI programs learn how to learn? Well, that\u2019s the focus of a AI discipline known as meta-learning.\n\nConceptually, meta-learning is the process of learning how to learn. A meta-learning algorithm typically takes in a distribution of tasks, where each task is a learning problem, and it produces a quick learner \u2014 a learner that can generalize from a small number of examples. Meta-learning is a brand new area of research in the deep learning space. Last year, the Berkeley research lab produced a new meta-learning algorithm called model-agnostic-meta-learning(MAML) that sort of set the bar for the space. A few days ago, researchers at OpenAI published a paper that describes a new meta-learning algorithm called Reptile that builds on the principles of MAML to determine the right learning path from a distribution of learning tasks.\n\nThe Reptile algorithm learns an initialization for the parameters of a neural network, such that the network can be fine-tuned using a small amount of data from a new task. For every given task, Reptile simply performs stochastic gradient descent (SGD) to evaluate its performance and adjust accodingly. This makes Reptile take less computation and memory than predecessors like MAML that rely on calculating second-order derivatives in the computation graph. In the research paper you can find a pseudo-code for the Reptile algorithm:\n\nTechnically, Reptile achieves proposes a meta-learning model that works by repeatedly optimizing on a single task, and moving the parameter vector towards the parameters learned on that task. The algorithm is not neccesarly superior to MAML in terms of learning performance but its considerably simple to implement given that it relies on vanilla techniques such as SGD.\n\nIn addition to the research paper, the OpenAI team also published an implementation of Reptile based on TensorFlow. The source code is available on GitHub. and includes code for replicating the experiments on Omniglot and Mini-ImageNet. The team is also releasing a smaller JavaScript implementation that fine-tunes a model pre-trained with TensorFlow."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-accelerating-artificial-intelligence-with-winml-and-onnx-41aecde95ba4?source=user_profile---------36----------------",
        "title": "Technology Fridays: Accelerating Artificial Intelligence with WinML and ONNX",
        "text": "Welcome to Technology Fridays! Today we are going to discuss a technology that was just announced a few days ago but that can have some profound implications in the world of artificial intelligence(AI). Earlier this week, Microsoft announced the release of Windows Machine Learning(WinML), a new stack that will enable developers to build Windows applications that leverage hardware accelerate for AI.\n\nFrom the technical standpoint, WinML enables the execution of pre-trained machine learning models in Windows 10 devices. This capability can make machine learning capabilities more accessible in internet of things(IOT) topologies based on Windows 10 architectures. By leveraging WinML, Windows 10 devices would be able to perform local computations without dependencies on centralized cloud services which should play a role streamline the implementation of intelligent edge computing applications.\n\nIn terms of capabilities, there are a few things worth highlighting in the initial release of WinML:\n\n\u00b7 Hardware Acceleration: On DirectX12 capable devices, Windows ML accelerates the evaluation of Deep Learning models using the GPU. CPU optimizations additionally enable high-performance evaluation of both classical ML and Deep Learning algorithms.\n\n\u00b7 Local Evaluation: Windows ML evaluates on local hardware, removing concerns of connectivity, bandwith, and data privacy. Local evaluation also enables low latency and high performance for quick evaluation results.\n\n\u00b7 Image Processing: For computer vision scenarios, Windows ML simplifies and optimizes the use of image, video, and camera data by handling frame pre-processing and providing camera pipeline setup for model input.\n\nThe magic of WinML is based on another super cool AI initiative that Microsoft has been working on for a few months. The Open Neural Network Exchange (ONNX) is a project created by Microsoft and Facebook to define a computational graph model that can be used across different deep learning frameworks. Technologies such as Tensorflow, Keras, Microsoft Cognitive Toolkit or Caffe2 have been developing support for ONNX. If you are interested on learning more about WinML, go back to this article I wrote shortly after the initial release analyzing some of the market implications of the technology stack.\n\nHow is ONNX related to WinML? Very simply, WinML relies on ONNX as the main encoding format for machine learning models. The current release of WinML includes a series of tools that facilitates the conversion of other formats into WinML. Specifically, WinML tools support conversion from the following toolkits:\n\nDevelopers can start using WinML by downloading the latest Windows SDK and start converting trained models. Once converted, WinML models can be used across any Windows 10 device without taking dependencies on specific hardware.\n\nWinML is pretty much on a league of its own. There are current AI hardware acceleration packages such as the Nvidia CUDA stack but those requires optimization for specific hardware models. The release of WinML can help to streamline the optimization of WinML across the large portfolio of Windows 10 devices in the market."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-understanding-how-neural-networks-think-aa6404990f30?source=user_profile---------37----------------",
        "title": "What\u2019s New in Deep Learning Research: Understanding How Neural Networks Think",
        "text": "One of the challenging elements of any deep learning solution is to understand the knowledge and decisions made by deep neural networks. While the interpretation of decisions made by a neural networks has always been difficult, the issue has become a nightmare with the raise of deep learning and the proliferation of large scale neural networks that operate with multi-dimensional datasets. Not surprisingly, the interpretation of neural networks has become one of the most active areas of research in the deep learning ecosystem.\n\nTry to imagine a large neural network with hundreds of millions of neurons that is performing a deep learning task such as image recognition. Typically, you would like to understand how the network arrives to specific decisions. Most of the current research has focused on detecting what neurons in the network have been activated. Knowing that neuron-12345 fired five times is relevant but not incredibly useful in the scale of the entire network. The research about understanding decisions in neural networks has focused on three main areas: feature visualization, attribution and dimensionality reduction. Google, in particular, has done a lot of work in the feature visualization space publishing some remarkable research and tools. Continuing their work in the space, Google researchers recently published a paper titled \u201cThe Building Blocks of Interpretability\u201d that proposes some new ideas to understand how deep neural networks make decisions.\n\nThe main insight of Google\u2019s research is to not see the different interpretability techniques in isolation but as composable building blocks of larger models that help understand the behavior of neural networks. For instance, feature visualization is a very effective technique to understand the information processed by individual neurons but fails to correlate that insight with the overall decision made by the neural network. Attribution is a more solid technique to explain the relationship between different neurons but not so much when comes to understand the decision made by individual neurons. Combining those building blocks, Google has created an interpretability models that does not only explains what a neural network detects, but it does answer how the network assembles these individual pieces to arrive at later decisions, and why these decisions were made.\n\nHow does the new Google model for interpretability works specifically? Well, the main innovation, in my opinion, is that it analyzes the decisions made by different components of a neural network at different levels: individual neurons, connected groups of neurons and complete layers. Google also uses a novel research technique called matrix factorization to analyze the impact that arbitrary groups of neurons can have in the final decision.\n\nA good way to think about Google\u2019s blocks of interpretability is as a model that detects insights about the decisions of a neural network at different levels of abstraction from the basic computation graph to the final decision.\n\nGoogle research of deep neural network interpretability is not only a theoretical exercise. The research group accompanied the paper with the release of Lucid, a neural network visualization library that allow developers to make the sort lucid feature visualizations that illustrate the decisions made by individual segments of a neural network. Google also released colab notebooks. These notebooks make it extremely easy to use Lucid to create Lucid visualization in an interactive environment"
    },
    {
        "url": "https://chatbotsmagazine.com/talking-to-einstein-some-thoughts-about-einstein-analytics-conversational-queries-7ea2d1573c3?source=user_profile---------38----------------",
        "title": "Talking to Einstein: Some Thoughts About Einstein Analytics Conversational Queries",
        "text": "Yesterday, Salesforce announced a new feature to its Einstein Analytics platform called \u201cConversational Queries\u201d. The new capability allow users to interact with Salesforce data via simple language interactions. For instance, an account execute can ask Einstein to \u201clist the top accounts in the last quarter\u201d followed by \u201cvisualize the results \u201cand the engine will be smart enough to retrieve the data and recommend the most appropriate visualizations.\n\nEinstein Analytics Conversational Queries is still very limited in terms of the conversational interactions that are available to users. To be exact, the release is limited to simple words and phrases. However, the new service of the Einstein platform could be the first step towards a new mode for users to interact with business data. Anthropologically, natural language represents a more natural mechanism to navigate and understand data sources. However, the implementation of a true conversational model for business data sources is far from being an easy endeavor and requires design considerations that we haven\u2019t seen before.\n\nInteracting with business datasets using conversational interfaces is fundamentally different than structured query paradigms like SQL, APIs or existing data visualization models. Most of the challenges come from the rich nature of language dialogs compared to the constrained nature of a query language. I\u2019ve listed a few ideas that should be considered in the next version of Einstein Analytics Conversational Queries or similar natural language interface for business datasets:\n\nThe algebra of most query languages, allows for are a finite (often one) ways to inquire about the same data. Natural languages enable infinite ways to structure the same query against a business data source. From that perspective, a conversational query interface should be able to seamlessly translate natural language intents to structured queries in a way that is completely transparent to the user.\n\nData queries and visualizations explicitly encode the intention of a business user against a business dataset. In a conversational model, the interaction should reassemble closer how humans process information and try to inferred the intentions of a user. For instance, if a user requests the top account for the quarter, a conversational engine should be able to infer the best visualization to present the information.\n\nConversational queries can be carried via voice or text interfaces. While text conversations are relatively easy to translate into a query language using modern natural language processing(NLP) stacks, voice conversations introduce a different level of complexity. In a voice dialog, a conversational query engine should be able to understand different languages, describe voice responses accordingly, pronounce business data source correctly, match the emotional stage of the user, etc.\n\nRetrieving data as structured tables or visualization is one thing but that\u2019s not exactly the way humans communication is it? A conversational query engine should be able to generate voice or text narratives based on the business data that can efficiently delivered to the user.\n\nOhh yes, the perennial aspect of any natural language scenario! Conversational queries are all about context. Enriching dialogs by understanding the context of a conversation will be essential to enable the mainstream adoption of conversational query engines such as Einstein. Imagine if a user requests the top account for the quarter and then asks Einstein to correlate it with the current marketing funnel. The platform should be smart enough to maintain the context of the conversation across different language interactions."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-understanding-deepmind-s-impala-4fbfa5d0ad0c?source=user_profile---------39----------------",
        "title": "What\u2019s New in Deep Learning Research: Understanding DeepMind\u2019s IMPALA",
        "text": "Deep reinforcement learning has rapidly become one of the hottest research areas in the deep learning ecosystem. The fascination with reinforcement learning is related to the fact that, from all the deep learning modalities, is the one that resemble the most how humans learn. In the last few years, no company in the world has done more to advance the stage of deep reinforcement learning than Alphabet\u2019s subsidiary DeepMind.\n\nSince the launch of its famous AlphaGo agent, DeepMind has been at the forefront of reinforcement learning research. A few days ago, they published a new research that attempts to tackle one of the most challenging aspects of reinforcement learning solutions: multi-tasking.\n\nSince we are infants, multi-tasking becomes an intrinsic element of our cognition. The ability to performing and learning similar tasks concurrently is essential to the development of the human mind. From the neuroscientific standpoint, multi-tasking remains largely a mystery and that, not surprisingly, we have had a heck of hard time implementing artificial intelligence(AI) agents that can efficiently learn multiple domains without requiring a disproportional amount of resources. This challenge is even more evident in the case of deep reinforcement learning models that are based on trial and error exercises which can easily cross the boundaries of a single domain. Biologically speaking, you can argue that all learning is a multi-tasking exercise.\n\nLet\u2019s take a classic deep reinforcement learning scenario such as self-driving vehicles. In that scenarios, AI agents need to concurrently learn different aspects such as distance, memory or navigation while operating under rapidly changing parameters such as vision quality or speed. Most reinforcement learning methods today are focused on learning a single task and the models that track multi-task learning are too difficult to scale to be practical.\n\nIn their recent research the DeepMind team proposed a new architecture for deep reinforcement multi-task learning called Importance Weighted Actor-Learner Architecture (IMPALA). Inspired by another popular reinforcement learning architecture called A3C, IMPALA leverages a topology of different actors and learners that can collaborate to build knowledge across different domains. Traditionally, deep reinforcement learning models use an architecture based on a single learner combined with multiple actors. In that model, the Each actor generates trajectories and sends them via a queue to the learner. Before starting the next trajectory, actor retrieves the latest policy parameters from learner. IMPALA uses an architecture that collect experience which is passed to a central learner that computes gradients, resulting in a model that has completely independent actors and learners. This simple architecture enables the learner(s) to be accelerated using GPUs and actors to be easily distributed across many machines.\n\nIn addition to the multi-actor architecture model, the IMPALA research also introduces a new algorithm called V-Trace that focuses off-policy learning. The idea of V-Trace is to mitigate the lag between when actions are generated by the actors and when the learner estimates the gradient.\n\nThe DeepMind team tested IMPALA on different scenarios using its famous DMLab-30 training set and the results were impressive. IMPALA proved to achieve better performance compared to A3C variants in terms of data efficiency, stability and final performance. This might be the first deep reinforcement learning models that has been able to efficiently operate in multi-task environments."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-book-club-homo-deus-a-brief-history-of-tomorrow-5a3ffd895061?source=user_profile---------40----------------",
        "title": "The Book Club: Homo Deus: A Brief History of Tomorrow",
        "text": "Yuval Noah Harari is one of the most original writers when comes to topics such as history and philosophy. His breakthrough book Sapiens captured the praises of people like Bill Gates or Barack Obama. Sapiens has been translated into over 40 languages and can be considered one of the most important history books of the last decade. So how do you follow up after such a success as Sapiens. With a sequel of course! Harari\u2019s latest book: Homo Deus: A Brief History of Tomorrow explores humanity in a techno-dominated future.\n\nIn Harari\u2019s thesis, Homo Deus is the next phase of mankind. Humans will transition from Homo Sapiens to this new phase dominated by new godlike technologies such as artificial intelligence and genetic engineering. \u201cModernity is a deal,\u201d Harari writes. \u201cThe entire contract can be summarized in a single phrase: humans agree to give up meaning in exchange for power.\u201d That power, he suggests, may in the near term give us godlike attributes: the ability to extend lifespans and even cheat death, the agency to create new life forms, to become intelligent designers of our own Galapagos, the means to end war and famine and plague. There will be a price to pay for this power.\n\nWhat does the transformation from Homo sapiens to Homo Deus entails for humanity? Harari explores this difficult subject using an erudite, deeply thoughtful style that will force you to see the future through a different lense"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-gluon-wants-to-be-the-ruby-on-rails-of-the-deep-learning-world-afcc71d4904b?source=user_profile---------41----------------",
        "title": "Technology Fridays: Gluon Wants to be The Ruby on Rails of the Deep Learning World",
        "text": "Welcome to Technology Fridays! If you are a developer embarking in your first deep learning project, the number of technologies available to you can result overwhelming. A few years ago, we had one or two machine learning frameworks that were ready for prime time. Today, not a month goes by in which we don\u2019t hear about other shining deep learning library that is trying to streamline the implementation of deep learning models. Tensorflow, Theano, Microsoft Cognitive Toolkit(CNTK), MxNet, PaddlePaddle, Keras, Bonsai, Caffe2, Torch and the list doesn\u2019t seem to end. Even more challenging, is the fact that all those frameworks are relatively low level and require a solid understanding of the computation graphs required in deep learning models. In order for deep learning to become more mainstream, we are going to need higher level frameworks that result more appealing to average developers. Last year, Microsoft and Amazon surprisingly partnered in an effort to create a higher level programming model that works across different deep learning frameworks. They named the project Gluon.\n\nThe goals of project Gluon are to provide a series of high level APIs that abstract the implementation of deep learning programs across different runtimes such as Apache MxNet(Amazon\u2019s favorite), PyTorch or CNTK(Microsoft deep learning framework). The Gluon interface allow developer to quickly prototype and train deep learning models without having to understand all the mechanics of the underlying computation graph. Even more impressive is the fact that that Gluon accomplishes that without sacrificing the performance of the models. From that perspective, models developed using Gluon can achieve comparable performance that if implemented in MxNet or CNTK.\n\nFrom an architecture standpoint, Gluon was designed following four key principles:\n\nWe already talked about the simplicity of the programming model and the native performance so let\u2019s discuss some of the following aspects. One of the major theoretical contributions of Gluon is this idea of building dynamic neural networks on the fly that change their size and shape based on the conditions of the experiment. Additionally, because the Gluon interface brings together the training algorithm and the neural network model, developers can perform model training one step at a time which results is much easier debugging and optimization mechanisms.\n\nFrom the programming standpoint, Gluon includes different relevant building blocks. The Gluon API providers The Gluon API offers a flexible interface that simplifies the process of prototyping, building, and training deep learning models without sacrificing training speed. Similarly, Gluon includes a Neural Network Layers API that provides a series of prebuilt neural network structures such as convolutional neural networks(CNNs), dropout or pooling layers which can be combined to rapidly architect deep learning models. The Recurrent Neural Network API is Gluon interface to build recurrent neural networks such as long term short term memory(LTSM) models. The Gluon Data API is responsible for abstracting the loading and pre-processing of datasets while the Autograd API focuses on gradient optimization algorithms.\n\nThe combination of the different layers makes the implementation of deep learning models using Gluon substantially simpler compared to lower level deep learning frameworks. For instance, let\u2019s take the following example of a neural network implemented using Apache MxNet:\n\nThe same model implemented using Gluon looks like the following:\n\nSeems way simpler. Well, that\u2019s the promise of Gluon and the more impressive thing is that the same model can be applied across different deep learning runtimes.\n\nGluon is not the only effort to enable higher level programming constructs for the implementation of deep neural networks. The DeepMind team released the Sonnet library last year which accomplishes some similar for Tensorflow graphs. Similarly, Bonsai\u2019s ideas look promising across different deep learning frameworks."
    },
    {
        "url": "https://cryptocurrencyhub.io/the-crypto-stability-dream-part-i-understanding-stablecoins-cb03cf472c2?source=user_profile---------42----------------",
        "title": "The Crypto Stability Dream Part I: Understanding Stablecoins",
        "text": "They have been called the holy grail of crypto currencies and have been positioned as the crypto-asset that finally bridges the gap between digital currencies and financial markets. Stablecoins are the latest hottest trend in the cryptocurrency space and one that promises to become an important element of the whole ecosystem.\n\nYesterday, I found myself in two different conversations about Stablecoins so I\u2019d figure it might be a good idea to write down my thoughts about this new crypto-trend. A lot has been written recently about Stablecoins and their potential role in the cryptocurrency world so I don\u2019t plan to bother you with the basics ;). However, most of the initial content seems to be subjected to the speculation of any nascent and complex technology trend. From my standpoint, there are two main things that should be understood about Stablecoins: what are they? And how do you build one?\n\nConceptually, Stablecoins are the ideal crypto-asset that shares most of the benefits of digital currencies and few of the risks. Specifically, Stablecoins came into existing the address the uncontrollable volatility of most digital currencies. While volatility is a great characteristic for speculation, it\u2019s a limitation for the implementation of long term financial products. Most companies or countries won\u2019t conduct large trades in Bitcoin or Ether because of the volatility associated with those assets. Also, even when some people have been able to sell real estate using Bitcoin the proposition remains too risky to be adopted at scale. To put it in more clear terms, the current generation of digital currencies are great vehicles for speculation but not so great stores of value or mediums of exchange.\n\nStablecoins supposed to be the solution to this dilemma, a cryptocurrency with stable value. Ideally, Stablecoins will have many of the great digital benefits of Bitcoin or Ether without suffering the price volatility. To be a bit more specific, there are four key characteristics that I think should be present on any Stablecoin:\n\nThe first three elements are clearly essential to achieve a stable market behavior but why are we talking about decentralization? Aren\u2019t all cryptocurrencies supposed to be decentralized? Of course they do, but, as we should see soon, some of the requirements of Stablecoins can be conducive to centralization of authority.\n\nThe simplest way to think about a Stablecoin is to collateralize its value to another stable asset. However, is that enough to achieve price stability? From the tulip crisis of the 1637 to the recent financial crisis, history taught us that stable assets can also be subjected to speculation. Furthermore, some people might argue that collateralizing a crypto-asset directly challenges the promise of decentralization. As you can see, the answer is not trivial, linking a collateral to a cryptocurrency is an important but not the only way to define a Stablecoin.\n\nThe architectures of Stablecoins are directly related to the models used as collaterals which is another way to say that they are related to the different \u201cstable\u201d asset class in the market. The exact architectures for Stablecoins are currently being explored. In my opninion, there are a few models that can be become relevant in the market:\n\nKeep the above chart in mind because we are going to deep dive into each of the specific categories in the next post."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-learning-and-teaching-the-west-world-way-659892b2e452?source=user_profile---------43----------------",
        "title": "What\u2019s New in Deep Learning Research: Learning and Teaching the West World Way",
        "text": "West World is one of my favorite TV series of the last few years. The HBO drama combines a stellar group of actors in an engaging plot that touches upon some of the most controversial aspects of the future of artificial intelligence(AI). In almost every episode of the first season of West World, we find humans trying to understand the decisions made by the hosts(robots) on specific circumstances. Every time some human needs an explanation about the host behavior can simply query a system that will proceed the explain the reasoning behind the host decision. Simply saying \u201cAnalysis, explain X or Y\u201d and the host will pleasantly proceed to detail the intricacies behind its behaviors or actions. If only things work like that in real artificial intelligence(AI) systems.\n\nExplaining and interpreting knowledge is one of the hardest problems in modern deep learning systems. In supervised deep learning systems, the processes for training a model and the knowledge built in that model are almost uninterpretable. However interpretation of knowledge is a key element in the way humans learn. Let\u2019s take a classic student-teacher setting in which the teacher is trying to convey a specific concept to the student using a series of examples. Based on the feedback from the student, the teacher will adapt his explanations and try to select the most appropriate examples to improve the knowledge of the student. That pedagogical process works brilliantly for humans but fails miserably for neural networks.\n\nSome of the most interesting scenarios in deep learning systems require a seamless collaboration between humans and neural networks. However, in most scenarios, its incredibly difficult to establish that collaboration as both sides speak different protocols. A recent research paper from OpenAI is trying to address this challenge by proposing a more pedagogical way to tech deep learning systems.\n\nUnder the title \u201cInterpretable and Pedagogical Examples\u201d the OpenAI researchers formulate an intriguing thesis about what makes understanding the knowledge of deep learning systems so difficult. In their opinion, part of the challenge is that most deep learning architectures rely on teacher and student neural networks to be train jointly which prevents any feedback loop between the two. Instead of that model, the OpenAI team proposes a structure in which teacher and student networks can be train iteratively which can produce more interpretable teaching strategies.\n\nThe OpenAI interpretable teaching strategy can be seen as a game dynamic between two neural networks, a student and a teacher. The goal of the game is for the student to guess a particular concept based on examples of that concept and the goal of the teacher is to learn to select the most illustrative examples for the student. Using an image recognition scenario as an analogy, the student should try to guess the concepts in a specific image while the teacher should try to select the most appropriate images to improve the knowledge of the student.\n\nThe two-stage technique to interpretable teaching works like this: a \u2018student\u2019 neural network is given randomly selected input examples of concepts and is trained from those examples using traditional supervised learning methods to guess the correct concept labels. In the second step, the \u2018teacher\u2019 network \u2014 which has an intended concept to teach and access to labels linking concepts to examples \u2014 tests the different examples on the student and see which concept labels the student assigns them, eventually converging on the smallest set of examples it needs to give to let the student guess the intended concept.\n\nThe key to the OpenAI methods is that the teacher and student networks are being trained iteratively rather than jointly. In the traditional mode, both neural networks will be trained together selecting examples that are hard to interpret by humans. The goal of the OpenAI technique is to produce more interpretable teaching strategies but how do we really quantify interpretable? To evaluate the performance of the mode, the OpenAI team centered in two fundamental metrics:\n\n1. Evaluating how similar the selected strategies are to intuitive human-designed strategies in each task.\n\n2. Evaluating the effectiveness of the selected strategies at teaching humans.\n\nThe OpenAI researchers applied interpretable strategies across a large variety of scenarios producing remarkable results that vastly improve over traditional techniques. More specifically, interpretable teaching leads the student model to learn an interpretable learning strategy, which then constrains the teacher to learn an interpretable teaching strategy."
    },
    {
        "url": "https://towardsdatascience.com/a-decentralized-kaggle-inside-algorithmias-approach-to-blockchain-based-ai-competitions-8c6aec99e89b?source=user_profile---------44----------------",
        "title": "A Decentralized Kaggle: Inside Algorithmia\u2019s Approach to Blockchain-Based AI Competitions",
        "text": "Well, it seems that I am going to keep writing about decentralized artificial intelligence(AI). In the last few days, I\u2019ve written articles about federated learning and the innovative startup OpenMined as well as some of other ideas behind the decentralization of AI models. Yesterday was a very interesting day for the decentralized AI ecosystem when Algorithmia announced a new machine learning competition that is going to award five Ethereum tokens(ETH) for models that detail voter preferences in the last presidential election. That\u2019s not exactly news but this is: the entire contest is going to be regulated by smart contracts hosted in the Ethereum blockchain!\n\nYes, you heard that right. Algorithmia is piloting a concept that can extend its centralized AI algorithm marketplace with a decentralized infrastructure powered by the blockchain. The name of the new project is DanKu and is, fundamentally, a new blockchain protocol for evaluating and purchasing AI models using publick blockchains. DanKu takes the idea behind machine learning contest platforms such as Kaggle and leverages public blockchain smart contracts to remove the centralization and implicit trust required by those architectures. In essence, DanKu is a true trustless machine learning smart contract.\n\nIn the DanKu model, each machine learning contest will be modeled using a smart contract. Those programmable contracts will allow data scientists to publish data sets, evaluation functions, and monetary rewards for anyone who can provide the best trained machine learning model for the data. The different participants in the contests will train neural networks to using the available datasets, and submit their models to the blockchain. The blockchain will then executes these neural network to evaluate their performance. The best performing model will receive the monetary reward via a blockchain transaction.\n\nBy using smart contracts as the underlying protocol of an AI competition, DanKu creates a true decentralized marketplace for AI models. In that world, any data scientists can monetize their skillset without the need of relying on a centralized authority. The use of the blockchain also ensures that the evaluation, optimization and results of the models will also be completely transparent.\n\nDecentralizing AI models is disruptive enough but applying that architecture to AI competition unveils some interesting benefits that we haven\u2019t seen in the AI world. Here are some of my favorites:\n\n\u00b7 Removal of the AI Middleman: In the DanKu world, data scientists can submit data or machine learning models without implicitly trusting Algorithmia or any other centralized authority.\n\n\u00b7 Monetary Network: Because the DanKu-based smart contracts run on a public blockchain, any Ether holder can contribute to the monetary reward associated with it. This model opens the door to interesting scenarios such as decentralized fundraising and to asses the true market value of specific AI models.\n\n\u00b7 Transparency: The mechanisms for detecting conditions such as overfitting or underfitting as well as poor regularization or optimization models are often obfuscated in machine learning scenarios. DanKu-based smart contracts can ensure the transparency of those mechanisms by publishing the details in a decentralized ledger.\n\n\u00b7 Multi-Step Contests: Traditional machine learning are constrained to the creation and evaluation of the algorithms but, in the real world, there are many scenarios that require other steps to operationalize and run those models. The use of smart contracts could allow developers to model more complex, multi-step contests that cover different aspects of the lifecycle of AI applications."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-understanding-federated-learning-b14e7c3c6f89?source=user_profile---------45----------------",
        "title": "What\u2019s New in Deep Learning Research: Understanding Federated Learning",
        "text": "Last week I published a brief analysis of the OpenMined platform as one of the new technologies that is trying to enable truly decentralized artificial intelligence(AI) processes by leveraging blockchain technologies. In the article, I mentioned that OpenMined drew parts of its inspiration from Google\u2019s research about federated learning as a mechanism to improve on the traditional centralized approach to train AI models. From my perspective, I consider federated learning is one of the most interesting AI research breakthroughs of the last two years that is already powering mission critical applications.\n\nThe idea behind federated learning is as conceptually simple as it its technologically complex. Traditional machine learning programs relied on a centralized model for training in which a group of servers run a specific model against training and validation datasets. That centralized training approach can work very efficiently on many scenario but it also proven to be challenging in use cases involving a large number of endpoints using and improving the model. The prototypical example of the limitation of centralized training model can be found in mobile or internet of things(IOT) scenarios in which the quality of a model depends on the information processed across hundreds of thousands or millions of devices. In those scenarios, each individual endpoint can contribute to the training of a machine learning model in its own autonomous way. In other words, knowledge is federated.\n\nFederated learning was initially proposed by Google researchers in a paper published last year. The original publication describes federated learning as an alternative to centralized AI training in which a shared global model is trained under the coordination of a central server, from a federation of participating devices. In that model, the different devices can contribute to the training and knowledge of the model while keeping most of the data in the device.\n\nGoogle describes the approach to federated learning in four simple steps:\n\n1. A subset of existing clients is selected, each of which downloads the current model.\n\n2. Each client in the subset computes an updated model based on their local data.\n\n3. The model updates are sent from the selected clients to the sever.\n\n4. The server aggregates these models (typically by averaging) to construct an improved global model.\n\nLet\u2019s explain federated learning in the context of an image recognition algorithm that is running on a large number of mobile devices. In that scenario, the data required to train the model is effectively living on the different devices. Each device will be responsible for downloading a version of the model and run an optimization algorithm such as stochastic gradient descent(SGD) based on new data. After that, the devices will upload the updates to the main servers hosting the model that will aggregate them using a new optimization process.\n\nOne of the main elements in federated learning models is determined by the nature of the updates which should be designed to reduce the communication costs. Typically, we can categorize updates in a federated learning process in two main groups:\n\n1. Structured updates, where we directly learn an update from a restricted space that can be parametrized using a smaller number of variables.\n\n2. Sketched updates, where we learn a full model update, then compress it before sending to the server.\n\nGoogle has moved beyond theory when comes to federated learning and is using the new technique in large scale services such as its mobile vision API and the GBoard app. The search giant has also worked on a version of TensorFlow that can run on mobile devices and is particularly well equipped to support federated learning models.\n\nThe clear benefit of federated learning is to distribute the quality of knowledge across a large number of devices without necessarily centralizing the data used to optimize and train the model. That approach also enables to improve the quality of centralized machine learning models while maintaining the privacy of the training datasets. However, federated learning does not come without problems. Like any other software architectures, decentralization introduces challenges in areas such as work coordination, management or monitoring. If nothing else, federated learning is an interesting complement, and not necessarily an alternative, to the traditional centralized supervised and semi-supervised learning architectures."
    },
    {
        "url": "https://towardsdatascience.com/technology-fridays-openmined-powers-federated-ai-using-the-blockchain-d124e6560dd?source=user_profile---------46----------------",
        "title": "Technology Fridays: OpenMined Powers Federated AI Using the Blockchain",
        "text": "Welcome to Technology Fridays! The world of decentralized artificial intelligence(AI) applications has been gaining a lot of momentum. Part of this raise in popularity has been triggered by the steady evolution of blockchain platforms as well as the frenzy surrounding AI technologies. Recently, I wrote about SingularityNet as one of the platforms powering the decentralized AI movement. Today, I would like to cover another one of the innovative companies in the space: OpenMined.\n\nThe idea behind OpenMined has been influenced by the idea of Federated Learning that was initially published by Google researchers and has become increasingly popular in the deep learning community. Conceptually, federated learning proposes a mechanism to train a high quality centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. OpenMined can be considered an implementation of a federated learning architecture which powers decentralization using blockchain smart contracts.\n\nWhy is this decentralized AI thing such as big deal? Well, if you consider the traditional process of building a deep learning solution, there are several building blocks such as data acquisition, training, regularization or optimization that require an implicit trust between the different parties. For instance, if an organization shares a dataset with a group of data scientists, there is an implicit trust relationship between them that, if violated, can affect the final outcome of the project. In a bit more technical context, deep learning algorithms need to undergo multiple regularization and optimization cycles in which teams are focused on tuning what is called the hyperparameters of the model. For the most part, there is no historical record or accountability of a deep learning program without requiring trust on a centralized authority. Wouldn\u2019t it be nice if we could decentralize the lifecycle of deep learning applications in a way that customers and data scientists could collaborate in a trustless but secure manner. This is the fundamental premise of platforms such as OpenMined.\n\nFrom a technical standpoint, OpenMined combines the principles of federated learning with cutting edge techniques such as homomorphic encryption and blockchain smart contracts to enable a collaborative model to implement deep learning application in a completely decentralized way.\n\nSpecifically, the OpenMined architecture is based on four fundamental building blocks:\n\nTogether the four components of the OpenMined platform enable an innovative channel in which data scientists can collaborate in the implementation of deep learning applications while being rewarded by the quality of their contributions. Similarly, the OpenMined architecture ensures the privacy and integrity of the data and models in the platform without the need of relying on a centralized authority.\n\nOpenMined is entering the new but high profile market of decentralized AI platforms. Currently, there are only a handful of platforms that have achieve meaningful traction in the market but that number is likely to increase in the near future. SingularityNet and Effect.AI are two platforms that have caught my attention and that, together with OpenMined, I believe are likely to become relevant players in this new space."
    },
    {
        "url": "https://towardsdatascience.com/whats-new-in-deep-learning-research-introducing-population-based-training-35c3e5526a90?source=user_profile---------47----------------",
        "title": "What\u2019s New in Deep Learning Research: Introducing Population Based Training",
        "text": "Training and optimization of deep learning models are some of the most challenging aspects of any modern machine intelligence (MI) solution. In many scenarios, data scientists are able to rapidly arrive to the correct set of algorithms for a specific problem just to spend countless months trying to find the optimal version of the model. Recently, DeepMind published a new research paper that proposes a new approach for training and optimizing deep learning models known as population based training.\n\nThe optimization of traditional deep learning models is focused on minimizing its test error without drastically changing the core components of the model. One of the most important approaches in deep learning optimization centers around tuning elements that are orthogonal to the model itself. Deep learning theory typically refers to these elements as hyperparameters. In the past, I\u2019ve written about hyperparameter optimization and its implications in deep learning programs so I don\u2019t plan to bore you with the details :). Typically, hyperparameters in deep learning programs include elements such as the number of hidden units or the learning rate which can be tuned to improve the performance of a specific model.\n\nOptimizing hyperparameters is a game of finding the right balance between the performance of a deep learning function and its cost. Algorithms such as stochastic gradient descent and its variations have become the center of deep learning optimization but still have major challenges when applied in large scale scenarios. Typically, there are two major approaches to deep learning hyperparameter optimization: random search and hand-tuning. In random search scenarios, a population of models are trained independently in parallel and at the end of training the highest performing model is selected. Typically, this means that only a small fraction of the population will be trained with good hyperparameters while the rest will be trained with bad ones, wasting computer resources.\n\nThe hand-hunting approach is based on sequential optimization processes. ) Sequential optimization requires multiple training runs to be completed (potentially with early stopping), after which new hyperparameters are selected and the model is retrained from scratch with the new hyperparameters. This is an inherently sequential process and leads to long hyperparameter optimization times, though uses minimal computational resources.\n\nAs you can see, there are advantages and limitation to both random search and hand-haunting techniques. Recently, the DeepMind team published a research paper advocating for a new optimization technique that tries to combines the best of both approaches.\n\nPopulation based training(PBT) uses a similar approach to random search by randomly sampling hyperparameters and weight initializations. Differently from the traditional approach, PBT runs each training asynchronously and evaluates its performance periodically. If a model in the population is under-performing, it will leverage the rest of the model population and replacing itself with a more optimal model. At the same time, PBT explores new hyperparameters by modifying the better model\u2019s hyperparameters, before training is continued.\n\nThe PBT process allows hyperparameters to be optimized online, and the computational resources to be focused on the hyperparameter and weight space that has most chance of producing good results. The result is a hyperparameter tuning method that while very simple, results in faster learning, lower computational resources, and often better solutions.\n\nIn the research paper, the DeepMind team applies PBT across different scenarios such as deep reinforcement learning or machine translations. The initial results have been very encouraging with PBT showing great improvements over the traditional techniques.\n\nWe can expect PBT to be included in popular deep learning frameworks soon. There is an initial implementation available in Github and we should see this work adopted by other frameworks soon."
    },
    {
        "url": "https://cryptocurrencyhub.io/building-better-icos-understanding-daicos-a065b29ed8f8?source=user_profile---------48----------------",
        "title": "Building Better ICOs: Understanding DAICOs \u2013",
        "text": "Initial coin offerings(ICOs) continue being the subject of passionate debates in the cryptocurrency communities. While token fundraising mechanisms have shown no signs of slowing down, there are pretty clear indications that they require some improvements. Nobody should expect ICOs models to be rock solid in such a short period of times and, just like IPOs, improvements should be welcome as a sign of the evolution of the model.\n\nI believe the analogies between ICOs and IPOs is often misleading but we can use the history of the latter to extrapolate some lessons for token offerings. The first modern IPO dates back to 1602 when the Dutch East India Company offered shares and bonds of the company to the public in order to raise capital. However, it wasn\u2019t until the 1800s that public offerings became more mainstream in markets such as London and some of the current processes such as quiet periods or stag profits have been only implemented recently. If we accept that ICOs are a viable mechanisms for companies to raise funds, then we should be in search of new protocols that improve the current dynamics in token offerings.\n\nOne of the most intriguing proposals to improve the current ICO model came out at the beginning of this year from Ethereum\u2019s creator Vitalik Buterin. Under the catchy name of DAICO, the proposal looks to combine some of the best ideas behind ICOs with some of the principles of the infamous Decentralized Autonomous Organization (DAO) . Vitalik has been continuously proposing ideas for improving the mechanisms behind ICOs in order to alleviate some of the ethical and financial concerns currently casting a shadow over the fundraising mechanisms. From all the ICO improvements ideas I\u2019ve seen in the last year, DAICO seems to be one of the most compelling.\n\nThe main goal behind DAICO is to prevent the scenario in which founders can have complete access to the funds raised during an ICO, particularly if the token sell was executed before the product was actually built. It\u2019s not a secret that many ICOs have been plagued with scams and fraudulent ideas that haven\u2019t gone beyond the initial whitepaper. How does the DAICO model address this challenge specifically?\n\nDAICO combines the decentralized voting mechanisms of DAOs with the fundraising dynamics behind ICOs. Just like ICOs, DAICOs are based on smart contracts created by companies that intend to raise funds for a specific projects. A DAICO contract starts off in \u201ccontribution mode\u201d, specifying a mechanism by which anyone can contribute ETH to the contract, and get tokens in exchange. So far this looks just like a normal ICO. The main difference between DAICOs and ICOs comes after the initial token sale and involves a mechanism that Buterin likes to call tap.\n\nA tap essentially controls the amount per second that the development team can take out of the contract. Just like DAOs, shareholders can vote on specific resolution regarding the tokens. Specifically, the DAICO model includes two main types of resolutions:\n\nThe DAICO contract implicitly brings some benefits preventing the withdraw of funds from the company without the blessing of the token holders while also clearly preventing some malicious scenarios that are common in ICOs. Keeping the tap at a reasonable level should guarantee that the funds raised should be used properly. While a malicious actor can try to increase the level of the tap for his benefits, the DAICO models believes that the wisdom of the shareholder community should prevail in the long term keeping the tap at adequate levels.\n\nThe ideas behind DAICO are extremely creative and combine the best of two of the most important concepts in the history of cryptographic tokens. However, the model is not without challenging. One of the my major hesitations is the fact that ignorant token holders can strangle startups by keeping the tap level arbitrarily low for no other reason that being conservative. Also, I believe the destruction of the contract should have a more controlled mechanism than a simple voting. After all, Apple shareholders can\u2019t simply vote to liquidate the company if they wanted to ;).\n\nI believe many of the concepts that can be used to improve ICOs can be extrapolated from the way public companies operate today. I will explore some of those concepts in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/what-googles-acquisition-of-xively-taught-us-about-the-iot-market-ff6596b51e68?source=user_profile---------49----------------",
        "title": "What Google\u2019s Acquisition of Xively Taught Us About the IOT Market.",
        "text": "Last week, Google announced a preliminary deal to acquire internet of things(IOT) platform pioneer Xively. The acquisition has been estimated around $50 million and signals to the market that Google has some serious ambitions about the enterprise IOT space. Xively was initially incubated by LogmeIn and was considered, together with platforms such as ThingWorx(now PTC) one of the early proponents of the idea of a platform as a service(PaaS) model for IOT applications.\n\nConsidering Xively\u2019s deep technology stack, the deal can be seen as a bargain for Google. The valuation certainly seems on the low end for a company that has been battling in the IOT platform space for a few years now. However, beyond the headlines and speculation, there are some interesting implications that the IOT market can extrapolate from the acquisition.\n\nXively had all the ingredients to have become a successful standalone player in the IOT platform space. A strong technological foundation that included some of the fundamental building blocks of IOT backends. A solid financial backing from its parent company and an ambitious vision that positioned as a leader in the IOT platform space for both the consumer and enterprise markets. However, differently from other markets, those ingredients are not enough to win in the IOT platform space.\n\nIOT solutions are a capital intensive market. Each implementation of an IOT platform entails long sales cycles followed by months or years of development. Not surprisingly, those dynamics have made it easier for big enterprise software companies such as IBM, GE, Amazon or Microsoft to achieve leadership positions with their respective IOT platforms. Large sales forces combined with deep pockets to invest in professional services and industry expertise is making it incredibly harder for startups to stay relevant in the enterprise IOT space.\n\nXively will be a great addition to Google Cloud IOT Core stack and one that will even the playfield with competitors such as Azure IOT Suite or Watson IOT Platform. Is not a secret that Google Cloud has been trailing the other cloud incumbents in terms of its IOT capabilities and the addition of Xively can help to accelerate its roadmap.\n\nFrom my perspective, the first order of business should be to integrate Xively with some relevant services from the Google Cloud platform such as Cloud ML, Apigee or Dataflow which fill a technical gap in the Xively stack and present a very appealing technology suite for IOT customers.\n\nThis is not exactly news but the IOT platform market might be headed for another wave of consolidation. Two years ago, we saw some enterprise software incumbents such as Amazon, Citrix or Cisco acquire early market leaders in the IOT platform space. The pinnacle of that M&A wave was Cisco\u2019s acquisition of Jasper for $1.4 billion. Google\u2019s acquisition of Xively could mark the beginning of another wave of M&A activity. Startups such as IOTIFY, Things+ or ThingSpeak are definitely attractive targets.\n\nWhen enterprise software markets passed the peak of their hypecycle curve and some consolidation happens, there is always one or two vendors that are able to remain as viable standalone companies and play a relevant role in the next phase of the market. In the IOT platform space, that roles seems to fall on the shoulders of C3IOT which seems to be the most complete IOT platform not owned by a big enterprise software vendor. An ambitious technical vision and heavy capitalization might help C3IOT to become an influential force in the next phase of the IOT platform market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-book-club-life-3-0-352513eab837?source=user_profile---------50----------------",
        "title": "The Book Club: Life 3.0 \u2013 Jesus Rodriguez \u2013",
        "text": "Recently there have been plenty of books published about the role that artificial intelligence(AI) is likely to play in the future of the human race. Unfortunately, many of those books lack the scientific and even literally rigor to be considered seriously. Its really easy to write a book speculating about terminator-like versions of AI but its really hard to provide the right scientific backing to arguments about a human-machine symbiotic future. Late last year, I read Max Tegmark\u2019s Life 3.0 and was very impressed by the detailed research and original thinking presented in this book.\n\nLife 3.0 explores some the fundamental questions that we should face as AI becomes an intrinsic part of our future. Is life as we know it changing? What does it mean to be human in the age of AI? The arguments presented in the book are deeply philosophical but Tegmark does a solid job backing them with pragmatic ideas from some of the top AI thought leaders.\n\nTegmark biggest accomplishment might be to have written an AI book full of original ideas expressed in very accessible terms for the mainstream reader. Instead of making predictions about an AI apocalypse, Life 3.0 explores a variety of scenarios that discuss the impact of AI across diverse areas such as the job market, warfare and our political systems and democracies.\n\nMac Tegmark is uniquely positioned to present the ideas covered in Life 3.0. A cosmologist at MIT, Tegmark has been deeply involved in the AI community exploring some of the most important challenges that the human race will face in the age of AI. Life 3.0 conveys many of Tegmark\u2019s ideas in a fun and easy to read way that should help educate the public about the myths and realities facing the evolution of AI."
    },
    {
        "url": "https://cryptocurrencyhub.io/technology-fridays-a-technical-deep-dive-into-microsofts-decentralized-identity-vision-f239bfa55626?source=user_profile---------51----------------",
        "title": "Technology Fridays: A Technical Deep Dive Into Microsoft\u2019s Blockchain Identity Vision",
        "text": "Welcome to Technology Fridays! Earlier this week I wrote about Microsoft\u2019s new vision to leverage public blockchains to enable the next generation of decentralized identity solutions. Microsoft\u2019s ideas about decentralized identities and nothing if not ambitious and they contrasts with the highly-centralized identity management models present in products such as Azure Active Directory or Office365. More importantly, the building blocks to enable Microsoft\u2019s decentralized identity models are likely based on open source technologies that fall outside the control of the Redmond giant. Today, I would like to dig deeper into some of the technical elements of a decentralized identity architecture.\n\nA way to think about Microsoft\u2019s vision for decentralized identity models is as a series of identity-centric protocols that can run on top of public blockchains such as Ethereum or Litecoin. The main pillars behind Microsoft\u2019s decentralized identity ideas can be found in the works of the Decentralized Identity Foundation(DIF) which has been able to create a series of working groups focused on some of the main components of a blockchain-based identity systems. In the case of Microsoft, their original vision for decentralized identitites included four major components:\n\nA new identity model most likely will entail a new identity representation. Decentralized Identifiers(DIDs) are a new type of identity that is fully under the control of the subject and that bypass the need for a centralized authority. Technically, DIDs documents are composed of cryptographic proofs used to authenticate a specific subject. The cryptographic elements could take different forms such as public keys or biometric templates.\n\nIn addition to the crypto elements, DIDs also include a series of service endpoints used to interact with the holding entity. DIDs are typically used in distributed ledger or network. That model requires defining a DID method in a separate DID method specification. A DID method specifies the set of rules for how a DID is registered, resolved, updated, and revoked on that specific ledger or network. The underlying architecture for enabling DIDs is based on the ideas of decentralized PKI models.\n\nIdentity Hubs(IHs) are the component responsible for storing identity assertions about subjects. IHs are based on a decentralized model to store semantic representations of any object and expose then as specific URLs. An IH architecture can bring together identities stored on different providers ranging from cloud directories to devices. The following picture illustrates the architecture behind IHs.\n\nThe role of verifiable credentials(VCs) is to encode the identity assertions expressed in DIDs in a way that are easily verifiable without the need of a centralized authorities. The ideas of VCs are the result of a W3C working group focused on reimagining how we represent identity in modern software systems.\n\nA VC should contain identity assertions about a subject, the authority that issue the credentials as well as the process by which the credentials were obtained. More importantly, VCs should be created in a way that are cryptographically secure, privacy respecting, and automatically verifiable.\n\nMicrosoft\u2019s vision for decentralized identities is not restricted to a single blockchain or network. If we assume that we are operating in an ecosystem with multiple blockchains carrying millions of DIDs, how can we efficiently resolve identities without sacrificing the decentralized nature of the model? Does that problem sounds familiar? It should, because is a fairly similar model to the one used by DNS systems to resolve addresses.\n\nA Universal DID Resolver has a similar purpose to Binding mechanism in DNS system. Instead of working with domain names, Universal DID Resolvers focused on addressing self-sovereign identifiers that can be created and registered directly by the entities they refer to. The following diagram explains some of the components behind Universal DID Resolvers.\n\nIs Microsoft the only player focused on building a new platform for dentralized identities? Not really. The Redmond giant should be credited for joining the race to decentralize identity models early on but its faces competition from innovative startups such as Blockstack ID or uPort. IBM is also trying to achieve relevance in the space."
    },
    {
        "url": "https://cryptocurrencyhub.io/what-you-need-to-know-about-microsofts-new-blockchain-based-vision-for-decentralized-identities-c3c4aca666a4?source=user_profile---------52----------------",
        "title": "What You Need to Know About Microsoft\u2019s New Blockchain-Based Vision for Decentralized Identities",
        "text": "Earlier this week, Microsoft announced that is planning to leverage blockchain technologies to build a next generation identity platform based on a decentralized architecture. The decision can be seen as controversial as Microsoft is one of the biggest centralized identity authorities in the internet with assets such as Office365, Azure Active Directory, Xbox or Outlook.com that managed millions of identities globally. However, if you follow the work that the Redmond giant has been doing as part of the Decentralized Identity Foundation(DIF), then the news should not come as a surprise.\n\nA lot has been said about the impactful role that blockchain technologies can have in the next generation identity management platforms. However, with the exception of some companies such as GuardTime and their work with the government of Estonia, very little has been done in order to take these concepts mainstream. Microsoft\u2019s decision is certainly an ambitious move to enable decentralized identity management at scale. In order to understand Microsoft\u2019s vision about decentralized, blockchain-based digital identities, we should start by analyzing the challenges with the current generation of identity management solutions.\n\nIdentity is one of the pillars of the modern internet and, until recently, one that was really hard to enable at scale. For decades identity management remained one of the unsolved problems of the internet. That arguably changed in the last few years when identity providers such as Facebook or Google opened up their identity platforms to third party applications. However, despite the progress, the current model to identity management solutions has some fundamental flaws.\n\nThe current model to digital identities is based on users trusting dozens of identity providers with their information and constantly granting access to third party applications to use that identity representation. That model does not only require implicit trust in centralized identity authorities but is also impossible to manage. If you don\u2019t believe me, try to enumerate the number of websites and mobile apps that you have recently granted access to your Facebook or Google identities and you will realize what I mean. In an ideal world, identity systems should put the user in control of its own identity and the providers should focus on asserting claims about specific identities.\n\nTraditional identity management solutions are mostly based on authentication and access control models enabled by centralized providers as well as by identity federation bridges built between them. In the real world, identity is less about what you have access to and more about who you are. From that perspective, a next generation identity platform should provide an organic model to nurture assertions about the identity of a user that can be easily used across providers.\n\n3)Google, Amazon and Facebook Own Your World\n\nYou can argue that Google, Amazon and Facebook know more about your identity than other important entities in your life like the government, banks or your employer. Those three companies cover the major pillars of your digital life: Internet(Google), Ecommerce(Amazon) and Social(Facebook). Together, we are trusting those entities with a disproportional control over our digital identities that can result on unfortunate events. It is not a coincidence that the U.S Senate has been having active discussions about whether some of these entities should be regulated.\n\nIn order to address some of the aforementioned challenges, Microsoft envisioned a new generation of digital identity systems powered by blockchain protocols. Specifically, Microsoft believes that public blockchains such as Ethereum or Litecoin are well suited to incorporate protocols to enable the management of digital identities. The ultimate goal should be to transition the control identity assertions back to its rightful users while maintaining high levels of security and privacy.\n\nMicrosoft\u2019s vision for decentralized identities is still in very early stages. In collaboration with other vendors, Microsoft announced that is actively working on the following initiatives to enable a new wave of decentralized identity management protocols and solutions:\n\nIn more practical terms, Microsoft also revealed its plans to pilot decentralized identities as part of its Authenticator service. In that model, Microsoft Authenticator will be able to act as your gateway to manage identity data and cryptographic keys. The current plans is to keep an off-chain platform that supplements public blockchains with some of the components mentioned in the previous section. In that architecture, only the ID is rooted on chain. Identity data is stored in an off-chain ID Hub (that Microsoft can\u2019t see) encrypted using these cryptographic keys.\n\nI am planning to deep dive into the different components of Microsoft\u2019s decentralized identity architecture in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/learning-by-competition-understanding-adversarial-neural-networks-part-ii-ee40aad1a764?source=user_profile---------53----------------",
        "title": "Learning by Competition: Understanding Adversarial Neural Networks Part II",
        "text": "This is the second part of an essay focused on exploring the intricacies of adversarial neural networks in modern deep learning systems. Yesterday, we discussed some of the fundamental challenges that motivated the creation of adversarial neural networks as a mechanism to simulate human intuition in artificial intelligence(AI) agents. Additionally, we discussed the main distinctions between generative and discriminative classification systems as the two main schools of thought existent before the arrival of adversarial neural networks.\n\nFor decades the world of classification models was divided between generative and discriminative models. While both models have clear strengths, very often they result impractical in real world scenarios. In 2014, a group of deep learning lioneers led by Ian Goodfellow published a research paper that proposed the provocative idea of combining discriminative and generative techniques in a single adversarial model that could improve data classification in many high-dimensional scenarios. They called the new techniques Generative Adversarial Networks(GANs).\n\nMany knowledge-centric processes in life are accelerated by the friction created between different, often competing, interests. From the dynamics in stock markets to trade relationships, adversarial processes are a driving force behind many major economic trends. A more natural example of the influence of adversarial processes in learning can be seen in the intuitive ways in which infants acquire knowledge by finding intuitive solutions to challenges.\n\nFollowing some of those examples, the GAN researchers proposed a neural network formed by discriminator and generator models that compete in order to improve a classification process.\n\nIn the GAN model, the generator tries to generate data based on a probability distribution estimated from the training dataset. Mathematically speaking, a generator is itself a neural network that takes a input z from p(z), where z is a sample from probability distribution p(z). The generator then generates a data distribution that is fed to the discriminator network.\n\nThe other component of a GAN model is the discriminator which is also a neural network. The discriminator takes the data distribution created by the generator as well as inputs p(x) from the original training set and tries to solve a classification problem that determines whether the data is from the original training set or not.\n\nAs you can see, the magic of GAN models is based on the constant friction between the generator and discriminator network. In that architecture, the generator trying to maximize the probability of making the discriminator mistakes its inputs as real while the discriminator guiding the generator to produce more realistic data.\n\nIn some context you can evaluate GANs through the lenses of game theory and see the two networks as players in a game trying to maximize their outcome. If the game achieves a Nash Equilibrium, the generator would be able to capture the general training data distribution. As a result, the discriminator would be always unsure of whether its inputs are real or not."
    },
    {
        "url": "https://medium.com/@jrodthoughts/learning-by-competition-understanding-adversarial-neural-networks-part-i-b8dab1b99b75?source=user_profile---------54----------------",
        "title": "Learning by Competition: Understanding Adversarial Neural Networks Part I",
        "text": "This weekend I was reading some interesting research about new techniques to analyze adversarial neural networks and it occurred to me that it might be a good idea to revisit some of the fundamentals of this new technique that has been gaining a lot of traction in the deep learning ecosystem. In the past, I\u2019ve briefly written about adversarial neural networks but without getting too deep into the details so there is no risk of sounding too repetitive ;).\n\nAdversarial neural networks were created to address one of the most important challenges of modern deep learning applications: how to train models with high quality data while keeping the resources manageable. This type of problem has been at the center of machine learning and deep learning almost since their inception. One of the reasons that makes the training of deep learning systems so challenging is that it typically relies on pre-processed data. That approach contrasts with the way humans acquire and generate knowledge and, in particularly, with one of our most magical cognitive abilities: intuition\n\nConceptually, intuition is the ability of understanding knowledge without explicit conscious reasoning. The unconscious aspect of intuition is some important that some neuroscientists even refer to this phenomenon as unconscious cognition. As humans, every time we are presented with a new piece of knowledge we can \u201cintuitively\u201d derive variations of it without the need to reason deeply about it. In other words, we are generating new knowledge without conscious reasoning. Wouldn\u2019t it be nice if we could apply similar concepts to deep learning systems?\n\nSimulating intuition in deep learning models can be the combination of two often competing processes: generating new knowledge and discriminating facts to assert its quality. These two processes encompassed two of main school of thoughts of deep learning classification models before adversarial neural networks came along.\n\nTo understand adversarial neural networks it might be useful to revisit the two main approaches of information classification in traditional machine learning systems:\n\nBoth discriminative and generative models have strengths and weaknesses. Discriminative algorithms tend to perform incredibly well in classification tasks involving high quality datasets. However, generative models have the unique advantage that can create new datasets similar to existing data and operate very efficiently in environments that lack a lot of labeled datasets.\n\nFor years, the entire space of classification algorithms could be segmented between generative and discriminative models. That changed in 2014 when a group of researchers led by deep learning luminary Ian Goodfellow(now with OpenAI) published a paper advocating for a new type of model that combine both generative and discriminative techniques to generate high quality knowledge. They called the new technique generative adversarial networks(GANs) and that will be the subject of our next post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-dfinity-wants-to-lead-the-next-phase-of-blockchain-platforms-7efc305b33f2?source=user_profile---------55----------------",
        "title": "Technology Fridays: DFINITY Wants to Lead the Next Phase of Blockchain Platforms",
        "text": "Welcome to technology Fridays! Today we are staying in crypto land to explore one of the newest platforms that is likely to become a household name in the blockchain ecosystem. We are talking about DFINITY.\n\nHave you ever heard the argument that blockchain techbologies might present the first real alternative to traditional cloud computing paradigm? From a conceptual standpoint, cloud platform are the epitome of centralization. In AWS and Azure we trust when we deploy our code to their cloud infrastructures. New architecture styles such as edge computing are in desperate need of a more decentralized compute network that natively enables scenarios such as internet of things(IOT) topologies. Blockchains seem to be the obvious candidate to fulfill that promise. If this is so obvious, why hasn\u2019t happened yet. One answer: performance!\n\nFrom its inception with technologies like Bitcoin, blockchain networks have been notoriously slow. Ethereum has certainly become the most important platform in our quest to make blockchain applications mainstream but its performance still results prohibited for many real world scenarios. This is where DFINITY come in. A new type of blockchain platform that extends some of the principles pioneered by Ethereum with a modern and high performant infrastructure.\n\nDFINITY is the first blockchain platform that has a real chance to pioneer a truly decentralized cloud. At its core, DFINITY is a decentralized network built on top of what they like to call a \u201cvirtual blockchain computer\u201d(VBC). The VBC concept is a trivial as it is ambitious. VBC distributes computations across nodes. VBC uses a novel architecture to finalize computations quickly (using short block times and by requiring only a small number of blocks as\u201dconfirmations\u201d) while achieving predictable performance (by keepingthe time between confirmations approximately constant).\n\nThe VBC serves as an enabler to what can be considered the main component of DFINITY, the blockchain nervous system(BNS). The goal of BNS is to enable a new type of governance model in blockchain networks based on artificial intelligence(AI). While most of the governance model in networks like Ethereum is controlled by code expressed in smart contracts, BNS takes a slightly different approach. BNS can be seen as a network of nodes known as neurons. Any transaction in the network can be submitted to the BNS for a fee. The BNS then decides on proposals using votes made by human-controlled \u201cneurons\u201d that automatically follow each other. This model imitates the basics of a liquid democracy system. The BNS adapts and learns to make better decisions as neurons respond to feedback. Decisions get made by neuron follow relationships cascading in a manner that is non-deterministic due to timing. In this architecture, each neuron is operated using special client software run by its owner on the edge of the network.\n\nThe concept of BNS enables true algorithmic governance in blockchain networks. The model can be easily adapted to other platforms such as Ethereum but the DFINITY is obviously in a better position to carry the first implementation. Like other blockchain technology, DFINITY uses its own digital tokens known as dfinities. The tokens are used on different tasks in the platform such as enabling neurons to join the BNS. You can also receive dfinities by mining them using DFINITY client software.\n\nSecurity is one of the areas in which DFINITY excels. The platform leverages techniques such as top-level Threshold Relay protocols to address some of the traditional security vulnerabilities of traditional blockchain networks. The model also interoperates seamlessly with the security techniques of networks such as Ethereum.\n\nYou can certainly see DFINITY as an alternative to blockchain platform such as Ethereum but I don\u2019t neccesarly think they are competitive. Given DFINITY focus on the enterprise, I believe the startup is likely to encounter technologies such as Hyperledger Fabric, Sawtooth or Corda as competitors while Ethereum becomes more like a partner and allied. Interesting times\u2026."
    },
    {
        "url": "https://cryptocurrencyhub.io/what-you-need-to-know-about-the-state-of-the-blockchain-report-part-i-305996af9ce9?source=user_profile---------56----------------",
        "title": "What You Need to Know About the State of the Blockchain Report: Part I",
        "text": "Last night, Crypto news website CoinDesk published its anticipated State of the Blockchain report which covers the major developments in the digital currency space. Inspired by Mary Meacker\u2019s famous \u201cState of the Internet\u201d reports, CoinDesk\u2019s work is very comprehensive and covers many areas of the blockchain ecosystem. In case you are not planning to go through the 170 pages of the report, I thought I summarize some of the most important highlights. Here are my favorite five:\n\nThe transaction volumes for all digital currencies has been off the charts but in the case of Ethereum is simply atypical for a digital asset. Part of the increase in the Ethereum\u2019s activity is due to the new wave of initial coin offerings(ICOs) which are based on the Ethereum blockchain in its vast majority.\n\nFollowing China\u2019s forceful exit of the cryptocurrency markets, Japan and The United States have fill that gap and are increasing their leads as the major markets for Bitcoin. This fact also poses a risk for Bitcoin as it can become vulnerable to regulators in both countries.\n\nThe market for enterprise blockchain platforms is forecasted to reach $22 billion by 2025 from about $3 billion last year. That\u2019s a 7x growth which is remarkable in any enterprise software market.\n\nWe are often seeing vendors partners on different alliances targeting specific segments of the enterprise blockchain market. At the moment, organizations such as the R3 consortium, Hyperledger and the Ethereum Alliance all include major players in the enterprise blockchain space.\n\nDespite the increasingly hostile regulatory environment, ICOs are not showing signs of slowing down and they reached new records at the end of last year. The total investment in ICOs top $4 billion in 2017 compared to less than $250 million that was deployed by venture capitalists in blockchain companies."
    },
    {
        "url": "https://cryptocurrencyhub.io/these-charts-show-some-interesting-relationships-between-bitcoin-and-public-markets-164e2fcb80b4?source=user_profile---------57----------------",
        "title": "These Charts Show Some Interesting Relationships Between Bitcoin and Public Markets",
        "text": "These Charts Show Some Relationships Between Public Markets and Cryptocurrencies\n\nDigital currencies are often seen as an alternative to traditional market investing and many people use it as a hedge against traditional securities and commodities. From that perspective, there is a popular believe that crypto assets are immune to some of the behavior of public markets. That couldn\u2019t be further from the truth. While the correlations between public equities and crypto assets is still being explored, there is no doubt that the digital currency space is impacted by the behavior of public markets.\n\nThis week offered a unique perspective to evaluate the relationship between the two market ecosystem. Until now, the raise in cryptocurrencies has coincided with one of the biggest bull markets of the last decade. In other words, we haven\u2019t had a lot of downturns to evaluate how crypto assets react to market turmoil. That clearly changed this week with the plummeting and rebound of all major stock indices across the world. Last night, I collected some data and ran some basic analysis and I thought I\u2019d share some of the results. I am in the process of running more sophisticated pattern detection analysis but even these basic techniques might help to illustrate some correlations between public market and cryptocurrencies.\n\nTechnology investors are an important part of the cryptocurrency ecosystem. The following chart compares the highs and lows of the NASDAQ Composite Index and Bitcoin in the past seven days. As you can see, the correlations remain incredibly stable indicating that both assets traded similarly.\n\nWe applied the same technique to the DOW and, surprise surprise, the results were pretty much the same.\n\nThe Cboe Volatility Index or VIX is a primary market indicator that reflects the 30 day volatility expectation. In recent days, the VIX went crazy spiking over 100% in recent days as reflected in the following chart.\n\nNot surprisingly, Bitcoin\u2019s volatility has also been off the charts as captured by the BTC volatility index.\n\nI hope the following charts illustrate some of the relationships between Bitcoin and public market equities. In the next few days, I will post some more detailed analysis."
    },
    {
        "url": "https://medium.com/@jrodthoughts/expanding-the-nash-equilibrium-a-new-strategy-for-asymmetric-games-c47c1672389b?source=user_profile---------58----------------",
        "title": "Expanding the Nash Equilibrium: A New Strategy for Asymmetric Games",
        "text": "Yesterday I published a brief overview about the main types of games we can find in game theory and their relevance in deep learning or artificial intelligence(AI) scenario. Today, I would like to bring your attention to a new method that was recently published by Alphabet\u2019s subsidiary DeepMind and that provides a unique way to tackle asymmetric game problems. DeepMind\u2019s breakthrough can have profound implications in modern multi-agent, AI systems that are often modeled as asymmetric games. Before getting there, let\u2019s try to understand what\u2019s so difficult about asymmetric game environments.\n\nSymmetric games are the favorite examples used to illustrate the dynamics of game theory as they are mathematically elegant and near perfect. As we explained in yesterday\u2019s article, a symmetric game describes a dynamic in which the different players share the same strategy and goals. Typically, the simplicity of symmetric games makes it easier to model from a computational standpoint. Unfortunately, most real life game environments lack the mathematical elegance of symmetric games.\n\nAsymmetric games describe multi-agent environments in which players have different and often conflicting goals and strategies. Let\u2019s take yesterday\u2019s market collapse as an example. In that environment, some traders were desperately trying to offload their positions while others were trying to accumulate new positions planning for a potential bounce back of the market (doesn\u2019t seem is going to happen today based on the futures ;)). Multiply that strategy for the millions of traders and investors around the world and you have an incredibly chaotic asymmetric game.\n\nIn game theory, the solution to many asymmetric game environments is modeled using the Nash equilibrium. The model was named after John Forbes Nash, the American mathematician immortalized by Russell Crow in the movie \u201cA Wonderful Mind\u201d. Essentially, a Nash equilibrium describes a situation in which each player has chosen a strategy and no player can benefit by changing strategies while the other players keep theirs unchanged.\n\nThe Nash equilibrium is a beautiful and incredibly powerful mathematical model to tackle many game theory problems but it also falls short in many asymmetric game environments. For starters, the Nash method assumes that players have infinite computing power which is rarely the case in real world environments. Also many Nash equilibrium models fail to account for the notion of risk which is omnipresent in most asymmetric games the economic markets. As a result, there are many asymmetric game scenarios that are hard to implement using the Nash equilibrium. This is particularly important in multi-agent AI systems that need to find the right balance between the mathematical elegance of the solution and the practicality of its implementation.\n\nIn a recent paper published by DeepMind, the authors proposed a very clever model to find solutions for highly complex asymmetric games by decomposing them into different symmetric games. In mathematical terms, the new techniques proposes that if (x,y) is a Nash equilibrium of an asymmetric game (A,B), this implies that y is a Nash equilibrium of the symmetric counterpart game determined by payoff table A, and x is a Nash equilibrium of the symmetric counterpart game determined by payoff table B.\n\nTo illustrate the new technique, I am going to borrow an example from the original post in the DeepMind\u2019s website. The example is based on the famous \u201cBattle of the Sexes\u201d game. Here, two players have to coordinate a night out to either the opera or the movies. One of the players has a slight preference for the opera and one of them has a slight preference for the movies. The game is asymmetric because, while both players have access to the same options, the corresponding rewards for each are different based on the players preferences. In order to maintain their friendship \u2014 or equilibrium \u2014 the players should choose the same activity (hence the zero payoff for separate activities).\n\nThis game has three equilibria: (i) both players deciding to go to the opera, (ii) both deciding to go to the movies, and (iii) a final, mixed option, where each player will opt for their preferred option three fifths of the time. This last option, which is said to be \u201cunstable\u201d, can be rapidly uncovered using DeepMind\u2019s new method by simplifying \u2014 or decomposing \u2014 the asymmetric game into its symmetric counterparts. These counterpart games essentially considers the reward table of each player as a separate symmetric 2-player game with equilibrium points that coincide with the original asymmetric game."
    },
    {
        "url": "https://towardsdatascience.com/what-data-scientists-should-know-about-game-theory-types-of-games-2ecc616ea725?source=user_profile---------59----------------",
        "title": "What Data Scientists Should Know About Game Theory: Types of Games",
        "text": "Game theory is one of the foundational building blocks of our behavior as social beings as well as many of our behavioral patterns. In the context of artificial intelligence(AI) and deep learning systems, game theory is essential to enable some of the key capabilities required in multi-agent environments in which different AI programs need to interact or compete in order to accomplish a goal.\n\nIn the past, I\u2019ve written about the implications of game theory in AI systems. The famous Nash equilibrium popularized by the movie \u201cA Wonderful Mind\u201d is the cornerstone of many AI interactions in modern systems. However, modeling an AI universe using the principles of game theory many times goes beyond the Nash equilibrium. A good place to start understanding the implications architecting AI systems using principles of game theory is to understand the different types of games that we typically encountered in our social or economic interactions.\n\nAny days, we participate in hundreds of interactions that are based on game dynamics. However, the architecture of those gamified environments are completely different and so are the incentives and goals of the participant. How to apply some of principles to the modeling of AI agents? Well, the first step is to identify the nature of the game we are trying to create:\n\nSuppose that we are modeling an AI system that involves multiple agents that will interact and compete to accomplish a specific goal. That\u2019s a classic example of game theory. Since its inception in 194, game theory has focused on modeling the most common interaction patterns that now we are seeing every day in multi-agent AI systems. Here is a taxonomy that might help you identify some of the most relevant types of games that have an equivalent in the AI world :\n\nOne of the simplest classifications of games is based on their symmetry. A symmetric game describes an environment in which each player has the same goals and the results will only depend on the strategies involved. Chess is a classic example of a symmetric game. Many of the situations we encountered in the real world lack the mathematical elegance of symmetry as participants often have different and even conflicting goals. A business negotiation is an example of asymmetric game in which each party has different goals and evaluates the results from a different perspective (ex: winning a contract vs. minimizing an investment).\n\nAnother important categorization of games is based on the type of information available. A perfect information game refers to an environment in which each player can see the other player\u2019s moves. Chess, again, is an example of a perfect information game. Many modern interactions are based on environments in which the moves from each player are hidden from other players and game theory classifies those scenarios as imperfect information games. From card games like poker to self-driving car scenarios, imperfect information games are all around us.\n\nA cooperative game environment is one in which the different participants can establish alliances in order to maximize the end result. Contractual negotiations are often modeled as cooperative games. Non-cooperative scenarios describe environments in which players are forbidden from forming alliances. Wars are the ultimate example of non-cooperative games.\n\nA sequential game takes place in an environment in which each player has information about the other player earlier actions. Board games are mostly sequential in nature. Simultaneous games represent scenarios in which both players can take concurrent actions. Securities trading is an example of simultaneous games.\n\nA zero-sum game refers to a scenario in which the gains or one player always come translate into looses for other players. Board games are examples of zero-sum games. Non-zero-sum games are often encountered in scenarios in which multiple players can benefit from the actions of one players. Economic interactions in which multiple participants collaborate to increase the size of the market is an example of a non-zero-sum game."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-book-club-black-edge-and-the-quest-to-convict-the-most-wanted-man-in-wall-street-2faf3e1c8f98?source=user_profile---------60----------------",
        "title": "The Book Club: Black Edge and the Quest to Convict the Most Wanted Man in Wall Street",
        "text": "I read Black Edge when it came out last year and, I have to say, that its one of the best books about Wall Street\u2019s stories I\u2019ve read in a long time. The book depicts the epic battle between hedge fund legend Steven A. Cohen. and federal authorities. The mastermind by New Yorker\u2019s writer Sheelah Kolhatkar, Black Edge goes in detail into the U.S Attorney\u2019s office quest to convict Cohen and his firm SAC Capital. The case that started with the arrest and conviction of Galleon Group hedge fund magnate Raj Rajaratnam, became an obsession for federal authorities which end up convicting numerous people associated with Cohen such as his lieutenant Mathew Martoma as well as companies such as Level Global, Diamondback Capital Management of Stamford, Connecticut and Loch Capital Management. Although SAC Capital pled guilty to securities fraud, the authorities were unable to convict Cohen whom, since then, has been working in his own asset management firm, Point72 and is gearing up to launch a new fund with external capital.\n\nBlack Edge does a phenomenal job describing one of the most intriguing Wall Street sagas of the last 20 years. Kolhatkar takes a pragmatic an impartial view to a very complex subject that exposes the best and both of both worlds."
    },
    {
        "url": "https://cryptocurrencyhub.io/technology-fridays-cosmos-wants-to-connect-all-blockchains-e686900704c?source=user_profile---------61----------------",
        "title": "Technology Fridays: Cosmos Wants to Connect All Blockchains",
        "text": "Welcome to Technology Fridays! Today, we are going back into the blockchain rabbit hole exploring the emerging ecosystem of cross blockchain protocols and discuss one of the most important players in the space: Cosmos.\n\nLast year saw the increased adoption of blockchain technologies across different sectors in the enterprise and consumer markets. With the proliferation of different types of blockchains and protocols, the interoperability between those components has become increasingly challenging. Consequently, there have been a number of players that have come to market with new technologies trying to address cross-blockchain interoperability. Recently, I wrote about Polkadot as one of the most exciting companies in the space. Cosmos is another vendor with a very interesting value proposition to address communications between different blockchain assets.\n\nFrom a topology standpoint, Cosmos can be considered a network of independent blockchains called Zones. Currently, Cosmos includes a single zone known as the Cosmos Hub but new zones are expected to be added in the future. The Cosmos Hub provides the fundamental building blocks of inter-blockchain communications including governance, token tracking and interoperability protocols. Using the Cosmos Hu, applications can exchange tokens between different blockchains without the need of a liquid exchange in the middle. Architecturally, the Cosmos Hub allows any blockchain such as Go-Ethereum, CryptoNote or ZCash to join the Zone without the requiring major modifications to its protocols.\n\nThe magic of Cosmos is based on another relevant project in the blockchain ecosystem: Tendermint. Sometimes labeled as the Zookeeper of the blockchain, Tendermint provides different capabilities for the operationalization of blockchain applications at large scale. Among its capabilities, Tendermint includes a Byzantine fault-tolerant (BFT) protocol that simplifies the validation of blockchain transactions. Cosmos leverages BFT to implement a concept called Validators which have a similar roles to miner in a blockchain network. Cosmos\u2019 Validators use cryptographic signatures to vote on the processing of specific transactions.\n\nIn order to enable the transaction exchange between different blockchains, Cosmos implements a protocol known as Inter-Blockchain Communication(IBC). Conceptually, the IBC protocol can naturally be seen as two types of transactions: an IBCBlockCommitTx transaction, which allows a blockchain to prove to any observer of its most recent block-hash, and an IBCPacketTxtransaction, which allows a blockchain to prove to any observer that the given packet was indeed published by the sender\u2019s application.\n\nDevelopers can start building applications in the Cosmos platform using the main SDK includes in the platform. The Cosmos SDK is a framework based on the Application-Blockchain Interface(ABCI) protocols which is also part of the Tendermint project. ABCI adds BFT capabilities to blockchains applications written on any programming language.\n\nCosmos is one of the most innovative players in the nascent space of inter-blockchain communication platforms. Other relevant names in the market include Polkadot and Aion."
    },
    {
        "url": "https://medium.com/@jrodthoughts/connectionists-and-symbolists-learning-rules-from-noisy-data-3188d7e85c8c?source=user_profile---------62----------------",
        "title": "Connectionists and Symbolists: Learning Rules From Noisy Data",
        "text": "In his book \u201cThe Master Algorithm\u201d, artificial intelligence researcher Pedro Domingos explores the idea of a single algorithm that can combine the major schools of machine learning. The idea is, without a doubt, extremely ambitious but we are already seeing some iterations of it. Last year, Google published a research paper under the catchy title of \u201cOne Model to Learn Them All\u201d that combines heterogeneous learning techniques under a single machine learning model. This week, Alphabet\u2019s subsidiary DeepMind took another step towards multi-model algorithms by introducing a new technique called Differentiable Inductive Logic Programming(DILP) that combines logic and neural networks into a single model to extract rules from noisy data.\n\nDILP brings together two of the major machine learning schools. Connectionists try to model knowledge by imitating representations of the brain in the form of neural networks and have been the driving force behind movements such as deep learning. Symbolists rely on logic to model knowledge based on well-understood rules. Both schools have well known advantages and drawbacks. Symbolist systems based on inductive logic programming(ILP) tend to generalize knowledge efficiently and they are semi-immune to overfitting. Also, ILP systems tend to be a great fit in transfer learning scenarios in which a trained model can be copied and reused in other models. The main limitation of ILP systems is their struggle with noisy or ambiguous data which is so common in deep learning scenarios.\n\nConnectionist systems tend to work well in environments with noisy data and can efficiently handle uncertainty and ambiguity. However, they tend to be expensive to train and version. Also, the knowledge learned from connectionist system is very hard to follow and understand which contrasts with the clarity of symbolist model. For years, many experts have highlighted the theoretical value on combining robust connectionist learning with symbolic relational learning. DILP is certainly a step on the right direction.\n\nConceptually, DILP combines neural networks with ILP to provide a model that can process noisy and ambiguous data while also generalizing well and avoiding deterioration. By combining the best of both worlds, DILP is a technique that differs from connectionist models in the sense that can generalize knowledge symbolically while also differing from traditional symbolist models by generalizing knowledge visually. The following matrix might help to illustrate the comparison between the three schools of thought.\n\nDILP is very creative approach to bring together two of the major tribes in machine learning. Combining the intuitive knowledge of connectionist systems with the conceptual knowledge of symbolists is a step closer to emulate human cognition and, maybe, a step closer to Domingo\u2019s master algorithm."
    },
    {
        "url": "https://cryptocurrencyhub.io/regulators-and-the-antifragility-of-bitcoin-80205726b9d8?source=user_profile---------63----------------",
        "title": "Regulators and the Antifragility of Bitcoin \u2013",
        "text": "Antifragility is one of my favorite concepts in the architecture of modern systems. Quoted by author and philosopher Nassin Nicholas Taleb in his book Antifragile, the concept defines entities that can benefit and get better by sustaining shocks and chaos. In the words of the master himself: \u201cSome things benefit from shocks; they thrive and grow when exposed to volatility, randomness, disorder, and stressors and love adventure, risk, and uncertainty. Yet, in spite of the ubiquity of the phenomenon, there is no word for the exact opposite of fragile. Let us call it antifragile. Antifragility is beyond resilience or robustness. The resilient resists shocks and stays the same; the antifragile gets better\u201d. I\u2019ve been very intrigued how the concepts of antifragility is manifesting in the digital currency ecosystem. Not only from the conceptual standpoint but in terms of the market impact. A few months ago, I published some of my initial thoughts about the nascent antifragile characteristics that we can observe in some digital currencies. The aggressive and coordinated regulatory crackdown of the last few days have offered a unique macro-perspective to analyze this phenomenon.\n\nThe antifragility of the digital currency market has manifested itself last year by adapting to shocking events such as China\u2019s ban of cryptocoin trading, the aggressive position of the U.S Securities and Exchange Commission regarding initial coin offerings(ICOs) or the regular hacking attacks against digital currency exchanges. However, nothing impact more the cryptocurrency markets than the potential of a regulatory crackdown by governments across the world. In recent weeks we have seen an escalation in the measures that regulators are taking to control digital currency assets. Just yesterday, we had a series of events that can make the price of a market asset collapse. Let\u2019s take a quick recap:\n\n\u00b7 The South Korea Korea Customs Service (KCS), the statement alleges that a total of 637.5 billion won worth (or around $600 million) in foreign currencies have been exchanged illegally, including unrecorded capital outflow using cryptocurrencies.\n\n\u00b7 Also, the South Korea Financial Services Commission (FSC) announced that, starting from Jan. 30, cryptocurrency investors in South Korea will have to use real-name bank accounts in order to continue trading.\n\n\u00b7 The U.S Commodities and Futures Trading Comission issued subpoenas to cryptocurrency exchange Bitfinex and cryptocurrency provider Tether regarding their financial holdings.\n\n\u00b7 Cryptocurrency company BitConnect was hit with another lawsuit alleging that the company has been operaring a Ponzi scheme with its investment vehicle.\n\n\u00b7 The U.S. Securities and Exchange Commission (SEC) is suing cryptocurrency banking company AriseBank with alleged fraud during its recent ICO.\n\nThat was just yesterday!!!!! Its impossible to find another market asset that can sustain a similar wave of recurrent bad news.\n\nAnd Bitcoin is Still Alive\n\nNot surprisingly, the price of Bitcoin dropped yesterday amid the wave of awful news and it triggered a drop in the price of other digital currencies across the board. However, the drop was only about 5% as of this morning which shows that Bitcoin, once again, is showing signs of antifragility.\n\nIs Bitcoin is able to get passed this wave of regulatory crackdowns, is not crazy to think that its price can raise towards new levels. So far, the $10,000.00 mark seems to the support territory.\n\nIn the long term, I believe regulations will have a positive impact in the digital currency ecosystem. If goverments are able to established thoughtful regulatory framworks for digital assets, that will pave the way for new financial products based on cryptocurrency and will legitimize the use of crypto tokens within the mainstream population beyond the speculative means. In the short term, is obvious that regulatory are playing a pivotal role in the recent decline on the valuations of most digital currencies. However, don\u2019t be surprised if the market is able to benefit from these shocks and keeps becoming more antifragile."
    },
    {
        "url": "https://towardsdatascience.com/the-most-important-algorithm-in-the-world-of-randomness-b0dcec53f5e5?source=user_profile---------64----------------",
        "title": "The Most Important Algorithm in the World of Randomness",
        "text": "In a previous post, we discussed the relevance of Monte Carlo methods in the deep learning ecosystem as an alternative to more traditional Las Vegas techniques. Essentially, both techniques fall under the umbrella of randomized methods but Las Vegas techniques focused on providing an exact answer while Monte Carlo methods provide an approximate exact answer based on a probabilistic distribution. The efficiency of Monte Carlo techniques when operating in large, multi-dimensional datasets have made it a favorite of deep learning practitioners. From sampling data, to regularization or optimization techniques, Monte Carlo methods have become an important building block of modern deep learning solutions.\n\nThere are several Monte Carlo techniques that have been widely implemented in modern deep learning platforms. The best known member of the Monte Carlo family is a technique that brings Markov chains into the world of randomness and is known by the name of Markov Chain Monte Carlo methods (MCMC).\n\nThe main objective of MCMC models is to obtain information about distributions using Markov random walks algorithms. This is fancy way of saying that MCMC techniques are able to learn the fundamental attributes of a probabilistic distribution without sampling all its members. Reading this you might be confused. Isn\u2019t the role Monte Carlo methods to draw examples from a distribution? If so, how are MCMCs any different?\n\nThe main difference of MCMC methods comes from the usage of Markov chains to generate the samples using a special sequential process. While standalone Monte Carlo methods are able to generate samples from a distribution, there are many scenarios in which there is no tractable methods to draw exact examples from a dataset. Markov chains complement traditional Monte Carlo methods by using a model in which each random sample is used as a stepping stone to generate the next random sample (hence the chain). A unique benefit of the chain is that, although each new sample depends on the one before it, new samples do not depend on any samples before the previous one (this is the \u201cMarkov\u201d property).\n\nLet\u2019s use a classic example in machine learning literature to illustrate the value of MCMC models. Suppose that a professor is interested in learning the average of test scores in a student population. While the mean test score is unknown, the lecturer knows that the scores are normally distributed with a standard deviation of 15. So far, the lecturer has observed a test score of a single student: 100. One can use MCMC to draw samples from the target distribution, in this case the posterior, which represents the probability of each possible value of the population mean given.\n\nIn order to draw samples from the distribution of test scores, MCMC starts with an initial guess: just one value that could be drawn from the distribution. Let\u2019s assume this initial guess is 110. MCMC is then used to produce a chain of new samples from this initial guess. Each new sample is produced by two simple steps: first, a proposal for the new sample is created by adding a small random perturbation to the most recent sample; second, this new proposal is either accepted as the new sample, or rejected (in which case the old sample retained). By continuously repeating this process, an MCMC model should produce a series of samples that are very close to the original probabilistic distribution."
    },
    {
        "url": "https://medium.com/@jrodthoughts/randomness-in-deep-learning-systems-monte-carlo-and-las-vegas-methods-fc03108fa80c?source=user_profile---------65----------------",
        "title": "Randomness in Deep Learning Systems: Monte Carlo and Las Vegas Methods",
        "text": "Monte Carlo methods play a super important role in the new generation of deep learning systems. While Monte Carlo based techniques have been around for a while, the explosion of multi-dimensional data sets common in deep learning system have brought its relevance to another level. Monte Carlo techniques fall into the category of randomized algorithms that attempt to provide an answer to a problem that entails certain degree of randomness. In that space, Monte Carlo methods are seeing as an alternative to another \u201cgambling paradise\u201d: Las Vegas.\n\nThe main difference between Monte Carlo and Las Vegas techniques is related to the accuracy of the output. Las Vegas methods tend to always provide an exact answer while Monte Carlo methods are return answers with a random amount of error. Obviously, the degree of error in Monte Carlo system decreases with the increase in resources such as data or computation models.\n\nA classic example of Las Vegas algorithms is the randomized quick sort algorithm which picks a pivot at random, and then partitions the elements into three sets: all the elements less than the pivot, all elements equal to the pivot, and all elements greater than the pivot.\n\nThe randomized quick sort method tends to consume a lot of resources but guarantees an exact answer. Consequently, Las Vegas methods tend to be recommended in scenarios with a small number of potential answers.\n\nEven though Las Vegas models seem great in theory, they result unpractical in many deep learning scenarios that, are so large, that can never expect to produce an exact answer. Monte Carlo techniques addresses some of the limitations of Las Vegas algorithms by improving the efficiency of the computation graph introducing certain level of randomness in the answers. Not surprisingly, Monte Carlo techniques have become incredibly popular in deep learning scenarios that deal with multi-dimensional, large volume datasets.\n\nOne of the main applications of Monte Carlo methods in deep learning systems is to draw samples from some probability distribution that represents a dataset. This is typically known as Monte Carlo sampling and has been widely used throughout history to solve highly complex data estimation problems. In one of the most notorious examples, French mathematician Pierre-Simon Laplace once proposed a method to estimate the value of pi using Monte Carlo sampling.\n\nIn the context of deep learning systems, Monte Carlo sampling methods have very well-known applications. For instance, it is common to leverage Monte Carlo sampling to select a distribution of the training dataset that approximates the original dataset. Monte Carlo methods also play a role in regularization or optimization techniques estimating the output datasets without having the evaluate the entire computation graph."
    },
    {
        "url": "https://medium.com/@jrodthoughts/book-club-the-money-formula-9905c804ef3b?source=user_profile---------66----------------",
        "title": "Book Club: The Money Formula \u2013 Jesus Rodriguez \u2013",
        "text": "Let\u2019s try something different today!. Normally, I try to read a lot of books during the year related to 2\u20133 topics that I decide to deep dive for a period of time. Recently, a friend suggested that I write about some of those books in this weblog. I am no book critic so I don\u2019t think I have a lot to add from the book review standpoint but maybe there is some value on sharing some of my basic impressions about what I have been reading.\n\nLet\u2019s start with the first book I read this year: The Money Formula is a fun ride into the world of quantitive finance. Authored by mathematician David Orrel and my favorite quant in the world: Paul Wilmott, the Money Formula explores the universe of financial derivatives and quantitive analysis. The book begins with a historical perspective of financial speculation and dives into important aspects of the finance ecosystem such as risk management before unveiling the curtain to the world of quants and derivatives. From the basic ideas of quant trading to exploring the role of quants in financial crises, The Money Formula provides unique perspectives of how mathematics are ruling the current markets.\n\nWilmott and Orrel are considered two of the most original thinkers in the quant space and their perspectives about financial markets are nothing but insightful and original. With quantitive trading experiencing a renaissance in the current markets and new financial products such as crypto currencies challenging traditional concepts, the ideas explored in The Money Formula couldn\u2019t be more current."
    },
    {
        "url": "https://medium.com/@jrodthoughts/learning-by-distributed-representations-91bb7a5a052c?source=user_profile---------67----------------",
        "title": "Learning by Distributed Representations \u2013 Jesus Rodriguez \u2013",
        "text": "In my recent series about natural language processing(NLP), I mentioned that neural language models(NLMs) derive its effectiveness from a technique known as distributed representations( see my previous articles about natural language processing). As a follow up to those articles, I thought it would be a good idea to expand into the concept of distributed presentations as it has become a widely adopted technique in the deep learning ecosystem.\n\nThe first thing to understand about distributed representations is that its consider a form of a large deep learning discipline known as representation learning. Conceptually, representation learning focuses on optimizing knowledge representations and reusing it across models. Representation learning is used in scenarios that fall outside the supervised learning umbrella and that involve large volumes of unlabeled data.\n\nThe most famous instance of representation learning is known as transfer learning and enables the reusability of optimized knowledge across different domains. Other notable variations of representation learning include unsupervised pretraining(see my article about unsupervised pretraining) and semi-supervised learning.\n\nOne of the main challenges of representation learning is in scenarios in which the large number of unlabeled data containing knowledge based on a large number of underlying concepts. This is the specific area in which distributed representations can be useful.\n\nImagine a scenario that uses NLP to understand the characteristics of objects based on large text datasets. For instance, our model can understand that human brains are divided in cortices based on interconnected neurons using structures known as axons and dendrites. Let\u2019s now extrapolate that example to scenarios in which each concept can have n different attributes with v possible values. Combining all the possible feature-value permutations, our model will be able to represent v^n different concepts which, in many cases, can result overwhelming to many traditional models.\n\nDistributed representations are idea to analyze multi-attribute datasets and understand the relevant categories or symbols that correctly represent the input.\n\nA good way to understand distributed representations is by understanding what they are not. The opposite of distributed representations is know as symbolic representations and are the foundation behind algorithms such as decision tree, clustering models or even NLP algorithms such as n-grams(see my article about NLP and n-grams). Symbolic representations typically associate an input record with a single symbol or category. While symbolic representations are an effective way to model a computational graph, they can run into issues trying to generalize knowledge in multi-attribute datasets.\n\nThe main advantage of distributed representations over symbolic models is that the former tends to generalize better in scenarios with unlabeled data. This is mostly due to the fact that distributed representations can identify shared attributes between concepts. For instance, lets\u2019 take a distributed representation algorithm that is interacting with a large dataset of pictures of animals. In that scenario, the target model can understand that different attributes such as \u201cfour_legs_,\n\n\u201chead\u201d or brain are common to cats and dogs. Among other things that capability is the underlying reason why NLP models such as NLMs that operate using distributed representations tend to outperform statiscal techniques such as n-grams."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-singularitynet-sits-at-the-intersection-of-artificial-intelligence-and-the-b4e09a5b0374?source=user_profile---------68----------------",
        "title": "Technology Fridays: SingularityNET Sits at the Intersection of Artificial Intelligence and the\u2026",
        "text": "Welcome to Technology Fridays! Today, we are going to explore one of the most exciting technologies and product visions I\u2019ve seen in recent years. SingularityNET combines two of the most innovative technology movements of our times: blockchains and artificial intelligence(AI) in a framework that can become the foundation of the next generation of AI solutions.\n\nIf you follow this blog, you know I am deeply passionate about AI and blockchain technologies so it should not come as a surprise that I am bias towards ideas such as SingularityNET that uncovers the initial potential of the intersection between the two technology ecosystems. However, looking beyond my personal favoritism, it is unquestionable that SingularityNET brings together the right vision and technological foundation to achieve one of the most important goals of the next wave of AI technologies: the democratization of IA.\n\nSingularityNET provides a decentralized network to publish and execute AI programs across different individuals and organizations. The platform leverages the economics of the blockchain to encourage AI agents to join and participate in the network in a way that benefits all participants. Also, SingularityNET attempts to provide a decentralized governance model for AI agents that resembles the foundations of a pseudo-democratic process. Speaking in more practical terms, SingularityNET provides a bridge to make AI accessible to any individual or organization even if they don\u2019t have to means to foster proprietary AI research.\n\nConceptually, SingularityNET acts as a general-purpose, decentralized marketplace that provides a portfolio of AI agents which can be used in exchange for cryptocurrencies. The platform extends AI agents with interfaces based on blockchain smart contracts that allow them to join the network and interact with third party applications or other agents. The initial version of SingularityNET smart contracts is based on Ethereum\u2019s Solidity language but other smart contract environments should be supported in the future. To execute operations, the smart contracts exchange AGI tokens as the main economic unit to pay for the services performed by an AI agent.\n\nAI programs are represented in SingularityNET using the concept of Agents. A SingularityNET Agents is an AI model written in Python or other languages which, in addition to its AI capabilities, implements a blockchain-facing API that allows it to join the network and advertise its services. When an Agent joins SingularityNET, the platform will execute a protocol that will make a copy of the underlying blockchain and deploy a smart contract that include a description of the Agent\u2019s capabilities.\n\nAgents in the SingularityNET network need to expose relevant details of their interfaces such as input-putput data formats, protocols or economic dynamics. Agents could be contacted by third parties or other agents and negotiate a price for a specific job. Once the job is agreed upon, it will be registered in the blockchain as a smart contract.\n\nThe initial implementation of SingularityNET is based on Ethereum. Agents are typically written in Python and packaged as Docker containers. The current platform provides robust support for the OpenCog framework and new deep learning frameworks and libraries is expected in the near future.\n\nMarketplaces are not new to the AI ecosystem. Technologies such as Kaggle and Algorithmia provide interesting marketplace models for AI programs. However, those technologies are completely centralized. From that perspective, SingularityNET combination of AI and blockchain technologies is very unique in the current market ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/deep-diving-into-natural-language-processing-part-ii-9f54afb18200?source=user_profile---------69----------------",
        "title": "Deep Diving Into Natural Language Processing Part II",
        "text": "This is the second part of an essay that explores the fundamental deep learning techniques in natural language processing(NLP) platforms. In the first part, we discussed the main value propositions as well as the history of NLP models. We also explored the grandfather of NLP algorithms, n-grams, which provides a statistical recursive model to determine the probability of occurrence of a series of n tokens or words based on the probability of the previous n-1 words. Today, I would like to expand our discussion onto other techniques actively used in NLP models.\n\nOne of the main challenges with n-grams models is that they are vulnerable to the curse of dimensionality(see my previous article about the curse of dimensionality). This is particularly relevant when processing grammatically and syntactically rich languages which contain multi-dimensional structures. One of the popular techniques that tries to address some of the challenges of n-grams is known as Neural Language Models(NLMs) and has been widely implemented in modern deep learning frameworks.\n\nThe curse of dimensionality is the Achilles\u2019 heel of many deep learning models like n-grams that purely rely on statistical computations which tend to underperform in scenarios with a large number of dimensions. NLMs overcome this challenge by using techniques that can recognize similarities between two worlds while still recognizing the unique characteristics of each word. From that perspective, NLMs avoid having to build knowledge subsets for each specific word in a dataset.\n\nThe magic behind NLMs is due to a technique called Distributed Representation which is a modality of Representation Learning that tries to learn individual features within a dataset by segmenting the input smaller combination of attributes. The classic example of Distributed Representation is to generate new images by composing objects identified in other images.\n\nIn the context of NLP, NLMs leverage Representation Learning to create a knowledge structure that links similar words based on their statistical strengths. For instance, let\u2019s take media articles that often use the terms \u201cartificial intelligence\u201d, \u201cdeep learning\u201d and \u201cmachine learning\u201d interchangeably. In that domain, a ELM model will map the attributes of those three terms and infer predictions of one term[ex: deep learning] based on sentences containing the other terms [artificial intelligence, machine learning].\n\nTechnically, ELM refers to the individual world representations as word embeddings. If we visualize the output of ELM models, we will see the different word embeddings in a proximity determine by the similarities of their attributes.\n\nNLMs provide many tangible advantages over n-grams and other NLP techniques but they are not without drawbacks. n-grams tend to be more efficient than NLMs achieving high model capacity because they require little computation to process an input dataset. If both NLMs and n-grams bring complementarily benefits then why not combine the two?\n\nThe idea of aggregating NLMs and n-grams has been catching up some momentum in the deep learning community. Ensemble learning techniques offer many ways in which the two algorithms can be combined to deliver highly sophisticated NLP models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/deep-diving-into-natural-language-processing-part-i-1491c23f082?source=user_profile---------70----------------",
        "title": "Deep Diving Into Natural Language Processing Part I",
        "text": "Interpreting and understanding written and spoken natural language is one of the best applications of modern deep learning models. From messaging bots to advanced digital assistants, natural language is a fundamental element of our daily interactions with artificial intelligence(AI).\n\nIn deep learning theory, the group of techniques used to interact with natural language are known as natural language processing(NLP) or natural language understanding(NLU). In some domains, AI experts like to draw a distinction between NLP and NLU with the latter having a more profound impact in contextual and semantic analysis of language expressions. However, in most scenarios, the terms NLP and NLU can be used interchangeably.\n\nThese days, there are plenty of frameworks and platforms that simplify the implementation of NLP models. From cloud AI platforms such as Watson Developer Cloud Conversation Service, Microsoft\u2019s LUIS or Google\u2019s API.ai to messaging runtimes like Facebook\u2019s Wit.ai to innovative startups like MonkeyLearn, there isn\u2019t a lack of options to build NLP applications. In addition to that, deep learning frameworks such as TensorFlow, Caffe2 or Theano provide libraries that enable the implementation of sophisticated NLP algorithms. Those deep learning frameworks are typically used in many domain-specific scenarios that require more advanced conversational capabilities or even custom NLP algorithms. For that reason, there is a tremendous value on understanding at least the fundamental deep learning techniques behind the current generation of NLP platforms.\n\nNLP algorithms typically focus on processing sequential data that represents a sentence in a natural language. From that perspective, many of the techniques such as recurrent or recursive neural networks(RNNs)(see my previous series RNNs) specialized on processing sequential vectors are relevant in the NLP universe. The history of NLP goes back to the late 1980s and early 1990s when computer scientists like Dyer and Schmidhuber started applying neural networks to understand the syntax of natural language sentences. However, is is not until a decade later with the work of deep learning pioneers like Yoshua Bengio that NLP started to gain momentum in real world applications. Most modern NLP models draw inspiration from a simple technique known as n-grams.\n\nConceptually, n-grams focus on determining the probability distribution of tokens such as words in a natural language sentence. Specifically, n-grams define the conditional probability of the occurrence of a token or word in the nth position of a sentence based on the probability of the previous n-1 words. n-grams leverage statistical techniques based on the Bayes theorem to determine the probability of a sequence of words. The Bayes based expression looks something like this:\n\nWhere P(x) expresses the probability of X and (Xt, Xt-1,\u2026,X1) is the input dataset.\n\nLet\u2019s illustrate n-grams in practice by taking the following sentence \u201cAI IS THE FUTURE\u201d. Running that sentence through a n-grams model looks something like this:\n\nP(AI IS THE FUTURE)= P3(AI IS THE)*P3(IS THE FUTURE)/P2(IS THE)\n\nWhere Pn(x) is the probability of nth order of x.\n\nn-grams has been an important step in the evolution of NLP but it also has severe limitations when applied to large natural language texts. Historically, n-grams has been very vulnerable to the curse of dimensionality.\n\nTomorrow we will cover new NLP techniques that have been created as an alternative to n-grams."
    },
    {
        "url": "https://medium.com/@jrodthoughts/more-thoughts-about-a-bitcoin-etf-c439832337?source=user_profile---------71----------------",
        "title": "More Thoughts About a Bitcoin ETF \u2013 Jesus Rodriguez \u2013",
        "text": "Exchange Traded funds(ETFs) have been an elusive goal for the Bitcoin community throughout recent years. a few months ago, the U.S. Securities and Exchange Commission denied the petition for a Bitcoin ETF requested by Cameron and Tyler Winklevos. However, with Bitcoin futures launching in the CME and Cboe, most experts thought that a Bitcoin ETF was the next logical step. However, the behavior of futures contracts have revealed some interesting behaviors that indicate that a Bitcoin ETF might take a little longer than expected.\n\nIn the past, I\u2019ve written several articles detailing some of my thoughts about Bitcoin ETFs( check out those articles). I am not planning to bore you by restating my previous ideas by I would like to reexamine the prospect of a Bitcoin ETF factoring in recent market developments mostly related to the futures contracts. Here are some of my new thoughts:\n\n1)More Products Might be Necessary\n\nThe idea that a single derivative product such as the CME-Cboe futures contracts would pave the way for a Bitcoin ETF was a valid thoughts but it might proven unrealistic. Based on the relatively small trade volumes in the CME and Cboe futures, regulators might want to see more derivative products before giving the green lights for an ETF.\n\nReading the statements made by different regulatory arms of the U.S. governments, you might be wondering if those different agencies ever talk to each others. The Commodities and Futures Trade Commission(CFTC) seem to be more open to the idea that Bitcoin and digital currencies should become a relevant asset class in the markets. The CFTC recently granted permissions to financial startup LedgerX to start trading Bitcoin options and has been working with the startup community to establish a proper regulatory framework for cryptocurrencies. In the CFTC view, crypto assets should be classified as commodities based on its limited supply.\n\nThe SEC seems to be taking a more aggressive position by labeling some digital currency products as securities and taking a tougher stand in terms of the regulatory approach. Until those two agencies reconcile their positions, a Bitcoin ETF will remain a nice idea but highly unpractical.\n\nAn interesting statistic that arises when analyzing the investor behavior in the CME and Cboe Bitcoin futures reveals that large institutional investors have been shorting the digital asset while smaller retail investors tend to be taking long positions. Recent data published by The Wall Street Journal highlights that traders holding fewer than 25 Cboe future contracts places 3.6 more bullish bets than bearish ones. Similarly, large hedge funds placed close to 40% more short bets than long ones and banks and large asset managers have remained absent from the trading of Bitcoin futures. Gaining large investors is important for the viability of a Bitcoin ETF.\n\nThe trading volume in both the CME and Cboe futures contract has been relatively modest and it hasn\u2019t provided strong liquidity. The value of the combined outstanding futures contracts between the two exchanges has been trending around $150 million which is a very small number compared to the valuation of the asset. Also, the number of trades has decreased following the excitement of the initial days. Getting traders excited about Bitcoin derivatives and providing active liquidity is a key element to materialize a Bitcoin ETF.\n\n5)Will We See a Bitcoin ETF in 2018?\n\nMy guess is still yes but its going to require some work. Maybe the initial version of ETFs won\u2019t be based on derivatives like the futures contracts. The world of ETFs grown tremendously in 2017 and we have ETFs for almost anything you can think of. So why not Bitcoin?"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-azure-enterprise-smart-contracts-makes-enterprise-baas-a-reality-1fb54900cf05?source=user_profile---------72----------------",
        "title": "Technology Fridays: Azure enterprise Smart Contracts Makes Enterprise BaaS a Reality",
        "text": "Welcome to Technology Fridays! In recent months, I\u2019ve written several articles about Azure Enterprise Smart Contracts and its relevance in the blockchain as a service(BaaS) space. While my previous posts were mostly focused on the market perspective of Microsoft\u2019s Enterprise Smart Contracts platform, today I would like to approach the subject from a technology perspective.\n\nAzure Enterprise Smart Contracts is the evolution of Microsoft\u2019s Project Bletchley, the first enterprise blockchain technology released by the Redmond giant. Bletchley was Microsoft\u2019s initial building block towards its vision of an enterprise BaaS platform powered by the Azure cloud . The initial release of Project Bletchley made important contributions in areas such as off-chain integration but it also discovered many of the missing elements of enterprise blockchain applications. The lessons learned with Bletchley morphed into a more complete platform that enable end-to-end capabilities in blockchain solutions.\n\nThe initial goal of Azure Enterprise Smart Contracts is to extend the vision behind traditional smart contracts with enterprise ready capabilities. Specifically, the platform focused on areas such as business logic implementation, integration with off-chain systems, cross blockchain transaction coordination or data privacy which are essential to enterprise blockchain applications.\n\nConceptually, the magic behind Azure Enterprise Smart Contracts is based on a separation of concerns approach that modularizes elements such as data, logic or external dependencies from core of the public smart contract protocol. That level of isolation/modularization enabled the implementation of specialized enterprise capabilities that can be used in blockchain applications.\n\nThe data elements used in Enterprise Smart Contracts are abstracted using the concept of a Schema. The same component is typically used to encode the cryptographic proofs needed to ensure the integrity of transactions in the platform. Schemas also include business logic blocks relevant to the fulfillment of a transaction.\n\nAzure Enterprise Smart Contracts coordinates transaction across different participants that can be anything from an individual to a company. Counterparties abstract different participants in smart contract transaction. Examples of counterparties include people, companies or even devices that act as originators or recipients of blockchain transactions. The Azure Enterprise Contracts platform includes other types of participants known as Observers that represent roles such as auditors or regulators that can inspect transaction data.\n\nExternal Sources represent data or business logic triggers that are part of a smart contract. This component extends the notion of Oracles in platforms such as Ethereum as a way to interact with off-chain data or systems. Initially, Azure Enterprise Smart Contracts includes External Sources for many Azure services which enables the implementation of highly sophisticated applications.\n\nOnce we have developed all the independent components of a contract, they can be assembled together using the notion of Contract Bindings. This component effectively creates an instance of an enterprise smart contract that can be used by different parties in a transaction.\n\nSecurity is one of the areas in which Azure Enterprise Smart Contracts really excels. The platform introduces cutting-edge security techniques such as zero-knowledge-proof or homomorphic encryption as first class citizens in blockchain transactions. Additionally, the platform integrates with different Azure security services such as Active Directory or Key Vault that have been widely adopted in the enterprise.\n\nEven though Azure Enterprise Smart Contracts is a blockchain agnostic platform, its main competition comes from blockchain runtimes that have specialized in enterprise environments. IBM\u2019s Hyperledger Fabric can be considered the market leader is such a term applies to the young enterprise blockchain market. Other blockchain runtimes such as R3 Corda , Chain or Intel\u2019s Sawtooth have been able to establish relevant presence in the enterprise and can be seen as competitors of Azure Enterprise Smart Contracts."
    },
    {
        "url": "https://medium.com/@jrodthoughts/recurrent-and-recursive-networks-in-deep-learning-systems-part-ii-bidirectional-and-deep-rnns-686590d51861?source=user_profile---------73----------------",
        "title": "Recurrent and Recursive Networks in Deep Learning Systems Part II: Bidirectional and Deep RNNs",
        "text": "This is the second part of an essay that explores recurrent and recursive neural networks(RNNs) in deep learning models. In the first part, we introduced recurrent neural networks as an architecture to process sequential data in a similar way as convolutional neural networks(CNNs) are used to handle multi-dimensional data structures. Today, I would like to discuss some variations of recurrent networks that have become really popular in real world deep learning systems.\n\nIn the last few years, recurrent neural networks have become one of the main architectures in deep learning models. However, despite its popularity, pure recurrent networks often result limited in order to address many real world deep learning scenarios. The lack of recursive connections or backward feedback loops regularly challenge recurrent neural networks implementations. To address those challenges, researchers have created variations of recurrent neural networks that have been widely implemented in popular open source deep learning frameworks. Among those, bidirectional and deep RNNs are often used in more sophisticated scenarios that deal with sequential data.\n\nThe use case for bidirectional recurrent neural networks is centered on scenarios in which the state of a node is affected by the state of nodes executed at a future time. The traditional RNN architecture is based on a very simple computation graph in which the state of the network at any given time is based solely on information about the past. Now let\u2019s take a simple speech recognition scenario in which the final analysis of an audio stream at any given time depends on the interpretation of a future segment of the audio stream. Suppose that a digital assistant inquires about your latest experience at the movies by asking you \u201chow was the movie?\u201d to what you answer \u201cWell\u2026\u201d indicating a level of uncertainty. However, the final analysis will depend on your next statement.\n\nBidirectional RNNs address the future-dependency limitations of traditional recurrent networks by combining two RNNs in the same model. The first RNN moves forward through time from the beginning of the network while the second RNN moves backward starting at the end of a specific sequence. This simple adaptation of traditional RNNs allow any hidden unit to compute knowledge that depends both on the past and the future relative to a specific time window.\n\nTraditional RNNs are represented using a very basic computation graph that connects the input unit to a sequence hidden units and the final hidden unit to the output unit. In that model, the computations performed by any of the hidden units have to be based on atomic transformations which often result insufficient to build more sophisticated data manipulation routines. Deep recurrent networks address that challenge by decomposing the state of a unit into a multi-layer network capable of performing arbitrarily complex operations.\n\nThe addition of depth to specific units directly expands the richness of its knowledge representation. However, is not as trivial as it sounds. Deep recurrent networks can have a negative impact by hurting the learning performance or making optimization more difficult.\n\nBidirectional and deep recurrent networks are two of the most popular forms of RNNs that you will find in deep learning stacks. In the next part of this article we will cover recursive neural networks as another technique to consider when processing sequential datasets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-bitcoin-as-a-commodity-662e56dc2819?source=user_profile---------74----------------",
        "title": "Some Thoughts About Bitcoin as a Commodity \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, the top U.S. derivatives regulator announced that is starting to work in new measures to address concerns about digital currencies and related products like the futures contracts. The Commodity Futures Trading Commission(CFTC) will host a meeting of one of its advisory committees at the end of this month to outline a regulatory strategy for Bitcoin and other crypto-assets.\n\nThe potential regulations are likely to be equivalent to the ones imposed on other market commodities. This is mostly due to the fact that the CFTC has long seen Bitcoin as a commodity which was the main factor that opened the door to the future contracts now trading in the CME and Cboe exchanges.\n\nThe view of Bitcoin as a commodity is certainly debatable. For years, financial gurus, blockchain technologists and regulatory agencies have struggled to classify Bitcoin within the existing ecosystem of financial products. The U.S. Securities and Exchange Commission(SEC) has labeled certain digital tokens as securities while the CFTC sees first-tier cryptocoin protocols as commodities. The struggle is partially a consequence of the unique characteristics of Bitcoin and other cryptocurrencies which are different from anything financial markets have seen so far.\n\nThe efforts for fitting Bitcoin into an existing financial asset class have been mostly a channel to establish the right regulatory framework and less about truly understanding the role of the cryptocoin in financial markets. Initially, the market rushed to categorize Bitcoin as a currency because it can be used in financial transactions. However, the comparison between ends there as Bitcoin has very little in common with fiat currencies. The behavior of the two asset classes are so far apart that Bitcoin has become a vehicle to hedge against weakness in currency markets in a manner similar to gold.\n\nBitcoin has also been labeled as a security but the similarities with this asset class are few and far between. Finally, entities such as the CFTC seen Bitcoin as a commodity mostly due to the finite number of Bitcoin that will ever be available in the network. Within this group there are experts that see Bitcoin as an asset value holder that can be an alternative to the way and other precious metals are used.\n\nAs the relationship between Bitcoin and financial markets evolves, I believe we will arrive to a consensus that Bitcoin is neither a currency nor a security or a commodity but rather a new class of asset. Bitcoin combines characteristics of traditional financial assets with features that are very particular to digital assets produced in blockchain networks. If Bitcoin is a new asset class, then we will lined a regulatory framework tailored to its unique characteristics.\n\nBitcoin as a Commodity and the Importance of Production Costs\n\nThe segment of the market that sees Bitcoin as a commodity typically believes that the cryptocoin is severely overpriced compared to its production costs. One of the axiomatic rules of commodity pricing states that, over a long period of time, assets tend to trade at prices relatively close and predictably correlated to their production costs. For instance, gold future contracts are pricing the precious metal a little above $13,000.00 a troy ounce while its cost of production is about $600; not a massive difference. In the case of Bitcoin, the cryptocoin traded last night for about $15,3000.00 while the cost of production is about $3200.00 depending on the region; that\u2019s a 5x ratio. Commodity trading wisdom suggests that Bitcoin prices will gravitate towards the production cost if demand dries up. Obviously, that scenario seems highly unlikely but is another one of the examples that challenge the classification of Bitcoin as a commodity."
    },
    {
        "url": "https://medium.com/@jrodthoughts/recurrent-and-recursive-networks-in-deep-learning-systems-4ec557a9be1d?source=user_profile---------75----------------",
        "title": "Recurrent and Recursive Networks in Deep Learning Systems",
        "text": "Deep learning is a very broad discipline that has been regularly expanding its areas of research. as a result, the number and variety of deep learning models has drastically grown during the last few years. Different types of deep neural networks have specialized on solving specific types of problems and processing specific types of data. For instance, convolutional neural networks(CNNs) are mostly used to process multi-dimensional datasets such as images. Another type of architecture that has become very popular in deep learning systems is recurrent and recursive networks(RNNs) which have been widely implemented on many of the popular deep learning frameworks in the market.\n\nJust like CNNs specialized on processing multi-dimensional data, the focus on RNNs is to handle sequential datasets. A sequential dataset is typically represented by a vector(x(1), x(2),\u2026.x(t)) where the data represents individual input records typically distributed across a time sequence t.\n\nThe origins of RNNs date back to the mid 1980s when computer scientists such as Rumelhat started using new ideas in statistical models such as parameter sharing to be able to generalize knowledge on a sequence of values. The use of parameter sharing resulted pivotal for the creation of RNNs as it made it possible to apply machine learning models to sequential datasets of different lengths and generalize knowledge from them while maintaining the performance of the computation graph.\n\nTo illustrate the use of parameter sharing, let\u2019s take an example from the natural language processing(NLP) space. Imagine that we are having a conversation about the NFL playoffs that just started this weekend and we say something around the lines of \u201cthe Saints beat the Panthers last night\u201d or \u201clast night, the Saints beat the Panthers\u201d. If we have a machine learning model that is trying to identify the objects in the sentence, we would like it to recognize the \u201cSaints\u201d and \u201cthe Panthers\u201d regardless of the order in which they appear in each sentence. A traditional fully connected feed forward network will use different parameters for each input which means that it will assign different weights for the different sentences resulting on a computational inefficient graph. Parameter sharing addresses that challenge by sharing weights across different time steps allowing the model to scale across inputs of different lengths.\n\nYou can visualize RNNs as a sequential computation graph composed of inputs, hidden units, loss functions and output units. In mathematical terms, an RNN can be expressed using variations of the following equation:\n\nwhere h are the hidden units, x represent the inputs, p are the parameters and t represent time units.\n\nThe equation is a fancy way to express that an RNN is trained to predict the future based on the immediate past. From that perspective, the can infer that RNN models tend to have the same input size regardless of the sequence length. This is due to the fact that the model is expressed in terms of transitions between states instead of variable lengths. Similarly, RNNs enable the reuse of the same transition function with the same parameters at every time step(parameter sharing). That characteristic allows RNNs to be very efficient generalizing knowledge even when data is missing from the training dataset.\n\nLater this week, we will continue the discussions about RNNs and its close cousin: recursive networks."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-signifai-enables-machine-intelligence-for-devops-b2cd0c4f9745?source=user_profile---------76----------------",
        "title": "Technology Fridays: SignifAI Enables Machine Intelligence for DevOps",
        "text": "Welcome to Technology Fridays in 2018! Last year, we started this section to explore the products and platforms that are innovating in technology markets but that are, somehow, still flying under the radar. Today, we are going to cover SignifAI, a platform that is leveraging machine learning to improve TechOps solutions.\n\nSignifAI represents the next evolution of the application performance monitoring(APM) and DevOps tools spaces. Both markets have seen tremendous levels of innovation in recent years with platforms such as NewRelic and AppDynamics leading the charge in the APM space and technologies like Chef or Puppet redefining the DevOps ecosystem. While those platforms have drastically improved the capturing and visualization of IT data, they are still missing the foundation to translate the data into relevant knowledge. That its where SignifAI comes in. The platform provides a layer of machine intelligence(MI) that brings it closer to the way human experts troubleshoot and manage IT operations.\n\nConceptually, SignifAI brands itself as a TechOps as a service but its much more than that. The platform literally expands traditional APM and DevOps solutions with machine intelligence models that enable the rapid diagnosis and resolution of software and infrastructure errors. SignifAI accomplishes that by combining two main capabilities: sophisticated data capture and fast root cause analysis.\n\nData collection is enabled in the SignifAI platform via Sensors which integrate with different types of software and infrastructure platforms. Active Inspectors are a type of Sensor that collects information by integrating with products through their specific APIs. For instance, the AWS Active Inspector provides data collection and analysis across different AWS services such as Lambda, RedShift, SQS, DynamoDB, ElasticCache and many others. Additionally, the AWS Active Inspector is able to receive events from AWS CloudWatch monitoring service which allow organization to implement SignifAI without altering their AWS architecture. In addition to AWS, SignifAI provides Active Inspectors for platforms such as DataDog, Grafana, Akamai among many others.\n\nThe other type of Sensor provided by SignifAI is known as Web Collectors which enable the integration with applications via webhooks. The list of Web Collectors include well known APM platforms such as AppDynamics, NewRelic or Splunk.\n\nThe SignifAI Control Center is the main user interface to interact with the data produced by the platform. The Control Center prioritizes the issues and alerts generated by the platform based on the specific customer needs. That level of prioritization is possible because of the Site Reliability Engineer Augmented Member or SAM which is an MI agent completely tailored to a tenant\u2019s environment. SAM uses machine learning algorithms to understand the characteristics of an environment and provide personalized answers to specific issues. SAM\u2019s intelligence improves as more data and activity gets into the platform which makes it almost as an intelligence digital assistant extension to your TechOps team.\n\nI tend to see SignifAI as the next evolution of APM platform. As a result, SignifAI is likely to experience competition from APM platforms such as NewRelic or AppDyanmics that are venturing into the MI space. Additionally, the APM services or platforms such as AWS or Azure can also be seen as a relevant competitor of SignifAI."
    },
    {
        "url": "https://medium.com/@jrodthoughts/dynamic-structure-in-deep-learning-systems-ffdd5efb4a7c?source=user_profile---------77----------------",
        "title": "Dynamic Structure in Deep Learning Systems \u2013 Jesus Rodriguez \u2013",
        "text": "The process of building deep learning systems in the real world is full of theoretical and practical challenges. On the theoretical front, data scientists are constantly obsessed about selecting the right model for a specific scenario as well as the correct regularization and optimization techniques. In more practical terms, deep learning applications need to run and scale on the right infrastructure and be able to sustain its performance as it grows.\n\nThere are many techniques that can be applied in order to architect deep learning systems that can grow sustainably. Among those, dynamic structures have become particularly popular in the deep learning community.\n\nThe concepts behind dynamic structure models might seem trivial but they are really difficult to implement in deep neural networks. Essentially, dynamic structure models are able to execute sub-networks of a model based on the input dataset/ Many deep learning experts also refer to dynamic structure using the term conditional computation which better highlights the nature of the technique.\n\nDeep learning architectures based on dynamic structure are particularly popular in ensemble learning systems that include various networks in the same model(see my previous articles about ensemble learning). Because dynamic structure architectures can predictably execute subsets of the network based on the input, they are relatively easier to scale as the size of the model grows. Specific implementation of dynamic structure have evolved across different areas of deep learning. An analogy to help you think about dynamic structure is think of an student taking different subjects in a semester. Depending on the specific class that the student is planning to attend, he or she will brush up on recent lessons and try to focus the attention on that specific topic. Dynamic structure tries to accomplish something similar for large deep learning models.\n\nWith the rapid rapid in popularity of deep learning architectures, several dynamic structure methods such as cascade classifiers or expert networks have become increasingly popular among deep learning practitioners.\n\nThe cascade of classifiers strategy is typically applied to scenarios in which we need to detect complex patterns in a dataset such as strange objects in a an image. One obvious way to solve that problem is to implement a highly sophisticated classifier which is typically very expensive to run. Alternatively, a model can run a sequence of inexpensive classifiers that can asset that an image does no contain the rare object. The sequence of classifiers can be orchestrated in a way that the most basic classifiers run first while the ones with higher precision are executed at the end which improves the costs even more.\n\nAnother popular dynamic structure method is known as mixture of experts and uses a neural network called the gater to determine what expert network to use based on the characteristics o the input. The selection of the expert network is based on probabilistic models that assign weights to every network. In the case that the model has a large number of expert networks, there are variations of the mixture of experts that use combinatorial gaters that are able to use a more complex selection criteria."
    },
    {
        "url": "https://medium.com/@jrodthoughts/crypto-psychology-irrational-behaviors-in-digital-currency-markets-part-ii-d8e8c5604a2?source=user_profile---------78----------------",
        "title": "Crypto-Psychology: Irrational Behaviors in Digital Currency Markets Part II",
        "text": "This is the second part of an article that explores some of the patterns of irrationality that are starting to emerge in the cryptocoin space. In the first part, we presented two competing theses that attempt to explain the behavior of public markets. The efficient market hypothesis(EMH) pioneered by Eugene Fama states that market tend to push the price of any security towards its intrinsic value. Another school of thought has its roots in the cognitive psychology field with the work of Daniel Kanehman and Amos Tversky as well as economists like Richard Thaler and states that market participants exhibit irrational behaviors when making decisions. The irrational market hypothesis(IMH) has become extremly popular in financial markets and can certainly be used as a reference point to explain the irrationality of digital currency markets. In order to understand IMH in the context of cryptocurrencies, let\u2019s explore five common patterns that we are seeing in the current market.\n\n5 Patterns of Irrationality in the CryptoCoin Space\n\nThe irrational behavior of digital currencies is one of the aspects that makes institutional investors skeptic about the space. Like in any other financial markets, IMH details different patterns of irrationality that explains behaviors that puzzle many experts in the cryptocoin space.\n\nThis behavior explains how, many times, we maintain beliefs even if they don\u2019t match the evidence. For instance, during last week, many people posted interesting articles explaining the recent drop and desaceleration in the price of Bitcoin. The explanations ranged from a sellout due to the holidays to the impact of the recently implemented futures contracts. Despite the intriguing arguments, most of the explanations were entirely subjective and lack analytic rigor.\n\nImagining correlations or patterns in datasets where they simply don\u2019t exists is another key bias in human reasoning. In recent weeks, several small-cap companies have rebranded their message to indicate that they are getting into the Bitcoin mining business in order to drive the price of their stocks. My favorite example in the Long Island Ice Tea Company that, after including the word blockchain as part of its new name saw its stock raise a large multiple.\n\nMore often than not, traders follow the opinions of others even if it clearly contradicts the evidence. Nothing moves the price of Bitcoin and digital currencies like news. Just yesterday, the announcement that Peter Thiel has been buying Bitcoin for years was enough to move the price of the cryptocurrency to the $15,000.00 level.\n\nThis behavioral pattern explains how often we prefer to hold onto things rather than switching to a better alternative. Last year, Ether,LiteCoin and Ripple(XRP were far better trades than Bitcoin in terms of profitability. However, retail investors kept rushing into Bitcoin or holding onto their positions mostly influenced by the press coverage received by the cryptocoin.\n\nThe immediacy effect bias explains, how we are willing to pay more for an item when it causes a visual impact. One of my favorite examples of this behavior is the recent increase in the buy activity in Ripple(XRP) and LiteCoin in the last two weeks of the year. A large percentage of the buyers were people that originally signed up to exchanges like Coinbase with the idea of buying Bitcoin given its rapid raise towards $20,000.00. However, after seeing the high price of Bitcoin and without knowing that you could buy just fractions of a Bitcoin they went for cryptocurrencies like Litecoin or XRP that looked cheaper even if the Bitcoin trade was better during those two weeks."
    },
    {
        "url": "https://medium.com/@jrodthoughts/crypto-psychology-irrational-behavior-in-digital-currency-markets-part-i-3e021c4ef611?source=user_profile---------79----------------",
        "title": "Crypto Psychology: Irrational Behavior in Digital Currency Markets Part I",
        "text": "Happy 2018 readers! I hope this ne year brings you lots of blessings and happiness for you and your family. I would like to start the year by discussing some of the patterns that can be spot in digital currency markets that explain many of the irrational behaviors in the space. Those patterns have been well established in the field of behavioral economics but they still result fascinating when perceived through the lenses of the cryptocoin markets.\n\nIn financial markets, there are two main theories that have become the favorites of economists in order to explain the often puzzling behavior of financial markets. The first of those theories dates back to 1970 and a young economist named Eugene Fama. In his doctoral thesis, Fama defined the idea of an \u201cefficient market\u201d as a place in which \u201c competition among the many intelligent participants leads to a situation where, at any point in time, actual prices of individual securities already reflect the effects of information based both on events that have already occurred and on events which as of now the market expects to take place in the future. In other words, in an efficient market at any point in time the actual price of a security will be a good estimate of its intrinsic value\u201d.\n\nFama\u2019s efficient market hypothesis(EMH) has triggered nearly 50 years of controversy as well as important contributions to portfolio theory such as the Black-Scholes-Merton formula which became the north star of financial markets for years and resulted on a Nobel prize for Scholes and Merton(Black died before the prize was awarded). Most notably, Fama\u2019s theory led to the creation of EMH- purist funds such as the infamous Long Term Capital Management(LTCM) which included Scholes and Merton on its staff and went on to post impressive profits for a couples of years before its dramatic collapse in 1998. In essence, EMH predicts that markets are unpredictable as any information is already known finds an organic way to be priced into a security.\n\nA challenging hypothesis to Fama\u2019s EMH proposes the idea that market participants will act irrationally despite the information they have access to. The idea of irrational markets has its rooms on the work of psychologists Daniel Kahnenman and Amos Tversky which created the roots of the field of behavioral economics. Kahneman and Tversky work eventually expanded into economics guided by brilliant minds such as Richard Thaler which was awarded the 2017 Nobel prize in economics. The irrational market hypothesis(IMH) states that market participants make decisions based on reasons that have little to do with statistics and more related to emotions. In other words, market participants tend to behave irrationally.\n\nThe classic example of IMH is the fear-of-missing-out(FOMO) behavior that rush investors into or out of a security together greatly amplifying its risk. As James Buchan cleverly put in his book Frozen Desire, investors buy or sell a security based on the hope, not the knowledge, that it will go up or down.\n\nMost people agree that digital currency markets behave quite irrationally but what are the specific behaviors that exemplified that irrationality? That will be the subject of tomorrow\u2019s post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/practical-deep-learning-selecting-the-right-model-and-gathering-training-data-part-ii-378eb5c793fb?source=user_profile---------80----------------",
        "title": "Practical Deep Learning: Selecting the Right Model and Gathering Training Data Part II",
        "text": "This is the second part of an essay that explains some of the practical tips in deep learning applications. Specifically, we are focusing on the selection of learning models and the correct structuring of training datasets. In the first part, we explored some of the basic methodology fro selecting baseline models in deep learning scenarios. Today, we are going to provide some guidance in regards to one of the most difficult challenges facing deep learning practitioners: how to determine if the right size of the training dataset?\n\nStructuring a proper training dataset is an essential aspect of effective deep learning models but one that is particularly hard to solve. Part of the challenge comes from the intrinsic relationship between a model and the corresponding training dataset. If the performance of a model is below expectations, it is often hard to determine whether the causes are related to the model itself or to the composition of the training dataset. While there is no magic formula for creating the perfect training dataset, there are some patterns that can help.\n\nWhen confronted with a deep learning model with poor performance, data scientists should determine if the optimization efforts should focus on the model itself or on the training data. In most real world scenarios, optimizing a model is exponentially cheaper than gathering additional clean data and retraining the algorithms. From that perspective, data scientists should make sure that the model has been properly optimized and regularized before considering collecting additional data.\n\nTypically, the first rule to consider when a deep learning algorithm is underperforming is to evaluate whether its using the entire training dataset. Very often data scientists will be shocked to find out that models that are not working correctly are only using a fraction of the training data. At that point, a logical thing to consider is to increase the capacity of the model( the number of potential hypothesis it can formulate) by adding extra layers and additional hidden units per layer. Another ideas to explore in that scenario is to optimize the model\u2019s hyperparameters( read my article about hyperparamenters). If none of those ideas work, then it might be time to consider gathering more training data.\n\nThe process of enriching a training dataset can be cost prohibited in many scenarios. To mitigate that, data scientists should implement a data wrangling pipeline that is constantly labeling new records. semi-supervised learning strategies might also help to incorporate unlabeled records as part of the training dataset.\n\nThe imperative question in scenarios that require extra training data always is: how much data? Assuming that the composition of the training dataset doesn\u2019t drastically vary with new records, we can estimate the appropriate size of the new training dataset by monitoring its correlation with the generalization error. A basic principle to follow in that situation is to increase the training dataset at a logarithmic scale by, for example, doubling the number of instances each time. In some cases, we can improve the training dataset by simply creating variations using noise generation models or regularization techniques such as Bagging(read my recent article about Bagging)."
    },
    {
        "url": "https://medium.com/@jrodthoughts/practical-deep-learning-selecting-the-right-model-and-gathering-training-data-part-i-6d487fd783eb?source=user_profile---------81----------------",
        "title": "Practical Deep Learning: Selecting the Right Model and Gathering Training Data Part I",
        "text": "Building deep learning applications in the real world is a never-ending process of selecting and refining the right elements of a specific solution. Among those elements, the selection of the correct model and the right structure of the training dataset are, arguably, the two most important decisions that data scientists need to make when architecting deep learning solutions. How to decide what deep learning model to use for a specific problem? How do we know whether we are using the correct training dataset or we should gather more data? Those questions are the common denominator across all stages of the lifecycle of a deep learning application. Even though there is no magic answer to those questions, there are several ideas that could guide your decision making process. Let\u2019s start with the selection of the correct deep learning model.\n\nThe first thing to figure out when exploring an artificial intelligence(AI) problem is to determine whether its a deep learning problem or not. Many AI scenarios are perfectly addressable using basic machine learning algorithms. However, if the problem falls into the category of \u201cAI-Complete\u201d scenarios such as vision analysis, speech translation, natural language process or others of similar nature, then we need to start thinking about how to select the right deep learning model.\n\nIdentifying the correct baseline model for a deep learning problem is a complex task that can be segmented into two main parts:\n\nII)Select the optimization algorithm that complements the algorithm selected on step 1.\n\nMost deep learning algorithms are correlated to the structure of the training dataset. Again, there is no silver bullet for selecting the right algorithm for a deep learning problem but, some of the following design guidelines should help in the decision:\n\na) If the input dataset is based on images or similar topological structures, then the problem can be tackled using convolutional neural networks(CNNs)(see my previous articles about CNNs).\n\nb)If the input is a fixed-size vector, we should be thinking of using a feed-forward network with inter layer connectivity.\n\nc) If the input is sequential in nature, then we have a problem better suited for recurrent or recursive neural networks.\n\nThose principles are mostly applicable to supervised deep learning algorithms. However, there are plenty of deep learning scenarios that can benefit from unsupervised deep learning models. In scenarios such as natural language processing or image analysis, using unsupervised learning models can be a useful technique to determine relevant characteristics of the input dataset and structure it accordingly.\n\nIn terms of the optimization algorithm, you can rarely go wrong using stochastic gradient descent(SGD)(read my previous article about SGD). Variations of SGD such as the ones using momentum or learning decay models are very popular in the deep learning space. Adam is, arguably, the most popular alternative to SGD algorithms especially when combined with CNNs.\n\nNow we have an idea of how to select the right deep learning algorithm for a specific scenario. The next step is to validate the correct structure of the training dataset. We will discuss that in the next part of this article."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-challenges-of-optimizing-deep-learning-models-1c4562aab312?source=user_profile---------82----------------",
        "title": "The Challenges of Optimizing Deep Learning Models \u2013 Jesus Rodriguez \u2013",
        "text": "Optimization is one of the broadest areas of research in the deep learning space. In previous articles, I explained the differences between optimization and regularization as two of the fundamental techniques used to improve deep learning models. There are several types of optimization in deep learning algorithms but the most interesting ones are focused on reducing the value of cost functions.\n\nWhen we say that optimization is one of the key areas of deep learning we are not exaggerating. In real world deep learning implementations, data scientists often spend more time refining and optimizing models than building new ones. What makes deep learning optimization such a difficult endeavor. To answer that, we need to understand some of the principles behind this new type of optimization n.\n\nSome Basics of Optimization in Deep Learning Models\n\nThe core of deep learning optimization relies on trying to minimize the cost function of a model without affecting its training performance. That type of optimization problem contrasts with the general optimization problem in which the objective is to simply minimize a specific indicator without being constrained by the performance of other elements( ex:training).\n\nMost optimization algorithms in deep learning are based on gradient estimations (see my previous article about gradient based optimization). In that context, optimization algorithms try to reduce the gradient of specific cost functions evaluated against the training dataset. There are different categories of optimization algorithms depending on the way they interact with the training dataset. For instance, algorithms that use the entire training set at once are called deterministic. Other techniques that use one training example at a time has come to be known as online algorithms. Similarly, algorithms that use more than one but less than the entire training dataset during the optimization process are known as minibatch stochastic or simply stochastic. The most famous method of stochastic optimization which is also the most common algorithm in deep learning solution is known as stochastic gradient descent(SGD)(read my previous article about SGD).\n\nRegardless of the type of optimization algorithm used, the process of optimizing a deep learning model is a careful path full of challenges.\n\nThere are plenty of challenges in deep learning optimization but most of them are related to the nature of the gradient of the model. Below, I\u2019ve listed some of the most common challenges in deep learning optimization that you are likely to run into:\n\na)Local Minima: The grandfather of all optimization problems, local minima is a permanent challenge in the optimization of any deep learning algorithm. The local minima problem arises when the gradient encounters many local minimums that are different and not correlated to a global minimum for the cost function.\n\nb)Flat Regions: In deep learning optimization models, flat regions are common areas that represent both a local minimum for a sub-region and a local maximum for another. That duality often causes the gradient to get stuck.\n\nc)Inexact Gradients: There are many deep learning models in which the cost function is intractable which forces an inexact estimation of the gradient. In these cases, the inexact gradients introduces a second layer of uncertainty in the model.\n\nd)Local vs. Global Structures: Another very common challenge in the optimization of deep leavening models is that local regions of the cost function don\u2019t correspond with its global structure producing a misleading gradient."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-neptune-finally-brings-graph-databases-to-aws-e557b8d514a6?source=user_profile---------83----------------",
        "title": "Technology Fridays: Neptune Finally Brings Graph Databases to AWS",
        "text": "Welcome to Technology Fridays! Continuing with the exciting new technologies AWS unveiled during the recent Reinvent conferences, today I would like to discuss my impressions of the Neptune graph database service.\n\nNeptune is the latest addition to AWS\u2019 database storage services portfolio and one that fills a well known gap on the stack. Graph databases have been a constant request from the AWS developer community as the demand for those capabilities have increased in modern architectures such as internet of things(IOT) backend or artificial intelligence(AI) models. The release of Neptune brings native graph storage capabilities to the AWS stack complementing an already impressive portfolio.\n\nAWS Neptune is a fully managed graph database service that enables the storing and querying of hierarchical data structures. Like other cloud storage services, Neptune is available across different geographic zones in the AWS platform.\n\nIf you follow the graph database space you know that it is inundated with standards and APIs to model and query data to a point that it is incredibly difficult for developers to figure out which approach to use. Neptune provides a clever solution to this challenge by supporting various query languages such as Apache TinkerPop Gremlin or W3C\u2019s SPARKQL using a consistent infrastructure. Developers using Neptune can model datasets using the Property Graph(PG) standard which can be navigates using Gremlin or the Resource description framework which can be queried using the SPARKQL language.\n\nPerformance is one of the areas n which Neptune really impresses. The platform is able to execute queries across billions of connected nodes in a graph. At scale, Neptune instances are able to execute more than 100,000 queries per second which is fairly remarkable compared to its competitors.\n\nNeptune was designed with scalability as a first class citizen. It is important to notice that scaling graph databases is far from trivial because of the complexities involved in partitioning connected graphs across different servers. Neptune supports up to 15 read replicas which provide a native model for scaling a graph database on-demand as well as fail over capabilities.\n\nSecurity is another core principle in the Neptune architecture. The platform enables access control capabilities using the AWS Key Management Services(KMS) as well as a data encryption model based on TLS. Additionally, Neptune instances can be isolated at the network level using AWS VPC.\n\nDevelopers can launch a Neptune instance directly from the AWS console. The interactions with the platform are abstracted via SDKs in languages such as Java, Python or the AWS CLI.\n\nAWS Neptune is entering the market of cloud graph databases. Neo4J is the undisputed leader in the space with distributions across all major cloud providers. The recently announced Azure CosmosDB also provides a graph database runtime that can be positioned as an alternative to Neptune."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-other-platform-aws-saas-ambitions-should-be-taken-seriously-ef29ef6a3838?source=user_profile---------84----------------",
        "title": "The Other Platform: AWS SaaS Ambitions Should be Taken Seriously",
        "text": "The race between Amazon, Microsoft and Google to dominate the cloud space have been the subject of many headlines in the mainstream press. In parallel, the software giants are embarked on another race that keeps flying under the radar and is centered around the dominance of the employee productivity space. While Microsoft and Google have an undisputed lead in the market with their Office 365 and G-Suite platforms respectively, Amazon\u2019s recent moves should be taken as an important sign of its ambitions in the space.\n\nDespite Microsoft\u2019s Azure impressive growth and Google Cloud\u2019s aggressive push into artificial intelligence(AI), AWS has managed to maintain a significant lead in the cloud market. From my perspective, there are two main factors that can threaten AWS\u2019 cloud market dominance. A first and somewhat obvious oine is to not fall behind its competitors in emerging technology areas such as AI or quantum computing. The other, and more subtle, challenge is to not achieve relevance in the employee productivity space.\n\nThe reasoning behind my statement is very simple: employee productivity SaaS offerings such as Office365 and G-Suite are indirect drivers for the adoption of cloud platforms like Azure or Google Cloud respectively. Those revenue numbers are not small by any measure amounting to billions per year in the case of Microsoft. Additionally, employee productivity SaaS stacks provide an entry point at the departmental or line-of-business level which has resulted traditionally challenging for the cloud platform incumbents.\n\nWhat is AWS Doing About it?\n\nRecognizing the importance of the employee productivity SaaS space, AWS has been aggressively building up a suite that can be competitive with Office365 and G-Suite. AWS\u2019 fast growing SaaS portfolio includes the following components:\n\n1)WorkMail: A service that provides email and calendar capabilities at a global scale.\n\n3)WorkSpaces: A service that enables desktop virtualization via the cloud.\n\n6)SSO: The newest addition to the stack, AWS SSO enables single-sign-on capabilities across different SaaS applications and cloud services.\n\nAs you can see, AWS\u2019s SaaS suite is starting to look like a relevant option for organizations looking to enable employees productivity capabilities via the cloud. Not surprisingly, all AWS\u2019 SaaS products provide deep integration with other AWS cloud services which enables the implementation of highly sophisticated employee productivity solutions. Maybe the most impressive factor of all is the fact that AWS has been able to assemble those capabilities in less than two years.\n\nI believe M&A is going to be a key factor in AWS\u2019s path to disrupt Microsoft\u2019s and Google\u2019s leadership position in the employee productivity SaaS space. the acquisition of productivity startups with established customer bases such as Slack or Dropbox or even not-so-well-known startups like SmartSheets that provide complementary capabilities could help AWS to bridge the gap with the market leaders. Now, if we are thinking to go all in, a company like Atlassian can immediately propel AWS to a leadership position in the productivity SaaS market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bagging-and-dropout-learning-ae484023b0da?source=user_profile---------85----------------",
        "title": "Bagging and Dropout Learning \u2013 Jesus Rodriguez \u2013",
        "text": "A few months ago, I wrote about ensemble learning as one of the most practical techniques used in real world deep learning applications. Conceptually, ensemble learning combines multiple models in a single meta-model in order to minimize the generalization error. As you might imagine, there are many ways to efficiently construct ensemble models. Among those, Bagging and Dropout have become increasingly popular in the latest generation of deep learning technologies.\n\nThe foundations behind ensemble learning goes back to the core of how humans make decisions. Research in decision theory shows that large and heterogeneous groups of people can arrive to better decisions that top experts on a specific subject. In machine learning theory, it is a well-known fact that most models underperform when exposed to datasets that deviate from the training data. This is commonly known as the no free lunch theorem. From that perspective, combining different models on an ensemble is an efficient way to expand the capacity of a model and reduce its generalization error. That\u2019s the textbook definition of a regularization method.\n\nMost everyone agrees on the value of ensemble learning. In recent years, the emergence of deep learning has produced a large number of techniques for constructing ensemble learning models and is becoming increasingly difficult to differentiate between them. Bagging and Dropout are two ensemble methods that have been widely implemented in deep learning frameworks and have been regularly used in modern applications.\n\nOne of the drawbacks of ensemble learning is that different models in the ensemble can have different training algorithms and objective functions which can make it computationally expensive to execute at scale. Bagging is an ensemble learning technique that enables the reusability of models, training algorithms and objective functions in a meta-model.\n\nThe essence of Bagging is to train a deep learning model using variations of the training dataset. Each variation is built by sampling subsets of the original training dataset and replacing some of the missing entries with duplicates from the original selection. That translates into a collection of datasets that are based on entries from the training data replicated multiple times. Let\u2019s use an example and assume that our original dataset is the vector [1,2,3,4,5]. A Bagging technique will produce datasets such as [1,1,2,3,5], [1,2,2,3,4], [1,2,3,5,5]\u2026 and many others. Bagging will use the generated datasets to train the original model and combine the results. Different trainings should specialize the model on different areas of the target data.\n\nIf Bagging trains the model on variations of the input dataset, Dropout works by generating subnetworks of the original deep neural network. Essentially, Dropout creates subnetworks by removing some of the non-output units and then train those subnetworks using the original dataset. The nature of Dropout enables to create an ensemble capabilities of the original model which can be incredibly efficient"
    },
    {
        "url": "https://medium.com/@jrodthoughts/improving-deep-learning-algorithms-optimization-vs-regularization-f9b6e86fee8c?source=user_profile---------86----------------",
        "title": "Improving Deep Learning Algorithms: Optimization vs. Regularization",
        "text": "Implementing machine learning and deep learning algorithms is different from writing any other type of software program. While most code goes through the traditional authoring, compilation/interpretation, testing and execution lifecycle, deep learning models live through a never ending lifecycle of testing and improvement processes. Most people generically refer to that part of the lifecycle as optimization but, in reality, it also includes another important area of deep learning theory: regularization. In order to understand the role that optimization and regularization play in deep learning models we should start by understanding how those models are composed.\n\nWhat is a deep learning algorithm? Obviously, we know it includes a model but is not just that, isn\u2019t it? Using a pseudo-match nomenclature, we can define a deep learning algorithm with the following equation:\n\nUsing this conceptual equation, we can represent any deep learning algorithm as a function of an input data set, a cost function, a deep neural network model and an optimization process. In the context of this article, we are focusing on the optimization processes.\n\nWhat those those processes so challenging in deep learning systems? One word: size. Deep neural networks include a large number of layers and hidden units that can also include many nodes. That level of complexity directly translates into millions of interconnected nodes which makes for an absolute optimization nightmare.\n\nWhen thinking about improving a deep learning model, you should focus the efforts in two main areas:\n\nThose two subjects have become broad areas of research in the deep learning ecosystem know as optimization and regularization respectively. Let\u2019s look at both definitions in a bit more detail.\n\nThe role of regularization is to modify a deep learning model to perform well with inputs outside the training dataset. Specifically, regularization focuses on reducing the test or generalization error without affecting the initial training error.\n\nThe field of deep learning has helped to create many new regularization techniques. Most of them can be summarize as functions to optimize estimators. Very often, regularization techniques optimize estimators by reducing their variance without increasing the corresponding bias( read my previous article about bias and variance). Many times, finding the solution to a deep learning problem is not about creating the best model but a model that regularize well under the right environment.\n\nThere are many types of optimizations in deep learning but the most relevant are focused on reducing the cost function of a model. Those techniques typically operate by estimating the gradient of different nodes and trying to minimize it iteratively. Among the many optimization algorithms in the deep learning space, stochastic gradient descent(SGD) has become the most popular variation with countless implementation in mainstream deep learning frameworks(see my previous article about SGD). It is also common to find many variations of SGD like SGD with Momentum that work better on specific deep learning algorithms.\n\nWhat we generally refer to as optimization in deep learning model is really a constant combination of regularization and optimization techniques. For deep learning practitioners, mastering regularization and optimization is as important as understanding the core algorithms and it certainly play a key role in real world deep learning solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/understanding-the-bitcoin-ecosystem-a-market-taxonomy-aafe68916222?source=user_profile---------87----------------",
        "title": "Understanding the Bitcoin Ecosystem: A Market Taxonomy",
        "text": "Bitcoin futures are officially trading in the biggest derivatives exchange in the world. Yesterday, future contracts made its debut on the Chicago Mercantile Exchange(CME) pushing the cash value of Bitcoin above $18,500. The CME joins the smaller Cboe as the two derivatives exchanges offering Bitcoin future contracts adding an important component to the Bitcoin ecosystem. That ecosystem has evolved in just a few years from a handful of miners to a very complex and complete market with a large variety of areas that can influence the price of Bitcoin.\n\nThe size and complexity of the Bitcoin ecosystem has created a series of new channels that are relevant to the price of Bitcoin. While most people reduce the Bitcoin market to miners, exchanges and, just now, future contracts, the fact of the matter is that there are over ten segments of the market that have become highly influential in the price and direction of Bitcoin. In that context, I\u2019ve put together a taxonomy that includes some of the biggest categories you should be aware of when evaluating the Bitcoin ecosystem. Here are my favorites:\n\n1 \u2014 Exchanges: Bitcoin exchanges play a centre role in the market allowing people to buy and trade Bitcoin for fiat currencies or other crypto-assets. CoinBase or BitStamp are examples of popular crypto currency exchanges.\n\n2 \u2014 Miners: Bitcoin Miners are a key component of the ecosystem as they use high computer power to create new Bitcoins. Companies such as AntPool or Bixin are important members of this group.\n\n3 \u2014 Crypto VCs: A recent category in the Bitcoin world, Crypto VCs are venture capital funds that are actively and exclusively investing in Bitcoin and blockchain companies. Polychain Capital and MetaStable are two notorious examples of Crypto VCs.\n\n4 \u2014 Crypto Quant Funds: Some of the best quant funds in the market have been devoting their analytical resources to the trade of crypto currencies. Chicago-based DRW is the most representative examples of this category.\n\n5 \u2014 Traditional VCs: Venture capital funds have also become very relevant in the Bitcoin ecosystem by investing in companies that are actively using or relying on the digital currency. Union Square Ventures and Andreessen Horowitz are two of the most active VC funds in the Bitcoin ecosystem.\n\n6 \u2014 Hedge Funds: Wall Street\u2019s traditional investors have been raising funds for investment vehicles entirely dedicated to digital currencies and Bitcoin. Miller Value Partners and Galaxy Partners are some of the best known examples in this category.\n\n7 \u2014 Passive Investment Vehicles: There is a group of companies that have been working on passive investment vehicles such as Bitcoin ETFs or similar products.VanEck and Grayscale are taking the lead in this area.\n\n8 \u2014 Securities: There are some security products related to Bitcoin that are an interesting investment channel. The Bitcoin Investment Trust(GBTC) is the best known example in this category.\n\n9 \u2014 Regulators: The regulatory arms of markets such as the US Securities and Exchange Commission(SEC) are likely to play a more active and influential role on the price of Bitcoin.\n\n10 \u2014 Futures: Futures are becoming more and more relevant in the Bitcoin ecosystem. CME, Cboe and, very soon, Nasdaq are the pioneers in this category."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-aws-sagemaker-provides-end-to-end-lifecycle-management-to-your-ml-solution-cf0df73b239?source=user_profile---------88----------------",
        "title": "Technology Fridays: AWS SageMaker Provides End-to-End Lifecycle Management to Your ML Solution",
        "text": "Welcome to Technology Fridays! The race between Amazon, Microsoft and Google for dominating the cloud machine learning platform space has been heating up. The cloud incumbents are trying to become the preferred home of machine learning solutions and they have been literally matching each other\u2019s capabilities feature by feature as well their pricing models. That competition has helped to increase the level of innovation in the machine learning space. Today, I would like to discuss AWS\u2019 latest addition to its machine learning suite and one that might become the cornerstone of the platform.\n\nSageMaker attempts to address a fundamental challenge of machine learning applications by providing end-to-end lifecycle management capabilities using a consistent infrastructure. SageMaker is a native cloud service that allows data scientists to create machine learning models using familiar tools and deploy them to a production-ready, scalable infrastructure. You can think about SageMaker as a complement to the original AWS ML platform with added capabilities focused on the lifecycle of machine learning models.\n\nIn order to enable the creation of data science models., SageMaker leverages the popular Jupyter stack. That strategy allows data scientists to create interactive notebooks that explore and interact with registered data sources without the need of provisioning any backend infrastructure.\n\nOne of the key benefits of sageMaker is the support for multiple deep learning frameworks. Data scientists can implement models that leverage stacks such as TensorFlow, MxNet, PySpark and several pothers. SageMaker provides a robust support for Apache Spark as well as related technologies.\n\nModel deployment and hosting are other areas of strength of SageMaker. Amazon SageMaker Hosting Services enables the deployment of machine learning models by packaging them as Docker containers. References to data sources are stored in AWS data services such as S3. Deployment can take place across different AWS availability zones to guarantee availability and scalability. After a model is deployed, sageMaker creates different HTTPs endpoints that can be used by third party applications to configure and interact with the model. the programmable interfaces can also be used to train the models with new datasets.\n\nSageMaker can be effectively used to cleanse and enable data transformation in datasets. This enables data scientists to create new representations that can be reused across models. Developers using SageMaker can build their own algorithms or reuse built-in ones available in the platform\u2019s repository. Similarly, data scientists can create new models by assembling layers of existing algorithms.\n\nSageMaker provides seamless interoperability with dozens of services in the AWS platform which enables the implementation of highly sophisticated machine learning applications. Areas such as access control, data privacy or monitoring are direct beneficiaries of that level of integration.\n\nAWS SageMaker competes with the cloud machine learning offerings from Azure and Google Cloud. Microsoft in particular has been very active in the space with the release of new technologies such as the Workbench, Model Management and Experimentation services. Innovative startups such as DataBricks and Algorithmia with the recently announced CODEX platform are also relevant when comes to providing end-to-end lifecycle management in machine learning applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-art-of-simplification-manifold-learning-dfc885fb74e3?source=user_profile---------89----------------",
        "title": "The Art of Simplification: Manifold Learning \u2013 Jesus Rodriguez \u2013",
        "text": "High dimensionality datasets are one of the biggest challenges in machine learning algorithms. In datasets with a large number of dimensions, the combinations of distinct sets of variables can grow exponentially making learning really unpractical due to the computational cost. This is known in deep learning theory as the curse of dimensionality and remains one of the main challenges that triggered the raise of deep learning. Among the many techniques used to address the curse of dimensionality, manifold learning has become incredibly popular within deep learning models.\n\nIn order to understand manifold learning it might be useful to draw some analogies from how our brains simplify knowledge. Think about the last time you explaining a complex subject to a friend or colleague. Most likely, you didn\u2019t try to convey your entire knowledge of the subject, which probably took you years to acquire. Instead, you decided to present the most relevant elements so that the recipient of the explanation could get a general idea about the topic: you decided to simplify.\n\nSimplification is a cognitive process that help us learn about complex subjects. The cognitive science behind simplification is, ironically, pretty complex and involves many heterogeneous sub processes. Among the many things out mid does when trying to simplify a subject, there are two that are very relevant to the concept of manifold learning:\n\na) We try to determine the most important parts of the subject of knowledge and skip the rest.\n\nb) We use analogies to simplifies to help us understand specific subjects.\n\nThe combination of simplification and analogies is at the core of manifold learning.\n\nA manifold is a fascinating mathematical structure that abstracts a connected region in which each point is associated with a set of points in its neighborhood. Because of the connections, points in a manifold can be transformed into other points with minimum effort. In the context of machine learning, manifolds are used to represent a connected number of data points that can be modeled as transformations from a higher-dimensional space.\n\nConfused already????? :) Its really simpler than it sounds. The key assumption of manifold learning is hat in a high dimensional structure, most relevant information is concentrated in small number of low dimensional manifolds. This is know in machine learning theory as the Manifold Hypothesis and includes two main points: data distribution and connectivity.\n\nOne part of the Manifold Hypothesis assumes that the probability distribution in datasets such as images or text is highly concentrated. A classic example to illustrate that point is to generate a meaningful text by randomly selecting words from a long text. Obviously this very unlikely to work because the distribution of coherent natural language sentences is a very small space in the dataset of the combinations of letters of the original text.\n\nThe second element of the Manifold Hypothesis is connectivity which entails that relevant data points are connected to other relevant data points. We can see clearly in images in which a pixel can be obtained using a simple transformation from another pixel in its neighborhood.\n\nManifold learning relies on the Manifold Hypothesis to extract relevant knowledge from a high dimensional dataset by transforming into manifold structures of a lower dimension. This technique drastically reduces the computational costs in many deep learning models and has become an increasingly important element of deep learning solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-ideas-for-more-transparent-icos-1e29f2296523?source=user_profile---------90----------------",
        "title": "Some Ideas for More Transparent ICOs \u2013 Jesus Rodriguez \u2013",
        "text": "Initial coin offerings(ICOs)) have taken financial markets by storm raising more than $3.5 billion this year. The excitement around ICOs is only matched by the fears of scams and fraud in the space. Those fears have caused different countries to ban ICOs and the US Securities and Exchange Commission(SEC) to launch a cyber crime unit with a special focus on digital currencies and ICOs. As a result, the SEC has started criminal proceedings against a couple of phantom companies including the infamous Plexcoin.\n\nThe bad actors and market manipulators in the ICO space are the consequence of a new and fast growing financial exchange vehicle. Labeling the ICO ecosystem as fraudulent because of those bad actors is just misleading. A lot of fraud has been committed using US dollars or any of the established financial channels in today\u2019s markets( stocks, options, FOREX\u2026). As ICOs evolve, new mechanisms will be implemented to prevent market manipulations. I would like to explore a few ideas that might help in that area.\n\nImplementing more transparent and ethical ICOs is far from being an easy endeavor. However, the programmable nature of ICOs provides very unique advantages to achieve that goal compared to traditional financial channels.\n\nICOs can implement enhancements or new features using blockchain smart contracts which enable not only faster iterations but a more resilient and trusted environment. In that context, new regulatory features in ICOs should not only manifest themselves as processes but also as smart contracts that can be programmable used by the rest of the ecosystem. If we follow that reasoning, there are a few ideas in the traditional venture capital(VC) and public equities markets that can be extrapolated to the world of ICOs. Let\u2019s explore some of my favorites:\n\nVesting is a well-established concept in VC rounds that allow shareholders to vest their stake on a company based on a specified schedule. A similar concept concept could be implemented as smart contracts that can prevent token holders to cash-out all their tokens on day one of an ICO.\n\nPublicly traded companies often use different classes of shares to represent specific rights of shareholders like voting. In the same way, ICOs could consider issuing different types of tokens that differentiate between token-holders and grant more influence to certain individuals on the company\u2019s decisions.\n\nImportant decisions in venture-backed or publicly traded companies are typically delegated to the board level. We could simulate that concept using smart contracts that allow token holders to vote on relevant decisions such as capital allocation, token distributions, investments and others.\n\nTransparency is a key feature of blockchain technologies so why not use it to improve the transparency of ICOs. Blockchain smart contracts could be used to publish relevant performance indicators or documents of the company that can be relevant to guide the price of tokens.\n\nThe topic of regulation is sensitive among blockchain enthusiasts but lets\u2019 assume that some level of regulation will be needed to legitimize ICOs. Why bring regulators into the blockchain world then? Imagine that entities like the SEC implement smart contracts to enable the automatic registration of ICOs and subsequent disclosures. It seems like an interesting concept to use the strengths of the blockchain as a regulatory mechanism."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-bias-and-variance-8bd1a4ff197c?source=user_profile---------91----------------",
        "title": "About Bias and Variance \u2013 Jesus Rodriguez \u2013",
        "text": "Knowledge generalization is, arguably, the biggest challenge of machine learning systems. It is relatively easy to create models that match a training set but the story is different when comes to performing against the test or other unknown dataset. Most machine learning models tend to overfit when executed against new datasets. In order to effectively generalize knowledge, machine learning algorithms leverage statistical estimation techniques. Instead of inferring the exact formula for a specific parameter, machine learning models rely on statistics to generalize the distribution of those parameters. Among the many estimators you should always consider in machine learning algorithms, bias and variance play a prominent role helping to achieve good generalizations.\n\nUnderstanding bias and variance is, essentially, analyzing the variations between estimated and known data points. Sometimes, those data points are parameters in a function while, other times, are the entire function itself. Finding an acceptable equilibrium between bias and variance is a key aspect of regularization and generalization strategies in machine learning models.\n\nWhen evaluating the bias of an estimator, we are looking at the variation between the estimation of a dataset and its true values. Mathematically, we can represent the bias of an estimator using the following formula:\n\nWhere the E function defines the estimated value of a parameter and V its true value.\n\nAn estimator is said to be unbiased if E(P) = Vp(P) or bias(P) = 0. Similarly, an estimator is called asymptotically unbiased if the bias trends towards 0 with a large number of examples.\n\nThe magic of calculating the bias of a hypothesis relies on finding the correct estimator. Well known statistical distributions such as Bernoulli or Gaussian include estimators that have proven effective on many machine learning algorithms.\n\nMoving away from mathematics, we can illustrate the concept of bias using examples from our everyday lives. A clock that is always one hour late or a quantitive trading algorithm that always predicts the price of a stock 1% higher are examples of data estimators with strong bias. In the context of machine learning algorithms, the goal of to regularize models by lowering the bias.\n\nWhen estimating a hypothesis in a machine learning algorithm, we should estimate how much it will vary as a function of the underlying dataset. This characteristic is known as variance and represents a strong complement to the bias property of estimators. Conceptually, the variance of an estimator quantifies how much its value will vary when resampling the dataset( from training to testing). The square root of the variance is another relevant metric known as the standard error.\n\nGoing back to our real world examples, if our clock is all over the place but, averaged over time, its values approximate the real time then is said to have a low variance. However, if the predictions of our quantitive trading algorithm change drastically from stock to stock then we say that the estimator has a high variance.\n\nHow are bias and variance relevant in machine learning models? In super simple terms, the art of generalization can be summarized by reducing the variance of a model without increasing its variance. Many machine learning models already include methods for tracking variance and bias and we should pay attention to both estimators if we want to avoid overfiting and improve the performance of machine learning models on unknown datasets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bitcoin-futures-are-here-some-initial-thoughts-afe25b65a895?source=user_profile---------92----------------",
        "title": "Bitcoin Futures are Here: Some Initial Thoughts \u2013 Jesus Rodriguez \u2013",
        "text": "I am writing this article on Sunday evening after Bitcoin futures have been trading for a few hours in the Cboe Global Markets, Inc exchange. My guess, is that, by the time you read it, you might be already bombarded with news about the first of trading of Bitcoin futures so I am going to try to stay away from stating the obvious and instead focus on expressing a few thoughts about my impressions from yesterday.\n\nIn the past, I\u2019ve regularly written about the implications of future contracts in the \u201cfuture\u201d of Bitcoin so its good to finally see some of those ideas implemented. Yesterday, may transcend in history as a pivotal day in the evolution of Bitcoin and its integration into the broader financial; markets. Kudos to Cboe and CME for taking the charge implementing future contracts for Bitcoin and staking their reputation on the future of digital currencies.\n\nAs of the time of writing this article, future contracts were trading around the $17,000.00 mark with the cash equivalent oscillating between $16,000.00 to $16,700.00. Overall, this can be considered an impressive performance particularly if we factor in the considerable volume or orders placed and the fact that may skeptics were predicting disaster for the first day of action. The significant volume of order caused the exchange to halt trading for a while which can be a lesson for new venues such as Nasdaq that are planning to enable Bitcoin futures in the next few months. The volume also reveals that the demand for Bitcoin futures has expanded beyond traditional institutional investors reaching mainstream audiences.\n\nThe launch of future contracts has long been seen as the biggest validation for Bitcoin and the main factor behind the recent rally on the price of the crypto asset. However, as we witnessed yesterday, futures may help to control or even diminish the price of Bitcoin. This is due to the fact that the new contracts offer a vehicle for skeptics of digital currencies, from which there are many among institutional investors, to short Bitcoin. Contrary to popular thinking, futures might introduce enough friction in the long term between bears and bulls to help stabilize the price of Bitcoin.\n\nWhile Bitcoin trading has been off the charts, gold markets have been experiencing an unprecedented calm. In fact, the gap between the upper and lower end of gold future contracts has been at its lowest level since October 2005. Bitcoin pioneers such as the Winklevos brothers have been very vocal positioning Bitcoin as an alternative to gold. The recent raise of popularity of Bitcoin can be definitely be considered one of the main facts behind the decline on the demand for gold.\n\nRecently, I wrote about the risk that derivatives built on top of cryptocoins can represent for the stability of the digital currency ecosystem. Derivatives such as future contracts are simply statistical predictions built on top of financial assets such as commodities or even other derivatives. The asset in this case(Bitcoin) turns out to be incredibly volatile and very sensitive to market manipulations. That combination of mathematical speculative models on top of volatile financial assets is definitely a risky proposition despite the regulatory framework that comes with future contracts. The potential reward for the successful implementation of Bitcoin futures is huge but the risk is relevant enough that regulators should keep an eye on it."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-cosmos-db-wants-to-be-the-only-database-you-will-ever-need-aa6de2c6e5e7?source=user_profile---------93----------------",
        "title": "Technology Fridays: Cosmos DB Wants to be the Only Database You Will Ever Need",
        "text": "Welcome to Technology Fridays! I don\u2019t often write about databases because I try to focus this segment on innovative technologies in emerging technical markets. Even though we can argue that we are in the golden age of databases, it is hard to find database technologies that are completely different from anything we\u2019ve seen before. Today, I would like to explore a new database platform that is literally redefining some of the traditional concepts in the industry.\n\nAzure Cosmos DB is the latest addition to the data storage services portfolio of the Microsoft cloud platform. Cosmos DB challenges some of the conventional wisdoms in database technologies by supporting multiple data models on a single runtime. Almost since their inception, database platforms have been designed for a specific data model such as relational, document, graph key-value pairs and others. However, modern application architectures such as mobile or the internet of things(IOT) increasingly demand multiple data models. That\u2019s the promise of Cosmos DB. One database to rule them all ;) Ok, maybe not but you get the idea :).\n\nAzure Cosmos DB is a multi-modal database platform that natively supports various data models such as document, graph, key-value, table, columnar and several others. The platforms supports all those data models using a consistent infrastructure, toolset and architectures which enables developers to switch from one mode to another without having to learn a new runtime. More importantly, Cosmos DB is compatible with industry protocols which guarantees interoperability with mainstream database runtimes such as MongoDB or Neo4J.\n\nA multi-modal database is a nice concept but its incredibly hard to achieve. If you think about it, every database runtime uses an underlying data structure optimized for its specific data model. For instance, B-Trees have long been the data structure behind relational databases just like HDFS is the underlying data structure behind platforms such as Hive or HBase. Cosmos DB relies on a structure called atom-record-sequence(ARS) which was designed from the ground up to support different data models without sacrificing performance or scalability.\n\nIn order to use Cosmos DB, developers can leverage the different APIs available with the platform including DocumentDB and MongoDB for document structures, Greemlin for graphs, Table API for columnar storage and others. Instead of inventing a new API and query language, Cosmos DB relies on industry accepted protocols which guarantees interoperability and portability with other database runtimes.\n\nThe multi-modal capabilities of Cosmos DB expand beyond the programming model and include different aspects of its infrastructure. The platform supports different consistency models ranging from robust SQL-like consistency to NOSQL-like eventually consistent paradigms. Similarly, Cosmos DB is able to scale across different Azure regions and handle massive amounts of read and write operations maintaining a very low latency. Cosmos DB seamlessly interoperates with other Azure services such as Azure Functions which can be used to enabled sophisticated server-side logic.\n\nAzure Cosmos DB is one of the first multi-modal cloud platforms in the market and doesn\u2019t have many direct competitors. However, technologies such as AWS DynamoDB and the recently announced Neptune or MongoDB Atlas do a phenomenal job supporting different data models and, in the future, can become relevant competitors of Cosmos DB."
    },
    {
        "url": "https://medium.com/@jrodthoughts/memory-in-deep-learning-systems-part-iii-neural-turing-machines-8832ba66194f?source=user_profile---------94----------------",
        "title": "Memory in Deep Learning Systems Part III: Neural Turing Machines",
        "text": "This is the third and final part of an essay that discussed the concepts of memory in deep learning models. The first two parts provided an overview about the fundamentals views about memory in neuroscience and cognitive psychology respectively. Today, we will explore how those theories have influenced the creation of deep learning models that imitate some of the characteristics of human memory.\n\nFrom the two previous articles we learning that, when exploring the theories of memory in neuroscience and cognitive psychology, there are some fundamental features that should be part of any system that attempts to recreate human memory using computing models.\n\na)Partition a memory into segments that describe different areas of knowledge\n\nc)Retrieve data based on contextual and not directly related information as well as external data references\n\nNo discipline in computer science can benefit more from a human-like memory system than deep learning. Since its early days, there have been efforts in the deep learning space to model systems that simulate some of the key characteristics of human memory.\n\nIn order to understand the relevance of memory in deep learning models, we should differentiate between the concepts of implicit and explicit knowledge. Implicit knowledge is typically subconscious and, consequently, hard to explain. We can find examples of implicit knowledge in areas such as speech and vision analysis such as recognizing a monkey in a picture or the tone and mood in a spoken sentence. Contrasting with that model, explicit knowledge is easily modeled declaratively. For instance, understanding that a monkey is a kind of animal or that certain adjectives are offensive are classic examples of explicit knowledge. We know that deep learning algorithms have made incredible progress representing implicit knowledge byyt they still struggle modeling and \u201cmemorizing\u201d explicit knowledge.\n\nWhat makes explicit knowledge so difficult in the context of deep learning algorithms? If you think about the traditional architecture of neural networks with millions of interconnected nodes, we will realize that they lack the equivalent of a working memory system that can store fragments of inferred pieces of knowledge and their relationships so that it can be easily acceded from different layers in the network. Recently, new deep learning techniques have been created to address this limitation.\n\nThe rapid evolution of deep learning algorithms has triggered the need for memory systems that can resemble the characteristics of human memory when processing explicit knowledge. One of the most popular techniques in the memory modeling space is known as Neural Turing Machines(NTM) and was introduced by DeepMind in 2014.\n\nNTM works by expanding a deep neural network with memory cells that can store complete vectors. One of the greatest innovations of NTM is that it uses heuristics to read and write information. For instance, NTM implements a mechanism known as content-based addressing that can retrieve vectors based on input patterns. This is similar to the way humans recall memories based on ctextual experiences. Additionally, NTM includes mechanics for increasing the prominence of memory cells based on how often they are recalled.\n\nNTM is not the only techniques that enables memory capabilities in deep learning systems but is certainly one of the most popular. Imitating the biological and psychological functions of human memory is not an easy endeavor and has become one of the most important areas of research in the deep learning space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/memory-in-deep-learning-systems-the-cognitive-psychology-perspective-ff4013312dd9?source=user_profile---------95----------------",
        "title": "Memory in Deep Learning Systems: The Cognitive Psychology Perspective",
        "text": "This is the second part of an essay that explores the intricacies of memory in deep learning systems. the ultimate objective of this essay is to highlight the key areas of human memory that are trying to be imitated in deep learning algorithms. In order to get there, we are exploring memory through the lenses of different schools of though such as neuroscience or cognitive psychology. In the first part of this essay, we presented the neuroscience theory of memory. Today, I would like to deep dive into the ideas that help to explain memory from the perspective of cognitive psychology.\n\nWhen discussing the neuroscience theory of memory , we talked about the \u201cbinding problem\u201d as the main theory that explains how scattered memory fragments can be recalled into cohesive memories. It turns out that, in order to explain the binding problem, we need to expand beyond our architecture of our brain and evaluate all sorts of psychological contextual elements that deeply influence how memories are recalled. One of the main theories in cognitive psychology that tries to explain the associative nature of memory is known as the Priming Effect.\n\nLike all good theories in cognitive psychology, let\u2019s try to explain the Priming Effect in the context of experiments. Think about the first thing that comes to mind when you hear the word DINNER. Was it wine( for me it was), dessert, maybe Saturday night date? AS you can see, something as simple as a word can evoke a mixed set of emotions and even other related words. We are effectively recalling associated memories.\n\nOne of the most remarkable results of the prior experiments is to notice how fast you were able to retrieve the those related words or memories. That happens because associated memories are part of what Economics Nobel Prize winner Daniel Kanehman calls System 1; they happen quickly and they produce a series of related emotional and physical responses. In psychology, that type of phenomenon is known as Associatively Coherent.\n\nGoing back to our word game; the fact that the word DINNER evokes the idea of WINE or DESSERT is known as a priming effect in the sense that \u201cdinner primes dessert\u201d. Priming has an important role explaining how memory works. The priming effect does not only applies to words but also to emotions, physical reactions, instincts and other cognitive phenomenon\u2019s. In the context of memory, the priming effect tells us that memories are not only recalled by associated ideas but by \u201cprimed ideas\u201d.\n\nAnother important element of the cognitive psychology theory of memory covers how we recall the frequency of events. For instance, if I ask you \u201chow many concerts have you attended in the last decade? \u201c you are likely to overestimate the number if the answer feels fluent or you have recently attended a concern. Otherwise, if you don\u2019t enjoy your last concert experience, the number might be too low. This cognitive process is known as the Availability Heuristic and explains how our memories are deeply influenced by the rapid availability of an answer.\n\nBy now we have an idea of how we can think about memory in the context of the brain(neuroscience) and our social settings(cognitive psychology). How are those theories imitated in deep learning algorithms. That will be the subject of tomorrow\u2019s post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/memory-in-deep-learning-systems-part-i-the-neuroscience-perspective-aa47fd56ad3c?source=user_profile---------96----------------",
        "title": "Memory in Deep Learning Systems Part I: The Neuroscience Perspective",
        "text": "Memory modeling is an active areas of research in the deep learning space. In recent years, techniques such as Neural Turing Machines(NTM) have made significant progress setting up the foundation for building human-like memory structures in deep learning systems. In the past, I\u2019ve written extensbily about the role of memory in artificial intelligence(AI) so I am not planning to bore you restating the same points. Instead, I would like to approach the subject from a different angle and attempt to answer three fundamental questions that we should have in mind when thinking about memory in deep learning models:\n\na) What makes memory such a complex subject in deep learning systems?\n\nb) Where can we draw inspiration about memory architectures?\n\nc)What are the main techniques used to represent memories in deep learning models?\n\nIn order to effectively answer the first two questions, we should should look at both the biological and psychological theories of memory. That should take us to the two schools of thought that have influenced our knowledge about memory the most: neuroscience and cognitive psychology. Following that same trend of thought we are going to structure this essay in three main parts. The first part will explain the neuroscience theory of memory. The second part will approach memory from the perspective of cognitive psychology while the final segment will focus on how deep learning is drawing inspiration from those disciplines to incorporate memory into neural networks. So let\u2019s start in the place where memories are created: the human brain.\n\nUnderstanding how memories are created and, sometimes, destroyed as well as the differences between long and short terms memory have been an important area of neuroscience research in the last decade. One of the iconic subjects that inspired that level of research was been known as patient HM.\n\nHenry Gustav Molaison(HM) suffered an accident at the age of nine that caused him to experience convulsions regularly for the following years. In 1952, at the age of twenty-five, HM underwent a surgery to relieve his symptoms. The procedure was considered initially successful until the doctors discovered that they have accidentally cut part of HM\u2019s hippocampus. as a result, HM was unable to retain new memories.\n\nThe idea of living without new memories is the analog of always living in the present. Trust me, I am not talking about the mindfulness way but in the way that you can\u2019t relate to a recent event in the past or envision an event in the future. Patient HM went about his day only retaining information for a few minutes, greeting the same people and asking the same questions over and over again. The HM case was pivotal to help neuroscientists understand how memories are created, stored and recalled.\n\nThe modern neuroscience theory of memory involves three fundamental areas of the brain: the thalamus, the prefrontal; cortex and the hippocampus. The thalamus can b considered a router that processes sensory information(vision, touch, speech) and relays is to the sensory lobes of the brain for evaluation. The evaluated information eventually reaches the prefrontal cortex where it enters our consciousness forming short term memories. The information is also sent to the hippocampus which distributes different fragments to various cortices forming long term memories. One of the biggest challenges neuroscience today is to understand how those scattered fragments of memories can be reassembled into cohesive memory experiences. This is known in neuroscience as the \u201cbinding problem\u201d.\n\nConsidered one of the most puzzling aspects of the neuroscience theory of memory, the binding problem challenges the concept of recreating memories from other sensory information. Take the experience of going to a concert with your loved one. Memories about the event will be broken down and stored across different regions of the brain. However, it will only take one experience such as listening to a melody of the same band or seeing your wife dancing to recall the entire memory of the concept. How is this possible?\n\nOne theory that solves the binding problem states that memory fragments are linked by electromagnetic vibrations that are constantly flowing through the brain. There vibrations create a temporal(not spatial) link between memory fragments allowing them to activate together as a cohesive memory.\n\nThe neuroscience theory of memory give us the foundation to understand some of the main components of an intelligent memory architecture. However, human memory is not only a by-product of the components of the brain but it is also deeply influenced by contextual circumstances. That will be the subject of the next post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-google-cloud-firestore-brings-real-time-communications-to-the-database-world-f36108f3f86b?source=user_profile---------97----------------",
        "title": "Technology Fridays: Google Cloud Firestore Brings Real Time Communications to the Database World",
        "text": "Welcome to Technology Fridays! When you think about databases, real time, instant communication is not the first thing that comes to mind. After all, databases are designed to persist data which, as a function, introduces delays in the processing of datasets. Today, I would like to discuss a new technology that is finally attempting to bridge both worlds.\n\nWhen Google acquired Firebase a few years ago, it didn\u2019t only add a robust mobile backend as a service(mBaaS) technology to its, then emerging, cloud platform but it also acquired the powerful real time communication engine behind the popular mBaaS stack. Over the years, the ability to develop real time, persistent communications between clients and mobile apps has been one of the main attractions of the Firebase platform. With Cloud Firestore, Google is making the technology behind Firebase available to non-Firebase developers via the Google Cloud platform.\n\nCloud Firestore is the mainstream iteration of Firebase database technology. The real time capabilities of Firestore makes it a common candidate to enable the backend of mobile and internet of things(IOT) applications. You might be wondering what does real time means in the context of cloud databases? Well, when using Cloud Firestore, client applications can listen to changes in the underlying data and react accordingly. That capability enables the implementation of responsive applications that can operate despite the absence of network connectivity or under complex network latency scenarios.\n\nFrom the data structure perspective, Cloud Firestore is a document database. That makes total sense if we consider the platform\u2019s background powering mobile and IOT applications. Firestore models data in documents which are based on key-value pairs grouped in structures known as collections. The platform also supports nested collections or subcollections which allow the modeling of data hierarchies that can be easily navigated. Cloud Firestore supports a large set of data types including geographical points and maps. Similarly, References can be used to link disjointed documents.\n\nThe capabilities of Cloud Firestore expand way beyond traditional databases. The platform includes features such as full ext search which enables the indexing and search of documents. The search capabilities of Cloud Firestore are powered by Algolia which is one of the most popular self-service search platforms in the market.\n\nScalability and performance are core features of Cloud Firestore. Data in the platform can be segmented using shards which control the performance of read and write data operations. The platform also includes sophisticated security capabilities in areas such as authentication, data privacy or access control. Developers can integrate with Cloud Firestore using the different SDKs available with the platform. Server side logic can also be injected using Cloud Functions and more sophisticated processes can be implemented by integrating with other Google Cloud services.\n\nGoogle Cloud Firestore is a very unique database technology focused on enabling the backed of mobile and IOT applications. Couchbase Mobile is a technology that is somewhat comparable to Firestore from the feature perspective. The recently announced Azure Cosmos DB is also an interesting option in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-other-ico-some-thoughts-about-interactive-coin-offerings-part-ii-5ffd49b1108c?source=user_profile---------98----------------",
        "title": "The Other ICO: Some Thoughts About Interactive Coin Offerings Part II",
        "text": "This is the second part of an essay that presents the model of interactive coin offerings(IntCOs) as an alternative to traditional initial coin offerings(ICOs). In the first part of the article, we discussed some of the benefits of ICOs derived from being a programmable platform that enables the creation of new value-exchange vehicles such as IntCOs. Similarly, we highlighted some of the main challenges and limitations of ICOs such as valuation( inability to accurately estimate the value of a company), participation(not everyone can get into an ICO) and market manipulation( the price of tokens can be inflated using social signals). This part will explain the protocol behind IntCOs and how it addresses some of those challenges.\n\nIntCOs were created with the objective of addressing some of the limitation of traditional ICOs while leveraging the core principles of token offerings. Specifically, IntCOs attempt to reconcile the ideas of valuation and participation which will allow anybody to get in a token sale while keeping the price of the tokens proportional to the amount of tokens sold.\n\nAt its core, IntCOs are Ethereum smart contracts that model the interaction between token buyers and holders. The main theoretical contribution of IntCOs is that it allow buyers to enter and exit a token auction based on the behavior of other buyers. That interactive behaviors should help to maintain an equilibrium on the valuation of the crowdsale while preventing buyers with large pools of capital or sophisticated mining capabilities to gain an unfair advantage over other buyers.\n\nIn order to participate in an IntCO, buyers should send the crowdsale smart contract messages specifying the amount of tokens that should be bought together with the valuation of the sale. After allocating the tokens to the buyers, the smart contract will adjust its status and balance which will be used for the remaining to the token sale.\n\nFrom the beginning of an IntCO until a maximum specified time, buyers can voluntarily cancel their bids. At that point, the smart contract will refund the tokens and readjust the balances. Withdrawals are forbidden after the specified maximum time elapses in order to allow buyers to deflate the price by retiring their bids last minute.\n\nIntCOs don\u2019t only support manual withdrawals but it enables a mechanism for automatic token refunds. In my opinion, this is the biggest innovation of the IntCO protocol. That feature is applicable when the valuation of a crowdsale exceeds the personal cap of certain buyers. In order to maintain the equilibrium in the price of the tokens, the smart contract will refund all buyers with minimum cap an equal portions of tokens proportional to their bids. So even if the buyers has not voluntarily withdraw his bid, the smart contract will automatically kick out some of his bids from the crowdsale.\n\nThere are many interesting ideas and side benefits of the IntCO model. for starters, the protocol enforces that all bids match the buyer\u2019s minimum cap. That feature directly addresses the participation challenge of traditional ICOs. Complementarily, the crowdsale smart contract guarantees that the price of tokens and the corresponding valuation will increase monotonically regardless of the type of bids buyers submit. That capability addresses the valuation issue of the current generation of ICOs. More importantly, IntCOs are a fair protocol that makes no distinction between small or large purchases.\n\nWhether IntCOs will become widely adopted as part of token offerings remains to be seen. Regardless, I believe some of the ideas of the protocol are worth exploring further and gradually testing with the next wave of token offerings."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-other-ico-some-thoughts-about-interactive-coin-offerings-part-i-23c954c299fd?source=user_profile---------99----------------",
        "title": "The Other ICO: Some Thoughts About Interactive Coin Offerings Part I",
        "text": "The world of initial coin offerings(ICOs) has become one of the most innovative ecosystems in financial markets in the last couple of years. Like an other new money exchange vehicle, ICOs have been subjected to misuse by bad actors and have surfaced some of the drawbacks of token sales. Recently, a new model called interactive coin offerings(IntCOs) was proposed to address some of the limitations of ICOs. Created by Ethereum\u2019s founder Vitalik Buterin and Jason Teutsch from the TrueBit foundation, IntCOs leverage the advantages of smart contracts to circumvent some of the main challenges of traditional token sales.\n\nThe Number One Advantage of ICOs\n\nSomewhat ironically, the thing that allows Buttering and Teutsch to create IntCOs can be considered, at the same time, the main innovation behind traditional token sales. A lot has been written about the limitations of ICOs. However, token sales hold a fundamental advantage that makes innovations such as IntCOs possible: they are programmable.\n\nI know I am stating the obvious but think about it in the broader context of financial markets. Programmability drastically reduces the time that takes to create improvements in digital token sales. Imagine that you would like to improve upon a traditional capital raising mechanism such as IPOs or bond sales. Just to think about the amount of paperwork, attorneys or testing that a small change would entail results overwhelming. More importantly, any possible change to those vehicles would be mostly based on processes instead of the underlying financial protocols.\n\nGiven that token sales rely on programmable smart contracts, changes can be made by simply modifying exiting protocols or creating brand new ones. That capability is what has made possible to envision models such as IntCOs and we should expect new protocols that improve token sales to continue come out in the near future.\n\nBefore we start deep diving into IntCOs, we should understand the challenges of traditional token sales that motivated the creation of a new protocol. Without neglecting the tremendous innovation and value of token sales, we should admit that the first wave of ICOs have surfaced a series of basic concerns. Let\u2019s look at a few of those challenges:\n\nBuyers in ICOs face the fundamental challenge of estimating the potential valuation of tokens without a lot of information. Traditional valuation modeling techniques such as security analysis don\u2019t apply to ICOs as there is very little information available about the companies. In the absence of fundamentals, buyers rely on market signals and the influence of other buyers to setup a price.\n\nAnother limitation of ICOs, is the fact that token sales are not available to everyone. Many ICOs offer pre-sales to a reduced number of investors which sorts of anchor the price of the official token offering. also, hot ICOs can selloff in a matter of minutes leaving many investors out.\n\nThe current structure of ICOs is prompt to different types of market manipulations. From inflating the value of a toke via social channels to obtaining unfair advantage using large pools of capital or sophisticated mining capabilities, the price of ICOs can, and frequently is, manipulated by smart buyers.\n\nHow does the IntCOs proposal address some of these challenges? That will be the subject of the next post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-algorithm-that-powers-deep-learning-9037b125a4f4?source=user_profile---------100----------------",
        "title": "The Algorithm that Powers Deep Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Ok, the title is a bit of an exaggeration but hopefully it caught your attention :)\n\nWhen looking into deep learning models, very frequently you are going to encounter the term stochastic gradient descent(SGD) as an optimization mechanism. SGD is, by far the most common algorithms in deep learning models and is not a stretch to say that nearly all deep learning is, to some extent, powered by SGD., What is the mystical algorithm and why is so relevant to deep learning?\n\nIn its most basic form, SGD is an optimization algorithm. Like many other optimization techniques, SGD focuses on minimizing the cost function of a specific model without drastically impacting the rest of the model. Optimization algorithms are nothing new in machine learning and has been a core part of it since its inception. However, most of the traditional optimization techniques in machine learning needed to be adapted to perform with the large datasets common in deep learning problems. Specifically, SGD is the deep learning adaptation of a common family of optimization methods known as Gradient Descent.\n\nThe general goal of optimization algorithms is to minimize the cost function(also known as error function) of a learning model. If we represent the cost function as c= f(x), the objective of an optimization algorithms would be to minimize c by altering x.\n\nGradient Descent Optimization(GDO) relies on derivatives to minimize the cost function. Derivatives is one of the pillars of calculus and has many applications on different areas of deep learning. GDP relies on a very particular property of derivatives that allows to obtain small changes in the output of a function by scaling its input. Using some mathematical nomenclature, if f\u2019(x) is the first-order derivative of our cost function f(x) and d is a very small number, then we can assert that:\n\nAll those mathematical expressions, simple tell us that we can make small changes in f(x) by modifying x. GDO uses that technique to find different optimization points for a cost function f(x). Even if you are not familiar with GDO, I am sure you have heard of some of its terms such as local minimum or maximum or global minimum or maximum as they are often used indiscriminately in mainstream technical articles.\n\nLocal minimum/maximum refers to a point on which a function f(x) is lower/higher that all its neighboring points. Similarly, global minimum/maximum refers to the absolutely lowest or highest point of the function. In the const of GDO, the goal of the algorithms is to find local minimums that don\u2019t contradict the global minimum.\n\ntraditional GDO techniques often result impractical and prohibitory expensive when dealing with large datasets. Imagine calculating derivatives across billions of data points in a training dataset. SGD improves on classic GDO techniques by uniformly drawing small sets of samples (ranging fro a few dozens to a few hundreds)) from the training datasets and evaluating different optimization functions.\n\nWithout getting into the algorithmic details behind SGD, it its important to highlight that it excels at funding very low values for the cost function very quickly. More importantly, SGD does so while keeping steady computational costs. SGD provides no guarantees that will ever arrives at a local minimum but the tradeoff in terms of speed and resources makes a more viable option than typical GDO algorithms.\n\nOptimization is a very active area of research in the deep learning space. Constantly, new algorithms are being actively tested by researchers and many of them are improvements on SGD. For now, SGD has become a favorite of the deep learning community and is important to understand some of its concepts when applied in deep learning solutions ."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-four-subjects-will-help-you-get-started-with-deep-learning-fc83191fea72?source=user_profile---------101----------------",
        "title": "These Four Subjects Will Help You Get Started with Deep Learning",
        "text": "Have you tried to get started with a deep learning framework just to give up after finding the experience incredibly frustrating? First of all, there are all those algorithms that you never seen before and they get assembled into complex structures that are really hard to understand. The you have all the crazy mathematical operations that take you back to the university years. Finally, there is the strange structure of the code that read like any programs you have seen before. Well, don\u2019t feel bad because you are far from being along about that experience.\n\nMastering deep learning can be an incredibly frustrating experience for most developers. Deep learning programs are \u201cdeeply\u201d mathematical and is hard to get a good sense of any algorithm without understanding its mathematical foundation. Additionally, deep learning builds on the foundations of machine learning algorithms which are essential to understand the functionality of any model. So there are really no shortcuts if you want to become a strong deep learning technologist but, understanding what to learn can make a huge difference. In that subject, I would like to give you a few recommendations about several areas that I believe will drastically improve your understanding of deep learning techniques.\n\nWhat to Learn to Deep Learn\n\nThere are several disciplines that are influential in deep learning applications and the list can get overwhelming. However, in my experience, there are four specific subjects that I would recommend to any aspiring deep learning practitioners.\n\nMost deep learning algorithms several complex operations on data structures such as matrices, vectors, tensors or other elements that are the core subject of linear algebra. While most computer science curriculums include some basics of linear algebra, we need to go a bit deeper to understand the operations used in deep learning models. From the fundamentals of matrix, addition, multiplication or inversion to sophisticated topics such as egendecomposition or the Moore-Penrose Pseudo universe, a deep understanding of linear algebra is key in order to master deep learning models.\n\nNumerical computation is the branch of mathematics that focuses on solving complex problems by iteratively estimating the solution. The approach followed by numerical computation techniques contrasts with traditional methods of discrete mathematics or logic that solve problems by codifying a formula. One of the key areas of numerical computation is Gradient-Based Optimization which can be considered the common denominator to every deep learning algorithm.\n\nDeep learning models can be seen as a computational graph for quantifying uncertainty and they require a mathematical framework to express statements about uncertainty. That\u2019s the role of probability theory which enables a mathematical foundation to reason under uncertainty. From classic probability distributions to the world of Bayesian statistics, probability theory has a strong footprint in deep learning models.\n\nNot much to say here. Machine learning algorithms provide the basics to understand deep learning models. Many layers of deep learning programs are combinations of machine learning algorithms. Getting an understanding of the fundamental machine learning techniques is a key requirement before diving into the deep learning universe."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-polkadot-enables-the-internet-of-blockchains-eb09d638ea72?source=user_profile---------102----------------",
        "title": "Technology Fridays: Polkadot Enables the Internet of Blockchains",
        "text": "Welcome to Technology Fridays! For my US readers, I hope you enjoyed a blessed Thanksgiving holiday surrounded of your loved ones. Today, we are going to discuss a recent addition to the blockchain ecosystem which is playing in the emerging space of inter-chain communications.\n\nPolkadot recently made news after completing a $140 million round to deliver on its promise of inter-blockchain interoperability. Polkadot approach is trying to prevent that the increasing fragmentation in the blockchain space becomes a roadblock for the evolution of the ecosystem. As more and more blockchains are implemented, Polkadot is attempting to become the channel that connects them all; an internet of blockchains or, as the industry names these new discipline, an inter-chain.\n\nThe reason for Polkadot\u2019s existence can be traced to a mismatch between the promises and reality of blockchain technologies. while, in theory, smart contracts should be able to interoperate from one blockchain to another, the reality has been that different blockchain stacks have relied on their own proprietary protocols creating a level of isolation with the rest of the ecosystem that prevents transaction to execute across different blockchains. Enter Polkadot, the platform\u2019s core focus is to enable authenticated transaction to execute seamlessly across blockchains.\n\nThe main idea behind Polkadot can be reduced to two main concepts: Parachains and Relay-Chains. In Polkadot, a Parachain is, essentially, a blockchain that is part of the network. Transactions between Parachains are coordinated using a Relay-Chain. While, the Relay-chain acts as a consensus coordinator between Parachains, the latter remains autonomy to validate and confirm transactions.\n\nIn order to enables its consensus model, Polkadot leverages Proof-Of-Stake mechanisms similar to Ethereum. Polkadot\u2019s consensus model uses an internal network token called DOT. In a Polkadot inter-chain, the owners of DOT tokens can vote on many decisions such as the validity of transactions or the addition or removal of Parachains.\n\nThe Polkadot architecture needs to coordinate transactions between heterogeneous topologies such as \u201chigh-value\u201d blockchains like Bitcoin or Ethereum with \u201clow-value\u201d private blockchains. Polkadot abstracts this diverse universe using four fundamental roles: Validators, Collators, Nominators and Fishermen.\n\nValidators are a key component of the Polkadot architecture responsible to operate a Relay-Chain client network. Transaction Collators are in charge of processing and confirming transactions in a similar way to how Miners work in Proof-Of-Work blockchains. Nominators typically place security bonds that indicate tryst on a specific Validator. Completing the Polkadot architecture, we have Fishermen which are components that are rewarded by detecting anomalies in the network. Polkadot combines these four fundamental components with innovative protocols that enable a simple and yet robust experience to the implementation of inter-chains.\n\nPolkadot is one of the key players in the emerging inter-chain space which is fairly new. However, we are already seeing some interesting alternative in that market segment. Cosmos is typically seeing as the main competitor of Polkadot. Ripple\u2019s dabbled into the space with its InterLedger Protocol which can be used as an interoperable channel between blockchains. Startups such as Aion or Lamden can also be considered competitors of Polkadot."
    },
    {
        "url": "https://medium.com/@jrodthoughts/knowledge-tuning-hyperparameters-in-machine-learning-algorithms-part-ii-2d5113d73a9c?source=user_profile---------103----------------",
        "title": "Knowledge Tuning: Hyperparameters in Machine Learning Algorithms Part II",
        "text": "This is the second part of an article that explores the role of hyperparameters in machine learning models. In the previous article, we presented the fundamental concepts behind hyperparameters and its relevance in validations ets. In this part, we are going to focus on the techniques for selecting and optimizing hyperparameters.\n\nThe process of selecting hyperparameters is a key aspect of any machine learning solution. Most machine learning algorithms explicitly define specific hyperparameters that control different aspects such as memory or cost of execution. However, additional hyperparameters can be defined to adapt an algorithm to a specific scenario. Data science technologists typically spend quite a bit of time tuning hyperparameters in order to achieve the best performance for a particular model.\n\nWhen comes to selecting and optimizing hyperparameters, there are two basic approaches: manual and automatic selection. Both approaches are technically viable and the decision typically represents a tradeoff between the deep understanding of a machine learning model required to select hyperparameters manually versus the high computational cost required by automatic selection algorithms.\n\nThe main objective of manual hyperparameter selection is to tune the effective capacity of a model to match the complexity of the target task. Imagine that you are training to climb Mount Everest. During the grueling training process, you want to subject your body to all sorts of routines so that it can perform on high altitude, low temperature and low barometric pressure situations. However, you don\u2019t want to push your body to an extreme that it might cause it to shut down. Similarly, you need to decide to carry enough provisions and tools to use in all sorts of unexpected situations but you also don\u2019t want to carry too much weight that can affect your agility on the mountain. In other words, the objective of the training process is to help you maximize your effective capacity for the task at hand.\n\nMachine learning models also have a notion of effective capacity. In that context, the effective capacity of a machine learning algorithm is determined by three main factors:\n\n1) The representational capacity of the algorithm or the set of hypotheses that satisfy the training dataset.\n\n2)The effectiveness of the algorithm to minimize its cost function.\n\n3)The degree on which the cost function and training process minimize the test error.\n\nSounds confusing? To see how these factors are related, let\u2019s select a deep learning algorithm with many layers and many hidden units. By definition, that type of model has a large representational capacity because it can easily model complex functions. However, our model might not be able to learn all those functions based on the constraints of the training set. Similarly, many of the potential functions might conflict with the model regularization strategies to minimize the test error. Tuning different hyperparameters is the key to find the optimal balance between those factors.\n\nOptimizing hyperparameter manually can be an exhausting endeavor. To address that challenge, we can use algorithms that automatically infer a potential set of hyperparameters and attempt to optimize them while hiding that complexity from the developer. Algorithms such as Grid Search and Random Search have become prominent when comes to hyperparameter inference and optimization."
    },
    {
        "url": "https://medium.com/@jrodthoughts/knowledge-tuning-hyperparameters-in-machine-learning-algorithms-part-i-67a31b1f7c88?source=user_profile---------104----------------",
        "title": "Knowledge Tuning: Hyperparameters in Machine Learning Algorithms Part I",
        "text": "Model optimization is one of the toughest challenges in the implementation of machine learning solutions. Entire branches of machine learning and deep learning theory have been dedicated to the optimization of models. Typically, we think about model optimization as a process of regularly modifying the code of the model in order to minimize the testing error. However, the are of machine learning optimization often entails fine tuning elements that live outside the model but that can heavily influence its behavior. Machine learning often refers to those hidden elements as hyperparameters as they are one of the most critical components of any machine learning application.\n\nHyperparameters are settings that can be tuned to control the behavior of a machine learning algorithm. Conceptually, hyperparameters can be considered orthogonal to the learning model itself in the sense that, although they live outside the model, there is a direct relationship between them.\n\nThe criteria of what defines a hyperparameter is incredibly abstract and flexible. Sure, there are well established hyperparameters such as the number of hidden units or the learning rate of a model but there are also an arbitrarily number of settings that can play the role of hyperparameters for specific models. In general, hyperparameters are very specific to the type of machine learning mode you are trying to optimize. Sometimes, a setting is modeled as a hyperparameter because is not appropriate to learn it from the training set. A classic example are settings that control the capacity of a model( the spectrum of functions that the model can represent). If a machine learning algorithm learns those settings directly from the training set, then it is likely to try to maximize them which will cause the model to overfit( poor generalization).\n\nIf hyperparameters are not learned from the training set, then how does a model learn them? Remember that classic role in machine learning models to split the input dataset in an 80/20 percent ratio between the training set and the validation set respectively? Well, part of the role of that 20% validation set is to guide the selection of hyperparameters. Technically, the validation set is used to \u201ctrain\u201d the hyperparameters prior to optimization.\n\nThe number and diversity of hyperparameters in machine learning algorithms is very specific to each model. However, there some classic hyperparameters that we should always keep our eyes on and that should help you think about this aspect of machine learning solutions:\n\n\u2014 Learning Rate: The mother of all hyperparameters, the learning rate quantifies the learning progress of a model in a way that can be used to optimize its capacity.\n\n\u2014 Number of Hidden Units: A classic hyperparameter in deep learning algorithms, the number of hidden units is key to regulate the representational capacity of a model.\n\n\u2014 Convolution Kernel Width: In convolutional Neural Networks(CNNs), the Kernel Width influences the number of parameters in a model which, in turns, influences its capacity.\n\nNow that we know the importance of hyperparameters, the next step is to learn how to optimize them. That will be the subject of the next post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cryptopolitics-the-irony-of-the-sec-tough-stand-about-icos-part-iii-historical-references-f4fa1823f938?source=user_profile---------105----------------",
        "title": "CryptoPolitics: The Irony of the SEC Tough Stand About ICOs Part III: Historical References",
        "text": "This is the third part of an essay that explores some of the ironies about the position taken by the U.S Securities and Exchange Commission regarding initial coin offerings(ICOs). Specifically, we compare the constrained potential damage that can be caused by ICOs with the high risks imposed by the virtually unregulated world of financial derivatives.\n\nThe first part of this essay provided some pragmatic metrics about ICOs compared to the massive market of financial derivatives. In the second article, we covered some of the history behind financial derivatives tracing it back to Scottish mathematician John Law and his rivalry with Isaac Newton . Following those two posts, I would like to explore some new perspective to the potential risks of financial derivatives compared to ICOs.\n\nAs mentioned in the previous articles, the biggest irony of the SEC position about ICOs has been to aggressively warn investors about the potential bad actors in the tiny ICO market while following a history of actively endorsing risky products( that share some commonalities with digital tokens) in the form of financial derivatives. Obviously, both things are not mutually exclusive. ICOs need and should welcome some regulation but they don\u2019t present a systemic threat to investors and financial markets. Financial derivatives definitely do. How bad van it get when derivative products go wrong? Let\u2019s review some of the most notable examples of crisis influenced by financial derivatives in the last few years:\n\n1)The Collapse Long Term Capital Management: One of the most hyped quant funds of all time, Long Term Capital Management(LTCM) included luminaries such as Nobel laureates Myron Scholes and Robert Merton(Black-Scholes formula fame). The fund focused on trading sophisticated derivatives products and posted impressive gains in its early years. However, in 1998, LTCM collapsed, and almost brought down the entire US financial system, when Russia defaulted on its bonds. It turns out that such a \u201cBlack Swan\u201d event was never considered in LTCM models.\n\n2)Financial Crisis: At the center of the 2008\u20132009 financial crisis, we have derivative products such as collateral debt obligations(CDOs) and credit default swaps(CDSs). Those type of products helped to shift risk between investors and created a massive expansion of money and credit which eventually was the genesis of the crisis.\n\n3) Flash Crash: In May 6 2010, the Dow Jones dropped 9% of its value over 1 hour wiping a TRILLION dollars off the U.S equity markets. Companies like Accenture traded at a few cents a share for a few minutes while others like Apple skyrocketed. Although the exact cause of the Flash Crash are still debatable, all hypothesis share a common denominator: derivatives.\n\n4) High Frequency Trading: Not an event itself, high frequency trading(HFT) is considered by many a Damocles sword hanging over financial markets. HFT is the channel by which many risky derivative products make it into the market by relying more on speed than on statistics or data intelligence. HFT has been constantly responsible for some of the irregular behavior in financial markets in the last few years.\n\nThe examples presented in these three articles are trying to convey the point that financial markets are constantly exposed to risks exponentially more dangerous than those created by ICOs. From that perspective, the position of the SEC results incredibly ironic. Additionally, the idea of classifying all ICOs are securities is questionable at best. I believe some level of regulation would be welcomed by the ICO community but I see no need for the paranoia created by recent statements which portraits ICOs as a bigger risk than they really are. In the long term, let\u2019s hope that rational minds prevails and that regulators learn to embrace the innovations behind ICOs that can help improve financial market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-oracle-ai-platform-cloud-service-delivers-machine-learning-the-oracle-way-d928a2fc20e3?source=user_profile---------106----------------",
        "title": "Technology Fridays: Oracle AI Platform Cloud Service Delivers Machine Learning the Oracle Way",
        "text": "Welcome to Technology Fridays! Today, I would like to discuss Oracle\u2019s new entrance in the machine learning space with its AI Platform Cloud Service.\n\nThe cloud platform market is becoming the ideal playground for machine learning applications. While platforms such as AWS ML, Azure ML or Google Cloud Ml have dominated the space in its initial iteration, customers has been long expecting Oracle\u2019s to become a relevant player when comes to enable machine learning applications. The reason for the high expectations? Very simple; the enterprise world runs on Oracle databases and perceives an Oracle Cloud-based, machine learning platform as a lower entry point into the data science space. The AI Platform Cloud Service is Oracle\u2019s answer to this very competitive field.\n\nDifferently from Oracle\u2019s traditional approach to launch proprietary application development technologies, the AI Platform Cloud Service represents an attempt to bring together the best machine learning stacks in the market using a consistent infrastructure and lifecycle management model. In that sense, the AI Platform Cloud Service allow developers to write programs using different deep learning frameworks such as TensorFlow, Keras or Caffe as well as tools like Jupyter, The support for Jupyter is particularly relevant as it allow developers to implement interactive notebooks that can seamlessly scale using Oracle Cloud\u2019s infrastructure.\n\nTo get started with Oracle AI Platform Cloud Service, developers can simply launch instances preconfigured with specific machine learning tools and frameworks. The AI Platform Cloud Service provides support for GPU architectures including novel technologies such as NVidia Pascal model for Tesla GPUs. Also, data science instances come pre-configured with technologies such as cuDNN and CUDA SDK.\n\nTo facilitate access to data sources, the integration with different data platforms such as Hadoop or Spark as well as mainstream databases. The platform also integrates with Oracle Cloud data services such s MySQL Cloud Service, Cloud Storage, Big Data Cloud Service, Database Cloud Service among several others. Similarly, the AI Platform Cloud Service leverages the Kafka-based Even Hub to enable low latency, high throughput communication between its components.\n\nApplication lifecycle management is one of the core capabilities of the Oracle AI Platform Cloud Service. Data scientists using the platform can train and test models using GPU-accelerated architectures. Once developed, AI models can be deployed to the platform infrastructure on which they can be scaled on-demand or even exported to be used in other runtimes. The development lifecycle can be started from different IDEs or from Oracle Cloud\u2019s command line interface.\n\nOracle AI Platform Cloud Service is entering the ultra-competitive market of machine learning cloud platforms. AWS ML and Azure ML were the first entrants in the space and have certainly captured relevant market share. Google Cloud ML excels at its support for TensorFlow applications while the Alibaba Cloud Machine Learning service enables applications built using different deep learning frameworks. Startups such as BitFusion or Floyd can also be considered competitors of the Oracle AI Platform Cloud Service."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cryptopolitics-the-irony-of-the-sec-tough-position-on-icos-part-ii-law-vs-newton-e8ce3709508b?source=user_profile---------107----------------",
        "title": "CryptoPolitics: The Irony of the SEC Tough Position on ICOs Part II: Law vs. Newton",
        "text": "This is the second part of an essay that presents some of the ironies of the fears about initial coin offerings(ICOs) presented by the U.S Securities Exchange Commission and its comparison with the world of financial derivatives. Although the SEC has been somewhat cautious about taking an official position about ICOs, its most notorious remarks have risen a warning about token offerings highlighting the risks that they could be regulated as securities.\n\nThe first part of this essay presented some statistics that demonstrated the relatively small harm that a collapse on ICOs can cause to financial markets. More importantly, I find it a bit ironic that the SEC is so outraged about ICOs when we are experiencing a market plagued with virtually unregulated financial derivatives that have been the cause of more than one financial crisis.\n\nThe purpose of this essay is not to trash financial derivative products. I am a big fan of derivatives and believe that quantitive trading has been one of the greatest innovations of financial markets. However, it is undeniable that the quadrillion dollar size market of financial derivatives is the biggest casino on earth.\n\nOne of the strongest arguments against digital currencies and token offerings is the fact that they are not backed by real tangible financial assets. Technically, that argument is somewhat flawed as the proof-of-work computation required to mine cryptocoins serves as the equivalent of an underlying asset but that\u2019s a debate for another post. A more interesting point to notice is that derivatives have built a quadrillion dollar markets out of sophisticated statistical models which have been the cause of every major financial crisis of the last 30 years. From that perspective, stressing about ICOs doesn\u2019t seem entirely logical.\n\nJust like digital tokens, financial derivatives don\u2019t operate backed by physical assets like gold or silver. Have you ever wondered where did the departure between monetary systems and precious metals started? Let me take you back to Scotland in the 1700s.\n\nIn 1705 the Scottish government was pushing for a union with the more powerful England. One of the leaders who opposed the union was a mathematician and an avid gambler named John Law. Considering that England\u2019s financial success was one of the main arguments in favor of the union, Law proposed the creation of a Scottish central bank and a new paper currency not backed by gold or silver but by the state. The Scottish parliament eventually rejected Law\u2019s proposal and the mathematician was forced to live the country and moved to France.\n\nParis in the 1700s was completely bankrupt after the lavish spending of Louis XIV the \u201cSun King\u201d. Law\u2019s ideas certainly resonated among the Parisian elite and he was quickly appointed Controller General of Finances by Philippe d\u2019 Orleans. The Scotsman rapidly proceeded to launch Banque Generale which issued a paper currency backed by gold and silver. At the same time, Law\u2019s created a company called The Mississippi Company (which had sort of a trade monopoly in the state of Louisiana) which issued paper notes that could be bought only using the currency issued by Banque Generale( sounds like an ICO? ;)). In 1718, Law\u2019s bank was nationalized and it was announced that the notes would no longer be redeemable by gold or silver. Law\u2019s maneuvers have finally succeeded decoupling money from precious metals.\n\nWith the state being able to literally \u201cprint money\u201d the French economy boomed and shares of The Mississippi Company went from 500 livres to over 10,000 livres. Eventually, the notes of the company finally collapsed and Law was forced to leave the country exiling in Venice when he became a celebrity.\n\nThe opposite of Law could be considered Sir Isaac Newton who during his tenure as Warden of the Mint of England worked tiressly to tie the British Pound to the \u201cgold standard\u201d. During Newton\u2019s years, currency counterfeiting in England was a crime punishable by death.\n\nThe difference between Law\u2019s and Newton\u2019s approaches are not about \u201cfake\u201d vs. \u201creal\u201d currencies but more about mathematics and finances ;) 300 years later, Law\u2019s ideas have been taken to a different level by the boom of statistical models and machine learning creating the world of financial derivatives. Just like the fall of The Mississippi Company, derivatives have been the cause behind massive crashes in the financial markets. More about that in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cryptopolitics-the-irony-of-the-sec-tough-stand-on-icos-part-i-bddf93a734c0?source=user_profile---------108----------------",
        "title": "CryptoPolitics: The Irony of the SEC Tough Stand on ICOs: Part I",
        "text": "A lot of speculation has surrounded the world of digital currencies about the potential regulation of initial coin offerings(ICOs) by the Securities Exchange Commission(SEC). Last week, the SEC, once again, presented a tough view on ICOs that indicates that ICOs might be headed towards a more regulated environment in the near future. Speaking at the Institute of Securities Regulation last week, SEC Chairman Jay Clayton went off script to volunteer his opinion about ICOs by saying \u201c I have yet to see an ICO that doesn\u2019t have the sufficient number of hallmarks of a security\u201d. With those remarks, Mr. Clayton suggested that the SEC clearly view ICOs as securities and could implement the corresponding regulatory measures. In this essay, I would like to explore the irony of that position.\n\nJust to clarify things before the polemic starts, the purpose of this essay is not to debate whether ICOs should be regulated or not. Personally, I think ICOs are in desperate need of a governance model and some form of regulation should be welcomed by the community. However, regardless of whether you agree with me or you are an ultra-libertarian who thinks that ICOs should fly free or a conservative pro-regulation who believes ICOs should be completely constrained this essay may be for you. The reason being is that, despite different sentiments about ICOs, I believe we can all agree that the position of the SEC results incredibly ironic. Where does the irony lies? Well, how about the fact that the SEC is talking tough about a tiny market such as ICOs while the, conceptually similar, market of financial derivatives which has been behind almost every recent crash remains largely unregulated.\n\nHow is the problem with ICOs. Maybe some numbers will put it into perspective. ICOs have raised a bit more than $3 billion this year. The whole market for cryptocurrencies is anywhere from $150 to $200 billion depending the market sentiment of the week. So if all goes to zero including Bitcoin( which is extremely unlikely), we are talking about the equivalent of a company like PayPal going under. Please don\u2019t get me wrong, $200 billions is a lot of money but is tiny from the perspective of the capitalization of financial markets. So the idea of teachers in Iowa loosing their savings in ICOs is a bit of a stretch. The vast majority of ICO investors are people with relevant holdings in Ethereum of Bitcoin who are \u201cexperimenting a bit\u201d. Yes, there are plenty of concerns about financial fraud and bad actors but those are common on any new financial vehicle and potential damage is relatively minor compared to other products.\n\nOne of the biggest concerns with ICOs and digital currencies is the fact that they are not backed by an underlying asset like gold. Let me please introduce you to the market of financial derivatives.\n\nJust like digital currencies and ICOs, quantitive derivatives are hardly backed by real financial assets. Every month, new exoteric derivatives enter the financial market shifting risk from one party to another. Behind those derivatives, we find incredibly sophisticated statistical models that almost impossible to follow by regulators. The size of that market? How about $1.2 quadrillions; that\u2019s 15 zeros or $1,200,000,000,000,000. Sounds big but a little comparison might help. Today, the market for derivatives is larger than the entire world\u2019s economy or 17 times larger than the market cap of the world\u2019s stock markets or 150 times the value of the world\u2019s gold supply. In case is still not clear, we are literally playing with vaporware. The result? From the demise of Long Term Capital Management to the financial crisis of 2008 to the flash crash of 2010, derivatives have been behind every recent crisis in financial markets. Ahh yes, because of its sophistication, the derivatives market remains largely unregulated despite the best efforts from the govement. Do you see the irony now?\n\nWhere did all started? That will be the subject of the next part of this essay. A little hit: it has to do with Sir Isaac Newton and a fellow names John Law. We will get from Newton to ICOs in the next few articles ;)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/my-model-knows-more-than-yours-part-ii-five-characteristics-of-high-quality-knowledge-1846394065f2?source=user_profile---------109----------------",
        "title": "My Model Knows More than Yours Part II: Five Characteristics of High Quality Knowledge\u2026",
        "text": "This is the second part of an essay that explores the factors that influence the quality of knowledge representation in machine learning models. Essentially, we are trying to answer a simple question: what makes a knowledge representation superior to others?\n\nIn the first part of the article, we revisited the No-Free-Lunch theorem and explained how generalization is the key element to high quality knowledge representations. Similarly, we discussed how, in order to reduce the generalization error, knowledge representations should be able to execute efficient regularization techniques. Today, I would like to dig a bit deeper into the specifics and review a five key regularization strategies that are relevant to improve representation learning models.\n\nJust to get the terminology straight, by regularization we are referring to the ability of a model to reduce its test error(generation error) without impacting its training error. Every knowledge representation has certain characteristics that makes it more prompt to specific regularization techniques. Artificial intelligence luminaries Ian Goodfellow and Yoshua Bengio have done some remarkable work in the area of regularization. Based on Goodfellow and Bengio\u2019s thesis, there are a few characteristics that make knowledge representations more efficient when comes to regularization. I\u2019ve summarized five of my favorite regulation patters below:\n\nOne of the key indicators of a robust knowledge representation is the fact that its features correspond to the underlying causes of the training data. This characteristic helps to separate which features in the representation correspond to specific causes in the input dataset and, consequently, help to better separate some features from others.\n\nRepresentation smoothness is the assumption that a value of a hypothesis doesn\u2019t change drastically among points in close proximity in the input dataset. Mathematically, smoothness implies that f(x = v) ==> f(x) for a very small v. This characteristic allow knowledge representations to generalize better across close areas in the input dataset.\n\nLinearity is a regularization pattern that is complementary to the smoothness assumption. Conceptually, this characteristic assumes that the relationship between some input variables is linear (f(x) = ax + b) which allows to make accurate predictions even when there are relatively large variations from the input.\n\nKnowledge representations based on hierarchies are ideal for many regularization techniques. A hierarchy assumes that every step in the network can be explained by previous steps which tremendously helps to better reason through a knowledge representation.\n\nManifold learning is one of the most fascinating, mathematically deep foundations of machine learning. Conceptually, a manifold is a high dimensional area of fully connected points. The manifold assumption states that probability masses tend to concentrate is manifolds in the input data. The great thing about manifolds is that they are relatively easy to reduce from high dimensional structures to lower dimensional representations which are easier and cheaper to manipulate. Many regularization algorithms are especially efficient at detecting and manipulating manifolds."
    },
    {
        "url": "https://medium.com/@jrodthoughts/my-model-knows-more-than-yours-representation-learning-and-knowledge-quality-part-i-f18d26ea670c?source=user_profile---------110----------------",
        "title": "My Model Knows More Than Yours: Representation Learning and Knowledge Quality Part I",
        "text": "Last week, we presented the notion of Transfer Learning as a way to create knowledge representations that could be transferable between different areas of a model. Transfer learning is a specific subset of a discipline known as representation learning which deals with structuring and optimizing knowledge in machine learning algorithms.\n\nIf you think about deep learning as a subset of machine learning, then representation learning is the domain in between. From that perspective, representation learning can be considered a subset of machine learning and a superset of deep learning:\n\nThe central problem of representation learning is to determine an optimal representation for the input data. In the context of deep learning, the quality of a representation is mostly given by how much it facilitates the learning process. In the real world, the learning algorithm and the underlying representation of a model are directly related.\n\nSo if the knowledge representation of a model is tied to is learning algorithm then selecting the correct representation should be trivial, right? We simply pick the knowledge representation associated with the learning task and that should guarantee an optimal performance. I wish were that simple. In the journey to find an optimal representation we quickly find an old friend: The No Free Lunch Theorem(NFLT).\n\nRemember NFLT? We discussed it in details a few weeks ago so I am not going to go deep into its details in this article. In a nutshell, NFLT states that, averages over all possible data generating distributions, every machine learning algorithm has approximately the same error rate when processing previously unobserved points (read my previous article about NFLT). In other words, no machine learning algorithm is better than any other given a broad enough dataset.\n\nIn the context of representation learning, NFLT demonstrates that multiple knowledge representations can be applicable to the learning task. If that\u2019s the case, how can we empirically decide on one knowledge representation vs. another? The answer is one of the core, and often ignored, techniques in machine learning and deep learning models: regularization.\n\nA core task of machine learning algorithms is to perform well with new inputs outside the training dataset. Optimizing that task is the role of regularization. Conceptually, regularization induces modifications to a machine learning algorithm that reduces the test or generalization error without affecting the training error.\n\nLet\u2019s now come full circle and see how regularization is related to representation learning. The relationship is crystal clear: the quality of a knowledge representation is fundamentally related to its ability to generalize knowledge efficiently. In other words, the knowledge representation must be able to adapt to new inputs outside the training dataset. In order to perform well with new inputs and reduce the generalization error, any representation of knowledge should be useful in regularization techniques. Therefore, the quality of representation learning models is directly influenced by its ability to work with different regularization strategies. The next step is to figure out which regularization strategies are specifically relevant in representation learning. That will be the topic of a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-driverless-ai-wants-to-bring-you-a-data-scientist-in-a-box-3eb227e1008b?source=user_profile---------111----------------",
        "title": "Technology Fridays: Driverless AI Wants to Bring You a Data Scientist in a Box",
        "text": "Welcome to Technology Fridays! Each week we try to deep dive into products that are revolutionizing emerging technology markets that sill remain under the radar. Today, I would like to focus on the self-service data science space through the lenses of the H2O.ai Driverless AI platform.\n\nImplementing machine learning or deep learning models remains a task constrained to advanced technologists or artificial intelligence(AI) researchers. Even more painful is the fact that, in real world scenarios, data scientists spend a fraction of their time implementing a model while a large percentage of the effort goes into complementarily areas such as data exploration, parameter tuning, model testing and other, let\u2019s say , more mechanical activities. Combine this with the generalized deficit in data science talent in the market and we get a glimpse of the challenges faced by most organizations. Not only data science talent is not available but it is often underutilized un tasks that can be better automated.\n\nDriverless AI is the latest addition to H2O.ai\u2019s popular machine learning suite. While the core of the H2O.ai platform it targeted to machine learning developers, Driverless AI focuses on non-AI experts. The platform democratizes the process of building machine learning models by providing sophisticated visual interfaces that automate many of the mechanical tasks in that type of solutions.\n\nFrom my own analysis, I believe the biggest contribution of Driverless AI is that while it abstracts the implementation of machine learning models it does so in a way that \u201ctreats AI researchers with respect\u201d. Here is what I mean: There are several platforms in the market that attempt to provide self-service solutions for creating machine learning models. However, despite their unquestionable simplicity, many of the models produced by those platforms are just too simplistic to be applied in real world scenarios. Driverless AI does provide point-and-click interfaces to implement machine learning models but also allow developers to deep dive into the underlying model and make the necessary optimizations.\n\nData exploration is one of the key capabilities of Driverless AI. The platform includes a component known as the Machine Learning Interpretability(MLI) that generates visualizations that identify patterns in datasets and explain machine learning models.\n\nThe balance achieved by the Driverless AI platform is partially the result of the friction between two of its components: AutoDL and AutoML. While the AutoDL stack is responsible for generating new features of a model, AutoML focuses on recommending machine learning algorithms and combine them into an ensemble of models that provide the best answer to the target problem (see my article about ensemble learning).\n\nTypically, a data scientist or developer will first use AutoDL to generate new features based on the attributes of a training dataset and perform other tasks such as optimizing the encoding of the attributes. After that, the new dataset can be processed by AutoML to discover and rank different machine learning models. Finally, the user can leverage MLI to interpret the models using different visualizations.\n\nDriverless AI provides first-class support for GPU runtimes which enables the scalability of the models. Additionally, the platform includes a large portfolio of machine learning algorithms which facilitates the implementation of highly sophisticated ensemble solutions. Finally, Driverless AI integrates seamlessly with the H2O.ai platform enabling the implementation of end-to-end machine learning experiences.\n\nDriverless AI is a welcomed addition to the nascent space of self-service machine learning platforms. Among its competitors, we can include technologies such as RapidMiner, BigML or DataIKU which provide similar capabilities. Technologies like the recently acquired DataRobot take a more developer-centric approach to enable a low touch experience for implementing machine learning models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-few-not-so-crazy-ideas-about-the-future-of-cryptocurrency-options-566e48fbdd86?source=user_profile---------112----------------",
        "title": "A Few Not So Crazy Ideas About the Future of Cryptocurrency Options",
        "text": "Options are coming to the world of Bitcoin and digital currencies. In the last few days, I\u2019ve published a couple of analyses about recent market developments that signal a more mainstream trajectory towards Bitcoin Options and Futures. Most notably, startup LedgerX recently received regulatory approval to start creating Bitcoin option contracts and the CME Group announced its intentions to start trading Bitcoin futures. With the prospect of Bitcoin options coming into the market, it is only logical to assume that new forms of derivatives and more sophisticated types of options will soon follow. How would those look like? That\u2019s the topic of today\u2019s post.\n\nMost people who follow financial markets are familiar with the classic type of option based on a call and put contracts. In that model, a call option is a contract that allows an investor to buy, at some point in the future, a specific share at a preset price. Similarly, a put option is a contract that allows an investor to sell a share in the future for a specified price. Using market terminology, the strike or exercise price is the price the investor sells or buys the option for. The expiration is the date on which the investor needs to exercise the option and the premium is the amount the investor pays upfront for the right to buy a share. While that traditional model for options is certainly the best established one is far from being the only one. Enter the world of quants and financial derivatives.\n\nQuantitive traders or quants have taken the financial market by storm building products that leverage statistics to price financial assets. The world of options and futures is quantland and, over the years, the market has seen the creation of many exoteric option contracts produced by the creative of quants. Many of those products are likely to find an equivalent in the world of digital currencies. Let\u2019s look at two well-known examples:\n\n\u2014 Up-and-Out Option: Suppose you believe that the price of a cryptocoin is going to increase but only in a limited way. The Up-and-Out call option works like standard call option in the sense that it pays off if the price of the underlying asset raises, but in the event of a drastic price increase, then a preset trigger activates and the option becomes worthless. Typically, the trigger level is set a level above the predicted price of the cryptocoin.\n\n\u2014 Multi-Asset Option: Intuitively, we associate options with a single type of assets such as Bitcoin. However, there are other types of options that pay off based on the behavior of multiple assets. For instance, in the digital currency world, we can envision a Multi-Asset option based on the best performing of the top 10 digital currencies.\n\nA Match Not Made in Financial Heaven\n\nThe world of Bitcoin and digital currencies is constantly subjected to speculative behavior by investors which causes regular volatility in the price of crypto assets. Combining digital currencies with exoteric financial derivatives can have unpredictable effects in the short term. However, some of the well known strategies for pricing options might help to add some stability to the price of digital currencies. More about that in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/best-of-enemies-some-thoughts-about-adversarial-training-71131daabfa8?source=user_profile---------113----------------",
        "title": "Best of Enemies: Some Thoughts About Adversarial Training",
        "text": "Training deep learning models is one of the fastest growing areas of innovation in the artificial intelligence(AI) ecosystem. Just like ew deep learning algorithms appear every month in research journals, new methodologies and techniques fro training models are an active area of research in the deep learning space. One of the disciplines that has been gaining a lot of momentum in that segment is known by the catchy name of adversarial training.\n\nTo understand adversarial training, it may be useful to rely on some analogies about how humans learn and master different skills. In many areas, knowledge training is drastically improved by creating regular and arbitrarily complex challenges. Let\u2019s take an example from the world of chess where a grandmaster can devote months to master the theory behind a specific opening that he or she is planning to use in an upcoming tournament. Despite his robust theoretical foundation, the grandmaster is likely to complement his preparations by playing numerous games against his trainign staff in which they are forced to look for \u201cnovelties\u201d or moves that fall outside the main line. In other words, his \u201cadversaries\u201d are contributing to improve his knowledge of the opening by introducing variation in the main knowledge base (opening theory).\n\nAnother more extreme example of adversarial training has transcended centuries. In ancient Rome, Emperor Nero became obsessed with assassinating his mother Agrippina which just happens to be Caligula\u2019s sister. You know, to make things more interesting. Knowing her son\u2019s intentions Agrippina decided to start drinking small portions of every poison available in order to build immunological defenses against a potential assassination attempt. Agrippina\u2019s methods help to teach her immune system how to build resiliency to the poisons by recognizing the effects they provoke in smaller doses. The strategy proved to be successful and Nero\u2019s attempt failed forcing him to rely on more traditional methods and asks some of his guards to slay her.\n\nThe metaphor of both examples is that we can constantly resolve to create adversarial situations in order to improve our knowledge of a specific domain. Adversarial training works in similar ways by introducing small variations to the input dataset creating new datasets that are likely to cause errors in the target model. In deep learning theory, we often refer to the modified input as the adversarial dataset. In practice, researchers have observed that even deep neural networks with 100% success rate with an input dataset can produce high error rates when using adversarial training.\n\nThere are many areas in which adversarial training is been widely applied today. The field of image classification is full of training models that add small vectors to the training dataset causing misclassifications in the original neural network. The modifications will be imperceptible to the human eye and the adversarial dataset will look identical to the original training set but the small linear variation will cause the classification model to regularly fail. Cybersecurity is another area that has notoriously benefited from the use of adversarial training as small variation in the code of a malware have been able to throw off the most sophisticated detection algorithms.\n\nMathematically, the success of adversarial training has been associated with the excessive linearity of many deep learning models. High dimensional, linear models are susceptible to produce large variations in the output when introducing small variations in the input."
    },
    {
        "url": "https://medium.com/@jrodthoughts/multitask-learning-and-the-art-of-knowledge-reusability-cc46533d3298?source=user_profile---------114----------------",
        "title": "Multitask Learning and the Art of Knowledge Reusability",
        "text": "One of the main differences between human and artificial intelligence(AI) agents is that the latter remain constrained to single tasks. I am not even talking about specific domains but about tasks within those domains. To this day, one of the greatest challenges of AI remains finding effective ways to reuse knowledge representations across AI models. In the deep learning theory, a small sub-discipline known as multitask learning is attempting to address that challenge.\n\nUsing the notion of a computational graph is a simple way to visualize deep learning models. In that representation, deep learning models typically have one input layer, a large number of hidden layers and an output layer. The outputs of one layers serve as inputs to other layers on the next level. Given the large number of nodes in each layer, reusing knowledge representations across them becomes both very appealing and really difficult. Not surprisingly, multitask learning has received a lot of attention among deep learning researchers and technologists.\n\nMultitask learning is a very broad term that encompasses a few different segments. Think about how humans reuse and apply knowledge. Sometimes, when performing a task, we apply knowledge we learn during a previous task. Other times, we need to adapt what is essentially the same knowledge and the same task to different domains. In the deep learning world, those variations of multitask learning are known as transfer learning and domain adaptation respectively.\n\nTransfer learning is a form of multitask learning that is applied when a model needs to perform different tasks and knowledge representations should be reused across those tasks. Let\u2019s consider the domain of language learning. When mastering a second or third language, we intuitively reuse many concepts or practices of our native language. Among languages that share similar origins, such as the ones coming from the Latin( Spanish, French, Italian, Portuguese\u2026) there are many commonalities in terms of syntax, ver conjugation, pronunciation, grammar and many other aspects. In a polyglot deep learning model, we can envision a transfer learning technique that reuses the knowledge representation from layers designed for one language and apply them on layers focused on another language.\n\nThe principle of domain adaptation are complementary to transfer learning in the sense that the target task remains fundamentally the same and what varies is the distribution of the input. Let\u2019s move our examples to the field of image analysis and take an algorithm that recognizes objects such as shoes, handbags or dresses in fashion designer pictures. Typically, those images include a model posing with the target items. On another scenario, we would like to build a model that recognizes the same objects(shoes, handbags and dresses) in images of social events that include multiple people each one wearing different items. Whether the knowledge created by the first model can clearly be applied in the second scenario, it would have to be represented in a way that can be generalized across both domains (fashion vs. social pics). That\u2019s the role of domain adaptation.\n\nWe can imagine that multitask learning will be an essential element in the quest towards achieving general AI. In many modern deep learning frameworks, there are some distinctions between transfer and multitask learning. Notably, transfer learning is mostly used in relationship with supervised models while multitask learning can be applied to both supervised and unsupervised algorithms."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-bitcoin-futures-ea4c44384883?source=user_profile---------115----------------",
        "title": "Some Thoughts About Bitcoin Futures \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, I published an article about the viability of Bitcoin Exchange Traded Funds(ETFs) as a vehicle to bring digital currencies to financial exchanges and institutional investors. One of the points I mentioned in that article was that the creation of Bitcoin options could be a strong move towards the implementation of an ETF. Well, it seems that we are getting even closer.\n\nA few hours after my article, the CME Group Inc announced its plans to launch a futures contract based on Bitcoin. The CME Group is the biggest exchange group in the world and has a long-established reputation for innovating in options and futures products. Needles to say that the announcement represents one of the strongest endorsements of the cryptocoin to this day and it helped push its price passe the $7000 level.\n\nThe creation of Bitcoin Futures can become one of the pivotal moments in the history of Bitcoin. In addition to having the biggest options house in the world staking its reputation behind Bitcoin, Futures are likely to be the vehicle by which institutional investors get a more analytical exposure to Bitcoin. The CME vote of confidence can also have profound implications for the near term price of Bitcoin. Let\u2019s explore those ideas and some other perspectives about how Bitcoin Futures can impact \u201cthe future\u201d of Bitcoin. See what I did there? ;)\n\nToday, Bitcoin remains almost exclusively a \u201clong trade\u201d. There is not easy way for investors to bet on the decline of the price of the cryptocurrency (read my article about this subject). Futures will allow long investors to buy contracts based on a predicted increase of the price of Bitcoin while short investors can purchase contracts that bet on a price drop. This is effectively a way to short Bitcoin.\n\nA side effect of the previous point cab help to bring some stability or predictability to the price of Bitcoin. Future contracts match the expectations of long and short investors. Investors can use Bitcoin Futures as a pragmatic data point about the market\u2019s view of the cryptocoin which should help to set a baseline for investments. Similarly, if the price of Bitcoin starts raising, short investors will be forced to cover their positions which will create automatic resistance levels.\n\nTrading Bitcoin Futures on the CME Exchange will setup the foundation for more sophisticated trading models involving Bitcoin. The futures model can/will be used in advanced trading strategies that can include Future contracts of other securities, commodities and other financial artifacts.\n\nCME is not the only accredited financial exchange planning to launch a Bitcoin Futures product. Cboe Global Markets Inc. also announced that is working on a Bitcoin Futures contract to be launched at the end of 2017 or early 2018. If those attempts receive positive traction, other exchanges should soon follow.\n\n5 \u2014 Futures for Other Digital Currencies and Tokens\n\nIf either CME or Cboe is successful with their respective Bitcoin Futures product, that should open the door to similar Futures contracts for other digital currencies such as Ether, Dash or LiteCoin. Down the road, Future Contracts can also be applied to digital tokens launched via initial coin offerings(ICOs)."
    },
    {
        "url": "https://medium.com/@jrodthoughts/practical-deep-learning-these-metrics-will-help-evaluate-the-performance-of-your-deep-learning-5cbe0edcde61?source=user_profile---------116----------------",
        "title": "Practical Deep Learning: These Metrics Will Help Evaluate the Performance of Your Deep Learning\u2026",
        "text": "One of the most difficult tasks in deep learning applications is to establish and evaluate the performance metrics of a model. In the deep learning world, perfection is often not a feasible objective so establishing clear performance metrics is fundamental to establish the behavior of a model.\n\nThe process of selecting performance metrics for a deep learning algorithm is far from trivial. To begin with, we are not talking about a single metric but rather a collection of them. While training processes can use well-established metrics such as cost-functions, the story is fairly different when comes to evaluate the runtime behavior of a model.\n\nMany times we refer to the performance of a model using the notion of accuracy as a metric that should reflect the percentage of cases in which a model produces the right answer. However, accuracy is often a misleading metric because, as we know all too well, some errors are most costly than others.\n\nLet\u2019s take the example of a deep learning that attempts to predict voter fraud. The algorithm will be a binary classifier that will process individual votes and classify them as legit or fraudulent. Clearly, the cost of an error that flags a fraudulent vote as legit is bigger than a similar error that marks a legit vote as potentially fraudulent (some countries might disagree but you get the idea ;) ). Support that our model processes a million votes and misses 100 fraudulent votes. Clearly the accuracy of the model is pretty high but most likely our model won\u2019t be used in real elections any time soon :).\n\nOne way to address the accuracy fallacy is to introduce two metrics known as precision and recall. Precision is the fraction of correct results produced by a model while recall is the fraction of true events that were detected. In our example, a binary classifier that predicts all votes to be legit has perfect precision but poor recall. Similarly, if the system claims that all votes are fraudulent will have perfect recall while precision will be the real percentage of fraudulent votes.\n\nThe relationship between precision and recall is typically reflected in a two-dimensional graph with precision metrics displayed in the y-axis and recall\u2019s in the x-axis. That chart is known as the Precision-Recall or PR Curve as is one of the most important visualizations to understand the performance of deep learning models. Using the PR Curve allow us to adjust the model trading precision for recall and vice versa. Ultimately, we are trying to quantify the area beneath the curve which can be calculated using the following expression:\n\nThis metric is known in deep learning theory as the F-Score and is often used in deep learning frameworks.\n\nAnother very useful metric in deep learning is the notion of coverage. This metric qualifies the fraction of examples for which the system is able to produce a response. Coverage is particularly useful in scenarios in which deep learning models can often produce no response. By conventional measures, a system can have high accuracy by producing a very small number of correct response but its coverage will be very low."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-interesting-developments-are-paving-the-way-for-a-bitcoin-etf-a4ca449e5c81?source=user_profile---------117----------------",
        "title": "These Interesting Developments are Paving the Way for a Bitcoin ETF",
        "text": "Exchange Traded Funds(ETFs) have become one of the most popular investment vehicles in today\u2019s financial markets. In the last 18 months, many investors have gravitated towards all kinds of ETFs as an alternative to more traditional vehicles such as hedge funds which(as a group) have regularly underperformed the market. ETFs have long been seen as a logical model to create a bridge between traditional investors and the digital currency community. While the attempts to create a Bitcoin ETF have not succeeded there have been a couple of interesting new developments that might help to warm the heart of the US Securities and Exchange Commission(SEC) towards the new investment model.\n\nThe most famous attempt to create a Bitcoin ETF came from Cameron and Tyler Winklevos last March. At the time, the SEC rejected the proposal citing that \u201csignificant markets for Bitcoin are unregulated\u201d. Before and after the SEC decision, I wrote extensibly about the market implications of a Bitcoin ETF and you can find the articles in this blog. Has anything changed since March? Well, not directly but there are a couple of new developments that are making a strong case for a Bitcoin ETF.\n\nETFs mostly trade financial products using derivatives. The common wisdom in financial markets is that if a derivative exists for an asset, then it should traded in an ETF. Derivatives are a relatively simple financial product to assemble but its been notoriously in the Bitcoin ecosystem. Until now\u2026\n\nRecently, cryptocurrency startup LedgerX won approval from the US Commodity Futures Trading Commission(CFTC) to start offering options based on Bitcoin. The approval opens the door to the creation of Bitcoin-based options and futures contracts which are two of the most important products used by investors to hedge positions. From there to an ETF is not a very long road.\n\nThere is a strong correlation between ETFs and Index Funds. In the case of Bitcoin and other digital currencies, the market has not yet created indices that can be used as a single investment vehicle. Now a company called Bitwise Investments is trying to change that dynamic.\n\nCalled the HOLD Index, the new Bitwise Investments Fund is designed to hold the top 10 digital currencies by market cap. Based on the current market, the initial version of the HOLD 10 includes the following currencies: BTC, ETH, XRP, BCH, LTC, DASH, NEO, ZEL, XMR AND ETC. Index funds are a great vehicle for passive investors that would like to protect their exposure to individual cryptocurrencies. This is another financial products that could influence the creation of a Bitcoin ETF.\n\nMaybe the most important factor that can trigger the creation of a Bitcoin ETF is the increasing demand for it in the investor community. Despite the increasing popularity of ETFs as an investment model, they haven\u2019t seen a lot of innovation in terms of their core product. Something new it would be certainly welcomed in the ETF world."
    },
    {
        "url": "https://medium.com/@jrodthoughts/practical-deep-learning-debugging-techniques-bbb5e7640dfb?source=user_profile---------118----------------",
        "title": "Practical Deep Learning: Debugging Techniques \u2013 Jesus Rodriguez \u2013",
        "text": "Building deep learning solutions in the real world is a journey full of challenges. Most of us are familiar with the difficulties finding sophisticated talent with enough understanding of deep learning algorithms and technologies. However, the challenges of implementing deep learning solutions expand way beyond the deficit technical talent.\n\nDuring the implementation of a real world deep learning program, technologists are constantly faced with roadblocks in areas such as training, optimization, model capacity management, testing and many other unconventional aspects that don\u2019t appear natural to mainstream developers. Among the areas that require a careful strategy during the implementation of deep learning systems, debugging stands out on own as one of the challenges capable of driving the most skillful technologists absolutely crazy.\n\nIn one word: unpredictability. When we write static code for a web or mobile application we know the expected behavior of every algorithms as this one is determined by the code itself. In the case of deep learning applications, the behavior of the algorithm is determined by the knowledge built during training instead of by static code. For instance, wif we train a convolutional neural network(CNN) and it achieves 3% error rate, its practically impossible to understand whether the behavior has been optimal or not without a deep analysis.\n\nTo the unpredictability challenges, we should add the fact that most deep learning models produced neural networks with hundreds of thousands or millions of nodes and many hidden units which makes debugging nothing short of a nightmare. Not surprisingly, despite great tools such as TensorFlow\u2019s TensorBoard, the tools and frameworks for debugging deep learning models are still in their infancy. So what do we do in order to effectively debug deep learning programs? There are a few tips that might help.\n\n1 \u2014 Visualize the Network and its Results\n\nA pretty obvious point. When building a deep learning application, it is imperative to leverage tools that can help to visualize the connected graph and the results of the model based on certain inputs. This will give developers a visually intuitive way to reason through the model and try to understand the behavior of the algorithms.\n\nThe training and test errors in a deep learning model can offer helpful clues about potential problems before they occur. For instance, if a model is overfitting( test error is high) but the training error remains low, then is likely that there are errors in the algorithm. However, if the training error is high then the model is underfitting and we are likely to find an error in the training procedure.\n\nBuilding on the previous point; if a model is underfitting, we need to determine whether is a code or data defect. A way to achieve that is to test with a very small number of examples. If the model fails, then it is most likely due to issues with the code.\n\nKeeping an eye on the activations of hidden units and the values of the gradients are essential measures to optimize a deep learning model. The number of node activations are an important metric to understand if a neural network is saturated. Similarly, getting a histogram view of the value of the gradients is a super helpful technique to understand the potential for future optimizations in the model."
    },
    {
        "url": "https://medium.com/@jrodthoughts/maai-the-frightful-4-of-enterprise-tech-ac0b83df47b4?source=user_profile---------119----------------",
        "title": "MAAI: The Frightful 4 of Enterprise Tech \u2013 Jesus Rodriguez \u2013",
        "text": "There is an interesting series of recent article in the New York Times(NYT) that describes how Apple, Facebook, Alphabet, Microsoft and Amazon are embattled in a race to dominate consumer technology markets. The NYT column refers to this group of companies as the frightful 5. If we look at the enterprise software space, we can identify similar signs of how Microsoft, Alphabet, Amazon and IBM( yes IBM!) are aggressively trying to lead on every emerging technology market. Let\u2019s call this group \u201cThe Frightful 4 of Enterprise Tech\u201d or MAAI.\n\nPick your favorite emerging enterprise technology space: internet of things(IOT), artificial intelligence(AI), blockchain, virtual reality or even quantum computing and you are going to see clear the MAAI group among the leaders in each space. Without exception, the MAAI companies have been able to defy market rational and rapidly innovate their way to market leadership in every single emerging technology space. What are the specific market patterns and dynamics influencing the frightful 4 and what can we expect in the near future? There are a few observations about this topic that I think are worth debating:\n\nOne key reason why the MAAI group has been able to expand so efficiently into new technology markets is because of their dominance in the cloud platform space. Cloud is the main delivery channel for new technologies such as AI, IOTA, blockchain or quantum. At the same time, most enterprise are likely to be running the workloads of new solutions on MAAI\u2019s clouds considering that those cloud platforms amount to over 85% market share. Consequently, it is very tempting for enterprises to embrace new technologies running on an infrastructure they are very comfortable with.\n\n2 \u2014 M&A Fever: The Cost Gap Between Building and Acquiring\n\nWhat do trends like AI, IOTA, blockchain, VR or quantum have in common? They require hard core computer science skills and they take time and resources to build. Starting in those markets typically require large amounts of venture capital in order to execute and get to critical mass. On the other hand, the balance sheets of the MAAI companies seem to be getting richer every earning season(except maybe, IBM) which has triggered an increase on M&A activity closing the door to new players to be able to compete with the MAAI group.\n\n3 \u2014 IBM the Pioneer, Microsoft Brings the Tools, Alphabet and Amazon the Infrastructure\n\nIBM research labs have been busy in the last decade. In almost every emerging tech market ( think AI, IOTA, blockchain and quantum), IBM has been first to market before facing competition from the rest of the MAAI group. The patterns become even more intriguing. In almost all markets, Microsoft has been able to lead by building impressive toolsets that lower the enterprise developers. similarly Alphabet and Amazon have excelled at building massive infrastructures to scale emerging tech applications. We can see those patterns playing forward in other emerging technology trends.\n\nIts becoming increasingly hard for startups to compete with the big research arms of the MAAI companies. Consequently, the MAAI group continues pushing the market into new areas and innovating more consistently than the competition.\n\n5 \u2014 MAAI Soon Could be MAAAI\n\nWhat company could soon join the MAAI group? I will give you a hit: is not SAP, Oracle or even Salesforce. Alibaba seems to be uniquely positioned to expand its relevance into emerging tech markets. A fast growing cloud platform(Alyun), a dominant position in the Asian market, an impressive R&D budget and a super healthy balance sheet seem to be the right ingredients to propel Alibaba to the MAAI group which could soon be MAAI."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-azure-ml-workbench-wants-to-be-the-entry-point-for-your-machine-learning-apps-1f76e5ac9666?source=user_profile---------120----------------",
        "title": "Technology Fridays: Azure ML Workbench Wants to be the Entry Point for your Machine Learning Apps",
        "text": "Welcome to Technology Fridays! Today I would like to continue exploring some of the recent additions to the Azure Machine Learning(ML) stack. specifically, I would like to cover the Azure ML Workbench toolset.\n\nAzure ML Workbench was created to streamline the implementation of machine learning solutions across different frameworks and tools. Sounds trivial? Don\u2019t rush to that conclusion. It turns out that the explosion of development tools and frameworks in the machine learning space has exponentially increased the complexity of the effort required to implement end-to-end solutions. In real machine learning implementations, coordinating a data routines with a Jupyter notebook interactive model with the testing and lifecycle management of your code in a Git repository is fairly complex. Now multiply that complexity by the number of machine learning tools and frameworks in the market and you get a picture of the challenge that Azure ML workbench is trying to solve.\n\nAt its core, Azure ML Workbench is a desktop application and a series of a command line tools that attempt to simplify the development lifecycle of machine learning applications. To some extent, Azure ML Workbench can be seen as the entry point and command-control center of your machine learning solution regardless of the underlying technology stack.\n\nFunctionally, Azure ML workbench provides a series of capabilities that simplify different areas of the implementation of machine learning programs. For instance, the platform streamlines data preparation tasks by providing a tool that itself leverages machine learning to infer data transformation routines. Similarly, ML Workbench Python SDK enables the execution of those data transformation packages using a very simple programming model.\n\nThe integration with other tools and frameworks is the hallmark if Azure ML Workbench. A prime example of this capability is the platform\u2019s support for Jupyter notebooks. Developers using ML Workbench can launch a Jupyter server directly from the application and start creating interactive notebooks. Additionally, ML workbench offers the ability of selecting Jupyter Kernels from pre-configured runtimes that include integration with technologies such as Azure HDInsight. In addition to Jupyter, ML Workbench provides integration with several deep learning frameworks such as TensorFlow, Microsoft Cognitive Toolkit, Chainer and many others.\n\nThe interoperability with Git is another key area of innovation of Azure ML Workbench. Any Azure ML Workbench project can be linked to a Git repo and enabling capabilities such as versioning or source control without abandoning the application environment. Not surprisingly, ML Workbench provides a first class integration with VSTS . ML Workbench also streamlines the implementation of machine learning models by suing the Team Data Science Process Templates as well as the integration with different IDEs such as Visual Studio Code or PyCharm which are among\u2019s developers favorites when comes to building machine learning programs.\n\nAzure ML workbench is a very unique solution in the machine learning space. The development toolset of platforms such as H2O.ai or cloud runtimes like DataBricks bears some similarities with ML Workbench but, for the most part, the offering represents a strong differentiator when comes to evaluating the Azure ML stack."
    },
    {
        "url": "https://medium.com/@jrodthoughts/convolutional-neural-networks-for-the-rest-of-us-part-iii-architectures-c4a10a44ce6a?source=user_profile---------121----------------",
        "title": "Convolutional Neural Networks for the Rest of Us Part III: Architectures",
        "text": "This is the third and final( yaaaay :) ) essay discussing the principles of convolutional neural networks(CNNs) in deep learning solutions. The first part provided an overview of CNN and some of the mathematical ideas behind them. The second essay focused on some of the benefits of CNN models compared to traditional neural networks. If by now you are convinced about the advantages of CNNs then let\u2019s discuss how to you use them in deep learning models.\n\nTypically, CNN are not used as a standalone algorithm in deep learning models. Instead they are often combined with other algorithms in order to implement complete deep learning solutions. It is also important to notice that a single deep learning model can have many convolution operations sometimes executed in parallel. This is typically due to the fact that convolution operations using a single kernel(one of the tensor parameters of the convolution function. Read part I) is likely to only be effective extracting a single feature. Ideally, we would like to architect deep neural networks in a way in which each layer is able to extract multiple features.\n\nFrom the architecture standpoint, CNN layers can be seen as a combination of three fundamental stages:\n\nThe first two stages are relatively trivial to explain while the third one requires some fait in the magic of statistics :).\n\nThe convolution stage executes a series of convolution operations in order to extract specific features. As mentioned before, many of those convolution operations are scheduled in parallel in order to provide the expected linear activations.\n\nIn this stage, the linear activations produced by the convolution tier are ran through a series of non-linear activation functions like the rectified linear activation. The purpose of this stage is to produce a non-linear out that that facilitates the use of statistical functions.\n\nThe pooling stage is the most complex component of a CNN architecture. Conceptually, pooling stages are a combination of pooling functions applied to the non-linear output produced by the Detector Stage. What is a pooling function then ?\n\nA pooling function is a mathematical operation that attempts to minimize the statistical error of the output. Pooling functions replace a specific input with the output of a statistical function that aggregates points closer to the original input. For instance, a popular pooling function in deep learning models replaces a specific data point with the average of values in a rectangular neighborhood.\n\nRemember the equivariance property of convolution operations? (read part II). Well, pooling functions make their output consistent despite small changes in the input. That property is known as invariance and is one of the most important characteristics of CNNs.\n\nSo there you have, when evaluating CNN model remember to think about in three stages: convolution, detector and pooling. I hope you found the information useful."
    },
    {
        "url": "https://medium.com/@jrodthoughts/convolutional-neural-networks-for-the-rest-of-us-part-iii-benefits-and-motivation-d84cd72f5670?source=user_profile---------122----------------",
        "title": "Convolutional Neural Networks for the Rest of Us Part III: Benefits and Motivation",
        "text": "This is the second part of an essay that explained the fundamentals of convolutional neural networks(CNNs). The first part detailed some of the main concepts behind CNNs an presented a few analogies based on real world scenarios. Continuing the journey, this article will focus on some of the main benefits and motivations behind CNNs when applied to deep learning architectures.\n\nCNNs are a key element of modern deep learning technologies. If you have been actively using frameworks such as TensorFlow, Caffe2, Theano or any of the dozens of new deep learning frameworks in the market, chances are that you have already encountered CNNs in some form or fashion. From that you should wonder what are the specific benefits that have made CNNs so popular compared to other neural network alternatives?\n\nThe main motivation behind the emergence of CNNs in deep learning scenarios has been to address many of the limitations that traditional neural networks faced when applied to those problems. When used in areas like image classification, traditional fully-connected neural networks simply don\u2019t scale well due to their disproportionally large number of connections. CNNs bring a few new ideas that contribute to improve the efficiency of deep neural networks. Let\u2019s explore a few of those some of the fundamental principles leveraged by CNNs:\n\nLet\u2019s assume that you are working on an image classification problem that involves the analysis of large pictures that are millions of pixels in size. A traditional neural network will model the knowledge using matrix multiplication operations that involve every input and every parameter which results easily in tens of billions of computations. Remember that CNNs are based on convolution operations between and input and a kernel tensors? Well, it turns out that the kernel in convolution functions tends to be drastically smaller than the input which simplifies the number of computations required to train the model or to make predictions. In our sample scenario, a potential CNN algorithm will focus only on relevant features of the input image requiring fewer parameters to use in the convolution. The result could be a few billion operations smaller and more efficient than traditional fully-connected neural networks.\n\nAnother important optimization technique used in CNNs is known as parameter sharing. Conceptually, parameter sharing simply refers to the fact that CNNs tend to reuse the same parameters across different functions in the deep neural network. More specifically, parameter sharing entails that the weight parameters will be used on every position of the input which will allow the model to learn a single set of weights once instead of a different set for every function. Parameter sharing in CNNs typically results on massive savings in memory compared to traditional models.\n\nEquivariance is my favorite property of CNNs and one that can be seen as a specific type of parameter sharing. Conceptually, a function can be considered equivariance if, upon a change in the input, a similar change is reflected in the output. Using a mathematically nomenclature, a function f(x) is considered equivariant to a function g() if f(g(x))= g(f(x)). It turns out that convolutions are equivariant to many data transformation operations which means that we can predict how specific changes in the input will be reflected in the output.\n\nThese are some of the main theoretical benefits behind CNNs. In the next part of this series we will review specific CNNs architectures that are commonly used in deep learning models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/convolutional-neural-networks-for-the-rest-of-us-4a9e6182441e?source=user_profile---------123----------------",
        "title": "Convolutional Neural Networks for the Rest of Us \u2013 Jesus Rodriguez \u2013",
        "text": "With the rapid raise of deep learning, we are constantly seeing how several academic terms are used by the mainstream media without providing any insights into the concepts which ends up causing a lot of confusion. Convolutional neural networks(CNNs) is one of those theoretical terms that you can regularly find in deep learning articles which can result confusing for the average reader. Without going too deep into the theory, I thought I\u2019d take a swing at explaining some of the concepts behind CNNs and how they relate to deep learning applications.\n\nCNNs have come to popularity with the emergence of computer vision scenarios. However, the theory behind CNNs dates back to the late 1980s. Conceptually, CNNs are a specific type of neural network that relies on a mathematical operation called convolution. In simple terms, a convolution is an operation between that involved two tensors( multi-dimensional arrays) known as input and kernel respectively. The objective of the convolution operation is to produce a new tensor that simplifies the noise in the input. In the context of deep learning models, convolutions can help to improve the computation model of a neural network. Typically, CNNs used convolution as amore efficient alternative to matrix multiplication operation across nodes.\n\nIf you are already confused do not feel bad ;); these concepts are really complex to explain outside the realm of mathematics. Let\u2019s try to use an example to put CNNs in a real world context. Support that we are monitoring an oil field using a large number of sensors. Each sensor produces telemetry data about different parameters such as temperature, terrain density, wind speed and many other relevant metrics. The measurements are produced every few millisecond but they can be all over the place because the weather conditions in the region affect the accuracy of the sensors. In other words, the data is noisy. To try to estimate more accurate telemetry information we can try to calculate averages of the data produced by sensors in the same area. However, that technique is not very effective as it assumes that all sensors in all areas are equally accurate regardless of their historical performance which is rarely the case in the real world. Alternatively, we can introduce a more sophisticated operation that uses weights and other statistical artifacts on the data. That\u2019s called a convolution in which the original telemetry dataset is the input and the weighted tensor in the kernel.\n\nFrom a historical standpoint, CNNs are, arguably, the most efficient type of deep learning model inspired by functions of the human brain. More specifically, CNNs have been inspired by the vision system in humans and other mammals.\n\nThe human brain contains an area known as the primary visual cortex(PVC) that a key element of our vision system. Anatomically, PVC receives visual signals from the optic nerve, responds to specific stimulus and passes the responses to other areas of the visual system. PVC\u2019s network structure as well as its different type of neurons were the historic inspiration for the creation of CNNs. Structurally, the PVC region is organized as a spatial map that mimics the retina guaranteeing that only specific areas are activated based on individual signals. CNNs are typically organized as two-dimensional maps that emulates PVC\u2019s structure. similarly, the response of certain neurons in the PVC region is not affected by minor change in elements of the input signal such as lighting and position. CNN\u2019s leverage the convolution operation to achieve the same goal.\n\nThis should give you a basic idea of the goals, mathematical concepts and historical influences behind CNNs. In the next part of this article, we will deep dive into CNNs from the context of deep learning models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/no-data-no-problem-some-thoughts-about-dataset-augmentation-in-deep-learning-solutions-957ce4a4da2d?source=user_profile---------124----------------",
        "title": "No Data, No Problem: Some Thoughts About Dataset Augmentation in Deep Learning Solutions",
        "text": "Deep learning models are only good as the quality of their training dataset. Many times people fall into the trap of thinking that all challenges in a deep learning model can be solved with additional training. The reality is that, in many scenarios, data is simply not available or in very poor quality. So what do you do when there is no data? Fake it :)\n\nDataset augmentation is a very popular technique in modern deep learning solutions. The premise of dataset augmentation is to create artificial data records and add them to the training set in order to improve the training processes. How is that even possible? If we train a model with \u201cnon real\u201d data it should produce the wrong results , shouldn\u2019t it? Well, not really. By fake data we don\u2019t mean any fake-fake data :) Think about it like a sophisticated forgery of a painter\u2019s masterpiece. It turns out that, in many deep learning scenarios, the results of a deep learning algorithm don\u2019t change drastically with small variations in the training data. From that perspective, it is relatively trivial to augment the training dataset by introducing small variations of the original data.\n\nTraditional deep learning tasks such as image recognition or speech analysis have been some of the greatest beneficiaries of dataset augmentation. High dimensional images are based on many factors that are mathematically simple to simulate. For instance, shifting a few pixels of an image on a different direction doesn\u2019t really alter the results of many image recognition algorithms. Obviously, there are many variations of images that are impossible to accomplish by adding simple pixel transformations which makes dataset augmentation impractical for those use cases.\n\nDo you remember the chaos monkey techniques that are widely used for testing large distributed software applications? The principle is to increase the robustness of an architecture by introducing arbitrarily failure conditions. Well, noise injection can be seen like a distant cousin of chaos monkey techniques but applied to knowledge building scenarios.\n\nNoise injection is a form of dataset augmentation that attempts to increase the robustness ot deep neural networks by introducing random noise in the training data. In the case of deep learning models, noise injection techniques are not only constrained to the input data but they are also regularly applied to the input of the hidden nodes and, in some extreme scenarios, to the output data.\n\nDataset augmentation can have a profound impact on the performance of deep learning models. As a result, it is recommended to keep very accurate measures about specific data transformations and their impact in the performance of the model. Many times, improvements on the output of a deep learning algorithm are based on augmentation of the training dataset instead of improvements in the model itself. Quantifying the impact of specific dataset augmentations is key to understand the runtime behavior and improve the training of deep learning models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-azure-ml-model-management-brings-devops-to-the-machine-learning-world-6e633ab8e0cb?source=user_profile---------125----------------",
        "title": "Technology Fridays: Azure ML Model Management Brings DevOps to the Machine Learning World",
        "text": "Welcome to Technology Fridays! A few days ago, I wrote about the release of three new additions to the Azure Machine Learning(ML) stack that improve the lifecycle management of machine learning solutions. Today, I would like to deep dive into one of those recent releases Azure ML Model Management.\n\nIn recent years, we\u2019ve seen an explosion on the number of machine learning and deep learning frameworks and platforms that enable the implementation of machine intelligence solutions. However, the tools for training, management and operating machine learning applications at scale have no evolved at the same pace. Not surprisingly, most organizations rely heavily on human-centric processes when comes to deploying and executing mission-critical machine learning workloads.\n\nAzure ML Model Management is a platform that enables the automation and lifecycle management of machine learning workflows. The platform brings a set of much-needed devops capabilities to the Azure eML ecosystem.\n\nDeployment is, arguably, the area in which Azure ML Model Management innovates the most. Moving away from the traditional proprietary runtime approach adopted by most cloud ML platforms, Azure ML Model Management enables the generation of Docker containers that encapsulate ML models and its dependencies. Those containers can be run locally or deployed to Docker runtimes such as the Azure Container Service. Using Azure ML Model Management, devops can leverage the emerging Kubernetes tool ecosystem to create highly sophisticated deployment workflows for machine learning programs. Additionally, containers generated using Azure ML Model Management include all necessary dependencies so that they can also be deployed to other Docker-Kubernetes cloud runtimes such as AWS or Google Cloud Container Services.\n\nModel instrumentation and tracking are two other key capabilities of the Azure ML Model Management platform. Devops can configure automated logging and telemetry settings that can be used not only to evaluate the runtime behavior of ML algorithms but also to improve its future training. The telemetry information collected its streamed to the Azure Application Insights service and archived for future usage.\n\nAPI generation is another area of innovation of Azure ML Model Management and one that builds upon the capabilities of the Azure ML service. Azure ML Model Management allows the generation of APIs for deployed ML models. Those APIs can then be used from third party applications using the SDKs available in languages such as Python, Java or C# as well as from the Azure ML CLI.\n\nSpeaking of the CLI, this is the main command-line scripting interface to automate operations on ML models. Some of those capabilities are also available through the Azure ML Model Management API which is also the main endpoint used to retrain models. From that perspective, devops can author scripts that retrain deployed models using the platform\u2019s REST API.\n\nAzure ML Model Management provides seamless interoperability with other Azure services which enables the implementation of highly sophisticated model automation workflows. The platform represents a strong differentiator with Azure ML top competitors such as AWS ML or Google Cloud ML.\n\nAzure ML Model Management can be considered a unique offering in the cloud ML platform space. Startups such as Bitfusion or Floyd provide comparable capabilities. We should also expect platforms such as AWS ML, Google Cloud ML or Alibaba ML service to release similar capabilities in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-growing-relationship-between-bitcoin-and-public-markets-947a52433731?source=user_profile---------126----------------",
        "title": "The Growing Relationship Between Bitcoin and Public Markets",
        "text": "What moves the price of Bitcoin? Today, it is mostly news and geo-political events but what else is there? That\u2019s something we are still trying to understand. Intuitively, many experts believe there is a not-so-obvious and growing relationship between Bitcoin and public markets. I tend to subscribe to that thesis as well. After all, how many $100 billion markets do you know that have no impact in public equities?\n\nThe relationship between Bitcoin and public markets is almost imperceptible today but growing really fast. as Bitcoin and digital currencies in general become a bigger presence in our lives, that relationship is likely to increase. From that perspective, we should differentiate the impact of Bitcoin in public markets today from its potential growth tomorrow.\n\nThere are not many publicly traded stocks with a meaningful exposure to Bitcoin or digital currencies. By meaningful, I am referring to somewhere in the 3\u20135% of their revenue. Currently, Bitcoin mining is the segment of the cryptocurrency space that has permeated the most into public markets. Chipmakers such as Nvidia and Advanced Micro Devices(AMD) are two stocks that have become vulnerable to the price of Bitcoin and vice versa.\n\nThe link between Nvidia, AMD and Bitcoin comes from the fact that both companies re involved in the manufacturing of GPUs which are actively used in the mining of cryptocurrencies. Bitcoin mining has recently experienced a renaissance drive, among other things, by the crackdown against Bitcoin in China which opened the doors to markets for Bitcoin mining. At the same time, the mining of other digital currencies remains a very competitive field.\n\nIn addition to direct investments in Nvidia and AMD, investors are indirectly exposed to Bitcoin through exchange traded funds(ETFs) with positions in those two stocks.\n\nIn my opinion, there is also an indirect relationship between Bitcoin and FOREX markets. We\u2019ve seen it before when the Chinese Yuan has become unstable causing many investors to look refugee in Bitcoin which has triggering an spike on the price of the cryptocoin.\n\nWhile Bitcoin\u2019s impact in public markets is certainly limited, we should not ignore its future influence based on its astonishing growth trajectory. Again, no $100 billion market goes unnoticed. In the near future, Bitcoin impact in public markets is likely to expand into several areas including a bigger footprint within chip manufacturers such as Intel, ARM or QUALCOMM.\n\nBig enterprise tech stocks are also a candidate to get exposure to Bitcoin and digital currencies. Specifically, companies such as IBM and Microsoft are getting more involved in block chain solutions and if you think there is no relationship between health of currencies like Either and the blockchain market you are only kidding yourself.\n\nFinancial markets is another area that is likely to receive certain level of influence from Bitcoin in the next few years. Financial powerhouses such as Fidelity already announced that they are actively mining Bitcoin and Ether. Goldman Sachs also announced that they are starting to study trading models for the digital currency. Other publicly traded investment funds might increase their footprint on Bitcoin in the very near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/marketing-vs-reality-some-thoughts-about-oracle-ai-strategy-87ed76d3d83d?source=user_profile---------127----------------",
        "title": "Marketing vs. Reality: Some Thoughts About Oracle AI Strategy",
        "text": "Oracle has finally announced its ambitions to be a competing force in the cloud artificial intelligence(AI) services market. At its annual Open World Conference, the software giant announced a new suite of tools and services to enable the implementation of aI solutions. Typical Oracle, the announcement was full of marketing non-sense already claiming a leadership position in the meerging market. However, if we read between the marketing red-tape, there are some interesting implications of the new Oracle offering for the AI market.\n\nIt\u2019s been a few days since Open World which means that the marketing hype has settled down a bit and we can take a more pragmatic view at Oracle\u2019s AI offering. The core of Oracle\u2019s release is the new AI Platform Cloud Service which can be seen as a workbench for the implementation of cloud data science applications.\n\nThe Oracle AI Platform Cloud Service includes a large GPU-based computation runtime for the execution of AI programs. The runtime is already integrated with popular AI technologies such as TensorFlow, Keras, Scikit-Learn and Jupyter Notebooks. The integration with Jupyter is particularly interesting because it provides data scientists with an interactive environment for the implementation of data science workloads. Until that point, Oracle\u2019s AI Platform Cloud Service doesn\u2019t\u2019t look very different from the current AI stacks from Google Cloud, Azure, Bluemix or AWS. From the purely technical standpoint, you can make the case that the AI Platform Cloud Service is relatively limited in terms of capabilities compared to the cloud incumbents. However, Oracle doesn\u2019t bring some unique features to the table such as the new Adaptive Intelligent Apps that define AI-powered business processes in vertical areas such as finance, marketing, manufacturing, supply-chain, sales and several others. The Adaptive Intelligent Apps follow a similar strategy to what Salesforce has been doing with its Einstein platforms and definitely play to Oracle\u2019s strengths in the industry-solution space.\n\nWhen evaluating Oracle\u2019s AI strategy from the market standpoint, there are several key points that deserve some attention.\n\nOracle AI Platform Cloud Service is certainly a welcomed addition to the market but is far from being a leader in the space. Compared to other AI cloud suites in platforms such as Google Cloud, Azure, AWS or Bluemix, the AI Platform Cloud Service has key technical limitations in areas such as cognitive APIs (ex: Watson Developer Cloud, Microsoft Cognitive Services\u2026), a unique machine learning runtime( ex: Azure ML, Google Cloud ML\u2026.), support for a broader set of deep learning frameworks(ex: Theano, Torch, Caffe2, MxNet\u2026) or data science tools(ex: Azure ML Experimentation Service).\n\nThe Oracle AI Platform Cloud Service Adaptive Intelligent Apps represent a unique differentiator compared to the AI offerings of Google, IBM, Microsoft and Amazon. Salesforce.com seems to be the company that can compete with Oracle in the SaaS-AI area but the AI Platform Cloud Services seems to be more flexible than the Salesforce Einstein stack in terms of the implementation of custom AI programs.\n\nSimilarly to IBM and Microsoft (and differently from Amazon and Google), Oracle can find a quick path to increase the adoption of the AI Platform Cloud Service within its existing customer based. From that perspective, making it easy for WebLogic and Oracle Apps customers to adopt the AI Platform Cloud Service will be a key element in the success of Oracle\u2019s AI Strategy."
    },
    {
        "url": "https://medium.com/@jrodthoughts/divide-and-conquer-supervised-pretraining-in-deep-learning-models-52df422643b1?source=user_profile---------128----------------",
        "title": "Divide and Conquer: Supervised Pretraining in Deep Learning Models",
        "text": "Most people divide the world of machine learning( and consequently deep learning) into two main types of algorithms: supervised and unsupervised. While that categorization is technically correct, its far from being complete. As deep learning practitioners quickly come to fund out, there are dozens of subcategories of supervised and unsupervised learning techniques with dozens of algorithms each. One of those subcategories that has become extremently popular with the emergence of deep learning is known as supervised pretraining.\n\nDeep learning models are typically represented by a neural net structure with several hidden layers or sub-networks. The essence of supervised pretraining is to break down tasks into simpler tasks that can be trained independently before confronting the original task.\n\nTo illustrate the ideas behind supervised pretraining, let\u2019s use a hypothetical deep learning model that is learning to master chess. Strategically, chess games are divided in three main stages: opening, middle-game and end-game. While the opening and end-game stages require very strong theoretical knowledge, the middle-game is where most deep strategies and tactic manipulations take place. Training a single deep learning model to learn chess can be really unpractical( not the best technical example but stay with me for a minute :) ) from the computational standpoint. Instead, we can use supervised pre-training to train individual sub-networks in opening, middle-game and end-game strategies and then combine them into a complete chess master deep learning model.\n\nLet\u2019s use another example, closer to the deep learning world, of a natural language understanding(NLU) agent that is learning o have conversations with humans on specific subjects. A human conversation goes beyond determining the subject and intent of a dialog and it includes many aspects such as empathy, tone, voice speed, clarifications and dozens of others. Supervised pretraining can be used to learn about these individual aspects and of a conversation and combine them into robust NLU models.\n\nWhy Do We Need Supervised Pretraining?\n\nThe simplest answer boils down to computational cost. Training large deep learning networks can be incredibly expensive and, many times, the information to train the model its simply not available. Supervised pretraining addresses that challenge with two simple goals:\n\na) Modify deep learning models into simpler versions that are easier to train.\n\nb) Evolve the trained simpler models into more complex models that solve the original task.\n\nGreedy supervised pretraining is one of the most popular types of supervised pretraining techniques and one that has been widely adopted in deep learning algorithms. Technically, greedy supervised pretraining breaks down a network into many different components and tries to solve the optimal version of each component. After that, greedy algorithms combines the optimized versions of the sub networks into a new deep learning model that solves the original problem and then proceeds to optimize that model.\n\nGreedy supervised pretraining should be seen as a tradeoff between knowledge and computational resources. Obviously, combining the most optimal version of sub-sub networks doesn\u2019t always produce an optimal deep learning model. Just because you are super empathetic it doesn\u2019t mean that you can have a conversation about politics or art. Nonetheless, greedy supervised pretraining are often computational cheaper compared to other training approaches. From that perspective, data scientists should balance the right level between knowledge and resource consumption in order to build an optimal process to train their models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/tokenomics-49bea5b9159b?source=user_profile---------129----------------",
        "title": "Tokenomics \u2013 Jesus Rodriguez \u2013",
        "text": "Crypto-Assets and digital tokens are becoming an increasingly important of many modern economic trends. Today, the market has over 80 tier-1 digital currencies and protocols such as Bitcoin, Ether or LiteCoin as well as thousands of digital tokens and crypto-assets produced by ICOs and, very soon, Reverse ICOs( read my previous articles about that topic). The total market capitalization of crypto-assets is valued somewhere above $100 billion which might not seem very large by financial market standards but it is sizable enough that it should not be ignored. More importantly, crypto-assets agree growing at a multiple higher than any other asset class in financial markets.\n\nIf we can picture a world in which a large number of companies use some sort of digital token, then the economics of that world would look different than the current standards. We will be entering the token economy.\n\nSome Thoughts About the Token Economy\n\nIf crypto-assets become part of financial portfolios of mainstream citizens, we are likely to start seeing their impact in areas of the economy beyond digital currency exchanges. How would an economy of combined digital and traditional assets look like? I have no idea :) However, I\u2019ve summarized a few thoughts that might help you think about crypto-assets in a macro-economic context and get the debate started.\n\nThese days, digital currencies such as Bitcoin are accepted by a growing number of merchants around the world but, in general, its usage remains constrained to small transactions. In the near future, we should expect traditional industries such as real estate, agriculture or oil & gas to warm up to digital currencies. So don\u2019t be shocked if you can buy your next house using Bitcoin( its kid of happening already in some markets :) ).\n\nIn the same way that fiat currencies are influenced by macro-economic factors such as fluctuations in commodities or central bank policies, crypto-assets are influenced by their underlying digital protocol such as Ether or Bitcoin. In that dynamic, fluctuations in a tier-1 digital protocol can have an impact on many digital tokens that depend on it.\n\nThe number of asset management firms dabbling into digital currencies remains small. However, it is expected that some of the most progressive asset managers will start including Bitcoin or Ether as part of financial portfolio packages. That model is likely to become the main channel by which mainstream citizen get exposed to the token economy.\n\nGetting paid in Bitcoin. Well, it has happened; just ask the founders to CoinBase or PolyChain Capital. However, those remain isolated cases .In the near future, compensation using digital should become more common as part of salaries or bonuses. Similarly, leveraging digital currencies as part of M&A transactions should be a viable alternative to traditional cash and stock acquisitions.\n\nWe are already seeing efforts by countries such as Estonia or Singapore exploring national digital currencies. Also, the world\u2019s recent socio-political climate indicate that we are likely to see the number of countries in the world increase in the upcoming years. Just take a look at the recent independence efforts in regions of Spain, Iraq, Africa, UK and many others. for new countries and emerging economies, the usage of digital currencies and crypto-assets offering very interesting options to be immediately competitive in financial markets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-chain-core-wants-to-be-the-redhat-of-the-blockchain-db4f395cdd98?source=user_profile---------130----------------",
        "title": "Technology Fridays: Chain Core Wants to be the RedHat of the Blockchain",
        "text": "Welcome to Technology Fridays! Today, I would like to cover one of the platforms that has been driving the enterprise blockchain ecosystem: I am talking about Chain Core.\n\nMany people like to compare blockchain platforms to the internet. I believe that comparison is flawed on several levels but that\u2019s a topic for another day :). In my opinion, a better analogy for blockchain platforms can be found in the server operating system(OS) space. Specifically, I like to compare the blockchain platform space to the Linux OS ecosystem and I think we can find many interesting similarities between the evolution of those two technology movements. Just like in the Linux world, today we have several version of blockchain-based platforms that are actively trying to achieve relevance in the enterprise. Chain Core is one of the platforms leading that charge that, many times, doesn\u2019t get the credit and visibility it deserves.\n\nAt its core, Chain Core is a software framework designed to run on permissioned blockchain networks. Chain Core\u2019s nodes maintain a cryptographically-secured, multi-asset ledger that enables the processing of distributed assets. My favorite feature of Chain Core is its super-simple programming model which is a rarity in an ecosystem plagued with complexity. At a high level, Chain Core architects blockchain programs using a handful of fundamental constructs such as Keys, Assets, Accounts and Transactions.\n\nEach participant in a Chain Core application requires a private key as the main authorization mechanism for the issuance and transfer of assets. Chain Core keys must be generated using an HSM( hardware security module) which can be sort of expensive but the platform includes a MockHSM API that streamlines the generation of keys in development environments.\n\nAssets are a fundamental concept in Chain Core applications that abstract the types of value that can be processed by an endpoint. In Chain Core, an Asset definition is, essentially, a set of key-value pairs that describe its properties. When a participant issues an Asset in Chain Core, its effectively creating an instance of that definition and declaring the number of units that need to be issued.\n\nIn order to track Asset ownership, Chain Core uses the concept of Accounts. The Chain Core platform maintain a local repository that hosts the definition of the existing Accounts. That repository is local to Chain Core and is not persisted in the underlying blockchain. Instead, the blockchain ledger is used to record instances of Transactions that transfer a number of units of a specific Asset.\n\nOne of the areas in which Chain Core really innovates is the security of Assets using the concept of Control Programs. Chain Core Control Programs are a set of predicates that must be satisfied in order to process a Transaction. The platform includes several types of Control Programs such as Account Control Programs to process Asset units or Retirement Control Programs to remove an Asset from the blockchain. Developers can even create Custom Control programs using a domain specific language included in the platforms.\n\nLike other blockchain platforms, Chain Core enables the implementation of Smart Contracts that orchestrate flows a specific Transaction flow. Chain Core\u2019s Ivy language enables the modeling of Smart Contract using a high level, domain specific syntax. Ivy is recommended to use mostly for experimentation and not in production scenarios but is, nonetheless, a powerful addition to the Chain Core stack.\n\nDevelopers can start building Chain Core application susing the platform\u2019s API or one of its several SDKs that today include languages such as Java, Ruby or NodeJS. The SDKs make it extremely simple to assemble highly sophisticated blockchain interactions. all objects created in a Chain Core application are persisted using a JSON format and are accessible via a simple query language available in the API and SDKs.\n\nJust like Linux, the blockchain platform ecosystem is getting really really crowded. Chain Core typically competes with tier 1 blockchain platforms such as Ethereum, IBM Hyperledger Fabric, Intel Sawtooth or R3 Corda. Domain specific blockchain platforms such as Ripple, J.P Morgan Quorum or Nasdaq Linq can also be considered part of Cain Core\u2019s competition."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-keeps-making-the-right-investments-in-machine-learning-372e03c04560?source=user_profile---------131----------------",
        "title": "Microsoft Keeps Making the Right Investments in Machine Learning",
        "text": "A few days ago during the Ignite Conference, Microsoft unveiled a series of new tools that expand its machine learning(ML) capabilities and lower the entry point for developers and data scientists getting started with the platform. The new additions to the Azure ML stack signal that the Redmond giant is putting the right pieces in place to automate the end-to-end lifecycle of machine learning applications.\n\nMicrosoft\u2019s entrance in the machine learning space was marked by the launch of the Azure ML cloud service. While the initial version included some impressive capabilities such as the mode designer and the ability to generate APIs from ML algorithms, it had some notable limitations when came to implementing real world machine learning scenarios. To some extent, Azure ML felt more like the type of platform that could be used by mainstream Azure developers who were not necessarily machine learning experts while \u201creal\u201d data scientists will rely on emerging deep learning frameworks and tools such as TensorFlow, Caffe, Theano, Jupyter, Zepellin, etc. Don\u2019t get me wrong, Azure ML was a solid first release by Microsoft but the limitations were pretty obvious for data scientists and that has somewhat hindered its adoption. With the new release, Microsoft is directly addressing some of the well-known challenges of the initial version of Azure AML making it a more attractive destination for machine learning practitioners.\n\nThe new machine learning tools released by Microsoft mark the transition of Azure ML from a runtime to an end-toend machine learning application platform. The new release include capabilities in areas such as training, deployment and management which are essential in the implementation of machine learning solutions in the real world.\n\nThe Azure ML Experimentation Service enables the rapid training and deployment of machine learning experiments. The service integrates with several deep learning frameworks such as TensorFlow, Caffe2, PyTorch, Cahiner and Microsoft Cognitive Toolkit. The Experimentation Service also enables capabilities such as model versioning or integration with source control systems.\n\nIn Microsoft\u2019s own words: Azure ML Workbench should become the \u201ccontrol panel for your development lifecycle and a great way to get starting using machine learning\u201d. Distributed as Windows and Mac native applications the ML Workbench enables the implementation of models in Python, PySpark and Scala and integrates with Jupyter notebooks as well as IDEs such as Visual Studio Code and PyCharm.\n\nThe Model Management Service packages production ready machine learning models as Docker containers that can be ported over and executed on different runtime environments. The new service capability is likely to streamline Azure ML\u2019s integration with many advanced Docker-Kubernetes runtime stacks in the market.\n\nWhere are we at?\n\nThe release of Azure ML Experimentation, Workbench and Model Management services can become a strong differentiator with Azure\u2019s main competitors. While services such as AWS ML or Google Cloud ML remain mostly as advanced runtimes for machine learning applications, Azure ML seems to ambition to become an end-to-end platform for the automation of machine learning applications. More importantly, the new machine learning tools represent a strong addition to Microsoft\u2019s impressive suite of cognitive computing technologies that currently includes products such as Cognitive Services, Cognitive Toolkit, R Server, Azure ML and others."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-reverse-icos-part-ii-1c54353f760a?source=user_profile---------132----------------",
        "title": "Some Thoughts About Reverse ICOs Part II \u2013 Jesus Rodriguez \u2013",
        "text": "This is the second part of an essay explaining some of the implications of Reverse ICOs in the digital currency markets. The first part explored some of the fundamental concepts of Reverse ICOs and highlighted several of the most obvious implications that the market should consider if Reverse ICOs ever materialize as a viable mechanism for raising capital. Today, I would like to continue that discussion with a few more ideas related to the implications of Reverse ICOs.\n\nStock based acquisitions are fundamentally hard for startups given to the subjective nature of private valuations. Crypto-Tokens change that picture dramatically as they have a very tangible market value and offer an immediate path to liquidity. As a result, we might soon see a generation of \u201ccash and token\u201d M&A models in which private companies are acquired using digital tokens as the underlying currency.\n\nSuppose that there is a private startup that recently raised a large round of institutional financing and you believe the company is totally overvalued. Today, there is no market mechanisms available so that you can profit from that analysis. You can\u2019t short sell shares of a private company as they are not actively traded. Even in the case of an ICO, it is not clear if short selling would work as crypto-tokens are not directly tied to the company\u2019s valuation. All that changes with Reverse ICOs. If the mechanisms are available( which they are not today), I could potentially short sell a crypto-token based on a thesis that predicts the poor performance of the company.\n\nThere is a lot of legal work behind every IPO that could be directly applied to Reverse ICOs. From a market taxonomy perspective, Reverse ICOs are likely to be considered securities and subjected to similar regulations. A minor caveat, I believe that the legal and regulatory constraints around Reverse ICOs should be expressed as Smart Contracts that can be enforced programmatically in the blockchain. In my opinion, we are likely to see a new type of legal programmable frameworks powered by the Reverse ICO movement that embed legal contracts as part of digital tokens.\n\nSuppose that a startup that executed a successful Reverse ICO decides to go public a few years later. How will the digital tokens be valued in reference to the shares of the IPO? Let\u2019s now take the opposite scenario of a publicly traded company that creates its own digital currency and wants to execute a Reverse ICO. Is that even possible? If so, should there be a path for shareholders to convert shares to tokens? All those questions are highly speculative at this point but I think some models for bidirectional stock-to-token conversations should be explored in the near future.\n\n10 \u2014 A New generation of Financial Products for Reverse ICOs\n\nIPOs brought together a large number of financial products such as futures, options, index-funds, hedge funs, mutual funds, quant trading and many others. Similarly, ICOs and Reverse ICOs are likely to produce a new generation of financial products or extend some of the existing one to the new token economy. Given the similarities between Reverse ICOs and IPOs, many of the existing IPO-based products will have an equivalent in the Reverse ICO world."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-reverse-icos-part-i-e30f24aee0d8?source=user_profile---------133----------------",
        "title": "Some Thoughts About Reverse ICOs Part I \u2013 Jesus Rodriguez \u2013",
        "text": "Initial Coin Offerings(ICOs) have been one of the most exciting developments in the technology world in the last few years. With as many detractors as followers, ICOs are approaching the $2 billion mark in 2017 vastly surpassing the amount of venture capital raised by blockchain startups during the same timeframe. Consequently, ICOs have been on the close radar of governments and regulators with countries such as China and South Korea declaring them flat out illegal. If you are interested on ICOs, I recommend you read my previous articles about that topic. Today, I would like to explore another interesting movement that have been gaining some momentum in the token economy: Reverse ICOs.\n\nConceptually, Reverse ICOs are trying to address some of the regulatory concerns surrounding ICOs by structuring an equity offering as part of a token sale. Reverse ICOs follow a similar regulatory process to IPOs or growth stage venture capital rounds being constrained to accredited investors and using documents such as Reg A+ or Reg D which are common on institutional financing. At a very abstract level, you can think about a Reverse ICO as an IPI that, instead of a stock sale, issues a digital token,\n\nThe full dynamics of Reverse ICOs are still being put together and the infrastructure and tools are not ready yet. However, we are already seeing some encouraging signs such as the first group of token exchanges like t0.com that have been certified by the SEC. Whether Reverse ICOs become a viable product in the token economy or not, there are a few interesting implication of this phenomenon that I think are worth discussing.\n\nReverse ICOs are the type of process that is likely to attract venture capitalists invested in the blockchain ecosystem. Procedurally, Reverse ICOs will follow the due diligence and regulatory processes that are common on late-stage funding rounds which should make it more appealing to VCs than traditional ICOs.\n\nEmployee liquidity is one of the biggest challenges for private companies. Regardless of how many VC round a company has raised, it is very hard to appropriately price the company common shares. As a result, employees remain uncertain about the value of their stock options and they don\u2019t have many channels available to achieve liquidity. Reverse ICOs will provide employees with tokens that have a tangible market value and are also tradeable in certified token exchanges.\n\nIn IPOs or late stage private financing, the valuation of a company increases solely based on the investor\u2019s perspective of its performance. With Reverse ICOs, the valuation of a company can also increase drive by the value of tokens which are somewhat independent of the performance of the parent company. A startup whole tokens are actively used will see a higher valuation even if it hasn\u2019t raised a new round of financing.\n\nPrivate company valuations doesn\u2019t really change unless there is a new financing event. With Reverse ICOs, the valuation of a company changes every day based on the performance of its tokens. From that perspective, Reverse ICOs valuations models are closer to public markets than to VC valuation models.\n\nThere are a few aspects of Reverse ICOs that indicate that private companies that undergo that process will have an easier path towards an IPO. This assumption is based on the similarities between the two models. Obviously, it is way too early to tell."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-blockchain-strategy-seems-to-be-paying-off-66104ca04c46?source=user_profile---------134----------------",
        "title": "Microsoft Blockchain Strategy Seems to be Paying Off",
        "text": "A few weeks ago, I wrote about the release of Microsoft\u2019s Coco Framework, the latest addition to the Redmond giant blockchain stack. In that article, I mentioned that Microsoft was, slowly and steadily, building one of the most comprehensive blockchain technology suites in the market. Initial signs show that strategy seems to be working and Microsoft recently publicized some of its high profile wins in the distributed ledger space.\n\nThe most fascinating thing is that Microsoft\u2019s blockchain technology suite seems to be showing proficiency across incredibly diverse industries such as banking, retail or shipping insurance. Additionally, the initial set of case studies shows how much Microsoft\u2019s blockchain success is not only a result of its technological capabilities but also about the incredibly robust partner ecosystem built around its blockchain products.\n\nMarine insurance is one of the oldest and most archaic types of insurance models in the market. Shipping cargo between two locations involves many building blocks and pieces that can go wrong at any time. From port logistics to pirates in African waters, the processes for putting together a comprehensive shipping instance policy is ridiculously complicated. If we are talking about auditing those policies, then the process becomes nothing short of a miracle.\n\nMaersk knows a thing or two about marine insurance. The Danish shipping giant recently started looking at blockchain technologies to streamline the auditing processes in marine insurance policies. Maersk turned to Microsoft and some of its partners such as Ernst & Young and Guard Time to develop a 20-week proof-of-concept(POC) for simplifying the auditing processes in its marine insurance policies.\n\nThe core of the Maersk POC relies on Guard Time\u2019s KSI Ledged platform. The solution uses the blockchain to log real time, trusted insurance data across the different parties involved in a shipping process. That model reduces the time for the different parties to agree on the terms of insurance policies. Microsoft\u2019s role in the POC seems to be related to supplying the blockchain infrastructure to operate and scale the solution.\n\nBank guarantees are embedded into many business transaction across different industries. For instance, in real state, bank guarantees are used to as a security in tenant leases. However, the processes for handling bank guarantees are paperwork-intensive and regularly plagued with errors.\n\nRecently, Microsoft partnered with Israel\u2019s Bank Hapoalim to build a system that manages its bank guarantees. The solution will allow Bank Hapoalim\u2019s customers to receive documents in a secure manner powered by a blockchain. Microsoft\u2019s blockchain as a service(BaaS) infrastructure is used as the main runtime for the solution.\n\nWhat Makes Microsoft Win in the Blockchain?\n\nWhen comes to blockchain enterprise solutions, Microsoft has a lot of going for it. Technologies such as Azure BaaS, Coco Framework, Azure Enterprise Smart Contracts or Project Bletchley bring together a very complete set of blockchain capabilities. Additionally, the integration with Azure services or mainstream platforms such as Office365 is a very strong plus for many customers. More importantly, since day one, Microsoft has put a tremendous level of effort building a strong partner ecosystem around its blockchain technologies. All those factors have allowed Microsoft to quickly raise next to IBM as the two most trusted brands when comes to blockchain enterprise implementations. The race between the two tech giants to dominate the enterprise blockchain space is only going to get more interesting in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-dataprep-completes-google-cloud-data-science-pipeline-ee7caf078d92?source=user_profile---------135----------------",
        "title": "Technology Fridays: DataPrep Completes Google Cloud Data Science Pipeline",
        "text": "Welcome to Technology Fridays! Today, I would like to discuss a recent addition to the Google Cloud platform that enables a fundamental building block for data science applications and one that is missing in most platform as a service(Paas) stacks. Data wrangling and curation has been the missing element in Paas technologies such as Google Cloud. Now the search engine giant is addressing that limitation with the launch of Cloud DataPrep and a very intriguing partnership with one of the new generation of data quality technology providers.\n\nConceptually, Cloud DataPrep is a native cloud service that enable the preparation and curation of datasets. In terms of the Google Cloud platform, DataPrep sits in the middle between data storage services such as BigQuery or BigTable and advanced data science such as DataView or Cloud Machine Learning.\n\nIn a somewhat surprising move, Google didn\u2019t built DataPrep from the ground up. Instead, the cloud incumbent decided to adapt the technology from data wrangling market leader Trifacta to its suite of cloud services. We\u2019ve previously discussed Trifacta in this blog before but you should think about it as one of the new generation data quality management platforms that has emerged as an alternative to traditional solutions from incumbents such as Informatica Data Services or SQL Server Data Quality Services. Trifacta leverages machine learning algorithms to streamline the traditionally manual data curation processes. The result is an incredibly sophisticated data wrangling suite of tools that streamline the quality curation of data across an enterprise data pipeline. Cloud DataPrep is a version of the Trifacta suite optimized for Google Cloud data services.\n\nDevelopers can start using Google Cloud DataPrep directly from the Google Cloud Console. The first step in a Cloud DataPrep solution is selecting the datasets that need to be wrangled. DataPrep supports two main types of datasets: Imported and Wrangled. Imported datasets are a reference to source data residing in data storage systems such as Files, databases, big data file systems, etc. Complementarily, Wrangled datasets are used to transform the source data using Recipes.\n\nAtomic data cleansing and transformation steps in Cloud DataPrep are abstracted using Recipes. Typically, Recipes are authored using the Transform Editor tool and converted into Wrangle which is DataPrep\u2019s domain-specific language for data transformations. Wrangle provides a flexible syntax that express structural transformations across single and multiple data source models. At runtime, Cloud DataPrep intercepts the Recipes and executes the corresponding Wrangle code.\n\nWhile Recipes represent atomic data cleansing steps, DataPrep Flows are orchestrations involving multiple Recipes. Flows are typically used in more complex data cleansing tasks such as merging multiple datasets, identifying statistical outliers in the source data or many other data curation processes.\n\nVisual Profiling is another key capability of Cloud DataPrep . The platform\u2019s profiling tools include interactive visualizations that highlight key statistical patterns in datasets and recommend the appropriate transformations. A rich user experience combined with sophisticated statistical and machine learning algorithms make Visual Profiling and almost enjoyable experience in Cloud DataPrep certainly contrasting with the cumbersome profiling process in traditional data quality management stacks.\n\nCloud DataPrep completes the circle in Google Cloud\u2019s data science pipeline that includes services in areas such as storage, transformation, analytics and data science. More importantly, data wrangling services such as DataPrep are a strong differentiator of Google Cloud against competitive platform such as Azure or AWS.\n\nGoogle Cloud DataPrep is a unique offering in the Peas market. However, the platform faces competition from a new fast growing group of data quality management platform startups such as Paxata, Alation or Tamr. Additionally, Cloud DataPrep is likely to be perceived as an alternative to traditional data quality management incumbent solutions such as Informatica Data Services or Microsoft SQL Server Data Quality Services."
    },
    {
        "url": "https://medium.com/@jrodthoughts/assumptions-dimensionality-and-some-of-the-original-motivations-behind-deep-learning-a4df2f0f1689?source=user_profile---------136----------------",
        "title": "Assumptions, Dimensionality and Some of the Original Motivations Behind Deep Learning",
        "text": "Deep learning seems to be everywhere today. Not a week goes by in which we don\u2019t hear new announcements or press releases about new deep learning technologies. Like any other uber-popular technology trend with mainstream press coverage, deep learning has been subjected to a lot of misconceptions. In my opinion, there have been many articles out there that make little distinction between deep learning, machine learning or artificial intelligence which results extremely confusing for even technically savvy readers.\n\nOne way to understand the difference between deep learning with other cognitive computing disciplines such as machine learning or artificial intelligence is to understand some of the original factors that motivated the creation of deep learning from a theoretical standpoint. In principle, deep learning was created to address some of the limitations of traditional machine learning algorithms in several areas. Among those challenges, I like to cite two that, in my opinion, became key accelerators to the raise of deep learning: the curse of dimensionality and assumption formulation.\n\nToo Many Dimensions, Too Little Data: The Challenge of Dimensionality in Machine Learning\n\nMachine learning algorithms have been long learning before the creation of deep learning. From that perspective, a question we should ask is: what were the limitations of traditional machine learning models that triggered the emergence of deep learning? The answer might boil down to a single word: dimensionality.\n\nTraditional supervised and unsupervised machine learning models operate very efficiently on scenarios with a manageable number of dimensions but they become increasingly challenged when the number of dimensions in a dataset increases. That challenge is a consequence of the fact that the number of combinations of attributes in a dataset increases literally exponentially as the number of dimension grows. The industry has even labeled that phenomenon with the tragic name of the \u201ccurse of dimensionality\u201d.\n\nIn the context of traditional machine learning algorithms, the curse of dimensionality becomes apparent when the number of configurations of dimensions in a dataset vastly outnumbers the number of training samples. Think about it, the purpose of machine learning algorithms is to generalize knowledge based on input data but, in a high dimensionality space, many combinations of dimensions are likely to have no training data associated with it. At that point, how can we generalize knowledge from which we haven\u2019t seen any factual data? Before you state the obvious fact that the curse of dimensionality can be solved with more training data, consider that, in scenarios with a large number of dimensions, sometimes the data is simply not available or the computational costs associated with the training processes are prohibited.\n\nSo what can we do?\n\nWhat do we typically do when we don\u2019t know something? We make assumptions of course! Similarly, the whole field of deep learning is based on making assumptions to be able to generalize knowledge in high dimensionality scenarios. Technically, assumptions in deep learning algorithms are based on \u201cprior beliefs\u201d about the types of hypothesis a model should be learning. For instance, a classic assumption known as the Smoothness Prior states that the hypothesis functions should not change drastically within a small region of a dataset. So if we know certain hypothesis function for a specific segment of the dataset, we should assume that data points closer to that segment will comply with a small variation of that hypothesis. Another traditional assumption in deep learning relies on the principle that data was generated by a composition of factors that can be represented in some hierarchical form.\n\nThere are a large number of assumptions made in deep learning models. Assumptions help to generalize knowledge in the absence of data and without experiencing immense computation costs. I will deep dive into the subject of assumptions in deep learning algorithms in a later post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/this-technology-might-be-the-next-battlefield-for-big-tech-7776c56f5c3d?source=user_profile---------137----------------",
        "title": "This Technology Might be the Next Battlefield for Big Tech",
        "text": "Not artificial intelligence, or the internet of things or even blockchain technologies.\n\nQuantum computing is a term you might have read in science magazines or heard mentioned in sci-fi thrillers but now it might become the next battlefield for big technologies companies. Yes, that\u2019s right! Quantum computing is becoming real and transitioning from dark use cases in research facilities to more mainstream scenarios.\n\nAt the recent Ignite conference, Microsoft unveiled its plan to start bringing quantum computing to developers. Microsoft CEO Satya Nadella has regularly mentioned quantum computing alongside artificial intelligence and mixed reality as the three biggest areas of future growth for the mother ship. Under the name StationQ, Microsoft has assembled an elite team of researchers to advance its quantum computing agenda. StationQ includes academic luminaries such as Fields Medal recipient Michael Friedman who has done a lot of work in the area of quantum topology known as topological qubits. A side note for the ones of you not familiar with the Fields Medal, it is the equivalent to the Nobel prize in mathematics except that is only awarded every few years and it significatively harder to get :) .\n\nMicrosoft\u2019s entrance in the quantum computing space is certainly encouraging but is farom from being a walk in the park. Companies such as Google and IBM has been actively working in the space and have deployed their quantum computing technologies in mission critical scenarios. When thinking about the quantum computing space, there are two fundamental questions we should try to answer:\n\na) What are the key capabilities that should be included in first iteration of quantum computing platforms?\n\nb)Who will be the initial market leaders in quantum computing and what areas will they focus on?\n\nThe first generation of quantum computing platforms will have the monumental task to bring the new computing paradigm to mainstream developers. Below, I\u2019ve listed a few of the capabilities that I believe should be included in that first iteration of quantum computing technologies in order to get traction in the developer community:\n\n1 \u2014 Quantum as a Service: The business model for quantum computing is still up in the air but one thing is for certain: there is going to be a place for cloud computing in it. Offering quantum computing capabilities via cloud infrastructures and integrating them with existing platform as a service(PaaS) services could become the most viable channel for the adoption of this new computing models.\n\n2 \u2014 New Programming Languages: I tend to agree with Microsoft\u2019s thinking that quantum computing solutions will require new programming languages tailored to those runtimes.\n\n3 \u2014 Simulators: Quantum infrastructures are expensive and will remain so for the near future. There, quantum computing platforms are likely to require simulators that emulate the capabilities of quantum computing runtimes in server environments.\n\n4 \u2014 Application Lifecycle Tools: From application development to monitoring, quantum computing platforms will bring a new generation of tools that will automate different aspects of the lifecycle of quantum applications.\n\n5 \u2014 Industry Solutions: Just like every other game-changing technology trend, quantum computing will create a new generation of industry specific solutions powered by the new computing paradigm.\n\nEven though is still super early, the initial wave of quantum computing platforms has been driven by three main companies: IBM, Google and now Microsoft. I don\u2019t have any insights about the quantum computing strategies of those companies but I am still going to venture to make a very simple prediction. Here it comes:\n\nI believe that Microsoft, Google and IBM are going to dominate segments of the quantum computing space that are directly related with their current areas of strength. I know, genius right? ;) Before you discard it as a silly prediction, let me outline some other interesting predictions that we can derive from the original statement:\n\na) Microsoft is likely to dominate in developer and productivity tools for quantum computing applications.\n\nb)Google is likely to dominate in quantum computing infrastructures.\n\nc)IBM is likely to dominate in professional services and industry solutions that leverage quantum computing.\n\nI also think we will soon see some Chinese companies emerge with compelling quantum computing offerings that give the big three a run for their money. Tencent, Baidu and Alibaba are my candidates."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-different-way-to-think-about-overfitting-and-underfitting-3-theories-you-should-know-about-50674c85e038?source=user_profile---------138----------------",
        "title": "A Different Way to Think About Overfitting and Underfitting: 3 Theories You Should Know About",
        "text": "This is the second part of an essay explaining some methods and techniques to reason through the problems of overfitting and underfitting in machine learning models. Yesterday, we introduced the notion of Model Capacity( universe of potential hypothesis functions) as an efficient way to estimate the model\u2019s propensity to overfit or underfit. Today, I would like to explore some theories in machine learning and mathematics that will help to solidify that concept.\n\nThe principle of Occam\u2019s Razor is what happens when philosophers get involved in machine learning :) The origins of the this ancient philosophical theory dates back to somewhere between 1287 and 1347 associating it with philosophers like Ptolemy. In essence, the Occam\u2019s Razor theory states that if we have competing hypothesis that explain known observations we should choose the simplest one. From Sherlock Holmes to Monk, Occam\u2019s Razor has been omnipresent in world class\u2019s detectives that often follow the simplest and most logical hypothesis to uncover complex mysteries.\n\nThe Occam\u2019s Razor is a wise philosophical principle to follow in our daily lives but its application in machine learning results controversial at best. Simpler hypothesis are certainly preferred from a computational standpoint in a world in which algorithms are notorious for being resource expensive. Additionally, simpler hypothesis are computationally easier to generalize. However, the challenge with ultra-simple hypothesis is that they often result too abstract to model complex scenarios. As a result, a model with a large enough training set and a decent size number of dimensions should select a complex enough hypothesis that can produce a low training error. Otherwise it will be prompt to underfit.\n\nThe Occam\u2019s Razor is a nice principle of parsimony but those abstract ideals don\u2019t directly translate into machine learning models that live in the universe of numbers. That challenge was addressed by the founders to statistical theory Vapnik and Chervonekis(VC) who came out with a model to quantify the Capacity of a statistic algorithm. Known as the VC Dimension, this techniques is based on determining the largest number m from which exists a training set of m different x points that the target machine learning function can label arbitrarily.\n\nThe VC Dimension is one of the cornerstones of statistical learning and has been used as the basics of many interesting theories. For instance, the VC Dimension helps explain that the gap between the generalization error and the training error in a machine learning model decreases as the size of the training set increases but the same gap increases as the Capacity of the model grows. In other words, models with large training sets are more likely to pick the approximately correct hypothesis but if there are too many potential hypothesis then we are likely to end up with the wrong one.\n\nI would like to end this article with one of my favorite principles iof machine learning relevant to the the overfitting-underfitting problem. The No Free Lunch Theorem states that, averaged over all possible data-generating distributions, every classification algorithm has approximately the same error rate when classifying previously unobserved points. I like to think about the No Free Lunch Theorem as the mathematical counter-theory to the limitation of machine learning algorithms that force us to generalize semi-absolute knowledge using a finite training set. In logic, for instance, inferring universal rules from a finite set of examples is considered \u201cillogical\u201d. For machine learning practitioners, the No Free Lunch Theorem is another way to say that no algorithm is better than others given enough observations. In other words,thee role of a machine learning model is not to find a universal learning function but rather the hypothesis that better fits the target scenario."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-different-way-to-think-about-overfitting-and-underfitting-in-machine-learning-part-i-capacity-738aa1bd5498?source=user_profile---------139----------------",
        "title": "A Different Way to Think About Overfitting and Underfitting in Machine Learning Part I: Capacity",
        "text": "In the past, I\u2019ve written extensibly about the concepts of overfitting and underfitting and their roles in machine learning models (check out my article about Borges and overfitting). Most of the previous articles explained the concepts of overfitting and underfitting at a cognitive/psychological level which is helpful but not immediately applicable to machine learning algorithms. Today, I would like to present a couple of pseudo-mathematical ideas that may give you a framework to deal with overfitting and underfitting in machine learning models.\n\nChallenges such as overffitting and underfitting are related to the capacity of a machine learning model to build relevant knowledge based on an initial set of training examples. Conceptually, underfitting is associated withe the inability of a machine learning algorithm to infer valid knowledge from the initial training data. Contrary to that, overfitting is associated with model that create hypothesis that are way too generic or abstract to result practical. Putting it in simpler terms, underfitting models are sort of dumb while overfitting models tend to hallucinate(imagine things that don\u2019t exist ) :).\n\nLet\u2019s try to formulate a simple methodology to understand overfitting and underfitting in the context of machine learning algorithms.\n\nA typical machine learning scenario starts with an initial data set that we use to train and test the performance of an algorithm. The statistical wisdom suggests that we use 80% of the dataset to train the model while mainthing the remaining 20% to test it. During the training phase, out model will produce certain deviation from the training data which we is often referred to the Training Error. Similarly, the deviation produced during the test phase is referred to as Test Error. From that perspective, the performance of a machine learning model can be judged on its ability to accomplish two fundamental things:\n\n2 \u2014 Reduce the gap between the Training and Test Errors\n\nThose two simple rules can help us understand the concepts of overfitting and underfitting. Basically, underfitting occurs a model fails at rule #1 and is not able to obtain a sufficiently low error from the training set. Overfitting then happens when a model fails at rule #2 and the gap between the test and training errors is too large. You see? two simple rules to helps us quantify the levels of overfitting and underfitting in machine learning algorithms.\n\nAnother super important concept that tremendously helps machine learning practitioners deal with underfitting and overfitting is the notion of Capacity. Conceptually, Capacity represents the number of functions that a machine learning model can select as a possible solution. for instance, la linear regression model can have all degree 1 polynomials of the form y = w*x + b as a Capacity (meaning all the potential solutions).\n\nCapacity is an incredibly relevant concept machine learning models. Technically, a machine learning algorithms performs best when it has a Capacity that is proportional to the complexity of its task and the input of the training data set. Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit. From that perspective, Capacity represents a measure by which we can estimate the propensity of the model to underfit or overfit.\n\nWe will cover a few other machine learning theories relevant to understand overfiting and underfitting in the second part of this essay."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-nats-makes-application-messaging-as-simple-as-texting-3880b78c85e0?source=user_profile---------140----------------",
        "title": "Technology Fridays: NATS Makes Application Messaging as Simple as Texting",
        "text": "Welcome to Technology Fridays! The world of application messaging platforms experienced a renaissance in the last few years with a group of innovative, open source platforms challenging the status quo established by incumbents such as Tibco(Rendezvous), IBM(WebSphere MQ) or Oracle. These days, when you think about application messaging platforms, names such as Apache Kafka or RabbitMQ come to mind. Today, I would like to cover another technology that I think you should add to that list: NATS\n\nThe brain child of developer -extraordinaire Derek Collison(Rendezvous fame), NATS is an ultra-fast, lightweight, open source messaging platform designed to support large-scale, distributed applications. There are a lot of adjectives in that states but, fundamentally, you should think about NATS as a messaging platform that was conceived from the ground up to support cloud infrastructures. Not surprisingly, NATS has evolved to become the massaging backbone of the Cloudfoundry platform as a service(PaaS) stack.\n\nAt its core, NATS is a high-performance, real time, publish-subscrive messaging platform. applications can send and receive messages to hierarchical subjects. At first glance, that doesn\u2019t sound very innovative so what is it about NATS that makes it special in the messaging platform space?\n\nWell, for starters, speed. NATS is optimized for processing high volumes of concurrent messages in real time. This is possible in part due to NATS non-persistent model that relies on short-term memory storage to relay messages between publishers and subscribers.\n\nAnother unique capability of NATS is its text-based protocol that exposes the capabilities of the platform via simple text commands. Differently form other messaging platforms that rely on binary protocols, developers can stop interacting with NATS via a simple telnet session. The NATS text-based protocol exposes commands such as CONNECT, PUB, SUB or MSG that abstract the main building blocks to exchange messages through the platform.\n\nNATS is based on two main subsystems: NATS Messaging and NATS Streaming. NATS Messaging enables synchronous and asynchronous publish-subscribe exchanges between endpoints. NATS Streaming provides event streaming capabilities with robust delivery guarantees as well as message routing. One of the coolest capabilities of NATS Streaming is its ability to replay historical data using a secondary storage mechanism. NATS Streaming makes the platform a strong candidate for emerging scenarios in areas such as internet of things(IOT) or telemetry monitoring.\n\nNATS was originally created in Go which means it was designed with concurrency as a first-class citizen. The NATS protocol includes important capabilities such as message ordering and delivery guarantees. NATS enforces message ordering in a per publisher basics but rarely across multiple publishers. Message delivering is enabled using an \u201cat-most-once\u201d model for NATS messaging applications or an \u201cat-least-once\u201d models for NATS streaming solutions.\n\nConnectors are components responsible for integrating NATS with other technologies. For instance, a Redis connector relays messages from NATS to the Redis Pubsub subsystem. The NATS Connector Framework enables the implementation of custom connectors using a consistent programming model.\n\nThe messaging platform space is crowded with innovative platforms that can be considered NATS competitors. Definitely way too many to cover here. Technologies such as RabbitMQ, ZeroMQ, Apache Kafka and Kafka\u2019s famous enterprise distribution Confluent are some of the best regarded technologies in the space. Also, legacy messaging platforms such as tibco Rendezvous are still very relevant in the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-taxonomy-to-understand-the-blockchain-application-platform-market-923759ab041a?source=user_profile---------141----------------",
        "title": "A Taxonomy to Understand the Blockchain Application Platform Market",
        "text": "The blockchain technology space is exploding with innovation. Every month, new technology stacks are entering the market with the promise to finally take blockchain application development mainstream. Venture capitalists are certainly excited about the market and new funding mechanisms such as initial coin offerings(ICOs) have provided blockchain platform startups with the resources to achieve initial relevance in the market.\n\nThe rapidly increasing number of blockchain platforms is certainly accelerating innovation in the space but it has also brought some confusion and misunderstanding. Today, if you are company evaluating blockchain application platforms it is incredibly easy to feel overwhelmed and confused by the large number of options in the market. Most analyst firms are still very early in their coverage of blockchain applications platforms and, frankly, there far too many articles out there comparing apples and oranges. I certainly don\u2019t claim to have any solution to magically make you understand the blockchain application platform market but there is a taxonomy that I frequently rely upon and that I think some of you might find useful.\n\nIf you are evaluating technology platform to build and scale blockchain applications(especially in the enterprise) you can think about the market in terms of the following categories:\n\nIn this group we can place the \u201clow level\u201d or tier 1 blockchain platforms that enable the construction of blockchain networks and the implementation of decentralized applications. This type of platforms include artifacts such as smart contracts, oracles, decentralized applications, consensus protocols or distributed ledgers which can be assembled to implement highly sophisticated blockchain applications. Ethereum is the prototypical example of this type of technology but we can also include platforms such as IBM Hyperledger Fabric, R3 Corda, Intel Sawtooth, Tezos, J.P Morgan Quorum or Nasdaq Linq in that category. This group of platforms can be seen as an enabled to other blockchain technologies included in this taxonomy.\n\nBuilding mainstream applications such as website or mobile apps powered by a blockchain infrastructure is really complex even when using blockchain infrastructure platforms. As a result, there is a segment of the blockchain application platform market composed of frameworks that streamline the implementation of common types of applications such as websites or mobile apps. Eris Tech is a good example of this group.\n\nBlockchain as a service(BaaS) are native cloud services that enable the provisioning and management of blockchain networks and infrastructures. BaaS are typically provided by the big cloud platforms which use the model to expand the model with their own blockchain technologies. Azure BaaS(Project Bletchley, Coco Framework, Enterprise Smart Contracts) and Bluemix BaaS are among the leaders in this space.\n\nBlockchain platforms as a service(PaaS) are suites of cloud services and frameworks built with blockchain technologies as the underlying platform. The goals of blockchain PaaS is to enable the implementation of decentralized application without caring about the underlying blockchain infrastructures. There are obvious overlap between the BaaS and blockchain PaaS models. However, there are enough differences to classify as two different groups. Differently from BaaS stacks, blockchain PaaS can operate on hybrid blockchain networks and include proprietary application development model. Platforms such as Nxt or BlockStack are leading the charge in this area.\n\nLike any other type of software solutions, blockchain applications require capabilities such as identity management, storage, integration and many others. There is a group of technologies in the market that has specialized on enabling those capabilities using different blockchain infrastructures. BigChainDB(database) or the aforementioned Azure Enterprise Smart Contracts(integration) are some examples of this type of technologies.\n\nI hope you found previous market taxonomy useful. The goal is not to create an exclusive categorization of blockchain application technologies in the market but rather to provide a guidance that may help you navigate this increasingly complex ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/with-this-little-project-microsoft-and-facebook-are-planning-to-solve-one-of-the-biggest-25170c85ae?source=user_profile---------142----------------",
        "title": "With this Little Project, Microsoft and Facebook are Planning to Solve One of the Biggest\u2026",
        "text": "The fragmentation of the deep learning technology ecosystem has been one of the biggest roadblocks for the mainstream adoption of these frameworks. The large number of heterogeneous deep learning frameworks, each one with their own strengths and weaknesses, makes it really challenging for developers and organizations to select the right tool fo the job. More importantly, interoperability across the different deep learning stacks is almost non-existent. Now Microsoft and Facebook seem to have a solution.\n\nCalled the Open Neural Network Exchange(ONNX) , the result of the collaboration between Microsoft and Facebook makes it possible to share neural networks across different deep learning runtimes. Specifically, the first version of ONNX focuses on the interoperability between PyTorch and Caffe2. This is mostly based on the fact that both technology stacks are broadly adopted across different Facebook divisions such as Applied Machine Learning(AML) or Facebook AI Research(FAIR). Additionally, ONNX is planning to add support for Microsoft Cognitive Toolkit(CNTK) in the near future.\n\nAt its core, ONNX works by tracing the execution of a deep learning model and creating a generic computation graph that can be used across different frameworks. This is possible because, as it turns out, all those different deep learning frameworks generate very similar computation graphs at runtime. However, PyTorch, CNTK and Caffe2 had to be modified in order to support ONNX which indicates that there is going to be some effort required to adapt frameworks such as Apache MxNet, TensorFlow, Theano, PaddlePaddle and others to the ONNX stack.\n\nBeyond the obvious benefits in terms of portability and interoperability, there are several intangible benefits to the adoption of ONNX. Let\u2019s discuss a few that come to mind:\n\nAlgorithm marketplaces (such as Algorithmia) are an emerging field in the AI technology ecosystem. Until now, AI algorithm marketplaces host models in their own runtime representation and there is no portability to other frameworks. Technologies such as ONNX can enable the adoption of deep learning models hosted in a marketplace across different frameworks which should help to boost the adoption of AI marketplaces to more mainstream scenarios.\n\nONNX provides a generic computation graph that is agnostic to the different deep learning frameworks. As a result, ONNX should open the door to new AI model monitoring and evaluation tools that use the generic computation graph to work consistently across the different stacks. Similarly, AI lifecycle management platforms such as BitFusion or Floyd could immediately benefit from embracing ONNX.\n\nONNX allows the reusability of trained neural networks across other different AI models and frameworks. As a result, ONNX should be able to boost the creation of new AI training tools that perform efficiently in multi-framework environments.\n\nONNX is still in very early stages but its already showing a lot of promise. In the very near future, we should expect to see new deep learning runtimes and platforms to add support for ONNX."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-statistical-learning-in-ai-systems-part-ii-challenges-51c00e76dc24?source=user_profile---------143----------------",
        "title": "Some Thoughts About Statistical Learning in AI Systems Part II: Challenges",
        "text": "How many Bayesians do we need to change a light bulb? We are not sure, come to think about it, we are not sure about the probability that the light bulb is burn out :) I know, I know, AI people should stay away form comedy :) but hopefully you got the point. Today, I would like to continue out analysis about statistical learning by highlighting some of its limitations in real world artificial intelligence(AI) systems.\n\nThe previous part of this essay explained some of the fundamentals and principal techniques used in statistical learning. From Siri to DeepMind\u2019s recent breakthroughs, statistical learning has become of the most prevalent models in AI agents. However , there are many well-known challenges when we rely solely on statistics to acquire knowledge.\n\nSometimes I like to compare statistical learning models with polite bureaucrats that always have some form of an answer to every questions but can never give you a straight answer. The only question to never ask a bureaucrat is \u201cWhy?\u201d says an old wisdom quote. Similarly to bureaucrats, statistical learning systems run into trouble trying to reach deterministic conclusions. To some extent, Bayesians or statistical learning really means that you can never be completely sure of anything. as it turns out, that level of uncertainty can be troublesome in many real world AI scenarios.\n\nStatistical learning models such as Bayes networks or Markov Chains rely on connecting states in an environment via probabilities and compute future probabilities associated with potential actions. However, the fact that we are able to represent probabilistic distributions, it doesn\u2019t always mean that we can reason effectively through them. This is known as the Inference Dilemma.\n\nTo explain the Inference Dilemma, let\u2019s use a basketball example. Suppose that, in an NBA team, we are trying to predict the likelihood that out All-Star power-forward will score over 35 points against a rival team. Our power-forward typically scores over 35 points in games when he plays over 40 minutes and our starting point-guard has over 10 assists. Obviously, we need to compute those probabilities. The point-guard has recently struggled against zone-defense so, in order to estimate the his chance of getting 10 assist, we need to factor in the time that the opposite team will play zone defense. Out power-forward also seems to be 30% more effective shooting from the right side of the ring so we need to compute the probability that he can play towards to the right side of the ring for at least 50% of his possessions. However, there is a backup power-forward in the opposite team that is notorious for forcing players to drive to the left side of the ring so we also need to factor in the minutes of this player. I can keep going for another hour but hopefully you see how this model can easily get out of control.\n\nThe complexity of statistical learning can get even worse if we start including the so called \u201cinvisible connections\u201d between states. For instance, in ur basketball scenario, the number of assists of our starting point-guard and shooting-guard seem apparently independent. However, every time the shooting-guard assists on a play, it indirectly means that the point-guard didn\u2019t get that assist so there is an invisible, unquantifiable relationship between those states.\n\nThe key to solve the Inference Dilemma is to try to model a statistical network as a tree without the trunk getting o thick. Easier said that done though :) One of the most common techniques that address the Inference Dilemma is what is known as Markov Chain Monte Carlo(MCMC). Algorithmically, MCMC is a fairly complex process that tries to simulate random navigations through a statistical network but doing so in a way that tthe number of time each state is visited is proportional to its probability. an optimal MCMC should converge to a stable distribution that produces approximately the same answers of the original network but its much easier to navigate.\n\nMaybe the biggest drawback of statistical learning models is that they rely on large probabilistic distributions to build knowledge that, in many cases, can be simply expressed by a series of logic functions. To express the knowledge contained in a few If\u2026Then statements we might need a massive statiscal network. Obviously, statiscal learning models tend to be used in scenarios that operate in uncertain, incomplete environments in which logic can result useless. As a result, many AI scenarios try to combine statistics and logic to achieve superior forms of knowledge building."
    },
    {
        "url": "https://medium.com/@jrodthoughts/statistical-learning-in-artificial-intelligence-systems-e68927792175?source=user_profile---------144----------------",
        "title": "Statistical Learning in Artificial Intelligence Systems",
        "text": "Uncertainty is a key element of many artificial intelligence(AI) environments in the real world. By uncertainly, we refer to the characteristics that prevent an AI agent from knowing the precise outcome of a specific state-action combination in a given scenario. Uncertainly is typically the result of nondeterministic and partially observable environments. Statistical learning has become a powerful weapon to overcome uncertainty in AI scenarios and, consequently, it has been widely implemented in many modern AI frameworks.\n\nWhen we talk about statistical learning, there is a name that comes to mind: Bayes. Even though most of modern statistic theory was the result of the work of French mathematician Pierre-Simon de Laplace who lived five decades after Bayes, it is Bayes who got all the credit in a theorem that bears his name. Thomas Bayes was an eighteen century British clergyman that described new insights to think about chance and uncertainty. Laplace codified Bayes ideas into a single theorem that helps us reason about almost anything in the world with an once of uncertainty:\n\nBy P(A|B) we denote the probability and A occurs given B. Replacing cause and effect in the previous equation with the probabilities of any state-action combination in an AI environment we arrive to the fundamentals of Bayesian learning. Essentially, Bayesian or statistical learning focuses on calculating the probabilities of each hypothesis and make predictions accordingly.\n\nAlthough Bayesian learning seems theoretically trivial, it runs into many roadblocks in real world AI solutions. Specifically, Bayesian learning models frequently result impractical in environments in which the number of hypothesis is very large or infinite. A very well-known AI algorithm that tries to address those limitations is the maximum a posteriori(MAP) model that simply makes predictions based on the single most probable hypothesis,\n\nMaybe the most notorious algorithm in statistical learning is the Naive Bayes model( also referred to as the Bayesian classifier) which uses networks to model environments in which the effects are independent given the cause. The model is \u201cnaive\u201d precisely because it assumes that attributes are independent of each other given the class.\n\nAI models like Native Bayes are only applicable in fully-observable environments. Many AI which don\u2019t resemble many real world AI environments. For instance, many AI environments contain hidden variables that are not available in the training data set. Let\u2019s take an example from the health care world, electronical medical records typically include observations about the symptoms is a disease rather than about the disease itself. In those scenarios algorithms such as unsupervised clustering using Mixture of Gaussians, Learning Bayesian Networks and Learning Hidden Markov Models are typically a good choice.\n\nAs it turns out, statistical learning is not a solution to every AI problem. Laplace\u2019s original thought that any form of human knowledge can be codified in a statistical network failed to account for many aspects of human reasoning. A very well known limitation of statical learning models is the absence of logic which results key in many forms of knowledge. As a result, statistical learning techniques are not applicable in many AI scenarios in the real world. That will be the subject of the second part of this essay."
    },
    {
        "url": "https://medium.com/@jrodthoughts/forgerock-ip-is-the-mysql-of-the-identity-management-world-4adad76a0e9e?source=user_profile---------145----------------",
        "title": "ForgeRock IP is the MySQL of the Identity Management World",
        "text": "Welcome to Technology Fridays! In lune with ForgeRock\u2019s recently announced filling fro IPO, I thought we should cover the platform in this week\u2019s Technology Friday. ForgeRock Identity Platform(IP) may be one of the coolest identity management suites you\u2019ve never heard of. The platform has been winning in the complex world of identity management using an unconventional formula based on open source, simplicity and a passionate developer community.\n\nForgeRock UP is an open source identity management platform(IAM) build from the ground up to automate the lifecycle of most aspects of identity management solutions. That part is actually very relevant because most IAM stacks in the market focus on specific capabilities such as authentication, identity federation or user management. Contrasting with that model, ForgeRock provides a comprehensive suite of products that cover most aspects of the lifecycle of identity management solutions.\n\nFrom a functional standpoint, ForgeRock IP is based on four fundamental building blocks: access management, identity management, identity gateway and directory services. All together, the four components enable end-to-end identity lifecycle management capabilities that can be implemented in diverse environments ranging from small startups to large enterprises. All ForgeRock IP products provide a consistent programming model based on standard and lightweight user interfaces that enable devops to easily interact with the platform.\n\nForgeRock IP delivers access management capabilities using its OpenAM product which provides features such as authentication, authorization, single-sign-on and others in a cohesive product. OpenAM exposes its capabilities using a simple REST API based on standards such as OAuth 2.0. SDKs for programming languages such as Java or C++ are also available in the platform.\n\nOpenDJ is ForgeRock IP\u2019s product responsible for automating directory services capabilities. By providing an open, lightweight and easily manageable user directory, OpenDJ cab be seamlessly deployed on both on-premise and cloud environments. OpenDJ provides robust capabilities such as password management, replication, monitoring as well as REST and LDAP interfaces.\n\nOpenIDM is the identity management arm of the ForgeRock IP platform. OpenIDM enables the provisioning and management of identities across devices and applications. OpenIDM provides a very modular architecture based on OSGi that includes connectors to many line of business and enterprise security systems. Those connectors are typically implemented using the OpenICF(Identity Connector Framework). Capabilities such as password synchronization or workflow provisioning are also part of OpenIDM.\n\nThe fourth component of the ForgeRock IP stack is OpenIG which is a centralized identity gateway that enables capabilities such as single sign-on and sign-out, password capture-replay and policy management. OpenIG delivers its capabilities via standards such as SAML2.\n\nForgeRock operates in very competitive market that includes cloud IAM platforms like Okta, PingIdentity, OneLogin or SailPoint which have gained strong market traction in the last decade. Similarly, identity services included platform as a service(PaaS) stacks such as Azure Active Directory or AWS IAM are also strong competitors. Innovative startups such as Auth0 have become a favorite of developers when comes to high level IAM tasks. Finally, traditional enterprise software powerhouses such as IBM, CA or Oracle still remain competitive in the enterprise IAM space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-central-banks-backed-digital-currencies-part-ii-230085586446?source=user_profile---------146----------------",
        "title": "Some thoughts About Central Banks Backed Digital Currencies Part II",
        "text": "This is a continuation of previous article in which we discussed an idea that has been causing some noise in financial markets around the world. The core of the idea is about the potential for central banks to issue their own digital currency, The first part of this essay discussed some of the most immediate implications about the relationship between central banks and cryptocoins. Today, I would like to deep dive a bit into that analysis by dissecting some other implications that the behavior of financial markets could have in digital currencies issued by central banks.\n\nThe idea of countries and central banks issuing their own digital currencies might seem ludicrous at first but we should not be quick to discard it. A few days ago, the Bank of International Settlements(BIS) produced a 16-page analysis that presented the idea of central banks-backed digital currencies as a way to participate and influence the, in their own worlds, \u201cnew taxonomy of money\u201d. In the previous article, we explored three key implications of this ideas. Let\u2019s now discuss a few others:\n\nOne of the not-so-subtle implications of a digital currency backed by central banks is the fact that the cryptocoins will have to be hosted in places(blockchains ) outside banks. More specifically, national cryptocurrencies will operate on public blockchains such as Ethereum. As a result, banks will have to grow accustomed to the idea of relinquishing a lot of the currency control mechanisms they have traditionally enjoyed.\n\nThe financial market is still trying to figure out what influences the price of Bitcoin besides news. Venture capitalist Nikhil Kalshatgi recently suggested the idea that there might be baskets of stocks that influence the price of Bitcoin but he also mentioned he wasn\u2019t confident enough to pick those stocks. That picture radically changes when we start talking about a digital currency backed by a central bank. In that scenario, financial instruments tied to the parent central bank can indirectly influence the price of the cryptocoin. Instruments such as treasury bonds or simple GDP metrics can be highly influential on the price of a digital currencies backed by central banks.\n\nSimilarly to the behavior of FOREX markets, central bank-backed digital currencies are likely to influenced by indicators that reflect the economic health of a nation. Employment reports, the US Index of Economic Indicators (LEI), trade deficit metrics, consumer confidence reports, retail sales are just some examples of indicators that can become relevant of central bank digital coins.\n\nOne interesting balance-act for central bank digital currencies will be how to reconcile the anonimity of cryptocoins with tax obligations. A national cryptocoin can almost become a substitute for traditional cash transactions which are notorious for not being reflected in tax reports.\n\nTo leave the most polemic observation to the end; the idea of raising funds for central bank digital currencies via initial coin offerings(ICOs) is very intriguing. The process can be similar to the sales of bonds or other debt instruments and can be restricted to accredited investors. This idea is more viable in emerging markets than in large first world economies."
    },
    {
        "url": "https://medium.com/@jrodthoughts/this-cool-technology-brings-natural-language-processing-to-databases-58449a6664cb?source=user_profile---------147----------------",
        "title": "This Cool Technology Brings Natural Language Processing to Databases",
        "text": "Seq2SQL is one of the coolest developments in natural language processing(NLP) for business applications in the last few years. Created by Salesforce.com, Seq2SQL allows users to leverage natural language to query information stored in databases.\n\nUsing natural language to interact with databases has long been an elusive goal of information workers. However, recent advancements in NLP technologies have addressed most of the limitations that caused the first wave of technologies in the space to be notoriously ineffective. Seq2SQL now represents the initial step towards making natural language a universal vehicle to interact with databases.\n\nThe specifics of Seq2SQL were outlined in a recent research paper published by Salesforce. One of the most notable contributions of Seq2SQL is the use of reinforcement learning to evaluate the validity of queries and output and improve the behavior of the framework over time. WikiSQL is another cool addition to the Seq2SQL stack. Conceptually, WikiSQL provides a method for training systems that connect natural language to database systems. As you might have guessed, WikiSQL uses Wikipedia as the underlying dataset from which it derives its initial knowledge. Interestingly enough, Salesforce leveraged crowdsourcing techniques powered by Amazon Mechanical Turk to label Wikipedia datasets so that they can be used in natural language queries.\n\nThe release of Seq2SQL is a very exciting development to streamline the application ot natural language in database systems. However, the integration of NLP and line of business systems is far from trivial from a technical standpoint. Here are a few ideas to consider for the short-term roadmap of Seq2SQL:\n\nTools that allow data scientists to train Seq2SQL to interact with heterogeneous databases and line of business systems is a must in order to lower the entry point for the adoption of the technology. Similarly, some of the knowledge built during specific training exercises can be reused by other instances of Seq2SQL.\n\nAmbiguity remains one of the biggest challenges integrating natural language and database systems. One of the manifestations of ambiguity is the fact that a tool like Seq2SQL can produce multiple \u201ccorrect answers\u201d as a response to the same query. Curation mechanisms and tools can help to address this type of behavior in Seq2SQL solutions.\n\nAnother example of ambiguity in tools like Seq2SQL is represented by multiple queries with the same intent that produce the same output. Reinforcement learning and curation tools are essential to address this behavior.\n\nEnabling translations from multiple languages to SQL is also going to become an interesting challenge for the mainstream adoption of Seq2SQL. Fortunately, advanced NLP stacks today provide great support for a large number of natural languages and dialects.\n\nToday, Seq2SQL is mostly conceived as an interfaces that processes natural language queries and produces data outputs. In a future version, the framework should consider producing narratives based on the data outputs. That capability will be key to enable voice interfaces that leverage Seq2SQL."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-case-for-central-bank-digital-currencies-ecfde5a6bdb5?source=user_profile---------148----------------",
        "title": "The Case for Central Bank Digital Currencies \u2013 Jesus Rodriguez \u2013",
        "text": "Yesterday, I explored some of the reasons behind\u2019s China crackdown on Bitcoin and initial coin offerings(ICOs). We concluded the article by explaining that one of the most intriguing rumors about the behavior of the Chinese government was related to their intentions to established their own digital currency. I have no idea about the veracity of those claims but the idea is far from crazy and follows similar initiatives by other countries. However, implementing the concept at the cale of the world\u2019s second largest economy is another matter. Today, I would like to discuss a few ideas that make the case pro and against digital currencies backed by countries and central banks.\n\nFollowing the Path of Others\n\nCentral banks and governments are paying close attention to Bitcoin and cryptocurrencies in general. Just a few days ago, the BIS issued a statement urging central banks to closely follow the trends developed by digital currencies. Along those lines, there are countries which have already announced their intentions to explore the idea of a national digital currency.\n\nIts always Estonia! When comes to adopting cutting edge digital technologies, the small European nation seems to be setting up an example for governments all around the world. Recently, Estonia announced plans to build a national cryptocoin that can operate on the, already established, country blockchain. With the catchy name of Est-Coin,, Estonia\u2019s digital currency will be likely accepted by merchants and government entities and will integrate with the many digital services already powering the Estonian society. To spice things up, Estonia is planning to raise funds for the Est-Coin via an ICO.\n\nEstonia is not the only country evaluating options for the national digital currency. Singapore also seems interested on exploring the idea of a national cryptocoin. Just like Estonia and Singapore, it is more likely that we will see national digital currencies as part of fast growing emerging markets instead of on the world\u2019s top economies.\n\nNational digital currencies will, most likely, be backed and owned by central banks. As a result, they will be influenced by central bank policies such as interest rate levels or cash reserves or stimulus. Similarly, it is likely that central banks will own and keep certain reserves of their own digital currency in order to influence the pricing and market.\n\nI have to admit I have mixed feelings about the long term benefits of national digital currencies. However one of the undeniable advantages of government-backed cryptocoins is the potential for automatic adoption across a large number of businesses and government entities in their country of origin. Those levels of adoption can result a positive influence for the digital currency markets. c\n\nLogically, national digital currencies will have a strong correlation with FIAT currencies. For instance, the price of a hypothetical Chinese cryptocoin should have a strong correlation with the price of the Yuan. That indirect relationship will allow for better trade mechanisms as many FOREX trading patterns will be automatically relevant to cryptocurrencies.\n\nThat idea of a central bank-backed digital currency doesn\u2019t have to be constrained to a single country. How about the idea of an Euro-like digital coin backed by the European Central Bank(ECB). Many of the constraints that make the adoption of the euro complicated across Europe don\u2019t exist in the digital world and the ECB has sure proven to be very effective establishing policies to maintain the stability of currencies."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-dark-reason-behind-china-bitcoin-crackdown-that-nobody-is-talking-about-783eca861d79?source=user_profile---------149----------------",
        "title": "The Dark Reason Behind China Bitcoin Crackdown that Nobody is Talking About",
        "text": "China\u2019s crackdown on digital currencies continues. Following the People\u2019s Bank of China\u2019s recent ban on initial coin offerings(ICOs)(read my previous post about that topic), the Chinese government has proceeded to shutdown the major Bitocoin exchanges in the country. The move was not exactly surprising but it still managed to cause an immediate sharp decline on the price of Bitcoin\n\nChina\u2019s love-hate relationship with digital currencies is somewhat counter intuitive taking into consideration that the country has become the most influential economy in the raise of Bitcoin. Many articles have been written about the different reasons behind China\u2019s crackdown on Bitcoin. However, there is a little hidden reason that has been ignored by most experts and that is at the root of the behavior of the Chinese government. Like everything in China, it boils down to politics. I am talking about the upcoming congress of the Communist Party.\n\nThe meetup of the Party elite in China is never an event to take lightly by financial markets but this one is particularly important. This year, China\u2019s president Xi Jinping is presenting his case to the Party for a second five year term after a not very impactful first term. From that perspective, nothing can hurt his case more than a sentiment of financial instability and vulnerability to \u201ccapitalist corruption\u201d. So yes friends, this is all about politics.\n\nThe reasons behind China\u2019s crackdown on Bitcoin is the same reason why the Asian giant has remained hesitant to take a tough stand on North Korea or why it has been conducting a very aggressive anti-corruption campaign across the country. Its all about perception in the months preceding the \u201cPeople\u2019s congress\u201d.\n\nThe ban on digital currencies is just one piece of a much broader anti-corruption operation by the Chinese government. If you follow China\u2019s financial the you have probably seen the headlines about this operation because they are literally everywhere. Restriction on money-lending startups, a highly publicized trial about a massive Ponzi scheme, commitments from the major investment funds to focus on deploying capital in their homeland, some hard-to-read news about authories questioning some of the country\u2019s most respected business tycoons and the crackdown on crypcoins are all part of President Xi\u2019s reelection message. And you know what? It seems to be working!\n\nAfter years of financial ups and down, China\u2019s financial markets seems to be suspiciously stable. The Yuan is trading at it highest level in years compared to the US Dollar(that is bringing its own set of challenges but that\u2019s a story for another day :) ). Chinese equities (specially tech) keep flying high with stocks like Alibaba and Tencent outperforming the hottest US tech stocks. The recent stability has attracted the attention of US financial powerhouses such as hedge fund Bridgewater Associates which recently announced plans to deploy parts of a new fund in China. Factoring all those perspectives, things seems to be looking up for President Xi leading up to the Communist Party Congress.\n\nBack to Bitcoin now. There have been some analysis indicating that the ban on digital currencies is only temporarily and that China will gradually start opening the doors to cryptocurrency investments under a more regulated environment. There are also rumors that China is evaluating the launch of its own digital currency which can be super interesting. That will be the subject of my next post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-rapid-miner-wants-to-be-the-tableau-of-data-science-28330bfc4fa5?source=user_profile---------150----------------",
        "title": "Technology Fridays: Rapid Miner Wants to be the Tableau of Data Science",
        "text": "Welcome to Technology Fridays! Today we are going to explore one of the emerging areas in the machine intelligence(MI) market: self-service data science and one of the platforms leading the charge in this new field: Rapid Miner.\n\nWhen we talk about self-service business intelligence, immediately names such as Tableau, Qlik or Microsoft\u2019s PowerBI come to mind. With the emergence of MI technologies, there are a new group of platforms that are looking to extend that value proposition into the MI space with new tools that enable non-data scientists to create models and algorithms against their data sources. Rapid Miner is one of the pioneers in that market with a highly sophisticated platform that allows the creation of self-service data science experiences. In that context, you can think about Rapid Miner as a Tableau-like experience for the creation and operationalization of data science applications. Another way to look at this emerging market is as a successor of data intelligence products such as SAS that, although incredibly successful, require a lot of resources to be implemented in enterprise environments.\n\nThe Rapid Miner platform is based on four fundamental components: Studio, Server, Cloud and Radoop. While the Rapid Miner Studio enables the creation of self-service data science models, the other three components of the platform represent runtimes to run and scale those models.\n\nRapid Miner Studio is the main entry point to the data science platform. The tool provides an interactive environment for the creation of data science application. Upon launching the Studio, users have access to hundreds of data science processes that illustrate the different capabilities of the MI engine. Those samples are powered by the Rapid Miner Repository which serves as a catalog of data science models. Users can explore the models visually and even execute them locally, setting up breakpoints and exploring intermediate results. Data sciences programs can also be executed in a background mode in a local environment. The local runtime allow users to test the models without the need of an expensive runtime which is incredibly useful in real world data science applications.\n\nWhen a data science model is ready fro primetime, , it can be deployed to the Rapid Miner Server. This component provides a scalable environment for the persistence and execution of data science programs. The Server runtime also provides tools that enable the evaluation, tracking and monitoring of data science processes.\n\nRapid Miner Cloud extends the capabilities of Rapid Miner Server onto an on-demand cloud runtime. The Cloud environment is fairly symmetric with Rapid Miner Server which streamlines its adoption in hybrid topologies. One of the main advantages of Rapid Miner Cloud is the ability of configuring the runtime requirements (memory, GPUs\u2026) for each individual data science process.\n\nThe integration with third party technologies is another area of strengths of Rapid Miner. The platform provides many connectors that integrates with mainstream data and line of business systems. Among those, Rapid Miner excels at the integration with Hadoop environments powered by Rapid Miner Radoop. Conceptually Radoop provides a self-service graphical interface for analyzing data in a Hadoop cluster. Radoop can be executed directly from the Studio or Server environments. The Radoop Next is a key component of the platform. Nest enables the connection to a Hadoop cluster as well as the execution of data science processes. Under the covers, Radoop and Next leverage Hive to power is data analysis capabilities.\n\nTogether the four components of the Rapid Miner platform( Studio, Server, Cloud and Radoop) provide one of the most comprehensive stacks for the implementation of data science solutions. Rapid Miner is definitely one of the leaders in the self-service data space but it does faces stiff competition in this rapid growing market.\n\nRapid Miner competitors can be segmented in two main groups. One one side, we can place end-to-end machine learning platforms that, even when they are not in the exact same market, have an overlap with Rapid Miner feature set. H2O.ai is the prototypical example of a platform in that market segment. One the other side, we have an increasing group of self-service data science platforms that. despite the difference in terms of capabilities, the are fundamentally going after the same customer base as Rapid Miner. Platforms such as DataIKU, DataRobot, BigML or H2O.ai\u2019s own Driverless are relevant in this market group."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-alexa-cortana-friendship-part-ii-group-conversation-patterns-b81edf922258?source=user_profile---------151----------------",
        "title": "Some Thoughts About Alexa-Cortana Friendship Part II: Group Conversation Patterns",
        "text": "Hello there, we are back after a brief interruption due to hurricane Irma. Today I would like to pick up where we left last week and cover the second part of the essay exploring the implications of the partnership between Amazon and Microsoft to integrate their respective digital assistants [Alexa and Cortana]. In the first part of this article, we discussed the basic integration model proposed in the first iteration of the partnership as well as a series of implications from a market perspective. Today, I would like to focus on some natural language understanding(NLU) patterns that we might see in future versions of Alexa-Cortana integrations.\n\nAs we discussed in the previous article, the initial version of the integration between Alexa and Cortana is based oin a simple patter that allows a user to launch a digital assistant[DA] (Alexa or Cortana) while interacting with the other DA. For instance, a user can ask Alexa to start up Cortana saying something like \u201cAlexa, please open Cortana\u201d. While this interaction pattern is certainly exciting, it results relatively simple to mimic human group conversations. As the integration between Alexa and Cortana progresses, we are likely to see more complex conversational patterns that better resemble human group interactions.\n\nThe integration between Alexa and Cortana can have profound implications for NLU applications as, for the first time, we have the opportunity to interact with multiple DAs as part of the same conversation(not just now but hopefully we will get there :) ). If we use human group conversations as an inspiration, there are some interesting patterns that can be followed to enrich Alexa-Cortana conversations. Let\u2019s explore a few:\n\nThe DA delegated question pattern allows a DA to ask a question to another DA on behalf of its user. Imagine a user in a dialog with an Echo device that requests some information from Cortana asking something like: \u201cAlexa, please ask Cortana to check the number of active opportunities in our CRM\u201d. In that scenario, the user will receive the answer from Alexa without being forced to switch DA runtimes.\n\nImagine take a scenario in which a user is simultaneously interacting with two DAs which share contextual information about the dialog in order to provide more accurate answers. Let\u2019s take the following example:\n\nUser: \u201cCortana, what times are available in my calendar on Friday after.\u201d\n\nUser: \u201cAlexan, could you call Dr. Anderson and book an appointment for that time? \u201c .\n\nIn the previous dialog, Alexa and Cortana are sharing contextual information that includes the user\u2019s calendar availability which is relevant to both parts of the dialog. I know this scenario is a bit futuristic but hopefully it illustrates the potential.\n\nIf Cortana and Alexa become aware of each other\u2019s skills and strengths, it could be possible to develop conversation in which one DA \u201cintuitively\u201d asks the other for information without relying on an implicit user instruction. Imagine a scenario in which a user asks Alexa for the sales forecast for the current quarter and the Amazon DA automatically asks Cortana for the marketing pipeline related to that forecast, that lives in Dynamics365, in order to provide a more complete answer.\n\nThere are many other group conversation patterns that could be relevant to multi-DA conversations. The integration between Alexa and Cortana hopefully becomes the first step towards richer group conversations in DA runtimes."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-intel-sawtooth-is-another-blockchain-platform-going-after-the-enterprise-942d6f631cfc?source=user_profile---------152----------------",
        "title": "Technology Fridays: Intel Sawtooth is Another Blockchain Platform Going After the Enterprise",
        "text": "Welcome to Technology Fridays! As a follow up to last week\u2019s post in which we covered R3 Corda, I decided to stay in blockchain land and discuss another rapidly growing platform in the enterprise blockchain space: we are talking about Intel Sawtooth.\n\nSawtooth represents Intel\u2019s long awaited entrance in the blockchain platform market. Considering Intel\u2019s footprint in industries such as manufacturing or the internet of things(IOT), blockchain technologies seem like a natural fit for the hardware giant. Sawtooth is Intel\u2019s first iteration in the space and one that is clearly targeted to its core industries.\n\nFrom a functional standpoint, Sawtooth can be classified as a blockchain-inspired, distributed ledger platform that extends traditional blockchain stacks with capabilities optimized for enterprise deployments. One of those key contributions of Sawtooth is the support for multiple Consensus protocols.\n\nProof of Elapsed Time or PoET( more marketable ;) ) is a Consensus protocol that follows traditional Nakamoto-style consensus patterns. Sawtooth leverages PoET as the main Consensus algorithm to very transactions in a large blockchain network.\n\nSpeaking of transaction validation, Sawtooth\u2019s transaction processing architecture is, arguably, its biggest innovation from the technology standpoint. Sawtooth includes a very extensible transaction processing pipeline that includes several components. ChainControllers are the Sawtooth component responsible for coordinating the processing of Blocks in the blockchain. A specific type of ChainController known as BlockValidators is focused on validating Blocks and resolving forking in a blockchain network.\n\nThe process of successfully completing transaction is at the core of any blockchain technology. Sawtooth introduces the notion of Completers as components tasked with ensuring that transaction blocks and batches are completed before delivery them to the network. Sawtooh\u2019s Completers use a sequential model in which a Block is considered complete if all its predecessors are also complete. Similarly, Sawtooth includes another component known as BlockPublishers which are responsible for final updates to the network.\n\nTransactions in a Sawtooth network abstract atomic updates to the ledger but they can also be grouped into different structures such as Batches or Families. While Transaction Families model arbitrarily complex transaction taxonomies, Batches represent a group of transactions that should be processed atomically. this clever architecture allows Sawtooth to be applied to highly sophisticated scenarios.\n\nDevelopers can interact with Intel\u2019s Sawtooth via its API or the different SDKs available with the platform. The Sawtooth CLI also offers other vehicles for automating the lifecycle of blockchain applications.\n\nIntel Sawtooth can be considered a tier1 blockchain infrastructure platform. Obviously, Ethereum remains the unquestionable leader in the space. However, competition is stiff with platforms such as R3 Corda, Hyperledger Fabric, Chain or even the intriguing Tezos achieving relevant traction in the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-chinas-ico-shutdown-38f818c6a90a?source=user_profile---------153----------------",
        "title": "Some Thoughts About China\u2019s ICO Shutdown \u2013 Jesus Rodriguez \u2013",
        "text": "This week, the world of digital currencies was shocked by the news that Chinese regulators declared initial coin offerings(ICOs) illegal. The news sent the prices of Ether and Bitcoin(the two cryptocurrencies most used as exchange for ICO tokens) tumbling 8% and 20% respectively before some recovery in the last few days.\n\nThe move by Chinese financial regulators followed warnings from financial market authorities in countries such as Singapore, Canada and The US expressing that some ICOs could be treated as securities and subjected to the corresponding regulation. However, China went far beyond warnings and declared that all fundraising activities through ICOs should cease immediately. The move was obviously extreme but shouldn\u2019t be surprising to anybody familiar with China\u2019s financial markets. After seeing some of the initial overreaction in the market, I decided to write down a few thoughts that might help to put the decision of Chinese regulators into perspective.\n\nThe Things that Makes Chinese Financial Regulators Tick\n\nOne word: stability! That\u2019s essentially the main thing that moves the regulatory arms of China\u2019s financial markets. In China, the government and regulators will to to extreme extends to enforce the stability of the Yuan, the stock exchanges and even the fintech startup ecosystem. Let\u2019s go back to a recent example from early 2016 when Chinese equitities trading all over the world experienced a sharp decline. During those months not a week went by in which we didn\u2019t hear of yet another measure adopted by the government in order to stabilize the trading of equities. From passing \u201covernight laws\u201d that controlled the volume of shares allowed to be sold per stock, bypassing trading halts triggered by market\u2019s circuit breakers( ironically implemented for that purpose) to injecting ridiculous amounts of money into equities, the Chinese government did everything possible to preserve the image of a stable market.\n\nWhen comes to ICOs, Chinese financial regulators see the fundraising mechanisms as a potential sign of instability. Those fears have been accelerated by the growing number of Chinese citizens who are digital currency holders and have been actively participating in ICOs. Another factor influencing the fear of the regulators in the questionable performance of some recent token offerings. Declaring ICOs illegal is definitely an extreme measure but it can be entirely surprising if you understand the DNA of the Chinese financial market.\n\nThe fear by Chinese regulators is partially due to the underperformance of recent ICOs. Just this year, ICOs have raised about $1.5 billion vastly passing the amount of capital raised by blockchain startups. While most ICOs have performed decently, there have been some very high profile token offerings that have disappointed casting a shadow over the entire market. Among the underperformers, we have Bancor which tokens have lost about 12% after raising over $143 million to build a crypto-token exchange. Similarly, Estonia-based Polybius is down 24 % after raising 32%, Encryptel\u2019s token are down 50% and BitcoinGrowthFund is down 59%. Overall, 10% of the ICOs are trading downwards from their original price and 30% have not traded at all.\n\nSeeing those numbers, we can understand the reaction of Chinese regulators but I think that perspective can be very misleading. By the previous numbers, we can infer that 60% of the ICOs are performing above their initial price. That beats the majority of market indices. In terms of numbers, the overall value of ICO tokens have raised an astonishing 28 times since their initial offering overperforming some of the top Index-Funds in the market. On any stable market there are always underperformers; just look at the recent debacle of Snap and BlueApron or the inexplicable raise and fall of the mysterious DryShips stock and suddenly the ICO numbers don\u2019t seen that scary at all.\n\nChina is not the only country (although is certainly the most extreme) to try to take a regulatory stand on ICOs. Last month, the Canadian Securities Administrators(CSA) declared that ICOs are likely to be considered securities and warned about some behaviors in ICOs that could hurt investors. Similarly, the US Securities and Exchange Commission(SEC) recently ruled that one high profile ICO which have raised over $150 million for an automated investment model was in fact a securities offering. To its credit, the SEC published guidelines to help companies pursuing an ICO, understand the circumstances under which their token offering could be considered a security. Singapore is another country that has issued regulatory guidelines about ICOs.\n\nGenerally speaking, ICOs are likely to experience some level of regulation in the near future and I think that should be welcomed by the ICO community. While classifying all ICOs are security offerings might be oversimplistis, we should keep in mind that many times regulators react first and think later :)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/alexa-and-cortana-are-friends-part-i-a-market-perspective-6338e45c0309?source=user_profile---------154----------------",
        "title": "Alexa and Cortana are Friends Part I: A Market Perspective",
        "text": "Cortana and Alexa are becoming friends. At least they are talking to each other ;). Last Wednesday, Microsoft and Amazon announced their intention of integrating their digital assistants(DA) so that users can take advantage of both runtimes simultaneously. The first iteration of the Alexa-Cortana integration is scheduled for later this year and, although simplistic, it enables all sorts of interesting scenarios.\n\nThe basic integration pattern being implemented will allow users interacting with either Alexa or Cortana to launch the other assistant respectively without having to abandon their runtime. Using that pattern, a user interacting with Alexa can launch Cortana by simply saying something around the lines of: \u201cAlexa, please open Cortana\u201d. Similarly, Cortana users will be able to launch Alexa directly from the Microsoft\u2019s DA runtime. While the interaction model seems pretty basic from the conversational standpoint, it has some profound implications for the DA market and the evolution of voice conversational models in general.\n\nWhat Does the Alexan-Cortana Integration Means for the DA Market?\n\nEven though we are still in pretty early stages, we can start speculating about some of the potential implications of the integration between Cortana and Alexa. Today, I would like to cover some of my impressions from the market perspective and in the second part of this article we will discuss some of the implications from the technological standpoint. Let\u2019s review a few of my initial thoughts:\n\nThe Alexa-Cortana integration indirectly acknowledges leverages the strengths and addresses the weaknesses of each DA on several market areas. For instance, by launching Cortana, Alexa users will be able to better interact with Microsoft\u2019s information worket products such as Office365 or Dynamics365. similarly, Cortana users will be abel to take advantage of Alexa\u2019s borad home automation skills portfolio.\n\n2 \u2014 Close the Door to Google and Apple\n\nBy partnering with Microsoft, Amazon will be potentially constraining the avenues for home-assistants competitors such as Google Home or Apple HomePod to gain relevant market traction.\n\nDigital assistants are one of the new and most desired runtimesofothee next generation of digital advertisement platforms. Voice-based advertisement on DA runtimes will unlock new sources of revenues for ad-publishers and have the potential of creating brand new ad-exchange models. I am very intrigued some potential ad-revenue sharing models that could be enabled by the integration between Cortana and Alexa.\n\nThe Alexa-Cortana integration is based on a single pattern that allows a user to launch a DA by directing a voice instruction to another DA. While that pattern seem technologically trivial, it can also be considered the first iteration towards conversational models that involve multiple DA agents. If you think about traditional patterns in human group conversations, there are some very interesting ideas that can be explored to enrich the dialogs involving Alexa, Cortana and end users.\n\nLet\u2019s be a bit ambitious and think beyond the basic runtime switching model enabled by the first iteration of the Alexa-Cortana integration. Imagine scenarios in which two DAs can interact with each other in order to provide the best answer to a user or they can intelligently delegate questions or answers on each other based on their expertise. In the next part of this article, I will present some of the group conversation patterns that I think can enrich multi-DA interactions such as the ones powered by the integration between Alexa and Cortana."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-gets-in-the-ai-first-hardware-game-with-project-brainwave-3af05394eca4?source=user_profile---------155----------------",
        "title": "Microsoft Gets in the AI-First Hardware Game with Project Brainwave",
        "text": "Microsoft has been steadily building one of the most complete artificial intelligence(AI) suites in the market. In just a few years, the Redmond giant has added relevant capabilities in areas such as machine learning platforms(Azure ML), AI APIs(Cognitive Services), R distributions(R Server), deep learning frameworks(Cognitive Toolkit), digital assistants(Cortana) and several others. A few days ago, Microsoft announced its intentions to venture into the AI-first hardware space by unveiling Project Brainwave during the Hot Chips Conference in Cupertino.\n\nProject Brainwave is a new type of programmable chip optimized for the execution of deep learning models. The project builds on Microsoft\u2019s previous announced field programmable gateway(FPGA) chips which offer significant advantages over traditional GPUs and CPUs when comes to the execution and scalability of deep learning programs.\n\nFPGAs have been optimized for the execution of several types of deep learning algorithms such as convolutional neural networks(CNNs), long-short term memory(LSTM) models, reinforcement learning and a few others. The new hardware model has reported over 10x performance improvement over similar GPU and CPU architectures and has been widely deployed across Microsoft\u2019s data science infrastructure.\n\nDeep neural network(DNN) algorithms deployed onto FPGA chips are loaded into the hardware\u2019s memory and scaled across different boards. Currently, Brainwave supports models built on Microsoft Cognitive Toolkit and Google\u2019s TensorFlow but support for new deep learning frameworks should be added in the future.\n\nDiving into chip design might seem like a deviation from Microsoft\u2019s software core strength but it is important to realize that hardware acceleration is an increasingly relevant element of AI solutions. Additionally, Microsoft is not delivering Brainwave on its own and has reportedly partnered with Intel\u2019s Altera on the design and manufacturing of the chips.\n\nThe hardware accelerated AI space is getting really crowded with software vendors such as Microsoft, Google or IBM getting into a market traditionally dominated by chip manufacturers like Intel, NVidia, ARM or Qualcomm. I wrote down a few observations that might help better understand this nascent AI market:\n\n1 \u2014 Multi-Runtime vs. Uni-Runtime Chips: As the market evolves, we should see the adoption of both chips like FPGA that can run AI programs in multiple runtimes(Cognitive Toolkit, TensorFlow) as well as chips like Google\u2019s TPU optimized for a single runtime (TensorFlow).\n\n2 \u2014 Algorithm-Optimized Chips: In the future, we could also see chips optimized to execute specific deep learning algorithms such as CNNs, LSTM or reinforcement learning models.\n\n3 \u2014 Bad News for Chip Manufacturers Stocks: In the long run, the entrance of companies like Google Microsoft, Facebook or IBM into the hardware accelerated AI market can harm the public market sentiments towards chip manufacturers. After all, Wall Street places a lot of importance in the role that IA will play in the market adoption of new technologies from the traditional chip manufacturers.\n\n4 \u2014 Open Source Hardware Accelerated AI: We should soon see new open source designs of AI-first chips that get support from different software and hardware companies.\n\n5 \u2014 Cloud Distributions Matter: Cloud infrastructures such as AWS, Azure, Google Cloud, Bluemix or Alibaba Cloud are likely to become the main distribution channel for AI-first chips. As a result, the cloud incumbents are in a unique position to influence the future of hardware accelerated AI."
    },
    {
        "url": "https://medium.com/coinmonks/technology-fridays-r3-corda-is-the-greatest-blockchain-platform-you-never-heard-of-b4baf1336b58?source=user_profile---------156----------------",
        "title": "Technology Fridays: R3 Corda is the Greatest Blockchain Platform You Never Heard Of",
        "text": "Welcome to Technology Fridays! Today we are going to discuss one of the most complete blockchain platforms in the market that doesn\u2019t get the recognition it deserves; we are talking about R3 Corda.\n\nWhen you think about blockchain infrastructure platforms, names like Ethereum or IBM Hyperledger Fabric come to mind. Corda is a name that should definitely be in that list. create by a consortium of the top banks in the world, Corda can be considered, feature-by-feature, one of the most sophisticated platforms to enable the implementation of enterprise blockchain applications.\n\nMany experts would argue that Corda should not even be considered a blockchain platform as its feature set expand way beyond the typical value proposition of blockchain technologies. The R3 consortium prefers the term distributed ledger platform to label Corda. To avoid confusions, let\u2019s use the term blockchain-inspired distributed ledger platform (how was that for a marketing contribution ? ;) .\n\nLike other blockchain technologies, Corda\u2019s infrastructure is based on a network of nodes that are responsible for executing smart contracts. Corda takes this traditional concept a step further and introduces the notion of Corda Distributed Applications or CorDapps which encapsulate all components of a decentralized business process. CorDapps include several capabilities including Contracts which is Corda\u2019s analogous of blockchain smart contracts.\n\nA CorDapp Contract is responsible for process transactions and make the appropriate modification to the state of the underlying ledger. The transaction verification process in Corda must be deterministic ( a contract must always accept or always reject a transaction) in order to ensure the integrity of the network. To guarantee that determinism, Corda introduces the concept of a Contract Sandbox which is an environment that prevent Contracts from importing libraries that can introduce non-deterministic artifact such as random numbers, dates or external data.\n\nDeterministic contracts are essential in blockchain applications but, let\u2019s face it, they can also result very imitating in order to implement complex business logic. To circumvent that limitation, Corda introduces the notion of Flows which are processes that coordinate updates to the ledger without being subjected to the deterministic limitations of Contracts. Just like Contracts, Flows execute as part of CorDapps but they are able to perform non-deterministic actions such as network calls, IO operations, invoking external libraries and other operations subjected to randomness. Flows can be implemented using Corda\u2019s Flow framework in JVM-based languages like Java.\n\nFrom the infrastructure standpoint, Corda can be seen as a network of nodes running CorDapps. However, differently from other blockchains, Corda\u2019s networks are completely permissioned which means that every node in the network has a known identity. In order to enable that capability, Corda uses the concept of a Doorman which are nodes responsible for enforcing the identity management protocols that allow nodes to join the network. Nodes in Corda communicate strictly using point-to-point protocols based on TLS encrypted messages delivered via AMQP. To improve the transaction throughput limitation of traditional blockchain stacks, Corda relies on the UTXO(unspent transaction output) model. UTXO constraints transaction to receive a number of states as input and produce a corresponding number of states as output which facilitates the execution of transactions in parallel.\n\nOne of the most complex but equally innovative capabilities of Corda is it node architecture. In a Corda network, every Nodes uses an architecture based on five fundamental components:\n\n1 \u2014 A persistent tiner that has a vault for storing historic and current states as well as a storage services that logs the transactions processed by that Node.\n\n2 \u2014 A network interface that enables the communication with other Nodes.\n\n3 \u2014 A RPC interface used to interact with the Node\u2019s owner.\n\n4 \u2014 A Service Hub that allows Flows to call Services from other Nodes or access other information relevant to coordinate ledger updates.\n\n5 \u2014 A Plug-in Registry that is used to access and install CorDApps in that Node.\n\nLike other blockchain technologies, Corda\u2019t networks rely on Consensus algorithms in order to process transactions. One notable innovation in this are is the concept of Notaries which are nodes required to sign a transaction before its finalized. Conceptually, Notaries are designed to address the famous \u201cdouble-spend\u201d problem in blockchain networks.\n\nBorrowing a page from Ethereum\u2019s architecture, Corda also uses the notion of Oracles to allow the access to off-chain information relevant to a transaction. Oracles are the main mechanisms to integrate Corda with external applications.\n\nI like to think of Corda as a blockchain-inspired, distributed ledger infrastructure platform. From the competitive standpoint, Corda competes with tier-1, low level blockchain platforms such as Ethereum or Hyperledger Fabric. Other blockchain platforms such as J.P Morgan\u2019s Quorum, Tezos , NASDAQ\u2019s Linq or Chain can also be considered relevant competitors of Corda."
    },
    {
        "url": "https://medium.com/@jrodthoughts/reinforcement-learning-soup-mdps-policy-vs-value-learning-q-learning-and-deep-q-networks-4ac137acd07?source=user_profile---------157----------------",
        "title": "Reinforcement Learning Soup: MDPs, Policy vs. Value Learning, Q-Learning and Deep-Q-Networks",
        "text": "Reinforcement learning is one of the hottest topics in artificial intelligence(AI) and one that has been broadly covered in this blog. Today, I would like to get a bit more technical and refresh some of the concepts I previously covered about policy vs. value learning and discuss the concept of Q-Learning as one of the most interesting techniques in modern reinforcement learning applications.\n\nMDPs and Policy vs. Value Learning\n\nReinforcement learning is one of the AI disciplines that resembles human thinking the closest. Essentially, reinforcement learning models AI scenarios using a combination of environments and rewards . In that world, the role of an AI agent is learn about the environment while maximizing its total reward. One of the most popular mechanisms to represent reinforcement learning problems is known as Markov Decision Processes(MDPs) which decomposes scenarios as a series of states, connected by actions and associated to a specific reward. In MDPs, an AI agent can transition from state to state by selecting and action and obtaining the corresponding rewards.\n\nConceptually, MDPs aim to help AI agents to find the optimal policy in a target environment. Policies are defined by the action an AI agent takes on a specific state. The objective of MDP policies is to maximize the future return fro the AI agent. The biggest challenges on any MDP scenario is always how to tech the AI agent to the reward. Broadly speaking, the solutions to this challenge fall into two main categories: policy and value learning.\n\nPolicy learning focuses on directly inferring a policy that maximizes the reward on a specific environment. Contrasting with that approach, value learning tries to quantify the value of every state-action pair. Let\u2019s explain those concepts using an example of an AI agent trying to learn a new chess opening. Using policy reinforcement learning, the AI agent would try to infer a strategy to develop the pieces in a way that can achieve certain well-known position. In the case of value-learning, the AI agent would assign a value to every position and select the moves that score higher. Taking a psychological perspective, policy-learning is closer to how adults reason through cognitive challenges while value-learning is closer to how babies learn.\n\nQ-Learning is one of the most popular of value reinforcement learning. Conceptually, Q-Learning algorithms focus on learning a Q-Function that qualifies a state-action pair. A Q-Value represents the expected long term reward of a Q-Learning algorithm assuming that it takes a perfect sequence of actions from a specific state.\n\nOne of the main theoretical artifacts of Q-Learning is known as The Bellman Equation and it states that \u201cthe maximum future reward for a specific action, is the current reward plus the maximum reward for taking the next action\u201d. That recursive rule seems to make a lot of sente but it runs into all sorts of practical issues.\n\nThe main challenge with Q-Learning and the Bellman Equation comes to the compute cost associated with estimating all combinations of state-action rewards. The computation cost quickly gets out of control in problems involving a decent number of states. To deal with that challenge, there are techniques that try to approximate a Q-function instead of learning an exact one by evaluating all possible Q-Values.\n\nOne of the biggest breakthroughs in Q-Learning cam from Alphabet\u2019s subsidiary DeepMind when they used deep neural networks to estimate the Q-Value of all possible actions for a given state. This technique is called Deep-Q-Networks and has become one of the best-known forms of Q-Learning. I will deep dive into Deep-Q-Networks in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/macie-brings-ai-first-infrastructure-to-aws-318ce6df4199?source=user_profile---------158----------------",
        "title": "Macie Brings AI-First Infrastructure to AWS \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) is becoming an integral component of all aspects of enterprise architectures and infrastructure is not the exception. At the recent AWS Summit in New York City, Amazon announced the release of Macie, a new cloud service that leverages machine learning to protect data in the AWS cloud. Macie is an example of a new trend that I often referred to as AI-first infrastructure.\n\nConceptually, Macie is designed to identify and protect sensitive information across a broad range of AWS data services like S3. When users configure Macie, they use a risk score to classify sensitive information. The initial classification effectively turns into a training dataset used to help Macie get familiar with the structure of the data and apply the knowledge to new data going forward. From that point on is where the magic of Macie happens. The platform leverages unsupervised learning algorithms to detect access patterns in sensitive data elements. Anomalies in the access behavior are flagged and communicated to human experts for subsequent reviews.\n\nThe concept behind Macie contains some interesting novelties but is far from being a breakthrough innovation in the cloud security space. The idea of leveraging machine learning models top detect access control patterns in cloud data systems has been around for a few years. Recently acquired Elastica has been one of the pioneers in the space that today include incumbents such as Microsoft which has acquired similar capabilities and implement them into its Azure and Office365 platforms. However, there are some specific benefits of Macie brings to the table that should not be taken lightly.\n\nFirst of all, Macie will be able to provide access control intelligence across the large portfolio of data storage services available in the AWS cloud. At the moment, Macie only works with S3 but new storage services should soon be supported. Similarly, it is not crazy to think that, in the future, Macie could be integrated with third party cloud database or services running on AWS. Secondly, I believe Macie\u2019s laser focus on access control patterns can drive a lot of innovation and benefits to AWS storage systems while avoiding the distraction of tackling broader cyber-security areas. Finally, we should ignore the fact that AWS\u2019s market dominance and large footprint within enterprise customers can help to accelerate the adoption of Macie to make it a leader in the space.\n\nThe Raise Towards and AI-First Infrastructure\n\nIn the past, I\u2019ve written extensibly about the concept of AI-First infrastructure technologies. Macie is not the first example of AI-First infrastructure stack but is, arguably, one of the most visible attempts to take those concepts mainstream.\n\nBy AI-First infrastructure, we refer to technologies that incorporate many of the knowledge of devops and IT operators into the infrastructure layer. Security, storage networking, compute are some of the infrastructure areas that are being re-imagined with AI as a foundational building block. Obviously, the AI-infrastructure space offers plenty of opportunities for startups but they should be aware that cloud incumbents such as Amazon, IBM, Microsoft and Google are jumping aggressively into that market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/azure-event-grid-is-a-first-step-towards-the-vision-of-a-serverless-middleware-d2807b553eee?source=user_profile---------159----------------",
        "title": "Azure Event Grid is a First Step Towards the Vision of a Serverless Middleware",
        "text": "A few weeks ago, I wrote about the potential of serverless computing to enable the next generation of middleware technologies. Now, Microsoft is talking a first step towards that vision with the release of Azure Event Grid.\n\nAt a high level, Event Grid is a native Azure service that simplifies the implementation of event-based applications. More specifically, Event Grid enables the routing of events across different Azure services. Using Event Grid, developers can public and receive events from different services, dynamically categorize them under different topics and route them to different Azure endpoints.\n\nEvent Grid is an obvious extension to Microsoft\u2019s serverless stack. However, surprisingly, the platform wasn\u2019t built using Azure Functions which is Microsoft\u2019s foundational serverless technology. Instead, Event Grid was implemented on top of Service Fabric which is Azure\u2019s platform for building and managing microservices. Service Fabric provides fundamental building blocks of microservices architectures such as Actors or Stateful Services in a simple architecture and programming model. Leveraging Service Fabric provides Event Grid with an extensible, scalable and manageable foundation to deliver its serverless messaging capabilities.\n\nConceptually, Event Grid makes Events generated by Azure services a first-class citizen in the Azure platform. To some extent, you can think about Event Grid as a platform for managing and processing events across different Azure endpoints. The platform integrates with several Azure services including Functions, Blob Storage, Resource Manager, Event Hub, WebHooks, LogicApps and several others. New integrations, including a much expected support for Azure IOT Hub should be added in the near future.\n\nAzure Event Grid represents a strong differentiator in the serverless technology market which have seen the top competitive stacks evolve into very similar offerings. Despite your cloud platform preferences, we can\u2019t deny that serverless platforms such as AWS Lambda, Bluemix OpenWhisk, Google Cloud Functions or Azure Functions literally match each other feature by feature. Technologies such as Azure Event Grid expand the value proposition of serverless platform beyond the simple execution of functions.\n\nThe initial release of Azure Event Grid looks like a solid step towards a very ambitious vision. This version provides some glimpse into the potential evolution of serverless middleware technologies as a relevant category in the cloud space. Before getting too excited, I\u2019ve listed a few ideas I would like to see as part of Azure Event Grid in the shorterm.\n\n1 \u2014 Third Party Event Publishers and Handlers: Azure Event Grid should include integrations with popular SaaS stacks to generate and process events through the platform.\n\n2 \u2014 Event Hub-IOT Hub Strategy: Azure provide several messaging technologies that enable event routing and management and there is certain level of overlap that can cause confusion among developers. From that perspective, I would like to see a clear strategy for using Event Grid together with other Azure messaging services such as Event Hub or IOT Hub.\n\n3 \u2014 Cortana Integration: The combination of Event Grid and Cortana Skills opens the door to so many interesting scenarios that would require a separate post to explain them :).\n\n4 \u2014 Cognitive Services Handlers & Publishers: Event Grid could be an ideal bridge to integrate Microsoft Cognitive Services with other cloud technologies.\n\n5 \u2014 Logic Apps Integration: As an advocate of the serverless middleware concept, I find the integration between Event Grid and Logic Apps super intriguing. I would like to see Event Grid capabilities expanded to support more sophisticated iPaaS scenarios with Logic Apps."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-utility-theory-and-artificial-intelligence-part-ii-axioms-6dc09b2388ec?source=user_profile---------160----------------",
        "title": "Some Thoughts About Utility Theory and Artificial Intelligence Part II: Axioms",
        "text": "This is the second part of an essay about the role of Utility Theory in artificial intelligence(AI). In the first part of this article, we introduced Utility Theory as one of the main vehicles AI agents use to make decisions under uncertainty. We also introduced one of the main elements of Utility Theory known as the principle of maximum utility or MEU which is an indispensable element of AI algorithms that rely on this theory (please read the previous article for more details). today, I would like to explore some of the fundamental mathematical axioms of Utility Theory and it relationship with AI scenarios.\n\nWhen we left out previous article, we had just introduced a hypothetical scenario that have you at a nice restaurant struggling to make a decision between a salmon or a chicken dish. As you can imagine, there are many unknown factors(uncertainly) that can contribute to that decision. To help you through your struggles, Utility Theory introduces six fundamental axioms that we are going to cover in this article. The axioms will also help to put the principle of MEU in a more constrained perspective.\n\nThe principle of Orderability states that given two sets of options, a rational AI agents should either prefer one to the other or rate the two as equally preferable.\n\nGoing back to our nice dinner scenario, you must decide between the salmon and the chicken dish or rate the two as equally delicious. Orderability is another way to say that the AI agent can\u2019t avoid making a decision at any given state.\n\nThe Transitivity axiom states that given any three paths Op1, Op2 and Op3. If an AI agent prefers Op1 to Op2 and Op2 to Op3 then it must prefer Op1 to Op3.\n\nIn our scenario, the principle of Transitivity means that if you prefer salmon to duck and duck to chicken then you must prefer salmon to chicken.\n\nThe principle of Substitutability states that if an AI agent is indifferent between two options Op1 and dOp2, then the agent is also indifferent between two more complex options that are identical except that Op1 is substituted for Op2 in one of them.\n\nUsing Substitutability, if you don\u2019t have any preference between salmon and chicken then you should also like salmon fettuccine and chicken fettuccine the same.\n\nThe Monotonicity axiom states that if two options have the same two possible outcomes Oc1 and Oc2, if an agent prefers Oc1 to Oc2, it should also prefer the option with the highest probability of Oc1 occurring.\n\nSuppose that you are going to pair the salmon or the chicken with either a red Burgundy (Chambertin) or a white one (Montrachet ). If you prefer the Montrachet to the Chambertin, then you should also prefer the salmon to the chicken as the former goes better with the Montrachet(that\u2019s also debatable but I am trying to wrap up this article ;) )\n\nThe principle of decomposability states that complex options can be reduced to simpler ones using the laws of probability.\n\nIn our dinner scenario, Decomposability tells us that if you prefer salmon fettuccine to chicken fettuccine there is also a high probability that you would prefer salmon to chicken.\n\nThe Continuity law states that if there is an Op3 between Op1 and Op2 in preference, then there is a probability P for which an AI agent will be indifferent between Op3 and an option that yields Op1 with probability P and Op2 with probability 1-P\n\nI know the principle of Continuity might sound confusing but, if we take our scenario, it simply \u201csorts of\u201d means that if you prefer chicken to rabbit and rabbit to salmon, there is some dish based on both chicken and salmon that you would like as much as rabbit( that\u2019s just a theory though ;) ).\n\nThe previous axioms are the cornerstone of Utility Theory and setup the foundation for the applicability of the principle of MEU in AI agents. Despite the undeniable logical value of Utility Theory, we humans are great at ignoring it using cognitive abilities such as judgment or biases. That will be the subject of a future article."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-iot-is-a-bright-spot-in-oracle-clouds-portfolio-61378d16f735?source=user_profile---------161----------------",
        "title": "Technology Fridays: IOT is a Bright Spot in Oracle Cloud\u2019s Portfolio",
        "text": "Welcome to Technology Fridays! Today we are going back to the internet of things(IOT) market with a platform that has been, little by little, gaining a lot of traction in the space; we are talking about the Oracle IOT Cloud Service.\n\nOracle Cloud has a lot of work to do to become competitive with market leaders such as Azure, AWS, Bluemix or Google Cloud. While Oracle Cloud is certainly a contender when comes to traditional storage and compute cloud technologies, the platform has fallen behind incumbents in new technology areas such as artificial intelligence(AI), machine learning, serverless computing, cyber-security and others. IOT seems to be the exception to that rule. Oracle IOT Cloud Service has established itself as one of the most sophisticated cloud IOT platforms in the market frequently outperforming competitive offerings from Amazon, Microsoft, IBM or Google.\n\nFrom a featureset standpoint, Oracle IOT Cloud Service looks generally similar to its competitors. The platform provides a suite of infrastructure and platform services that enable backend capabilities of IOT solutions in areas such as device management, messaging, security, stream data processing ,analytics and several others. However, Oracle IOT Cloud Service also provides some very differentiated innovations in several of those areas.\n\nDevelopers can start using Oracle IOT Cloud Service by logging into the platform\u2019s Management Console UI. The Console UI is the main user interface to configure the different component of IOT solutions such as applications, devices, objects, business rules and many others. Using the IOT Cloud Console UI, developers can also configure integrations with other Oracle Cloud services such as Cloud Storage.\n\nNo IOT platform is complete without a robust device management layer and Oracle IOT Cloud Service definitely excels in this area. The Oracle IOT Cloud Service Gateway efficiently brokers the communication between IOT devices and the platform\u2019s endpoints using protocols such as MQTT. The IOT Service Gateway also performs smart message processing routines such as message throttling or roaming which are indispensable in high volume message IOT topologies. One of my favorite features of the Oracle IOT Cloud Service is the IOT Device Simulator that enables the creation of simulated devices without requiring any hardware deployments. Needles to say that the IOT Device Simulator results incredibly useful to simulate complex device topologies in IOT scenarios.\n\nOracle Cloud IOT Service provinces a rich set of options for developers implementing IOT applications. The platform includes client libraries for common IOT runtimes such as JavaScript, Java Android, IOT, C POSIX and others. Those client libraries are abstractions on top of the Oracle IOT Cloud Service REST API that provides programmable interfaces for the main capabilities of the platform. The Oracle IOT Cloud Service also operates on low-level architectures such as the ARM mbed OS. Most client libraries provide support for MQTT as the main protocol to exchange messages between IOT devices and cloud endpoints.\n\nAnother cool innovation of the Oracle IOT Cloud Service platform is the use of BOPs(Business Object Providers) that can ne directly integrated into the Oracle Application Builder Cloud Service(ABCs) to create rich mashups and dashboards. IOT Cloud Service BOPs include devices, models, messages, and others. Device provisioning is enables in Oracle IOT Cloud Service via the Interactive Provisioning Tool. That utility is, essentially, a shell script that enables the creation and onboarding of trusted assets in IOT devices. Once provisioned, devices can start exchanging messages with the platform\u2019s endpoints. Typically, Oracle IOT Cloud Service processes those messages using its stream data processing capabilities and integrates them into Oracle Cloud Big Data infrastructure for further analytics. Oracle IOT Analytics is the component responsible for those processes.\n\nOracle IOT Cloud Services faces strong competition on several segments of the IOT platform market. PaaS-centric IOT services such as Azure IOT Suite, AWS, IOT, Google Cloud IOT Core or Watson IOT Platform are formidable competitors. Industrial IOT platforms such as GE Predix, C3IOT or ThingWorx are strong contenders in the industrial enterprise space. Finally, IOT startups such as Xively have enough traction to be considered relevant competitors of the Oracle IOT Cloud Service."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-utility-theory-in-artificial-intelligence-part-i-9c536dd1d40d?source=user_profile---------162----------------",
        "title": "Some Thoughts About Utility Theory in Artificial Intelligence Part I",
        "text": "Utility functions are one of the elements of artificial intelligence(AI) solutions that are frequently mentioned but seldom discussed in details in AI articles. That basic AI theory has become an essential element of modern AI solutions. In some context, we could generalize the complete spectrum of AI applications as scenarios that involve a utility function that needs to be maximized by a rational agent. Before venturing that far, we should answer a more basic question: What is a utility function?\n\nUtility functions are a product of Utility Theory which is one of the disciplines that helps to address the challenges of building knowledge under uncertainty. Utility theory is often combined with probabilistic theory to create what we know as decision-theoretic agents. Conceptually, a decision-theoretic agent is an AI program that can make rational decisions based on what it believes and what it wants. Sounds rational, right? :)\n\nOk, let\u2019s get a bit more practical. In many AI scenarios, agents don\u2019t have the luxury of operating in an environment in which they know the final outcome of every possible state. Those agents operate under certain degree of uncertainly and need to rely on probabilities to quantify the outcome of possible states. That probabilistic function is what we call Utility Functions.\n\nUtility Theory is the discipline that lays out the foundation to create and evaluate Utility Functions. Typically, Utility Theory uses the notion of Expected Utility (EU) as a value that represents the average utility of all possible outcomes of a state, weighted by the probability that the outcome occurs. The other key concept of Utility Theory is known as the Principle of Maximum Utility(MEU) which states that any rational agent should choose to maximize the agent\u2019s EU.\n\nThe principle of MEU seems like an obvious way to make decisions until you start digging into it and run into all sorts of interesting questions. Why using the average utility after all? Why not to try to minimize the loss instead of maximizing utility? There are dozens of similar questions that challenge the principle of MEU. However, in order to validate the principle of MEU, we should go back to the laws of Utility Theory.\n\nThere are six fundamental axioms that setup the foundation of Utility Theory. In order to explain those, let\u2019s pick a scenario in which you are having dinner at a restaurant and you are trying to decide between a salmon or a chicken dish. There are many factors that go into that simple decision. Which dish goes better with this gorgeous Montrachet we just ordered? How about the dessert? How would I feel if the chicken is overcooked? Is the salmon\u2019s portion too small?\u2026Hopefully you got the point.\n\nUtility theory assigns a probability to each one of those possible states that try to orchestrate decisions based on that. However, those decisions are governed by a group of six fundamental axioms: Orderability, Transitivity, Continuity, Substitutability, Monotonicity and Decomposability. Together these six axioms help to enforce the principle of MEU. I will deep dive into each one of these axioms in the second part of this essay."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cryptic-but-intelligent-how-homomorphic-encryption-can-revolutionize-artificial-intelligence-aef29b9c988e?source=user_profile---------163----------------",
        "title": "Cryptic but Intelligent: How Homomorphic Encryption can Revolutionize Artificial Intelligence",
        "text": "Have you ever heard of homomorphic encryption? If not, I recommend you check it out because that relatively unknown security parading promises to become one of the most important developments to accelerate the mainstream adoption of artificial intelligence(AI) in the near future.\n\nData sharing is one of the biggest challenges with the adoption of AI solutions in the real world. While every week there are new AI models that pioneer breakthrough techniques, they hardly ever get applied against confidential datasets from regulated industries. The examples that we find in AI research literature of AI algorithms evaluated using public datasets such as the famous MNIST, they are rarely directly applicable in real world scenarios. That\u2019s just a reality.\n\nIn this ultra-competitive, global economy, data has become a new form of currency and companies closely guard and protect their precious datasets frin anybody that can get extra competitive advantage from analyzing them. as a result, in most regulated industries such as financial markets, healthcare or defense, there are almost no public datasets that can be actively used by AI researchers in order to tackle mission-critical problems from that industry. Furthermore, most companies are reluctant to share their datasets with AI labs in universities because of fears that the information might be stolen. That bring us to homomorphic encryption.\n\nThe roots of homomorphic encryption date back to 2008, when an IBM researcher named Craig Gentry was able to perform a series of mathematical operations on encrypted data without needing to decrypt it. Gentry\u2019s initial prototype tool the cyber-security world by storm and it is widely regarded as the first example of homomorphic encryption.\n\nThe biggest challenges with practical homomorphic encryption techniques is that they tend to require ridiculous amount of computing power. However, recent breakthroughs by companies such as Microsoft and IBM seem to be taking us closer to see homomorphic encryption techniques available in cloud platforms such as Azure or Bluemix.\n\nClearly, homomorphic encryption will allow organizations to share protected datasets so that they can be used in AI models. However, the benefits of homomorphic encryption for AI agents go beyond conceptual and into the core mathematical foundation of this new security technique. Today, we have practical homomorphic encryption techniques such as the Fan and Vercauteren Schemes that allow the execution of addition and multiplication operations on high degree polynomial ciphertexts in an algebraic ring. The thing is that achieving consistency in addition and multiplication helps to preserve the structure of the dataset. Considering that AI algorithms deeply care about the structure of the data, that type of homomorphic encryption technique ais key to allow the execution of AI models on encrypted datasets. Neural cryptography is another similar technique that is specifically optimized for machine learning algorithms using encrypted datasets.\n\nhomomorphic encryption has the potential of bridging the gap between enterprises and AI researchers. Using homormophic encryption techniques, companies can share confidential, encrypted datasets with partner companies so that they can be used in novel AI models. similarly, homomorphic encryption can help to enforce new levels of compliance and regulation in AI solutions without necessarily constraining progress."
    },
    {
        "url": "https://medium.com/@jrodthoughts/with-coco-framework-microsoft-wants-to-become-the-redhat-of-the-blockchain-5b35f8ac8707?source=user_profile---------164----------------",
        "title": "With Coco Framework, Microsoft Wants to Become the RedHat of the Blockchain",
        "text": "Did you see what I did with that title, right? ;) Well, if the blockchain is the new Linux, Microsoft (as weird as that sounds) is certainly trying to become the RedHat of the new ecosystem. The newest addition to the Redmond giant blockchain stack is another step in that direction.\n\nThe interest around blockchain technologies continues raising but its adoption in enterprise environments remains limited. Aspects such as governance, access control, transaction throughput are still very constrained in blockchain platforms that target the enterprise. To some extent, the evolution of blockchain enterprise runtimes hasn\u2019t really kept pace with the rapid raise of the blockchain application development stacks. Furthermore, the increasing number and fragmentation of blockchain technologies makes incredibly difficult for enterprises to implement a consistent runtime. Now Microsoft wants to fill that gap.\n\nCoco framework is Microsoft\u2019s latest addition to its blockchain suite of technologies. Functionally, Coco framework attempts to simplify the deployment and operationalization of blockchain applications. Interestingly enough, Coco framework is not another blockchain ledger. Instead, the new platform focuses on providing a consistent runtime compatible with a variety of blockchain protocols and application development stacks such as R3 Corda, J.P Morgan Quorum or Intel\u2019s Hyperledger Sawtooth.\n\nFunctionally, the Coco Framework introduces the notion of a trusted execution environment (TEE) that can run and scale blockchain applications. Coco Framework\u2019s TEE leverages tools such as Intel\u2019s Software Guard Extensions and Windows Server Virtual Secure Mode which ensure secured , trusted connections between endpoints. the \u201cimplicit\u201d trust in the environment allows application running on TEEs to avoid performing the costly proof-of-work algorithms common in blockchain infrastructures. As a result, applications running on Coco Framework have seen tremendous improvements in transaction processing capacity. For instance, Microsoft reported that their initial pilot of Ethereum and Coco Framework is able to process about 1600 transactions per second.\n\nIn addition to performance throughput, the Coco Framework improves blockchain stacks with several enterprise-ready capabilities such as governance and access control improves blockchain stacks with several enterprise-ready capabilities such as governance and access control. With only a few modifications to the Ethereum protocol, Coco introduces access control policies that help to govern aspects such as transaction visibility and confidentiality. In some context, the Coco Framework can be seen as an access control and governance layer on top of blockchain platforms such as etheruem.\n\nMicrosoft is planning to open source the Coco framework in early 2018. The current work is focused on optimizing the stack to work with different blockchain platforms such as corda, Hyperledger or Quorum.\n\nI have to confess I have mixed feelings about the Coco Framework. The new additions in areas such as runtime governance, consistency, transaction throughput, access control are certainly a must-have in order to streamline the adoption of blokchain technologies in the enterprise. However, bypassing the proof-of-work protocol can diminish some of the benefits of blockchain technologies in several scenarios. We will have to see how the Coco Framework evolves but we can all agree that the technology represents another interesting blockchain innovation by Microsoft that has been quietly building one of the most complete enterprise blockchain offerings in the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-azuqua-and-ipaas-2-0-making-cloud-integration-cool-again-3fc1bda931b6?source=user_profile---------165----------------",
        "title": "Technology Friday: Azuqua and iPaaS 2.0: Making Cloud Integration Cool Again",
        "text": "Welcome to Technology Fridays! Today we are going to focus on the integration platform as a service(iPaaS) space and one of the new names that is bringing a lot of innovation to that market: Azuqua. Fresh from a $10.8 million round led by Insight venture Partners, Azuqua is one of the names to follow among the new generation of iPaaS technologies.\n\nThe iPaaS segment has seen a lot of demand in the last few years buts the current composition of the market still has major gaps that need to be filled. On one side of the spectrum, we have dominant, enterprise-focused iPaaS stacks such as SnapLogic or MuleSoft CloudHub which posses incredibly sophisticated capabilities but typically require some on boarding and professional services work before a company can leverage their full benefits. On the opposite side of the iPaaS market, we have stacks like Zapier or IFTTT that provide a self-service model that allows developers to quickly get started with the platform but that results too limited for most enterprise scenarios. In between those two groups of iPaaS stacks, the market has created a strong demand for cloud integration technologies that are sophisticated enough to power enterprise scenarios while also simple enough for developers to quickly get started building integration solutions. Let\u2019s call this generation of technologies iPaaS 2.0 and consider Azuqua one of the platforms leading that class.\n\nAzuqua abstracts integration applications using a very simple group of constructs that are available through the Azuqua designer, the platform\u2019s mail development tool. Azuqua introduces the concept of FLOs as a container for all artifacts related to an integration application. A FLO is structurally composed by a series of Cards which represent atomic actions in integration workflows. Azuqua includes two main types of Cards: Actions and Events. From a workflow standpoint, an Azuqua FLO always starts with an Event followed by a series of Actions.\n\nAs you might have already figured out, Azuqua Events represent a point-in-time occurrence that triggers the execution of a FLO. Azuqua models Events in three main groups: Application, Scheduled and On-Demand. Application Events are created based on a condition in an external application. Scheduled Events start a FLO oat a specific time while On-Demand Events activate a FLO from an external or internal applications.\n\nActions are Azuqua Cards that orchestrate the control and data flow of an integration FLO and abstract specific business logic routines. Azuqua includes different categories of Action such as cryptographically functions, control flow primitives or mathematical routines.\n\nDevelopers can implement Azuqua FLOs directly from the designer and expose them via APis so that they can be invoked by client applications. Azuqua operates like a native cloud service but it also supports connectivity to on-premise back-office systems. the platform has a strong dependency on the Microsoft Azure platform (probably attributed to the DNA of the founding team) but support for other cloud infrastructures should soon follow.\n\nAzuqua is one of the new platform pushing the boundaries of the iPaaS 2.0 market. Another technology I like to place in this category ( of an up and coming iPaaS stack) is Azure Logic Apps which enables iPaaS capabilities as a native Azure service. iPaaS pioneers such as SnapLogic, MuleSoft CloudHub, Dell Boomi or IBM CastIron Live should also be considered competitors of Azuqua."
    },
    {
        "url": "https://medium.com/@jrodthoughts/antifragility-and-digital-currencies-how-chaos-is-helping-the-cryptocoin-market-part-ii-1f62a720972d?source=user_profile---------166----------------",
        "title": "Antifragility and Digital Currencies: How Chaos is Helping the Cryptocoin Market Part II",
        "text": "This is the second part of an essay that presents the thesis of antifragility as a key characteristic of digital currency markets. In the first part this essay, we introduced the concept of antifragility based on the thesis proposed by Nassim Nicholas Taleb in his book antifragile in which he refers to antifragility as a property of systems that get better with random shocking events. The first part of this essay explored three key factors that are helping cryptocurrencies grow into a really antifragile ecosystem(see the first part of this article for more details\u2026). Today, I would like to continue exploring some of the factors that have been contributing to the antifragility of cryptocoins. Let\u2019s get started:\n\n4 \u2014 When Killing the Founder Doesn\u2019t Kill the Currency\n\nA few weeks ago, Ether experienced a massive crash from $400 to almost 10 cents. The reason for the abrupt decline was a fake press release claiming that founder of Ethereum had been killed in a car accident. Even when the markets realized that the whole thing was a scam designed to benefit a handful of speculators, digital currency exchanges such as CoinBase decided to honor the transactions that bought Ether on the low end before its quick recovery.\n\nThe Ether crash certainly showed how vulnerable digital currencies can be to fake news, both positive and negative. However, the event also highlighted Ether\u2019s strong foundation. The cryptocurrency didn\u2019t only rapidly recover from the crash but it is also back trading close to $300. More importantly digital currency exchanges are already working on the mechanisms to better factor in news sentiment. That\u2019s a sign of antifragility.\n\n5 \u2014 Survival at 7 Transactions per Second\n\nFor years, Bitcoin was operating under massive constraints from its network which was constantly at the risk of running out of space and was only able to process 7 transactions per second. Under those limiting circumstances, Bitcoin maintained over 40% of the digital currency market and rose to a price over $3000. Not surprisingly, went a controversial update that addressed some of those limitations was implemented at the beginning of the month the optimism around Bitcoin investors rose pushing the currency to over $4000 this week. It is important to notice that the recent raise on the price of Bitcoin has taken place at the same time that the Bitcoin Cash fork currency entered the market. That\u2019s antifragility.\n\nA few months ago, the price of bitcoin stated suffering under an anti-corruption campaign by the Chinese goverment that involved some of the major bitcoin exchanges in that country. At the same time this was happening, the Japanese goverment also imposed new regulations on the use of Bitcoin. China and Japan and their respective currencies are incredibly important to Bitcoin as they account for a large percentage of the trades worldwide. Instead of collapsing under the crackdown, the price of bitcoin benefited from the regulatory guidance and market recognition provided by both the Japanese and Chinese governments. As soon as the goverment crackdown stopped, the price of Bitcoin started rapidly trending upwards. That\u2019s antifragility."
    },
    {
        "url": "https://medium.com/@jrodthoughts/blockchain-has-been-the-unexpected-white-knight-to-this-big-industry-challenge-a7f0dfcec3a6?source=user_profile---------167----------------",
        "title": "Blockchain Has Been the Unexpected White Knight to this Big Industry Challenge",
        "text": "Counterfeiting is a ten digit, global, cross-vertical fraudulent industry. From pharmaceuticals to food processing, counterfeiting cost billions of dollars every year to industries worldwide. As demonstrated in the last couple of years, counterfeiting doesn\u2019t only affect its direct victims but also shareholders from targeted companies (just ask Alibaba).\n\nThe fight against counterfeiting has gone through several generations of technologies and now it seems to have found a new weapon on blockchain technologies. Last week, Bloomberg published an extensive report about how companies are starting to leverage blockchain stacks to combat fraud in the food processing industry.\n\nFood adulteration is as old as the industry itself but it has certainly increase in the last two decades with the entrance of China in the global food supply chain market. The world\u2019s largest food producer and consumer has certainly had an impact on the raise of fraud in the food processing market and has forced companies to upgrade their digital defenses.\n\nOne of the most important aspects to fight adulteration in the food processing industry is to keep accurate records that prove the provenance of food. Until now, the food processing supply chain has relied on centralized, human-dependent solutions that involve a lot of paperwork and, consequently, they have proven to be inefficient and easy to tamper with. The secure, trustless, decentralized nature of the blockchain provides a unique set of capabilities to guarantee the integrity of food records. I know, I know\u2026easier said than done\u2026but this is happening already.\n\nWalmart Stores, Inc is in the process of completing a pilot that tracks pork supply chain in China using blockchain technologies. Initial reports claim that Walmart has been able to reduce the time taken to track pork\u2019s supply chain from 26 hours to just seconds. Not surprisingly, Walmart is extending the pilot to other areas.\n\nLet\u2019s go back to alibaba before somebody asks ;) The ecommerce powerhouse is starting to leverage blockchain technologies with food suppliers in Australia and New eland. If successful, we can see how the pilot can be implemented in china where food safety has become a major concern for Alibaba.\n\nCertainly, a company like Alibaba can push the adoption of anti-counterfeiting solutions using blockchain technologies to several other industries. Luxury goods and pharmaceuticals are two sectors that could leverage blockchain technologies to improve traceability and integrity of records. The global reach and influence of Alibaba can be a strong catalyzer to develop a brand new generation of anti-counterfeiting solutions in areas such as reputation management, traceability, proof-of-posession and others, everything powered by blockchain technologies. In that context, alibaba can influence other merchants to adopt and be compliant with this new approach to leverage blockchain technologies for fight counterfeiting across different industries."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-missing-argument-motivation-and-artificial-intelligence-f582649a2680?source=user_profile---------168----------------",
        "title": "The Missing Argument: Motivation and Artificial Intelligence",
        "text": "A few days ago, I wrote about Nick Bostrom\u2019s theory of SuperIntelligence as an answer to the debate between Elon Musk and Mark Zuckerberg about the threat that artificial intelligence(AI) represents to humanity. Certainly, the dangerous and even apocalyptic versions of AI are dominating the headlines but, almost without exception, the debate has stayed on a very abstract surface. Today, I would like to explore a challenge that not only will be at the core of the next generation of AI technology but one that is also essential to any theory of AI taking over the world. We are talking about motivation.\n\nGoal setting and motivation are key characteristics of human\u2019s decision making process which are still missing from AI agents. Without a dynamic motivation system it is unlikely that AI systems will be able to cause any harm to humanity on-purpose. Additionally, figuring out the mechanics of motivation is also essential to build more advanced intelligent AI agents. Until this point, motivation in AI agents has been expressed in the form of very constrained goal setting mechanisms such as maximizing utility functions against a well known set of hypotheses. That type of goal is certainly simple to express in code but also fundamentally different to how humans setup goals. Let\u2019s review a few thoughts about topic to dig deeper into the argument of motivation and AI agents.\n\nthe human brain has a unique capacity for formulating very abstract goals and dynamically break them down into more constrained and even tactical objectives. Today, it is unconceivable to think about AI agents operating using generic goals such as \u201cmaximizing return to shareholders\u201d or \u201cbeing happier\u201d. However, I think more generic, although not completely abstract motivations will be part of the next generation of AI agents. Keep in mind that generic motivation is more conducive to autonomous bad behavior by AI agents.\n\nMost of the motivation modeling in AI agents is based on passive goals such as \u201cfind patterns in X dataset\u201d or \u201cpredict the value of X attribute\u201d. Those type of goals don\u2019t necessarily require any actions taken as part of the models. Active motivation system are common on scenarios such as quantities trading in which AI agents take actions (buy or sell securities) based on their ultimate goals. Active motivation systems are obviously riskier in AI systems.\n\nNot to sound too rhetorical but part of the trick to solve goal-setting in AI agents is to build motivation systems that can change and adapt over time. Reinforcement learning should play a key role to enable that new type of dynamic motivation system.\n\nOne of the most intriguing and certainly controversial theories about motivation in AI agents in known as the Orthogonality Thesis.. In essence the Intelligence-Motivation Orthogonality Thesis states that intelligence and motivation are essentially independent. More or less any level of intelligence can be combines with more or less any final goal. In my opinion, the Intelligence-Motivation Orthogonality Thesis is more relevant in strong AI (rather than weak AI) systems and is a philosophical argument in favor of caution when comes to generally intelligent AI agents.\n\nAnother interesting theory about the relationship between motivation and AI states that highly intelligence agents with final goals can pursue intermediate goals based on instrumental reasons. For instance, a trading algorithm focused on defense stocks can set get really smart about weapon manufacturing because the knowledge directly contributes to its final goal. Again, this argument is more applicable to strong AI systems.\n\nThese are some of the most common arguments to consider when thinking about the role of motivation in AI agents. Motivation is certainly one of the aspects that will be at the core of the AI debate in the not so distant future :)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-aws-deep-learning-amis-takes-us-closer-to-the-ai-first-cloud-72032c7d9417?source=user_profile---------169----------------",
        "title": "Technology Fridays: AWS Deep Learning AMIs Takes Us Closer to the AI-First Cloud",
        "text": "Welcome to Technology Fridays! Today we are going to cover one of the most exciting recent releases in the cloud deep learning space: AWS Deep Learning AMIs.\n\nFragmentation is one of the aspects hindering the mainstream adoption of deep learning application development stacks. The release of Google\u2019s TensorFlow a couple of years ago, triggered an explosion of open source deep learning frameworks each one with its own strengths and weaknesses. Today, any development team building a deep learning solution has over a dozen open source stacks such as TensorFlow, Torch, Theano, Microsoft Cognitive Toolkit, Caffe2, Caffe, Keras, Bonsai, MxNet and many others at their disposal. More importantly, each one of those frameworks requires specific infrastructure configurations in order to perform optimally and often needs to integrate with other data science technologies in order to deliver complete solutions. In summary, if you thin that building a deep learning application is just a matter of using the correct framework you are up for a surprise!\n\nAWS Deep Learning AMIs extend AWS\u2019s infrastructure and machine intelligence stack with the tools and frameworks to enable data scientists and researchers to build and scale deep learning applications. Built on top of the popular EC2 service, AWS Deep Learning AMIs allow data scientists to quickly launch instances pre-configured with specific frameworks and tools that expedite teh implementation and operationalization of deep learning models.\n\nThe current release of AWS Deep Learning AMIs supports the implementation and execution of deep learning algorithms across different frameworks such as TensorFlow, Microsoft Cognitive Toolkit, Caffe, Caffe2, Theano, Keras and MxNet. The instances in the platform also come pre-configured with Jupyter which enables the implementation of interactive deep learning models using Python 2.7 or 3.4. Additionally, the AWS Deep Learning AMIs include the AWS Python SDK which streamlines the interoperability with other AWS services. In addition to Jupyter, AWS Deep Learning AMIs include popular toolkits such as CppLit, PyLint, Pandas, GraphViz and several other.\n\nHardware acceleration plays an important role in the AWS Deep Learning AMIs. The platform is optimized for NVIDIA CUDA and cuDNN drivers as well as the Intel Math Kernet Library( MKL). Those configuration improve GPU-acceleration in deep learning models without requiring any code modifications.\n\nOne of the strongest differentiators of AWS Deep Learning AMIs is the integration with other AWS services. Fro instance, the platform leverages AWS IAM for access control policies, AWS SQS to exchange metadata configuration between instances, AWS Lambda of auto-scaling jobs, NAT Gateway and VPC of communication with external infrastructures and a few other AWS services. Additionally, AWS Deep Learning AMIs integrates with CloudFormation to expedite and automate the creation of deep learning clusters. Automation is also possible via the AWS CLI.\n\nAWS Deep Learning AMIs can be classified as a could deep learning infrastructure platform. GPU-optimized instances in PaaS stacks such as Azure or Google Cloud can be considered distant competitors. Multi-platform deep learning runtimes such as Bonsai, Floyd or BitFusion are also rapidly becoming relevant in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/learning-by-committee-ensemble-learning-and-artificial-intelligence-da377b4644cb?source=user_profile---------170----------------",
        "title": "Learning by Committee: Ensemble Learning and Artificial Intelligence",
        "text": "Most artificial intelligence(AI) algorithms focus on selecting a hypothesis from the problem space and use it to make predictions. In that sense, most AI techniques are specializations of processes that discover and optimize hypothesis in order to make the most accurate predictions. Obviously, each class of AI algorithms provide very specific models to try to select the very best hypothesis available. The question is\u2026.what happens when they fail to do so?\n\nEnsemble learning is an increasingly popular technique in AI circles that tries to overcome some of the risks of single-hypothesis algorithms. Conceptually, the idea behind ensemble learning is top select a collection(ensemble) of hypotheses and combine their individual predictions into a final prediction. Think about ensemble learning as asking a question to a panel of experts each one of which provides a different answer and explanation which you will then combine into a final answer.\n\nThe reasoning behind ensemble learning is as simple as it is clever. If the selected hypothesis is not completely stupid (which they are not in most cases ) the combination of predictions should at least help to reduce the error rate and, in many cases, improve the final prediction of the algorithm. Consider a simple classification example that determines whether a person is likely to vote Republican or Democrat. Instead of evaluating a single hypothesis, an ensemble learning algorithms could generate 20 different decision trees and make a final prediction by simply majority voting. In that trivial example, the ensemble will have to get 11 hypothesis wrong in order to misclassify the voter. This is, of course, assuming that no Russian hackers are involved ;)\n\nBoosting is, arguably, one of the most popular ensemble learning methods in modern AI. The algorithm leverage the notion of a weighted training set in which each example has an associated weight based on its importance. The higher the weight, the higher the importance of that example related to the target hypothesis.\n\nAt the beginning, the Boosting algorithm assigns all training sets the same weight and proceeds to evaluate the first hypothesis. After the initial hypothesis is evaluated, the algorithm will increase the weight of the misclassified examples g and decrease the weight of the examples classified correctly. With that network configuration, the Boosting algorithm will proceed to generate and evaluate the second hypothesis and it will repeat the same process until is has successfully successfully N hypothesis (N is typically an input of the Boosting algorithm). The final ensemble hypothesis will combine all N hypothesis according to how they performed on the training set. For the AI geeks, I recommend checking out the ADABoost algorithm which is one of the most common implementations of the boosting model and is included in many popular AI frameworks.\n\nOne of the drawbacks of ensemble learning is the propensity towards generating complex hypothesis and, consequently, become victims of overfitting (poor generalization). Like everything in life, simpler explanations are better but, many times, simple and accurate are hard to find :)."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-icos-part-ii-a-technology-perspective-199d03ef491b?source=user_profile---------171----------------",
        "title": "Some Thoughts About ICOs Part II: A Technology Perspective",
        "text": "This is the second part of an essay about my perspective about initial coin offerings(ICOs). The first of this essay analyzed ICOs from the perspective of financial markets drawing some analogies with public market artifacts. Today. I would like to look at ICOs though the lenses of technology markets and the impact that this phenomenon can have in the next wave of technology solutions.\n\nUntil now, ICOs have been sued in its basic capacity to provide a non-dilutive fundraising mechanism for startups. However, the raise of ICOs is having a profound impact in technology markets. Let\u2019s discuss a few key observations that might help to explain that idea:\n\nNot surprisingly, the vast majority of ICOs have been conducted by blockchain technology startups. The are two main factors influencing that dynamic. First, ICOs are a non-trivial process from the pure technological standpoint that requires some deep understanding of blockchain technologies. Secondly, most ICO investors were early adopters of digital currencies and therefore have a preference and understanding of blockchain startups.\n\n2 \u2014 New ICO-Specific Technology Comes Into the Market\n\nIn the same way that there are technology providers that enable and support IPOs, a new window is optning in the market for ICO-specific software platforms. From the creation of tokens to the pricing and performance monitoring of ICOs, there is plenty of opportunity for new technology offerings in this new area of the market.\n\n3 \u2014 New Levels of Cyber-Security are Required for ICOs\n\nICOs are a magnet for hackers. Just look at the recent attack during the CoinDash ICO. Cyber attacks on ICOs are not only damaging to the target company bot also to its investors and the ICO industry in general. As a result, ICOs are likely to require new types of cyber-security technologies specifically tailored to that market.\n\n4 \u2014 Tokens Become as Ubiquitous as API Keys\n\nICO tokens can be conceptually considered analogous to paid API keys. In the same way API keys offer developers access to resources in its underlying platform, ICO tokens provide access to resources within a product of can be redeemed for ETH and access to the Ethereum platform.\n\nOne of the most fascinating use cases that can be enabled by ICOs is peer-to-peer commerce between devides in an IOT topology. You can imagine a home automation scenario in which a smart dish washer can directly place an order for detergent to your favorite ecommerce platform and use tokens to pay for it.\n\nI am very intrigued by what can come out of the intersection of ICOs and open source technologies. While popular open source products have been traditionally distributed as free products, we can envision plenty of scenarios in which developers leverage ICO tokens to receive certain level of compensation from fans and early adopters.\n\nICO tokens and crowdsourcing are a match made in heaven. Tokens are a global, liquid compensation mechanism that can be used with participants in crowdsourcing campaigns. Furthermore, the value of tokens can increase with fluctuations in the digital currency making more attractive to the participants in the campaign.\n\nGamification is one of those super exciting trends that hasn\u2019t quite crossed the chasm into mainstream adoption. With ICO tokens, developers can extend gamified interfaces with new compensation mechanisms that reward the best users and early adopters.\n\nAnother interesting idea is the applicability of ICO tokens to traditional SaaS license models. We can envision a scenario in which a company distributes tokens to users as part of a specific license scheme that will grant them access to specific features of the product.\n\nthe proliferation of ICOs also means that companies will enable more of their capabilities via blockchain smart contracts. as a result, new forms of ecommerce powered by existing smart contracts are likely to become mainstream in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-icos-part-i-887c3ab23dc6?source=user_profile---------172----------------",
        "title": "Some Thoughts About ICOs Part I \u2013 Jesus Rodriguez \u2013",
        "text": "Initial coin offerings(ICOs) are one of the most exciting phenomenon in the digital currency world and one that has had the biggest impact in the market since the creation of Bitcoin. Conceptually, ICOs allow companies to raise capital using a crowdfunding model in which they exchange a proprietary token for a established digital currency such as Ether or Bitcoin. In return, the tokens will give ICO investors a special access to the product and can be used as a form of equity in the network.\n\nI plan to cover of the technical details behind ICOs in a future post. Today and tomorrow, I would like to present some thoughts about the implications of the ICO phenomenon from the perspective for the financial and technology markets. Since January, blockchain companies have raised significantly more funds via ICOs than traditional venture capital(VC) channels. as a result, most of the ICO debate has been centered around its relationship with the VC industry. However, I believe ICOs will have a more profound impact in financial and technology markets. Let\u2019s review a few ideas that might help to illustrate that point:\n\n1 \u2014 The Difference Between Public and ICO-Based Markets Will Get Blurrier\n\nCompanies go public for three main reasons: to achieve liquidity for shareholders, to raise funds and have a currency that allows them to make acquisitions and quantify its valuation. With ICOs, companies can achieve two of those goals: they raise funds and, quite literally, acquire a currency that, although it is not a direct representation of the company\u2019s valuation, it has an indirect correlation to it. From that perspective, as more companies participate in ICOs, the difference between public and ICO-based markets will blurry.\n\nComplementing the previous point, ICOs now offer investors a vehicle to trade in private companies. I believe this will open a complete new segment of the market focused on providing tools and infrastructure to streamline those trades.\n\nI believe ICOs will set the foundation for a new generation of products modeled after the public markets. Hedge funds, index funds, mutual funds, financial/robo advisors are some examples of fintech products that will have an equivalent in the ICO world.\n\nThe first stock exchange in the world opened in 1611 in Amsterdam and, even though is was highly unsophisticated, setup the foundation for public markets. In his famous book \u201cConfusion of Confusions\u201d Dutch trader Joseph de la Vega describe many of the patterns in the Amsterdam exchange that later became established and regulated behaviors. The ICO trend seems to be taking us back to 1611 to a world in which we have the opportunity to write the rules for a new type of financial exchanges and products.\n\nMany of the regulated or flat-out illegal behavior in public market is fair game ein the ICO world. Obviously, we should expect institutions such as the SEC to slowly start introducing regulations but that effort could prove to be extremely challenging as ICO markets are highly internationalized.\n\nThe first example in the Ethereum documentation is how to build a new digital currency. Not surprisingly, most ICOs are using Ether as the underlying crypto-currency. As a result, ICOs are already having a deep impact in th eprize and trading behavior of Ether (see my previous article about this topic).\n\nJust like the underwriting process fro IPOs, there is certain amount of legal work that should be delivered as part of ICOs. Some of the most respectable law firms in the world have started to provide services to startups planning ICOs. In my opinion, the ultimate expression of those legal services should be expressed as Smart Contracts included in the ICO itself. This will setup a strong, trusted and completely automated legal foundation for fund raising.\n\nJust like stocks are a viable currency for acquisitions, we can see a scenario in which startups use ICOs as a way to finance M&A transactions. That model could be similar to how junk-bonds were used to finance massive corporate take overs in the 1990s. That industry created power houses like KKR but also loved/hated figures such as Michael Milken.\n\n9 \u2014 How Long Before we See an ICO from a Public Company?\n\nThere have already been several ICOs from companies with substantial backing from VCs. It is only logical to ask how long before a publicly traded company looks to raise additional funding via ICOs. Obviously, there are many considerations to that scenario but the idea is intriguing nonetheless.\n\n10 \u2014 Welcome to the Wild Wild West\n\nICOs are brand new territory for market regulators and many of the established rule sin public markets simply don\u2019t apply in this new world. Being backed by digital currencies, from which there is little understanding in the market, not directly tied to\n\nthe valuation of a company and operating in an ecosystem used by some of the smartest cyber-outlaws of the last decade, ICOs offer a blank canvas for market manipulators. However, just as public markets evolved, ICOs will become more resilient and trusted with time."
    },
    {
        "url": "https://medium.com/@jrodthoughts/dow-22000-has-a-tech-favor-dow-30000-next-5733f91a04c2?source=user_profile---------173----------------",
        "title": "Dow 22000 Has a Tech Favor. Dow 30000 Next? \u2013 Jesus Rodriguez \u2013",
        "text": "The US equity markets continues reaching new highs. While the current administration has certainly played a role in the beginnings of the current securities rally, most experts agree that we are way passed the so called Trump trade. The Dow broke an historic 22,000 points last Wednesday and held steady through the week. That brought together quite a bit of speculation. Are we on solid grounds or headed for a massive crash? While I don\u2019t claim to have any answers, I would like to share a few observations that might be useful to analyze this subject.\n\nThe 22,000 point milestone for the Dow can be attribute mostly to two companies: Boeing and Apple. While Boeing was responsible for the initial momentum after crossing 21,000, Apple blowout earnings can certainly be credited for the final push towards the milestone. That movement highlights an important characteristic of the current equity markets in which a few technology companies have a tremendous influence on the major market indexes.\n\nIn order to put the previous statement into perspective, we can simply examine the influence concentrated in the top tech stocks in the market in 2017. Grouped under the FAANG or FAAMG acronym (Facebook, Amazon, Apple, Google), depending whether you prefer Netflix or Microsoft respectively, that group of stocks has been responsible fro 33% of the S&P 500 growth in 2017. Those companies have rallied over 30% this year increasing their market value by an astonishing $670 billion. Not surprisingly, a small movement on any of the FAANG-FAAMG stocks typically causes a major change on one of more market indexes.\n\nNow that we have quantified the influence of the top tech stocks in the market, we can either fill bullish or bearish about the prospects of the Dow and other market indexes to continue rallying in the near future. Can the Down reach 30,000 by the early 2020s? Here are some points on both sides of the argument:\n\n1 \u2014 Power Will Continue to Concentrate on Tech\n\nThe bears that are afraid of the fact that too much market influence is concentrated into a handful of tech stocks should get accustomed to it. The current market is likely to continue dominated by technology companies as they have more room for growth in an increasingly tech-dependent world. It is more likely that Alibaba, instead Bank of America or GE, will be the next member of the FAANG-FAAMG club.\n\nLong time investors may argue that we are in the longest bull market ever seen and that we are long due for a correction. this picture makes even more sense if you factor in that the FAANG-FAAMG cohort is trading at about 62 time earnings which can be placed on the upside of the valuation spectrum.\n\nThe market seems to be really hopeful about the potential of congress passing Trump\u2019s proposed tax reform. Most the FAANG-FAAMG stocks have large sums of cash parked overseas that could be moved back to the US under the correct tax policy.\n\nLove it or hate it, markets are far from being completely objective and follow deeply psychological patterns. From that perspective, a high flying Dow pushed by a very small cohort of stocks might defy the idea of rationality of many investors. That level of psychologically-induced fear can force a correction on the markets despite the performance of the underlying stocks.\n\nThe killer performance of FAANG-FAAMG stocks has translated into very rich balance sheets that has allow them to become more ambitious about expanding into other market segments. Alphabet is venturing into self-driving cars through its subsidiary Waymo, Facebook is becoming a news/media powerhouse, Amazon is expanding into brick and mortar retail and Apple is\u2026well\u2026just selling a lot of iPhones but hopefully you get my point ;) The top tech stocks are rapidly gaining leadership positions in new industries which can make them even more resilient to market swings."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-enterprise-smart-contracts-and-some-thoughts-about-the-state-of-blockchain-in-the-c1e2d4424152?source=user_profile---------174----------------",
        "title": "Microsoft Enterprise Smart Contracts and Some Thoughts About the State of Blockchain in the\u2026",
        "text": "The enterprise blockchain market has long been awaiting a strong entrance of the cloud incumbents. With the sole exception of IBM\u2019s Service Fabric, most of the blockchain solutions provided by enterprise software incumbents have seen relatively limited adoption. Now Microsoft is taking another step towards an enterprise blockchain offering.\n\nEnterprise Smart Contracts is Microsoft\u2019s latest addition to its blockchain enterprise offering. This release follows joins the open source Project Bletchley which was Microsoft\u2019s official entrance in the enterprise blockchain market. Enterprise Smart contracts try to bridge the gap between blockchain applications and off-chain communications with Azure services. Specifically, Enterprise Smart Contracts enable blockchain applications to seamlessly integrate with Azure services such as Active Directory for access control capabilities or Key Vault for encryption key management. Microsoft\u2019s new release can be considered a generalization of Ethereum\u2019s Oracle concept applied to the Azure platform.\n\nMicrosoft Enterprise Smart Contracts is a welcomed addition to the enterprise blockckchain ecosytstem. Even though the enterprise blockchain market continues to drive a lot of attention from venture capitalists, it is safe to say that this initial iteration has brought plenty of surprises that have defied most of the expert predictions about the space. Let\u2019s review a few ideas that might provide a picture of the current state of the enterprise blockchain market:\n\n1 \u2014 Infrastructure Beats Platforms: So far, the vast majority of the investment in enterprise blockchain solutions has been based on \u201clower-level\u201d infrastructure technologies such as Etehreum while \u201chigh-level\u201d blockchain stacks have seen limited (although promising) traction.\n\n2 \u2014 Verticals Beat Horizontals: Industry-specific solutions have been the main vehicle to get enterprises to embrace blockchain. Vertical blockchain solutions currently outperform horizontal stacks in terms of market traction and customer adoption.\n\n3 \u2014 A Better/Bigger Professional Services Ecosystem is Needed: Enterprise blockchain applications are notorious for requiring consulting and implementation services. However, the ecosystem and talent availability of blockchain application development firms remains incredibly small compared to the number of technologies in the market and its customer demand. We need more companies like Consensys that are pushing the boundaries of innovation delivering blockchain solutions for enterprise customers.\n\n4 \u2014 IBM Continues to Dominate: IBM\u2019s offerings around its Hyperledger stack as well as its professional services organizations have allowed big blue to capture a leading position in the first wave of enterprise blockchain solutions.\n\n5 \u2014 Big Financial Services Companies are Building their Own Blockchain Stacks: Nasdaq\u2019s Linq and J.P Morgan Quorum are notorious examples of proprietary blockchain platforms released by major financial services firms. Both Quorum and Linq include serious contribution to blockchain enterprise architectures that should be adopted by more mainstream platforms such as Ethereum.\n\n6 \u2014 BaaS Hasn\u2019t Taken Off: The blockchain as a service(BaaS) model promoted by PaaS incumbents such as Microsoft, IBM or Amazon hasn\u2019t gain major traction within the enterprise community. This is likely to change as more solutions such as Microsoft\u2019s Enterprise Smart Contracts enter the market.\n\n7 \u2014 ICOs Haven\u2019t Reached the Enterprise Blockchain Yet: The Initial Coin Offering(ICO) phenomenon that has been driving a lot of momentum(upwards and downwards ;) ) in the digital currency market has had very limited impact in the enterprise blockchain ecosystem. Most of the relevant ICOs have been focused on consumer blockchain technologies.\n\n8 \u2014 Governance is Important: Speaking of ICOs, Tezos recent monster ICO clearly signals that the enterprise blockchain market cares about regulation and governance. Will see how the technology performs."
    },
    {
        "url": "https://medium.com/@jrodthoughts/using-the-super-intelligence-theory-to-settle-musk-zuck-debate-6bdea2ad83ae?source=user_profile---------175----------------",
        "title": "Using the Super-Intelligence Theory to Settle Musk-Zuck Debate",
        "text": "In you follow the artificial intelligence(AI) news ( or any tech news for that matter) you should have heard about the silly debate between Elon Musk and Mark Zuckerberg about the potential catastrophic effects of unregulated AI.\n\nIf two tweets can be considered a debate, then this one started with a tweet from the Facebook CEO about Musk\u2019s recent remarks at the National Governor\u2019s Association in which he referred to AI as the biggest existential threat faced by humanity. In his tweet, Zuckerberg mentioned that comment\u2019s like Musk\u2019s seemed irresponsible to what Musk replied that Zuckerberg seem to have \u201climited understanding\u201d of the space.\n\nNeedles to say that the simple exchange has been blown out of proportions by the press. These days there is nothing that feeds sensational tech blogging/journalism like the apocalyptic versions of AI taking over the world. Typically, I prefer to stay away from those type of debates but, in this case, I thought I\u2019d present a not-very-well-known AI theory that helps to explain why both Zuckerberg and Musk are right about their positions.\n\nThe theory I am referring to comes from British philosopher and AI thought leader Nick Bostrom who currently serves as Director of the AI Research Centre at Oxford University. Bostrom is famous within AI circles for his theory about super-intelligence that attempts to quantify the probabilities of machine intelligence evolving into forms of intelligence vastly superior than human\u2019s. I am not planning to review Bostrom\u2019s entire theory in this post but there are a couple of points that I believe are very relevant to the Musk-Zuckerberg debate.\n\nIn his theory, Bostrom presents several paths to achieve what he calls super-intelligence (intelligence that is superior to the collective knowledge of humanity). AI is certainly one path to super-intelligence but not the only one, Bostrom argues. Brain emulation, computer-brain interfaces (like Musk\u2019s Neuralink) or biological cognition are other equally viable options to achieve super-intelligence. With all those vehicles, Bostrom divides the path to super-intelligence in three main stages: human-intelligence, mankind-intelligence and super-intelligence.\n\nThe human-intelligence phase represents the time where machines will achieve human equivalent intelligence. That process is likely to be very slow and full of challenges. This is the phase that we are currently experiencing. More importantly, there is no certainty that machines will ever achieve human-like intelligence. From that perspective, Zuckerberg\u2019s camp is right.\n\nThe second part of Bostrom\u2019s theory refers to the fact that if/when machines achieve human-intelligence then there should be a short time before they surpass the collective intelligence of humanity. After that level is reached, machines will be in a position to achieve strong levels of super-intelligence or a level of intelligence vastly superior to the combined intelligence of mankind. Here is the best part, Bostrom believes that the transition from civilization-intelligence to super-intelligence could either happen at a low pace or really fast.\n\nA slow takeoff towards super-intelligence will allow governments to correctly control and regulate machine intelligence levels. However, that option might not exist if the transition happens in a matter of minutes. A fast takeoff scenario could be disastrous for humanity as will prevent humans or other forms of machine intelligence to respond accordingly. The fast takeoff to super-intelligence scenario aligns better with Musk\u2019s views of the world.\n\nNick Bostrom\u2019s theory of super-intelligence is absolutely brilliant but also controversial. As a result, Bostrom has both admirers and detractors within the AI community. However, the multi-phase approach to super-intelligence presented in his theory provides a simple explanation to settle the Musk-Zuck debate. I plan to write more about the super-intelligence theory in the next few days."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-ai-citadel-how-google-is-building-the-most-comprehensive-ecosystem-in-the-market-for-ai-talent-ec92c6c7d42c?source=user_profile---------176----------------",
        "title": "The AI Citadel: How Google is Building the Most Comprehensive Ecosystem in the Market for AI Talent",
        "text": "Last week, Google announced the launch of a Studio program to incubate artificial intelligence(AI) startups. Part of Google\u2019s famous Launchpad initiative, the new studio will help AI startups with crucial elements such as specialized datasets, simulation tools and access to AI luminaries like Peter Norvig or Dan Ailey.\n\nthe :aunchpad Studio is the latest on a series of massive strategic initiatives that Goggle has been implementing to become a mandatory stop for AI talent and startups. The initiatives include both technical products as well as new organizations and programs that provide foundational elements for companies embarking in their AI journey. Google\u2019s AI announcements has been so many and so frequent that is easy to put them all together and overlook the ambition of the AI infrastructure they have been building. Let\u2019s take a quick recap so you can get an idea of what I am referring to:\n\nGoogle recently announced a new investment vehicle exclusively dedicated to AI startups. Gradient Ventures joined other Google\u2019s venture funding channels such as GV or Capital G providing a very complete funding ecosystem for AI startups. Considered a specialized funding vehicle within Google, Gradient Ventures has the benefit to invest directly off of Google\u2019s huge balance sheet. Gradient Ventures rivals similar initiatives companies such as Microsoft which recently announced a new fund solely focused on AI.\n\nNo introduction needed here, in just a couple of years TensorFlow has become the most popular deep learning stack in the market which is currently powering many of Google\u2019s mission critical applications. TensorFlow competes with a dozen of open source deep learning frameworks including some from Google\u2019s top competitors such as Baidu( PaddlePaddle), Microsoft( Cognitive Toolkit) or Facebook( Caffe2).\n\nRecently acquired by Google, Kaggle offers a unique platform for hosting machine learning contests between AI developers and researchers. Kaggle combines crowd and artificial intelligence in a unique platform that has no equivalent among Google\u2019s competitors.\n\nTensorFlow Processing Unit(TPU) is Google\u2019s first attempt to venture into the AI-first hardware space. Even though TPU faces competition from incumbents such as Intel, QUALCOMM or NVIDIA, it has already achieve very relevant market traction within and outside Google.\n\nGoogle Cloud Machine Learning( ML) is a native cloud service for the deployment, execution and scalability of Tensorflow programs. Cloud ML faces competition from services such as Azure ML, AWS ML or Alibaba Cloud ML Service.\n\nGoogle Cloud AI APIs expose advanced deep learning models in areas such as image recognition, natural language processing, video analytics, speech translation and others using very simple APIs. In this area, Google faces competition from stacks such as Watson Developer cloud or Microsoft Cognitive Services.\n\nThe latest addition to Google\u2019s AI strategy, the Launchpad Studio will attempt to incubate and mentor promising AI startups and put Google\u2019s sophisticated AI machinery at their disposal. Launchpad Studio faces competition from Microsoft-backed Element AI but can be nonetheless considered a unique addition to Google\u2019s AI arsenal.\n\nGoogle contributions to AI research might rank among the top in the world. Similarly, Google is home for some of the top minds in the AI ecosystem such as Peter Norvig (whose books are considered by many the bible of AI algorithm theory). Having access to this level of thought leadership is an invaluable asset for companies and engineers starting their AI initiatives."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-neural-network-told-me-to-do-it-behavior-analysis-for-machine-intelligence-part-ii-ec4161a3e921?source=user_profile---------177----------------",
        "title": "A Neural Network Told Me to Do it: Behavior Analysis for Machine Intelligence Part II",
        "text": "Last week I wrote about the great potential for technologies that analyze and understand the behavior of machine intelligence(MI) programs. Borrowing some concepts from cognitive psychology, we introduced the concept of machine intelligence behavior analysis(MIBA). Today, I would like to deep dive into some of the key elements, I believe, are necessary for the adoption of MIBA solutions.\n\nFrom a conceptual standpoint, MIBA focuses on understanding and analyzing the decision many dynamics of MI models like neural networks. Beyond the many benefits of understanding how MI models build knowledge and make decisions, MIBA capabilities are essential to create the correct regulatory environment for MI technologies claimed by many (including Tesla-SpaceX CEO Elon Musk) to be paramount to our survival in the era of super intelligence. Not surprisingly, as explained in the first part of this essay, MIBA represents a great opportunity for startups and venture capitalists looking to power the next generation of MI technologies. So expectations are high; but what are really the relevant features that we need in the first group of MIBA solutions? I\u2019ve been thinking about that question for a while and I\u2019ve compiled a few ideas that might be worth discussing.\n\n1 \u2014 What Did You Do? MIBA via Model Monitoring\n\nWe need a Google Analytics for machine/deep learning models. The increasing fragmentation in the MI platform space makes it extremely hard to effectively monitor MI models across different frameworks. A consistent platform for instrumenting, visualizing and analyzing the behavior of MI models will go a long way helping us understand the behavior of intelligent applications.\n\n2 \u2014 How Did You Do That? MIBA via Interrogation\n\nAsking questions is a natural vehicle used by humans in order to understand and reason about a particular subject. Similarly, MIBA techniques can benefit from interfaces that allow human experts or application to interrogate an MI model in order to better understand its behavior.\n\n3 \u2014 Please Explain That To Me: MIBA via Knowledge Abstraction and Visualization\n\nMI knowledge representations such as neural networks or Markov Chains are fairly complex structures which can be hard to navigate and understand. In order to streamline MIBA capabilities, I believe we need tools that can extrapolate MI knowledge structures onto representations that use elements such as visualizations or natural language narratives which can be easily understood by human experts.\n\n4 \u2014 You Should Not Do That: MIA via Ethics and Regulation\n\nOnce we are able to understand the behavior of MI agents, we can start creating regulatory and ethic frameworks that constraint and influence the actions of MI programs. Instead of relying heavily on human supervision like we do today, I believe the new MIBA regulatory technologies will be embedded in MI models to guide their behavior and decisions.\n\n5 \u2014 How Much do You Know? MIBA via Automated Testing\n\nJust like modern institution today, we will need MIBA tools that regularly evaluate MI agents to detect specific behavioral profiles. From that perspective, MIBA tools might become the psychologist of MI applications :). In that context, MIBA tools would interact with MI models looking for well-established behavioral patterns and, if necessary, improve their behavior with new knowledge and logic."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-boltdb-wants-to-be-the-storage-layer-of-the-edge-computing-world-59fcfea569d9?source=user_profile---------178----------------",
        "title": "Technology Fridays: BoltDB Wants to be the Storage Layer of the Edge Computing World",
        "text": "Welcome to Technology Fridays! Today, we are going to talk about embedded databases and one of the most popular technologies in that market: BoltDB.\n\nEmbedded databases became really relevant in the industry with the evolution of mobile computing. Even though there have been models of embedded databases for decades it was the emergence of mobile apps which brought the space into prominence. Most mobile developer have certain level of familiarity with SQLLite which can be arguably considered the best-known embedded database in the market. However, SQLLite often results limited in many mobile or internet of things(IOT ) scenarios due to its dependence on relational models. This is where the new generation of embedded databases led by BoltDB comes in. If SQLLite is the OracleDB of the embedded data storage world then BoltDB can be considered the equivalent of DynamoDB of in-application databases.\n\nOriginally built on Go, BoltDB can be executed as a library bundled into a process such as a website or mobile app. Obviously, that characteristic entails that only a small number of processes can access the BoltDB runtime concurrently but it simplifies aspects such as backups or portability.\n\nKey-value pairs are the main model used to represent information in BoltDB. From that perspective, BoltDB can be used to store semi-structured or unstructured data using a consistent model. The platform also introduces the concept of Buckets to group key-value pairs into logical units within the same database. Buckets can be dynamically created using the different client SDKs available with the platform. BoltDB can combine multiple Buckets into more complex hierarchical structures called Nested Buckets. A Nested Bucket can be composed by several layers of Buckets. For instance, a social network application can have a root User Bucket containing individual Buckets for each user which are formed by other Buckets that represent user-specific information such as friends or photos.\n\nTransactions play an important role in the BoltDB experience. The platform allows both read-only and read-write transactions but the runtime considerations are fairly different. BoltDB supports many concurrent read-only transaction but only one read-write transaction can be active at any given time. The constraint makes complete sense if you factor in that BoltDB does not run in a server side environment but rather inside an application process.\n\nInternally, BoltDB uses a B+Tree structure to store the data using a single file. That feature, together with the serializable ACID transaction semantics, make BoltDB excel in scenarios that involve high-volume reads and consistent writes. Developers can start interacting with BoltDB using the different client libraries available with the platform. The SDKs covers different runtimes such as Android or IOS as well as general-purpose programming languages such as Go.\n\nBoltDB enjoys a vibrant developer community that has contributed valuable tools to the platform such as BoltDBWeb(management or BoltStore( session persistence). Additionally, BoltDB is the underlying data storage runtime behind popular platforms like Consul.io( discovery) or InfluxDB( time-series database).\n\nBoltDB is an embedded database platform which many times is positioned as an alternative to the ultra-popular SQLLite. However, competition for BoltDB does not stop there. LevelDB, RocksDB and HyperLevelDB are alternative to BoltDB that have a stronger focus on writing performance. LMDB is another embedded database that shares a lot of similarities with BoltDB even though the developer experience is a bit more complex."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-neural-network-told-me-to-do-it-why-behavior-analysis-represents-a-gold-mine-for-ai-startups-e6762f025271?source=user_profile---------179----------------",
        "title": "A Neural Network Told Me to Do it: Why Behavior Analysis Represents a Gold Mine for AI Startups",
        "text": "The artificial intelligence(AI) space is evolving at an incredibly fast pace and that rapid growth has brought up all sorts of fears and speculations. recently, at a meeting of the National Governor\u2019s Association, Tony Stark\u2026I mean Elon Musk :) mentioned that AI is \u201c the greatest risk we face as a civilization\u201d and urged the government to be proactive and forceful in regulation.\n\nNeedles to say that Musk\u2019s remarks sparked quite a bit of controversy within the AI community. By enlarge, mainstream media and the general population tend to side with apocalyptic versions of AI while most AI experts believe Musk\u2019s concerns agree overly exaggerated. Obviously, the Tesla-SpaceX CEO has a long history proving that he can think way ahead of everybody else but the reaction to his comments should not come as a surprise. While versions of AI taking over the world and building a modern Skynet are good for TV ratings, book deals and speaking engagements there are major challenges to overcome in order to get to a point in which we can even consider regulation. However, assuming that there is value in Musk\u2019s call for the government to be proactive, the bigger question remains how can we regulate something that we don\u2019t understand?\n\nThis long introduction brings me to today\u2019s point; monitoring, analyzing and understanding the knowledge and behavior of AI agents represents one of the biggest opportunities in the AI market. Until know, we have made a tremendous amount of progress producing frameworks and platforms for the implementation of AI applications. Robust runtime for executing and scaling AI agents are starting to catch up. However, the tools for monitoring and understanding the behavior of AI systems are, by enlarge, missing from the ecosystem.\n\nBehavioral analysis in AI agents is far from being an easy endeavor. To begin with, we are just barely starting to understand how humans make decisions. In cognitive psychology, the work started in the 1970s by scientists like Amos Tversky and Nobel laureate Daniel Kanehman sparked new field such as prospect theory or behavioral economics. However, the correlation of those theories with neuroscience patterns (aka how does the brain makes decisions) is still an active subject of research. In terms of AI, the market desperately needs the equivalent of behavioral economics for AI agents. Let\u2019s put on our marketing hats and call this discipline Machine Intelligence Behavioral Analysis(MIBA). Is not very catchy but it will have to do for the purpose of this post ;)\n\nWhy MIBA is a Golden Ticket for AI Startups?\n\nMIBA is one of those areas that has remained mostly untapped in the AI market. Companies such as OpenAI or DeepMind have started efforts in this space and Google recently announced some interesting technologies as part of its PAIR (people + AI research) initiative. However, all these efforts around MIBA are still in very early stages. Below I\u2019ve listed a few reasons why I believe that MIBA represents a massive opportunity for AI startups and venture capitalists:\n\n1 \u2014 Capitalizing on the AI Market Fragmentation: MIBA tools can provide a consistent model to visualize and understand AI models across the large number of AI frameworks that have been invading the market. Think about building the AI version of platforms such as NewRelic or AppDynamics.\n\n2 \u2014 A Never Say No Market: There is a famous saying in enterprise software that organizations often have a hard time saying no to security and analytic tools. After all, nobody ever gets fired for investing in more security and better analytics. MIBA tools also fit that profile. If you are investing in AI solutions, why wouldn\u2019t you have a strong toolset to understand the behavior of your AI systems.\n\n3 \u2014 Bridge People-Machine Interfaces: MIBA tools are essential to improve the communication between human experts and AI agents. If we are able to understand the behavior of AI agents, we can train them better and improve their knowledge and decision making models.\n\n4 \u2014 There are no Incumbents: Differently from other areas in the AI market, there are no incumbent platforms that dominate the MIBA space.\n\n5 \u2014 Setup the Foundation for Smart Regulation: We are back full circle to Elon Musk\u2019s remarks. MIBA tools will help us to better understand the behavior( good or bad) of AI agents and pave the way for smart government involvement and regulation.\n\nI will have to leave this discussion as a purely theoretical exercise. In the next few days, I will try to deep dive into some of the capabilities that I believe should be included in the first generation of MIBA tools"
    },
    {
        "url": "https://medium.com/@jrodthoughts/yandex-open-sources-catboost-to-continue-building-the-polyglot-deep-learning-world-ccb5a132b65d?source=user_profile---------180----------------",
        "title": "Yandex Open Sources CatBoost to Continue Building the Polyglot Deep Learning World",
        "text": "Another month and another deep learning framework to get familiar with. A few days ago, Russia\u2019s search giant Yandex open sourced CatBoost, a new deep learning library that specializes on a technique known as gradient boosting. CatBoost encapsulates Yandex\u2019s latest machine learning research efforts replacing an older framework known as MatrixNet which has been widely adopted across many Yandex\u2019s services.\n\nFrom a theoretical standpoint, gradient boosting is a machine learning technique that specializes on discovering learning patterns in highly sparse datasets. Gradient boosting excels when applied against semi-structured or structured transactional and historical data instead of the traditional sensorial data(video, audio, image) that is so common in deep learning algorithms.\n\nIf you are reading this you might already be thinking: Jeez\u2026 do we really need another machine learning framework? After all, the market is already inundated with open source deep learning libraries such as TensorFlow, Torch, Theano, Caffe and many others. This level of fragmentation gets an order of magnitude more complex if we consider the fact that deep learning frameworks are not exactly easy to learn by mainstream developers.\n\nThe short answer to the previous question is that deep we are and will continue to live in a multi-framework deep learning world. In this polygot ecosystem, there are frameworks and runtimes that specialize on different areas of the broad machine learning theory. Undoubtedly, the proliferation of deep learning frameworks may result scary to people getting started in the space but there are some ideas that might help us to better navigate the ecosystem.\n\nBelow, I\u2019ve listed a few ideas that could help you understand the current polygot deep learning ecosystem. If nothing else, some of this ideas should help you to better reason about this emerging market:\n\n1 \u2014 No Framework is Good at Everything: The first thing we should understand in order to not feel overwhelmed by the large number of deep learning frameworks in the market is that no single framework can be generically applied across the entire spectrum of machine learning problems. Some frameworks specialized on different models of learning( supervised, unsupervised, reinforcement\u2026) while other excel at operating against specific types of data and scenarios.\n\n2 \u2014 Big Software Companies Have Their Favorite Frameworks: Part of the fragmentation in the deep learning space is due to the fact that software incumbents are regularly putting resources behind different frameworks. Google open sourced TensorFlow, Microsoft its Cognitive Toolkit, Baidu recently released PaddlePaddle, Facebook is actively contributing to Caffe2, Amazon backs up MxNet and now we have Yandex\u2019s CatBoost.\n\n3 \u2014 High & Low Level Frameworks: When inspecting the deep learning space, it might help to make a distinction between high and low level frameworks. In the low level category we can place frameworks like TensorFlow, Torch or Theano that directly enable the manipulation of computation graphs. There are also higher level frameworks such as Keras, Sonnet or Bonsai that provide simpler programming models to create structures such as neural networks while using \u201clow-level\u201d frameworks as the underlying runtime.\n\n4 \u2014 Keeping Up with Machine Learning Research: The proliferation of deep learning frameworks is directly related to the explosion in machine learning research in recent years. Many times, developers want to take advantage of a new machine learning research technique (ex: gradient boosting) but they realize that the models are not easy to implement with the existing frameworks so, you guessed it, they decide to create and open source a new library.\n\n5 \u2014 The Opportunity for a Common Deep Learning Runtime: The fragmentation of the deep learning space has created a massive opportunity for startups providing tools and runtime infrastructure that can efficiently interoperate across the existing frameworks. Platforms such as Bonsai, BitFusion or Algorithmia CODEX are already dabbling into that space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-other-platform-office365-g-suite-and-the-new-era-of-productivity-tech-ed0e31250b15?source=user_profile---------181----------------",
        "title": "The Other Platform: Office365, G-Suite and the new Era of Productivity Tech",
        "text": "Microsoft and Google are embarked in a fascinating quest to dominate the productivity application landscape. While the cloud race between AWS, Azure and Google Cloud regularly dominates the headlines an, certainly, takes a prominent spot in the earning reports, the battle between Office365 and G-Suite should be equally fascinating but it is often ignored.\n\nIn recent days, during the Inspire Conference, Microsoft announced new exciting additions to the Office365 platform. Connections is a new tool that enables the creation of email marketing campaigns a la MailChimp. Microsoft Invoicing is another new member of the Office365 family focused on enabling financing invoicing and payment processing capabilities. The third addition to the Office365 suite is Microsoft Listings which allows the management of ad-listings across platforms such as Facebook, Google, Bing or Yelp.\n\nGoogle hasn\u2019t been sitting still and they have been enhancing their G-Sutie platform to remain competitive or even edge Office365. Google Hire is a super-exciting addition to G-Suite dabbling into the complex world of HR and recruiting. Hire enables G-Suite to manage the recruiting pipeline and processes for open positions in a company. The new product complements the recently announced Google Jobs service.\n\nThe race between Office365 and G-Suite is having profound side effects across the technology market. Considering that the business productivity tools space has a market cap comparable to cloud computing and a multiple higher than most enterprise software markets, it is shocking that Wall Street analysts and investors pay so little attention to this segment of the market compared to others such as cloud computing. To put that statement in perspective, let\u2019s examine of the impact of the Office365-G-Suite context.\n\n1 \u2014 Amazon is Becoming More Aggressive in Terms of M&A\n\nIn addition to its main focus to power information workers, Office365 and G-Suite have served as great catalyzers for the adoption of Azure and Google Cloud respective edging AWS in many competitive scenarios. As a result, AWS has been working on its own line of business productivity services in areas such as email or messaging. Its is expected that Amazon will become very acquisitive in this market to bridge the gap with Microsoft and Google. Slack has been a well-reported target of Amazon\u2019s M&A initiatives and others might soon follow.\n\nAs a generalization of the previous point, we should expect tech giants such as Salesforce, Apple, WorkDay, Amazon and others to use their giant balance sheets to acquire startups that help them remain competitive with Office365 and G-Suite. If recent acquisitions are an indicator of the state of the productivity tools market, we are likely to see a new wave of consolidation in the space.\n\nWindows and Azure dominate public investor sentiment when comes to Microsoft. Similarly, investors see Google through the lenses of ad revenues. Considering the size of the productivity tools market, we should expect Wall Street analysts to pay more attention to it in the near future and to have a more profound impact during earnings season.\n\nSalesforce.com is another company that I believe is in a unique position to compete with Office365 and G-Suite. The acquisition of Quip and Brett Taylor\u2019s influential position in the company are strong indicators about Salesforce\u2019s ambitions in the space.\n\nWho knows? Until know, Apple\u2019s efforts in the productivity tools and services space have been fruitless but Office365 and G-Suite represent a threat to Apple\u2019s enterprise revenue. Apple can only rely on its big balance sheet to make a game changing acquisition in the space. Why not to buy Adobe which marketing cloud naturally complements many Apple\u2019s offerings?\n\nA polemical thought is always a good way to end a post ;)\u2026."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-reasons-why-ethereum-is-getting-killed-8d1cd5937731?source=user_profile---------182----------------",
        "title": "Five Reasons Why Ethereum is Getting Killed \u2013 Jesus Rodriguez \u2013",
        "text": "It seems that every other month I find myself writing an article about the causes behind either the astonishing raise of sharp decline of cryptocurrencies. Certainly, as a tradable asset, digital currencies swing from bull to beat markets and back faster than any other security. Today, I would like to explore some of the factors influencing the rapid declined of one of the most influential cryptocoins in the market: Ethereum.\n\nAs a digital currency, Ethereum\u2019s Ether has become, together with Bitcoin and Ripple\u2019s XRP, of the three currencies that can move the entire market. That means that bullish or bearish moves in Ether are likely to impact the market in positive or negative ways respectively. Additionally, Ethereum has become the most popular platform in the space for the implementation of blockchain solutions. Until last month, Ether had enjoyed an super-bull run in the market with its price raising above the $400 mark which represents an increase of over 2000% in just seven months. However, in the last few weeks, the price of Ether has gone down drastically dipping below $150. Those value swings can scare the most bulling investor out of the digital currency space. But it shouldn\u2019t once we understand some the fundamental causes behind the decline.\n\nRecently, notorious fake news site 4Chang published a \u201cpress release\u201d detailing the death of the founder of Etehreum in a car accident. The news coincided with a fairly large sell order for Ether hitting the exchanges with caused the price of the cryptocurrency to free fall until hitting about 10 cents (yes that\u2019s cents not dollars). After a while, the price of Ether bounced back to more stable territories. That type of movement resembles classic pump-and-dump( maybe dump-and-pump in this case ;) ) scams in penny stocks with a 100x higher volatility factor. That\u2019s enough to make anybody to reconsider their investment in Ether.\n\nYou might have heard the news that, a few days ago, hackers successfully penetrated cryptocurrency exchange CoinDash and stole $7 million worth of Ether. The hack cleverly took advantage of a vulnerability in CoinDash\u2019s planned initial coin offering(ICO) in which the attacker was able to change the address to which investors needed to send the funds. Paradoxically, CoinDash still was able to raise over $6.4 million in the ICO. Needles to say that situations like this one tend to cause panic among Ether currency holders.\n\nPart of the reason fro Ethereum\u2019s price drop has been a simple and necessary correction in the digital currency market. Like many of you, I am very bullish about Ethereum and digital currencies in general but no security trades upwards for such a long time without some correction. Part of the reason that Ether\u2019s price rose so fast was typical investor FOMO behavior( see my previous article about this topic) and, consequently, a correction was expected and, frankly, welcomed if it wasn\u2019t for the sharp decline.\n\nA more subtle but incredibly important factor on Ether\u2019s decline is related to startups cashing out after an ICO. for many reasons, most ICO are based on the Ethereum platform which creates a indirect link between their performance and the price of Ether. While the funds risen via ICOs have been nothing short of remarkable, many startups such as EOC( raised $200 million on ETH) and TenX( $67 million on ETH) have offloaded part of their ETH revenues which has put downward pressure of the cryptocurrency.\n\nFear of being last is a traditional behavior in panic-sales of financial securities. If you are not investing in ether for the long term, you are very likely to be influenced by the price decline and decide to sell part of your Ether holdings which, in turn, causes the price of the digital currency to go further down.\n\nI believe most of this factors will be gradually addressed in the near future as the Ethereum markets gets more resilient. I am very bullish about the value and future of Ethereum and, most likely, we will be here in a month writing an article explaining the new remarkable bull run of the digital currency. Fun times\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/can-computers-have-common-sense-polanyis-paradox-judgment-and-artificial-intelligence-4119c4199a1d?source=user_profile---------183----------------",
        "title": "Can Computers Have Common sense? Polanyi\u2019s Paradox, Judgment and Artificial Intelligence",
        "text": "The path for building intelligent systems is full of fascinating challenges. Many of those challenges are related to our own ability to create intelligent programs that resemble human decisions. Common sense, intuition, judgment are some of the mystical human cognitive ability that seem impossible to replicate in artificial intelligence(AI) systems.\n\nWhat is judgment and commons sense anyway? There are plenty of verbose and often contradictory definition about those human cognitive skills but most of them agree that they relate to human\u2019s ability to reason beyond data and calculations. As disciplines such as behavioral economics or cognitive psychology explain, we regularly make decisions based on factors other than statistics. Every year, Amazon\u2019s business book section is packed with titles from business leaders explaining how to make decisions based on \u201cgut feeling\u201d. Malcolm Gladwell\u2019s Blink is a fascinating book about this subject. If we make decisions based on common sense, intuition and judgment, can we then \u201csimulate\u201d those skills in AI systems. The short answer is yet but don\u2019t stop reading just yet ;)\n\nOne of my favorite ways to think about the mismatch between human reasoning and AI learning algorithms is explained by what is known as Polanyi\u2019s Paradox. British-Hungarian mathematician Michael Polanyi regularly studied the causes behind our ability to acquire knowledge that we can\u2019t quite explain. Just try to explain to a kid step by step how to ride a bike and you will see what I mean. You clearly know how to do it but there is no easy way to explain it. Polanyi\u2019s Paradox summarizes this cognitive phenomenon explaining that many times \u201cwe know more than we can tell\u201d.\n\nAs you can imagine, Polanyi\u2019s Paradox has deep implications in the AI field. After all, if we can\u2019t explain our knowledge how can we possibly train AI agents?\n\nFortunately, AI has evolved passed Polanyi\u2019s Paradox and we can thank Google for that. For decades, GO was considered the poster child for Polanyi\u2019s theory. Many of the well accepted strategies in the ancient game are very hard to mode as a series of rules and atr typically more related with human\u2019s intuition. As everybody knows, between 2016 and 2017, DeepMind\u2019s AlphaGo program regularly defeated the world\u2019s top GO players before graciously retiring a few months ago ( whatever that means for an AI program ;) ).\n\nAlphaGo broke passed the Polanyi Paradox using very clever AI techniques. Instead of relaying on traditional symbolist\u2019s algorithms such as inverse deduction to teach AlphaGo the rules of clever Go strategies., the DeepMind team used a combination of deep learning and reinforcement learning to train AlphaGo on super-complex strategies. Initially, AlphaGo studied millions of Go games and try to infer hidden patterns between a specific strategy and the outcome of the game. After that, researchers have AlphaGo to play numerous games against itself building new knowledge.\n\nWhat Does that Take Us?\n\nThe lessons from AlphaGo show that the way to build human-type judgment into AI systems is by architecting systems that learn on their own and including judgment-based decisions in the training data. More about this in a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-everything-platform-how-big-companies-are-trying-to-become-everything-to-everybody-part-ii-762866c78ddb?source=user_profile---------184----------------",
        "title": "The Everything Platform: How Big Companies Are Trying to Become Everything to Everybody Part II",
        "text": "this is the second part of an essay describing a modern market dynamic in the technology sector on which big software companies are trying to become relevant in almost every new trend. Artificial intelligence, self-driving vehicles, drones, virtual reality, internet of things, messaging platforms are just some of the areas in which companies such as Amazon, Alphabet, Microsoft, Samsung, Apple, Alibaba and others are battling each other for market dominance. In the first part of this essay we referred to this phenomenon as the Everything Platform.\n\nThe more interesting questions come when trying to understand the causes behind the Everything Platform trend. The factors pushing this new technology market dynamic can be found anywhere from macro-economic to technological trends. Let\u2019s explore a few:\n\n1 \u2014 The Quest for a New runtime\n\nAfter mobile computing, the big software incumbents have embarked on a frantic race to discover and dominate a new runtime platform. Runtime can create empires. Google was the undisputed king of the web runtime while mobile brought Apple back from the ashes to become the most valuable company in the world. Understandably, the software incumbents are trying to be at the forefront of the creation of new runtimes.\n\nThe fascinating thing about this market is that there might be not one but many runtimes to follow mobile as the main technology ecosystem in the market. Voice assistants, messaging, virtual reality and vehicle consoles are the four leading trends in the market that might evolve in the next big runtime. As a result, software incumbents are trying to become relevant in as many markets as possible.\n\nFrom a macro-economic standpoint, technology typically evolves in waves. The fascinating thing is that many of the biggest waves or technology trends have been product of previous waves. For instances, the social network market was only possible because the web was well-established. Similarly, augmented reality can be seen as a side evolution of mobile computing. Consequently, missing one technology wave can result of missing several future trends that are produced by that wave.\n\nUnderstanding wave-nature of technology trends, software incumbents are trying to remain competitive in many technology trends because, even if they don\u2019t get to dominate that trend it might put them in position to catch the next wave that evolves from that trend. We can argue that Microsoft\u2019s leadership in the virtual reality space was a consequence of the Redmond giant resiliency to stay as a neglect able number three player in the mobile OS market.\n\nTechnology incumbent stocks have been trading at an all time high and with that comes healthy balance sheets. As a result, big software companies have the resources to invest in research in new technology areas and attract world class talent. Additionally, the valuable stocks are rich balance sheets together with the crazy competitive market have created a uniquely fertile ecosystem for M&A. The M&A frenzy in areas such as artificial intelligence or self-driving vehicles offer incumbents a relatively cheap vehicle to take a position in new tech markets while also removing innovative startups from the competitive landscape.\n\nThere are other factors contributing to the Everything Platform trend but the aforementioned ones are playing a key role in the increasing dominance of the big software incumbents across several new tech markets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-everything-platform-how-big-software-companies-are-trying-to-become-everything-to-everybody-96e0bc85a0e4?source=user_profile---------185----------------",
        "title": "The Everything Platform: How Big Software Companies are Trying to Become Everything to Everybody\u2026",
        "text": "Last week Alibaba announced its entrance in the home assistant market with the release of its Tmall Genie device. Among the many reports of the announcement, some analysts expressed concern about how rapidly the home assistant market is becoming overly crowded. Tmall Genie joins efforts from Amazon, Google, Microsoft, Apple, Samsung and others to be relevant in that nascent space. Interestingly enough, the home assistant market is just one of many examples of a macro-trend occurring in the technology space in which major technology companies are trying to expand into almost every major technology marked by providing an integrated experience. I like to refer to this trend as the Everything Platform.\n\nThe Quest for the Everything Platform\n\nPick two or three of your favorite emerging technology markets and chances are that you will find the same incumbents battling each other for dominance in those markets. Amazon, Facebook, Microsoft, Alphabet, Alibaba, Samsung, Apple and, to a lesser extend, companies such as Baidu or Tencent are trying to be everything to everybody providing innovative solutions on several of the nascent technology markets. A fascinating thing to notice is that, in most of those markets, the incumbents ( and not startups) have become the dominant force regularly outinnovating or regularly acquiring new players. Let\u2019s look at a few examples:\n\n\u2014 Artificial Intelligence(AI): AWS, Azure, Alibaba Cloud and Google Cloud all provide cognitive services and machine learning(ML) platforms which enables the implementation and execution of AI solutions. Similarly, Google(TensorFlow), Microsoft(Cognitive Tookit) and Baidu(PaddlePaddle) have open sourced their deep learning stacks nurturing large developer communities.\n\n\u2014 Virtual Reality(VR): Microsoft and Facebook have been actively competing in the high end VR space with technologies such as Hololens and Oculus respectively. Samsung and Google have also been active in the market with simpler VR offerings.\n\n\u2014 Self-Driving Cars: Baidu and Alphabet are two of the most dominant players in the self-driving vehicle space. Tencent has also disclosed its ambitions in that market with the release of its Apollo/DuerOS stack.\n\n\u2014 Digital Assistants & Home Devices: Pick your favorite: Alexa, Cortana, Google Assitant, Bixby, Siri are constantly trying to become your favorite digital partner. Similarly, Echo, HomePod, Home and now TMall Genie are competing to become a hub for your home devices.\n\n\u2014 Messaging & Bots: Facebook Messenger, Tencent\u2019s WeChat, Skype, Google\u2019s Allo are some of the platform trying to become the dominant messaging and bots runtime in the market.\n\n\u2014 Next Gen Productivity Apps: Office365 and G-Sutie are embarked in a long race to reimagine business productivity applications. Amazon has been slowly entering the space via acquisitions.\n\n\u2014 Augmented Reality: Facebook, apple, Google are some of the companies that have announced aggressive AR roadmaps.\n\n\u2014 Next-Gen Media & TV: Apple, Facebook Amazon and Alphabet are actively trying to deliver new content and media experiences for TV platforms.\n\nWhat\u2019s Causing the Emergence of Everything Platforms?\n\nFrom economic trends to the search for a new runtime, there are several factors contributing to the raise of the Everything Platform trend. That will be the subject of a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-ibm-hyperledger-fabric-brings-the-blockchain-to-enterprises-4ca4188ce8d6?source=user_profile---------186----------------",
        "title": "Technology Fridays: IBM Hyperledger Fabric Brings the Blockchain to Enterprises",
        "text": "welcome to Technology Fridays! every week we try to cover exciting new technologies that are driving transformations in hot market trends. Today, we are going to cover IBM\u2019s Hyperledger Fabric, one of the platforms that is trying to streamline the development of blockchain applications in the enterprise.\n\nHyperledger Fabric is one of the several blockchain projects under the Hyperledger branch of the Linux Foundation, In 2015, the Linux foundation partnered with IBM to create Hyperledger in order to advance blockchain technologies. Hyperledger Fabric is IBM\u2019s marquee contribution of the foundation in the sense that it provides a complete platform for the implementation of blockchain solutions.\n\nLike other blockchain technologies, IBM Hyperledger Fabric combines smart contracts and an immutable ledger to enable different endpoints to exchange assets using transactions. However, differently from other blockchain technologies, Hyperledger Fabric is completely extensible allowing developers to incorporate new data formats, consensus protocols, membership services and other aspects of blockchain applications. Also, Hyperledger Fabric differs from other blockchain technologies in the fact that it is private and permission.\n\nAssets are a key elements of Hyperledger Fabric that defines any component of monetary value in the network. Assets can be defined using Fabric\u2019s Chaincode which is the language used for modeling business logic as well as tools such as Fabric Composer. Hyperledger represents Assets either as binary or JSON formats and its states its typically recorded in the ledger.\n\nIn order to define Assets and business logic, Hyperledger Fabric relies on Chaincode. The language allow developers to define functions and Smart Contracts that are initiated via transactions and interact with the ledger. Hyperledger Fabric supports different programming languages in order to write Chaincode such as Go or Java. Like other blockchain technologies, Fabric relies on an immutable ledger to maintain a verifiable history of all transactions in the platform. However, Fabric takes the concept of a blockchain ledger a step further by associating it with a specific scope of privacy known as Channels. Essentially, Fabric\u2019s ledgers live within Channels which can be shared to all nodes in the network or be constrained to a few participants.\n\nConceptually, you can think of Hyperledger Fabric as a network of nodes that communicate with each other executing transactions and interacting with ledger data. In the Fabric architecture, we can find three types of nodes: Peer, Client and Ordering-Service. At a high level, Peer nodes are responsible f recommitting transaction into the ledger and maintaining its state. Fabric also uses Peer nodes is an special role as Endorsers which allow them to \u201cendorse\u201d a transaction before is committed. Fabric networks maintain an endorsement policy that details the rules for endorsing transactions before successfully committing them.\n\nClient nodes connect to Peers in the blockchain and invoke the corresponding transactions. The communication between Client and Peer nodes is achieved through Channels created by Ordering-Service nodes. clients can connect to a Channel and broadcast messages which are then delivered to the Peer nodes via the Ordering-Service.\n\nHyperledger Fabric uses Transactions to abstract Chaincode that is either deployed or execute it. Fabric refers to those two types of transactions as Deploy-Transactions and Invoke-Transactions respectively.\n\nThere are several other components of the Hyperledger Fabric architecture but most of them center around Nodes, Chaincode, Transactions and, of course, Ledgers.\n\nIBM Hyperledger Fabric should be considered as a blockchain application development platform and, therefore, is operating in a very competitive market. Platform such as Ethereum or Ripple are some of the best known platforms in the space. Technologies such as Microsoft Project Bletchey (based on Ethereum) or Chain can also be considered competitors."
    },
    {
        "url": "https://medium.com/@jrodthoughts/one-model-to-learn-them-all-inside-googles-multimodel-algorithm-370cf4fc040f?source=user_profile---------187----------------",
        "title": "One Model to Learn Them All: Inside Google\u2019s MultiModel Algorithm",
        "text": "This is the third( and final I promise ;) ) part of an essay related to Google\u2019s recent and famous research paper about a new multi-domain learning algorithm. The first part of the series explained some of theory and vision behind multi-model machine learning algorithms. On the second part, we explored the master algorithm theory of a universal learner popularized ( if that word can be applied to machine learning) by University of Washington\u2019s researcher Pedro Domingos. Today, I would like to discuss some of the main ideas behind Google\u2019s MultiModel algorithm without going too crazy into the implementation details.\n\nThe objective behind the Google MultiModel algorithm was to create a single deep learning model that can learn tasks from multiple domains. Specifically, MultiModel focuses on deep learning areas such as machine translation, image classification, speech recognition and language parsing.\n\nOne of the first challenges that Google researchers faces when conceiving MultiModel was the diversity of data inputs types such as images, audio and text files as well as their different sizes and dimensions that needed to be processed. In order to address that challenges, MultiModel creates individual \u201csub-networks\u201d to process specific inputs and transform it into a uniform representation. MultiModel refers to those \u201csub-networks\u201d as modality nets and they specialize on processing data from a specific modality such as text, images or audio files. One important characteristic of Google\u2019s MultiModel algorithm is that it maintains a single modality net for each category of task instead of having individual modality nets for each task. In that sense, all translation tasks will share the same modality net instead of having specific modality nets for each language. This important design decision facilitates generation while preventing the number of sub-networks to get out of control. Specifically, MultiModel uses fout modality nets for language, image, audio and categorical data respectively.\n\nIn terms of the overall architecture, Google MultiModel combines its modality nets into an structure that includes an encoder that processes the inputs, a mixer that combines the encoded inputs with previous outputs and an autoregressive decoder that processes the outputs of the mixer and generates new outputs.\n\nMultiModel proposes an architecture for the encoder and decoder that combines three fundamental building blocks to operate efficiently across different domains. The first component are called Convolutional Blocks that focus on detecting patterns and generalizations across domains. Technically, Convolutional Blocks receives an input tensor and returns an output tensor of the same shape. The second component of called Attention Blocks which improve the performance of the model by focusing on specific elements. Finally, the third component of the architecture are Mixture-Of-Experts Blocks that consist on a number of neural networks and a trainable gating that select the appropriate expert networks to process a specific input.\n\nConfused? Is not that bad ;) Think about MultiModel as a combination of encoders, mixers and decoders and each one of those blocks architected using a combination of convolutional, attention and mixture-of-experts blocks. Google has released an implementation of MultiModel based on TensorFlow which makes it relatively easy to follow.\n\nBased on the initial evaluations, MultiModel didn\u2019t show any particular improvements over individual models but it highlighted some areas on which learning processes can be drastically improved by sharing knowledge from different domains. From this initial experience, Google believes that the key to designing successful MultiModel algorithms is to leverage an architecture in which parameters and computational blocks are shared across different domains."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-ideas-for-watsons-roadmap-44e5d1f99f12?source=user_profile---------188----------------",
        "title": "Some Ideas For Watson\u2019s Roadmap \u2013 Jesus Rodriguez \u2013",
        "text": "Yesterday, I wrote about the challenges that the IBM Watson platform is experiencing in the market. As explained then, part of the challenges Watson has been dealing with has been self-inflicted by IBM\u2019s disproportional marketing efforts while others are due to fundamental limitations in the technology. I am afraid I can\u2019t offer any relevant advice on the marketing front( except maybe one: tone it down!) but there are a few ideas I feel are worth considering for Watson\u2019s short-term roadmap. Here is my top list:\n\nWatson Developer Cloud(WDC) is, essentially, a series of APIs that abstract specific models in mainstream areas such as image recognition, video analytics, natural language processing and others. while APIs makes it relatively simple for developer to leverage AI models in client applications, it is completely impractical when comes to implementing and deploying new algorithms.\n\nTo address this challenge, Watson could expand its runtime to support programs written in deep learning frameworks such as Caffe, TensorFlow, Torch, Theano and others. IBM is already pretty involved with Caffe so this recommendation might not be a long stretch.\n\ncomplementing the previous point, Watson should find a vehicle to incorporate new AI algorithms produced by universities and research centers into the platform. Linking the AI research community to the Watson platform could give IBM a viable alternative to competitive platforms such as Google\u2019s Kaggle.\n\nExpanding support for on-premise and container infrastructures would certainly accelerate the adoption of Watson in the enterprise. IBM has certainly made some progress in this area but more work is necessary for mainstream adoption.\n\nWatson is tightly integrated into IBM\u2019s IOT offerings. Taking this vision a step further, some Watson capabilities are well positioned for edge computing devices. A lighter edition of Watson that works on IOT devices could be a great addition to the platform. This will provide an alternative to technologies such as Azure IOT Edge.\n\nGoogle open source Tensorflow, Microsoft has its cognitive Toolkit, Github is flown with innovative AI tools and frameworks and yet Watson\u2019s open source contributions remain relatively small. Open sourcing tools and frameworks that integrate with the Watson platform could help to gain the hearts of the AI developer community.\n\nContinuing with the previous points, the Watson developer community could benefit from new tools and frameworks that help with the training and optimization of AI models. Frameworks such as OpenAI Gym or DeepMind Lab can provide some inspiration in this area.\n\nEasier said than done but I believe Watson should expand its integration with popular consumer applications such as games or digital assistants. That strategy will directly expose Watson to millions of consumers and will validate some of its core capabilities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/is-watson-loosing-its-magic-53c4b8372f06?source=user_profile---------189----------------",
        "title": "Is Watson Loosing its Magic? \u2013 Jesus Rodriguez \u2013",
        "text": "IBM Watson has been the face( or the logo to be more exact ;)) of the artificial intelligence(AI) movement in the last few years. However, recently, Watson seems to have lost its initial momentum which has triggered a lot of speculation and criticism in the market. One of the most vocal criticisms about Watson came last month when, in an interview with CNBC, Social Capital investor extraordinaire Chamath Palihapitiya mentioned that \u201cWatson is a joke\u2026\u201d, \u201c\u2026 the companies that are advancing machine learning and AI don\u2019t brand it with some nominally specious name that\u2019s named after a Sherlock Holmes character\u201d.\n\nI personally think that classifying Watson as a joke is an unnecessary misrepresentation of the market and the technology. Even though IBM\u2019s hallmark AI platform is not as dominant as it used to be, it is still a force to be reckon with in the enterprise and it can certainly be credited with a lot of the excitement and awareness around cognitive technologies in the business world.\n\nWhat is Happening to Watson?\n\nBeyond the market speculation, there are a series of factors that have been clearly contributing to the \u201cperception\u201d that Watson has been loosing momentum in the AI market. I am purposely using the term perception because we should be clear that Watson is still, by far, the most dominant AI platform in the enterprise by adoption and market share. However, there is a real sense that Watson\u2019s lead in the AI space is rapidly shrinking. However, without numbers, all that is just a market perception and nothing else.\n\nBack to the our argument, here are a few elements that might be contributing to Watson\u2019s momentum slowdown.\n\nNo surprise here; for a couple of years after the release of the Watson Developer Cloud(WDC), it enjoyed almost no competition in the AI space. However, that market dynamic has changed drastically and incumbents such as Microsoft, Google and Amazon have launched competitive offerings. Today, platforms such as Microsoft Cognitive Services can match WDC almost feature by feature.\n\nIBM has recently suffered some visible setbacks in major Watson implementations. Among those, M.D Anderson Cancer Center decision to move away from Watson after a substantial investment received a lot of press that reflected negatively on the AI platform.\n\nHave you seen those funny Watson commercials? Well, there are just one example of the mismatch between IBM\u2019s marketing message and the real capabilities of the Watson platform. Many people feel that Watson has been a victim of IBM disproportional marketing effort presenting an unrealistic picture of the platform.\n\nAmazon\u2019s cognitive API (Lex, Rokognition\u2026) power platforms such as Alexa or Amazon.com, Microsoft Cognitive Services is used by popular technologies such as Cortana or Office365, Google AI APIs power some of the popular websites in the world as we as mission critical platforms such as Waymo\u2019s self-driving car stack. It feels that Watson is still missing a client application that experiences adoption by hundreds of millions of users.\n\nWDC is mostly focused on abstracting well-known capabilities such as sentiment analysis or image recognition via APIs. However, most mission critical AI scenarios require the implementation of custom AI models which is not currently supported by Watson. as a result, most developers are gravitating towards extensible AI frameworks such as TensorFlow or Microsoft Cognitive Toolkit as well as their corresponding platform runtimes."
    },
    {
        "url": "https://medium.com/@jrodthoughts/one-model-to-learn-them-all-exploring-the-master-algorithm-b89ebe7ff51b?source=user_profile---------190----------------",
        "title": "One Model to Learn Them All: Exploring the Master Algorithm",
        "text": "A few days ago, I wrote about a new research paper from Google that has been causing a lot of debate in the machine learning(ML) and artificial intelligence(AI) communities. \u201cOne Model to Learn Them All\u201d proposes an approach to combine several deep learning models in areas such as image recognition, natural language processing or speech analysis on a single algorithm that can solve problems across different domains. In my previous article, I mentioned that the principles behind Google\u2019s model have been around for decades within the machine learning research circles. Specifically, University of Washington\u2019s ML researcher Pedro Domingos has been an active proponent of the idea of a universal learning algorithm.\n\nIn his book \u201cThe Master Algorithm\u201d, Domingos introduces the idea of a universal learner (humblingly named Alchemy ;) ) that combines the main algorithms of the top five ML schools:\n\n\u2014 Symbolists: Symbolists focus on solving problems by manipulating symbols and replacing expression by other expressions. Their main algorithm is, typically, inverse deduction which generalizes knowledge by making predictions about it.\n\n\u2014 Connectionists: Connectionists focus on solving problems by simulating brain functions. Their main algorithm is backpropagation which compares the results of a model against expectations and adjusts the structure of a neural network accordingly.\n\n\u2014 Bayesians: Bayesian focus on solving uncertainty via probabilistic inference. Not surprisingly, their master algorithm is the Bayes Theorem.\n\n\u2014 Evolutionaries: Evolutionaries focus on improving learning structures by inspecting knowledge. Their master algorithm is genetic programming.\n\n\u2014 Analogizers: Analogizers improve learning by recognizing similarities. Their main algorithm is support vector machines which tracks and combines inputs to derive new predictions.\n\nThe core of Domingo\u2019s master algorithm theory( and it is just that, a theory ;) ) is to combine the five ML leading schools using a cohesive model. Specifically, the master algorithm focuses on three main areas:\n\n\u2014 Representation: This is the area in which a learner forms a representation of the knowledge related to a model. For instance, symbolists rely on logic to model knowledge while connectionists focus on neural networks.\n\n\u2014 Evaluation: This is the area in which the accuracy of models is evaluated. For instance, connectionists use continuous error measures( ex: squared errors) to evaluate the distance between predicted results and true values. Bayesians rely on posterior probability for the same task.\n\n\u2014 Optimization: This is the are in which the master algorithm selects the highest scoring among its model. In order to achieve that task, symbolists rely on inverse deduction while connectionists are likely to leverage gradient descent algorithms.\n\nCombining ML algorithms from the main five ML schools across the representation, evaluation and optimization stages produces some very interesting multi-model algorithms. Markov Logic Networks(MLN) are a great example of this technique which combines logic and probability for knowledge representation ,making it one of the most flexible ML models for general learning.\n\nMaster algorithms such as Google\u2019s MultiModel are likely to become essential in order to simulate human intelligence. Without a doubt, multi-model algorithms can be considered on eof the greatest challenges of the next decade of machine learning."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-algorithmia-codex-wants-to-be-the-runtime-for-enterprise-ai-eaf6b08fa6ab?source=user_profile---------191----------------",
        "title": "Technology Fridays: Algorithmia CODEX Wants to be the Runtime for Enterprise AI",
        "text": "Welcome to Technology Fridays! Today we are going back to deep learning land with one of the most exciting new releases in the space: Algorithmia CODEX. recently, I\u2019ve published a couple of articles that highlights Algorithmia Algorithm as a Service(AgaaS) model as one of the most creative offerings in the artificial intelligence(AI) market. CODEX is the newest addition to the Algorithmia platform and one that expands its capabilities into the enterprise space.\n\nCODEX is trying to address one of the biggest challenges in AI solutions by providing a runtime that enables the execution and management of AI applications. From that perspective, CODEX provides a cloud-agnostic runtime that streamlines the lifecycle management of AI models implemented using diverse programming languages such as Java, Scala, Ruby, NodeJS, Python and others. By cloud-agnostic, we are referring to CODEX\u2019s capability to operates on different cloud platforms such as AWS, Azure or Google Cloud we well as on-premise environments powered by OpenStack. CODEX also actively leverages as part of its infrastructure.\n\nOne of the main capabilities of Algorithmia CODEX is its ability to generate REST APIs directly from AI models. CODEX APIs receive request from client applications, execute the corresponding algorithm and return the results in the from of JSON payloads. CODEX also provides client libraries that abstract the integration with the generated APIs.\n\nThe core CODEX infrastructure is composed of three types of nodes. API nodes are responsible for hosting the APIs generated from registered algorithms. APIs nodes receive request from client applications and pass them to worker nodes. Algorithms deployed to the CODEX platform are hosted in worker nodes. That type of nodes are, essentially, containers clusters in which each container hosts a specific algorithms. CODEX includes two main types of worker nodes: GPU and CPU depending on the underlying hardware infrastructure. The third type of node supported by CODEX are Web Nodes that are responsible fro hosting the platform\u2019s web portals such as its Admin Panel, the Legit git hosting service or Pyrometer metering service.\n\nCODEX extends the lifecycle of AI applications beyond just algorithms. The platform also enables the registration and management of datasets from heterogeneous sources such as HDFS or SQL-based databases. That capability allows the management of AI models together with its training and test data sources.\n\nMonitoring and instrumentation are other relevant capabilities of the Algorithmia CODEX platform. From APIs, to AI models to data sources, CODEX provides an end-to-end visibility into the execution of AI applications. Similarly, CODEX enables robust access control and data privacy capabilities across all tiers of the platform.\n\nAlgorithmia CODE is operating in the emerging market of hybrid AI runtimes. Innovative startups such as Bonsai, H2O.ai or Bitfusion are actively competing for developers\u2019 mindshare in that market. Native cloud machine learning services such as AWS ML, Google Cloud ML or Azure ML can also be considered CODEX\u2019 competitors in cloud environments."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-einstein-platform-services-and-salesforce-ai-strategy-9ae36757a8a6?source=user_profile---------192----------------",
        "title": "Some Thoughts About Einstein Platform Services and Salesforce AI Strategy",
        "text": "Salesforce recently added new artificial intelligence(AI) services to its Einstein platform signaling strong progress in its AI ambitions. Under the Einstein Platform Services name, Salesforce added three new services focused on natural language understanding(NLU) and object recognition.\n\nThe new capabilities are powered by the MetaMind platform which Salesforce acquired last year. Among the big enterprise software incumbents, Salesforce stands up as the most aggressive acquired in terms of AI startups with half a dozen acquisitions in the last 18 months. Not surprisingly, some of the acquired capabilities have been slowly surfacing as part of the Einstein platform.\n\nNLU plays a center role in the new Einstein Platform Services offering. Einstein Intent Service allows developers to train Einstein in intent-actions related to natural language sentences. Einstein links intents to specific actions on the Salesforce platform. Another addition to the new platform is the Einstein Sentiment Service which provides sentiment analysis in text data determining whether a user feels positive, negative or neutral. That type of capability can become a powerful addition to Salesforce business applications which already process large amounts of text data .\n\nEinstein Object Detection is the third service in the Einstein Platform Services suite. The new API enables developers to train and use models that recognize objects in images. Object Detection capabilities can be a strong differentiator in some of Salesforce\u2019s newest areas of focus such as ecommerce(Salesforce acquired ecommerce powerhouse DemandWare last year).\n\nThe release of Einstein Platform Services shades some light onto Salesforce\u2019s AI strategy. Here are a few observations that I think are worth discussing about the new release:\n\n1 \u2014 More Like WDC and MCS: Einstein Platform Services functionally compares with cognitive API platforms such as Watson Developer Cloud, Microsoft Cognitive Services or the AI APIs in PaaS stacks such as Google Cloud or AWS. From that perspective, Einstein Platform Services indicates that Salesforce plan to be a force to be reckon with in the cognitive services market.\n\n2 \u2014 Not an AI Application Development Platform: The release of Einstein\u2019s new cognitive services also indicates that Salesforce plans to focus on AI APIs instead of an open platform that can host AI models created in frameworks such as TensorFlow, Torch, Caffe2 and any other of the dozen deep learning stacks that have inundated the market in recent years. In that context, Einstein Platform Services is unlikely to compete with cloud machine learning(ML) platforms such as Google Cloud ML, Azure ML or AWS ML.\n\n3 \u2014 Leading the AI-First SaaS Trend: The new Einstein Platform Services offering clearly indicates that Salesforce is reinventing itself as an AI-first SaaS. The sophisticated capabilities of the Einstein platform might help Salesforce to distance itself from its top competitors that, with the exception of WorkDay, haven\u2019t put the same level of investment into AI technologies.\n\n4 \u2014 A PaaS Follower, No Longer a Leader: Despite its impressive capabilities, the release of Einstein Platform Services is another examples of Salesforce trailing PaaS leaders such as AWS, Azure, Google Cloud, Bluemix and even Alibaba Cloud when comes to innovation in new technology markets. Mobile, big data, IOT, machine learning and now AI are some of the transformative technology trends in which Salesforce has constantly followed the PaaS leaders with undifferentiated technologies. Einstein Platform Services certainly looks similar to the AI APIs platforms from Microsoft, IBM, Google and Amazon."
    },
    {
        "url": "https://medium.com/@jrodthoughts/this-new-technology-extends-bonsai-into-a-universal-ai-runtime-12313f4658e3?source=user_profile---------193----------------",
        "title": "This New Technology Extends Bonsai Into a Universal AI Runtime",
        "text": "Bonsai continues taking tangible steps towards becoming your favorite runtime fro artificial intelligence(AI) applications. Fresh off a funding round led by Microsoft Ventures, Bonsai just announced the release of Gears, an extension to its platform that allows the execution and management of non-Bonsai models.\n\nFor people not familiar with Bonsai, they can think about it as a new platform that provides a higher level programming model for the implementation of neural networks. Bonsai uses a language called Inkling to model deep learning applications and is considerably simpler than other deep learning frameworks. More importantly, Bonsai provides a runtime infrastructure and toolset that enables the execution and monitoring of deep learning models. If you are not too bored, you can check my recent article about Bonsai a few weeks ago ;).\n\nThe initial release of Bonsai positioned the platform as a competitive, and somewhat more sophisticated, alternative to \u201clow-level\u201d deep learning frameworks such as TensorFlow, Torch or Theano. With Gears, Bonsai extends its capabilities to become a universal runtime to those deep learning applications written in those frameworks.\n\nGears inspects models created in non-Bonsai, and preferably Python based, d deep learning frameworks and integrates it into the Bonsai platform. Specifically, Gears supports frameworks such as TensorFlow, Torch, OpenCV, Microsoft Cognitive Toolkit, Scikit-Learn and several others. Developers can implement neural networks on any of those platforms and still leverage Gears to execute and monitor those models using the Bonsai toolset.\n\nGears is the type of technology that can make Bonsai the runtime of choice for deep learning applications. That premise is even more important in enterprise environments in which the need for robust runtimes is one of the aspects holding back the adoption of deep learning platforms. There are other additions that, in my opinion, can help Bonsai and Gear\u2019s value proposition as a universal runtime for deep learning applications. Let\u2019s explore a few:\n\n1 \u2014 API Generation: Generating REST APIs from Inkling models would streamline the interoperability of Bonsai programs and third party applications. That capability is already present in some of Bonsai\u2019s competitors such as Algorithmia CODEX.\n\n2 \u2014 Training Tools: Tools for training specific categories of deep learning models (object detection, sentiment analysis\u2026) is essential to operate Bonsai applications in large environments. Again, this capability is remarkable important in enterprise settings in which Bonsai\u2019s testing and training tools are a must to streamline the adoption of the platform .\n\n3 \u2014 Testing Tools & Frameworks: Integrating training tools and frameworks such as OpenAI Gym or DeepMind Lab would help to simplify the lifecycle management of Bonsai applications.\n\n4 \u2014 Data Source Management: Extending Bonsai\u2019s management to support test and training data sources should be another welcomed addition to Bonsai in order to enable an end-to-end experience for deep learning applications.\n\n5 \u2014 Platform Portability: Ensuring Bonsai\u2019s portability across different cloud and container platform would remove friction for the adoption of Bonsai across heterogeneous infrastructures."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-and-a-new-machine-learning-theory-of-everything-48911bb70230?source=user_profile---------194----------------",
        "title": "Google and a New Machine Learning Theory of Everything",
        "text": "A new academic paper published by Google has been causing a lot of buzz in the machine learning community. Title \u201cOne Model to Learn Them All\u201d, the paper outlines a single machine learning template that can perform different tasks efficiently.\n\nThe MultiModel algorithm, as Google researchers call it, can be trained on different deep learning tasks such as object detection, speech translation, language parsing, image recognition and several others. while Google doesn\u2019t portrait MultiModel as a mater algorithm that can learn everything at once, its creation represents a significant milestone for machine learning applications.\n\nMulti-medium learners has long been seen as the holy grail of machine learning. While artificial intelligence(AI) and machine learning technologies has certainly come a long way, most of today\u2019s applications are constrained to models that can only perform a single task. And even those are ridiculously hard to train and optimize! The single-task nature of most AI learning paradigms drastically contrasts with the multi-medium characteristic of human intelligence. Throughout centuries, humans have created knowledge about different domains using heterogeneous mediums such as text, video, pictures, audio and many others. Creating AI agents that can efficiently extract knowledge from different mediums and combine diverse learning paradigms( supervised, unsupervised\u2026) takes us a step closer to simulate human intelligence.\n\nGoing back to Google\u2019s paper, the MultiModel algorithms didn\u2019t particularly showed radical improvements over existing approaches but it did highlighted a couple of interesting improvements derived from training machine learning models on several tasks. For instance, Google demonstrated that the MultiModel algorithms improved its accuracy on tasks such as machine translation, speech and parsing when trained on all operations simultaneously compared to models that were just trained on one operations. Additionally, the MultiModel approach seems to require less training data than traditional algorithms in order to achieve similar levels of efficiency.\n\nThat question has been at the center of machine learning almost since its inception. The short answer is yes! Most experts seem to agree that all human knowledge can le learned by a single master algorithm. They also agree that, despite the creation of the MultiModel, we are nowhere near the creation of universal learner.\n\nFrom all the theories about machine learning master algorithms, one of my favorites comes from Pedro Domingos, an AI researcher at the University of Washington. In his book \u201cThe Master Algorithm\u201d (what else ;) ) and in several dozens of research papers, Domingos has championed the theory of a universal learner that combines the main (or masters) algorithms of the five lead schools of machine learning: Symbolists which rely on inverse deduction as their core algorithm, Connectionists which use backpropagation, Evolutionaries which derive from genetic programming, Bayesians that live and die by Baye\u2019s theorem and Analogizers that are based on Support Vector Machines. I will deep dive into Domingo\u2019s details of a Mater Algorithm in a future post. For now, Google\u2019s MultiModel takes us a step closer to make that theory a reality."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-algolia-makes-enterprise-search-sexy-again-102c2a39d4fa?source=user_profile---------195----------------",
        "title": "Technology Fridays: Algolia Makes Enterprise Search Sexy Again",
        "text": "Welcome to Technology Fridays! today we are going to deep dive into the search platform space with a technology that is gaining a log of momentum in the market: Algolia. The Algolia platform is one of the new players in the search space powering many well-known websites including this one(Medium).\n\nThe search space is one of the super hot areas that hasn\u2019t live up to expectation in the enterprises. From the search platforms provides by enterprise software incumbents such as Oracle(Endeca) or Microsoft(SharePoint) to open source stacks such as Lucene-Solr and some of its corresponding commercial distributions such as Lucid Imagination\u2019s Fusion, search platforms have generally failed to capture meaningful market share and become mainstream in the enterprise. Recently , a new generation of search platforms lead by Elasticsearch but including technologies such as SwiftType, Searchify and, of course, Algolia have stormed the market with simpler, developer-friendly search models that have gain them a lot of traction with both consumers and enterprises.\n\nAlgolia is a cloud-based search platform that enables the indexing and search of documents using very simple and yet robust interfaces. Algolia supports a large number of search models such as full-text, numerical or facets which can be adapted to different scenarios.\n\nSimplicity is one of the key assets of the Algolia platform. Developers can start using Algolia by importing the data they would like to search upon. That process can be done manually through the Algolia Dashboard(the main UI of the platform) or using the API. The import model support data additions, updates, deletions and other data change mechanisms that enable seamless data synchronization with business data sources.\n\nAfter the data is imported, algolia starts building indices that store the data in a format optimized for searching. Indices are the fundamental record storage structure in Algolia and can be managed using the Dashboard or the API. When Algolia initially indexes data, it uses a default algorithm to rank the search results. Developers can customize the relevance of search results by configuring Ranking Attributes that guide the search engine based on the relevant of individual data records.\n\nThe Algolia Search API is the main vehicle used to issue search queries against indexed data. Algolia supports various search techniques such as facet or proximity-based searching that can be used to filter and optimized the search results. Additionally, Algolia provides SDKs for different programming languages such as Java, C# or Objective-C which simplifies the use of Algolia in third party applications. Algolia represents search results as JSON payloads that include not only data records but also relevant search metadata such as facets, processing times, number of hits and many others.\n\nOne of the key differentiators of Algolia is its capability to expand beyond a backed search platform by helping developers optimize the frontend search experience. In that context, Algolia provides helper libraries that can be used to customize the frontend search UI. For instance, the autocomplete.js library dynamically updates a dropdown menu of possible search queries as the user types. Similarly, the instantsearch.js updates search results real time based on the user input.\n\nAlgolia runs on a highly sophisticated Distributed Search Network(DSN) that encompasses over 30 data centers across the globe. algolia\u2019s DSN uses some of the principles of CDNs to clone search results closers to users.\n\nMany people might intuitively compare Algolia to Elasticsearch, the uber-popular open source search platforms. However, that comparison might not be completely accurate. While Elasticsearch provides an open platform to build search engines, Algolia focuses on providing both backend and frontend experiences to power search experiences in websites and mobile apps. Other search stacks such as searchify or Swifttype are closer to Algolia\u2019s feature set and vision."
    },
    {
        "url": "https://medium.com/@jrodthoughts/algorithmia-and-the-promise-of-agaas-in-the-enterprise-f6698c38f3ef?source=user_profile---------196----------------",
        "title": "Algorithmia and the Promise of AgaaS in the Enterprise",
        "text": "If you follow this blog, you know I am a big fan of Algorithmia. The Seattle-based company recently announced a new $10.5 million series A to expand its algorithm as a service(AgaaS) model into the enterprise. The round was led by Google\u2019s new artificial intelligence(AI) fund as well as existing investors Work-Bench, Madrona Venture Group, Rakuten Ventures and Osage University Partners.\n\nAlgorithmia has pioneered the vision of AgaaS as an essential element of modern AI architectures. The closest analogy to AgaaS is the mobile app store concept which have served as the distribution backbone of the mobile app ecosystem. Similarly, agaaS provides a model to distribute and provision AI algorithms.\n\nThe best known capability of the AIgorithmia platform is its AI marketplace that contains about 3500 AI algorithms as well as complementarily functions for the implementation of AI solutions. Additionally, Algorithmia provides a private cloud version of its CODEX platform that can run AI models at scale. Feature-by-feature, Algorithmia can be considered one of the most creative offerings in the new AI technology ecosystem.\n\nThere are several reasons why Algorithmia represents a unique but incredibly relevant offering in the AI market in general and specifically for enterprises. Here are some of my favorite (some of which I listed in my previous article about Algorithmia).\n\nAI researchers and academics are constantly creating new and innovative algorithms. However, a significant percentage of AI research foes unnoticed beyond small academic circles it is simply buried in the pages of AI scientific journals. Algorithmia\u2019s marketplace offers a more practical distribution channel fro AI models that can be made available to mainstream users.\n\nIndirectly, Algorithmia is providing a bridge for enterprise to have access to the latest AI research and explore new algorithms that can be applied to their specific scenarios. Algorithmia allow enterprises to effectively discover new AI models that can be used on their machine intelligence solutions.\n\nThe pages of AI journals are filled with claims about the unmatched virtuosity of specific algorithms. Despite its theoretical contributions, many of those published AI models have never been validated in real world scenarios using industry data sources. Algorithmia provides an efficient platform to validate and improve the efficiency of AI algorithms in the real world.\n\nPeer reviews are an important aspect of academic research and AI is not the exception. However, even the most prestigious AI publications constraint peer reviews to a handful of experts. Algorithmia collaboration features allow AI researchers and developers to regularly review and contribute to AI algorithms.\n\nThis blog is like a broken record when comes to preaching the importance of scalable runtimes for enterprise AI solutions. Algorithmia\u2019s CODEX provides a runtime engine that can execute AI models on both public and private cloud infrastructures which is vital for the mainstream adoption of AI in the enterprise. Algorithmia joins the efforts of other innovative platforms such as Bonsai, H2O.ai or bitfusion in this area.\n\nThe fact that Google led Algorithmia\u2019s series A could be taken as a sign of a potential acquisition in the near future. In my opinion, Algorithmia\u2019s AgaaS model is still new and needs to be validated. However, the Seattle-based company already has tangible assets such as over 45,000 developers and 3500 algorithms as well as a solid technology stack. Under Diane Green\u2019s leadership, Google has shown to be an aggressive acquirer in the AI space and Algorithmia could be a very unique addition to Google Cloud and a strong differentiator against competitors from Amazon and Microsoft."
    },
    {
        "url": "https://medium.com/@jrodthoughts/mongodb-stich-and-the-database-as-a-platform-trend-331684cc99e2?source=user_profile---------197----------------",
        "title": "MongoDB Stich and the Database as a Platform Trend \u2013 Jesus Rodriguez \u2013",
        "text": "The MongoDB Developers Conference finished a few days ago and it brought us a few exciting announcements. Among those, the release of the Stich backend as a service(BaaS) platform was incredibly well received by the developer community.\n\nStich is a BaaS stack that sits on top of MongoDB and it enables the integration with third party services and line of business systems. The vision behind Stich is to empower developers to build applications that rely on MongoDB but also leverage data from other APIs and back-office systems.\n\nFrom a functional standpoint, Stich can connect to external service and pull datasets into MongoDB databases. Stich offers a consistent programming model for accessing data services from heterogeneous systems. The initial release of Stich includes integration with Google, Facebook, Twilio, AWS and many other services. Additionally, developers can implement custom integrations with APIs.\n\nStich is an important addition to MongoDB but the release has implications well beyond its technical capabilities. The launch of Stich is MongoDB\u2019s first step to transition from a traditional database company to a database as a platform stack that includes services that fall outside core database functions. MongoDB is not the only database runtime undergoing this type of transformation; Microsoft SQL Server recently added a series of capabilities that add support for stacks such as R or Python programs as well as a series of other services that has drastically enhanced the footprint of the database platform.\n\nthe transition from a core database to a complete database as a platform stack is a relevant trend in the enterprise software market. the movement has been catalyzed by platforms such as Spark or Flink that combine data storage capabilities with higher level data computation services. the addition of other data service could help the lead database platforms to differentiate in a highly crowded market. With that in mind, let\u2019s brainstorm other interesting services that can be added to MongoDB\n\nThe release of sTich is a major milestone for MongoDB to expand beyond its core database services. Here are some ideas of other data service capabilities that could be a welcomed addition to MongoDB:\n\n1 \u2014 Machine Learning Services: Imagine being able to build and execute machine learning models in languages such as R or Python that leverage data from MongoDB and execute on MongoDB clusters. That added service will position MongoDB as a relevant platform in the emerging machine intelligence market.\n\n2 \u2014 Serverless Computing: MongoDB could become an ideal runtime to power the emerging generation of serverless application in on-premise enterprise environments.\n\n3 \u2014 Stream Processing: Stream data processing is an important element of modern big data pipelines. Adding services that enable the ingestion and processing of data streams in a MongDB cluster could be an interesting idea.\n\n4 \u2014 Programming Languages Runtime: MongoDB has a first-class support for NodeJS and is has made inroads to improve the support for other languages. MongoDB application could certainly benefit from a multi-language runtime that enables the implementation of in-database applications in languages such as Python or Java.\n\n5 \u2014 Data Visualizations: Mongo Charts was another welcomed announcements in the recent MongoDB Developers Conference and one that represents an initial step towards adding robust data visualizations to MongoDB applications. We should expect to see more innovation from MongoDB in the data visualization space in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-rapid-raise-of-the-citizen-developer-market-565a68a9c8d6?source=user_profile---------198----------------",
        "title": "The Rapid Raise of the Citizen Developer Market \u2013 Jesus Rodriguez \u2013",
        "text": "Citizen developers are becoming an important part of modern enterprise environments. as line of business units in large companies build their own \u201cshadow IT\u201d groups, they are becoming more ambitious about the types fo application they can deliver. Additionally, the software tools and platforms targeting shadow IT or citizen developers seems to be experiencing a phenomenal growth and is being embraced by giants such as Microsoft, Google or Amazon.\n\nCitizen developer tools and platforms are mostly focused on enabling the implementation of applications using minimum code. The goal of these tools is to enable non-developers, or certain non-experts, to implement full-featured applications on specific areas. While a couple of years ago, citizen developers were constrained to very specific areas such as website implementation, today they are proliferating in almost every area of modern enterprise software development. There are several factors contributing to the rapid growth of the citizen developer market.\n\n5 Factors Contributing to the Raise of Citizen Developer Market\n\nTechnology is evolving exponentially faster than previous decades and traditional enterprise continue experiencing tremendous challenges acquiring talent in emerging technology areas. As a result, there is a strong demand for tools that simplify the creation of applications in new technology domains and line of business units don\u2019t want to be constrained by the limitations of IT departments.\n\nThe never ending friction between business and IT is just being accelerated by the adoption of new technologies. as a result, line of business units will continue supporting and expanding shadow-IT initiatives.\n\nFollowing Salesforce, some of the most popular SaaS systems in the market such as Office365, G-Suite, WorkDay, etc have been rapidly expanding its capabilities to support self-service application development models. This has empower citizen developers that can now implement full-feature applications without abandoning their favorite SaaS system.\n\nThe increasing complexity of new technology areas such as artificial intelligence or data visualization is creating a strong demand for tools and solutions that provide an experience for non-developers to deliver applications in those areas.\n\nMany of you might be surprised to see serverless computing included in this list but the new technology movement has become one of the key factors that has facilitated the proliferation of citizen developer platforms. Serverless computing platforms such as AWS Lambda or Google Functions has become a key extensibility mechanism for SaaS and mobile business applications.\n\nBeyond traditional web application development, there are several new booming markets that are actively leveraging citizen developers.\n\n1 \u2014 Mobile Applications: Recently, Google and Microsoft launched self-service mobile application development platforms integrated with G-Suite and Office365 respectively. That move is a strong validation for the self-service mobile application development market.\n\n2 \u2014 Integration: Self-service integration tools continue to experience a high demand in the enterprise. Platforms such as IFTTT or Zapier are clear winners in this category.\n\n3 \u2014 Artificial Intelligence: A new generation of platforms trying to enable the creation of AI applications by non-developers has been emerging within the AI market. Natural language processing, image recognition or voice analytics are some fo the strong areas of self-service AI. Platforms such as BigML or recently acquired DataRobot are examples of technologies in this category.\n\n4 \u2014 Bots: Bots are called a strong market for citizen developers. As a result, the market is exploding with platforms that enable the creation of bots with minimum code. BetaWorks\u2019 Dexter is one of my favorite examples in this category.\n\n5 \u2014 In-SaaS Applications: the demand for citizen developers that can build applications that extend traditional SaaS systems continues to be strong. Salesforce.com, Office365 and G-Suite are front runner examples of platforms embracing this model ."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-sex-social-value-and-artificial-intelligence-40b49d7068a2?source=user_profile---------199----------------",
        "title": "About Sex, Social Value and Artificial Intelligence",
        "text": "Artificial intelligence(AI) agents are all about acting \u201crational\u201d and maximizing \u201cutility\u201d. Not surprisingly, AI theory borrows a lot of principles from economics and specifically game theory which are centered around maximizing utility value. However, utility (or market value) optimization is hardly enough to replace human interaction in many environments. As humans, our behavior and decisions are not only dictated by the benefits of its market value but also about their social impact. Let\u2019s call that metric social value.\n\nSocial norms typically involve the friendly requests that people make one of another. Could you help me with the homework? I am paying for dinner tonight. According to psychologists, we live in parallel worlds: one regulated by transactional value and another one governed by social value. While AI has made great inroads in models that maximize market value, there is still a lot of work to be done in terms of social value.\n\nTo understand the difference between market and social value (and to spice things up a bit ;) ) , let\u2019s take sex as an example. From a social perspective, sex value is related to the emotional connection that creates between the parties involved. However, there is also another context in which sex has a market value and cost money. Typically, bad things happen when somebody tries to optimize both the social and market value of sex simultaneously. That\u2019s why prostitutes are not necessarily always looking for eternal love (contrary to what some customers might believe ;) ) or why husbands and wives don\u2019t expect money in return for intimacy.\n\nGifts are another example of social value. Many gifts don\u2019t bring any intrinsic relevant monetary value but they produce a direct emotional value. Gifts are an important element of human interaction because they are a good example of social norms and the parties involve receive immediate emotional gratification from it. In that context, gifts are a direct producer of social value.\n\nAI algorithms are great optimizers of market value but they struggle when comes to creating social value. However, I think this is slowly starting to change. Can we create AI algorithms that operates in a social context and efficiently maximize social value. I believe we can. Let\u2019s imagine a scenario in which multiple AI agents collaborate and compete against each other in a social context. In those environments, maximizing social value could be an important asset to AI agents.\n\nIn my opinion, social value in AI can be other in two fundamental ways: learning social norms and maximizing social utility. There is a good change that well-established algorithms such as inductive learning can be used to learn social norms in the way they learn rules in large datasets. In the context of social value, there are some AI models that can be adapted to obtain and maximize social utility. Techniques such as sentiment analysis can be used to evaluate and even quantify the reaction to social actions and they can be effectively used to maximize social value."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-openai-gym-makes-reinforcement-learning-real-bcf762c16774?source=user_profile---------200----------------",
        "title": "Technology Fridays: OpenAI Gym Makes Reinforcement Learning Real",
        "text": "Welcome to Technology Fridays! Today we are going to artificial intelligence(AI) land with one of the most creative technology stacks in the agent enablement space: OpenAI Gym. The first product released by the OpenAI Foundation(Elon Musk, Sam Altman\u2026), OpenAI Gym is a framework for the implementation and evaluation of reinforcement learning algorithms.\n\nReinforcement learning is becoming one of the most exciting disciplines in modern AI solutions. conceptually, reinforcement learning focuses on building knowledge in AI agents using a combination of rewards and punishment. Some experts might argue that all forms of AI learning can be modeled as variations of reinforcement learning but, as an AI discipline, reinforcement learning has taken a back seat to other forms such as supervised learning. However, the recent emergence of AI scenarios that operate in incomplete environments such as self-driving cars or even poker games have triggered a new interest in reinforcement learning.\n\nOne of the biggest challenges in reinforcement learning applications is the need to regularly and efficiently train and evaluate models. This is the challenge that OpenAI Gym addresses. The platform provides the foundational pieces to compare and evaluate reinforcement learning models. At a high level, OpenAI Gym consist of two main components: OpenAI Gym Library and Service. The OpenAI Gym library is an open source framework that provides a collection of environments and test problems that can be used to evaluate reinforcement learning algorithms. The OpenAI Gym service is an API and web interface that enables the comparison of the performance of reinforcement learning models.\n\nEnvironments are a concept at the core of the OpenAI Gym architecture. From the AI theory standpoint, Environments provide an abstraction to the outside world surrounding an AI agent. OpenAI Gym includes a large collection of environments abstracted by the Env interface. the platform also includes a registry that lists available Environments associated to classic AI problems such as Atary, Inverted Double Pendulum, Go9x9 and many others. Each OpenAI Gym Environment exposes its specific requirements via the EnvSpecs interface.\n\nOpenAI Gym Environments provide operations that enable their interaction with AI agents. For instance, the Reset operation restarts an Environment to its original state while the Step operation advances the Environment by one timestep. Developers can use these operations to interact with Environments from their reinforcement learning models.\n\nThere are no hard specifications to OpenAI gym agents. the platform an open to any reinforcement learning algorithms. Typically, the role of an agent is to send to data Environments and receive back a list of observations and rewards.\n\nOne of the coolest capabilities of OpenAI Gym is the evaluation of AI models. Every time a model runs, the results can be uploaded to the OpenAI Gym servers via its APIs. Some models are automatically scored while others require peer reviews. The platform maintains a list of evaluation associated with specific environments.\n\nOpenAI gym is a new platforms in a nascent field knows as AI agent enablers. Despite OpenAI Gym unique focus on reinforcement learning, platforms such as DeepMind Lab, Kitt.ai or Octane.ai can also be considered relevant in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bancor-and-the-battle-for-crypto-coin-stability-d632257e85b2?source=user_profile---------201----------------",
        "title": "Bancor and the Battle for Crypto-Coin Stability \u2013 Jesus Rodriguez \u2013",
        "text": "Earlier this week, I wrote about the influence that Initial Coin Offerings(ICOs) are playing in Ethereum\u2019s increasing market share in the digital currency space. Now, a new company has closed a record ICO to bring some stability to the crypto-currency space. Insert your ironic comment here\u2026 ;)\n\nIn June 13, blockchain startup Bancor raised $150 million in an ICO with the objective to legitimize the exchange rates f digital currencies. Bancor is trying to adapt some well-established techniques from financial services to the smart token/digital currency worlds. Regardless of whether you agree with the Bancor\u2019s approach( I have some concerns about the fundamentals), we should all welcome that type of financial rigor and innovation in the crypto-coin space. So how does exactly Bancor works?\n\nBancor is attempting to provide a foundational platform to make smart tokens( the ones you use in an ICO) widely acceptable. Bancor envisions a world in which almost every company can issue its own digital currency with guarantee liquidity. As crazy as that might sound considering the current digital currency market, Bancor\u2019s model is incredibly viable. Let\u2019s explain it using an example:\n\nLet\u2019s assume that your favorite company( FC) decides to issue a new smart token(FCT) that customers can use to conduct business with FC or some of its partners that accept the new currency. In that scenario, Bancor will allow FC to establish a constant exchange rate between FCT and a proprietary token called Bancor Network Exchange Token(BNT). The rate is enforced using Ethereum\u2019s smart contracts and, more importantly, is backed by a pool of Ethereum. In order to make this work, Bancor needs to hold Ethereum reserves to guarantee liquidity.\n\nThe magic behind Bancor relies on the well-known Constant Reserve Rates(CRR) model which builds liquidity into the BNT itself. Bancor\u2019s BNTs will be used to back a large number of the relevant cryptocurrencies in the market. To make this model more viable, Bancor introduces a protocol that guarantees the exchange of BNTs to other crypto-assets including Ethereum\u2019s Ether.\n\nIf you are into finance, you might already be comparing Bancor\u2019s relationship to digital currencies to the role that central bank policies such as Capital Adequacy Ratios play on banks. The main difference, of course, is that central banks\u2019 cash instruments are globally accepted and are rarely exposed to the levels of volatility of cryptocurrencies.\n\nWe Need More Ideas Like Bancor\n\nBancor\u2019s vision is as ambitious as it is risky. Concerns ranging from the viability (or the lack thereof) of most ICO smart-tokens to the dependencies on currencies built on top of Bancor itself are some of the challenges that the blockchain startup is likely to face. Regardless, ideas like Bancor targeted to bring stability to cryptocurrencies are fundamental to the long term viability of digital currencies.\n\nIn my opinion, there are over a dozen well-established mechanisms in financial markets that can be adapters to the digital currencies market in order to improve its stability. Option contracts, collateral models, derivative contracts, risk management models are just some of the ideas that be modeled as smart contracts in order to improve stable exchange rates in digital currencies."
    },
    {
        "url": "https://medium.com/@jrodthoughts/simplicity-bias-variance-and-some-ideas-to-solve-overfitting-in-machine-intelligence-models-c0f3eb3e4b8?source=user_profile---------202----------------",
        "title": "Simplicity, Bias, Variance and Some Ideas to Solve Overfitting in Machine Intelligence Models",
        "text": "Yesterday, we introduced the concept of overfitting as one of the biggest challenges of machine intelligence(MI) applications. Today, I would like to explore a few ideas to deal with overfitting in MI models.\n\nIn yesterday\u2019s post, I drew the parallel between overfitting and hallucinations. Conceptually, overfitting occurs when MI algorithms infer incorrect knowledge or patterns from datasets. Obviously, the potential consequences of overfitting in MI models can be catastrophic if not handled appropriately. Then we have to ask ourselves how to protect MI models from \u201challucinating\u201d. There are a few ideas that might help.\n\nOther than bad algorithmization, overfitting mostly occurs when a model produces too many hypothesis without the corresponding data to validate them. As a result, MI application should try to keep a decent ration between the test datasets and the hypothesis that should be evaluated. However, this is not always an option.\n\nThere are many MI algorithms such as inductive learning that rely on constantly generating new and sometimes more complex hypothesis. In those scenarios, there are some statistical techniques that can help estimate the correct number of hypothesis needed to optimize the chances of finding one close to correct. Harvard professor Leslie Valiant brilliantly explains this concept in his book Probably Approximately Correct.\n\nA conceptually trivial but technically difficult idea to deal with overfitting in MI models is to generate simpler hypothesis. Of course! Simple is always better isn\u2019t it? But what is a simpler hypothesis in the context of MI algorithms? If we need to reduce it to a quantitive factor, I would say that the number of attributes in an MI hypothesis is directly proportional to its complexity.\n\nSimpler MI hypothesis tend to be easier to evaluate than others with large number of attributes both computationally and cognitively. As a result, simpler are typically less prompt to overfit than complex ones. Great! now the next obvious headache is to figure out how to generate simpler hypothesis in MI models. A non-so-obvious technique is to attach some form of penalty to an algorithms based on its estimated complexity. That mechanism tends to favor simpler, approximately accurate hypothesis over more complex and sometimes more accurate ones that could fall apart when new datasets appear.\n\nPedro Domingos is one of my favorite MI researchers and thought leaders. In some of its work, Domingos explains the friction between bias and variance as a mechanism to handle overfitting in MI models. One of Domingos\u2019 most famous examples to explain bias and variance refers to a clock that is always one hour late as an example of high bias but low variance. If instead the clock is all over the place but almost always indicates the right time, then we say it has high variance but low bias.\n\nIn the context of MI models, we can regularly compare hypothesis against test datasets and evaluate the results. If the hypothesis continue outputting the same mistakes, then we have a big bias issue and we need to tweak or replace the algorithm. If instead there is no clear pattern to the mistakes, the problem is variance and we need more data."
    },
    {
        "url": "https://medium.com/@jrodthoughts/borges-planes-and-overfitting-in-machine-intelligence-e4c196f5201d?source=user_profile---------203----------------",
        "title": "Borges, Planes and Overfitting in Machine Intelligence",
        "text": "Overfitting is one of the best challenges in modern machine intelligence(MI) solutions. I often like to compare MI overfitting to human hallucinations as the former occurs when algorithms start inferring non-existing patterns in datasets. Despite its notoriety, there is no easy solution to overfitting and MI application often need to use techniques very specific to individual algorithms in order to avoid overfitting behaviors. This problem get even more scarier if you consider that humans are also incredibly prompt to overfitting. Just think about how many stereotypes you used in the last week. Yeah, I know\u2026.\n\nUnquestionably, our hallucinations or illusions of validity are present somewhere in the datasets used in the training of MI algorithms which creates an even more chaotic picture.\n\nIntuitively, we think about data when working on MI algorithms but there is also another equally important and often forgotten element of MI models: knowledge. In the context of MI algorithms, data is often represented as persisted records in one or more databases while knowledge is typically represented as logic rules that can be validated in the data. The role of MI models is to infer rules that can be applied to new datasets in the same domain. Unfortunately for MI agents, unlimited powerful computation capabilities are not a direct answer to knowledge building.\n\nJorge Luis Borges is considered one of the most emblematic Latin American writers and one of my favorite authors during my teenage years. In his story \u201cFunes the Memorious\u201d, Borges tells the story of Funes, a young man with a prodigious memory. Funes is able to remember the exact details he sees, like the shapes of the clouds in the sky at 3:45pm yesterday. However, Funes is tormented by his inability to generalize visual information into knowledge. Borges\u2019 character is regularly surprised by his own image every times he sees himself in the mirror and is unable to determine if the dog seen from the side at 3:14pm, is the same dog seen from the back at 3:15pm. To Funes, two things are the same only if every single detail is identical in both of them.\n\nFunes\u2019 story is a great metaphor to explain that knowledge is not only about processing large volumes of information but also about generalizing rules that ignore some of the details in the data. Just like Funes, MI algorithms have almost unlimited capacity to process information. That computation power is a direct cause of overfitting as MI agents can infer millions of patters in data sources without incurring in a major cost.\n\nWhat You Don\u2019t See is as Important as What You See\n\nDuring World War II, the Pentagon assembled a team of the country\u2019s most renown mathematicians in order to develop statistical models that could assist the allied troops during the war. One of the first assignments consisted of estimating the level of extra protection that should be added to US planes in order to survive the battles with the German air force. Like good statisticians, the team collected the damage caused to planes returning from encounters with the Nazis.\n\nFor each plane, the mathematicians computed the number o bullet holes across different parts of the plane (doors, wings, motor, etc). The group then proceeded to make recommendations about which areas of the planes should have additional protection. Not surprisingly, the vast majority of the recommendations focused on the areas with that had more bullet holes assuming that those were the areas targeted by the German planes. There was one exception in the group, a young statistician recommended to focus the extra protection in the areas that hadn\u2019t shown any damage in the inventoried planes. Why? very simply, the young mathematician argued that the input data set( planes) only included planes that have survived the battles with the Germans. Although severe, the damage suffered by those planes was not catastrophic enough that they couldn\u2019t return to base. therefore, he concluded that the planes that didn\u2019t return were likely to have suffered impacts in other areas. Very clever huh?\n\nThe previous story has some very profound lessons for anti-overfitting MI techniques. The only way to validate new knowledge is to apply it to unseen datasets and many times missing datasets are as important as existing ones. This is known in cognitive psychology as \u201clearning by omission\u201d. As many scientists know: \u201cone million experiments are not enough to prove you right but a single one might be enough to prove you wrong\u201d."
    },
    {
        "url": "https://medium.com/@jrodthoughts/icos-technology-and-madness-make-the-bull-case-for-ethereum-3bdfa533cad?source=user_profile---------204----------------",
        "title": "ICOs, Technology and Madness Make the Bull Case for Ethereum",
        "text": "Bitcoin has been on the raise lately breaking all time highs regularly. While the price raise of Bitcoin has dominated the headlines, other digital currencies such as Ripple and Ethereum have very quietly posted even more impressive performances. Specifically Ethereum\u2019s growth has been outpacing Bitcoin by a large margin.\n\nTo put the previous statement in perspective, consider that the price of Ether( Ethereum\u2019s main cryptocurrency) has risen over 5000% from the beginning of the year crossing $400 a few days ago. Bitcoin, on the other hand, has seen its value raise above $3000 and over 200% this year. That put the year-to-date growth between Ethereum and Bitcoin to about 25 to 1 which is pretty impressive.\n\nWhat I find remarkable about Ethereum\u2019s bull run is that it wasn\u2019t so much based on speculation as much on solid market trends. That foundation is likely to contribute to the long term viability of Ethereum in the digital currency market. From those foundational factors, there are two that I would like to discuss today: ICOs and the technological limitations of Bitcoin.\n\nInitial Coin Offerings(ICOs) might very well be the killer application for digital currencies after Bitcoin. Conceptually, ICOs are a fundraising mechanism that allows an organization to receive digital currencies of immediate liquid value such as Bitcoin or Ethereum in exchange of newly issue cryptocoins associated with a company.\n\nSounds crazy? Not really. The mechanics of ICOs have well-known similarities with established money exchange models such as venture financing in which companies exchange money for shares without an immediate liquid value. Option investing is another asset exchange mechanism that can be compared to ICOs as investors purchase contracts based on the future (vs. the current) price of a security. The foundation of ICOs has been around for a long time and, interestingly enough, Ethereum applied some of those principles in its early days by raising $18.4 million in 2014 on a pre-sale of Ether or Bitcoin.\n\nWhile ICOs were initially seen seen as a fundraising toy for startups, its recent success stories seem taken from Alice in Wonderland. Earlier this month, a startup called Brave launched an ICO for a new web browser and ended up raising $35 million in about 30 seconds. Well known companies such as Kik nad Omige are also very committed to ICOs.\n\nHow are ICOs related to the price of Ethereum? Well, Ethereum\u2019s architecture makes it incredibly simple to implement custom cryptocurrencies and, consequently, it has become the platform of choice for ICOs. Currently, Ethereum accounts of more than half of the ICO events in the market; a trend that is likely to increase in the near future. More importantly, if ICOs become an establish fundraising mechanism, Ethereum could become something like the IMF of the cryptocurrency world making it an invaluable asset.\n\nDespite its massive bull run, Bitcoin is still subjected to well-known technological limitations some of which are directly benefiting Ethereum\u2019s market position. first of all, bitcoin transactions continue to be slow and expensive (about $1.50 per transaction) compared to other cryptocurrencies. The Bitcoin blockchain has been under a considerable amount of stress lately during the market raise and many Bitcoin holders have been divesting themselves of bitcoin to acquire Ether."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-blockapps-c48d1d87107c?source=user_profile---------205----------------",
        "title": "Technology Friday: BlockApps \u2013 Jesus Rodriguez \u2013",
        "text": "Welcome to Technology Fridays! Every Friday, I try to cover software products or platforms that are bringing innovation to hot technology areas while still flying under the radar of mainstream media. today, I would like to cover one of my favorite frameworks in the blockchain technology ecosystem: BlockApps.\n\nBlockApps addresses the challenges of streamlining the implementation of blockchain based solutions. Specifically, BlockApps provides a series of high level building blocks for implementing Ethereum applications. From the market standpoint, BlockApps is trying to address one of the biggest challenges in the blockchain ecosystem: simplifying the implementation of mainstream applications.\n\nIf you are confused about the role of BlockApps in relationship to platforms such as Etehreum, think about the comparison between Ruby on Rails and Ruby. Just like Ruby, Ethereum provides the main building blocks for the implementation of blockchain applications such as Smart Contracts, DApps, Oracles, scripting languages such as Solidity and many others. However, most developers can find Ethereum too \u201clow level\u201d for the implementation of mainstream applications such as websites or mobile apps. This is where BlockApps comes in.\n\nOriginally implemented in Haskell, BlockApps provides APIs, runtimes and tools that simplify the implementation of blockchain applications. The platform expands Ethereum\u2019s core capabilities with a stack that includes components ranging from basic management APIs to plug-in to popular IDEs.\n\nStrato is one of the main components of the BlockApps platform. From a functional standpoint, Strato exposes many of the capabilities of the Ethereum blockchain via a simple set of REST APIs. This model allows developers to perform typical Ethereum tasks such as accessing blocks, deploying smart contracts, querying users and dozens of others via simple HTTP calls. The model of simplifying access to complex platforms via APIs has proven successful before; just think about Elasticsearch in relationship to Solr-Lucene.\n\nBlockApps also enables the prototyping of blockchain application in local environments using the Bloc Server. Developers can install the Block Server as a NodeJS module and point it to a Strato instance used for development and testing as well as to an Ethereum instance used for production.\n\nNow you have Strato and the Bloc Server up and running, how do you interact with them? The Block CLI is a command line interface that automates the lifecycle of BlockApp solutions. Additionally, blockApps has been building SDKs and frameworks that lower the entry point for developers across different platforms. Among those, BlockAppsJS enables the implementation of Smart Contracts using JavaScript and the Xamarin and Ionic SDKs abstract the implementation of blockchain based mobile apps.\n\nBlockApps is technically platform agnostic but tithe current version has been obviously optimized for Microsoft environments. The current version of BlockApps includes a Visual Studio plug-in and a native Azure instance that allow developers to get up and running with the platform in no time.\n\nBlockApps is part of the fast growing ecosystem of platforms trying to bring blockchain technologies to mainstream developers. ErisTech is a well known platform in the space. Similarly, blockchain PaaS such as Nxt or BlockStack can be seen as competitors of BlockApps in some scenarios."
    },
    {
        "url": "https://medium.com/@jrodthoughts/platforms-like-spark-and-flink-are-key-to-the-future-of-deep-learning-in-the-enterprise-730ca68f159c?source=user_profile---------206----------------",
        "title": "Platforms Like Spark and Flink are Key to the Future of Deep Learning in the Enterprise",
        "text": "The recent Spark Summit brought up a lot of interesting announcements about the future of Spark. Among those, the release of Deep Learning Pipelines was particularly well received by the developer community. Created by Databricks, Deep Learning Pipelines enables the execution of deep learning models in Spark clusters.\n\nDeep Learning Pipelines addresses one of the most important challenges in modern deep learning solutions: the absence of a sophisticated runtime. The recent generation of deep learning frameworks such as TensorFlow, Torch, Theano, Caffe2, MxNet and others have certainly simplified the implementation of deep learning applications but they remain rather limited in terms of the runtime infrastructure required to execute deep learning models at scale. Aspects such as instructing and coordinating the execution of deep learning programs across a large GPU farm are far from trivial. Those efforts require concurrency and coordination models that have little to do with deep learning algorithms. Arguably, the number one friction point for the mainstream adoption of deep learning technologies in the enterprise is the lack of robust runtimes.\n\nDeep Learning Pipelines takes advantage of a very clever technique to bring deep learning models to the Spark platform. The framework provides a library that converts deep learning models into SQL functions which can be easily integrated with Spark MLib Pipelines in order to run on a Spark cluster. The process might not be applicable to all deep learning frameworks in the market but is certainly an interesting start.\n\nMassive parallel processing(MPP) platforms such as Apache Spark or Flink could be the missing runtime for deep learning programs. regardless of whether you like the approach taken by the Deep Learning Pipelines Frameworks ( I have my reservations) there is an unquestionable value in creating versions of deep learning frameworks optimized for MPP runtimes such as Spark of Flink.\n\nAs mentioned earlier, the absence of sophisticated runtimes in the main challenge for organizations embracing deep learning frameworks. This problem is even more relevant in enterprise scenarios that rely on on-premise infrastructures in order to execute deep learning programs. Platforms such as Spark or Flink bring very unique benefits as deep learning runtimes:\n\n1 \u2014 Parallel Runtime: Deep learning programs and natively parallel but parallelization itself it really hard to achieve at a runtime level. Platforms such as Flink or Spark natively support scalable, parallel and concurrent execution of programs.\n\n\u2014 Tooling: By leveraging platforms such as Spark or Flink, deep learning programs can have access to a sophisticated suite of management tools and automation frameworks.\n\n\u2014 Integration with Other Technologies: Natively supporting stacks such as Spark or Flink will allow deep learning programs to interoperate with other native technologies such as Spark MLib, Flink Streaming or Spark R that natively run on those platforms.\n\n\u2014 Hybrid Infrastructures: Platforms such as Spark or Flink are widely supported across cloud platforms which will provide deep learning frameworks hybrid runtimes that can be very viable in enterprise settings."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-ai-human-creativity-paradox-artificial-intelligence-as-a-spark-to-human-creativity-a205d563e923?source=user_profile---------207----------------",
        "title": "The AI-Human Creativity Paradox: Artificial Intelligence as a Spark to Human Creativity",
        "text": "Creativity is one of the holy grails of artificial intelligence(AI). For decades, transcendent cognitive abilities such as creativity or aptitude have been seen as a frontier for AI systems. Nowadays, we are regularly seeing new examples of what can be considered sparts of creativity in AI systems. From the many examples of AI agents creating forms of art to DeepMind\u2019s AlphaGo \u201ccreative\u201d strategies in recent matches( the famous move 37 ), AI systems are starting to exhibit behaviors that \u201csimulate\u201d human creativity. However there is another angle of the relationship between AI and human creativity that is not explored often and is the fact that AI has proven to spark human creativity on different disciplines.\n\nThe quest for unlocking creativity in AI agents is a fascinating one but there is another aspect of the relationship between AI and human creativity that is equally important and not discussed very often and is the fact that use of AI has proven to spark human creativity in different cognitive disciplines. There are many examples in cognitive studies that show that as AI agents get better in \u201cnon creative\u201d tasks such as knowledge gathering or tactical problem resolution, humans will feel more confident to be more creative on specific disciplines. I like to call that relationship the AI-Human Creativity Paradox.\n\nRecently, I\u2019ve written extensibly about creativity in AI agents (check out previous posts) but don\u2019t worry that I don\u2019t plan to bother you with neuroscientific definitions ;) A very simple way to define creativity is as the ability to recognize patters despite differences in detail and context.\n\nCreativity is one of the cornerstones of human cognition and an ability that has been essential to the evolution of human knowledge. Some of the most important laws and theories of human\u2019s existence such as Darwin\u2019s, Newton\u2019s or Einstein\u2019s were created in sparts of creativity, Now AI\u2019s capabilities ave the opportunity to broaded the horizons of human creativity.\n\nThe AI-Human Creativity Paradox explains that in a collaborative scenario between humans and AI agents, humans tend to become more creative as the knowledge of AI agents becomes more complete. The paradox can be seen as a specialized case of the famous Moravec theory. In 1988, well-know scientists Hans Moravec stated that \u201ccomputers tend to be good on tasks in which humans aren\u2019t and vice versa\u201d. There have been a lot of debate about the Moravec\u2019s paradox over the years but some examples still hold true.\n\nAn Example from Chess\n\nIn order to illustrate the AI-Human Creativity Paradox let\u2019s take an example from Chess. For the last 20 years, computer systems have regularly outplayed chess grandmasters. However, most experts agree that chess AI systems are not really creative but rather good on finding complex technical manipulations. For instance, chess software systems have no notion of strategy but they excel on positional tactics.\n\nAs a result of the mainstream adoption of chess systems, many players have reduced their strategies to repeat moves learned from computers during training sessions. After all, if chess computers rarely make mistakes, how could you loose? Not surprisingly, the number of draws in chess tournaments have increased exponentially and highly solid openings such as Reti or Caro-Kahn have become a favorite of young grandmasters.\n\nBased on the previous explanation, you might think that competitive chess is getting really boring. Far from it! The fascinating thing is that, while second-tier tournaments are plagued with matches using computer-dictated openings and strategies, top chess tournaments have seen an explosion of theoretical \u201cnovelties\u201d or creative strategies that deviate from the mainstream theory. There are two fundamental factors contributing to this phenomenon. firstly, top chess grandmasters assume that their opponents are overly prepared in the main lines of an opening so they try to surprise them using not-very well known strategies. But how are they coming up with those creative strategies? Very simply, are top grandmasters rely on chess computers in their preparations, they feel encouraged to explore new, out-of-the-book strategies because they know that computes will always find the best corresponding tactical position to backup their strategy. In other words, the fact that chess systems excel in non-creative tactical manipulations is pushing grandmasters to be more creative strategically; a clear example of the AI-Human Creativity Paradox.\n\nIn an environment obsessed with the human vs. machine scenarios, the AI-Human Creativity Paradox is an example that the collaboration between humans and AI agents can push transcendent cognitive skills such as creativity to the next level."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-bandit-problem-in-reinforcement-learning-f1f99b008c6c?source=user_profile---------208----------------",
        "title": "The Bandit Problem in Reinforcement Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Reinforcement learning is becoming one of the most popular disciplines in modern artificial intelligence(AI). even though many experts believe that reinforcement learning is far from becoming mainstream, it is hard to ignore the large number of cognitive scenarios that can be address with some variation of reinforcement learning techniques. In recent months, the release of tools and frameworks such as OpenAI Gym or DeepMind Lab are helping AI researchers to streamline reinforcement learning tasks but many challenges still remain. One of the most well know challenges in reinforcement learning is known as the Exploration-Exploitation Dilemma and is illustrated in computer science literature in a series of techniques known as the bandit problems.\n\nTo understand the relationship between bandit problems and reinforcement learning let\u2019s start with a quick recap of the latter (you can see previous articles in this blog about reinforcement learning). Conceptually, reinforcement learning learning helps AI agents to learn a specific environment via a combination of exploration, reward and punishment. Imagine playing a game without knowing the rules and, after a certain number of moves, learning that you\u2019ve won or lost. That\u2019s the essence of reinforcement learning.\n\nAI theory covers two fundamental types of reinforcement learning algorithms: active and passive. In passive reinforcement learning, an AI agent is assumed to know what to do but it must learn the \u201cutility\u201d associated with the different states of the environment. An active reinforcement learning agent must learn what to do as well as the utility of the states. The concept of \u201cexploration\u201d plays a key role in active reinforcement learning scenarios. By exploration we are referring to the task of an AI agent learning as much as possible about an environment in order to behave in it. The concept of exploration is directly related to the bandit problems.\n\nThe Exploration-Exploitation Dilemma and the Bandit Problem\n\nExploration is a key piece of reinforcement learning based agents but also a really expensive one. By exploring an environment, an AI agent can improve its knowledge of it but it doesn\u2019t directly maximizes the reward or utility of its specific state. At any given point, a reinforcement learning agent faces the tradeoff between exploration to maximize its long-term knowledge and exploitation to maximize its reward. Let\u2019s call that friction the Exploration-Exploitation Dilemma and is well represented in AI theory with the bandit problems. Here is textbook example:\n\nIn a casino, a one-armed bandit is a slot machine. An n-armed bandit has n levers. A gambler can insert a coin, pull a lever and collect the winnings(if any). At any give state, the gambler must decide which lever to play on each successive coin; the one with the best payoff or the one that has not been tried yet? With one decision, the gambler will choose to maximize the reward based on its current knowledge of the environment at the risk of never finding an optimal strategy( exploring new levers) while the other strategy optimizes the long term knowledge of the environment but sacrifices immediate rewards.\n\nThe Exploration-Exploration-Exploitation Dilemma is present in many well-known active reinforcement learning scenarios such as stock trading strategies or budget allocation. In order to avoid the heavy computation burden of finding a completely optimal strategy to solve the Exploration-Exploitation Dilemma, many reinforcement learning algorithms rely on heuristics that make assumptions about the knowledge. More about that in a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/ambient-os-and-natural-language-as-the-universal-home-device-protocol-3efc2ca6f59a?source=user_profile---------209----------------",
        "title": "Ambient OS and Natural Language as the Universal Home Device Protocol",
        "text": "A few days ago, during an interview at the Code Conference and a profile in Wired Magazine, Android creator Andy Rubin disclosed his plans to release a new operating system optimized for smart home devices. Code-named Ambient OS, the new platform provides abstractions and services that enable the implementation of applications that execute in smart home environments.\n\nThe conceptual similarities between Ambient OS and Android are impossible to ignore which makes Rubin the ideal candidate to tackle this problem. Based on the little information available about Ambient OS, it seems that natural language will play a foundational role in the new platform. Beyond the initial hype surrounding Ambient OS, the announcement is an important example to highlight how natural language is becoming a key element of smart home devices. In fact, I believe natural language could soon become the universal protocol for devices interacting in smart homes.\n\nInteroperability between devices is one of the biggest challenges of home automation solutions. While there are many standards like MQTT and others, they still require two devices to be painfully aware of each other\u2019s programmable interfaces in order to interoperate. This level of knowledge-coupling is even more painful is we consider that the programmable interfaces for home devices are rather simple from the protocol standpoint. They are mostly constrained to the execution of commands and the on-demand query of data.\n\nNow, let\u2019s imagine a scenario in which gome devices could simply interact with each other or though s smart hub device using natural language sentences. The universality of natural language makes it an ideal vehicle to address many of the communication and interoperability challenges between smart home devices. Leveraging natural language protocols could bring some very unique dynamics for the communication between devices in a smart home. Here are a few ideas:\n\nImagine a scenario in which, upon installing a new home device, this one will broadcast an introductory message to other devices in the network: \u201cHello (gotta be polite ;) ), I am device X and these are my skills: <list of skills>\u201d. Natural language will allow other home devices to immediately interact with the new device without needing too much understanding of its skills. Devices will issue requests in natural language and process the responses.\n\nLet\u2019s take a scenario in which we have a smart device that is able to open the garage\u2019s doors based on a simple voice command. A few weeks later, we install a new sensor in the house that is able to track and report weather parameters such as rain, temperature, humidity, etc. Now, we could direct the game controller device to open the garage doors only if is not raining. Natural language should allow the gate controller device (or a smart hub such as Essential\u2019s) to automatically interact with the new weather sensor to gather the rain parameters.\n\nNatural language will allow home devices to incorporate new skills a-la Alexa without needing to modify the front-end interfaces. This model will allow smart home environments to evolve organically without major disruptions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-istio-makes-microservices-ready-for-primetime-a15742314c9d?source=user_profile---------210----------------",
        "title": "Technology Friday: Istio Makes Microservices Ready for Primetime",
        "text": "I started the week writing about Istio so I figured it should be the topic of today\u2019s technology Friday.\n\nAs explained in my previous article, Istio is a platform that enables the operational readiness of microservices solutions. The reason I\u2019ve been so excited about Istio is because I believe it fill one of the biggest gaps in the microservices\u2019 value proposition. If you have faced the task of implementing a decent-size microservices architecture, then you are likely to have experienced the pain of operating and managing those type of solutions at big scale.\n\nIstio enables foundational capabilities of microservices architectures in areas such as traffic management, routing, service discovery, fault interaction, security and several others. Istio\u2019s architecture can be segmented in two fundamental areas: data plane and control plane. The data plane is responsible for managing flow-related capabilities in a service mesh including features such as routing and load balancing. The control plan is responsible for modeling and activating those capabilities via policies. Istio operates at the network level of a microservices architecture using a sidecar proxy model associated with a Kubernetes pod. Istio\u2019s sidecar architecture is based of the popular Envoy proxy framework originally created by Lyft.\n\nIstio-Manager is the main interface for directly interacting with the platform. That component is responsible for managing the lifecycle of Envoy proxies in a service mesh. The Istio-Manager also enables the authoring of policies in areas such as security or traffic management using a proprietary DSL. Service discovery is another key feature enabled by the Istio-Manager via a service registry that i dynamically updated as Envoy proxies come on and off the service mesh.\n\nIstio is technically infrastructure agnostic but its first release has been optimized for Kubernetes infrastructures. Istio includes a component called the Mixer which abstracts the interaction with an underlying runtime such as Kubernetes, Mesos, Cloudfoundry an others. Istio\u2019s Mixer i based on a plug-in based architecture that support several platform adapters.\n\nSecurity is another key capability of the Istio platform. The Istio-Auth component is responsible for features such as service-to-service authentication, TLS encryption, service identity management and others. One of my favorite features of Istio is it fault-injection capabilities based on circuit breaker techniques. Istio\u2019s model allow developers to build microservices solutions that factor failure as a first-class citizen.\n\nIn terms of infrastructure support, Istio excels on Kubernetes-based environments such as Google Cloud. Support for IBM Bluemix should be expected soon and other cloud platforms should follow.\n\nIstio is a very unique offering in a not very crowded space.Platforms such as Azure Service Fabric or Spring Cloud offer similar capabilities in areas such as security, discovery or traffic management. The Lagom framework also has some overlap with Istio although the former is more focused on developer capabilities. Finally, some individual projects of the Netflix OSS stack such as Atlas or Hystrix can also be seen as alternatives to Istio."
    },
    {
        "url": "https://medium.com/@jrodthoughts/machine-learning-and-data-governance-2-0-293631d54f96?source=user_profile---------211----------------",
        "title": "Machine Learning and Data Governance 2.0 \u2013 Jesus Rodriguez \u2013",
        "text": "Data governance and data quality management are some of the most painful aspects of enterprise data solutions. For decades, data platform vendors such as Informatica, Oracle, Microsoft and others have continuously attempted to solve the data governance and quality management challenges but none of their solutions achieved mainstream success.\n\nTraditional data governance and data quality management platforms have typically relied on static rules that execute against well-defined data sources. Products such as SQL Server Data quality Services or Informatica Data Services provide Excel-like interfaces that can allow data stewards to identify patterns in datasets and create rules for data filtering and curation. Not surprisingly, this types of platforms have resulted too constrained to operate in modern data environments.\n\nThe limitation of traditional data governance and quality management platforms and lack of mainstream adoption made the entire market fall out of favor in the enterprise space. Recently, a new generation of startups has been reimagining the data governance and quality management market using new techniques such as machine learning and advanced data visualizations. Platforms such as Trifacta, Paxata, Tamr or Alation are great examples of this generation of technologies. Let\u2019s call this movement data governance 2.0.\n\nConceptually, data governance 2.0 can be seen as a combination of three fundamental capabilities: data capture and quality management, data discovery and exploration and data security and governance. I know that data governance purists might have another 100 capabilities to add to my definition but, in my experience, most of those can be encapsulated into one of those three main groups.\n\nData governance 2.0 such as Trifacta or Paxata remove the friction of human create data quality rules with machine learning and sophisticated statistical models that facilitate the exploration of data sources, detect hidden patterns and formulate rules that curate and control their quality. By leveraging machine learning, data governance 2.0 platforms are not only able to create more advanced data quality management models but also adapt to changes in registered data sources without requiring heavy human intervention.\n\nHow to implement advanced analytics or machine intelligence(MI) solutions when we don\u2019t even know what data sources are available in my origination? Data catalog have become a very powerful mechanism to enable data exploration and discovery in enterprise settings. Tamr Data Catalog is one of the most innovative data discovery platforms in the market. Azure Data Catalog is another interesting initiative in the PaaS space.\n\nData privacy and access control policies are an essential element of data governance 2.0 platforms. Machine learning again plays an important role in this capability as models can detect vulnerabilities on and data sources and apply or recommend the appropiate security policies. Alation is a platform that has been pioneering this new type of data governance and security model."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-cognitive-toolkit-2-0-69abc781de2b?source=user_profile---------212----------------",
        "title": "Microsoft Cognitive Toolkit 2.0: The Big Software Companies Behind Popular Deep Learning Frameworks",
        "text": "A few days ago, Microsoft announced the released of the second version of its Cognitive Toolkit. Previously known as CNTK, the Microsoft Cognitive Toolkit is an open source, deep learning framework that enables the implementation of advanced neural network models. The Cognitive Toolkit is Microsoft\u2019s alternative to popular open source deep learning frameworks such as Theano, Torch, TensorFlow and others.\n\nAmong the notable features of the Cognitive Toolkit 2.0 we have the interoperability with Keras, a popular Python-based library that provides a high level programming model for the implementation of neural networks. Keras programs can run on deep learning runtimes such as Theano, TensorFlow and now the Microsoft Cognitive Toolkit. In its new release, the Microsoft Cognitive Toolkit also includes Java language bindings (in addition to C# and Python which were supported before) as well as a set of new tools that enable the optimization of models to run on smartphones and IOT devices. Finally, the Cognitive Toolkit also released some impressive benchmarks that show it outperforming its competitors by up to 3x on some specific scenarios.\n\nThe Microsoft Cognitive Toolkit joins the highly fragmented market of open source deep learning frameworks. In this ecosystem, many of the top software companies in the world have aligned their artificial intelligence(AI) efforts with different deep learning frameworks which makes up a fascinating competitive landscape.\n\nMany of the top software companies in the world such as Facebook, Google, Amazon, Microsoft, Baidu or Alibaba have been regularly releasing highly sophisticated AI APIs. What is not so well-known is the fact that these same vendors have been actively supporting and pushing different open source deep learning libraries which is creating a unique combination of innovation and competition in the deep learning market. Let\u2019s take a look:\n\n\u2014 Google & TensorFlow: TensorFlow is arguably the best example of the link between a big tech company and an open source deep learning framework. Google open sourced TensorFlow a couple of years ago and it has made it the cornerstone of its AI strategy. In just a few months, TensorFlow has become the platform behind some of Google\u2019s premier AI technologies such as Google ML, DeepMind Lab-Sonnet, Google AI APIs, TensorFlow Lite, etc.\n\n\u2014 Facebook & Caffe2: Facebook has worked on several deep learning stacks like Torch. However, recently the social media giant seems to be lining up its efforts behind Caffe2 releasing several contributions such as Caffe2Go.\n\n\u2014 Amazon & MxNet. AWS has been trailing Google Cloud and Azure on its AI efforts but recently it seems to be putting more effort behind Apache MxNet. Not as popular as some of its competitors, MxNet provides C++ and Python based programming models for the implementation of neural networks.\n\n\u2014 Baidu & PaddlePaddle: The Google of China has also been active in the deep learning space. Baidu recently open sourced its PaddlePaddle stack which provides a Python-based programming model for the implementation of deep learning models.\n\n\u2014 Alibaba is Playing Neutral: In a market in which cloud incumbents are actively pushing specific deep learning frameworks, Alibaba is playing a more neutral strategy. Currently, the Aliabab cloud Machine Learning service supports programs written on a variety of deep learning frameworks which makes it a very unique offering in the market.\n\nNo single deep learning framework is good at everything. TensorFlow notably excels on natural language processing and image e analysis models while the Microsoft Cognitive Toolkit has shown an impressive performance in areas such as speech recognition. With the support and resources of big tech companies, open source deep learning frameworks are likely to continue expanding its capabilities on specific areas creating a fascinating, yet very fragmented, competitive landscape."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-lyft-and-ibm-have-been-collaborating-on-this-platform-to-make-microservices-more-ceed77cc3ae5?source=user_profile---------213----------------",
        "title": "Google, Lyft and IBM Have Been Collaborating on this Platform to Make Microservices More Mainstream",
        "text": "Microservices has become the new fashion for building large scale distributed systems. as an architecture style, microservices advocates partitioning large applications into small, atomic, functional building blocks that communicate via APIs or RPC-protocols (yes those are back ;) ). Not surprisingly, microservices has been adopted as the architecture paradigm powering internet powerhouses such as LinkedIn, Netflix, Uber, Facebook and many others.\n\nDespite its hype, the promise of microservices hasn\u2019t materialized in a new generation of technology platforms. To this day, there are only a handful of microservices platforms such as Spring Cloud, Lagom or Azure Service Fabric that provides a somewhat-complete experience for building, deploying and managing microservices. More importantly, none of those platforms has been able to achieve dominant market share. Efforts such as Netflix OSS has produced a lot of interesting contributions to the microservices space but they remain mostly a set of isolated tools and frameworks rather than a cohesive platform.\n\nIstio is a new platform tha provides a network of microservices, or service mesh, with infrastructure capabilities to enable relevant aspects of microservices architectures such as traffic management, security, monitoring, discovery, load balancing, fault injection and several others. Istio provides tools and frameworks that enable the creation of policies that regulate different runtime aspects of a service mesh. The platform operates at the network level and it leverages Lyft\u2019s open source Envoy proxy. This characteristic allows Istio to operate without requiring changes on specific microservices.\n\nIstio leverages Kubernetes as its underlying runtime infrastructure but it plans to rapidly add support to other runtimes such as Mesos or Cloud Foundry. The dependency on Kubernetes has drawn the involvement of Google in the project. Google is working to expand Istio\u2019s capabilities to some of its technologies such as Cloud Endpoints and the Apigee platform. IBM\u2019s involvement indicates that Istio might soon be included in Bluemix cloud services.\n\nThe release of Istio highlights the need and opportunity for new microservices platforms to enter the market. Despite the availability of platforms such as Spring Cloud, Lagom or Azure Service Fabric, there is a plenty of opportunity for new microservices development and devops stacks to capture meaningful market share in the nascent microservices space. Some of the following areas could be attractive to new microservices platforms:\n\n\u2014 Microservices Implementation: Frameworks and tools to model microservices patterns such as actors or stateful services are super relevant of the mainstream adoption of microservices. Frameworks such as gRPC , Thrift or Finagle are relevant examples of this capability.\n\n\u2014 Monitoring and Network Visualizations: Tools that enable the visualization and monitoring of microservices topologies are one of the most exciting categories in this market. Tools such as Netflix OSS\u2019 Atlas are a good example of this capability.\n\n\u2014 Lifecycle Management: Microservices architectures are considerably more complex than other distributed systems. Tools and frameworks that enable the testing and lifecycle management of microservices is one of the categories that is likely to receive a lot of attention in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-tamr-catalog-simplifies-data-discovery-in-the-enterprise-a1df90c82075?source=user_profile---------214----------------",
        "title": "Technology Fridays: Tamr Catalog Simplifies Data Discovery in the Enterprise",
        "text": "Welcome to another Technology Friday on which I try to cover innovative technologies in hot markets that are somewhat flying under the radar. Today, I would like to focus on the challenging market of data discovery and discuss a platform that is literally redefining the space: Tamr.\n\nData discovery, is, very often, the forgotten child of enterprise data pipelines. In large enterprise environments with thousands of back office systems, sophisticated analytic solutions often fail because the simple fact that people don\u2019t know what data sources are available and how to interact with them. This problem has gotten drastically worse with the proliferation of unstructured and semi-structured data sources . For decades, traditional data quality management vendors attempted to provide enterprise data discovery solutions but none of those solutions achieved mainstream adoption.\n\nTamr tackles the enterprise data discovery challenges using a metaphor from the consumer market: data catalogs. Data marketplaces have become a popular concept in the consumer internet as a way to discover and explore public data sources. Tamr Catalog combines some of the user experience concepts of consumer data marketplaces with advanced machine learning techniques that provide a novel model to enable data discovery and exploration in the enterprise.\n\nTamr Catalog is distributed as an open source solution for data discovery and exploration. At the core of the platform, there is a catalog-like user experience that enables the browsing of registered data sources. Tamr provides connectors to mainstream data systems such as SQL Server, Oracle, MongoDB, Teradata. Similarly, Tamr Catalog can connect to popular SaaS and line of business applications. Developers can extend Tamr Catalog by providing connectors to new databases of back-office systems.\n\nFor each registered source, Tamr Catalog leverages static algorithms to highlight relevant metrics such as Attributes (fields or columns), Records( number of rows), Items( tables\u2026) and several others. Tamr Catalog users can add new metadata constructs to Sources in the form of comments, tasks and other artifacts.\n\nTamr Catalog leverages advanced machine learning and data visualization techniques to streamline the discovery and exploration of data sources. Treemaps are a premier example of this capability. Tamr Catalog\u2019s Treemaps provide an intuitive visualization for large volumes of data. Treemaps cleverly use color-scales and shapes to help users explore data sources and metrics.\n\nThe capabilities of the Tamr Catalog platform expand beyond its sophisticated user interface. The platform includes APIs and SDKs that enables its integration with third party applications. Additionally, the Tamr CLI provides a command-line interface to automate data discovery and exploration tasks.\n\nEnterprise data discovery is experiencing a renainesence in the enterprise. Consequently, Tamer is experiencing active competition from new platforms such as Alation as well as data quality management innovators such as Trifacta or Paxata. Cloud data discovery services such as Azure Data Catalog are also relevant competitors of Tamer in some contexts."
    },
    {
        "url": "https://medium.com/@jrodthoughts/heuristics-and-artificial-intelligence-4e0d73844f8a?source=user_profile---------215----------------",
        "title": "Heuristics and Artificial Intelligence \u2013 Jesus Rodriguez \u2013",
        "text": "Supervised and semi-supervised learning are the dominant types of learning models in modern artificial intelligence(AI) solutions. As a result, AI agents regularly inherit patterns of human thinking and cognitive decision making processes that have little to do with statistical reasoning and more to do with subjective cognition. In the past, I\u2019ve written extensible about bias as one of those subjective cognitive factors that can permeate the knowledge of AI systems. Today, I would like to cover another essential element of human reasoning that can have an impact in the knowledge acquired by AI solutions: heuristics.\n\nConceptually, heuristics are a cognitive mechanism that helps us find correct but imperfect answers to complex questions. Renown psychologists and novel prize winner Danny Kahneman and his long time collaborator Amos Tversky shocked the world in the 1990s when they showed that heuristics often substitute statistical reasoning when comes to make decisions. Gerard Gigerenzer is another top psychologist that have dived into the science behind heuristics. Gigerenzer\u2019s book Simple Heuristics that Make Us Smart is one of the bibles of this topic.\n\nCognitive psychology recognizes many types of heuristics that are part of human knowledge and decision making processes. A classic example is the Substitution Heuristic that causes a person to substitute a complex questions with a simpler ones in order to provide an initial answer. For example, imagine an oncologist examining a cancer patient trying to answer a question such as: How likely is this tumor to metastasized? can come up with a probability by answering the heuristic question: How sick does the patient looks like today? The heuristic question-answer is not based on a detailed evaluation of the patient\u2019s symptoms but rather on the subjective opinion of the physician.\n\nAnother example of heuristic is what is known is psychology as the recognition heuristic which states that we tend to associate a hypothesis with a subject if we recognize it. For instance, a subject who is asked which of two (relatively big) cities is larger and recognizes one of them should guess that the one he/she recognizes is the largest one.\n\nOne of my favorite heuristics is what is known in economics as the Law of Small Numbers that states that many conclusions in experiments have been determined without sampling a large enough dataset. In order to validate an experiment, many times, experts choose samples simply too small to arrive to a meaningful conclusion but that doesn\u2019t seem to preclude them from asserting the results as valid.\n\nThere are many other well-known heuristics in the cognitive psychology space such as Confidence-Doubt or Cause-Chance. Over the years, heuristics have stamped their fingerprint all over human knowledge and data. Now, the same heuristic-based knowledge is becoming the source of information we use to train AI agents. As a result, many AI systems reflect cognitive patters that are highly illogical and have no correlation to statistical analysis principles.\n\nAddressing heuristic-based thinking in AI agents is far from trivial. For starters, the experts in charge of training AI systems are, after all, humans and therefore vulnerable to heuristic analysis which makes for an ironic vicious circle. However, the good news is that most sign of heuristics can be identified by running statistical or unsupervised learning models that inspect the datasets for heuristic patterns. We should also factor in that there are many scenarios in which heuristics can have a positive impact in AI systems. That will be the subject of a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/tensorflow-lite-and-the-raise-of-mobile-deep-learning-runtimes-64f282cc4819?source=user_profile---------216----------------",
        "title": "TensorFlow Lite and the Raise of Mobile Deep Learning Runtimes",
        "text": "Mobile applications are one of the most important sources of sensory information for deep learning applications. However, until now, mobile devices have not been a valid runtime for deep learning programs which are typically destined fro GPU-optimized environments in cloud platforms. In a typical scenario, a mobile application collects certain data point in the fro of text, images or contextual information and then invokes a deep learning model via an API interface which process and data and outputs the results. That picture is changing rapidly as deep learning stacks are becoming available in mobile runtimes.\n\nA few days ago at its I/O conference, Google announced TensorFlow Lite, a version of the popular deep learning framework that can run on Android devices. TensorFlow Lite allows developer to build leaner deep learning models optimized for Smartphone runtimes. The announcement was complemented by the release of the new version of the TensorFlow Processing Unit(TPU) chips which is increasingly powering a new generation of connected devices including smartphones.\n\ntensorFlow Lite is not the only effort to bring deep learning to Smartphone runtimes. Last year, Facebook released Caffe2Go, a version of Caffe that enables the execution of deep learning models on different mobile OSs. In the near future, we are likely to see more deep learning frameworks such as Theano, Torch, Keras, MxNet, PaddlePaddle and others extend their capabilities to mobile runtimes.\n\nWatson in Your Pocket: Mobile Cognitive Services Become Real\n\nAs smartphones become a viable runtime for deep learning models, the mobile OS providers will start including cognitive-AI services as a first class component of their runtimes just as common as geo-location, push notifications, accelerometers and others. A group of classic cognitive techniques such as sentiment analysis, knowledge extraction, image recognition, speech-to-text conversation, entity-intent analysis and several others are viable candidates to execute on mobile runtimes. From that perspective, mobile developers will start leveraging deep learning capabilities as a native component of mobile apps.\n\nMore and more, we are transitioning towards a multi-runtime AI world in which the same deep learning models can execute on different runtimes such as on-premise servers, cloud platforms, containers, IOT devices, smartphones, car consoles and several others. On each runtime, deep learning models will have to adapt to more efficiently take advantage of the specific capabilities of its environment.\n\nTensorFlow Lite is the type of capability that can give Google an edge over Apple in the mobile OS wars. In the last two years, Apple has made a series of acquisitions of machine learning and AI talent. From that standpoint, it is likely that Apple could soon release a suite of mobile and cloud cognitive services with the next version of IOS. Additionally, Apple could leverage its monster balance sheet to make a game-changing acquisition in the AI space. Nvidia anybody\u2026.?\n\nNothing like a crazy thought to end the post ;)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-bitfusion-flex-brings-lifecycle-management-to-artificial-intelligence-fe8933fb19cd?source=user_profile---------217----------------",
        "title": "Technology Friday: Bitfusion Flex Brings Lifecycle Management to Artificial Intelligence",
        "text": "On today\u2019s technology Friday I would like to cover one of the most exciting platforms in the deep learning space: Bitfusion flex. In the past ( more like every week ;) ) I\u2019ve written about the need for platforms that simplify the management, testing and training of deep learning applications. Bitfusion is trying to tackle this challenge head on with its Flex platform. The company recently received a strong validation by raising $5 million from investors such as Sierra Ventures, Vanedge Capital, Data Collective and several others.\n\nOne of the main challenges in the deep learning market is the lack of balance between application development frameworks and the corresponding application management tools. While we have witnessed an explosion on the number and variety of frameworks for building neural network applications such as TensorFlow, Theano, Torch, Caffe, MxNet, Bonsai, PaddlePaddle and many others, the tools and frameworks of managing and monitoring deep learning applications haven\u2019t evolved at the same pace.\n\nBitfusion Flex provides an elastic, GPU-optimized infrastructure for the execution of AI programs written in frameworks such as TensorFlow, Torch, Caffe, MxNet and others. Flex also includes tools of managing, training and monitoring deep learning applications.\n\nThe Bitfusion Manager is the main interface to interact with the Flex platform. The tool provides a web portal for managing deep learning projects and datasets as well as complementary assets. Projects are a core concept of the Bitfusion platform that encapsulates the code and data associated with a deep learning application. Developers can create and execute projects directly from the Bitfusion CLI which provides a command-line interface that automates many aspects of the lifecycle of deep learning applications. As part of the Project configuration, developers can specify the runtime environment (TensorFlow, Torch, Caffe\u2026) to execute the application as well as the expected GPU topology. Bitfusion typically encapsulates projects as containers and attaches GPU-CPU resources to them.\n\nAs mentioned before, one of the greatest benefits of Bitfusion Flex are its multi-framework capabilities. In order to streamline the implementation of deep learning applications ,Flex introduces the notion of Workspaces, an interactive environment based on Jupyter . With Workspaces, Bitfusion Flex developers have access to the core Jupyter artifacts such as code notebooks, file browser and the terminal web shell. The Bitfusion CLI is also included as part of the Workspace environment so that developers can manage different aspects of their applications without having to switch tools.\n\nanother innovative capability of Bitfusion Flex is the fact that it combines data and code within the same environment. Developers can use the Bitfusion CLI or Manager to upload datasets that are used to train, test and optimize deep learning applications.\n\nWho is the Competition?\n\nBitfusion Flex is a unique offering in the deep learning market and, as a result, it is still not experiencing a lot of competition. Other multi-runtime deep learning platform such as Floyd or the Alibaba Cloud Machine Learning service can be considered competitors. Also, if we are solely talking about TensorFlow applications, Google Cloud ML provides a comparable feature set to Flex."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-raise-of-the-third-runtime-and-new-opportunities-for-runtime-hypecycle-startups-da87a42be2ef?source=user_profile---------218----------------",
        "title": "The Raise of the Third Runtime and New Opportunities for Runtime-Hypecycle Startups",
        "text": "We are living in fascinating times in the technology industry with an unprecedented level of innovation creating new technology sectors and redefining others. In that dynamic, trends such as virtual reality(CR), self-driving cars or bots are driving new generation of applications and are attempting to become the next big runtime in the software market. The emergence of a new runtime has consistently brought new opportunities for startups in areas such as security, analytics, management tools and others. I like to call this type of emerging players runtime-hypeclycle startups as they consistently emerge from runtime wave to runtime wave and create a considerable amount of success and wealth.\n\nThe New Runtime: From Web to Mobile to What\u2019s Next\n\nThe web can be categorized as the first major mainstream runtime in the software industry. The web runtime created a generation of runtime-hypecycle startups in areas such as security( Symantec), application monitoring( BMC, NewRelic\u2026), application lifecycle management (Atlassian\u2026) and many others.\n\nMobile followed the web as the second major runtime for software developers. Just like the web, the mobile space created a generation of runtime-hypecycle companies in areas such as management( AirWatch, MobileIron\u2026), security( Mocana\u2026), monitoring( MixPanel, AppAnnie\u2026.) and several others.\n\nThe \u201cpost-mobile: world is unlikely to be dominated by a single runtime. Instead, there are several platforms that are emerging as suitable candidates to power the next generation of software application. Here are a few that are already here:\n\n1 \u2014 Messaging: Messaging runtimes such as Facebook Messenger or Slack are driving the raise of chatbots as a successor of mobile applications.\n\n2 \u2014 Virtual Reality: Virtual reality(VR) stacks such as Oculus Rift or Hololens will be another relevant runtime for a new generation of software applications.\n\n3 \u2014 Digital Assistants: Voice is becoming a great metaphor for the next type of user interface and technologies such as Alexa or Cortana are racing to dominate the space.\n\n4 \u2014 Self-Driving Vehicles: Companies such as Waymo are building a consistent runtime experience for self-driving vehicle applications.\n\n5 \u2014 Drones: Drones are also becoming a relevant runtime for a growing segment of the software industry.\n\nOn purpose, I didn\u2019t include categories such as wearable\u2019s in the list are they are often seen as an extension of mobile runtimes. Similarly, I excluded IOT devices because I don\u2019t find enough consistency in the space to classify it as a new runtime.\n\nAs the third generation of runtimes evolves, we are likely to see incumbents dominating areas such as application development and infrastructure. However, it is equally certain that we will see a new generation of runtime-hypecycle startups in areas such as the following:\n\n\u2014 Application Performance Monitoring: Runtimes such as messaging or virtual reality will require new application monitoring techniques and platforms.\n\n\u2014 Security: Application protection, threat analysis, data privacy are some of the security areas that can produce a new group of startups for segments such as self-driving cars or drones.\n\n\u2014 Application Lifecycle Management: Deployment, testing and distribution will require new platform for the third generation of application runtimes. Finding the Atlassian of self-driving vehicles is an interesting challenge for investors in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/iot-core-is-google-clouds-entrance-in-the-enterprise-iot-space-4e3f12a1c12a?source=user_profile---------219----------------",
        "title": "IOT Core is Google Cloud\u2019s Entrance in the Enterprise IOT Space",
        "text": "Internet of things(IOT) services are an important capability of lead platform as a service stacks such as AWS, Azure or Bluemix. IBM has made its Watson IOT platform a core component of its \u201cstrategic imperatives\u201d driving its transformation strategy. Similarly, Microsoft and Amazon have been aggressively pushing their Azure IOT Suite (IOT Bundle) and AWS IOT stacks respectively. Surprisingly, IOT has been missing from the Google Cloud platform, but that\u2019s about to change.\n\nGoogle IOT Core is Google Cloud\u2019s first attempt to provide a comprehensive strategy for linking Google Cloud capabilities and IOT devices. IOT Core enables the management of IOT devices that leverage Google Cloud services. The platform takes advantage of native Google Cloud services such as Cloud Functions and Pub/Sub to manage and distribute updates to devices. Specifically, Pub/Sub plays a central role in IOT Core as the main messaging hub to distribute data between IOT devices and Google Cloud endpoints.\n\nIOT Core actively leverages Google Cloud\u2019s advanced portfolio of data services integrating technologies such as BigTable and BigQuery to enable data storage capabilities, DataFlow to power data aggregation models against data produced by IOT devices as well as DataStudio and DataLab to enable advanced analytics in IOT topologies. that combination of capabilities enables IOT Core to power the implementation of highly sophisticated IOT scenarios.\n\nWith IOT Core, Google is bringing along chip manufacturers such as ARM or Intel which are becoming increasingly relevant for IOT devices. Similarly, we should see other IOT device manufacturers join and support Google IOT Core\u2019s efforts.\n\nHow About the Competition?\n\nBy providing IOT-specific services, Google IOT Core certainly addresses one of the biggest limitations of Google Cloud. However, the current feature set of IOT Core is still relatively limited in a highly competitive field. In addition to the IOT platforms in PaaS stacks such as Azure IOT Suite, AWS IOT or Watson IOT, Google faces competition from industrial powerhouses such as GE (Predix) and PTC (ThingWorx) as well as from innovative IOT startups such as C3IOT or Xively. Despite these challenges, Google has very unique assets that can become a differentiator for the IOT Core platform.\n\nGoogle Cloud\u2019s impressive artificial intelligence(AI) services portfolio can become incredibly relevant in IOT scenarios. Android is also a unique asset that Google can leverage to streamline the adoption of IOT Core. Other divisions of Alphabet such as Waymo (self-driving cars) or Nest( home automation) can become unique distribution channels for Google IOT Core.\n\nBelow, I\u2019ve listed some ideas that I would like to see in Google IOT Core in order to bridge the gap with the competition and become a more viable platform for the implementation of IOT solutions:\n\n1 \u2014 Stream analytics: Processing and executing SQL queries against continuous streams of data generated by IOT devices should be a high priority in Google IOT Core\u2019s roadmap. Azure Stream Analytics or AWS Kinesis Analytics are great examples of this type of technology.\n\n2 \u2014 Edge Computing Services: Enabling Google Cloud services such as Cloud Functions or Cloud ML to execute in IOT device runtimes will help to leverage the IOT Core platform in highly sophisticated IOT scenarios.\n\n3 \u2014 Device State Management: Backing up and restoring the state of IOT devices would be another welcomed capability for Google IOT Core. AWS IOT Device Shadows is a good reference point for this type of technology.\n\n4 \u2014 Time-Series Storage & Stream Simulation: Time-Series optimized databases and stream replay and simulation will improve the testing and maintenance of IOT solutions built on the Google IOT Core platform. Microsoft recently released Azure TimeSeries DB as a new component of its IOT capabilities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-companies-can-take-the-early-lead-in-the-edge-computing-market-512704a93b90?source=user_profile---------220----------------",
        "title": "These Companies Can Take the Early Lead in the Edge Computing Market",
        "text": "Edge computing is called to become one of the most important computing paradigms in the next decade of software applications. As a result, in the next few years we are likely to witness the emergence of a new group of platforms that power the next generation of edge computing solutions. Whether you are an enterprise evaluating edge computing initiatives of a venture capitalists interested in the space, developing a thesis about the edge computing market can become an important asset.\n\nLooking for the AWS of Edge Computing\n\nEdge computing is as exciting as it is challenging. The decentralized, autonomous of edge computing architecture introduce challenges unknown to most application development platforms. Furthermore, in order to gain relevant market share in the edge computing space, a platform provider should share a very unique set of characteristics such as the following:\n\n1 \u2014 Dynamic Developer Community: I believe the next generation of edge computing platforms are going to emerge from companies that already have large and vibrant developers communities which can easily make the transition into the new trend. At least in the near future, building a brand new developer community in addition to achieving market credibility can result on an impossible challenge for startups in the edge computing space.\n\n2 \u2014 Existing Platform Capabilities: Complementing the previous point, the first group of successful edge computing platforms is likely to emerge ass an extension to existing platforms with relevant capabilities in areas such as compute, storage, messaging, analytics and many other fundamental building blocks of edge computing solutions.\n\n3 \u2014 Domain Expertise in Industrial-Decentralized Applications: A large percentage of the first generation of edge computing solutions will take place in the industrial enterprise space. Expertise in that domain or a relevant presence building decentralized applications will incredibly important for the success of the first group of edge computing platforms.\n\n5 Companies Companies that can Lead the Edge Computing Platform Market\n\nBelow I\u2019ve listed some examples of companies that are well positioned to gain relevant traction in the nascent edge computing space:\n\n1 \u2014 Microsoft: Azure IOT Edge represents Microsoft\u2019s first serious attempt in the edge computing space. Microsoft\u2019s edge computing capabilities are initially delivered as an extension of the Azure cloud platform .\n\n2 \u2014 Amazon: Similarly to Microsoft, Amazon has been developing edge computing capabilities to extend the AWS platform. AWS Greengrass is a primary example of AWS\u2019 ventures into the edge computing space.\n\n3 \u2014 Alphabet: Android, Nest, Waymo are some of Alphabet\u2019s top assets in the edge computing space. Those assets plus the strong growth of the Google Cloud platform position Alphabet in a solid place to become a leader in the edge computing market.\n\n4 \u2014 GE: GE Predix is one of the best adopted IOT platforms in the market which already include relevant edge computing capabilities. Additionally, GE\u2019s unique expertise delivering edge computing solutions across different industries such as aerospace or manufacturing can result a unique advantage in its market position.\n\n5 \u2014 Ethereum: Blockchain technologies can be a powerful enabler of edge computing solutions. Ethereum is in a unique position to extend some of its capabilities such as Smart Contracts or DAOs to edge devices. More than any other company, Ethereum has the opportunity to define a new type of blockchain-powered architecture as the standard for edge computing solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/facebook-parlai-and-the-evolution-of-artificial-intelligence-testing-84d5ec70ef37?source=user_profile---------221----------------",
        "title": "Facebook ParlAI and the Evolution of Artificial Intelligence Testing",
        "text": "Testing and training are two of the most important aspects of artificial intelligence(a AI) solutions. While a lot of effort has gone into launching new AI-Deep Learning frameworks, the testing platform and frameworks have not kept up the pace.\n\nLast week, Facebook took a significant step towards improving the ecosystem of AI testing technologies with the open source release of ParlAI, a framework for testing, training and researching conversational models. ParlAI joins similar solutions in the AI industry as OpenAI\u2019s Gym or DeepMind\u2019s Lab which are aiming to build an ecosystem that can streamline the testing of AI applications.\n\nParlAI is the brainchild of the Facebook AI Research Lab(FAIR). With Facebook\u2019s investment in bots and conversational technologies, it should not be a surprise that ParlAI\u2019s initial focus has been on dialog and natural language processing techniques. In the future, we should expect ParlAI to expand onto other AI areas.\n\nParlAI brings together several capabilities that simplify the training and testing of AI models. The platform gives AI researchers quick access to highly curated datasets such as WebQuestions, bAblTasks, SQuAD and several others. The framework also makes it relatively simple for AI researchers to incorporate new algorithms that can be tested using the platform. ParlAI also provides integration with Amazon Mechanical Turk which enables the use of human tasks to curate data sources that can be used by AI models.\n\nOne of the areas on which ParlAI excels at is the bridge between natural language processing research and its practical availability. While there are many new conversational AI techniques pioneered by academic research, their scope is very often too narrow to be included in NLP stacks. ParlAI enables the testing and benchmarking of algorithms as well as their integration with other models to produce comprehensive conversational solutions.\n\nDifferently from solutions such as OpenAI\u2019s Gym or DeepMind\u2019s Lab that focus on general reinforcement learning models, ParlAI emphasizes on supervised conversational AI algorithms. This level of focus is likely to pay dividends for ParlAI in the short term as conversational applications are becoming the fastest growing discipline within the deep learning space.\n\nAs AI continues evolving, we are likely to see new testing frameworks similar to ParlAI. What are the key features to look for in these type of and? Here is an initial selection:\n\n1 \u2014 Curated Datasets: AI testing frameworks should provide a portfolio of curated datasets that can be easily used in AI models.\n\n2 \u2014 Interoperability with AI Application Development Frameworks: AI testing frameworks should seamlessly interoperate with AI application development frameworks such as Bonsai, TensorFlow, Theano and others.\n\n3 \u2014 Curated Algorithms: AI testing frameworks should enable the addition of new algorithms that can be tested and trained.\n\n4 \u2014 Algorithm Performance Monitoring: AI testing frameworks should provide mechanisms for monitoring and benchmarking the performance of AI models against specific datasets.\n\n5 \u2014 Collaboration: AI testing frameworks should facilitate the collaboration between AI researchers in order to optimize models and datasets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bonsai-is-making-deep-learning-real-for-enterprises-a15807e7f550?source=user_profile---------222----------------",
        "title": "Technology Friday: Bonsai Is Making Deep Learning Real for Enterprises",
        "text": "On today\u2019s Technology Friday I would like to cover one of my favorite artificial intelligence(AI) \u2014 deep learning platforms in the market: Bonsai. A long time favorite of AI researchers, Bonsai recently gained more notoriety by raising a $7.6 million funding round led by Microsoft Ventures.\n\nArchitecturally, Bonsai expands the capabilities of well-known, deep learning frameworks such as Theano, Torch or TensorFlow by providing a complete platform that enables the end-to-end implementation of deep learning solutions. From that perspective, Bonsai provides a series of tools and frameworks components that abstract the fundamental building blocks of AI applications.\n\nAt the center of the Bonsai platform, we have the concept of a BRAIN ( Basic Recurrent Artificial Intelligence Network)/ Bonsai\u2019s BRAINs are AI agents programmed with deep learning models using the Inkling AI domain specific language. Bonsai leverages Inkling as the main programming interface for the implementation of AI models. Based on Python (shockingly so ;) ), Inkling is a domain-specific language based on Pedagogical Programming techniques. Pedagogical Programming contrasts with traditional AI techniques in the sense that it teaches an AI agent how to find a solution to a problem instead of how to simply calculate it. Inkling relies on teaching-oriented approach that uses a series of AI foundational primitives but abstracts most of the underlying aspects of the implementation AI models. Developers can use Inkling from different Python environments including Bonsai\u2019s own Mastermind IDE.\n\nOne of my favorite capabilities of Bonsai is its programming model that includes components of real world AI solutions such as Simulators and Generators. Bonsai Simulators imitate a representation of a virtual environment use for training. Simulators could be as simple as a basic data pattern or as complex as a game or a self-driving vehicle scenario. Generators are the component of Bonsai responsible for producing labeled data used as a training source.\n\nBonsai AI Engine is the core runtime component of the platform. The AI Engine is responsible for executing and scaling BRAINs deployed on the platform. This component of the Bonsai stack includes a rich portfolio of machine learning algorithms and is in charge of managing the resources required to execute AI models. Additionally, the AI Engine manages the streaming data flow and the storage of data. One of the most fascinating aspects of Bonsai AI Engine are the heuristic algorithms it uses to determine the specific, models, topologies and optimization techniques required to train a specific BRAIN. That type of heuristic removes a lot of the heavy lifting from developers so that they can focus on building the fundamental aspects of the AI model.\n\nBonsai includes several components to enable the automation and extensibility of AI solutions. The Bonsai CLI provides a command line interface to dynamically interact with the AI Engine. Similarly, Bonsai exposes many of its capabilities programmatically thought its APIs. Developers can extend Bonsai\u2019s applications by implementing custom Generators or Simulators using the Bonsai SDKs.\n\nBonsai can be certainly classified as one of the most innovative AI platforms in the market. From a competitive landscape standpoint, I believe Bonsai should be compared to end-to-end AI application development platforms such as H2O.ai rather than to deep learning frameworks such as TensorFlow or Theano. However, developers should be aware that by selecting Bonsai, they are buying into a specific programming model for AI applications.\n\nAt least for now, Bonsai presents one of the most complete and innovative AI platforms in the market and can be a great option for enterprises venturing in their AI journey."
    },
    {
        "url": "https://medium.com/@jrodthoughts/with-azure-iot-edge-microsoft-looks-for-an-edge-in-the-cloud-wars-8c6d72b852fc?source=user_profile---------223----------------",
        "title": "With Azure IOT Edge, Microsoft Looks for an Edge in the Cloud Wars",
        "text": "Edge computing is becoming the next battleground of the application platform space and Microsoft wants to lead the charge. during the recent Build conference, Microsoft announced the availability of Azure IOT Edge, a new service that delivers cloud capabilities to IOT devices. This release represents Microsoft\u2019s first step in their new edge computing strategy.\n\nAzure IOT Edge extends the capabilities of the Azure IOT Bundle platform to edge devices. the platforms brings versions of traditional Azure services as well as thirds party technologies to IOT devices. Additionally, Azure IOT Edge simplifies the integration with machine intelligence services such as Cognitive Service or Machine Learning for in-device applications.\n\nModules are at a core feature of Azure IOT Edge. Functionally, Modules enable atomic capabilities in IOT applications. Azure IOT Edge enables inter-module integration by leveraging declarative messaging passing techniques. IOT Edge Modules typically run in Docker containers and exchange messages using an in-device version of the Azure IOT Hub ( a module itself).\n\nThe current version of Azure IOT Edge includes a rich catalog of modules such as BLE (bluetooth low energy), IdentityMap( MAC encoding), Logger( instrumentation), Simulated Device( BLE-enabled device simulation) and many others. developers can implement their own modules using different programming languages such as NodeJS, C# or Java,\n\nStream analytics is one of the most exciting modules added to Azure IOT Edge. The module enables the collection of streams of data as well as the execution of SQL queries that aggregate and filter data streams directly in the device runtime. The module integrate with Azure Stream Analytics for more scalable, out-of-device stream analytic operations.\n\nAzure IOT Edge is Microsoft\u2019s answer to AWS\u2019 initial edge computing efforts with technologies such as Greengrass. Edge computing is one of the new trends that can help Azure close the gap with AWS in the cloud computing market. While AWS remains the undisputed leader in the space, Azure seems to be growing at a faster pace lately. In the last earning reports, Microsoft announced that Azure has grown an astonishing 90% year-over-year which was almost double of AWS\u2019 growth. Furthermore, Azure already possesses the best hybrid cloud story in the market and edge computing can be a natural extension of those capabilities.\n\nregardless of how the edge computing market evolves, it is fairly certain that we are going to see a large number of Azure and AWS services release version that operate on edge devices. Stream analytics( Azure Stream Analytics- Kinesis Analytics), lambda computing( Azure Functions- AWS Lambda), messaging( Azure Service Bus-AWS SQS), machine learning( Azure ML- AWS ML), document storage( Azure DocumentDB, AWS DynamoDB), deployment( Azure Container Service \u2014 AWS Container Service) are some of thhe key cloud services candidates to deliver edge computing capabilities in the near future.\n\nIn addition to delivering edge computing services, PaaS incumbents such as Microsoft, Amazon or Alphabet are also trying to own new runtimes that can catalyze their ambitions in the edge computing space. Microsoft is clearly relying on versions of Windows that can run on edge devices. Alexa is Amazon\u2019s candidate for a next generation edge computing device. Alphabet has a number of powerful options for edge computing runtimes including Android, Nest and Waymo\u2019s self-driving car platform. One thing is certain, the edge computing battles are going to get interesting in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/natural-language-processing-and-the-art-of-asking-questions-af1a2851284d?source=user_profile---------224----------------",
        "title": "Natural Language Processing and the Art of Asking Questions",
        "text": "Questioning is one of the weakest points in the current generation of digital assistants(DA) and natural language processing( NLP) technologies. Popular conversational products such as Alexa, Siri or Cortana are perfectly able to engage in fairly rich reactive conversations but they are still very limited when comes to determining and asking questions.\n\nRecently, I had the opportunity to review a research paper published by Microsoft Maluuba about machine learning techniques that can be used of question generation. If you are not familiar with Microsoft Maluuba, it is a team mostly composed of artificial intelligence(AI) researches that Microsoft acquired at the beginning of the year.\n\nMaluuba\u2019s paper promotes the idea of using reinforcement learning models to automate question generation. The techniques proposed in the paper are focused on optimizing the accuracy and grammatical structure of questions. The nature of reinforcement learning guarantees that the performance of the algorithms will improve as they are being used. Reinforcement learning techniques are focused on maximizing a utility function based on the result of specific actions (read some of the articles about reinforcement learning in this blog). Maluuba\u2019s algorithms leverage reinforcement learning to generate questions that can be answered based on the content of a specific text.\n\nThe efforts by Microsoft Maluuba\u2019s team are still in very early stages but the ideas showed a lot of promise (at least from the theoretical standpoint). The techniques proposed on the paper, or a variation of them, can result on the initial steps to implement effective question generation models for NLP stacks and DAs.\n\nFrom ad AI and NLP standpoint, question generation is an incredibly difficult task. As a result, most NLP stacks have managed to delay the implementation of question generation capabilities despite its well-known benefits. Let\u2019s look at some of the immediate advantages from leveraging effective questioning in conversational interfaces:\n\nQuestion generation is an effective technique to gather contextual information on a conversation in order to determine which actions should be taken. Think about a sales executive requesting a list of accounts from a DA. Upon receiving the request, the DA can ask additional questions about the nature of accounts in order to execute the correct query against the CRM system.\n\nMost conversational interactions between users and DAs are reactive in nature. Users ask questions and DAs provide answers. Effective question generation algorithms can open the door to a new type of interactions in which DAs can start a conversation with a user by asking a question.\n\nFrom a cognitive standpoint, the ability to generate questions will allow NLP and DA stacks to provide more accurate answers. This is simply based on the fact that, from the linguistic standpoint, there are many questions that lead to the same answers. Understanding a diverse pool of questions related to a specific fact, will help DAs and NLP solutions to provide more effective answers.\n\nQuestions can make DAs to operate more efficiently in contexts of uncertainly. By asking the right questions, a DA can help to transition a conversation from an uncertain context to a certain one.\n\nQuestion generation is an effective cognitive mechanism to clarify a specific intention. Similarly, DAs and NLP stacks can use questions to clarify users intended actions and gather information that can be used as input to self-training NLP models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/private-equity-and-the-post-ipo-life-of-enterprise-tech-companies-6617a8968611?source=user_profile---------225----------------",
        "title": "Private Equity and the Post-IPO Life of Enterprise Tech Companies",
        "text": "This is the third and final part of an essay about the role that private equity (PE) firms have been playing acquiring publicly traded enterprise software companies. The first part of the essay focused on some of the recent high profile acquisitions of PE firms such as Jive, Rackspace, Tibco, Qlik, Marketo and several others. The second part examined some of the factors that make public enterprise tech companies an attractive target for PE firms. Today, I would like to explain our analysis by highlighting some examples of public companies that could be at risk of becoming a target for PE firms.\n\nPublic enterprise tech markets are fundamentally different today than a few years ago. As explained in our previous article, publicly traded enterprise tech companies are operating ni environments on which technology trends are constantly changing diverting the attention of investors. More importantly, many enterprise tech companies are actively facing competition from cloud platform incumbents such as Amazon, Microsoft or Google which are rapidly racing to provide a large percentage of the features required by modern software applications. Think about, you are a publicly traded cloud service company providing a specific capability and you are competing against AWS, Azure or Google Cloud that not only provide that feature but an entire suite of cloud services and are not afraid to drive the price of the service close to zero in order to gain market share. That\u2019s not a great picture when you need to please investors quarter-to-quarter.\n\nIn that climate, PE firms offer many benefits to troubled enterprise tech companies. For starters, PE firms have become masters at identifying under-valued public enterprise tech companies that could be acquired at a discount even if that represents paying a premium compared to their current public market valuation. Additionally, many PE firms such as Vista or Thomas Bravo have developed extremely thoughtful practices in enterprise tech markets. That level of expertise, together with their operational and financial engineering capabilities can be of great help for enterprise tech companies looking to restructure away from the pressure of public markets.\n\nUnderstanding those dynamics, let\u2019s look at some examples of public enterprise tech companies that could become the target of PE firms as well as some that, I believe, are safe from now ;)\n\nSome Enterprise Tech Companies that can Become Attractive PE Targets\n\nThis section does not intend to provide an exclusive list. Instead, I am just trying to give some examples of publicly traded enterprise tech companies that, based on our thesis, can be on the radar of PE firms.\n\n\u2014 MobileIron: MobileIron\u2019s tock has been under an incredible amount of pressure lately but the company still operates on a massive market which doesn\u2019t have many relevant players anymore.\n\n\u2014 Hortonworks: Hortonworks has regularly underperform as a public stock and it faces pressure from incumbents such as IBM, Amazon, Google as well as recently IPO Cloudera.\n\n\u2014 Okta: Okta ad a spectacular debit in public markets and it doesn\u2019t have enough trading history to make it a target of PE firms. However, Okta fits our thesis because it faces direct competition in the identity management space from cloud platforms such as AWS, Azure or Google Cloud. Additionally, the acquisition of Okta\u2019s competitor Ping Identity by a PE powerhouse sets a strong precedent.\n\n\u2014 Tableau: Tableau continues facing strong competition from incumbents such as Microsoft, Google and Amazon and the stock has been somewhat irregular in its performance. Also notice that Tableau\u2019s competitor Qlik was recently acquired by a PE firm which could serve as an indicator for how to structure a potential deal.\n\nNow let\u2019s look at some examples of publicly traded enterprise tech companies that are safe from PE firms for now.\n\n\u2014 Atlassian: The Australian company stock has been flying high and is the undisputed incumbent in the application lifecycle management and collaboration space.\n\n\u2014 Mulesoft: Recently IPO Mulesoft has a lot of room fro growth as a public stock. Mulesoft has been regularly out-innovating and out-performing competitors and is free from pressure from many incumbents in the enterprise integration space (Oracle, IBM might be the exception).\n\n\u2014 Twilio: Twilio has had an incredible run as a public stock and is operating on a space on which the cloud incumbents don\u2019t have a relevant presence. Twilio has a bright future as an independent company."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-ventures-wants-to-become-an-artificial-intelligence-powerhouse-56b60cd25bc1?source=user_profile---------226----------------",
        "title": "Microsoft ventures Wants to Become an Artificial Intelligence Powerhouse",
        "text": "Microsoft hasn\u2019t traditionally been considered an active venture investor but that has been changing in the last few years. Microsoft Ventures has been steadily developing a reputation as a smart corporate venture investor and wants to become one of the go-to venture capital firms for artificial intelligence startups.\n\nLast December, Microsoft Ventures announced the launched of its AI fund and its first investment in Montreal-based Element AI. Just in the last few days, Microsoft ventures has led investments on two promising AI startups: Agolo and Bonsai. Little by little, the venture capital arm of the Redmond giant has been building an impressive portfolio of AI investments that nicely complements its technology stack.\n\nMicrosoft Ventures\u2019 AI fun led the recent $7.6 million round in Berkeley CA-based Bonsai. The Bonsai platform is a recent addition to the fast growing deep learning framework ecosystem. In fact, Microsoft recently open sourced the Microsoft Cognitive Toolkit stack that could be considered a competitor of Bonsai.\n\nBonsai provides an open source, deep learning framework that simplifies the implementation of neural network applications. Bonsai enables a high-level programming models that contrasts with the experience provided by \u201clow level\u201d deep learning frameworks such as TensorFlow or Theano. Those capabilities are accompanied by a highly sophisticated toolset that streamlines the management, training and optimization of deep learning models. The platforms leverages some of the latest libraries released by AI thought leaders such as OpenAI or DeepMind.\n\nMicrosoft Ventures followed its investment in Bonsai by leading the $3.5 million of New York based AI platform Agolo. In that round, Microsoft Ventures partnered with an interesting group of of venture investors including CRU and Steve Cohen\u2019s Point72 Ventures.\n\nAgolo specializes on an area of natural language understanding(NLU) known as content-summarization. Essentially, the Agolo platform is able to analyze long pieces of content, identify key subject areas and their relationships and develop visual summaries that can be easily understood by an end user. Agolo\u2019s summarization platform already integrates with platforms such as Facebook and Amazon\u2019s Alexa.\n\nCorporate venture capital is always controversial but there are many tangle benefits that startups can get from partnering with Microsoft Ventures. For starters, today Microsoft possesses one of the most complete AI offerings in the market which includes cloud machine learning platforms such as Azure ML, AI APIs such as Microsoft Cognitive Services, R distributions like Microsoft R Server, deep learning frameworks such as Microsoft Cognitive Toolkit, data visualization platforms such as PowerBI and one of the most advanced AI database runtimes in the market in SQL Server. Additionally, Microsoft SaaS offerings such as Office365, Dynamics 365 or even Xbox Live offer a massive distribution channel to test new AI technologies. With all those benefits, we should expect Microsoft Ventures AI fund to continue building an impressive portfolio of AI startups in the short term."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-trifacta-wrangler-af897bf9a474?source=user_profile---------227----------------",
        "title": "Technology Friday: Trifacta Wrangler \u2013 Jesus Rodriguez \u2013",
        "text": "Today\u2019s technology Friday takes us to the data quality management space and one of my favorite products: Trifacta Wrangler. Data quality management sounds as boring as it is important. The thing is that, for the last couple of decades, data quality management has been just that: boring.\n\nHave you ever tried to implement a data quality management solution using some of the platforms from traditional data incumbents such as Microsoft, Informatica, Oracle, etc? The experience is nothing short of nightmare. Hundreds of hardcoded data quality rules that are constantly falling out of sync with the data, an archaic user experience that requires constant training are some of the challenges you can look forward to if you decide to pursue that path.\n\nDue to some of those challenges, data quality management platforms has none been able to enjoy mainstream adoption in the enterprise. However, its relevance has only increased with the emergence of new trends such as big data and machine intelligence(MI). Currently, a new generation of startups is reimagining data quality management using new technologies such as machine learning(ML) and artificial intelligence(AI). Among those, Trifacta Wrangler stands up as one of the leaders in the space.\n\nTrifacta Wrangler is a new generation data quality management platform that enables data stewards to analyze, cleanse and transform datasets in order or power other data processes in the enterprise. Trifact Wrangler addresses some of the limitations of its predecessors by leveraging advanced machine learning and data visualization models that provide an engaging experience for data stewards.\n\nTrifacta Wrangler is a highly sophisticated technology stack bt its guided by two simple principles: Predictive Transformation and Visual Profiling.\n\nBased on a strong academic research, Predictive Transformation is a group of design and interface principles that guide the user\u2019s interaction with the data. Predictive Transformation combines domain knowledge of the data with an advanced transformation engine.\n\nMachine learning and advanced statistics are at the core of Trifacta Wrangler\u2019s Predictive Transformation processes. The stack includes sophisticated transfromation routines such as data cleansing (standardization, data removal, etc), statistical manipulation (outliers, profiling, etc), enrichment(data joins, lookups, etc), distillation( aggregation, sampling, filtering, etc. ), restructuring( data extraction, pivot/unpivot, etc) and several others.\n\ntrifacta Wrangler Visual Profiling are a series of techniques that provide real-time, highly interactive visualizations that can assist with the discovery and interpretation of datasets. Trifacta data visualizations highlight aspects such as statistical summaries or outlier patterns that can simplify the exploration of datasets.\n\nMachine learning is at the core of Trifacta Wrangler. The platform provides predictive models that suggest patterns and transformations to apply to specific datasets. Additionally, Trifacta Wrangler enables the preview of transformation before they are actually applied.\n\nTrifacta Wrangler is supported on both on-premise and cloud platforms. Notably, Trifacta has been able to establish robust strategic alliances with cloud platforms such as Google Cloud that can streamline the distribution of the platform.\n\nTrifacta certainly brings a new approach to the very difficult challenge of data quality management in the enterprise. Steadily, Trifacta is becoming a key elements of modern enterprise data pipelines."
    },
    {
        "url": "https://medium.com/@jrodthoughts/private-equity-and-the-post-ipo-life-of-enterprise-tech-companies-part-ii-ab173132def2?source=user_profile---------228----------------",
        "title": "Private Equity and the Post-IPO Life of Enterprise Tech Companies Part II",
        "text": "In the first part of this essay, we discussed how private equity( PE) firms are becoming more active acquiring public technology companies that have been underperforming in public markets. We started the essay analyzing the recent acquisition of Jive by PE firm DSQ and listed other relevant examples of companies such as Rackpsace, Qlik, Tibco, Marketo or Dell that have been recently taken private by PE firms.\n\nThe recent level of activity of PE firms on the public market is certainly interesting. Like we explained in the previous article, PE acquisitions have become like a life-line for troubled enterprise tech stocks. The fascinating thing is that most of the tech companies recently acquired by PE firms have been incredibly successful but almost any relevant metric. And yet their stocks have been underperforming in a crazy tech market.\n\ntechnology is the most dynamic and sometimes irrational of the public markets and enterprise tech companies can sometimes become a victim of this phenomenon. Investor sentiment about tech companies swings at an incredibly rapid pace. Today, you can be the hottest tech IPO of the year and in a few months investors will classify as legacy software and turn their attention onto a new tech growth area.\n\nIn order to understand why public market can rapidly neglect enterprise tech companies, there are a few factors that should be considered.\n\nPublic market investors make little distinction between enterprise and consumer tech companies and their metrics. Fro the most part, analysts use very similar metrics to evaluate the performance of consumer and business software stocks. Jeez, we even use common market indexes that groups consumer and enterprise tech under the same umbrella. as a result, the investor sentiment in enterprise tech companies can suffer when evaluated using metrics more appropriated to consumer tech stocks. Among those metrics, none is more important than growth.\n\nFor the most part, tech stocks are seeing as growth stories by investors and analysts. In a market were Facebook and Google are posting ridiculous growth numbers it becomes hard for investors to adjust that sentiment to the performance of enterprise tech companies. So yes, more often than not enterprise tech companies are suffering from inflated growth expectation based on misleading analysis.\n\nInvestor sentiment in enterprise tech is shifting rapidly from sector to sector. A couple of years ago, mobile and big data were the hottest trends in enterprise tech. Companies that IPO during that time such as MobielIron or Hortonworks have been struggling ever since as attention has shifted toward more exciting markets such as artificial intelligence, virtual reality or cyber-security. It is very likely that Cloudera\u2019s recent valuation was partially a result of investor not going crazy about big data ny longer. the result of this dynamic is that enterprise tech companies that operate on a single market can seen their stock punished as investor attention shift towards newer trends.\n\nThere is no more exciting story in the enterprise tech public markets that the performance of cloud platforms such as AWS, Azure or Google Cloud. The thing is that those incumbents PaaS stacks are trying to provide every single capability relevant to modern software applications ranging from data storage to artificial intelligence. Consequently, if you are a cloud platform service company \u2014 such as recently IPO Okta- you are on a collision course with Amazon, Google and Microsoft. Even if that statement is not entirely true technologically, it does reflects the perspective of many public market analysts and investors."
    },
    {
        "url": "https://medium.com/@jrodthoughts/private-equity-and-the-post-ipo-life-of-enterprise-tech-companies-part-i-bebde5cce077?source=user_profile---------229----------------",
        "title": "Private Equity and the Post-IPO Life of Enterprise Tech Companies Part I",
        "text": "In the middle of the frenzy of tech IPOs, some of the biggest names in the tech industry continue being acquired by private equity( PE) firms. Last week, Jive Software, one of the former leaders in the enterprise collaboration space, was acquired by PE firm ESW Capital for $462 million. Jive is expected to go private as part of the transaction.\n\nESW is planning to add Jive to its family of sales and marketing companies called Aurea. ESW has steadily put together an impressive portfolio of companies in the sales and marketing area and has grown a reputation among PE firms as an specialists in the space. The acquisition ends a troubling run for Jive in public markets.\n\nJive\u2019s acquisition is another example of a high profile enterprise tech company getting acquired by PE firms after a disappointing performance in the stock market. To some extend, PE firms have become the \u201clife after the IPO\u201d option for many enterprise tech companies.\n\nIn recent years, the number of high profile PE acquisition of publicly traded enterprise tech companies seems to have skyrocketed. Vista Equity partners is one of the most active PE firms in enterprise tech. Last year, Vista took marketing automation leader Marketo private for $1.79 billion. Visa also acquired IPO candidate Ping Identity for $600 million. Thomas Bravo, another PE firm, acquired data visualization vendor Qlik for $3 billion while Apollo Global tool Rackspace private for $4.3 billion. Tibco and Informatica are also household enterprise tech names to be taken private via PE vehicles.\n\nDell is a company that seems to have mastered the PE game. After going private, Dell received a massive cash infusion from PE powerhouse Silverlake Partners in order to acquired EMC in a super complicated transaction. More recently, Dell sold its Spanning cloud backup unit to PE-VC firm Insight Venture Partners. As you can see, PE firms have been willing to spend big sums to become a viable channel for troubled enterprise tech stocks.\n\nWhy is this Happening?\n\nThere is a common denominator in all the examples used in the previous section. All those companies have been incredibly successful in their respective enterprise tech markets but have struggled as public stocks and eventually lost market share to newer competitors.\n\nRackspace was a leader in the infrastructure as a service(IaaS) space but never developed effective platform as a service(PaaS) capabilities and struggled to keep market share against faster PaaS competitors such as Amazon, Microsoft, IBM or Google. Marketo is an incredibly success story but the stock recently stumbled un comparison with new offerings from Adobe and pressure from startups in the space. Qlik ie one of the pioneers of the self-service data visualization tools market but the stock regularly underperform competitors like Tableau and was under pressure as incumbents such as Microsoft or Google entered the space with very innovative solutions. Tibco is a long-time leader in the enterprise integration market but the stock has regularly disappointed and the company has lost market share to younger competitors such as MuleSoft and Talend. Jive itself was one of the pioneers of the enterprise collaboration market but the focus on that space seems to have shifted to new companies such as Slack, Atlassian, Microsoft or Facebook.\n\nHow to look at this phenomenon from the perspective of a public market investor? That will be the subject of a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-fragmentation-problem-in-the-deep-learning-space-14ccd4dca308?source=user_profile---------230----------------",
        "title": "The Fragmentation Problem in the Deep Learning Space",
        "text": "Deep learning technologies have been evolving at an incredibly rapid pace during the last couple of years. Part of that evolution has produced a large number of deep learning frameworks all with their own merits and decent levels of adoption. Despite the many benefits that those technologies are bringing to the deep learning space, they are also causing a level of fragmentation that can be harmful to the market in the long term.\n\nBy the standards of the software industry, deep learning is a very young discipline. And yet, the number of frameworks in the space seems to have exploded out of control. If we just focus on open source , deep learning frameworks we can count a very large number of relevant technologies such as TensorFlow, Torch, Theano, Caffe, Microsoft Cognitive Toolkit, DeepLearning4J, Chainer, MxNext, PaddlePaddle, Keras and many others. Each one of those frameworks has achieved enough credibility and market traction to make it a relevant option for customers. However, if you are a developer or company embarking in a deep learning initiative, the task of selecting a technology stack can result nothing short of a nightmare. Ahh yes, on purpose eI omitted the cloud deep learning platforms provided by incumbents such as Microsoft, Google or Amazon because I think that those will eventually converge to become runtimes for the open source deep learning frameworks. That\u2019s a discussion for another post ;)\n\nWhat is the Real Problem?\n\nIn principle, there is nothing wrong with the proliferation of so many open source deep learning frameworks. Quite the opposite, the innovation created by those stacks is helping to push the deep learning space forward. While the benefits are certainly unquestionable, the increasing fragmentation of the deep learning technology landscape is also concerning.\n\nFor starters, deep learning frameworks are emerging and evolving a multiple faster than their corresponding runtime environments. As a result, the vast majority of deep learning stacks today lack key features such as training, management and optimization tools as well as robust runtime environments to execute deep learning models. Secondly, I feel that more time is devoted to create new deep learning frameworks that look just like the existing ones instead of rapidly advancing the capabilities of a smaller number of the lead deep learning stacks.\n\nA Necessary Step to Live in a Fragmented Deep Learning Ecosystem\n\nWe are still in the very early stages of the deep learning revolution and the industry needs to find its own path forward. However, in all the permutations of the future of deep learning technologies I can think of, there are a few common denominators.\n\nWe need to rapidly advance the capabilities of runtime stacks and tools that can interoperate with several of the lead deep learning frameworks in the market. Specifically, I am referring to runtime environments that can execute and scale programs written in frameworks such as TensorFlow, Theano, Torch and others. Similarly, the ecosystem desperately needs better tools for training, optimizing and monitoring deep learning models authored on those frameworks. Better runtime and tooling that can work across different deep learning stacks is a key step for the evolution of the space. If we use an analogy from another highly fragmented space (programming languages) we need to build the \u201cAtlassian of the Deep Learning market\u201d."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-m-a-targets-for-the-cloud-incumbents-889bce55b18?source=user_profile---------231----------------",
        "title": "Some M&A Targets for the Cloud Incumbents \u2013 Jesus Rodriguez \u2013",
        "text": "We are at the tail end of earnings season and the cloud has again played a pivotal role. Cloud platforms are a relevant line item in the reports of incumbents such as Amazon, Microsoft, Alphabet, IBM, Salesforce, Oracle, Alibaba and others. With these incumbents fighting hard for cloud dominance, any little differentiation counts. As a result, the climate for M&A has never been more favorable in the cloud space.\n\nThe recent performance in public markets has given companies like Amazon, Alphabet and Microsoft a massive war chest for M&A. Recent examples such as Google; acquisition of Apigee showed that the cloud incumbents are not afraid of spending big sums in order to accelerate their capabilities.\n\nAnother aspect to consider when evaluating the M&A climate for cloud companies is the fact that PaaS incumbents are trying to match each other feature by feature. In that dynamic, every time a PaaS vendor releases a new capability, its top competitors rush to match that feature. Strong M&A can definitely help PaaS leaders to both bridge the gap with competitors in some areas as well as to create a high bar for differentiation in others. Fro example, when Google acquired API market leader Apigee, it didn\u2019t only provide an answer to competitive offerings such as Azure API Gateway or AWS Api Gateway but it also made it really difficult for those competitors to match Apigee\u2019s advanced feature set.\n\nFactoring in that the cloud leaders have rich cash reserves at their disposal and that large acquisitions are becoming more common in the cloud space, let\u2019s speculate about some aggressive potential M&A targets for PaaS incumbents.\n\nThe are not many weaknesses in the AWS platform but I selected three areas of potential M&A focus: integration, infrastructure and citizen developer tools. Integration is an area on which AWS has no answer to technologies such as Azure Logic Apps. Zapier could be a target that fits nicely AWS\u2019 dev friendly mantra. In the self-service citizen developer tools space, AWS is trailing both Microsoft and Google\u2019s offerings. IFTT could be an interesting choice in this area. Finally, if AWS wants to expand its leadership in the cloud infrastructure space, why not to acquire Docker? ;)\n\nIn terms of capabilities, Azure might be the most complete cloud platform in the market. For the M&A perspective. I like areas such as machine learning and data quality management. Until now, Azure has done a remarkable job building its machine learning and artificial intelligence capabilities and now its time to keep accelerating. I think companies such as Algorithmia could be an interesting addition to the stack. Data quality management is an absent member of the Azure cloud. Trifacta, Tamr, or Paxata could be interesting targets in this area.\n\nAggressive M&A seems to be one of Google Cloud\u2019s core strategies in order to close the gap with AWS and Azure. Identity management and IOT top my list of Google Cloud areas of focus for M&A. Google Cloud\u2019s identity management suite is relatively limited compared to AWS\u2019s and Azure\u2019s. In this domain, I like recent-IPO Okta or Ping Identity as M&A targets. In the IOT space, Google Cloud has no capabilities that can compete with Azure and AWS IOT stacks. Xively seems to have the right combination of developer friendliness and scalability that Google likes. Zapier is also an interesting choice to bring much-needed integration capabilities to Google Cloud."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-the-recent-cloud-earnings-babe78de57bb?source=user_profile---------232----------------",
        "title": "Some Thoughts About the Recent Cloud Earnings \u2013 Jesus Rodriguez \u2013",
        "text": "Last week was earnings week fro most of the cloud leaders and the reports brought more of the same and some interesting surprises. The biggest highlights of the earning season were the continuous dominance of AWS as well as the fast pace of growth of Azure and Google Cloud. Beyond the numbers, and the speculation of Wall Street analysts , there are some interesting things we can learn reading between the lines in the earning announcements.\n\nAWS reported revenues of $3.66 billion and $890 million operating income. Those numbers represent a 42.6% growth year-over-year and an astonishing 89% of Amazon\u2019s total operating income. Both numbers are pretty impressive.\n\nIf we consider that AWS currently owns over 60% of the market and it is forecasted to be a $14 billion business this year, we can appreciate how remarkable a 42.6% growth rate is. Most software businesses of that size facing formidable competitors such as Microsoft or Google would be lucky to post a 25\u201330% growth. AWS continues dominance is making it hard for the competition to capture meaningful market share in new areas of the cloud market.\n\nIndia (not China) is a vital element of AWS\u2019 growth strategy and one that is likely to face tough competition. During the recent earnings call, Amazon highlighted India as one of the factors that is likely to drive a lot of new growth for AWS in the near future. Differently from China in which Alibaba Cloud dominates the cloud market. India doesn\u2019t have a local incumbent. Additionally, the large community of AWS system integrators based in India can streamline and influence the adoption of AWS.\n\nAzure Growth Rate is Impressive but the Questions About the Numbers Remain\n\nMicrosoft announced that Azure revenue grew an impressive 93% year-over-year. The Redmon giant doesn\u2019t disclose Azure specific revenue numbers and it reports it as part of its Intelligent Cloud that also includes products such as Office365, Dynamics 365 and Windows Server. The Intelligence Cloud suite reported revenues of $6.76 billion which represent an 11% year-over-year growth.\n\nAzure\u2019s growth is certainly impressive in such as competitive space but I also believe some sectors of the market might have overreacted to the numbers. Without getting into a lot of speculation, if we factor in the fact that Office365's revenue is a multiple larger than Azure\u2019s and use some of the Office365 revenue numbers forecasted by analysts in the past, we might arrive to some numbers for Azure that are still drastically smaller compared to AWS.\n\nAzure\u2019s remarkable growth is catalyzed by two X factors: the best hybrid-cloud story in the market and the growth of Office365. Both factors are indirect drivers of Azure licenses in areas on which AWS doesn\u2019t have a strong story.\n\nGoogle posted quarterly revenues of $3 billion for its \u201cOther\u201d category which includes Google Cloud, G-Suite, Pixel phones and other non-ad businesses. The head of Google Cloud Diane Green bullishly predicted that their platform will surpass AWS by 2022. Considering AWS market share and growth rate, Google Cloud quarterly revenue must be close to $1.5 billion for that prediction to be take seriously."
    },
    {
        "url": "https://medium.com/@jrodthoughts/mulesoft-ipo-and-the-end-of-the-traditional-enterprise-integration-market-45025c3a5e9?source=user_profile---------233----------------",
        "title": "MuleSoft IPO and the end of the Traditional Enterprise Integration Market",
        "text": "MuleSoft has been leading the 2017 IPO renaissance posting very impressive and steady stock performances. The integration platform vendor has been able to drive investor excitement to new areas such as APIs, iPaaS or mobile integration. MuleSoft\u2019s performance in public markets is certainly a breath of fresh air of the enterprise software space that had seen how previous IPOs like Apigee or Hortonworks have been challenged matching investor expectations.\n\nIn addition to its encouraging stock debut, Mulesoft\u2019s IPO (just like Talend\u2019s a few months before) has some profound implications of the enterprise integration market. In my opinion, we should MuleSoft\u2019s and Talend\u2019s IPOs as the milestone that signaled the end of traditional enterprise integration.\n\nThe debut in public markets of modern integration vendors such as MuleSoft and Talend has been, somewhat ironically, accompanied by the return to private markets of traditional enterprise integration companies like Tibco or Informatica. Even though those companies are still highly competitive in the integration space, they had to be rescued by private equity firms due to a disappointing performance in public markets. Other kings of the integration space such as IBM, Oracle and Microsoft don\u2019t even report integration as a relevant line item in their earning reports.\n\nThe public market perspective is very relevant to illustrate the power shift in the enterprise integration space. Companies such as Tibco or Informatica went private following slow quarterly reports that showed how the integration incumbents were struggling to grow their businesses in predictable ways. At the same time, we have a new generation of integration vendors such as MuleSoft or Talent( or WSO2 and SnapLogic) that believe their performance is strong enough to wave the pressure of public markets. Let\u2019s face it, companies like MuleSoft and Talend are the new standard for enterprise integration.\n\nThe fascinating thing about MuleSoft and Talend is that they didn\u2019t start as modem integration platforms focused on cloud, mobile, IOT and APIs. Just a few years ago, both companies were considered second tier players compared to the traditional enterprise integration platforms. The emergence of the cloud and API movements as well as raise of mobile gave MuleSoft and Talend the opportunity to level the playfield and continue out innovating the incumbents. The result of this process was materialized in their recent public offerings.\n\nWhat Could Create the Next MuleSoft\n\nA couple of years ago, I was having a conversation with the CEO of a publicly traded software company when he brought up the argument that the integration market could use a new type of platform because \u201ceven MuleSoft wasn\u2019t flexible enough to rapidly adapt to the new tech trends\u201d. At the time, I thought the argument was a bit of a stretch but now I can see the logic of it. Just like the cloud push MuleSoft passed its competitors, there are new trends that have the potential to create the next MuleSoft of the integration space. Here some of my favorite trends:\n\n\u2014 Serverless Computing: I believe serverless computing can be the foundation of the next generation of integration platforms.\n\n\u2014 IOT: Its still hard to tell but IOT integration platforms could become a relevant standalone category in the integration market.\n\n\u2014 Natural Language Integration: I believe bots and digital assistants will drive the emergence eof new integration platforms based on natural language.\n\n\u2014 Dev-First Integration Platforms: I have a soft sport for integration platforms designed for developers (vs. system integrators). This category could see a tremendous amount of growth in the near future."
    },
    {
        "url": "https://medium.com/@jrodthoughts/dubai-and-the-blockchain-fever-23bea0f859e9?source=user_profile---------234----------------",
        "title": "Dubai and the Blockchain fever \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, The Wall Street Journal(WSJ) published an article detailing Dubai\u2019s ambitions to transform most of its business infrastructure to digital interfaces powered by the blockchain. The article detailed the efforts of Dubai\u2019s public and private sectors to leverage blockchain technologies as the core backbone of its new digital services.\n\nIn recent years, I\u2019ve had the opportunity to travel several times to Dubai and interact with enterprises, startups and government officials in the city. The topic of blockchain technologies has been in the minds of Dubai\u2019s technologists for quite some time and they certainly believe that the city processes the right balance of advanced infrastructure and government backing to become an important blockchain hub.\n\nDubai\u2019s efforts about blockchain technologies are bringing together public and private sectors. A couple of months ago, the Smart Dubai initiative kicked off an effort to leverage the blockchain across several sectors in the city. the goal of the citywide effort is to streamline business processes and increase transparency and accountability of new digital initiatives. It definitely should ambitious but some of the initial steps are encouraging.\n\nDubai\u2019s Department of Economic Development( DED) is a government entity that plays a pivotal role for any foreign company trying to conduct business in Dubai and UAE. DED\u2019s role includes different aspects ranging from issuing new commercial license to promoting trade initiatives. DED has already started an effort to move its entire licensing and registration services to the blockchain. Considering DED\u2019s large footprint on Dubai\u2019s business ecosystem, it is likely that its efforts will influence some of its many business partners to leverage blockchain technologies.\n\nEmirates NBD is Dubai\u2019s largest bank and another early adopter of blockchain technologies. The financial powerhouse is planning to leverage blockchain technologies to streamline trade and finance logistics. NBD\u2019s goal is to implement new blockchain smart contracts to simplify the documentation of the tracking, shipping and movement of goods. Considering Dubai\u2019s trading volume, NBD\u2019s efforts are nothing but ambitious.\n\nDubai\u2019s initial efforts about blockchain technologies are certainly impressive but they still, individually, look similar to other blockchain initiatives from large institutions in America and Europe. In order to expand beyond isolated initiatives and onto a true smart city infrastructure powered by the blockchain there is a lot of work to be done. I\u2019ve summarized a few ideas I think could result interesting in that context:\n\n1 \u2014 Smart City BaaS: As a result of its efforts, Dubai is likely to see the implementation of a lot of different blockchain solutions using different technologies. Providing a common city-wide blockchain as a service( BaaS) platform for government agencies and partners could be a way to streamline the implementation and management of the different blockchain initiatives.\n\n2 \u2014 Investing and Adapting Blockchain Startups: Dubai\u2019s blockchain ambitions reminds me In-Q-Tel\u2019s role in the US discovering and investing in promising enterprise software startups and adapting their technologies to the requirements of the US Intelligence Community. Dubai could establish a similar group that combine venture capitalists and technologists to identify innovative blockchain startups, bring them to Dubai using an investment vehicle and collaborate with them to reengineer their technologies to address the city\u2019s specific requirements.\n\n3 \u2014 Build Your Own Blockchain Technologies: Blockchain platforms are a very nascent ecosystem that is unlikely to address all the requirements of complex scenarios such as the ones provided by the Dubai\u2019s Smart City initiative. As a result, I believe Dubai technologist are going to see a lot of opportunities to extend the capabilities of platforms such as Hyperledger or Ethereum. Those contributions might expand beyond successful contributions to blockchain stacks and become standalone products that powered similar initiatives in the blockchain ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-fridays-howdy-botkit-brings-a-unique-flavor-to-bot-platforms-663e2dc5bcca?source=user_profile---------235----------------",
        "title": "Technology Fridays: Howdy Botkit Brings a Unique Flavor to Bot Platforms",
        "text": "This is the second post on my technology Friday session focused on presenting some analysis of hot and up and coming technologies. recently, I published an analysis about Microsoft\u2019s Azure Bot Service and its unique capabilities in the bot ecosystem. Today, I would like to apply a similar analysis to one of Azure Bot Service\u2019s strongest and most innovative competitors: Howdy Botkit.\n\nThe Botkit platform evolved from Howdy\u2019s experience in bot development scenarios. From that experience, the Botkit team has been able to extrapolate a series of capabilities that are foundational in the implementation of bot scenarios. The result is one of the most complete and yet simple and extensible bot platforms in the market.\n\nBotkit includes components that are essential to real world bot solutions including some of the following capabilities:\n\n\u2014 Botkit Studio: An integrated development environment for the design and implementation of bots.\n\n\u2014 Conversation APIs: Botkit conversation framework provides a flexible programming model for the implementation of user-bot conversations.\n\n\u2014 Capture Middleware: Botkit Capture Middleware brokers the communication between users and bots. The middleware intercepts and transforms messages and can execute logic blocks powered by services such as IBM Watson or Microsoft LUIS.\n\n\u2014 Botkit Studio Starter Kit: A toolkit that includes samples and guidance to get developers started on the implementation of bots.\n\nIn addition to the aforementioned capabilities, Botkit provides a sophisticated management and analytic experiences for bots developed on the platforms.\n\nBots implemented using Botkit can run on heterogeneous messaging platforms such as Facebook Messenger, Twilio IP Messaging, Slack and several others. Similarly to Azure Bot Service, Botkit integrates with Microsoft Bot Framework which offers developers a confusing but certainly flexible portfolio of choices fo implementing multi-platform bots.\n\nDespite its sophisticated feature set, Botkit faces formidable competition from incumbents in the market. On one side, messaging runtime vendors such as Facebook, WeChat, Microsoft or Slack provide advanced bot platforms that are incredibly optimized for their messaging runtimes. On the other side, cloud platform providers such as Azure, Google Cloud or AWS have developed competitive bot platforms that come with the full backing of their cloud platforms.\n\n5 Capabilities that should be in Botkit\u2019s Roadmap\n\nLooking at the current Botkit platform, I\u2019ve put together a list of capabilities that should be on its short term roadmap. Here are my top five:\n\n\u2014 Botkit Studio vNext: For Botkit to win in the market, Botkit Studio must become the number one bot development environment in the space.\n\n\u2014 Analytics: I would like to see a robust bot analytic platform included in Botkit.\n\n\u2014 Capture Middleware Connectors: Extending Botkit Middleware with connectors to SaaS business systems will offer developers and enterprises a framework for building highly advanced bot solutions.\n\n\u2014 Bot ALM Tools: Botkit should provide new tools that streamline the lifecycle of bot solutions including starting such as testing, deployment, continuous integration, etc.\n\n\u2014 Security: A more complete set of services to enable security capabilities such as access control, identity federation would certainly be a welcomed addition to Botkit."
    },
    {
        "url": "https://medium.com/@jrodthoughts/can-natural-language-processing-bring-back-the-excitement-to-domain-specific-languages-b38e7015c74a?source=user_profile---------236----------------",
        "title": "Can Natural Language Processing Bring Back the Excitement to Domain Specific Languages?",
        "text": "Domain specific languages(DSL) have been one of the most over-hyped and under-delivered tech trends in the last few years. While DSLs hve lost a lot of relevance as a general-purpose technology trend, they might be able to catch a second wave drive by the evolution of artificial intelligence(AI) and natural language processing(NLP).\n\nA few years ago, DSLs were called to become one of the most important technology trends of the next decade. Dozens of books and even conferences were created to preach the gospel of DSLs. Similarly, developers leveraged the syntactic extensibility of dynamic language such as Ruby or Python to create numerous DSL frameworks that became somewhat popular. However, after a few years, DSLs seem to have lost their initial momentum.\n\nWhat Caused the Decline of DSLs?\n\nLet me clear, I believe DSLs remain a super-important concept in model software development. However, the technological manifestation of DSLs is what I believe has lost its initial appeal. There are several factors that have contributed to the decline of DSL technologies:\n\n\u2014 DSLs are for Geeks: Not exactly but that was the position adopted by main mainstream information workers. Intuitively, people associate programming languages with difficult tasks reserved for geeks with deep analytical skills. As a result, many people rejected the idea of embracing DSLs for their daily work.\n\n\u2014 Poorly Designed Languages: Designing languages is hard and typically requires a deep computer science foundation. The rush around DSLs caused the creation of many poorly-designed DSLs that ran into a lot of challenges when applied in the real world.\n\n\u2014 DSL Designers Were Not Users: Most DSLs in the market were designed by programming language experts which were not using their creation on a daily basics. This approach contrasts with, for instance, general purpose programming languages on which designers age their own users. That level of friction between designers and users ended up producing many DSLs that were disconnected from its practical applications.\n\nNatural language, is, in many ways, a more effective and more natural vehicle to create DSLs. The evolution of AI and NLP can bring a new phase of DSL technologies that addresses many of the limitation of the previous generation. The are several benefits of leveraging NLP as the foundation of DSLs:\n\n\u2014 Intuitive Rules: Most DSLs are not more than sophisticated sets of logic rules. That type of rule-sets can be seamlessly modeled using NLP constructs .\n\n\u2014 Voice and Text Interfaces: NLP can enable the creation of DSLs using both voice and text which can improve the mainstream adoption of the language.\n\n\u2014 Syntax-Agnostic Extensibility: NLP-powered DSLs are naturally extensible without requiring new syntactical elements. For instance, adding a new verb or phrase to a DSL does not require to modify the language or to retrain users.\n\n\u2014 Tooling: NLP platforms such as Wit.ai, LUIS or Api.ai provide highly sophisticated toolsets that can be used to streamline the authoring and maintenance of DSLs.\n\n\u2014 Rich Grammars: NLP-designed DSLs can leverage grammars that are drastically more and intuitive than traditional DSLs."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ai-and-data-together-microsoft-wants-to-make-sql-server-its-runtime-for-machine-intelligence-72eeafae50a?source=user_profile---------237----------------",
        "title": "AI and Data Together: Microsoft Wants to Make SQL Server its Runtime for Machine Intelligence",
        "text": "Data and machine intelligence(MI) are growing closer together. For decades, database platforms have abstracted the fundamental operations on data in the from of queries or CRUD operations as well as some basic computation routines. However, that\u2019s quickly changing with the evolution of machine learning(ML) and artificial intelligence( or machine intelligence as the cool kids call it ;) ). Recently, Microsoft has made it really clear that they want to bring the world of databases and MI closer together.\n\nLast week, Microsoft announced the community technical preview(CTP) of SQL Server 2017 which takes important steps to bring new MI capabilities to the traditional database platform. Specifically, Microsoft announced that SQL Server 2017 will be able to execute Python scripts natively which opens the door to leverage Python\u2019s rich ecosystem of MI libraries directly on the SQL Server runtime. This effort complements last year\u2019s release of R Services as part of SQL Server 2016.\n\nSupporting Python, R, SQL and C# on the same database runtime certainly enables the creation of highly sophisticated MI applications. More and more we are going to see MI algorithms becoming as common as data access operations in database servers. Microsoft is in a unique position to lead this new trend but we should expect similar moves by competitors such as Oracle, IBM or newcomers such as MongoDB or Couchbase.\n\nWhere Does SQL Server 2017 Fits in Microsoft\u2019s MI Strategy?\n\nMicrosoft has, arguably, built the most complete MI technology suite in the market. The list of Microsoft\u2019s MI technologies includes advanced platforms such as Azure ML or R Server, AI APIs such as Microsoft Cognitive Services, data visualization tools such as PowerBI or even vertical solutions included in the Cortana Intelligence Suite. In that diverse ecosystem, we can only question the role of SQL Server MI capabilities.\n\nAdding Python and R support for SQL Server will allow developers to implement MI models that natively process data stored in SQL Server databases. Those MI models can be directly persisted in the underlying database servers and scaled as part of SQL Server clusters. Mor importantly, developers will have access to these capabilities using the familiar SQL Server toolset.\n\nThe runtimes for R and Python are initial steps to make SQL Server a viable MI platform. However, there are other ideas that Microsoft should consider in this area.\n\n1 \u2014 MCT Support: SQL Server can become the ideal runtime for Microsoft Cognitive Toolkit(MCT) programs. Supporting Python is definitely a step in the right direction as MCT\u2019s programs natively supports the popular programming language.\n\n2 \u2014 Support for Open Source Deep Learning Frameworks: If we want to get really ambitious, we can foresee SQL Server adding support for deep learning frameworks such as TensorFlow, Torch, Chainer, Theano, etc.\n\n3 \u2014 MI Management Tools: Providing a sophisticated toolset for managing, training and monitoring MI models can be a winning strategy for SQL Server.\n\n4 \u2014 Self-Service MI Tools: SQL Server should consider providing a native runtime for popular self-service MI and data exploration tools such as Jupyter or Zepellin.\n\n5 \u2014 MI Models as First-Class Citizens: MI models should become a first class component of SQL Server and its support should be at the same level of traditional database constructs such as tables, stored procedures, etc."
    },
    {
        "url": "https://medium.com/@jrodthoughts/understanding-the-blockchain-app-platform-space-challenges-and-a-market-taxonomy-4fffdf40e07b?source=user_profile---------238----------------",
        "title": "Understanding the Blockchain App Platform Space: Challenges and a Market Taxonomy",
        "text": "Blockchain application are an area of research and prototype across many major industries. Similarly, the ecosystem of blockchain application platforms and tools has been growing steadily. With that growth, the market has created several clearly defined groups of technologies that abstract tithe fundamental capabilities of modern blockchain applications. However, there is still disconnect between the potential of the technology and its practical adoption.\n\nLets\u2019 face it, blockchain applications are a super exciting trend but their adoption remains relatively slow. In fact, blockchain technologies has been growing at a slower pace than many other hot technology trends in the enterprise. There is nothing necessarily wrong with that as different technology markets evolves at different paces but it is a fact that we should acknowledge in order to understand the blockchain app platform market.\n\nThere are different factors that have been conspiring to cause the slow adoption of blockchain application platforms. The following list includes some of my favorites:\n\n1 \u2014 Challenges for Mainstream Developers: Blockchain platforms such as Ethereum or Hyperledger remain difficult and non-intuitive for mainstream developers. Some of the concepts in these platforms such as smart-contracts or decentralized autonomous organizations have no equivalent in traditional application development platforms an, consequently, require a larger than usual learning curve for developers.\n\n2 \u2014 Complexity of Private Blockchain Infrastructures: Private blockchain infrastructure are notoriously difficult to setup, scale and maintain which results in a challenge for most organizations.\n\n3 \u2014 Uncertainty About Public Blockchains: Recent security flaws in public blockchains such as Bitcoin or Ethereum continue to add uncertainly to organization looking to build on those infrastructures.\n\n4 \u2014 Talent Availability: Hiring and acquiring blockchain talent remains a challenge for many companies.\n\n5 \u2014 Lack of High Level Application Development Platforms: The ecosystem of high level blockchain application development tools and frameworks remains relatively small compared to other mainstream technologies.\n\nDespite the aforementioned challenges, the blockchain application platform ecosystem has been steadily evolving. There are different groups of technologies that have become relevant in that market. The following list might help you to better understand the different moving forces in the blockchain app platform space:\n\n1 \u2014 Tier-1 Blockchain Platforms: This category includes platforms such as Ethereum, Hyper ledger or Chain that provide the fundamental building blocks of blockchain applications.\n\n2 \u2014 Tier-2 Blockchain Platforms: This group includes platforms that abstract the implementation of web or mobile apps using Tier-1 blockchain platforms as the underlying infrastructure. ErisTech is a great example of a Tier-2 blockchain platform.\n\n3 \u2014 BaaS: Blockchain as a service(BaaS) are groups of native cloud services that enable the creation, scaling and management of blockchain applications (typically Tier-1). Azure BaaS and Bluemix-Hyper ledger are well-known examples of BaaS stacks.\n\n4 \u2014 Blockchain PaaS: Blockchain platform as a service(PaaS) technologies enable cloud services ranging from databases to web application hosting powered by the blockchain. Blockstack and Nxt are lead examples of this type of technology.\n\n5 \u2014 Blockchain Management & Monitoring Tools: I believe there is an underdeveloped segment of the market and one with a lot of potential. Tools and platforms that manage the lifecycle of blockchain applications including aspects such as application testing, management, deployment, monitoring could become a very relevant category in the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-weak-vs-strong-ai-part-iii-ai-consciousness-fb527656fca9?source=user_profile---------239----------------",
        "title": "About Weak vs. Strong AI Part III: AI Consciousness",
        "text": "This is the third part of an essay that explores the arguments between weak and strong artificial intelligence(AI) models. The first part outlined differences between weak AI models that simulate thinking and strong AI agents that attempt to actually think. The second part presented a framework to evaluate consciousness across species and introduced an argument about the potential of AI consciousness. Today, I would like to dig deeper into the concept of AI consciousness.\n\nConsciousness is one of the most passionate subjects of debate in the AI community. By AI consciousness, we are referring to the ability of an AI agent to be self-aware of its \u201cmental state\u201d. The previous part of this essay introduced a framework pioneered by known physicist Dr. Michio Kaku to evaluate consciousness in four different levels.\n\nIn Dr. Kaku\u2019s theory, Level 0 consciousness describes organisms such as plants that evaluate their reality based on a handful of parameters such as temperature. Reptiles and insects exhibit Level 1 consciousness as they create models of the world using new parameters including space. Level 2 consciousness involves creating models of the world based on emotions and the relationship to other species. Mammals are the main group associated with Level 2 consciousness. Finally, we have humans that can be classified at Level 3 consciousness based on models of the world that involve simulations of the future ( read part II of this article).\n\nBased on Dr\u2019 Kaku\u2019s consciousness framework we can evaluate the level of consciousness of the current generation of AI technologies. Most experts agree that AI agents today can be classified at Level 1 or very early Level 2 consciousness. Ranking AI agents at Level 1 involves many factors including mobility. Many AI agents today have been able to achieve mobility and develop models of their environment based on the space around them. However, most AI agents have a lot of difficulty operating outside their constrained environment.\n\nSpace evaluation is not the only factor placing AI agents at Level I consciousness. The number of feedback loops used to create models is another super important factor to consider. Let\u2019s use image analysis as an example. Even the most advanced vision AI algorithms use a relatively number of small number of feedback loops to recognize objects. If we compare those models with the cognitive abilities and insects and reptiles they seem rather unsophisticated. So yes, the current generation of AI technologies has the level of consciousness of an insect ;)\n\nSteadily, some AI technologies have been exhibiting characteristics of Level 2 consciousness. There are several factors contributing to that evolution. AI technologies are getting more advanced understanding and simulating emotions as well as perceiving emotional reactions around them.\n\nIn addition to the volution of emotion-based AI techniques, AI agents are getting more efficient operating in group environments on which they need to collaborate or compete among each other in order to survive. In some cases, the group collaboration has even resulted on the creation of new cognitive skills. To see some recent examples of AI agents that have exhibited Level 2 consciousness we can refer to the work of companies such as DeepMind and OpenAI.\n\nRecently, DeepMind conducted experiments on which AI agents needed to live in an environment with limited resources. The AI agents showed different behaviors when resources were abundant than when they were scarce. The behavior changed as the agents needed to interact with each other. Another interesting example can be found on a recent OpenAI simulation experiment on which AI agents were able to create their own language using a small number of symbols in order to better coexist in their environment. Pretty cool huh?\n\nThere are still very early days of mainstream AI solutions but enhancing the level of consciousness of AI agents is one of the most important goals of the current generation of AI technology stacks. Level 2 consciousness is the next frontier!"
    },
    {
        "url": "https://medium.com/@jrodthoughts/technology-friday-the-case-for-a-netflix-oss-enterprise-distribution-e45fe6539155?source=user_profile---------240----------------",
        "title": "Technology Friday: The Case for a Netflix OSS Enterprise Distribution",
        "text": "I decided to test a new idea with this blog: Every Friday, I will focus on providing an analysis of a specific product or technology and present some ideas about its market. The goal is not to provide a product review but to get a bit more specific about interesting technologies and present some thesis about their immediate future. Today, I would like to start by making a case for an enterprise distribution of the Netflix OSS project.\n\nNetflix OSS has become of the most popular open source projects in the market. Started as a series of isolated open source contributions by Netflix\u2019s engineering team, Netflix OSS has evolved into an indispensable asset for organizations building large-scale could solutions. Despite its popularity, Netflix OSS is lacking the proper channels for its mainstream adoption in the enterprise. That situation creates a strong market opportunity to create an enteprise distribution of Netflix OSS.\n\nThe software industry has a long history of delivering enterprise distributions of successful and popular open source projects. From RedHat to recent examples such as Cloudera or Docker, companies have been regularly able to capitalize on the demand for popular open source projects in the enterprise. More importantly, the emergence of cloud platforms have opened new channels for monetizing open source projects. Netflix OSS is not a single project but a suite of really popular tools and frameworks in areas such as microservices, big data, continuous delivery, security, user interface, data persistence and several others. Consequently, the market opportunity for an enterprise distribution of Netflix OSS seem tremendous. Let\u2019s explore this idea a bit further by digging into the specific business opportunities that can be capitalized by a Netflix OSS distribution.\n\nObviously, offering commercial support for Netflix OSS is a classic opportunity to monetize the platform. The large variety of Netflix OSS tools and frameworks makes it a nightmare for organizations to operate the project at scale. Support services will certainly be welcomed by enterprise evaluating Netflix OSS as part of their cloud initiatives.\n\nComplementing the previous point, I believe there is a market for system integrators and agencies implementing Netflix OSS technologies in the enterprise. Netflix OSS technologies such as Spinnaker (continuous delivery), Hystrix or Atlas are particularly well suited for this model.\n\nNetflix OSS technologies work spectacularly well on AWS but its support for other cloud platforms such as Google Cloud or Azure is very limited. Expanding Netflix OSS onto those cloud platforms should create new market opportunities for startups in the space. The same thesis applies for container platforms such as Kubernetes or CoreOS.\n\nMicroservices is an area of which Netflix OSS excels. Many experts trace the origins of microservices architectures to Netflix itself. Netflix OSS includes frameworks such as Falcor, Hystrix or Eureka which are common citizens of microservices solutions. Combining those technologies into a cohesive and interoperable suite to enable the implementation of microservices can result on an interesting opportunity for new companies.\n\nIn the current market, there are several candidate that are well positioned to deliver an enterprise distribution of the Netflix OSS project:\n\n\u2014 Startups: We can always count on startups to deliver innovative solutions around this new idea.\n\n\u2014 Pivotal: Cloudfoundry and Spring Cloud have been about the most popular adopters of Netflix OSS technologies. Pivotal can easily expand its support of Netflix OSS will a full enterprise distribution.\n\n\u2014 Amazon: AWS is on an enviable position to enable Netflix OSS technologies as native services in its platform.\n\n\u2014 System Integrators: Professional services firms are other strong candidates to provide commercial offerings for Netflix OSS based on its work with large enterprises.\n\n\u2014 RedHat: Redhat\u2019s expertise and success commercializing open source technologies as well the limitations of its current cloud offerings, makes it an interesting candidate to create an enterprise distribution of Netflix OSS."
    },
    {
        "url": "https://medium.com/@jrodthoughts/memory-in-artificial-intelligence-part-i-taking-inspiration-from-the-human-brain-45449c15b8dc?source=user_profile---------241----------------",
        "title": "Memory in Artificial Intelligence Part I: Taking Inspiration from the Human Brain",
        "text": "Memory is one of the most prominent elements of human cognition and one that is becoming increasingly important for artificial intelligence(AI) systems. As AI agents evolve and tackle more complex scenarios, the role of memory should become more relevant. Currently, memory models are one of the most notably missing components of AI platforms and frameworks.\n\nIn the past, I\u2019ve written about the role of memory in AI solutions. However, the more I think about this, the more I realize that architecting efficient memory systems for AI agents is ridiculously complicated. Maybe the best way to get an idea of this complexity is to draw inspiration for the human brain.\n\nThe creation of memories in the human brain involves very complex cognitive processes. When receiving sensory information from cognitive channels such as vision, touch, language, taste, etc the brain stem routes the information to the thalamus which decomposes it and sends it to different labels of the brain for evaluation. The result of that evaluation is what we know as SHORT-TERM-MEMORIES which are form in our consciousness and last for short periods of up to a few minutes.\n\nHere is where things get more complex. In order to capture memories for a longer duration, the information has to flow through the hippocampus where is partitioned and sent to various cortices of the brain. This means that LONG-TERM-MEMORIES are not stored as sequences but decomposed as individual fragments and scattered throughout the brain. For instance, emotional memories are typically stored in the amygdale while words are captured in the temporal lobe. Mysteriously, the brain is able to maintain the association between all these fragments and the entire memory can be reconstructed instantly based on related cognitive experiences. Let\u2019s take, for instance, the memory of going to a concert. The brain will decompose that memory into thousands of categories such as music, colors or emotions and store them across different sections of the brain. Time after, a single cognitive experience related to that memory -such as listening to a melody from the same band- can make the brain reconstruct the entire memory of the concert. How exactly does this process takes place is largely a mystery known in neuroscience as the \u201cbinding problem\u201d.\n\nThe Most Fascinating Thing About Human Memory\n\nWe typically associate memories with the past but, in fact, they are typically recalled when we are thinking about the future. This is, in my opinion, the most fascinating aspect of human memory. A famous neuroscientist once said \u201cthe purpose of memory is to predict the future\u201d. I know it sounds counter-intuitive at first but it makes perfect sense. Cognitive research has shown that the areas of the brain used to store long term memories are actively stimulated when we are immersed in future-related activities such as planning a trip or making a strategic business decision.\n\nHow Does This Relates to AI?\n\nI hope the previous examples gave you an idea of the complexities of the human cognitive processes related to the formation and retrieval of memories. To be efficient, AI agents will need to leverage hierarchical, federated rapid storage systems that can be used to \u201ccreate memories\u201d from the cognitive data source such as vision, voice, language, etc. What should be the capabilities of AI-memory systems? We will speculate about that in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-clouderas-ipo-price-205a8e8e280d?source=user_profile---------242----------------",
        "title": "Some Thoughts About Cloudera\u2019s IPO Price \u2013 Jesus Rodriguez \u2013",
        "text": "Cloudera is projected to be one of the most exciting tech IPOs of 2017 but some recent news yesterday started raising concerns about potential investors. Yesterday, Cloudera announced an initial price estimate for its IPO and the PPS(price per share) turned out to be less than half of recent financing rounds.\n\nCloudera is hoping to price its IPO between $12 to $4 per share which will value the company between $1.54 to $1.79 billion. The valuation increases a bit if we factor in options and restricted stock grants at which point Cloud could be worth $2 to $2.4 billion.\n\nThe reported numbers are certainly impressive but they represent a fraction of Cloudera\u2019s valuation in previous financing rounds. Most notably, we can refer to Cloudera\u2019s 2014 monster round on which Intel ended up investing $700 million at a $30.92 PPS. Currently, Intel owns about 22% of Cloudera and have been reportedly interested on buying up to 10% of the common stock to be issued during the IPO in order to keeps its stake in the company.\n\nCloudera\u2019s valuation also falls short of some of the expectations of its mutual fund investors even after they marked down their investments to between $17 to $26 PPS. Mark ups/downs has been a common practice followed by public market investors such as hedge funds or mutual funds when investing in private companies.\n\nThe announcement has certainly raised some concerns within Cloudera\u2019s potential investors but I thin there are a lot of factors that should be considered to formulate a thesis of Cloudera\u2019s IPO price. Below I listed some of my own observations:\n\n1 \u2014 Pricing Low is Smart: All these debated about Cloudera\u2019s PPS is going to be completely irrelevant if the stock spikes in its first days of trading. Based on recent tech IPOS such as MuleSoft and Yext, it is very likely that, by pricing on the low end. Cloudera might be putting themselves in a position to outperform investor\u2019s expectation on opening day.\n\n2 \u2014 The Horton works Factor: Cloudera\u2019s competitor Horton works has had a less than stellar run in public markets. That performance has to be influencing investor\u2019s sentiment prior to the IPO.\n\n3 \u2014 Heavy Competition Cloudera is the undisputed leader of the big data platform market but today is certainly experiencing a more intense competition than at the time of its previous financing. In addition to pur big data players such as MapR or Horton works, Cloud now competes with enterprise software incumbents such as Microsoft, Oracle, SAP, IBM, Amazon, Google, HP and more. Additionally, Cloudera is also challenged by innovating startups such as Databricks which are leading new trends in the big data market (Spark\u2026).\n\n4 \u2014 From Dominant Trend to Commodity: In 2014, big data was the hottest trend in the enterprise software space. In three years, big data has become more of an enabler to fast growing trend such as artificial intelligence(AI) or the internet of things(IOT).\n\n5 \u2014 Slow to Enter the AI-ML Space: In my opinion, Cloudera hasn\u2019t done a good job expanding beyond the big data infrastructure play and capitalizing on new trends such as AI or machine learning.\n\n6 \u2014 Valuation Irrationality: Cloudera\u2019s 2014 valuation has all the signs of being irrational: it was a mega-round($700 million), led by a single corporate investor(Intel) at a time of market exuberance(2014). Maybe a small correction will be healthy after all."
    },
    {
        "url": "https://medium.com/@jrodthoughts/deepmind-is-bringing-love-to-tensorflow-with-sonnet-531b7a32c2cb?source=user_profile---------243----------------",
        "title": "DeepMind is Bringing Love to TensorFlow with Sonnet",
        "text": "Deep Mind continues its active contributions to the artificial intelligence(AI) and deep learning(DL) developer communities. In recent months, the Google subsidiary has regularly open source some of the AI and DL tools and frameworks used in some of their high profile solutions. Sonnet is the latest addition to DeepMind\u2019s open source stack.\n\nDeepMind\u2019s Sonnet is a framework for the implementation of neural networks using Tensorflow. The framework provides a higher level of abstraction for the construction of neural networks based on a TensorFlow computation graph.\n\nAlmost since its launch, Google tensorflow skyrocketed to become the most popular, open source DL framework in the market. DeepMind itself, switched to TensorFlow after years of using Torch (another popular framework) as its underlying DL stack. the number of DL applications built using TensorFlow has grown exponentially and yet the framework remains somewhat complex for mainstream developers.\n\nDespite its high adoption, TensorFlow remains a low-level framework for assembling computation using a data flow graph. TensorFlow developers typically need to combine elements such as tensors, Sessions or Variables into a computing graph. even though TensorFlow is mostly used for DL applications, the data flow graph abstraction is generic enough that it can be applied in other computation problems. as a result, AI developers are forced to become intimately familiar with the underlying TensorFlow graphs in order to correctly architect its applications even though many of those details are completely irrelevant to DL models. DeepMind obviously encountered some of those challenges when deciding to implement Sonnet.\n\nAt a high level, Sonnet provides a programming model for implementing neural networks using TensorFlow. More specifically, Sonnet enables the creation of Python objects that represent components of a neural network which later can be assembled as part of a TensorFlow graph.\n\nModules are a core concept of Sonnet. Conceptually, Sonnet\u2019s Modules encapsulate elements of a neural network such as models which an be combined multiple times into a data flow graph. That process abstracts low-level aspects of TensorFlow applications such as session building or variable sharing. Modules can be combined using arbitrarily complex models and Sonnet enable developers to build their own Modules using a simple programming model.\n\nThe higher level programming constructs and the module-based configuration, connection separation are certainly tangible advantages of Sonnet. However, I believe some of the biggest benefit of the new DL framework might be hidden beneath the surface. Here are some of my favorite benefits related to Sonnet:\n\n\u2014 Multi-Neural Network Applications: Implementing multi-neural network solutions such as multi-layer neural networks or adversarial neural networks in TensorFlow is something short of a nightmare. Sonnet\u2019s Module programming model can help to implement individual neural networks that can be combined to implement higher level networks.\n\n\u2014 Neural Network training: Sonnet simplifies the training of neural networks by focusing on individual modules.\n\n\u2014 Testing: Sonnet\u2019s higher level programming model simplifies the automated testing of neural networks using mainstream frameworks.\n\n\u2014 Extensibility: Developers can easily extend Sonnet by implementing their own modules. they can even control the construction of the TensorFlow graph related to that module.\n\n\u2014 Composability: Imagine having access to an ecosystem of built and trained neural network modules that can be dynamically composed into higher level networks. Sonnet is certainly a step forward in that direction.\n\nIf DeepMind is successful with Sonnet, my prediction is that we are going to see an explosion on the number of modules as well as similar frameworks that abstract the implementation of different types neural networks using TensorFlow as the underlying runtime."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-weak-vs-strong-ai-part-ii-are-ai-systems-conscious-53899e18ab4e?source=user_profile---------244----------------",
        "title": "About Weak vs. Strong AI Part II: Are AI Systems Conscious",
        "text": "In the first part of this essay, we discussed the arguments about the weak vs. strong artificial intelligence(AI) debate. Although there are several definition of boths schools of thoughts, there are mostly based on the ability of AI systems to think(strong AI) or simulate thinking( weak AI). In the current market, I believe most people agree that weak AI is being materialized wither the present generation of AI technologies. However, there are still many doubts about the potential of strong AI.\n\nThe skepticism about strong AI has sparked arguments from ranging classic mathematical theory such as Goldel\u2019s Incompleteness Theorem to pure technical limitations of AI platforms. However, the main are o debate remains on the intersection of biology, neuroscience and philosophy and has to do with the consciousness of AI systems.\n\nThere are many definitions and debates about consciousness. Certainly enough to dissuade most sane people to pursue the argument of its role in AI systems ;) Most definitions of consciousness involve self-awareness or the ability for an entity to be aware of its mental states. Yet, when it comes to AI, self-awareness and metal states and not clearly defined either so we can quickly start going down a rabbit hole.\n\nIn order to be applicable to AI, a theory of consciousness needs to be more pragmatic and technical and less, let\u2019s say, philosophical. My favorite definition of consciousness that follows these principle comes from the laureate physicist Michio Kaku, professor of theoretical physics at University of New York and co-founder of the string field theory. A few years ago, Dr. Kaku presented what he called the \u201cspace-time theory of consciousness\u201d to bring together the definition of conscious ness from fields such as biology and neuroscience. In his theory, Dr. Kaku defines consciousness as follows:\n\n\u201cConsciousness is the process of creating a model of the world using multiple feedback loops in various parameters (ex: temperature, space, time , and in relation to others), in order to accomplish a goal( ex: find mates, food, shelter)\u201d\n\nThe space-time definition of consciousness is directly applicable to AI because it is based on the ability of the brain to create models of the world based not only on space (like animals) but in relationship to time (backwards and forwards). From that perspective, Dr. Kaku defines human consciousness as \u201ca form of consciousness that creates a model of the world and then simulates it in time, by evaluating the past to simulate the future. In other words, human consciousness is directly related with our ability to plan fro the future.\n\nIn addition to its core definition, the space-time theory of consciousness includes several types of consciousness:\n\n\u2014 Level 0: Includes organisms such as plants with limited mobility which create a model of its space using a handful of parameters such as temperature.\n\n\u2014 Level 1: Organisms like reptiles that are mobile and have a nervous system. These organisms use many more additional parameters to form a model of its space.\n\n\u2014 Level II: Organisms such as mammals that create models of the world not only based on space but in relation to others.\n\n\u2014 Level III: In this level we have human consciousness that can create models of the world not only based on space and other humans but also based on time and the future.\n\nThe short, and maybe surprising answer, is YES. Applying Dr. Kaku\u2019s space-time theory of consciousness to AI systems, it is obvious that AI agents can exhibit some basic forms of consciousness . Factoring the capabilities of the current generation of AI technologies, I would place the consciousness of AI agents at Level I (reptiles) or basic Level II.\n\nWe will discuss elaborate on this argument in a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-cloud-keeps-getting-better-via-partnerships-8f68833b2ae5?source=user_profile---------245----------------",
        "title": "Google Cloud Keeps Getting Better via Partnerships \u2013 Jesus Rodriguez \u2013",
        "text": "Google Cloud is determined to challenge AWS and Azure for the dominance in the cloud market and has been partnering aggressively to do so. A few days ago, Google announced that its bringing native services for Elasticsearch, Kibana and Trifacta to Google Cloud. The strategy of supporting up and coming enterprise platforms as native cloud services might pay strong dividends for Google Cloud in the short term.\n\nBy native cloud services, we are referring to capabilities that can be provisioned and scaled without any knowledge of the underlying VMs and infrastructure( just like ground up Google cloud services). AWS, Azure and Bluemix support the provision of many thind party technologies as pre-configured VMs. However, only a small number of platforms are available as native cloud services.\n\nThe partnership with Elastic will enable products such as Elasticsearch and Kibana as native cloud services. The offering will also include graph analytics, alerts, commercial support as well as other capabilities of high-end Elastic subscriptions. The new service should be comparable to AWS-s which enables as Elasticsearch native service in addition to its own Amazon Cloud Search service. Azure only offers Elasticsearch as preconfigured VMs as a complement to its Azure Search services.\n\nThe partnership with Trifacta is even more interesting. Offering trifacta as a native service will expand Google Cloud with one of the most innovative data quality management platforms in the market. data quality services is a feature notably missing from the AWS and Azure platforms.\n\nPartnership with hot enterprise software startups and offering its capabilities as native services can help to rapidly advance the feature set of Goggle Cloud in areas in which its been railing the competition. Following that logic, there are other markets and partnerships that should result interesting for Google Cloud.\n\nIntegration is one of the most important capabilities sill missing from Google Cloud. Offering a technology such as Mulesoft\u2019s CloudHub as a native service could bring one of the most sophisticated integration platform as a service(iPaaS) to Google Cloud. Integration services would also give Google Cloud an edge in the iPaaS market over its top competitors. Currently, Azure offering LogicApps which is still very limited compared to CloudHub while AWS doesn\u2019t have any relevant iPaaS capabilities( CloudHub does run on AWS).\n\nIn addition to a potential partnership, MuleSoft market traction makes it an interesting acquisition target for Google.\n\nInternet of things(IOT) capabilities is another area in which Google Cloud has been trailing competitors such as AWS, Azure and Bluemix. However, it could be challenging for Google Cloud to find a suitable partnership in this area as most relevant IOT platforms are already offered as cloud services not compatible with Google Cloud. GE Predix is a notable exception to this rule with a hybrid, Cloudfoundry-based IOT platform that can enable industrial IOT capabilities in Google Cloud.\n\nWe should expect Google Cloud to soon launch a blockchain as a service ( BaaS) offering to competed with AWS, Azure and Bluemix\u2019s capabilities in the space. Ethereum and Eris Tech as well as emerging blockchain-based PaaS such as BlockStack or Nxt could be considered strong candidates for partnerships with Google Cloud."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-weak-and-strong-artificial-intelligence-part-i-5db9356a51a3?source=user_profile---------246----------------",
        "title": "About Weak and Strong Artificial Intelligence: Part I",
        "text": "With all the technological hype about artificial intelligence(AI), I find it sometimes healthy to go back to its philosophical roots. From all the philosophical debates surrounding AI, none is more important that the weak vs. strong AI problem.\n\nIn AI theory, weak AI is often associated with the ability of systems to appear intelligence while strong AI is liked to the ability of machines to think. By thinking I mean really thinking and not just simulated thinking. This dilemma is often referred to as the \u201cStrong AI Hypothesis\u201d.\n\nIn a world exploring with digital assistants and algorithms beating GO and Poker champions, the question of whether machines can act intelligently seems silly. In constrained environments (ex: medical research, GO, travel) we have been able to build plenty of AI systems that can act as it they were intelligence. Therefore, most experts agree that weak AI is definitely possible but many also share tremendous skepticism when comes to strong AI.\n\nThis questions has hunted computer scientists and philosophers since the publication of Alan Turing\u2019s famous paper \u201cComputing Machinerary and Intelligence\u201d in 1950. The question also seems a bit unfair when most scientists can\u2019t even agree on a formal definition of thinking.\n\nTo illustrate the confusion around the strong AI hypothesis, we can use some humors from the well-known computer scientists Edgger Dijkstra who in a 1984 paper compared the question of whether machines can think with questions such as \u201ccan submarines fly?\u201d or \u201ccan airplanes fly\u201d. While those questions seem similar, most English speakers will agree that airplanes can, in fact, fly but submarines can\u2019t swim. Why is that? I\u2019ll leave that debate to you and the dictionary ;) The meta-point of this comparison is that without a universal definition of thinking it seems irrelevant to obsess about whether machines can think.\n\nOne of the best known objections to the strong AI hypothesis comes from mathematics. In 1931, mathematician Kurt Godel demonstrated that deduction has its limits by proving his famous incompleteness theorem. Godel\u2019s theorem states that any formal theory strong enough to do arithmetic (such as AI) there are true statements that have no proof within that theory.\n\nThe incompleteness theorem has long been used as an objection to strong AI. The proponents of this theory argue that strong AI agents won\u2019t be able to really think because they are limited by the incompleteness theorem while human thinking is clearly not. That argument has sparked a lot of controversy and has been rejected by many strong AI practitioners. The most used argument by the strong AI school is that it is impossible to determine if human thinking is subjected to Godel\u2019s theorem because any proof will require formalizing human knowledge which we know to be impossible.\n\nMy favorite argument in the strong AI debate is about conciousness. Can machines really think or just simulate thinking? If machines are able to think in the future that means that they will need to be conscious (meaning aware of its state and actions) as conciousness is the cornerstone of human thinking. Can machines really be conscious? More about that in a future post\u2026."
    },
    {
        "url": "https://medium.com/@jrodthoughts/alibaba-cloud-artificial-intelligence-strategy-is-taking-shape-8fe407c66a6a?source=user_profile---------247----------------",
        "title": "Alibaba Cloud Artificial Intelligence Strategy is Taking Shape",
        "text": "In the past, I\u2019ve written extensible about the astonishing trajectory of Alibaba Cloud to go from an unknown platform to a force to be reckon with in the cloud ecosystem. In those articles, I repeatedly mentioned the pivotal role that artificial intelligence(AI) should play in the future of Alibaba Cloud as it competes more frequently with PaaS incumbents such as AWS, Azure, Google Cloud or Bluemix. Recently, we\u2019ve seen a few announcements from Alibaba Cloud that share some light into their AI strategy in order to bridge the gap with the market leaders.\n\nA few days ago, Alibaba Cloud announced the general availability of its machine learning platform (PAI) as well as the release of AI APIs for scenarios in healthcare and manufacturing. At this point, I believe Alibaba Cloud\u2019s AI strategy is based on three fundamental pillars:\n\nThe PAI machine learning service is at the core of Alibaba Cloud\u2019s AI strategy. With the release of PAI 2.0, Alibaba Cloud announced support for multiple deep learning frameworks and a catalog of over a hundred AI algorithms that can be used by applications built on the PAI platform.\n\nPAI 2.0 contrasts with the strategy followed lead AI cloud technologies such as AWS ML, Azure ML or Google Cloud ML. By supporting the execution of AI programs written in open source deep learning frameworks, Alibaba Cloud can allow organizations to leverage the existing developer talent in deep learning communities such as TensorFlow, Torch, Caffe, Chainer, Theano, DeepLearning4J and many others while also providing a robust runtime and management experience for those applications. In contrast, stacks such as Azure ML or AWS ML only support their proprietary machine learning language with some limited extensions in languages such as R or Python. While Google Cloud ML is a great platform for TensorFlow models, it doesn\u2019t support the rest of the popular deep learning stacks.\n\nPAI 2.0 also allows organizations to pilot AI-deep learning applications on their own premises using their favorite deep learning stack while leveraging Alibaba Cloud for running and managing the solution at scale. That level of hybrid interaction is missing from most of the cloud AI stacks. PAI 2.0's flexibility seems to have directly paid off with a large catalog of AI algorithms that can help to bootstrap applications built on the platform.\n\nAnother clever move by Alibaba Cloud was to start offering industry-specific AI services. Specifically, the new version includes ET Medical Brain and ET Industrial Brain which abstract core AI capabilities such as image analysis, energy optimization or predictive maintenance which are relevant in the healthcare and manufacturing industry respectively. The launch of those AI industry services should make Alibaba Cloud more competitive with IBM Watson and Google DeepMind which also provide vertical AI services.\n\nAI APIs that abstract key cognitive capabilities in areas such as vision, speech, language or knowledge are also a key component of Alibaba Cloud\u2019s strategy. These capabilities should make Alibaba Cloud more competitive with technologies such as Watson Developer Cloud or Microsoft Cognitive Services."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-the-fragility-of-the-cloud-part-ii-c1cff395eb54?source=user_profile---------248----------------",
        "title": "About the Fragility of the Cloud: Part II \u2013 Jesus Rodriguez \u2013",
        "text": "In the first part of this essay, we discussed several factors that actively contribute to the fragility of cloud platforms. Despite the robustness of cloud infrastructures such as AWS or Azure, its massive mainstream adoption drastically increases the potential catastrophic effects of any type of error.\n\nIncreasing the resiliency against large and unexpected cloud outages is far from being a trivial task. Technologies that provide an alternative to the centralized models of cloud platforms imply don\u2019t offer the levels of sophistication and the rich feature set of cloud stacks such as Azure, AWS or Google Cloud. Additionally, there is always a financial cost associated with architecting more anti-fragile cloud solutions which results prohibited for most organizations.\n\nThe case to avoid the fragility of the cloud on mission-critical applications can be summarized in two main phases: In the near future, we can attempt to mitigate some of the risk by considering enhanced versions of technologies such as Cloudfoundry which provides an infrastructure agnostic cloud programming models. In the loger term, I believe that we are going to see the emergence of decentralized PaaS stacks.\n\nCloudfoundry is a great platform fro designing cloud infrastructure agnostic applications. However, it is undeniable that the capabilities of Cloudfoundry are relatively limited compared to platforms such as AWS, Azure or Google Cloud. From that perspective, applications built using Cloudfoundry can\u2019t take advantage of some of the vintage services such as BigQuery, Azure Service Bus or AWS Kinesis included in the incumbent PaaS platforms.\n\nAn interesting idea in this context would be to extend Cloudfoundry with services that match the capabilities of the different PaaS stacks and adapter that provide the implementation for a specific cloud service .For instance, we could have a Cloudfroundry messaging service with adapters for Azure Service Bus, Google lCloud Pubsub or AWS SQS or a Cloudfoundry Data Warehouse service with adapters for AWS Redshift, Google Spanner or Azure Data Warehouse.\n\nUsing this model, we could build Cloudfoundry applications that expand across multiple clouds while taking advantage of the core services of the underlying platform. I would be the first one to admit that this model is far from idea but it could yield interesting results for mission critical applications that expand across multiple clouds.\n\nThe Emergence of the Decentralized PaaS\n\nThe evolution of blockchain technologies and the emergence of higher-level platforms such as Nxt or Blockstack are effectively creating the first generation of decentralized PaaS technologies. Platform such as Ethereum have been able to provide higher level constructs or blockchain applications in the form of smart contracts or decentralized autonomous organizations(DAO). Now stacks such as Eric Tech, Nxt or Blockstack are attempting to enable the implementation of complete applications with a decentralized backend and are taking the first steps towards decentralized PaaS architectures. Although still in early stages, blockchain-powered PaaS could soon become a viable model for applications trying to avoid the fragility of the cloud."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-the-fragility-of-the-cloud-part-i-8940265894b8?source=user_profile---------249----------------",
        "title": "About the Fragility of the Cloud Part I \u2013 Jesus Rodriguez \u2013",
        "text": "I\u2019ve been meaning to write this essay for a few weeks but I was afraid that people might think that I had gone crazy just by reading the title. After all, you can\u2019t be very sane if you are talking about the fragility of the cloud. For many, cloud platforms are the most robust architecture ever built after the internet. And yet, they are still fragile.\n\nIn recent weeks, we have witnessed how a deployment error on the S3 service spread throughout regions of the AWS infrastructure drastically affecting a significant part of the internet. A few days after, Microsoft Azure suffered a similar (although not as catastrophic) outage that affected a large number of its customers. Those examples showed how random, unpredictable events can have disastrous consequences for cloud infrastructures. That\u2019s the definition of fragility.\n\nAs Big as the Internet\n\nThe fragility of the cloud can be compared to the fragility of banking systems. Both architectures are incredibly robust and pervasively adoptive to the point we can\u2019t conceive our lives without it. Yet in 2008 the US financial systems erased over $2 trillion in assets and came on the verge of collapse after irresponsible bets in sub-prime mortgages permeated through the system. Just a decade before, Long Term Capital Management(LTCM) was crushed by Russia\u2019s unexpected decision to default on its debt and threaten to cause major losses to the US financial systems as most big banks has trading relationships with LTCM. Just as I write these lines, Italy is struggling with the bailout of its oldest bank to try to avoid the collapse of its finance infrastructure.\n\nComing back to the cloud, the analogy of the fragility of banking systems could help us explain a few concepts. Just like banks, platforms such as AWS are so widely adopted that they can be considered a second internet. As a result, a large percentage of the world\u2019s online presence requires these underlying cloud platforms to exhibit near perfect robustness. The inverse is also true (although more scarier) an unexpected failure on cloud infrastructures can have disproportional consequences in online business across the world. The thing is that, when comes to centralized, worldwide adopted, complex and incredibly interconnected software infrastructures such as the cloud: robust is never robust enough.\n\nIt is obvious that cloud platforms such sa AWS and Azure are robust. The might ran among the most robust software infrastructure ever created. However, they are also incredibly large and complex which exponentially increases the impact of a potential failures. They are simply fragile. The type of fragility we are talking about in this article is not the one you can address with more robust infrastructures and chaos monkey testing techniques. We are talking about resiliency to random, unexpected events: A human deployment error spreads through the AWS cloud, Chine decides to expel Amazon from the country and cuts access to AWS datacenter, a conflict emerges between North and South Korea destroying cloud data centers in South East Asia; malicious Russian hackers( all hackers seem to be Russian these days ;) ) discover a vulnerability that can bring down core Azure services\u2026Hopefully you get the idea.\n\nWhat it is the right balance between cost and architecting systems that are \u201cmore resilient\u201d ( by definition we can\u2019t plan for many of those events) to those scenarios? Most businesses can live knowing that, from time to time, they will be affected by cloud disasters. Fro others, that\u2019s simply not an option.\n\nIn a recent Wall Street Journal conference, Andreessen-Horowitz partner Peter Levine casually mentioned that he had been working on a thesis of a world on which cloud computing goes away. Levine\u2019s argument was related to the emergence of decentralized, edge computing platforms that can\u2019t simply be exposed to the fragility of the cloud. While I don\u2019t subscribe to that theory (yet ), I believe it includes some ideas worth exploring in order to build systems more resilient to the fragility of the cloud. More about that in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/conversational-analytics-64d25143e99b?source=user_profile---------250----------------",
        "title": "Conversational Analytics \u2013 Jesus Rodriguez \u2013",
        "text": "Let\u2019s say you are an executive at a big company or the CEO of a mid-size startup. You\u2019ve requested information about the quarterly sales performance of your company and your team has put together a report that renders the latest sales metrics using beautiful charts. So here you are, reviewing a detailed report with gorgeous visualizations and you are still confused about what it all means. Then you start a conversation with your team to better understand the data and brainstorm possible strategies.\n\nDoes this scenario sounds familiar? It should because it is certainly common in the corporate world. Data analytics are typically accompanied of additional information in the form of human conversations. To put it in simple terms, natural language plays a role improving analytics.\n\nThe advancements in deep learning techniques such as natural language processing(NLP) and natural language understanding(NLU) have created new opportunities to enhance analytics as we know it. We might soon be entering the era of conversational analytics.\n\nData serves little purpose as an isolated element. Just when it is interpreted data acquired a semantic meaning associated with a specific context. Voice and conversational interactions can create narratives to enrich business data sets. Additionally, natural language narratives can expand the semantic interpretation of data sets beyond static visualizations. For instance, a sales forecast visualization might show a positive version of the company\u2019s performance but the management team could interpret it using a different narrative of the data as they understand the forecast still falls below their top competitors.\n\nUser: Alexa, what does the bottom right quadrant of this chart represents?\n\nImagine having that type of conversation with your favorite digital assistant and reviewing explanations about specific data analytics. Interpretation is one of the areas on which voice conversations can really improve how we consume analytics. Conversational analytics will not only provide right visualizations but it will complement the graphics and data with voice narratives that will help to interpret them.\n\nSuppose that you recently reviewed the latest quarterly sales forecast of your company and that you are currently in your car driving to a meeting with investors. Imagine if you could ask the analytics digital assistant in your car\u2019s console: \u201cAlexa, please help me review our latest sales forecast\u201d. At that point, the digital assistant will start providing a succinct voice summary of the forecast data and clarifying some of your questions. Pretty cool, huh?\n\nConversational analytics open the door to models that allow the consumption of analytical data across different channels ranging from rich web dashboards to voice-only devices.\n\nIn a typical business day, we have dozens of conversations and meetings on which we discuss hundreds of data points. Those data points and ideas aren\u2019t typically captured anywhere except in our own memories. Imagine, having an analytics assistant that is constantly documenting the data points in our conversations and creating real time analytics based on them. That would be something, wouldn\u2019t it?"
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-the-release-of-amazon-connect-caf05ddfdb5f?source=user_profile---------251----------------",
        "title": "Some Thoughts About the Release of Amazon Connect \u2013 Jesus Rodriguez \u2013",
        "text": "Amazon continues looking for creative avenues to expand its AWScloud. Last week, the cloud giant announced the released of Amazon connect, a contact center solution powered by AWS services. Apparently, Amazon Connect is based on the same technology AWS has been using to power customer conversations for over a decade.\n\nAt the core of Amazon Connect, we have the notion of \u201cVirtual Contact Centers\u201d, a customer service center that can be provisioned in minutes using the AWS Management Console. Virtual Contact Centers enable traditional capabilities such as ticket management or customer support but it also provider an integrated experience with AWS services such as DynamoDB, Aurora or RedShift. Additionally, Amazon Connect integrates with external services such as Salesforce.\n\nAmazon Connect is entering a super crowded market that already counts with incumbents such as ZenDesk and innovators like FreshDesk as well as a good number of legacy players. While analysts have focused their attention on the implications that the release of Amazon Connect can have for ZenDesk as a publicly traded company, I believe the market implications are broader and can impact different segments of the cloud market. Let\u2019s start by looking at AWS\u2019 direct competitors.\n\nWhats Does Amazon Connect Means for Azure and Google Cloud?\n\nCustomer support is one of the key requirements raised by enterprises when adopting cloud platforms. Amazon Connect now provides organizations with a contact center solution that can dynamically scale with their AWS infrastructure. That capability can become a strong differentiator against competitors such as Azure and Google Cloud that don\u2019t posses a similar capability. Considering that AWS , Azure and Google Cloud have been trying to match each other feature by feature, it is not crazy to think that Microsoft or Google could try to acquire a SaaS Contact Center platform.\n\nIs Not Just About Platform Services for AWS\n\nConnect is another example of business and high level productivity services that Amazon has been steadily adding to AWS. Those types of capabilities are making AWS more defensible against Microsoft and Google which count with multi-million SaaS productivity platforms such as Office365 or G-Suite respectively.\n\nWhat Does this Means for ZenDesk?\n\nHard to tell. ZenDesk is not an obvious acquisition target for Microsoft or Google as it platform runs on AWS. Similarly, its hard to envision Amazon Connect causing an immediate dent on ZenDesk\u2019s market share outside heavy AWS customers. ZenDesk\u2019s stock has been performing extremely well and I don\u2019t think Connect will have any impact on the short term.\n\nAlexa is Coming to a Contact Center Near You\n\nAmazon already announced that Connect will leverage their latest innovation on natural language processing and artificial intelligence.Wed should soon see services such as Alexa and AWS Lex integrated into Virtual Contact Centers.\n\nWhat Does Connect Means for FreshDesk and Other Startups?\n\nWhile the implications for ZenDesk are unclear, the release of Amazon Connect can make customer contact center startups such as FreshDesk or Zoho an immediate acquisition target. Certainly, the release of Amazon Connect is helping to make the space more competitive."
    },
    {
        "url": "https://medium.com/@jrodthoughts/floyd-and-cloud-deep-learning-platforms-part-ii-a15fce6827b1?source=user_profile---------252----------------",
        "title": "Floyd and Cloud Deep Learning Platforms Part II \u2013 Jesus Rodriguez \u2013",
        "text": "In a previous article, I discussed the emergence of cloud deep learning platforms such as Floyd and its viability on a market dominated by incumbents such as AWS, Google Cloud, Azure or IBM bluemix. Today, I would like to focus on the potential capabilities that these platforms should explore in order to be successful in the market.\n\nFrom a functional standpoint, technologies such as Floyd offer a cloud service to automate the execution of deep learning from from popular frameworks such as Caffe, TensorFlow, Chainer and many others (over 10). Additionally, Floyd expects to build a marketplace for curated datasets and algorithms. While Floyd\u2019s value proposition is certainly comprehensive, there are some serious challenges for that type of platforms on a market that, although young, is already dominated by incumbents such as Amazon, Google, Microsoft and IBM (see the previous article). However, technologies like Floyd also have an opportunity to capitalize on the well known limitations of the incumbent platforms. In order to do that, there are a series of capabilities that should be considered as part of their roadmap.\n\nWhile cloud cognitive APIs are a great potion for simple deep learning tasks such as image recognition, many artificial intelligence(AI) scenarios require custom deep learning models. For those scenarios, deep learning frameworks such as TensorFlow or Caffe offer incredibly robust capabilities. Providing a runtime and infrastructure for the execution and management of programs authored on different deep learning frameworks should be a key capability of a cloud deep learning platform. This feature can also result on a strong differentiator as most incumbent cloud deep learning platforms don\u2019t offer support for those frameworks( with the exception of Google cloud ML that supports TensorFlow programs).\n\nThe current generation of open source deep learning frameworks is extremly sophisticated when comes to the implementation of AI programs but it lacks the operational toolset to operate in enterprise environments. Tools for training, monitoring and managing deep learning models should be an essential element of cloud deep learning platforms.\n\nTo address a broader spectrum of enterprise scenarios, a deep learning platforms should be able to operate on both cloud and on-premise infrastructure. That level of symmetry is missing in the current generation of PaaS incumbents.\n\nProviding a curated data source catalog will allow data scientists to author deep learning models without spending time and effort provisioning and curating the data. After the models are completed, they should be exposed via APIs that can be consumed by third party applications.\n\nEnvironments such as Jupyter, Zepellin or Google dataLab have become extremely popular among data scientists. I believe that a cloud deep learning platform should leverage similar concepts and enable an interactive, self-service experience to author deep learning models using frameworks such as TensorFlow or Theano against curated datasets.\n\nIn the current AI market climate, we are experiencing an M&A frenzy. As a result, it is conceivable that cloud deep learning platforms will become hot acquisition targets. Surprisingly, I believe that PaaS incumbents such as Google, Microsoft or IBM are unlikely to pursue other cloud deep learning platforms as their technology stacks and visions don\u2019t quite align. Having said that, there are several groups within the AI space that can become really acquisitive when comes to cloud deep learning platforms:\n\n1 \u2014 Big Data Distributions: Big Data platform vendors such as Cloudera, Hortonworks or MapR are looking to expand their offerings beyond infrastructure and into higher level data services. Cloud deep learning platforms are an emerging market that naturally complements the capabilities of these platforms.\n\n2 \u2014 Second Tier Cloud Providers: Cloud platforms such as Alibaba Cloud or Oracle Cloud need to quickly expand their AI offerings. Acquiring solid deep learning services could be a great way to become more competitive against the incumbent PaaS vendors.\n\n3 \u2014 Amazon & Salesforce: AWS deep learning stacks are still training the competition and they can become a really compelling acquirer (many cloud deep learning platforms already run on AWS). Salesforce recently partnered with IBM Watson to develop its Einstein service. However, adding deep learning capabilities to Heroku is still a viable idea."
    },
    {
        "url": "https://medium.com/@jrodthoughts/is-edge-computing-the-next-major-computing-revolution-part-ii-e60c70e550c5?source=user_profile---------253----------------",
        "title": "Is Edge Computing the Next Major Computing Revolution? Part II",
        "text": "In our previous article, we discussed some of the market dynamics influencing the raise of edge computing. Today, I would like to focus on providing some market perspectives about the potential evolutionary path as well as the key characteristics of edge computing platforms\n\nThe evolution of trends such as IOT, drones and self-driving vehicles is drastically influencing the evolution of edge computing capabilities. Logically, the growth of edge computing requirements is likely to evolve onto a new generation of platforms that enable the implementation of edge computing solutions by mainstream developers. Trying to understand the core capabilities of edge computing platforms and predicting the potential evolution of the market, is a challenge for venture capitalists and startups entering the space. Below, I\u2019ve summarized some of my thoughts about the capabilities of the first generation of mainstream edge computing platforms to get the debate started ;)\n\nEdge computing solutions are notoriously technologically complex and require fairly large implementation cycles. The role of an edge computing platform would be to provide the fundamental building blocks of edge computing solutions. From that perspective, the first generation of edge computing platforms is likely to enable capabilities such as in-device storage, application containers, data security, in-device messaging, device discovery, cloud services integration, analytics-monitoring and other components required to simplify the mainstream adoption of edge computing solutions.\n\nHaving an understanding of the potential feature set of edge computing platforms, the next important aspect is to forecast what segments of the market will produce those capabilities.\n\nThe market for edge computing platforms promises to be a super competitive one. In my opinion, there are several segments of the technology market that are likely to produce relevant edge computing platforms.\n\n1 \u2014 Cloud Computing Platform Vendors: Companies such as Amazon and Microsoft are position edge computing as an extension of their cloud platform capabilities. AWS Greegrass is a great example of edge computing technologies that naturally complements existing cloud platform services (AWS Lambda).\n\n2 \u2014 Self-Driving Vehicle Platforms: As self-driving vehicle companies continue gaining relevance , we should see some of their edge computing technologies delivered as open source distributions.\n\n3 \u2014 IOT Platform Vendors: Edge computing is an important aspect of industrial IOT solutions. IOT platforms such as ThingWorx, C3IOT or GE Predix already provide interesting edge computing capabilities. Those efforts are likely to evolve into full-blown edge computing platforms focused on the industrial enterprise.\n\n4 \u2014 IOT Device Manufacturers: Device manufacturers focused on industrial IOT devices are another sectors able to produce relevant edge computing platform components. As many things in this sector, we might see different vendors partner and create consortium organizations to drive innovation and the creation of edge computing platforms.\n\n5 \u2014 Telcos: Telecommunication companies have, arguably, more experience than any other industry deploying mission critical edge computing solutions. Consequently. we might see some interesting platforms coming out of forward thinking telcos that factor in some of the best practices learned throughout the years."
    },
    {
        "url": "https://medium.com/@jrodthoughts/is-edge-computing-the-next-major-computing-revolution-part-i-54e2e6546347?source=user_profile---------254----------------",
        "title": "Is Edge computing the Next Major Computing Revolution? Part I",
        "text": "Cloud computing has dominated the computing platform market for the last decade and is not showing any sign of slowing down. However, the emergence of new technologies such as autonomous vehicles have pushed the need for new computing paradigms. Among those trends, edge computing has been getting a lot of attention recently as the potential driver of the next major revolution in computing platforms.\n\nBy edge computing, we are referring to architectures that involve a large number of independent nodes that can autonomously execute business logic and computations without a centralized authority. While the concept of edge computing has been around forever, it is just recently that technology has gotten to the point of enabling the mainstream implementation of that type of architecture.\n\nThe Need for Decentralization: What is Pushing Edge Computing?\n\nBack in the 60s, IBM famously proclaimed that the vast majority of software applications in the world will be ran by a handful of mainframes( I am paraphrasing on purpose to make the statement sound less ridiculous than what it really was ;) ). While the prediction didn\u2019t turn out to be truth for mainframes, it certainly became valid five decades later with the mainstream adoption of cloud platforms. After all, aren\u2019t platform as a service(PaaS) stacks just like big mainframes? (just kidding\u2026).\n\nToday, a significant percentage of the cloud application sin the world are ran on an incredibly small number of platforms. Even more astonishingly is that one of those platforms (AWS) currently controls over 60% of the market. If you are looking for a text-book example of a fragile ecosystem it doesn\u2019t get much better than the cloud platform market\n\nWhile cloud computing is likely to become the architecture model of choice for an important percentage of the software applications in the world, a new generation of technologies are claiming the need for decentralized, autonomous computing models. This group of technologies are known as edge computing. There are many examples of edge computing models but, in terms of the market impact, we can cite these top four examples:\n\n\u2014 Autonomous Vehicles: Self-driving vehicles are the most notable examples of edge computing architectures.\n\n\u2014 IOT: Internet of things(IO)T and industrial enterprise applications require sensors and smart devices to operate autonomously without a centralized authority.\n\n\u2014 Bitcoin: Bitcoin is a primal example of decentralized architectures powering mission critical capabilities.\n\n\u2014 Drones: Drones architectures are a great example of edge computing operating at a global scale.\n\nSome Cool Edge computing Models to Draw Inspiration From\n\nThere are many great examples of edge computing architectures and technologies. Below I listed some of my favorites that are helping to drive the mainstream adoption of edge computing paradigms.\n\n\u2014 Blockchain Platforms: Technologies such as Ethereum, Ripple o rHyperledge are great frameworks for building decentralized, edge computing models based on the blockchain.\n\n\u2014 Consul.io: Consul.io is a decentralized platform to enable DNS-like discovery of services in a network.\n\nKnowing that edge computing is likely to become a relevant trend in the software platform market, we can start brainstorming the capabilities of edge computing platforms. That will be the topic of the next post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/floyd-and-the-deep-learning-cloud-market-1ece81f717c7?source=user_profile---------255----------------",
        "title": "Floyd and the Deep Learning Cloud Market \u2013 Jesus Rodriguez \u2013",
        "text": "The deep learning technology market is booming with innovation. However, differently from other enterprise software trends, we are seeing as much innovation in deep learning coming from big corporate labs as from startups. At the moment, the deep learning cloud platform market is dominated by the big four cloud incumbents: Google Cloud, AWS, Azure and Bluemix. Recently, I learned about Floyd, a startup that is attempting to change that landscape.\n\nGraduated from the most recent Y Combinator class, Floyd provides a series of native cloud services for the execution and management of deep learning models. The platform uses a cloud runtime for over 10 deep learning frameworks such as Caffe, TensorFlow or Chainer while also providing the corresponding management nad lifecycle automation tools. Additionally, Floyd is planning to build a marketplace of algorithms and curate dataset a la Algorithmia. Certainly an ambitious vision.\n\nWhile offers such as Floyd are certainly welcomed in a market dominated by incumbents, the big question mark remains to asses whether this type of standalone platform has a long term chance against bigger and also very innovative PaaS competitors. Personally, I am bullish about the opportunity of standalone deep learning cloud platform such as Floyd but entering a young market already dominated by companies such as Microsoft, Google, IBM or Amazon is far from trivial. In the current market, the deep learning PaaS incumbents has some very well known advantages but also some frustrating limitations.\n\nFrom an enterprise perspective, there are certainly very tangible advantages in the deep learning offerings of platforms such as Watson Developer Cloud, Google Cloud ML-AI APIs or Azure ML-Cognitive Services. For starters, those services are delivered as part of broader cloud platforms that include capabilities in areas such as data integration, storage, messaging, APIs, etc which enables the implementation of sophisticated deep learning solutions. Additionally, those platforms expose really sophisticated deep learning models as simple APIs [ex: Microsoft Cognitive Services, Watson Developer Cloud, AWS Lex\u2026] which can be easily integrated into third party applications. Global availability, established enterprise SLAs and a robust partner ecosystem are also some of the key advantages of the incumbent deep learning cloud services. However, now everything is rosy when comes to these technologies and there are some interesting challenges that could open the door for startups in the space.\n\nExtensibility , on-premise integration and interoperability with open source deep learning frameworks are some of the key weaknesses of the deep learning platforms provided by Google Cloud, AWS, Azure and Bluemix. Excepting, Google Cloud ML (which supports TensorFlow programs) the deep learning services provided by the cloud incumbents are currently unable to execute models authored on popular frameworks such as Caffe, Theano or Torch. That limitation contrasts with Floyd\u2019s ability to support over 10 deep learning stacks. Extensibility is another challenge of the incumbent deep learning services as those services typically limited themselves to allow the execution of custom R or Python scripts. Finally, the big cloud deep learning platforms are currently unable execute on on-premise environments with the exception of some creative work Microsoft is doing to support Azure ML on Azure Stack.\n\nAbsolutely! The unique characteristic of the enterprise deep learning market on which a lot of the innovation is being delivered as open source frameworks (Tensorflow, Torch, Chainer, Microsoft Cognitive Toolkit\u2026) creates an interesting opportunity for cloud services in the space. Additionally, deep learning algorithms and data marketplaces in a nascent segment in the market. How could deep learning startups platforms like Floyd become and stay relevant in a market already dominated by incumbents? We will discuss some ideas about this in the next post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/hello-bixby-strengths-and-weaknesses-of-samsung-new-digital-assistant-strategy-84855043cb3?source=user_profile---------256----------------",
        "title": "Hello Bixby: Strengths and Weaknesses of Samsung New Digital Assistant Strategy",
        "text": "This week, Samsung unveiled Bixby as part of the Galaxy S8 announcement. Bixby is a new voice-powered assistant that will join Siri, Alexa, Google, Cortana and dozens of others in a highly competitive market.\n\nBixby is the evolution of Viv, an artificial intelligence(AI) assistant built by the creators of Siri. Early demos of Viv looked really impressive but there was always a question mark in terms of its ability to compete in the long term with incumbents such as Google, apple, Microsoft or Amazon that control a significant percentage of the market distribution. After acquiring Viv, Samsung went to work on a strategy to make voice a fundamental element of its next generation products. Bixby is the first release of that new strategy.\n\nBased on the initial demos and content available, Bixby looks really sophisticated and even exhibits some unique characteristics compared to its more matured competitors. However, Samsung\u2019s digital assistant has some very tangible limitations that it should overcome in order to remain competitive in the space.\n\nIn the Galaxy S8, Bixby is aware of the user activity within its apps which allows of context rich conversations. Additionally, Bixby supports a large percentage of the S8 apps features and functions which enables it to take over using voice commands. This experience is drastically more integrated than what we\u2019ve seen from Siri, Alexa, Cortana or Google Assistant up to this point.\n\nThe Galaxy S8 is just a starting point of Bixby. Very soon, we should count on seeing the digital assistant integrated into many different Samsun products ranging from bracelets to refrigerators. Samsung expertise and diversity on hardware is certainly unique asset of Bixby.\n\nI really like this concept! Cognitive tolerance represents Bixby\u2019s flexibility to understand incomplete or confusing voice commands. The assistant seems to doa solid job asking additional questions back to the user in order to determine the right actions to take.\n\nOne of the coolest capabilities of platforms such as Cortana, Alexa and Google Assistant is their ability to incorporate new skill\u2019s logic via serverless computing functions delivered by platforms such as AWS Lambda or Azure Functions. Samsung\u2019s serverless computing skills are very limited compared to its competitors and that could have an impact of Bixby\u2019s long term evolution.\n\nanother limitation of Bixby is the absence of an open NLP-AI platform similar to Microsoft LUIS or Google\u2019s API.ai which can be used to implement sophisticated conversational interactions and add new skills that can be trained and improved over time.\n\nTechnologies such as Cortana, Alexa or Google Assistant not only count with robust NLP capabilities but with a suite of cognitive services in relevant areas such as image processing, speech translation or video analytics. Samsung has some catch up to do in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ambiguity-in-natural-language-processing-part-ii-disambiguation-fc165e76a679?source=user_profile---------257----------------",
        "title": "Ambiguity in natural Language Processing Part II: Disambiguation",
        "text": "In the first part of this essay, we discussed some of the key characteristics of ambiguity in natural language processing(NLP) systems. Considered one of the most challenging aspects of NLP solutions, ambiguity encompasses a borad spectrum of forms from lexical and semantic ambiguity to more complex structures such as metaphors. Handling ambiguity requires sophisticated NLP techniques but is also an essential capabilities of robust conversational applications.\n\nIn artificial intelligence(AI) theory, the group of techniques used to handle ambiguity is known as disambiguation. From a conceptual standpoint, disambiguation is the process of determining the most probable meaning of a specific phrase. Typically, disambiguation leverages statistical model to reflect the probabilities of an assertion. Even though it sounds very simple, the algorithms that deal with disambiguation are some of the most complex areas in NLP applications. In order to be effective, disambiguation techniques should combines knowledge from the following types of models:\n\n\u2014 World Model: This type of knowledge reflects the probability of a specific utterance based on global knowledge of the world. For instance, if we say \u201cJohn\u2019s ears are burning\u201d. we should infer that somebody was speaking about John rather than John catching fire.\n\n\u2014 Mental Model: This type of knowledge reflects the probability of the speaker intentions of communicating a known fact in the context of a specific conversation. For example, in a dialog about baseball, if we say \u201cthe pitcher was painting the corners\u201d. the model will assume that the pitcher was effectively throwing strikes rather than painting a window.\n\n\u2014 Language Model: This type of knowledge express the likelihood that certain strings of words will be chosen considering the speaker\u2019s intentions. Language models use advanced linguistic analysis in order to infer the correct meaning of an utterance.\n\n\u2014 Acoustic Model: This type of knowledge is very similar to the language model for it focuses on spoken communications and factors in aspects such as accents, sentiments and many other relevant elopements of audio communications.\n\nSome Best Practices to Deal with Disambiguation\n\nMost modern NLP stacks include sophisticated, general-purpose disambiguation techniques. However, AI agents should contribute to the disambiguation knowledge in their specific domain. Some of the following ideas are relevant to deal with disambiguation:\n\n\u2014 Context, Context, Context: In order to be effective, disambiguation processes require rich contextual information about a conversation. Actively populating contextual metadata throughout the different stages of a conversation is essential to handle ambiguity.\n\nGlobal vs. Domain Specific Disambiguation: While NLP stacks are very effective interpreting utterances using global knowledge, AI agents should complement that ability with domain specific disambiguation models that include knowledge of specific industries, ethnic group, etc.\n\n\u2014 Continuous Training: There is no more effective way to handle ambiguity that the continuous training of AI agents. Recording ambiguous utterances from part conversations with users and using them as a training data source is an effective way to handle ambiguity in the long term."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-black-swan-in-artificial-intelligence-part-ii-9a6fe28c023f?source=user_profile---------258----------------",
        "title": "The Black Swan in Artificial Intelligence Part II \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, I published the first part of this article that focuses on the implication of random events in artificial intelligence(AI) models. Specifically, we focused on mega-random events known as Black Swans that share three key characteristics:\n\n1 \u2014 The are random-outlier phenomenon\u2019s from the perspective of regular knowledge.\n\n3 \u2014 Despite their randomness, we try to find a retrospective explanation or even predict similar events in the future.\n\nThe first part of this essay focused on the relevance and impact of Black Swans on AI systems. This part presents some ideas and best practices that can help AI agents to perform in a Black Swan ecosystem.\n\nFrom the perspective of AI systems, a Black Swan is a random event that falls outside the realm of knowledge of a trained AI agent. However, that definition doesn\u2019t necessarily entails that Black Swans will have a negative impact on AI systems. Random events that unveiled the discovery of a new drug or a new profitable trading strategy can have massively positive consequences. In an ideal scenario, AI agents should maximize their resiliency to negative Black Swans while also optimizing its exposure to positive Black Swans. Sounds simple, doesn\u2019t it? ;)\n\nIs Not All About Resiliency\n\nResiliency or robustness should be an architecture principle of any software system, not just AI agents. However, in the case of AI, we are not only referring to resiliency in the form of infrastructure or software errors but in the from of new knowledge and behavior that challenges the universe an AI agent. From that standpoint, AI agents need to be able to contain negative behavior influenced by unexpected forms of knowledge created by Black Swans.\n\nResiliency is not the only aspect to consider when designing AI agents in pro Black Swan environments. Absorbing new forms of knowledge and spotting positive side effects from unexpected events is also essential in order to benefit from positive Black Swans. However, how does that translate into specific AI techniques? Let\u2019s explore a few ideas that might help when designing AI systems in environments propense to Black Swans.\n\nI like competitive neural networks because they automatically introduce friction in an AI system. Using AI techniques such as competitive neural networks to challenge the knowledge pf AI agents could start automatically building resilient behaviors into the systems which will make it more likely to survive negative Black Swans.\n\n2 \u2014 Leverage Continuous Unsupervised or Semi \u2014 Supervised Analysis on New Knowledge\n\nTo be exposed to positive Black Swans, AI agents should be able to acquire new forms of knowledge and identify its positive effects on areas of the environment. In many supervised models, that exposure to new knowledge is constrained to new training data which, by definition, does not factor in Black Swans. To address that limitation, AI agents could leverage unsupervised or semi-supervised that continuously evaluate new knowledge and identify positive effects.\n\nMost knowledge and hypothesis built into AI systems is communicated via fixed training data sets. However, remember that, in Black Swan environments, what you don\u2019t know is often as important as what you know. Knowledge by subtraction is a cognitive technique that allow us to form new knowledge by negating some of our current hypothesis. For instance, suppose we train an AI agent on a hypothesis that bonds are an effective hedge mechanism for stocks (bonds tends to go up when stocks go down and vice versa). Our AI agent will start trading under market conditions that support our hypothesis but suddenly will encounter one of the many events in financial markets that could cause both stocks and bonds to go up or down simultaneously. By encountering that single event, our AI agent should be able to build new knowledge that negates its original hypothesis. That technique is called knowledge by susbtraction.\n\nIn cognitive theory, knowledge by subtraction is one of the most effective forms of knowledge. While our AI agent might need infinite observations to validate the original hypothesis that bonds can hedge stocks, a single observation is sufficient to disprove it. By being exposed to knowledge by subtraction, AI agents can be more resilient to negative Black Swans and prone to benefit from positive Black Swans."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-the-enterprise-market-for-digital-assistants-a0939482765e?source=user_profile---------259----------------",
        "title": "Some Thoughts About the Enterprise Market for Digital Assistants",
        "text": "Digital assistants(DA) are becoming an important part of our everyday lives and are steadily becoming part of out business life as well. Recently, I was watching some examples about how devops are using Amazon Alexa to automate the provisioning and management of AWS assets via voice commands and couldn\u2019t avoid thinking about the market potential for this type of enterprise DA solutions in the short term.\n\nDon\u2019t take me wrong. If you read this blog you know I\u2019ve been actively exploring the technical and, let\u2019s say, somewhat philosophical aspects of DA voice interfaces in the enterprise. However, being bullish about the technology and understanding the avenues that will guide the evolution of that market in the short term are two different things. Following that train of thought, I would like to explore some ideas about the challenges and opportunities of DA solutions in the enterprise.\n\nCan DAs Become a Relevant Runtime in the Enterprise?\n\nFollowing the web and mobile movements, DAs and messaging platforms are called to become the new runtime of choice of the new generation of applications. For people actively exploring this space, the more interesting question is to try to determine whether the trend will translate into a large enterprise market.\n\nTo illustrate my point, let\u2019s look at the two most immediate predecessors of DA runtimes: mobile and web. Web development completely transformed the enterprise by creating an entire generation of successful companies and multi-decade technology movements. However, we can\u2019t quite say the same thing about enterprise mobile solutions. While mobile apps are certainly relevant in the corporate world, the promise of the mobile-first enterprise didn\u2019t quite materialize. From the market perspecitve,even though some movement within the mobile space such as security and mobile device management(MDM) were certainly successful , the number and market capitalization of enterprise mobile companies is certainly a fraction of its web predecessor.\n\nUsing that analogy as a reference, we should question whether DA solutions are going to become as transformational as the web or as, let\u2019s say, semi-transformational as mobile apps in the enterprise.\n\nHaving discussed the challenges, I would now like to explore some key opportunities for DA solutions in the enterprise:\n\nBring your own digital assistant(BYODA) to work could become the next evolution of the BYOD movement in the enteprrise. Qs DAs become more prevalent in our lives, it is expected that employees will discover and start using their own bots for business scenarios and organizations will need to remain responsive to those requirements. Platforms that automate the onboarding, security and management of multi-DA work environments are an interesting opportunity in the enterprise.\n\nSimilarly to mobile business apps, there is a market for bots that automate common business tasks. It is also expected that SaaS platforms will start providing bots and DA skills as part of their distributions.\n\n3 \u2014 Multi-DA Platforms: Can you imagine the nightmare of building different versions of a DA solution for heterogeneous runtimes such as Alexa, Cortana, Google Asisstant or Siri (at some point) ? I believe there is an opportunity for development platforms that enable the implementation of bots across different DA runtimes.\n\nWithout a doubt, enterprise DA solutions will require a new type of analytics that factors in aspects such as sentiment analytics, language session, engagement and many other relevant metrics that have no equivalent on the current generation of app monitoring platforms. DA analytics could become a very strong trend in the enterprise\n\n4 \u2014 Security: Voice-based authentication to corporate systems, access control, SSO, identity management, data privacy are some of the security capabilities that might be required in enterprise DA solutions. Security is a robust are of opportunity in the enterprise DA space.\n\nThese are my top five opportutnies in the nascent enterprise DA space. Other interesting segments include: integration, testing, discovery and distribution. Certainly the enterprise DA market is very young but is already showing strong signs of excitement."
    },
    {
        "url": "https://medium.com/@jrodthoughts/strategic-alliances-and-the-battle-for-the-chinese-cloud-d41a966b3344?source=user_profile---------260----------------",
        "title": "Strategic Alliances and the Battle for the Chinese Cloud",
        "text": "China is one of the battlegrounds of the modern could computing markets. From US incumbents trying to penetrate the Chinese market to local cloud companies becoming more relevant at an international scale, the battle for the China cloud market is nothing short of fascinating.\n\nA few das ago, IBM announced a partnership with Wanda Group to bring IBM cloud services to China. The partnership presented some important clues about the strategies to developed the Chinese cloud market. Today, I would like t o present a few speculative ideas about other strategic models that we might seen in the near future.\n\nFor years, the Chinese Cloud market can be described as a constant friction between US and Chinese companies. While US cloud incumbents have struggled to make inroads in China, a new generation of Chinese cloud companies have been steadily gaining traction in the local market. At the same token, most Chinese cloud vendors have struggled to gain any relevant traction internationally.\n\nCurrently, Alibaba Cloud (also known as Aliyun) dominates the cloud market in China and is growing at an incredibly fast pace ( see my previous article about Aliyun). Other companies such as Huawei an China Telecom have also produced relevant offers in the space. In addition to Alibaba, the other dominant forces of the China software market: Baidu, Xiaomi and Tencent haven\u2019t been that active in the cloud platform space.\n\nKnowing the current context of the China cloud market, we can start speculating about some potential strategic alliances that might make sense in the near future.\n\nAs mentioned before, last week IBM announced a partnership with Wanda Group to provide its cloud services in China. The cloud infrastructure will be delivered as part of Wanda cloud data centers. The partnership will form a new entity called Wanda Cloud Company that will share its revenue with IBM.\n\nThe partnership represents the cornerstone of IBM\u2019s cloud strategy in China and certainly an important milestone for the Chinese cloud market. We should expect that this agreement could trigger similar moves by IBM\u2019s competitors.\n\nIn a previous article about Aliyun,I speculated about a potential Google-Alibaba alliance to dominate the Chinese cloud market while also expanding Aliyun\u2019s presence in the US. Currently, Google Cloud desperately needs to establish a solid presence in China in order to keep up with competitors such as Amazon and Microsoft as well as to better support the cloud operations of some high profile customers such as Snap. A potential partnership with Google Cloud could also drastically expand Aliyun\u2019s technical capabilities to make it more competitive with Azure and AWS and it will help to expand its presence and traction in the US market. As I mentioned before, the idea is highly speculative at this point.\n\nAmazon and Microsoft Go an on Cloud Acquisition Spree\n\nAWS and Azure have been able to establish a successful presence in China but its share of the market remains relatively small. To shift that balance, we can expect Microsoft and Amazon to expand its footprint in China by acquiring popular Chinese cloud services startups and rolled into Azure and AWS respective offerings. Similarly, Microsoft and Amazon could explore strategic alliances with some of other moving forced in the China software market such as Baidu, Tencent and Xiaomi."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ambiguity-in-natural-language-processing-15f3e4706a9a?source=user_profile---------261----------------",
        "title": "Ambiguity in Natural Language Processing \u2013 Jesus Rodriguez \u2013",
        "text": "Ambiguity is an intrinsic characteristic of human conversations and one that is particularly challenging in natural language understanding(NLU) scenarios by ambiguity, w are essentially referring to sentences that have multiple alternative interpretations.\n\nAmbiguity is one of those areas of cognitive sciences that doesn\u2019t have a well-defined solution. The spectrum of what can be considered ambiguous on any language varies greatly depending on the speaker. From a technical standpoint, any sentence in a language with a large-enough grammar can have alternative interpretations. However, most native speakers only recognize the primary interpretation when hearing a phrase while alternative representations may be more obvious to non-native speakers whom, cognitively speaking, need to rewire their brains in order to lean a new language. If humans find it difficult to deal with ambiguity in conversations, just imagine the challenge for NLU systems.\n\nTechnically defining ambiguity can, well, ambiguous. However, there are different forms of ambiguity that are relevant in natural language and, consequently, in artificial intelligence(AI) systems.\n\nLexical Ambiguity: This type of ambiguity represents words that can have multiple assertions. For instance, in English, the word \u201cback\u201d can be a noun ( back stage), an adjective (back door) or an adverb (back away).\n\nSyntactic Ambiguity: This type of ambiguity represents sentences that can be parsed in multiple syntactical forms. Take the following sentence: \u201c I heard his cell phone rin in my office\u201d. The propositional phrase \u201cin my office\u201d can e parsed in a way that modifies the noun or on another way that modifies the verb.\n\nSemantic Ambiguity: This type of ambiguity is typically related to the interpretation of sentence. For instance, the previous sentence used in the previous point can be interpreted as if I was physically present in the office or as if the cell phone was in the office.\n\n\u2014 Metonymy: Arguably, the most difficult type of ambiguity, metonymy deals with phrases in which the literal meaning is different from the figurative assertion. For instance, when we say \u201cSamsung us screaming for new management\u201d, we don\u2019t really mean that the company is literally screaming (although you never know with Samsung these days ;) ).\n\nMetaphors are a specific type of metonymy on which a phrase with one literal meaning is used as an analogy to suggest a different meaning. For example, if we say: \u201cRoger Clemens was painting the corners\u201d, we are not referring to the former NY Yankee star working as a painter.\n\nMetaphors are particularly difficult to handle as they typically include references to historical or fictitious elements which are hard to place in the context of the conversation. From a conceptual standpoint, metaphors can be seen as a type of metonymy on which the relationship between sentences is based on similarity.\n\nIn AI theory, The process of handling ambiguity is called disambiguation . Those techniques are very challenging to handle with the current generation of AI technologies. I would cover more on that topic on a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bitcoin-i-being-challenged-by-recent-market-events-b459bdc0429c?source=user_profile---------262----------------",
        "title": "Bitcoin I Being Challenged By Recent Market Events \u2013 Jesus Rodriguez \u2013",
        "text": "Bitcoin has lost over a fifth of its value in the last few days. After trading at a near all time high of $1300, Bitcoin value fell to $970 over the weekend. The crypto-currency seems to be going through a tough time as a series of market events are colliding causing negative effects on its valuation and trading volume.\n\nFrom developments by regulatory authorities in the US and China to a never ending technical argument in the developer community, Bitcoin is experiencing severe challenges on different fronts. The drop on the price of Bitcoin seems to be more than a mere correction and the platform has certainly shown a lot of fragility and vulnerability to those type of market events. The change of value and volatility confirms that there is still a lot of work to be done stabilizing the crypto-currency as a tradable asset.\n\nLast week, the Securities and Exchange Commission passed a harsh judgment on Bitcoin by rejecting the proposal to create an exchange traded fund(ETF) for the digital currency( read my previous article about this topic). The SEC cited potential fraud and market manipulation as some of its arguments against the ETF proposal.\n\nAn approval for a Bitcoin-based ETF by the SEC would have been a tremendous validation for Bitcoin and it would have allowed institutional investors to trade the crypto-currency. Additionally, as I reflected on a previous article, Bitcoin would have benefited from more sophisticated trading strategies and the correlation with other tradable assets. Just a few hours after the SEC decision, the price of Bitcoin dropped about 15% to about $1050.\n\nDuring the weekend, China\u2019s central bank circulated new guideline to regulate Bitcoin exchanges. The guidelines dictate that Chinese Bitcoin exchanges could be subjected to anti-money laundering and banking laws. Additionally, the document indicates that Chinese Bitcoin exchanges could be required to disclose and verify the identities of its clients. The guidelines are a continuation of the Chinese government crackdown on Bitcoin exchanges operating in that country which has been causing a lot of concern among investors and is having a material impact on the market.\n\nA couple of months ago, Yuan-based Bitcoin trades accounted for 97% of the global volume. However, after authorities got involved, the volume has dropped to about 17% while Dollar-based trades rose to about 50% from 1.4% and Yen-based trades got to 15% from 1%. One thing is for certain, we haven\u2019t seen the latest of the influence of the Chinese governments on the price of Bitcoin.\n\nA two year old disagreement between Bitcoin developers continues to regularly impact (both positively and negatively) the price of the digital currency. The argument is related to the size of an atomic batch of transaction that gets processes by the Bitcoin network (also known as a block). Currently, Bitcoin restricts the size of a block to 1MB and which is causing some serious challenges in terms of the scalability of the network. Part of the Bitcoin community has come up with a clever solution known as bitcoin Unlimited that increases the size of a block. However, there is another important group in the community that continues defending the current model (known as Bitcoin Core).\n\nWhy is this is a big deal for the price of Bitcoin? Well, the main threat to the price of Bitocin is that the arguments between the two groups have come close to cause a \u201chard-fork\u201d of the Bitcoin code effectively creating two versions of the network which will immensely complicate its tradability."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-intel-mobileye-deal-and-the-frenzy-of-automotive-tech-m-a-6ff075d4d4f7?source=user_profile---------263----------------",
        "title": "The Intel-Mobileye Deal and the Frenzy of Automotive Tech M&A",
        "text": "A few days ago, Intel shocked the market by announcing the $15 billion acquisition of Mobileye, a darling of the auto-tech industry . Born in Israel, Mobileye developed a camera based software that has been widely adopted by car manufacturers. The acquisition event was not as surprising as the price. $15 billion is not only a ridiculous multiple of Mobileye\u2019s forward earnings but it also represents Intel\u2019s second biggest M&A deal after the acquisition of Altera a couple of years ago. The acquisition is a confirmation of the favorable climate for auto-tech M&A investments.\n\nIntel\u2019s acquisition of Mobileye is hardly the first high profile M&A deal in the auto-tech market. Qualcomm (Intel\u2019s biggest rival) recently spent $39 billion on the acquisition of NXP Semiconductors, a chip manufacturer widely used in vehicle telematic systems. Speaking of telematics, Samsung recently bought Harman International for $8 billion, clearly signaling to the market that they intend to be a contender in the auto-tech market. Siemens is another software powerhouse that has been an active acquirer in the auto-tech market. The company recently bought Mentor Graphics Corp which produces design software for automotives. Uber also acquired Otto recently for its self-driving vehicle technologies which have sparked a law suit by rival Alphabet\u2019s Waymo.\n\nBig tech companies are not the only acquirers in the auto-tech space. Car manufacturers have also been incredibly active. Just to list a few examples: Ford has acquired several auto-tech companies such as ArgoAI or SAIPS. Toyota also recently acquired the team behind Jaybridge Robotics which develops self-driving vehicle technologies Similarly, GM bought Cruise Automation to expand its advance auto-tech capabilities.\n\nAcquisition has not been the only financial channel available to auto-tech companies. Corporate strategic investments dollars are also flying fast into the sector. Leading the way im obviously, GM and Toyota with their monster investment in Lyft and Uber respectively but there are plenty of more relevant examples. Companies such as BMW and VW recently invested in Chargepoint to help develop fast-charging networks. Ford has not only been an active acquirer bt also an aggressive investors with positions in companies such Velodyne.\n\nAt the center of the auto-tech revolution we have Alphabet\u2019s Waymo. The company has been aggressively expanding its strategic deals in the space. The most notable example is the partnership with Fiat Chrysler which opted to outsource its self-driving technology program to the Waymo. The Alphabet subsidiary is also uniquely positioned to become the most universal auto-tech provider in the market but it will definitely face strong competition on several fronts."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-black-swan-problem-in-artificial-intelligence-part-i-74306aee0156?source=user_profile---------264----------------",
        "title": "The Black Swan Problem in Artificial Intelligence: Part I",
        "text": "The Black Swan is one of the most fascinating problems in modern cognitive theory. The term was coined by one of my favorite authors: Nassin Nicholas Taleb in its best seller book of the same title. The rapid emergence of artificial intelligence(AI) has drastically increase the relevance of the Black Swan problem in the context of AI systems.\n\nIn a nutshell, Black Swan are random and unexpected phenomenon that carry a big or disproportional impact. Examples of Black Swans are all around us: September 11 2001, the publication of a mega-best-seller by an unknown author, the emergence of Facebook, the demise of Long Term Capital Management are some notorious examples of Black Swans. In his book, Taleb uses three basic axioms to describe a Black Swan:\n\n1 \u2014 Black Swans are outlier phenomenon from the perspective of regular expectations.\n\n3 \u2014 After the Black Swan takes place, we try to rationalize an explanation for it and even venture to plan and predict its next occurrence.\n\nFrom Taleb\u2019s perspective, human history can be almost explained as a sequence of a relatively small number of Black Swans. From an environmental perspective, Black Swan can yield positive (Facebook) or negative( 9/11) results but always carrying an extreme change in the environment around it.\n\nAs a cognitive phenomenon, Black Swans are extremely important in the design and evolution of AI systems. AI is based on human knowledge and no events affect and evolve human knowledge as Black Swans,\n\nTrying to understand the role of Black Swans in AI, I\u2019ve divided this essay into two main parts: this post covers some of the important characteristics of AI Black Swans while the following post will explore some potential best practices to design AI systems that can cohabit in Black Swan environments.\n\nIf we go back to the three key characteristics of Black Swans: rarity, extreme impact and retrospective predictability, it is easy to spot some concepts that are relevant in AI systems.\n\nBlack Swans, by definition, are based on and create uncertainly. The current generation of AI techniques is fundamentally based on the certainty of knowledge. The human brain has a remarkable ability to adapt to uncertainly but that capability doesn\u2019t have yet materialized in AI models. How can we best design AI systems that handle uncertainty? A good starting point is to always assume that the rules we design for the knowledge of an AI agent are never complete and that what the knowledge we don\u2019t posses at the time is equally important that the knowledge we have. In other words, What we don\u2019t know matters as much as what we know.\n\nBlack Swans raise the importance of knowledge models in AI systems to another level. By definition, AI agents will not be able to predict Black Swans but we can do a better job building knowledge models that account for extreme and relatively unknown circumstances. Many cognitive experts refer to this term as antiknowledge.\n\nIn the context of AI, Black Swans confirm the importance of unsupervised learning models. Even though supervised techniques are prevalent today, the future of AI relies on unsupervised models. In a Black Swan world, we should not only focus on AI models that are more resilient to that phenomenon but that can also learn and even benefit from positive Black Swans. More about that in a future post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/apache-apex-is-an-intriguing-addition-to-the-stream-data-processing-market-5f0032dbd1b2?source=user_profile---------265----------------",
        "title": "Apache Apex is an Intriguing Addition to the Stream Data Processing Market",
        "text": "The stream analytics and data processing market seems to have become incredibly crowded in the last few years. Everywhere we look there seem to be newer and popular technologies for implementing stream data computation applications. Just within the Apache foundation, the number of stream data processing platforms seems to have grown out of control: Strom, spark Streaming, Flume, Samza, Flink Streaming are some of the most popular stream computation frameworks that have been well received by the customer and developer communities.\n\nRecently, I started learning more about Apache apex, yet another Apache-based, stream data computation platform. Based on Hadoop YARN, Apache Apex might, on the surface, seem like another addition to an already crowded space. However, Apex seems to have made the necessary investment and taken the required steps to catalyze its mainstream adoption in complex environments.\n\nOne of the main challenges developers and businesses face when evaluating stream data processing platforms, is the complexity that many of those stack introduce when implemented at scale. While most stream analytic technologies have done a remarkable job providing really innovative stream data processing capabilities, many are still lacking the programming model simplicity and the toolset to be adapted by mainstream developers. this is where Apache Apex excels at. The Apex platform seems to have taken into account the aforementioned challenges by providing a very simple programming model and infrastructure for the implementation of stream analytic solutions.\n\nAt the core of apache Apex we have the Malhar framework, an open source library that includes connectors, parsers, stream manipulation and computation routines that can be assembled into really sophisticated stream data processing applications. Apex Malhar includes connectors to common databases, messaging platforms and line o business systems while also supporting multiple transport and messaging protocols. In addition to its integration capabilities, Malhar includes stream data computation primitives such as JOIN, GROUP BY, LIMIT, ORDER BY and dozens of others that can be combine to enable the real time processing of data streams. Malhar also provides data manipulation, statistics, filtering and pattern matching routines that are relevant in sophisticated stream analytic solutions.\n\nApache Apex developers can leverage the straightforward programming model across several programming languages such as JavaScript, Python, Ruby or R. Ultimately, Apex models applications using a direct acyclic graph(DAG) representation in which nodes represent individual routines. The flexibility of this data structure enables the use of Apex in arbitrarily complex stream data processing scenarios.\n\nAnother aspects that contributes to the growing popularity of Apache apex is its architecture based on Hadoop YARN. The YARN model allow Apex applications to scale linearly across tens of thousands ot nodes while enjoying capabilities such as fault tolerance, data partitioning or processing guarantees without having to invest on a proprietary infrastructure.\n\nA robust stream data computation framework, a simple programming model, integration with mainstream systems and a widely adopted infrastructure are some of the strategic elements contributing to the rapid adoption of Apache Apex. As mentioned before, stream analytics is an incredibly crowded space but Apex is certainly an intriguing addition to it."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-video-intelligence-api-is-a-major-milestone-for-the-ai-space-cf9ea73c4fc7?source=user_profile---------266----------------",
        "title": "Google Video Intelligence API is a Major Milestone for the AI Space",
        "text": "Google Cloud is really committed to make artificial intelligence(AI) the foundational piece of its next generation services. A few months ago, Google Cloud had little or no capabilities in the AI space. Now, in just a few months, Google Cloud has launched a series of AI and machine learning(ML) services that are making the cloud platform some of the top contenders in the market. Last week during its Cloud Next Conference, Google announced a new addition to its cognitive AI stack with the release of the Video Intelligence API.\n\nThe availability of a Video AI API represents a major milestones for Google for a couple of reasons. For starters, the new API could become a robust differentiator with competitors such as Microsoft Cognitive Services or Watson Developer Cloud that have limited or no video intelligence capabilities at the moment. Secondly, Google Video Intelligence API represents an initial step on what could be one of the biggest markets for mainstream AI capabilities. Notice that I\u2019ve used the term mainstream because, even though there have been a lot of practical video AI capabilities (noticeably self-driving cars or airport surveillance ) there haven\u2019t been available to mainstream developers. The general availability of technologies such as Google Video Intelligence API can open the door to one of the biggest AI markets known until this point.\n\nThe mainstream availability and richness of content of video data sources creates an ideal environment of the proliferation of video AI capabilities such as the ones provided by Google Video Intelligence API. However, the unique characteristics of video analytic scenarios make this space equally exciting and challenging. To clarify some of these ideas, let\u2019s explore some of the video AI techniques and capabilities that could be soon included as part of Google Video Intelligence API or competitive offerings.\n\nRecognizing objects in video sequences is one of the most straightforward video AI techniques. This capability has been the core focus of Google\u2019s new Video Intelligence API. Some of the interesting scenarios addressed by this feature include object search video cataloging, etc.\n\nVideos, differently from images, include enough data points to detect intentions or actions of objects in the video. For instance, a Video AI API analyzing a bank branch could identify relevant situations such as person extracting cash from an ATM or a customer who has been waiting in line for a long time.\n\nVideo AI techniques can also enable sentiment analysis capabilities similar to those used in text analytic stacks. A Video AI system could process streams from a casino cameras and determine whether players on a poker game are anxious, happy or acting suspiciously.\n\nVideo AI models can be used to predict and calculate the actions of objects in a video feed. Let\u2019s use a self-driving car scenario on which a car can determine if another vehicle is changing lanes or if a pedestrian is crossing the road.\n\n5 \u2014 Bringing it all Together\n\nVideos, more than any other cognitive data source resembles real life environments. Video data sources combine information in the form of audio ,text and, of course, video. As a result video AI capabilities orchestrate many AI capabilities such as image processing, speech recognition, natural language and many others. More about this in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-taxonomy-of-the-enterprise-ai-market-aef721daabff?source=user_profile---------267----------------",
        "title": "A Taxonomy of the Enterprise AI Market \u2013 Jesus Rodriguez \u2013",
        "text": "In the past, I\u2019ve written extensibly about the enterprise artificial intelligence(AI) space analyzing some of the key vendors and platforms. Today, I would like to explore the different categories of technologies that are relevant in the enterprise AI market.\n\nThe raising popularity of AI technologies have created an incredibly crowded ecosystem of products and platforms. However, the number of categories on which enterprise AI products can be grouped remains relatively small. This article provides a taxonomy that covers the main types of AI products that are actively evaluated by enterprises. Similarly, if you are a startup or a venture capitalist in the enterprise AI space, most likely your products or technologies will fall into one of these categories. Let\u2019s take a look.\n\nAI cognitive service cloud platforms are a popular choice for enterprise as they provide a relatively low entry point to leverage very sophisticated AI capabilities in areas such as vision, speech or natural language processing. Platforms such as Watson Developer Cloud, Microsoft Cognitive Services, Google AI Services or AWS AI APIs are dominating this category but there is plenty of room for startups that provide differentiated capabilities in the space.\n\nPlatforms that enable the implementation and management of machine learning(ML) models are also gaining traction in the enterprise. These offerings go beyond the simple creation of ML models by providing robust infrastructure and toolset required to manage the lifecycle of ML solutions. Platforms such as H2O.ai as well as cloud services such as AWS ML, Azure ML or Google Cloud ML are relevant products in this area.\n\nR remains one of the most popular languages for implementing advanced statistical and ML solutions in the enterprise. In that context, many enterprises have been able to nurture and acquire R engineering talent. As a result, R distributions are a relatively simple entry point into enterprise AI strategies. Microsoft R Server, H2O.ai and the popular R Studio are solid offerings in the space.\n\nEmpowering data scientists with tools for authoring and creating AI models is a top priority in enterprise environments. While legacy tools such as SAS are still dominant in this space, there is an emerging ecosystem of platforms such as Jupyter, Zepelling or Google Cloud DataLab that are gaining traction in the enterprise.\n\nThis might sound like a subcategory of the previous ones but the market opportunity is big enough that s deserves its own group. Enterprise distributions of deep learning frameworks such as TensorFlow, Caffe, Theano and others will be essential to streamline the adoption of deep learning capabilities in the enterprise. While cognitive cloud APIs are a great option for enabling well-known and relatively simple deep learning models, open frameworks are often required to implement custom models for more sophisticated scenarios. As a result, there is an interesting opportunity for startups that enable enterprise distributions of some of the most popular deep learning frameworks in the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-ai-lessons-from-watsons-failure-at-md-anderson-9b895cf70840?source=user_profile---------268----------------",
        "title": "Some AI Lessons from Watson\u2019s Failure at MD Anderson",
        "text": "Last week, The Wall Street Journal(WSJ) broke a story about the failure of a $62 million implementation of IBM Watson at the University of Texas MD Anderson Cancer Center. The reasons outlined in the article don\u2019t question the capabilities of the Watson platform but rather the inability to developer the project by a joined team of MD Anderson specialists, IBM and Pwc engineers.\n\nAccording to the report, the goal of the project was to build an Oncology Expert Advisor( OEA) that will improve recommendations about cancer care and treatment options. OEA was supposed to integrate with MD Anderson electronic medical records(EMR) as well as medical literature in order to build knowledge that feeds the AI models.\n\nThe WSJ article describes that the project was initially focused on leukemia treatments but MD Anderson decided to shift the attention towards lung cancer in the middle of the project. According to an audit conducted by the University of Texas System Audit Office, MD Anderson paid about $39 million in fees to IBM and another $23 million to Pwc for implementation services. The audit declared the project \u201cnot ready\u201d citing challenges integrating with EMR systems as well as outdated records. In an unrelated event ;) MD Anderson President Ronald Dephino resigned last week.\n\nThe objective of this post is not to criticize the failure of the Watson implementation at MD Anderson. The project was nothing short of ambitious with ambition come risks. These type of failures should be expected in a new and challenging discipline like AI on which traditional corporate IT teams lack knowledge and expertise. However, there are some interesting lessons about AI projects that can be extrapolated from the MD Anderson experience. For starters, the project highlighted how advanced AI technologies need to be accompanied by solution delivery methodologies, techniques and processes in order to ensure the delivery to real world AI solutions. In the case of MD Anderson, it seems that Watson\u2019s technical capabilities were far ahead and disconnected from the other aspect of the solution.\n\nPractical Lessons About AI Projects We Can Learn from the MD Anderson Experience\n\nThe MD Anderson audit repeatedly refers to outdated data as one of the main roadblocks of the project. This challenge highlights the importance of incorporating data curation and quality processes as part of AI projects. Modern data quality platforms such as Trifacta, Tamr or Paxata should be considered in these efforts.\n\nThe MD Anderson experience shows the importance of streamlining the integration of AI platforms and back office systems. Interoperability with modern ETL-ELT platforms should be considered as an important aspect of the implementation of AI solutions.\n\nAI projects are notoriously long and complex but 4 years and $62 million before detecting a problem seems a bit overkill. Aligning the new generation of AI platforms with established lean and continuous delivery methodologies. should help in this area.\n\nEstablishing the mechanisms to regularly train and validate the performance of AI models is an essential and often ignored aspect of AI solutions. The MD Anderson project clearly shows the importance of incorporating training and monitoring tools and processes as part of the AI solution delivery lifecycle."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-the-watson-einstein-partnership-4ec5b0e49f23?source=user_profile---------269----------------",
        "title": "Some Thoughts About the Watson-Einstein Partnership",
        "text": "Einstein and Watson partnering sounds like the trainer of a bad scifi movie. However, the alliance is taking place in the artificial intelligence(AI) space. A few days ago, IBM and Salesforce announced a strategic partnership to integrate their AI platforms (Watson and Einstein respectively) as well as complementary software and services.\n\nThe AI agreement also includes IBM\u2019s deployment of Salesforce;s Service Cloud to address its customer support requirements. Even though the AI partnership might have surprised a few considering that IBM and Salesforce are perceived as competitors in the AI space, it makes a lot of sense from a strategic standpoint. However, to understand the implications of the Einstein-Watson strategic alliance, we should look beyond the general statements in the press release eand into the strategic roadmap of both AI platforms.\n\n5 Things to Consider About the Watson-Einstein Partnership\n\n1 \u2014 Just Like in IOT, Salesforce Opts to Partner vs. Building\n\nThe partnership with IBM is another example of Salesforce\u2019s strategy to partner with a top PaaS providers in highly strategic areas instead of investing on building its own capability. About a year ago, Salesforce announced a similar agreement with AWS IOT in order to incorporate its capabilities into the Salesforce IOT Cloud. Now Salesforce follows the same pattern by partnering with IBM Watson after announcing the release of Einstein.\n\nFrom those two strategic moves, we can conclude that Salesforce is having a tough time keeping up with PaaS rivals such as Azure, AWS, Bluemix or Google Cloud on horizontal cloud services capabilities. Instead, Salesforce seems to be focusing on building higher level cloud business services and partnering with other PaaS to supplement the underlying technical infrastructure.\n\nFrom an AI standpoint, Einstein is the main beneficiary of the partnership. By leveraging Watson, Einstein will have access to a complete suite of cognitive services in areas such as speech, voice, vision and knowledge which would have, otherwise, been hard to build from the ground up by Salesforce.\n\n2 \u2014 Adoption is the Main Benefit for Watson\n\nBy partnering with Salesforce, IBM should expect a major increase on the adoption of Watson\u2019s capabilities within Salesforce\u2019s large customer base. The partnership is certainly a strong commercial validation for Watson that continues executing better than competitors.\n\nWhen comes to SaaS, Salesforce pretty much controls the direction and pace of innovation of the market. The strategic alliance with Watson offers Salesforce the ability to innovate and move faster than competitors in the AI space. As a result, we should expect other top SaaS vendors to establish similar strategic alliances with vendors such as Microsoft, Amazon, Google or even IBM to match Salesforce\u2019s capabilities.\n\nWatson continues outperforming competitors when comes to market adoption.,. The partnership with IBM is likely to yield big adoption adoption numbers for Watson. As a result Watson competitors such as Google, Amazon or Microsoft might look to establish similar alliances with Salesforce\u2019s competitors such as WorkDay, Oracle, SAP among others. In that area, Microsoft and Google can leverage Ofice365 and G-Suite as an important channel to drive adoption of their respective cloud AI platforms."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-implications-of-the-bitcoin-etf-decision-112717033872?source=user_profile---------270----------------",
        "title": "The Implications of the Bitcoin ETF Decision \u2013 Jesus Rodriguez \u2013",
        "text": "This could be a pivotal week for Bitcoin. The Security and Exchange Commission(SEC) is due to decide this week whether to green light a new Bitcoin Exchange Traded Fund(ETF). The decision could provide the crypto-currency with a robust regulatory framework and provide investors with an easier access to Bitcoin assets.\n\nThe specific ETF being evaluated is the Winklevos Bitcoin Trust(WBT) ran by Cameron and Tyler Winklevos. The twin brothers came to mainstream notoriety based on their controversial role in the early days of Facebook. In a great second act, the twins have become two of the most prominent thought leaders, champions and investors in the Bitcoin space. they have invested on several relevant Bitcoin startups and also own a Bitcoin exchange Thee potential green light of WBT by the SEC will consolidate the Winklevos brothers as the dominant investment powerhouse in the space.\n\nBased on the initial application, the Winklevos ETF will trade on the Bats Global Market Exchange under the symbol COIN. The ETF will facilitate access to the digital currency to investors, hedge fund and other financial institutions.\n\nWBT is not the only Bitcoin ETF pending SEC approval. Digital Currency Group recently filed with the SEC for listing its ETF on the New York Stock Exchange. Also, SolidX Management filed an application for a Bitcoin-based ETF last summer. Whichever ETF gets approval, the implications for Bitcoin can be profound.\n\nHere are some of the implications that an SEC approval for a Bitcoin ETF can have in the market:\n\nBitcoin has been trading at extremely high values lately and a potential SEC approval for WBT could raise the prices considerably. Similarly, a potential SEC rejection can send Bitcoin prices down on a spiral.\n\nThe Bitcoin-based ETF race might be one of those scenarios on which the first vendor to market can have a decisive advantage. If we use gold ETFs as a reference, there is a significant market valuation difference between the leader (SPDR Gold Shares) and other ETFs.\n\nIt is common knowledge that Bitcoin\u2019s market behavior is sometimes related to the performance of the Chinese Yuan. A Bitcoin-based ETF will open the door to very interesting trading scenarios that involve Bitcoin and other currencies. Similarly, investors could hedge bets on Bitcoin with other asset classes. All that can be done today but requires a considerable amount of work.\n\nA Bitcoin-based ETC will create new opportunities for sophisticated trading strategies that haven\u2019t yet been seen in the Bitcoin eco-system. This is not different to the advanced trading models available on other asset classes.\n\n5 \u2014 Other Exchanges, Countries and Digital Currencies to Follow\n\nA potential SEC approval of a Bitcoin-based ETC can be the beginning for new exchanges in other countries to open similar mechanisms to trade the crypto-currency. Similar vehicles may later involve other digital currencies. However, Bitcoin is still a very small asset class from a public market perspective and other currencies in the market are considerably smaller."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-enterprise-ethereum-alliance-is-trying-to-build-the-business-first-blockchain-1e3533b490eb?source=user_profile---------271----------------",
        "title": "The Enterprise Ethereum Alliance is Trying to Build the Business-First Blockchain",
        "text": "A new consortium arrives to the blockchain market with big backers! At this point, this shouldn\u2019t even be news are every other week we learn about big organizations partnering to build new blockchain solutions. And yet this announcement feels different.\n\nThe Enterprise Ethereum Alliance is a new group focused on building and promoting business applications and technologies backed by the Ethereum blockchain. The consortium is bringing together many impressive names such as Microsoft, Intel, J.P Morgan Chase, Accenture, Credit Suisse, Thompson Reuters, BNY Mellon and several others. The new alliance is a massive endorsement for Ethereum which remains the most viable alternative to the Bitcoin blockchain.\n\nWhile Bitcoin disproportionally beat Etehreum in terms of market value [$19 billion to $1.5 billion approximately]. Ethereum has become a more viable alternative for the implementation of doamin-specific applications and private blockchains. Its not a surprise that Etheren has been the platform choice behind many private blockchain initiatives such as Microsoft Project Bletchey or vertical-specific blockchains such as J.P Morgan Quorum. Speaking of J.P Morgan, the finance giant is going to take the lead providing the technology for the consortium.\n\nThe Enterprise Ethereum Alliance is not the first organization of this sort. R3 is another famous blockchain consortium that has delivered some very impressive blockchain solutions.\n\nCompared to R3, the Enterprise Ethereum Alliance seems to have taken a more holistic approach instead of focusing on a specific industry. Also, even though it is still very early, I believe the fact that the consortium is specifically focused on Ethereum (vs. a specific industry) will yield more positive results in the short term.\n\nIdeas that the Enterprise Ethereum Alliance Should Explore\n\nTo wrap this up, I would like to present a few ideas that are desdesperatelyeded to streamline the adoption of Etehreum in the enterprise that could be worth exploring by the alliance:\n\n1 \u2014 DevOps Tools: Operation management tools for Ethereum applications are a requirement for the adoption of the crypto-currency platform in the enterprise.\n\n2 \u2014 Security & Compliance Frameworks: With Quorum, J.P Morgan made some important contributions to Ethereum\u2019s privacy and security models. More frameworks and solutions in the security and compliance space would be a welcomed addition to the Ethereum stack.\n\n3 \u2014 Off-Chain System Integration: Extending the ideas behind Ethereum Oracles to access off-chain data is essential to integrate Ethereum applications with enterprise back-office systems.\n\n4 \u2014 Industry-Specific Smart Contracts: One of the areas of teh focus of the Ethereum Enterprise Alliance must be to implement to new smart contracts that abstract important industry capabilities such as payments, banking operations, etc.\n\n5 \u2014 Vertical Ethereum Applications. Obviously, we should expect the Enterprise Ethereum Alliance to champion new industry specific solutions powered by Ethereum."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-reinforcement-learning-8d5ce321bdcc?source=user_profile---------272----------------",
        "title": "About Reinforcement Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Learning is the essence of artificial intelligence(AI). Most people associate machine learning(ML) and AI with two fundamental learning models: supervised and unsupervised. While those two models, in fact, constitute the main groups of AI learning techniques, there are many variations in between. Reinforcement learning is one the AI learning techniques that have been gaining a lot of traction in recent months.\n\nFrom a conceptual standpoint, reinforcement learning address some of the limitation of supervised learning methods by introducing a reward or reinforcement systems based on expert feedback. Let\u2019s consider the example of training an AI agent on a specific chess opening( ex: Ruy Lopez, Sicilian Defense, etc). Using a traditional supervised learning model requires labeled data that teaches the agent every possible variation of every possible position . That volume of detailed training data is seldom available in real world scenarios. Alternatively, the AI agent can start collecting continuous feedback or reinforcements from experts when it achieves a favorable position. That model allows the AI agent to progressively learning from its own experiences.\n\nIn strategy games such as Chess, Poker or Go, reinforcements are only received after a few moves that take the game to a favorable or unfavorable state for a specific participant. Other games such as ping-pong require more frequent reinforcements as each point is considered a potential reward.\n\nIn reinforcement learning theory, rewards can be seen as policies that change the state of the AI environment. The goal of reinforcement learning is to discover a policy that maximizes the reward for a participant. Algorithms such as Markov Position Process are particularly good at this.\n\nReinforcement learning techniques can be classified in two main groups: active and passive. In a passive model, the policies for an AI agent are fixed and the goal of the model is to learn how good those policies are as well as to better understand the environment. techniques such as Direct Utility Estimation, Adaptive Dynamic Programming or Temporal Difference Learning are typically used to infer the \u201cutility\u201d of a policy (aka: how good the policy is).\n\nActive reinforcement learning doesn\u2019t operate with fixed policies. Instead, the AI agent must decide which actions to take on any given stage. One fascinating aspect of active reinforcement learning is the friction between maximizing the reward for a specific state and the potential of rlearning new information. This is commonly known as the exploitation-exploration trade off.\n\nReinforcement learning action-reward model seems like an obvious way to train AI agents but it is not applicable to all AI scenarios. AI environments that deal with incomplete information are noot well equipped for reinforcement learning models.\n\nThe theory behind reinforcement learning goes all the way back to 1940s computer scientist such as John Von Newman and Alan Turing but it is only recently that has achieve practical applicability. Some of the tools and frameworks released by OpenAI (gym) or DeepMind are a great example of how reinforcement learning can be incorporated in AI solutions in the real world."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-5-technologies-can-change-the-future-of-enterprise-integration-c6ed85e98c40?source=user_profile---------273----------------",
        "title": "These 5 Technologies Can Change the Future of Enterprise Integration",
        "text": "Integration is as old as enterprise software itself. since the early inception o business software system, integration has been an omnipresent challenge in the enterprise. Throughout the years, enterprise integration platforms have evolved alongside other technologies. Movements such as mainframes, relational database, SOA, mobile or cloud have created new types of integration platforms. However, the fundamental architecture principles of enterprise integration platforms have remained surprisingly unchanged during the last three decades.\n\nDespite the remarkable advancements in enterprise software technologies, the patterns and principles behind integration platforms have remained incredibly consistent throughout the years. Don\u2019t take me wrong, there have been plenty of innovation in the enterprise integration space but the core architecture components of modern integration platforms still look very similar to its predecessors. Whether you are evaluating a traditional ETL platform such as Informatica, an ESB such as MuleSoft or an iPaaS such as SnapLogic, concepts such as connectors, orchestrating, business rules or process analytics remain very similar. More importantly, the architecture model that relies on a central messaging broker to orchestrate the data flow between endpoints hasn\u2019t really changed in a few decades.\n\nThe unchanged nature of enterprise integration patterns have been partially due to the smooth transition paths between different generations of enterprise software technologies such as web and cloud. However, in recent years, the evolution of recent technologies movements is offering an opportunity to completely reimaging enterprise integration. These days, we are living in the middle of a series of technology revolutions that can change the foundation so enterprise integration platforms as we know them today. Let\u2019s take a look at some of the core technology movements that can influence the next generation of enterprise integration platforms.\n\nInternet of things(IOT) architectures brings new integration challenges to enterprise that can\u2019t be easily addressed with traditional integration platforms. Requirements such as large volume of messages, thousands of concurrent endpoints, in-device integration logic and bidirectional communication s are claiming for a new type of IOT-first interation platform. Efforts such as Apache Nifi or Node-Red are solid initial efforts in this area.\n\nBlockchain applications often require integration with off-chain databases or business systems. These type of requirements are likely to influence a new type of integration architectures optimized for blockchain technologies. Additionally, blockchain platform can influence decentralized integration models which are becoming very relevant in the enterprise (ex: IOT scenarios). Technologies such as Ethereum Oracles or Microsoft\u2019s Project Bletchey Cryplets are relevant efforts in the space.\n\nartificial intelligence(AI) is redefining every aspect of enterprise software and integration is not an exception. AI techniques can help to completely reimaging enterprise integration solutions by creating models that understand the behavior of the different endpoints and assemble intelligent orchestrations. Other traditional aspects of enterprise integration platforms such as business rules or analytics can also be redefined with AI as a first-class citizen.\n\nServerless computing stacks can drive an entire new generation of enterprise integration platforms. Key aspects of serverless platform such as developer friendliness, high availability or multi-language interfaces result incredibly attractive to enterprise integration scenarios. AWS Lambda Step Functions is a great example of how these technologies can evolve in the near future.\n\nVoice is becoming a new form of user interfaces and, as a result, will drive a new group of enterprise integration requirements. Natural language, voice-drive integrations will powered sophisticated bots and digital assistant solutions in the enterprise. Even though we are still in very early stages, the voice integration space is starting to get a lot of attention by startups and venture capitalists. Amazon Alexa already provides very complete integration to popular SaaS and line of business systems."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-reasons-why-aws-is-going-after-office365-and-g-suite-4c374e4ac2b?source=user_profile---------274----------------",
        "title": "Five Reasons Why AWS is Going After Office365 and G-Suite",
        "text": "AWS has been steadily expanding beyond its traditional IaaS-PaaS capabilities into business applications and not it seems to be ready to take those efforts to the next level. A few days ago, there were some reports that indicated that AWS has been working g on a new line of services for traditional information worker tasks such as word processing, presentations or spreadsheets. The initiative is a clear indication of AWS\u2019 intentions to compete with cloud rivals such as Microsoft and Google for the supremacy in the cloud productivity tools space.\n\nAWS\u2019s new line of services are far from being the only effort of the cloud gain in the business apps space. Last week, AWS announced Chime, a video-collaboration tool that rivals offers such as Skype for Business or Google Hangouts. WorkMail is another business centric service included in the AWS cloud.\n\nWhether AWS\u2019 move was anticipated or not it still results fascinating. Here we have a company with over 60% domination in the cloud platform market expanding into a complementarily market vastly dominated by its two closes competitors in the cloud space. It doesn\u2019t get any better than that. The move can be compared with Facebook\u2019s audacious entrance in the messaging space or Google release of Home to compete with Amazon Alexa.\n\nWhat could be triggering AWS\u2019s decisions to go into productivity tools? How feasible are those plans? Here is part of my initial analysis:\n\nOffice365 and G-Suite are two of the biggest assets that Microsoft and Google can use to disrupt AWS\u2019 domination in the cloud platform space. Both platforms are indirect channels for the commercialization of Azure and Google Cloud and AWS, obviously, intends to build that market.\n\nBuilding on the previous point, Office365 and G-Suite count with millions of business as customers which provides an easier transition point to Azure or the Google Cloud platform. That channel is particularly important in large enterprise environments.\n\nOne aspect that I haven\u2019t heard analysts consider is AWS\u2019s capability to grow its productivity apps portfolio via acquisitions. At the end, a large percentage of the popular cloud business apps in the market are built on AWS. That position contrasts with Office365 and G-Suite\u2019s grow that has been mostly based on in-house IP.\n\nI think is safe to assume that Office365 and G-Suite are going to remain the dominant cloud productivity suites in first-world markets such as North America, Europe or Australia. However, AWS is rapidly trying to consolidate its leadership position in emerging markets such as China, India, Middle East or Brazil in which a new business apps suite can be a great asset.\n\nMicrosoft and Google have done a remarkable job expanding the capabilities of Office365 and G-Suite to non-developers. Tools such as Office365's Flow or PowerApps are great examples of this trend. Until now, AWS have remained exclusively an infrastructure and developer-centric platform but the new productivity apps and service can set the foundation for non-developer tools and solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/byoda-bring-your-own-digital-assistant-to-work-788ab7d876d7?source=user_profile---------275----------------",
        "title": "BYODA Bring Your Own Digital Assistant to Work \u2013 Jesus Rodriguez \u2013",
        "text": "Digital assistants(DA) are ecoming to your work environment! With conversation becoming the next user experience frontier, DAs have the opportunity to become one of the most relevant runtime for the next generation of enterprise software solutions. However, for DAs to become a viable runtime for business applications, they need to be adapted to operate in highly regulated enterprise environments.\n\nA few years ago the enterprise was disrupted by the bring-your-own-device(BYOD) trend which triggered an entire generation of successful products and technologies. Similarly, we should start seeing an equivalent phenomenon with DAs. Let\u2019s call this trend bring-your-own-digital-assistant (BYODA).\n\nThe idea behind BYODA is fundamentally simple: In the near future, we should expect expect employees to start leveraging their DAs to perform work related activities such as interacting with documents, consulting data, sending messages and many others. even though we should see some enterprise-focused DA platforms to enter the market in the near future, the bulk of business DA solution are more likely to operate on mainstream DAs such as Alexa, Cortana, Allo, Siri and others.\n\nThere are many scenarios that will become relevant in order to enable movements such as BYODA. The great news is that, as an industry, we can leverage many of the lessons learned from the mobile-BYOD trend which created many successful products and companies as well as notorious failures. To get the debated started, I\u2019ve listed some of my favorite BYODA scenarios:\n\n1 \u2014 Authentication: Users should beable to user their voice from a DA to authentication to corporate networks.\n\n2 \u2014 Distribution: Enterprise should customize DA skills based on the roles of specific employees.\n\n3 \u2014 Auditing & compliance: DA skill should enable certain levels of instrumentation, logging, auditing and compliance when operating in business environments.\n\n4 \u2014 Data Privacy: Conversations with DA skills should dbe protected when operating within enterprise environments.\n\n5 \u2014 Access Control: DA skills should factor in user\u2019s corporate roles and attributes in order to enable access to specific capabilities.\n\nLike any other hot movements in enterprise software, BYODA has the potential to create exciting opportunities for startups and venture capitalists that enter the space. Here are some of my favorites:\n\n1 \u2014 DA Management Platforms: Just like the mobile device management(MDM) movement during the enterprise mobility days, BYODA is likely to require new platforms for provisioning, securing and operating DAs when operate in enterprise environments.\n\n2 \u2014 Voice Identity Management Platforms: Using voice as an authentication mechanism and integrate it with existing corporate platforms such as Active Directory will be key for BYODA to become mainstream in the enterprise. Pindrop Security is a great example of this type of technology.\n\n3 \u2014 Enterprise DAs: Of course, BYODA will create opportunities for enterprise-first DAs which could also interoperate with mainstream consumer DAs.\n\n4 \u2014 DA Skills Marketplaces: Similarly to enterprise app stores, BYODA will require new marketplace platforms to manage, distribute and provision corporate DA skills.\n\n5 \u2014 DA Analytics & Auditing Platforms: BYODA could benefit from platforms that enable advanced analytics, ;logging and compliance capabilities. Mainstream consumer DA skills can be easily adapted to include that behavior when operating in business environments."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-voice-search-part-ii-252515571d6e?source=user_profile---------276----------------",
        "title": "Some Thoughts About Voice Search Part II \u2013 Jesus Rodriguez \u2013",
        "text": "Earlier this week, I published an initial list of characteristics that differentiate voice search experiences from traditional web search techniques. today, I would like to continue that post by highlighting some additional capabilities of voice search experiences as well as providing some general impression about the early voice search market.\n\nIn addition of the 5 capabilities listed in the previous article, here are a few others that should be taken into consideration when evaluating voice search technologies:\n\nVoice search mechanisms are likely to provide an improved experience searching voice and video file. The advancements on natural language understanding(NLU) technologies providers more sophisticated experiences for indexing video and audio data so that is can be effectively accessed by voice search interfaces.\n\nUser: Trinity (remember her? ), what are the main five subjects in Shakespeare plays and how they related to other authors from the same period?\n\nThe previous question composes two atomic search queries into a single one. That type of query is very common on human conversations but rather unusual to implement in web search experiences.\n\nUser: Trinity, what are the most popular US Presidential speeches of the last 25 years?\n\nDA: Here are the results\u2026.\n\nUser: Ok, can you go back 50 years instead?\n\nIn the previous dialog ,the second search inquiry is dependent on the first question as well as the context of the conversation. Issuing this type of interrelated search queries as per of conversations with digital assistants should be a key element of voice search experiences.\n\nGiven the succinct characteristic of digital conversations, it is common that users will frame their search questions in the a form that is conducive a single and short answer. This model contrasts with traditional web searches that tend to produce a long list of results for users to interpret.\n\nUser: Trinity, what battles of Napoleon\u2019s campaigns are references in The War and Peace?\n\nThe previous search can result ambiguous are there are many battles of the Napoleonic wars discussed in Tolstoy\u2019s book but only a handful involve the characters of the novel. Reasoning through ambiguity is an intrinsic characteristic of human conversations that should be recreated in voice search experiences.\n\nIt Is Between Amazon and Google\n\nAlthough the voice search market is just getting started, it seems destined to become a two-horse race between Amazon and Google. while Amazon has a head start in voice experiences with the Alexa service and family of devices, Google has a deep expertise and assets in search that will become relevant in the voice search market. The ubiquitous, multi-device adoption of Android is also a factor that will help Google provide a different level of sophistication when comes to voice search experience. While other players such as Microsoft or Samsung can become relevant in the voice search market, Google and Amazon seem to have an advantage today."
    },
    {
        "url": "https://medium.com/@jrodthoughts/watson-iot-keeps-going-faster-and-more-vertical-than-competitors-fc7e614c101a?source=user_profile---------277----------------",
        "title": "Watson IOT Keeps Going Faster and More Vertical than Competitors",
        "text": "Months ago, I published an analysis of the IBM Watson IOT platform in which I mentioned that IBM seemed committed to leverage its industry expertise to accelerate the adoption of the platform across different verticals. Well, a few days ago, big blue unveiled new IOT headquarters in Munich, Germany and announced a series of new developments that confirm IBM\u2019s strategic direction in the IOT space. Here is a quick summary of the announcements:\n\n\u2014 VISA will be using Watson IOT to turn wearable\u2019s devices into point of sale systems by 2020.\n\n\u2014 Bosch is partnering with IBM to explore industrial solutions using Watson IOT.\n\n\u2014 Several world class companies such as BNP Paribas are moving into Watson IOT new headquarters to collaborate closely with IBM engineering new IOT solutions.\n\n\u2014 IBM announced free an unlimited availability of the Watson IOT platform for startups working with Indiegogo and Arrow Electronics crowdfounding-to-production service.\n\nThis series of announcements have relevant implications for the enterprise IOT platform market that I believe are worth discussing.\n\nIBM\u2019s IOT strategy is another signal that enterprise IOT platforms such as Watson IOT belong in Steve Case\u2019s Third Wave technology category. From that perspective, aspects such as partnerships, regulation and industry specific capabilities are going to be essential on the commercialization of IOT solutions.\n\nFrom a strategic standpoint ,we can safely divide the IOT platform market into two main groups: companies such as IBM( Watson IOT), GE( Predix) or PTC( ThingWorx) are clearly driving towards a vertical-first strategy while companies such as Microsoft( Azure IOT), Amazon( AWS IOT) or LogmeIn( Xively) remain focused on horizontal capabilities.\n\n3 \u2014 Watson IOT is a Clear Leader in the Enterprise IOT Space\n\nIf we factor in aspects such as revenue, technical capabilities and partner ecosystem ,we can place Watson IOT as a clear leader in the enterprise IOT platform market. GE and IBM seem to be ahead of the rest of the leaders when comes to revenue and Watson IOT technical capabilities are second to none.\n\nSome of the initiative announced by IBM confirm that enterprise industrial IOT solutions require multi-year long development, deployment cycles. This characteristics favors incumbents with long term commitments to the space.\n\n5 \u2014 The Market for Enterprise IOT Platform Startups is Shrinking\n\nIBM\u2019s announcements confirm that the enterprise IOT platform market is dominated by large enterprise software incumbents and remains quire challenging for startup with limited resources.\n\nWatson IOT has made a tremendous amount of progress in the last few years. I believe that some of the following capabilities could be a great addition to its short term roadmap.\n\n1 \u2014 In-Device Computing: Local, in-device computation capabilities similar to AWS Greengrass could be a great addition to the Watson IOT platform.\n\n2 \u2014 Simulation and Testing: Tools for testing and simulating IOT topologies are desperately needed.\n\n3 \u2014 In-Device Security: Capabilities that prevent cyber-security attacks on IOT devices should be a key component of the Watson IOT platform.\n\n4 \u2014 IOT-first Cognitive Services: We should expect IBM to extend Watson cognitive APIs with IOT specific SDKs and services.\n\n5 \u2014 IOT Middleware: The is room for extending technologies such as Node-Red into full blown IOT middleware."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-voice-search-part-i-a7efe803e301?source=user_profile---------278----------------",
        "title": "Some Thoughts About Voice Search Part I \u2013 Jesus Rodriguez \u2013",
        "text": "Voice search is one of the most exciting fields in artificial intelligence(AI). Even before the raise in popularity of AI, the emergence of smartphones and wearable\u2019s forced the industry to start envisioning new search experiences for those digital mediums. Now, the advancements in areas such as natural language understanding(NL) have open the door to new search experiences using voice as the fundamental user interface.\n\nTo understanding voice search, we should first agree to avoid drawing too many parallels with traditional web search techniques. Voice search experiences are fundamentally different that its web predecessors and are closer to the communication patterns we use to conduct inquires in normal conversations. To illustrate that point, I\u2019ve put together a list of some of thekeyy unique characteristics of coice search experiences as well as its differences with traditional search mechanisms.\n\nAn obvious difference between voice search and web-search experiences is that in the former users will express the search using natural language questions compared to the traditional keyword mechanism of web search engines. This aspects is very relevant as there are infinite ways on which we can formulate the same questions in natural language which makes the understanding of the semantics of a questions a key element of voice search experiences.\n\nImagine a scenario on which a users asks a digital assistant (DA) a question like the following:\n\nUser: Trinity( my chosen name for our DA ;) ), could you find all documents that refer to AA 2016 earnings?\n\nFollowed by User: And please include documents that include Wall Street predictions for the airline industry.\n\nThat type of interaction composes two searches into a single experience. A voice search engine should be able to maintain and understand the state of the conversation between searches.\n\nVoice search experiences should be able to produce responses via voice as well as data. In many cases, a voice search engine should generate short narratives that describe the results of a specific search.\n\nUser: Trinity, could you find the document supporting my Tax returns?\n\nThat previous dialog leverages a clarification question as a way to enrich the search criteria. Although the pattern is completely natural in human conversations is not very common in web search experiences.\n\nThat type of questions requires a voice search engine understand that there is a negative sentiment in the stock market and then search for news to analyze or reports that provide an explanation. After that, the voice search engine should generate the response in the form of a narrative. To accomplish that, the voice search engine needs to be able to understand the search criteria beyond simple keywords or phrases as well as to understand the fact that the user is expecting a simple answer.\n\nI will continue with a list of unique features of voice search platforms in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/openfin-and-the-industry-i-never-thought-was-going-to-be-disrupted-by-open-source-680c0b9ccbd1?source=user_profile---------279----------------",
        "title": "OpenFin and the Industry I Never Thought Was Going to be Disrupted by Open Source",
        "text": "Capital markets are notorious for being secretive, incredibly regulated and anti open source. Even though capital markets operators such as hedge funds have been active consumers of open source stacks they never been active contributors to the communities. It is not surprising that many of the most successful platforms in capital markets such as Palantir TEchnologies have been surrounded by secrecy when comes to their products and solutions. But those times are changing.\n\nOpenFin, a startup trying to build an \u201coperating system\u201d for capital markets, recently scored bug with a $15 million funding round led by J.P Morgan with the participation of Bain Capital Ventures and NEX Euclid Opportunities as well as previous investors. The platform is attempting to disrupt capital markets by providing an open source stack that enables a common infrastructure for building and distributing applications for financial services.\n\nOpenFin was developed on top of Google\u2019s Chromium project and uses that platform as the main distribution channel. Currently, OpenFin is installed across over 100,000 desktops on 35 large banks and hedge funds such as J.P. Morgan, Citadel, Electronifie, ICAP, Greenkey and many others.\n\nOpenFin markets itself as a way for companies building applications fro financial markets to operate efficiently across different programming environments, hedge funds or marketplaces. The platform sees itself as an Android for capital markets. Even that that analogy might need some revisions ;) there is a tremendous amount of value on OpenFin\u2019s proposition.\n\nBenefits of an Open Source Platform for Capital Markets\n\nLooking at OpenFin\u2019s architecture and distribution channels, it seems closer to models such as Docker or Cloudfoundry than to Android. Regardless, there are many benefits to OpenFin\u2019s approach to capital market applications which are notorious fro requiring a lot of time and resources. Even in a market not accustomed to open source innovations, the benefits of a platform such as OpenFin are obvious.\n\n1 \u2014 Uniform Distribution: Chromium provides OpenFin applications with a uniform model for distributing and provisioning applications for capital markets.\n\n2 \u2014 Consistent Management Experience: OpenFin provides a consistent layer and tools for managing and monitoring fintech applications. In the near future, it is not crazy to expect to see advance management and monitoring platforms developed on top of OpenFin.\n\n3 \u2014 Integration with Financial Institutions: OpenFin enables a layer of integration with banks, hedge funds and other financial institutions that streamlines the implementation of new capital market applications.\n\n4 \u2014 Security: OpenFun enables a consistent layer for authentication, access control, data privacy and compliance for applications in financial markets.\n\n5 \u2014 Contributions: Obviously, OpenFin active contributions from its developer community. as more financial institutions start using the platform, we should expect to see some of their IP contributed back to the community."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-cloud-spanner-and-the-evolution-of-the-cloud-data-storage-market-b0bbdc32fe5?source=user_profile---------280----------------",
        "title": "Google Cloud Spanner and the Evolution of the Cloud Data Storage Market",
        "text": "Last week, Google announced the beta launch of Cloud spanner, a new globally distributed relational database service for massively scalable applications. At first glance, we might have been tempted to ignore the release of Cloud Spanner. After all, cloud relational database services are not exactly new. However, Cloud Spanner innovates on several areas that long been the Achilles heel of relational databases.\n\nCloud Spanner is based on a research paper published by Google in 2012. The project started based on the need to look for alternatives to MYSQL that could address Google\u2019s infinite scalability needs. Cloud Spanner architecture combines the best of the relational and NOSQL worlds by providing a relational model with transactional consistency that can achieve seamless scalability. The database service natively supports aCID transactions without sacrificing its scalability model.\n\nCloud Spanner has been used in production for a while powering services such as Google Photos. The release is certainly a strong addition to Google Cloud\u2019s impressive data storage service portfolio that can rival market leaders such as AWS and Azure. However, the launch of Cloud Spanner also represents yet another database service that conceptually overlaps with existing offerings such as Google Cloud DataStore which makes it confusing for companies evaluating different cloud storage platforms.\n\nCertainly, the cloud data storage platform market seems to be growing out of control. Just a few years ago, most cloud platforms only included some basic relational and NOSQL capabilities. Today, the PaaS leader offer overwhelming portfolios of cloud storage services that expand across many different categories. To illustrate that point, we can use the following list that includes the main data storage categories present in the current generation of PaaS technologies.\n\n1 \u2014 File Systems: This is the most basic form of storage in cloud platforms represented by services such as AWS S3 or Azure Blob Storage.\n\n2 \u2014 Relational Database Services: Relational database such as Google Cloud DataStore or SQL Azure have been part of PaaS stacks since the very beginning.\n\n3 \u2014 NOSQL Database Services: Most PaaS providers include native NOSQL capabilities with services such as AWS DynamoDB , Google Cloud BigTable or Azure DocumentDB.\n\n4 \u2014 Hadoop Services: Support for traditional big data stacks with products such as Hadoop, HBase or HIVE have been another area of focus of PaaS stacks. Technologies such as AWS EMR, Azure HDInsights or Google Cloud Dataproc are relevant examples of this category.\n\n5 \u2014 Data Warehouse Services: Massively parallel processing (MPP) data warehouse solutions have become a common citizen of PaaS stacks. Products such as AWS Redshift, Azure Data Warehouse and now Google Cloud Spanner are the key products in this space.\n\n6 \u2014 Data Lake Services: While most PaaSs provide the fundamental building blocks to assemble data lake architectures, now they are moving a step further and started offering entire data lake solutions as cloud services. Azure Data Lake Store is the best example of this emergent type of cloud service.\n\n7 \u2014 Search Services: Search is another type of storage service present in PaaS technologies. Services such as AWS ElasticSearch or Azure Search are relevant example of this category.\n\n8 \u2014 Third Party database: Most PaaS stacks have done a remarkable job providing support for some of the most popular NOSQL and relational databases in the market. Even though this type of storage doesn\u2019t offer the same levels of scalability and management as native cloud services, it is still a relevant category of the cloud storage ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/deep-learning-and-artificial-intelligence-platforms-are-gaining-traction-behind-the-firewall-97d291e18484?source=user_profile---------281----------------",
        "title": "Deep Learning and Artificial Intelligence Platforms are Gaining Traction Behind the Firewall",
        "text": "Artificial intelligence(AI) and deep learning(DL) are two of the most important items in the agenda of modern enterprises. Until now, most of the complete experiences for building AI-DL solutions have been delivered as part of cloud services such as Watson Developer Cloud or Microsoft Cognitive Services but now the attention seems to be shifting to on-premise environments.\n\nDon\u2019t take me wrong. we have had plenty of incredible innovation in open source DL and AI frameworks that can be used on-premise. However, the on-premise infrastructures and tools required to scale and manage large AI-DL workloads are still limited compared to its cloud counterpart.\n\nWhile AI-DL cloud services are a great starting point for relatively mainstream scenarios, most serious enterprise AI-DL use cases require custom algorithms and models that can only be implemented using AI-DL frameworks. Additionally, a large percentage of the data required on enterprise AI-DL scenarios resides behind corporate firewall. As a result, there is a strong demand for on-premise AI-DL platforms that can operate an an enterprise scale. While companies such as how.air have done a remarkable job enabling AI-DL applications, there is plenty of room and demand for new stacks.\n\nLast week there were two announcements that indicate that we are about to see a lot more activity in the on-premise AI-DL platform space. First, Yahoo announced the open source release of TensorFlowOnSpark, a framework of executing TensorFlow programs as part of a Spark infrastructure. Also last week, IBM announced its intentions to bring Watson-like AI-DL capabilities to on-premise environments. Both announcements are clear indicators that on-premise AI-DL solutions are going to see more attention and innovation in the near future.\n\nTensorFlowOnSpark combines two of the most popular platforms in the advanced analytics space on a single, cohesive experience. Using the new framework, TensorFlow applications can leverage Spark capabilities in areas such as advanced data computations, scalable infrastructures, SQL data access, data streaming, R supports and many others. Additionally, TensorFlowOnSpark allows TensorFlwo programs to be managed and monitored using standard Spark tools. The release of TensorFlowOnSpark follows CaffeOnSpark, another initiative by Yahoo to adapt FL frameworks to advanced data computation platforms such as Spark or Flink.\n\nIBM\u2019s announcements addresses one of the major requirements of Watson\u2019s customers. Conceptually, the solution attempts to provide a symmetric set of capabilities between on-premise and cloud environments. The proposed solutions will work with mainstream tools such as Spark ML, TensorFlow or H2O as well as it would provide support for different programming languages such as Scala or Python. One of the most innovative additions to the stack seems to be IBM Research\u2019s Cognitive Assist for Data Science which helps data scientists select the right algorithm based on specific requirements.\n\nThe announcements by IBM and Yahoo share the same pattern combining advanced DL frameworks with scalable data computation platforms such as Spark or Flink. That model could become the most viable short term option for adapting DL technologies to mission critical enterprise environments."
    },
    {
        "url": "https://medium.com/@jrodthoughts/game-theory-and-artificial-intelligence-ee8a6b6eff54?source=user_profile---------282----------------",
        "title": "Game Theory and Artificial Intelligence \u2013 Jesus Rodriguez \u2013",
        "text": "Continuing our series of articles about the different foundational aspects of artificial intelligence(AI), today I would like to focus on game theory. Games have been one of the most visible areas of progress in the AI space in the last few years. Chess, Jeopardy, GO and, very recently, Poker are some of the games that have been mastered by AI systems using break through technologies. From that viewpoint, the success of AI seems to be really tied to the progress on game theory.\n\nWhile games are, obviously, the most visible materialization of game theory, is far from being the only space on which those concepts are applied. From that perspective, there are many other areas that can be influenced by the combination of game theory and AI. The fact us that most scenarios that involve multiple \u201cparticipants\u201d collaborating or competing to accomplish a task can be gamified and improved using AI techniques. even though the previous statement is a generationazation, I hope it conveys the point that game theory and AI is a way to think and model software systems rather than a specific technique.\n\nFrom a conceptual standpoint, there are several aspects of game theory that could help better understand AI systems. Let\u2019s explore a few of those concepts.\n\nAI systems that could be improved using game theory require more than one participant which narrows the field quite a bit. For instance, a sale forecast optimization AI systems such as Salesforce Einstein is not an ideal candidate for applying game theory principles. However, in a multi-participant environment, game theory can be incredibly efficient. In those settings, game theory can serve two fundamental roles:\n\n\u2014 Participant Design: Game theory can be used to optimize the decision of a participant in order to obtain the maximum utility.\n\n\u2014 Mechanism Design: Inverse game theory focus on designing a game for a group of intelligent participant. Auctions are a classic example of mechanism design.\n\nThere are many other goals of game theory but they can all be seen as variations of the ones listed above.\n\nGame theory covers a large spectrum of games. Some of the most relevant and well-known include:\n\n\u2014 Single-Move Games: This type of game is based on each player taking a single action without knowing the action of any other participant. Stock purchasing is a classic example of single move games.\n\n\u2014 Repeated Games: This type of game faces players with the same choice multiple times but, each time, each player has knowledge about the previous decision of the other players. Many repeated games are variations of single move games with repetitions.\n\n\u2014 Sequential Games: As you might have guessed, sequential games model the environment as a series of turn which can produce new and different states. Chess, GO are examples of sequential games.\n\nRemember John Nash\u2019s story famously depicted on \u201cA Wonderful Mind\u201d ? Well Nash\u2019s contributions have been at the center of game theory for decades. Specifically, the Nash Equilibrium theory proves that every game can achieve a point on which no player can benefit from switching strategy assuming than the other players stay with their current strategy. That state is known as Equilibrium. Nash theory has become an essential element o game modeling.\n\nIn many cases, the problem is not to optimize the participant\u2019s strategy on a game but to design a game around the behavior of rational participants. this is the role of inversed game theory. Auctions are considered one of the main examples of inverse game theory.\n\nI will cover other aspects of game theory on future posts. I hope this content can give you an idea of the influence of game theory artifacts in the AI space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-googles-ai-collaboration-experiment-c55bdd7cede?source=user_profile---------283----------------",
        "title": "Some Thoughts About Google\u2019s AI Collaboration Experiment",
        "text": "Alphabet\u2019s subsidiary DeepMind has been conducting a series of experiments to explore the behavior of AI agents in situations suited for collaboration or competition. The experiment attempts to shade some light onto the future of AI on which agents will will to collaborate in order to accomplish specific tasks.\n\nDeepMind designed the experiments around well-known \u201csocial dilemmas\u201d. These are a variation of game theory scenarios on which participants on a game can benefit from being selfish but all participants loose if everyone behaves selfishly. The most notorious scenario of this type of problems is the \u201cprisoner\u2019s dilemma. The famous problem states that, after being caught on a robbery, two people are offered to be released if they testify against the other person. Neither participant is aware of the other person\u2019s decision. Alternatively, the robbers could be facing up to 10 years in prison if they refuse to cooperate and the other person testifies against them or up to 5 years if neither party cooperates. Problems similar to the prisoner\u2019s dilemma play an important tole in economic theory.\n\nSome of the initial results of DeepMind\u2019s experiment highlighted that agents were willing to cooperate with each other when plenty of resources were available but quickly turned against each other when resources became scarce. Another important observation was that \u201cagents with the capacity to implement more complex strategies tried to tag the other agent more frequently i.e. behave less cooperatively\u201d.\n\nEven though the observations were based on preliminary experiments, the results are one of the first indicators of how multi-agent AI environments may operate in the future. Thinking about the initial results, I\u2019ve summarized some ideas that may be relevant when thinking about the behavior of AI agents in collaborative/competitive environment.\n\nIn order to become more cooperatively, AI agents should be trained to achieve an \u201cequilibrium\u201d state. This means that no participants can benefit from changing strategy at that stage. Some of the work of US mathematician John Nash ( A Wonderful Mind) proved that any game has an equilibrium.\n\nAs AI agents evolve, ethics should become an important part of the training. Ethics can guide the behavior of AI agents in competitive environments.\n\nEvolutionism is one of the main AI schools of thought. AI systems designed under the evolutionist theory assumes that a subset of the population of AI agents in a competitive environment will survive and evolve to be more more efficient.\n\nAI agents are designed to maximize utility on a specific environment. From that perspective, AI agents are expected to do anything they can to increase utility with each decision. However, humans don\u2019t make decisions just factoring utility gains. Judgment is an important part of human decision making processes. As AI agents are trained using data based on historical human decision, they could show early forms of judgement when making decisions in competitive or collaborative environments.\n\nAn interesting aspect to consider about experiments such as DeepMind\u2019s is the role that emotions such as fear, anger, happiness or others will play on how AI systems make decisions in competitive settings."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-factors-are-contributing-to-the-renaissance-in-enterprise-search-e3f5cb006e02?source=user_profile---------284----------------",
        "title": "These Factors are Contributing to the Renaissance in Enterprise Search",
        "text": "Enterprise search is slowly making comeback. Just this week, Google released its Cloud Search services that enables search capabilities across G-Suite products including Drive, Gmail, Sites, Calendar and a few others. Previously known as SpringBoard, Google Cloud Search leverages intuitive machine intelligence and card-style visualizations to improve the search and discovery of information in G-Suite environments. Cloud Search also includes a mobile-first experience as an entry point to the platform.\n\nGoogle is not the only company reimagining enterprise search. Startup Swiftype has put together a very innovative platform that leverages machine intelligence and a modern user experience to power search across common business systems such as ZenDesk, Salesforce.com, Office365 and others. The platforms also enables the search experiences in popular websites such as TechCrunch.\n\nGoogle and Swiftype\u2019s efforts are a strong indicator of the renaissance of the enterprise search space. A few years ago, enterprise search was regularly highlighted as one of the biggest and most promising trends in enterprise software. Even though the space produced some winners such as FAST(acquired by Microsoft), Endeca(acquired by Oracle) or Lucid Imagination, it largely fell short of becoming a foundation trend in enterprise software systems.\n\nThere are many factors that have used to explain the \u201cfailure\u201d of enterprise search. The unfriendliness of most enterprise search experiences as well as the complexity of its underlying infrastructures are two of the factors that contributed to the disappointment of organizations looking to build a \u201cGoogle experience\u201d for their business.\n\nNow, a few years after, enterprise search is staging a second act and there are many factors contributing to it.\n\n1 \u2014 SaaS Adoption: The growing presence of SaaS business systems and its corresponding APIs in the enterprise has definitely simplified the requirements for building enterprise search experiences.\n\n2 \u2014 Elastic: The emergence and wide adoption of the Elastic platform is another factor that has lower the bar for the implementation of enterprise search solutions. With Elastic, companies can focus on enabling a killer user experience and higher level search services while relying on Elastic for lower level tasks such as indexing, data storage optimization ,etc.\n\n3 \u2014 Artificial Intelligence: AI enables the implementation of novel search techniques such as knowledge inference or document relationships which are very relevant in enterprise environments.\n\n4 \u2014 Natural Language Processing: The advancements is NLP makes possible to implement search experiences that leverage natural language sentences.\n\n5 \u2014 Voice Search: Voice search is a new and exciting area in enterprise search .\n\n6 \u2014 New UX Paradigms: New UX techniques such as Google\u2019s card-style visualization help to power new search experiences in the enterprise.\n\n7 \u2014 Enterprise Data Growth: The massive growth rate in enterprise data has increase the need for comprehensive search experiences.\n\n8 \u2014 Serverless Computing: Serverless computing stacks drastically simplify the architecture of components such as data crawlers or connectors that are an essential part of enterprise search solutions.\n\n9 \u2014 Image & Video Search: Enabling intelligent image and video search capabilities bring exciting opportunities to the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/artificial-intelligence-lessons-from-wall-street-a31d00cb79d0?source=user_profile---------285----------------",
        "title": "Artificial Intelligence Lessons from Wall Street \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) is called to revolutionize every industry in the next few years. However, there is an industry that has been actively relying on AI for decades and that can provide a lot of inspirations when comes to adopting AI technologies: we are talking about Wall Street. Relying is the imperative world in the previous sentence, Wall Street doesn\u2019t only uses AI but it actively relies on it for some of its fundamental business functions.\n\nFrom the emergence of quantities trading to the popular raise on high frequency trading passing through many high profile episodes, AI has evolved to become an essential component of Wall Street\u2019s operations. In that sense, there are many lessons that other industries can learn from Wall Street\u2019s journey through the adoption of AI technologies. Here are some of my favorite lessons:\n\n1 \u2014 AI Can Get Out of Control\n\nThe last two decades of Wall Street are full of stories of AI-based quantities trading systems spinning out of control and causing major losses in the market. Remember Long Term Capital Management(LTCM)? The quantities trading hedge fund was started by academic luminaries and future Nobel prize winners promoting the ideas of the Efficient Market Hypothesis (EMH). LTCM relied on AI, quantities trading algorithms to identify and execute trading stragies based on EMH-based arbitrage models. After a few successful years, LTCM AI systems started placing questionable bets on markets such as Russia and Japan ended up literally wiping out the fund\u2019s assets and threaten to bring down the entire US financial system.\n\nLTCM is not the only example of scary episodes caused by AI systems in Wall Street. Famous quantities trading houses such as Ken Griffin\u2019s Citadel have been on the brink of failure more than once dues to AI-drive strategies spinning out of control. Those episodes highlight the importance of the continuous training and monitoring of AI systems.\n\nLast year, the US Government published several different reports about the role of goverment in the adoption of AI technologies. From Wall Street\u2019s experience, we know that compliance and regulation are extremely important to guide the sane adoption of AI platforms on mission critical solutions.\n\n3 \u2014 Advanced Statistics can Carry Us a Long Way\n\nThe industry is obsessed with machine learning(ML) and AI technologies. However, from Wall Street trajectory, we can learn that advanced statistics can provide a tremendous amount of value across different industries. From the early days of quantities trading based on Ed Thorpe (Beat the Dealer, Beat the Market, Man of all Markets\u2026) to current high frequency trading models, advanced statistics have been an efficient stepping stope towards the adoption of AI technologies.\n\nSometimes, I feel that some industries are mistakenly looking at AI strategies as a zero-sum-game. We often see vendors promoting THE AI STRATEGY for sales forecasting or marketing optimization. If we look at Wall Street, however, we can learn that industries are going to produce many and often competitive AI strategies to solve the same problem. In Wall Street, the competition between different AI strategies has been a vehicle to improve the efficient of different market algorithms.\n\nWall Street has become a master at leveraging AI strategies in an autonomous fashion for long periods of time. More importantly, Wall Street AI strategies are regularly making independent decisions that are immediately translated into financial gains and losses. For instance, if an arbitrage AI strategy infers that a specific market is overvalued, it can make the decision of shorting a number of stocks in that market. If the market continues trending upwards, covering those shorts will immediately reflect on a financial loss that is only justified by the trust on the underlying intelligence of the AI model. That\u2019s a lot of trust to place in an algorithms. Similarly to Wall Street, as AI evolves on other industries, we are likely to see more cases of this semi-autonomous, \u201ccruise-control\u201d AI."
    },
    {
        "url": "https://medium.com/@jrodthoughts/understanding-semi-supervised-learning-a6437c070c87?source=user_profile---------286----------------",
        "title": "Understanding Semi-supervised Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Semi-supervised learning(SSL) is one of the artificial intelligence(AI) methods that have become popular in the last few months. Companies such as Google have been advancing the tools and frameworks relevant for building semi-supervised learning applications. Google Expander is a great example of a tool that reflects the advancements in semi-supervised learning applications.\n\nConceptually, semi-supervised learning can be positioned halfway between unsupervised and supervised learning models. A semi-supervised learning problem starts with a series of labeled data points as well as some data point for which labels are not known. The goal of a semi-supervised model is to classify some of the unlabeled data using the labeled information set.\n\nSome AI practitioners see semi-supervised learning as a form of supervised learning with additional information. At the end, the goal of semi-supervised learning models is to sesame as supervised ones: to predict a target value for a specific input data set. Alternatively, other segments of the AI community see semi-supervised learning as a form of unsupervised learning with constraints. You can pick your favorite school of thought ;)\n\nSemi-supervised learning models are becoming widely applicable in scenarios across a large variety of industries. Let\u2019s explore a few of the most well-known examples:\n\n\u2014 Speech Analysis: Speech analysis is a classic example of the value of semi-supervised learning models . Labeling audio files typically is a very intensive tasks that requires a lot of human resources. Applying SSL techniques can really help to improve traditional speech analytic models.\n\n\u2014 Web Content Classification: Organizing the knowledge available iun billions of web pages will advance different segments of AI. Unfortunately, that task typically requires human intervention to classify the content.\n\nThere are plenty of other scenarios for SSL models. However, not all AI scenarios can directly be tackled using SSL. There are a few essential characteristics that should be present on a problem to be effectively solvable using SSL.\n\n1 \u2014 Sizable Unlabeled Dataset: In SSL scenarios , the seize of the unlabeled dataset should be substantially bigger than the labeled data. Otherwise, the problem can be simply addressed using supervised algorithms.\n\n2 \u2014 Input-Output Proximity Symmetry: SSL operates by inferring classification for unlabeled data based on proximity with labeled data points. Inverting that reasoning, SSL scenarios entail that if two data points are part of the same cluster (determined by a K-means algo or similar) their outputs are likely to be in close proximity as well. Complementarily, if two data points are separated by a low density area, their output should not be close.\n\n3 \u2014 Relatively Simple Labeling & Low-Dimension Nature of the Problem: In SSL scenarios, it is important that the inference of the labeled data doesn\u2019t become a problem more complicated than the original problem. This is known in AI circles as the \u201cVapnik Principle\u201d which essentially states that in order to solve a problem we should not pick an intermediate problem of a higher order of complexity. Also, problems that use datasets with many dimensions or attributes are likely to become really challenging for SSL algorithms as the labeling task will become very complex.\n\nIn a future post, I will cover some of the fundamental types of SSL algorithms."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-capabilities-will-be-needed-fro-voice-to-become-a-viable-runtime-in-the-enterprise-93392b0618e6?source=user_profile---------287----------------",
        "title": "These Capabilities Will Be Needed Fro Voice to Become a Viable Runtime in the Enterprise",
        "text": "Recently, I published another article about amazon Alexa\u2019s potential to drive a new generation oof enterprise solutions. Voice platforms such as amazon Alexa have the potential of becoming the next great user interface platform. However, these type of platforms still need to build many enterprise-ready capabilities in order to achieve mainstream adoption in business environments.\n\nThe potential for an enterprise voice platform is an interesting topic of debate in the AI community. Today , it is perfectly possible to implement enterprise-ready voice bots with platforms such as Alexa or Cortana. However, those solutions require a considerable level of effort to enable required enterprise features in areas such as integration, security, compliance, etc.\n\nAn enterprise voice runtime should provide developers and devops with the fundamental building blocks for the implementation and lifecycle management of voice bots. What are those building blocks? The following list provides a starting point:\n\nProviding voice and conversational integration with SaaS and on-premise business systems is an essential element of an enterprise voice platform .\n\nSearch is one of the fundamental vehicles for interacting with business voice bots. An enterprise voice platform should provide a consistent search experience for voice bots.\n\nDelivering voice notifications containing business data sources is another relevant mechanism to engage business users with voice bot solutions.\n\nSeamless integration with enterprise messaging and collaboration tools such as Slack or HipChat will allow voice bots to tap into existing conversational channels in the enterprise.\n\nBusiness Mobile apps will be an important channel to data and process actions generated by voice bots. as a result, an enterprise voice platform should leverage mechanisms such as deep links to integrate with existing mobile business apps.\n\nIn an enterprise environment, not all users will access to all bots available. An enterprise voice platform should enable access control policies that integrate with existing identity management platforms.\n\nMonitoring voice interactions between bots and users is key for the adoption of voice platforms in the enterprise. Similarly, compliance models will have to be adapted to voice platforms for its adoption across regulated industries.\n\nEnterprise voice bots will be subjected to different levels of security and compliance than consumer bots. Being able to configure and provision completely isolated instances of Alexa or Cortana backend services would be essential to streamline the adoption of voice bot solutions in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/blockchain-gains-ground-in-the-iot-market-7cffec3f923f?source=user_profile---------288----------------",
        "title": "Blockchain Gains Ground in the IOT Market \u2013 Jesus Rodriguez \u2013",
        "text": "Blockchain technologies have long been perceived as an important element for the future of the internet of things(IOT) market. However, with some exceptions, the applications of blockchain stacks to IOT have remained mostly as a theoretical exercise. Last week, a new technology consortium was created with the purpose to advance blockchain applications in the IOT space.\n\nCisco, Bosch, FoxConn, Gemalto are some of the founding companies of a new consortium that will focus on exploring how blockchain technologies can be used to improved IOT applications. The organization also includes thought leaders in the blockchain space such as blockchain startup studio Consensus Systems (ConsenSys).\n\nThe blockchain-IOT consortium follows the path of similar efforts on other industries. In the financial sector, the R3 consortium has brought together more than 40 banks and has delivered impressive blockchain solutions applied to the banking industry. By following this approach, the new Blockchain-IOT consortium can capitalize on a large opportunity for creating standards and solutions to streamline the adoption of blockchain IOT technologies.\n\nThe opportunities for blockchain technologies in IOT are tremendous but there are some that seem more practical than others considering the current state of blockchain technology stacks. Here are some ideas that I think could be relevant in the space in the near future:\n\nTechnologies such as Ethereum Smart Contracts offer a robust foundation for modeling the capabilities of IOT devices so that they can operate as part of a blockchain network. By standarizing on Smart Contract protocols, IOT devices can leverage a uniform mechanism to transact with other devices.\n\nFollowing on the previous point, Smart Contract protocols would allow IOT devices to exchange assets, money without the need of a centralized hub. That model could be the foundation of device-todevice autonomous commerce.\n\nBlockchain technologies have created new models for decentralized public key infrastructures(OKI). That capability could be a unique asset to protect device identities and data in an IOT network.\n\n4 \u2014 Supply chain is one of the often overlooked areas of the IOT market that can be revolutionized using the blockchain. The distributed ledger can provide unique visibility throughout the supply chain process of IOT devices.\n\nBlockchains provide a unique opportunity to maintain a universal, trusted record of the activity in IOT devices. This historical record can be used as a form of identity and credentials that IOT devices can present to join a specific IOT network. There\n\nThese are just some of the initial ideas that could be achievable in the short term by applying blockchain technologies in the IOT space. Certainly, the blockchain-IOT consortium is an exciting development to advance blockchain IOT applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/amazon-earnings-questions-the-faith-of-aws-bulls-ce5bfa1b3487?source=user_profile---------289----------------",
        "title": "Amazon Earnings Questions the Faith of AWS Bulls \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, I published an article analyzing six cloud platforms based on their earnings report. The article was published ahead of Amazon\u2019s earnings and used some of its guidance numbers. well, last Thursday, Amazon reported earnings and the numbers have brought some interesting questions about AWS\u2019 growth trajectory.\n\nBefore we go too far, let me clarify that I believe that both Amazon and AWS\u2019 numbers were outstanding and that the questioning is more a result of your typical Wall Street analyst rhetoric than based on reality. Despite that, the argument is worth discussing.\n\nAmazon\u2019s fourth quarter numbers brought a raise on profit of 55% to $729 million which exceeded the retail giant\u2019s guidance. Revenue was the weakest spot on the earnings report with an increase of 22% to $743.7 billion which was below analysts\u2019 expectations. Amazon\u2019s stock traded down by more than 4% after hours.\n\nIn terms of AWS, the revenue of the cloud platform grew 47% year over year to $3.5 billion. the number missed analysts\u2019 estimates by 2%. Some experts blame the miss on Wall Street\u2019s inability to account for adverse currency impacts. Regardless, after the report, analysts started to question AWS\u2019 ability to continue its growth trajectory. Based on the last earnings, it is pretty obvious that Microsoft Azure is growing at a faster pace year-on-year.\n\nBefore you disregard Wall Street\u2019s analysis about AWS as stupid, you should put it in the context of Amazon\u2019s stock. Growth is every for Amazon shareholders. At this point, the stock is trading at 100 time forward earning which is absolutely ludicrous unless you think the company can continue its double digit growth trajectory. Having said that, Wall Street\u2019s doubts seem a bit exaggerated when comes to AWS.\n\nLast year absolutely consolidated AWS as the cloud platform market leader. To put some of the numbers in perspective, J.P Morgan Chase estimates Microsoft Azure revenue at about $2.7 billion for 2016. That number represents about 22% of AWS revenue for the same period. That\u2019s a massive gap between number one and number two on any technology market.\n\nConsidering that most of Wall Street\u2019s concerns about AWS were related to its growth, I would like to discuss a few areas of growth potential that AWS is in a unique position to exploit in the near future.\n\n4 Areas of Growth for AWS in the Near Future\n\n1 \u2014 Alexa: Voice interfaces are rapidly growing in popularity. Alexa together with complementary AWS service such as Lex are in a unique position to drive that market.\n\n2 \u2014 Artificial Intelligence: As the artificial intelligence(AI) market evolves and AWS improves its AI suite of services, we are likely to see huge AI workloads to move to the AWS cloud.\n\n3 \u2014 International Expansion: IT-savy India remains a market that can bring a tremendous level of growth to AWS. Battling AliCloud in China and expanding its presence in Latin America could also influence the near term growth of the cloud giant.\n\n4 \u2014 Drones & VR: Drones and virtual reality(VR) backend are two areas that could move the niddle for AWS in the ear future. Both types of solutions require high performance , expensive, large-scale backend that are ideal for AWS."
    },
    {
        "url": "https://medium.com/@jrodthoughts/artificial-intelligence-ai-27b487d21818?source=user_profile---------290----------------",
        "title": "Artificial intelligence(AI) \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) is, arguably, the most important movement in the modern technology industry. Conceptually, AI focuses on modeling human-like, intelligent, thinking processes and behaviors using computer systems. In order to accomplish its goal, AI must leverage foundational knowledge from many disciplines.\n\nTraditionally, people associate AI with areas such as computer science and neuroscience. \u201cHowever, there are several other disciplines such as economics, philosophy or psychology that are equally influential on different AI areas. As the study of domain such as neuroscience can provide a strong technical framework for AI systems, other domains such as economics or psychology can influence higher order behaviors on AI solutions.\n\nThe fascinating thing about AI is that it drives influences from half a dozen disciplines without projecting any obvious conflicts. That characteristic contrasts with other areas of computer science that are based on a single domain. Knowing some of the foundational disciplines behind AI, it could be interesting their specific areas of impact and influence.\n\nThere are different disciplines within psychology that have a marked influence o. among those, cognitive psychology theories provide a robust foundation to model areas such as perception and communication as information systems. Other areas such as Behavior Theory are also relevant to AI systems.\n\nThe influence of economics in AI systems has resulted essential on decision making and evaluation techniques. While most people associate economics with money, economists like of think of themselves as students of decision making processes and its corresponding outcomes.\n\nDecision Theory provides the principles of decision making processes which are incredibly relevant to AI systems. Some of the work of Israeli psychologists Danny Kahneman and Amos Tversky in decision making theory is likely to influence AI systems for decades to come.\n\nGame theory is another economics discipline that is very relevant in AI techniques such as adversarial neural networks.\n\nThe influence of philosophy in AI systems might not seem immediately obvious. However, philosophy schools of thought are very influential in AI areas such as knowledge modeling and the relationship between knowledge and actions. Philosophy theories such as Rationalist, Materialism or Logical Positivism are very relevant in the modeling of AI systems. Recent developments in areas of philosophy such as Confirmation Theory are very influential on popular AI disciplines like Reinforcement Learning.\n\nNeuroscience can be considered the most influential discipline for modern AI systems. As neuroscientists make inroads understanding how the brain process information, new AI theories and techniques are likely to emerge to reflect the latest neuroscience discoveries."
    },
    {
        "url": "https://medium.com/@jrodthoughts/chinese-banks-want-to-be-relevant-in-the-blockchain-e4ee54b683e7?source=user_profile---------291----------------",
        "title": "Chinese Banks Want to Be Relevant in the Blockchain",
        "text": "Blockchain technologies are driving innovation all around the banking sector. According to the World Economic forum, about 80% of the top global banks are planning to launch blockchain projects in the next year. Now Chinese banks are looking to join the party.\n\nLike most financial markets related activities in China, the adoption of blockchain technologies will come in unique flavors and will have some unique implications for the blockchain space.\n\nChinese banks are initially looking at blockchain technologies to improve transparency to fight fraud in the financial sector. The Chinese banking space is still drastically behind the rest of the first world countries in terms of digitalization and the adoption of modern technologies. The adoption of blockchain solutions could help push Chinese banks to the forefront of a new wave of innovation in the banking sector.\n\nSimilarly, the Chinese government has recently embarked on an anti-corruption campaign that has uncovered more than one scandal. Top Chinese authorities such as the Ministry of Industry and Information has identified blockchain technologies as a fraud-fighting tool and called on the government to encourage large firms to invest on that area. As a result, big Chinese banks are aggressively trying to recruit blockchain engineering talent.\n\nAs a country, China certainly has a lot of experience with blockchain technologies. The Asian giant accounts for a large percentage of the Bitcoin global trading. However, the adoption of non-Bitcoin blockchain technologies remains almost non-existent.\n\nThe unique socio-political and economical environment in China is likely to cast a unique flavor in the adoption of blockchain technologies by Chinese banks. I\u2019ve summarized a few ideas about that should be considered when analyzing the implications of the adoption of blockchain technologies by the banking sector in China. Here are my top three:\n\n1 \u2014 A Private Chinese Financial Blockchain: Looking at how the Chinese government operates and regulates the country\u2019s internet access or public stock exchanges, it is likely that the involvement of the governments in the adoption of blockchain technologies will result on the implementation of a private or consortium blockchain among the Chinese banks and the government. That model will grant the Chinese government regulators special access to transaction data from its citizens.\n\n2 \u2014 A Chinese Ethereum Fork: The unique characteristics of the Chinese market creates an interesting opportunity for blockchain platforms specialized on that market. A Chinese version of the popular Ethereum platform is certainly an intriguing idea.\n\n3 \u2014 Communist Rules on the Blockchain: Not to get overly political but I can\u2019t avoid wondering what could be the implications of a communist government having access to an efficient systems to track financial transactions Crazier currency manipulations or stronger persecution of human rights activists are some of the things that come to mind."
    },
    {
        "url": "https://medium.com/@jrodthoughts/azure-bot-service-makes-microsoft-bots-ready-for-primetime-2a942a8e5cac?source=user_profile---------292----------------",
        "title": "Azure Bot Service Makes Microsoft Bots Ready for Primetime",
        "text": "Last year Microsoft announced the availability of its Bot Framework to enable the implementation of bots that an run on different messaging runtimes. The framework became instantly popular and today it counts with tens of thousands of developers and hundreds of bots running on diverse messaging stacks.\n\nConsidering the popularity of Microsoft Bot Framework, many were surprised when, a few months ago, Microsoft announced the Azure Bot Service, a platform to enable an end-to-end experience for the implementation and management of bot solutions.\n\nDo we really need another Microsoft offering for bots?\n\nThe question is perfectly logical but irrelevant as soon as we realize that Azure Bot Service is a natural complement to Microsoft Bot Framework. Conceptually, Azure Bot Service expand Microsoft Bot Framework with capabilities in areas such as backend services, continuous integration, artificial intelligence(AI) services, scalability and many other foundational elements of the lifecycle of bots. In some context, Azure Bot Services makes Microsoft Bot Framework bots ready to operate and scale in real world, mission critical environments. Even though the different capabilities of the Azure Bot Service can be independently used together with the Microsoft Bot Framework, it takes a considerable level of effort to do so. Azure Bot Service brings together several Microsoft products to provide a complete and sophisticated experience for the implementation of bot applications.\n\nUsing the Azure Bot Service, developers can implement bots using Microsoft Bot Framework directly from an in-browser experience powered by the azure Editor. Developers can leverage components such as Azure Functions to enable serverless backend routines or Microsoft Cognitive Services to provide AI features to bot applications. Additionally, Azure Bot Service enables continuous delivery by integrating with service such as GitHub, BitBucket or Visual Studio Team Systems. The Bot Service also provider a library of templates that streamlines the implementation of common bot scenarios.\n\nFactoring all those capabilities, it is very easy to see how Azure Bot Service complements Microsoft Bot Framework. Using some industry analogies, we can compare the connection between the two bot platforms with other well-understood technology relationships such as Confluent-Kafka in the messaging space, Cloudera-Hadoop in big data or Loopback-NodeJS in the server-side JavaScript application market.\n\nAzure Bot Service is a very unique offering in the bot platform space that Microsoft ahead of competitors such as Howdy, Facebook Messenger or Slack that provide relevant platforms in the space. Knowing that, we can speculate about what could be next for the Azure Bot Service.\n\nFive Cool Ideas for the Azure Bot Service Roadmap\n\nHere are some interesting ideas that I would like to see added the the Azure Bot Service in the near future:\n\n1 \u2014 Serverless Connectors: Leveraging technologies such as Azure Functions and LogicApps to implement serverless connectors to SaaS systems.\n\n2 \u2014 Relational and NOSQL Storage: Provide libraries that abstract the storage of relational and semi-structured data in bot solutions.\n\n4 \u2014 Bot Search and Discovery: Smart mechanisms for searching and discovering bots based on a specific criteria.\n\n5 \u2014 Knowledge Services: Integration with Cognitive Services that bring domain specific knowledge from public repositories such as WebMD, Wikipedia, etc."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-tale-of-6-clouds-an-earnings-perspective-625d49e22594?source=user_profile---------293----------------",
        "title": "A Tale of 6 Clouds: An Earnings Perspective \u2013 Jesus Rodriguez \u2013",
        "text": "Last week was earnings week in Wall Street and, with that, we go some insights into the performance of the cloud platform incumbents. Every quarter I post my opinions about the evolution of the cloud platforms based on the earning reports. However, this quarter feels a bit different as the list of relevant players keeps getting bigger and brighter.\n\nFor years, only AWS, Azure and IBM Bluemix were relevant cloud platforms from a Wall Street perspective. In the last two years, Google Cloud has become a force to reckon with in the cloud platform market. Now, companies such as Oracle and Alibaba are worth following as their offering are growing rapidly and they have developed relevant traction on specific market segments.\n\nThe earning seasons has consolidated Amazon as the undisputed cloud leader with Microsoft also distancing itself from the competition for the number 2 spot. Google cloud and IBM Bluemix are on a fierce battle for the third place in the market. After years of struggle, Oracle seems to finally be all in the cloud game and is leveraging its footprint in the enterprise to gain relevant market share. Finally, even though AliCloud\u2019s numbers are relatively small, its dominance in the Chinese market and rapid growth makes it a platform worth following. There are many things about AliCloud that resemblance the early days of AWS.\n\nArtificial intelligence(AI) and cognitive computing seems to be the focus of every cloud platform these days but that often seems more of a message tailored to Wall Street analysts to keep the stock price in check than the real focus for many cloud platforms ;). Let\u2019s review some observations about the individual cloud platforms.\n\nAWS remains the undisputed leader in the cloud platform space with second quarter revenues growing by 55% to $3.23 billion. At its re:Invent conference, AWS unveiled a series of new offerings that erased any doubts about its pace of innovation promised an exciting near term future for the cloud platform.\n\nImmediate Areas of Focus: To maintain its leadership position in the cloud market, AWS should remain competitive in areas such as machine learning(ML) , artificial intelligence(AI), bots, IOT and other emerging technolologies in which AWS is experiencing fierce competition from platforms such as Azure, Google Cloud and Bluemix. The expansion onto international markets, specifically India, should be a strong focus of AWS in the near future.\n\nMicrosoft doesn\u2019t report Azure\u2019s revenues as a separate line item. Instead, Azure numbers are included as part of its Intelligence Cloud segment. This quarter, Microsoft did report that Azure revenues grew by 93% and the Intelligent Cloud segment posted revenues of $6.9 billions.\n\nImmediate Areas Focus: Microsoft should continue its relentless focus on bridging the gap with AWS. To accomplish that goal, Azure should continue investing on emerging technologies areas such as AI, IOT or bots on which it has been consistently able to out-innovate AWS. Microsoft should also aggressively continue Azure\u2019s international expansion into attractive markets such as post-Brexit UK and India.\n\nAlphabet doesn\u2019t report Google Cloud revenue numbers. The non-advertisement segment which includes Google Cloud posted revenues of $3.4 billion. Under Diane Green, Google Cloud has made incredibly smart acquisitions such as Apigee or Twitter Mobile Fabric which have helped to improve relevant capabilities in the platform.\n\nImmediate Areas Focus: Opening new international data centers and improving its core infrastructure services has to be Google Cloud\u2019s top priority. Also, the combination of Cloud ML, TensorFlow and the AI APIs can give Google Cloud an edge over Azure and AWS in the AI space. Google Cloud should also continue adding smart acquisitions that can help to improve its capabilities as well as its developer community.\n\nIBM posted impressive revenues for its \u201cstrategic imperatives\u201d group which includes Softlayer and Bluemix. The group posted revenues of $9.5 billion and an expected growth of 11%. Cognitive computing, cyber-security and IOT continued to be the highlights of IBM\u2019s cloud offering.\n\nImmediate Areas of Focus: Continue expanding its leadership in the AI space with Watson as well as its IOT and cyber-security efforts must be IBM\u2019s core focus.\n\nCloud seems to have a new focus at Oracle. Constant announcements of new products and services and a renewed strategic focus are signaling to the market that Oracle Cloud matters. The revenue numbers are hard to infer as they are reported in combination with other offerings but we should assume they are still small compared to the market leaders.\n\nImmediate Areas of Focus: Doubling down on its core strengths such as database computing and WebLogic cloud migrations should be a strong focus of Oracle Cloud\u2019s strategy in order to improve its market traction.\n\nAlibaba reported revenues of less than $300 ,million for AliCloud. However, the growth (particularly in China) continues to be impressive. From a go-to-market perspective, AliCloud holds a lot of similarities with AWS in the early days.\n\nImmediate Areas of Focus: Consolidating its dominance in China, launching mainstream infrastructure and platform services that bridge the gap with the market leaders and expanding its offering in key areas such as AI and IOT should remain the core focus for AliCloud. I also believe AliCloud should be more aggressive in terms of M&A in order to expand its feature set as well as its developer and partner communities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-ciscos-acquisition-of-appdynamics-b33f54466f55?source=user_profile---------294----------------",
        "title": "Some Thoughts About Cisco\u2019s Acquisition of AppDynamics",
        "text": "This week, Cisco announced that it is buying enterprise software company appDynamics for an astonishing $3.7 billion. The price almost doubled the $1.9 billion valuation that investors placed on the company in 2015. The premium price amounts to roughly $36 per share, significantly above the expected IPO price for appDynamics. The application performance monitoring(APM) vendors was expected to price its IPO at about $10 to $12 a share.\n\nThe acquisition of AppDynamics represents another step by Cisco towards building a solid enterprise software offering. More importantly, the acquisition has relevant implications for different segments of the enterprise software space. Let\u2019s discuss a few of those:\n\nVenture capitalists were among the biggest winners in the acquisition of AppDynamics. Firms such as Greylock Partners and LightSpeed Venture Partners help big equity stakes in the company at about 20.8% ownership. Other investors such as Battery Ventures were also among the winners. Even the late stage, growth funds that entered in AppDynamics\u2019 last funding rounds were able to realize big returns.\n\nIn an unstable environment for public markets on which big enterprise software incumbents are enjoying healthy balance sheets, the M&A climate continues to be very favorable. In the case of Cisco, the acquisition of AppDynamics could be considered cheap compared to the valuation the APM vendor could have achieved if the price of the IPO soared on early trading.\n\nThe acquisition of appdynamics represents another example of Cisco\u2019s efforts to enhances its enterprise software portfolio. Under CEO Chuck Robbins, Cisco has been performing important acquisitions of software platforms that complements its networking and hardware offering.\n\n4 \u2014 AppDynamics IOT Efforts Will Be Accelerated Under Cisco\n\nIn recent years, AppDynamics launched new APM offerings for IOT topologies. Even though AppDynamics\u2019 IOT stack was nothing short of impressive from a technological standpoint, its adoption has been relatively limited. With Cisco\u2019s presence in the IOT space, Appdynamics IOT offerings are likely to experience a larger and more consistent adoption.\n\nThe acquisition of AppDynamics represents mixed news for the software IPO environment. The APM vendors was expected to inaugurate the IPO market in 2017. From that perspective, Wall Street will be missing a solid stock that could compete with similar public traded equities such as NewRelic or Splunk. However, the large premium that Cisco paid for AppDynamics is a sign that the healthy validation of some tech unicorns can be validated in the public markets.\n\n6 \u2014 Who Will Get Acquired Next?\n\nIs hard to tell whether Cisco\u2019s acquisition of AppDynamics will immediately trigger other acquisitions in the APM space. With most of the big players such as Splunk or NewRelic trading at premium valuations as public companies the target for acquisitions could centered on emerging APM startups. Companies such as HPE, Oracle or VMWare(Dell) could be potential acquirers."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-ibm-earnings-report-1a2be36fe3bd?source=user_profile---------295----------------",
        "title": "Some Thoughts About IBM Earnings Report \u2013 Jesus Rodriguez \u2013",
        "text": "IBM reported fourth quarter earnings last week and analysts have reasons to be optimistic about the results. Despite reporting its 19th consecutive quarter of sales decline, big blie produced better than expected quarterly revenues. More importantly, the numbers showed strong indication that IBM\u2019s famous transformation initiative is finally working.\n\nIn terms of the numbers, IBM reported a company forecast adjusted earnings of $13.80 per share beating analyst estimates of $13.74. The highlight of the earnings report was the performance of the so called \u201cstrategic imperatives\n\n\u201c which includes areas such as cloud, mobile, analytics and security. The group of technology segments which is the core of IBM\u2019s transformation now accounts fro 41% of IBM\u2019s total sales.\n\nEven though IBM\u2019s revenue fell 1.3% to $21.77 billion, it was still ahead of analyst\u2019s expectation of $21.64 billion. The market has recently rewarded IBM\u2019s stock which have raised 36.2% in the last 12 months (making long term shareholders like Warren Buffett look like geniuses again ;) )\n\nIBM\u2019s \u201cstrategic imperatives\u201d have been at the center of the movement of shift big blue from a traditional enterprise software company to a player in merging technology markets. The transformation has seen IBM jump in late in some markets such as cloud computing while learning the charge in others such as cognitive computing. The most impressive part of IBM\u2019s transformation is that it has taken place without avoiding the scrutiny of public markets.\n\nLast year I remember a prominent Silicon Valley venture capitalist (going to save the name) telling CNBC that betting on IBM was betting against the future of America. The comment came a few days after another disappointing earning report by big blue that raised some doubts about the viability of the ongoing transformation. Today, IBM\u2019s clear leadership in foundational technology markets such as artificial intelligence(AI) or internet of things(IOT) certainly presents a more appealing picture to investors.\n\nOne important aspect to understand and value IBM\u2019s transformation is that it should be seen as a continuous process without an explicit end date. A strong indicator that IBM\u2019s transformation has reached a mature stage will be when the software giant switches back to growth mode. However, analysts should not consider that sign a final point in the transformation. As IBM embarks in new strategic initiatives in green-feild markets such as blockchain technologies, its transformation imperatives are likely to evolve and change. From Wall street\u2019s perspective, IBM should aim to achieve stability and predictability and not a final stage on its strategic initiatives.\n\nTo put IBM\u2019s transformation movement in perspective, let\u2019s rapidly draw a quick comparison about big blue\u2019s position in strategic tech markets with a group of the incumbents that led the enterprise software space in the last decade: Microsoft, Oracle, SAP and HPE.\n\nIn the cloud computing space, IBM is training Microsoft azure but its performance remain ahead of Oracle, SAP and JHPE. IBM is also far ahead of other enterprise software incumbents in the AI and cognitive computing markets. In the IOT space, IBM Watson IOT Platform and Microsoft Azure IOT have achieved comparable market tractions which are superior than the results achieved by SAP, Oracle and HPE. IBM\u2019s cyber-security offerings have also out-innovated the rest of the traditional enterprise software incumbents.\n\nThat simple analysis clearly shows the impact of IBM\u2019s transformation in the emerging technology areas. At least for now, the number are showing a positive result."
    },
    {
        "url": "https://medium.com/@jrodthoughts/10-ideas-about-the-immediate-future-of-serverless-computing-f04ee3934fe2?source=user_profile---------296----------------",
        "title": "10 Ideas About the Immediate Future of Serverless Computing",
        "text": "Earlier this month, I wrote some predictions for the serverless computing space in 2017. Based on some o fthe feedback received as well as some new information available about the roadmap of the top serverless tacks in the market, I\u2019ve put together a compilation of 10 ideas that I think are going to be relevant in the immediate future of serverless technologies. Let\u2019s take a look:\n\nIntegration with SaaS and on-premise back-office systems should be a strong focus of serverless computing stacks in the near future. Platforms such as AWS Lex recently introducess a few serverless connectors that as part of its natural language processing platform.\n\nComposing serverless functions into more complex serverless routines will allow serverless computing stacks to tackle more sophisticated scenarios. Lambda Step Functions is an initial example of how this type of technology should work.\n\nI believe serverless routines are going to become the default extensibility mechanism for SaaS systems. Platforms such as Office365m Dynamics 365 or G-Drive are ideal candidates to pioneer that concept.\n\nCloud platforms such as Azure or AWS have been incredibly successful implementing tools to migrate on-premise solutions to cloud architectures. A similar approach that migrates the backed of traditional enterprise solutions to serverless architectures can be a great catalyzer for serverless computing stacks in the enterprise.\n\nExecuting serverless functions offline on on-premise or IO Runtimes is likely to become a key capability of the next generation of serverless computing platforms. AWS Greengrass is a great example of this capability.\n\nRapid application development(RAD) tools that enable the creation of web and mobile application with serverless backends are likely to become popular within citizen developers in the future.\n\nI firmly believe that serverless computing stacks can help reimaging traditional enterprise middleware technologies for the new era of IOT, voice interfaces, bots, etc. The integration of serverless routines into traditional middleware stacks could also be an interesting trend to watch.\n\nImagine a world on which developer would write normal programs and simply declare which routines should be deployed as serverless functions. To enable that scenario, compilers and deployment tools will have to be smart enough to identify those declarative settings and take the corresponding actions.\n\n9 \u2014 Private Serverless Function Marketplaces Extending the current serverless marketplace model to support private environments will be essential to improve the adoption of serverless stacks in the enterprise. This serverless marketplace model will be similar to the role that the app store plays for mobile apps.\n\nTools that improve the lifecycle management of serverless application in areas such as testing, monitoring or versioning should be high on the roadmap of serverless computing stacks. Integration with mainstream application lifecycle management tools might also be a welcomed addition to serverless computing stacks."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-missing-to-make-ai-conversations-more-real-bfcb2aca5ecb?source=user_profile---------297----------------",
        "title": "What\u2019s Missing to Make AI Conversations More real \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, I was reading about Semantic Machines, a Berkley-based startup that is building a new conversational platform to make AI-powered voice and text interactions \u201cmore human\u201d. Specifically Semantic Machines is building technologies that resemble human memory in order to improve AI-driven conversations.\n\nMemory is one of the cognitive aspects at the center o human intelligence and one that is notoriously missing from conversational AI platforms. Despite their unquestionable sophistication, natural language processing(NLP) platforms such as Facebook\u2019s Wit.ai, Google\u2019s API.ai or Microsoft LUIS operate in a very similar way: they process natural language sentences, detect entities and intests and execute relevant actions. You don\u2019t need to be neuroscientist to realize that there are many aspects of human conversations that don\u2019t quite match that model .Looking at the work developed by Semantic Machines, I started thinking about other cognitive aspects of human dialogs that could enhance conversational platforms.\n\nLet\u2019s start with the cognitive element at the center of Semantic Machines\u2019 work: Memory. The brain\u2019s neocortex continuously uses memory in order to respond to cognitive inputs. That\u2019s how we are able to recognize words in a text without analyzing character by character or are instinctively react to specific phrases remembering an analogy from a past experience. In the context of conversational platforms, memory can be used to enrich and personalize user-system interactions beyond recognizing the intent of a phrase.\n\nJudgment is a fundamental aspect of human intelligence and, consequently, of human conversations. From basic stereotypes to new opinions based on pre-existing biases or prejudices, judgments are an omnipresent elements in our daily dialogs. Obviously, we should not expect AI conversations to become judgmental by default but understanding implicit judgments in sentences can help to improve the dialogs between humans and systems.\n\nMetaphors are one of the hardest cognitive phenomenon\u2019s to explain but one that plays a key role in human conversations. Metaphors are, essentially, the ability of linking concepts to other concepts from unrelated domains. Developing cross domain context knowledge will be key to create and identify metaphors into AI-NLP systems.\n\nConversational AI platforms are actively improving their understanding and usage of contextual information but they still have along way to go in order to resemble human reasoning. Contextual elements are always present in human conversations Location, time, social setting, previous conversations are just some of the hundreds of contextual data points surrounding any human conversation. Paradoxically, the usage of contextual information might be one of the easiest aspects to improve within the existing generation of conversational platforms.\n\nSupervised training is the main mechanism we use to make conversational bots smarter. However, AI training techniques fall short o replicating human learning process. As it turns out, we are very good at acquiring knowledge as part of conversational interactions. Building conversational applications that can build new knowledge as part of the exchanges in a dialog and apply that new knowledge in new conversations is a drastic improvement compare to the current generation of conversational applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-googles-acquisition-of-twitter-mobile-fabric-621440d45726?source=user_profile---------298----------------",
        "title": "Some Thoughts About Google\u2019s Acquisition of Twitter Mobile Fabric",
        "text": "A few days ago, Twitter announced that it was selling its Mobile Fabric business to Google. The sale represents another step in Twitter\u2019s efforts to focus its technology efforts as the social media giant struggles with its perception in public markets. The acquisition of Twitter Mobile Fabric gives Google another relevant asset in its portfolio of mobile technologies. Beyond the obvious headlines, the transaction has some interesting implications for Google, Twitter and the mobile technology ecosystem in general. Here is a summary of some points in my initial analysis of the acquisition:\n\nApigee, API.ai and now Twitter Mobile Fabric. Diane Greene\u2019s group continues to excel at making incredibly smart acquisitions that complement the feature set of Google Cloud.\n\n2 \u2014 Twitter Mobile Fabric Has Found a Better Home at Google\n\nFrom the mobile developer standpoint, Mobile Fabric is likely to see a higher adoption and focus as part of Google Cloud. Despite the impressive numbers in terms of developer adoption, Mobile Fabric was never strong priority for rTwitter.\n\nThe sale of Mobile Fabric indirectly entail that its roughly 600,000 developers are moving away from the twitter ecosystem onto the Google Cloud platform. That number represents an important percentage of Twitter\u2019s developer base. The acquisition is another example of Twitter\u2019s continued struggles trying to deliver a comprehensive message to developers.\n\n4 \u2014 Firebase Just Got More interesting\n\nTwitter Mobile fabric is very likely to be integrated in Googel\u2019s Firebase platform adding strong analytics and user engagement capabilities to the already popular developer stack.\n\n5 \u2014 The Sale is Immaterial for Twitter\u2019s Stock Performance\n\nThe sale of Mobile Fabric is unlikely to ghave an impact on Twitter\u2019s stock price or investor sentiment. At best, investors can praise Twitter\u2019s focus on streamlining its prioties and perceive the transaction as an effort to avoid unnecessary distractions.\n\n6 \u2014 Google Cloud can go Head-To-Head with AWS as the Most Popular Mobile Backend Platform in the Market\n\n600,000 new developers, a robust mobile analytics suite and a robust developer tools and frameworks are welcomed additions that Twitter Mobile Fabric brings to Google Cloud mobile developer services. The combination of firebase, Apigee, Mobile Fabric as well as previous acquisitions such as Appurify positions Google Cloud as a strong second place in the mobile cloud platform market trailing AWS Mobile hub but ahead of Azure Mobile Apps and Bluemix.\n\nAt the moment, Google cloud mobile developer experience is a set of disjointed (altough popular) frameworks and services. A more integrated experience would certainly be welcomed by mobile developers.\n\nDespite the decline of mobile developer technologies from a VC investment, the acquisition of Twitter Mobile Fabric shows that mobile backed services startups with large developer communities continue to be a strong M&A target for PaaS incumbents such as Amazon, Google, Microsoft or IBM."
    },
    {
        "url": "https://medium.com/@jrodthoughts/aws-lex-can-be-a-strong-contender-in-the-conversational-platform-space-12a8d0547607?source=user_profile---------299----------------",
        "title": "AWS Lex Can be a Strong Contender in the Conversational Platform Space",
        "text": "AWS Lex was one of the most relevant additions to the AWS platform last year and one that is getting a lot of attention from developers. Lex is a platform that enables the implementation of conversational interfaces that can be used from bots and third party client applications. Powered by the same deep learning stack behind the popular Alexa service, AWS Lex can become a force to reckon with in the conversational platform market.\n\nLex is entering a highly competitive space that already includes incumbent services such as Google\u2019s API.ai, Facebook\u2019s Wit.ai Microsoft\u2019s LUIS, IBM\u2019s Watson Dialog Service as well as a few innovative starts like Semantic Machines. To some extend, the release of AWS Lex completes the picture of the big five contenders in the conversational platform market: IBM, Microsoft, Google, Facebook and Amazon. From the perspective of the competitive landscape, AWS Lex has some very unique advantages as well as some tangible limitations.\n\n1 \u2014 Voice Interface: AWS Lex does a phenomenal job enabling the implementation of bots that can use voice and text interfaces interchangeably. The support for voice bots seems superior than the other incumbent conversational platforms in the market which are mostly focused on text interfaces.\n\n2 \u2014 AWS Lambda Integration: AWS Lex relies on the Lambda serverless computing stack to implement \u201cfulfillments\u201d which are actions that need to be triggered based on a specific intent. Currently, Lambda is by fat the most widely used and most technologically advanced serverless computing platform in the market which brings some indirect advantages to the Lex service.\n\n3 \u2014 Alexa Skills Ecosystems & Connectors: AWS Lex can indirectly benefit from the massive number of Alexa Skills which can be adapted as Lex\u2019s Fullfillments. Also, AWS Lex already includes a series of serveless connectors for SaaS systems sch as Salesforce, Marketo or ZenDesk which are a unique assent to the platform .\n\n4 \u2014 Developer and Partner Communities: Without a doubt, AWS\u2019 developer and partner communities are a competitive differentiator for Lex and one that will be hard to match by most of the incumbents in the space. At the moment, only Microsoft counts with developer and partner ecosystems that can compare with AWS\u2019\n\nAWS Lex is an incredibly strong first iteration of conversational platform. However, despite the robustness of the product, there are still some challenges that should be considered:\n\n1 \u2014 Lack of Messaging Platform: Facebook has Messenger, Microsoft has Skype, Google has Allow and Amazon has\u2026.well\u2026Echo. The lack of a messaging runtime that acts that the default distribution channel can be a limitation for Lex bots in the long term. Obviously, Echo\u2019s customers are a relatively small population compared to Facebook Messenger\u2019s or Skype\u2019s user base.\n\n2-Last to Market: Despite its attractive feature set, we shouldn\u2019t ignore the fact that AWS Lex has been the last of the incumbent conversation platforms to enter the market and has some catch up to do with companies such as Facebook or Microsoft."
    },
    {
        "url": "https://medium.com/@jrodthoughts/types-of-artificial-intelligence-learning-models-814e46eca30e?source=user_profile---------300----------------",
        "title": "Types of Artificial Intelligence Learning Models \u2013 Jesus Rodriguez \u2013",
        "text": "Learning is one of the fundamental building blocks of artificial intelligence (AI) solutions. From a conceptual standpoint, learning is a process that improves the knowledge of an AI program by making observations about its environment. From a technical/mathematical standpoint, AI learning processes focused on processing a collection of input-output pairs for a specific function and predicts the outputs for new inputs. Most of the artificial intelligence(AI) basic literature identifies two main groups of learning models: supervised and unsupervised. However, that classification is an oversimplification of real world AI learning models and techniques.\n\nTo understand the different types of AI learning models, we can use two of the main elements of human learning processes: knowledge and feedback. From the knowledge perspective, learning models can be classified based on the representation of input and output data points. In terms of the feedback, AI learning models can be classified based on the interactions with the outside environment, users and other external factors.\n\nFactoring its representation of knowledge, AI learning models can be classified in two main types: inductive and deductive.\n\n\u2014 Inductive Learning: This type of AI learning model is based on inferring a general rule from datasets of input-output pairs.. Algorithms such as knowledge based inductive learning(KBIL) are a great example of this type of AI learning technique. KBIL focused on finding inductive hypotheses on a dataset with the help of background information.\n\n\u2014 Deductive Learning: This type of AI learning technique starts with te series of rules nad infers new rules that are more efficient in the context of a specific AI algorithm. Explanation-Based Learning(EBL) and Relevance-0Based Learning(RBL) are examples examples o f deductive techniques. EBL extracts general rules from examples by \u201cgeneralizing\u201d the explanation. RBL focuses on identifying attributes and deductive generalizations from simple example.\n\nBased on the feedback characteristics, AI learning models can be classified as supervised, unsupervised, semi-supervised or reinforced.\n\n\u2014 Unsupervised Learning: Unsupervised models focus on learning a pattern in the input data without any external feedback. Clustering is a classic example of unsupervised learning models.\n\n\u2014 Supervised Learning: Supervised learning models use external feedback to learning functions that map inputs to output observations. In those models the external environment acts as a \u201cteacher\u201d of the AI algorithms.\n\n\u2014 Semi-supervised Learning: Semi-Supervised learning uses a set of curated, labeled data and tries to infer new labels/attributes on new data data sets. Semi-Supervised learning models are a solid middle ground between supervised and unsupervised models.\n\n\u2014 Reinforcement Learning: Reinforcement learning models use opposite dynamics such as rewards and punishment to \u201creinforce\u201d different types of knowledge. This type of learning technique is becoming really popular in modern AI solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/blockstack-and-the-emergence-of-the-decentralized-web-52e97a790e5d?source=user_profile---------301----------------",
        "title": "Blockstack and the Emergence of the Decentralized web",
        "text": "Blockstack, a New York-based company aiming to build a platform that powers decentralized applications, recently raise $5.3 million from Union Square Ventures. The funding round represents a strong validation for the emergent market of decentralized web applications.\n\nI\u2019ve been following Blockstack for a while and I continue to be impressed by their bullish vision based on building the infrastructure for a new type of internet. Blockstack relies on blockchain technologies as the core element of its platforms. Even though there are many blockchain application developer platforms in the market, Blockstack seems to be laser-focused on assembling the right infrastructure building blocks for the implementation of decentralized web applications. In that sense, Blockstack enables capabilities such as storage, naming resolution, identity management which are foundational pieces of web applications. The latest release [0.14.0] includes major enhancements including the new Atlas network that improves the reliability of the core store infrastructure compared to previous versions based on distributed hash tables(DHTs).\n\nTo understand Blockstack\u2019s vision or the general ideas behind the decentralized web, it might help to go back to the early days of the Internet. During those days, the efforts were not centered on building social networks like Facebook, dating applications like Tinder or messaging platforms like Snapchat. Instead, the efforts were focused on building the core Snap chat of the internet and powering the first generation of application that leverage that infrastructure to improve user\u2019s lives. Following that analogy, we can start envisioning the building blocks that are going to be needed to power the decentralized web using platforms such as Blockstack. Here is a quick list:\n\n\u2014 Networking (Web 1.0 equivalent: Cisco): Building the basic networking protocols in areas such as routing, multi-casting, traffic optimization, etc will be essential to power decentralized web applications.\n\n\u2014 Browser (Web 1.0 equivalent: NetScape): The decentralized web is likely to require a new type of web browser optimized to work with content distributed in a federated network.\n\n\u2014 Search (Web 1.0 equivalent: Google): In the decentralized web, search will be likely to remain the prevalent for discovering and accessing data.\n\n\u2014 Storage (Web 1.0 equivalent: Oracle): Storage models for files, structured and semi-structured data and other assets required by decentralized web applications is also a MUST have capability for decentralized web applications.\n\n\u2014 Identity: Identity wasn\u2019t a big component of the web 1.0 generation but it has become a foundational piece of the internet and is definitely relevant to decentralized web applications.\n\n\u2014 Content Distribution (Web 1.0 equivalent: Akamai): Content distribution and routing is a hard problem to solve but an essential component of decentralized web solutions.\n\n\u2014 Standard Based and Infrastructure Agnostic: I saved the most obvious for last :) A decentralized web infrastructure MUST be able to work across different blockchain networks without introducing heavy dependencies on any particular infrastructures. Even though platforms such as Blockstack are still heavy reliant on the Bitcoin blockchain, its architecture provides a step on the right direction.\n\n\u2014 Killer Consumer Apps (Web 1.0 equivalent: Amazon.com, eBay): To increase the mainstream adoption of the decentralized web, the industry will need to produce killer consumer applications that drive mainstream users onto this new type of infrastructure. Ecommerce seems to be the obvious market to tackle in this area. a decentralized Amazon.com or eBay (ex: OpenBazaar) makes a lot of sense for the decentralized web. s"
    },
    {
        "url": "https://medium.com/@jrodthoughts/tdaas-looks-to-democratize-artificial-intelligence-training-45186a488fff?source=user_profile---------302----------------",
        "title": "TDaaS Looks to Democratize Artificial Intelligence Training",
        "text": "Last week, Mighty AI, formerly known as Spare5, announced a new $14 million funding round to expand its crowsourced artificial intelligence(AI) training platform. The reoun was led by Intel Capital as well as GV (Google Ventures), Accenture Ventures and previous Spare5 investors.\n\nThe investment on Mighty AI serves as the strongest validation of a new and yet very important discipline in the AI ecosystem: Training Data as a Service(TDaaS). Conceptually, TDaaS provides a cloud model for the curation of training data that will be used by AI algorithms. Mighty AI innovates on the traditional TDaaS concepts by leveraging crowsourcing techniques that can simplify and streamline the availability of training data for AI solutions.\n\nTDaaS platforms are banking on the long termi viability of supervised and semi-supervised AI models. While most AI experts agree that unsupervised algorithms are the future of AI, they also agree that technologies need to evolve in order to improve the practical applicability of unsupervised AI solutions. For the time being, supervised models are predominant in AI solutions. In many mission critical AI solutions, the training of supervised AI models is cost prohibited. As a result, companies such as Google or IBM have been investing tens of millions od dollars to acquire domain experts that can help train and build knowledge into their AI solutions. Crowsourced TDaaS models can help to drastically democratize the training of AI solutions while also providing many other interesting benefits.\n\n1 \u2014 Elastic Scalability of AI Training: Some AI problems require more training data and more intense processes than other. Crowsourced TDaaS solutions can elastically scale the curation of training data while controlling the costs.\n\n2 \u2014 Consistent Training Data Management Tools: Crowsourced TDaaS solutions such as Mighty AI provide consistent tools and user experience to manage training data across different AI models.\n\n3 \u2014 Consists Training Data APIs and Libraries: TDaaS platforms provide a consistent programming model for accessing training data across different AI solutions.\n\n4 \u2014 Training Data Continuous Curation and Monitoring: In AI systems, training is a continuous exercise that expands throughout the lifecycle of an AI solution. TDaaS platforms provide the infrastructure for continuously capturing, updating and curating training data relevant to AI solutions.\n\n5 \u2014 Public and Proprietary Training Data: Although the current generation of TDaaS solutions is focused on leveraging public data, the same model should extend to private, domain-specific data in the near future.\n\n5 Ideas or the Roadmap of TDaaS Platforms\n\nSome of the following ideas might be part of the immediate roadmap of TDaaS platforms:\n\n1 \u2014 Interoperability with Cloud ML Platforms: Solutions such as Mighty AI should provide seamless interoperability with cloud AI-ML service such as AWS ML, Azure ML or Google Cloud ML.\n\n2 \u2014 Integration with AI Training Tools: TDaaS solutions should integrate with the new generation of AI training tools such as the ones released by DeepMind, OpenAI, Microsoft, Google and other to AI solution providers.\n\n3 \u2014 AgaaS Interoperability: Algorithm as a Service(AgaaS) platforms such as Algorithmia should provide integration with TDaaS platforms in order to improve the testing and validation of AI algorithms published in the platform.\n\n4 \u2014 AI Training Effectiveness Monitoring: TDaaS platforms should include APIs and tools to monitor and validate the effectiveness of specific training datasets and models.\n\n5 \u2014 AI Training Tools: It seems obvious but the AI ecosystem desperately needs better training tools and experiences. TDaaS platforms on a unique position to address that limitation."
    },
    {
        "url": "https://medium.com/@jrodthoughts/alexa-will-become-the-default-digital-assistant-for-your-home-but-will-have-to-battle-cortana-in-a95f07c02f26?source=user_profile---------303----------------",
        "title": "Alexa Will Become the Default Digital Assistant for Your home but Will Have to Battle Cortana in\u2026",
        "text": "Amazon Alexa is steadily expanding its role from being the platform behind popular consumer devices such as Echo or Dot to become the default broker for voice-driven devices in home environments. With more and more start devices supporting and integrating with Alexa [35 devices announced Alexa integration at CES], the cloud service is increasingly becoming a gateway for voice integration between users and devices.\n\nIn terms of technical capabilities, Amazon Alexa seems to be leading the highly competitive digital assistant market. In addition to its dominance in the gome space, Alexa is starting to make solid inroads in the enterprise. However, differently from home environments, Alexa is likely to face at least one formidable competitor in the enterprise: Microsoft Cortana.\n\nLooking at the digital assistant market, Alexa and Cortana seems better equipped to power voice experiences in the enterprise than competitors such as Google Allo or Apple Siri. To understand that point, we should consider some of the factors that will be essential to streamline voice integrations in the enterprise.\n\n5 Essential Capabilities of Voice Digital Assistants in the Enterprise\n\nHere are some of the fundamental elements that both Alexa and Cortana will need to enable in order to streamline its adoption in the enterprise.\n\n1-Multi-Device Experience: From Smartphone\u2019s, wearable\u2019s to conference room experiences, enterprise voice assistant will need to operate across more than one device. Alexa is widely supported across many devices while Cortana is already included as part of Windows 10.\n\n2 \u2014 Voice Connectors or Skills: Integrating with back-office systems is another essential aspect to adopt voice interactions in the enterprise. Alexa already includes several SaaS connectors and Cortana should be able to bring this capability to life soon.\n\n3 \u2014 SaaS Distributions: Just like mobile apps, voice bots are likely to be mostly adopted via other SaaS and back-office systems solutions. Cortana\u2019s integration with Office365 and Dynamics365 can become a catalyzer in this area. Given its popularity, Alexa is likely to see integration with some of the top SaaS systems in the market.\n\n4 \u2014 Voice Identity Management: In order to be adopted in the enterprise, voice digital assistants will need to correlate user\u2019s voice with their corporate credentials as well as their credentials on different corporate systems. Microsoft\u2019s footprint in the enterprise with technologies such as Active Directory Federation Services and Azure Active Directory gives Cortana a strong edge in this aspect.\n\n5 \u2014 Skills Management Experience: Just like mobile app stores, voice digital assistants in the enterprise should enable the provisioning, configuration and management of Skills that can be used on voice-driven business applications. This capability might translate onto the implementation of private, dedicate versions of alexa and Cortana skills management portals.\n\n5 Quick Points that Compare Alexa and Cortana in the Enterprise\n\nComparing Alexa and Cortana\u2019s potential in the enterprise is a bit speculative at this point. However, below, I\u2019ve summarized a series of quick facts that I believe should be considered by people thinking about this area:\n\n1 \u2014 Alexa has a better and more complete Skills portfolio.\n\n2 \u2014 Cortana currently has a stronger potential for building large distribution channels driven by systems such as Office365 and Dynamics365.\n\n3 \u2014 Alexa is supported in a larger number of smart devices that are relevant in the enterprise.\n\n4 \u2014 Cortana has the edge on enterprise security based on the large footprint of Active Directory Federation Services and Azure Active directory.\n\n5 \u2014 Neither assistant currently has an advantage when comes to integration with enterprise backed systems. However, Cortana might be able to leverage Microsoft robust integration services such as Flow and LogicApps."
    },
    {
        "url": "https://medium.com/@jrodthoughts/artificial-intelligence-is-obsessed-with-recreating-with-brain-but-does-it-need-to-a03090d9c09f?source=user_profile---------304----------------",
        "title": "Artificial Intelligence is Obsessed with Recreating with Brain but Does it Need to?",
        "text": "Understanding and recreating the capabilities of the human brain has been one of the ambitions of artificial intelligence(AI) seems its inception. The group within AI practitioners that focus on simulating brain-like capabilities are known as connectionists and they leverage techniques such as neural networks as the fundamental mechanism for recreating models similar to the human brain.\n\nRecreating the capabilities human brain is an incredibly ambitious plan for AI at a moment on which neuroscience is still struggling to understand the brain from a biological and cognitive standpoint. An alternative school of thought within the AI community is that to focus the efforts on recreating the elements of the human brain that enable intelligence and ignore the rest for now.\n\nThe region of the brain responsible of intelligence is known as the neocortex and is formed of different layers of neurons that process information and infer specific patterns in order to take actions. The AI practitioners that favor the focus on intelligence essentially propose that should focus on emulating the patterns on the neocortex and ignore other regions of the brain. Although controversial, the idea certainly pragmatic and interesting.\n\nBeyond the obvious goal of AI systems of building and using knowledge, there are several capabilities of the brain that can be achieved by AI systems that focus on recreating intelligence. AI solutions built using this model that can recreate many of the process that are the result of bidirectional interactions between neurons on different regions of the neocortex. These processes power some of the most fascinating capabilities of the brain such as creativity, imagination, reasoning and many others.\n\nWhat Are We Missing?\n\nBy solely focusing on the neocortex, AI systems won\u2019t be able to emulate capabilities driven by other areas of the human brain. One clear example would be human characteristics like emotions that are the dependent on chemical reactions in tithe brain. Fear, anger, sadness, ambition, envy, empathy are some examples of emotions that fall outside the neocortex and, consequently, will be ignored by AI systems that focus on recreating that area of the brain. Many will argue that excluding those characteristics are not necessarily a bad thing ;) After all, who wants to deal with sad, angry or ambitious AI systems?\n\nWhat Technologies Can Help to Better Model Intelligence?\n\nUndoubtly, the AI platform system is exploding and there are many impressive technologies in the space. Google\u2019s DeepMind seems to be a platform that is constantly reaching new levels to simulate intelligence. During last year\u2019s match between DeepMind\u2019s AlphaGO and GO\u2019s number one player, experts were shocked by the levels of \u201ccreativity\u201d and \u201cimagination\u201d demonstrated by AlphaGo.\n\nAmong the mainstream frameworks in the AI space, TensorFlow provides a very robust model to model graphs that can bidirectionally exchange data in the form of Tensors. That flexible model is very similar to the foundational elements of the neocortex."
    },
    {
        "url": "https://medium.com/@jrodthoughts/6-types-of-artificial-intelligence-environments-825e3c47d998?source=user_profile---------305----------------",
        "title": "6 Types of Artificial Intelligence Environments \u2013 Jesus Rodriguez \u2013",
        "text": "When designing artificial intelligence(AI) solutions, we spend a lot of time focusing on aspects such as the nature of learning algorithms [ex: supervised, unsupervised, semi-supervised] or the characteristics of the data [ex: classified, unclassified\u2026]. However, little attention is often provided to the nature of the environment on which the AI solution operates. As it turns out, the characteristics of the environment are one of the absolutely key elements to determine the right models for an AI solution.\n\nThere are several aspects that dintuiguish AI environments. The shape and frequency of the data, the nature of the problem , the volume of knowledge available at any given time are some of the elements that differentiate one type of AI environment from another. Understanding the characteristics of the AI environment is one of the first tasks that AI practitioners focused on in order to tackle a specific AI problem. From that perspective, there are several categories we use to group AI problems based on the nature of the environment.\n\nComplete AI environments are those on which, at any give time, we have enough information to complete a branch of the problem. Chess is a classic example of a complete AI environment. Poker, on the other hand, is an incomplete environments as AI strategies can\u2019t anticipate many moves in advance and, instead, they focus on finding a good \u2018equilibrium\u201d at any given time.\n\nA fully observable AI environment has access to all required information to complete target task. Image recognition operates in fully observable domains. Partially observable environments such as the ones encountered in self-driving vehicle scenarios deal with partial information in order to solve AI problems.\n\nCompetitive AI environments face AI agents against each other in order to optimize a specific outcome. Games such as GO or Chess are examples of competitive AI environments. Collaborative AI environments rely on the cooperation between multiple AI agents. Self-driving vehicles or cooperating to avoid collisions or smart home sensors interactions are examples of collaborative AI environments.\n\nstatic AI environments rely on data-knowledge sources that don\u2019t change frequently over time. Speech analysis is a problem that operates on static AI environments. Contrasting with that model, dynamic AI environments such as the vision AI systems in drones deal with data sources that change quite frequently.\n\nDiscrete AI environments are those on which a finite [although arbitrarily large] set of possibilities can drive the final outcome of the task. Chess is also classified as a discrete AI problem. Continuous AI environments rely on unknown and rapidly changing data sources. Vision systems in drones or self-driving cars operate on continuous AI environments.\n\nDeterministic AI environments are those on which the outcome can be determined base on a specific state. In other words, deterministic environments ignore uncertainty. Most real world AI environments are not deterministic. Instead, they can be classified as stochastic. Self-driving vehicles are a classic example of stochastic AI processes."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bringing-tensorflow-to-the-enterprise-8a3fec4e1907?source=user_profile---------306----------------",
        "title": "Bringing TensorFlow to the Enterprise \u2013 Jesus Rodriguez \u2013",
        "text": "TensorFlow is one of the most popular open source project in Github and certainly the fastest growing deep learning framework in the market. Like many other popular open source projects, there is a market for bringing distributions of those technologies to the enterprise. In the case of TensorFlow, the possibility of an enterprise distribution is even more appealing considering the importance of deep learning and artificial intelligence(AI) in modern business solutions.\n\nDespite its robust deep learning capabilities, TensorFlow is still missing a lot of relevant features to enable its mainstream adoption in the enterprise. Fundamentally, an enterprise distribution of TensorFlow will need to leverage other open source frameworks in order to in relevant areas of enterprise AI solutions such as security, management, monitoring and others. How would a TensorFlow enterprise distribution look like? Here are a few ideas to consider:\n\n1 \u2014 TensorFlow Cluster Manager: TensorFlow Clusters are groups of jobs focused on a single objective [ex: training a neural network]. More robust tools for managing and configuring clusters will be required to adopt TensorFlow in mission critical enterprise solutions.\n\n2 \u2014 Training Tools: TensorFlow has an incredibly robust model for training models. That flexibility should be complemented with tools in order to allow non-developers to train TensorFlow programs.\n\n3 \u2014 TensorBoard Extensions: TensorBoard is a fantastic tool for evaluating and debugging TensorFlow programs. Creating new extensions for TensorBoard will be a very welcoming addition to an enterprise distribution of TensorFlow.\n\n4 \u2014 TensorFlow Model APIs: TensorFlow relies on the Master-Worker Service model to enable the distributed execution of deep learning graph[hs. An enterprise distribution of TensorFlow should extend this model and expose APIs directly from TensorFlow graphs in order to increase the interoperability with third party applications. Cloud machine learning(ML) stacks such as Azure ML or AWS ML enable this capability very effectively.\n\n5 \u2014 TensorFlow Graph Store: TensorFlow graphs are persistent by design. Enterprise TensorFlow solutions could benefit from extensions to this model that leverage robust database as the persistent store for deep learning programs.\n\n6 \u2014 Data Source Connectors: An enterprise distribution of TensorFlow should provide connectivity with mainstream enterprise databases and back-office systems in order to simplify the access to data relevant to deep learning graphs.\n\n7 \u2014 Security Services: Services that enable security capability such as authentication, access control or data privacy will be essential in order to streamline the adoption of TensorFlow in the enterprise.\n\nThere are several players in the data intelligence market well positioned to provide an enterprise distribution of TensorFlow. Here are my top picks:\n\n1 \u2014 Big Data Platform Vendors: Platforms such as Cloudera, Hortonworks, MapR or DataStax can benefit from extending its capabilities into the AI space. Providing an enterprise distribution of TensorFlow that integrates with their big data platforms seems like a seamless way to make that transition.\n\n2 \u2014 Startups: We can always count on new startups that will extend TensorFlow capabilities into the enterprise.\n\n3 \u2014 Google: Google hasn\u2019t been exactly successful commercializing on-premise enterprise software. However, an enterprise distribution of TensorFlow that complements Google Cloud ML stack could be an interesting idea for the internet giant."
    },
    {
        "url": "https://medium.com/@jrodthoughts/10-differences-between-voice-and-text-conversations-ca1fc4c9e4dd?source=user_profile---------307----------------",
        "title": "10 Differences Between Voice and Text Conversations",
        "text": "A few days ago, Facebook CEO Mark Zuckerberg blogged about his experiences building Jarvis, a digital butler that he built as part of his personal yearly challenge. Among the many lessons learned, Zuckeberg highlighted the importance of supporting both voice and text models as conversational interfaces. I found that point particularly interesting s there is not a lot of content about the differences between voice and text when comes to designing conversational interfaces.\n\nMost conversational interface platforms support both text and voice as cognitive input-output mechanisms. However, from the user experience and design standpoints, there are very important differences between text and voice interactions. At a high level, here are some of the key differences that should be taken into consideration when designing voice and text conversational interfaces.\n\n1-Text is Better for Richer UX\n\nTextual conversations allow the usage of rich UI formats such as HTML to display information. From that perspective, text conversation such as the ones that take place with chatbots in a messaging client are better at displaying complex information structures than the equivalent voice models. Facebook Messenger is a great examples of a platform that enables rich UX in textual conversations.\n\n2-Voice is Better to Communication Emotions\n\nVoice bots are more efficient communicating and interpreting emotions as calm, excitement, sadness, etc.By efficiently using elements such as tone, speed, accent and others, voice vots can be very effective establishing an emotional connection with users.\n\n3-Text is Better to Avoid Repetitions\n\nA user interacting with a chatbot in a messaging application can access the entire conversation thread by simply scrolling up and down which avoid unnecessary repetition which are so common in voice conversations. That model of rapidly accessing past information in absent of voice conversations.\n\n4-Voice is Better for Group Conversations\n\nVoice bots such as the ones powered by Amazon Alexa are very effective interacting with multiple users at the same time. That characteristic makes voice bots better equipped to handle real time collaboration scenarios such as dialogs in a meeting room.\n\n5-Text is Better to Implement Complex User Actions\n\nBy leveraging rich UX artifacts such as login forms, links or data lists, chatbots are a better mechanism to model complex user actions such as login into a back-office system, booking a flight, etc.\n\n6-Voice is a Better Form of Authentication\n\nVoice bots are intrinsically more secure as the unique characteristics of the human voice as be used as an authentication mechanism. Additionally, voice bots can effectively single-sign-on into back office systems using the user voice as the initial identity.\n\n7-Text is Better for Long, Data-Centric Communications\n\nText is a robust channel to deliver long texts or data payloads. Attempting to accomplish that with voice bots can result on very complex conversations model subjected to behavior such as interruptions, subject changes and other frequent dynamics in human conversations.\n\n8-Voice is Better for Succinct, Real Time User Actions\n\nVoice is a great channel to communicate succint, real time actions such as buying share of a public stock or requesting an Uber.\n\nAlthough simple, the process of translating voice to text communication in both often misses element such as emotion, tone of voice or other intrinsic aspect of voice conversation which have no direct representation in a textual dialog.\n\nConverting textual conversation to voice often misses UI structures which are very hard to translate into plain text narratives. As a result, text to voice translations are only effective for short forms of text."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-obvious-predictions-about-serverless-computing-in-2017-6e16ad55a704?source=user_profile---------308----------------",
        "title": "Some Obvious Predictions About Serverless Computing in 2017",
        "text": "In the third article about technology predictions in 2017, we are going to focus on the serverless computing space.\n\n2016 was the year on which serverless computing evolved from an obscured architecture style of a mainstream technology trend. Last year brought releases of new serverless platform and major upgrades some of the established ones. More importantly, in 2016, serverless computing was acknowledged by many giants of the software giants as a technology trend to follow in the next few years. What does 2017 has in stock for the serverless computing space. Let\u2019s start with some general predictions about the market.\n\n1 \u2014 Local Serverless Computing Becomes a Trend: The release of AWS Greengrass marked the beginning of the adoption of serverless computing paradigms in local IOT runtimes. In 2017, some of AWS competitors are likely to release technologies similar to Greengrass pushing the adoption of local serverless computing.\n\n2 \u2014 An Open Source, On-Premise, serverless Framework Becomes Popular Within the Developer Community: Serverless computing is a great fit for enterprise environments but the cloud-only nature of most popular serverless platforms remains an impediment for its mainstream adoption. This year we should see the emergence of an open source serverless computing stack that removes some of the roadblocks of enterprises in order to adopt this new computing trend.\n\n3 \u2014 Enterprises Become Serious About Serverless Computing: Complementing the previous point, 2016 was an experimental year for serverless in the enterprise. 2017 should continue the evolution of serverless computing into mission critical enterprise scenarios.\n\nThose were some general predictions about the serverless computing space. Now let\u2019s look at some predictions related to the market leaders:\n\n1 \u2014 Azure Functions Goes On-Premise: This year we are likely to see Azure Functions supported as part of the Azure Stack hybrid cloud platform.\n\n2 \u2014 Office365 Embraces Serverless Extensions: The integration between Office365 and Azure Functions is an obvious asset for extending the features of Office365 applications.\n\n3 \u2014 Cortana Serverless Skills Grow Drastically: After the release of the Cortana Skills Kit, we should expect a large number of serverless extensions developed for the digital assistant in 2017.\n\n1 \u2014 Greengrass Becomes Relevant: AWS Greengrass is a unique flavor of serverless technologies that should receive strong adoption this year.\n\n2 \u2014 Lambda Step Functions Evolves Into a Serverless Middleware: Many companies are likely to start adopting Lambda Step Functions to power middleware scenarios using a serverless architecture style.\n\n3 \u2014 More Serverless Connectors: With Lex Serverless Connectors, AWS shows starting levering serverless technologies to enable the integration with back office and SaaS systems. This trend is likely to continue in 2017.\n\n1 \u2014 OpenWhisks Powers a New IOT Middleware: This year we are likely to see the OpenWhisk serverless platform to power new IOT middleware capabilities for the Watson IOT platform.\n\n2 \u2014 OpenWhisk Sees More On-Premise Adoption: From the lead serverless computing stacks in the market, OpenWhisk is the one with better support for on-premise infrastructures. IBM is likely to extend those capabilities in 2017.\n\n3 \u2014 New Serverless Watson Extensions: This year we are likely to see Openwhisk used as a mechanism to extend the capabilities of the Watson Developer Cloud.\n\n1 \u2014 Allo and Home Drive the Adoption of Google Cloud Functions: In 2017, the adoption of the Google Cloud Functions serverless platform should be fundamentally driven by powering extensions to popular platforms such as Google Home or the Allo digital assistant.\n\n2 \u2014 G-suite Serverless Extensions: Similarly to Microsoft, we should expect Google to start leveraging Cloud Functions as the fundamental extensibility mechanism of G-Suite.\n\n3 \u2014 New Languages are Added to Google Cloud Functions: This year, Google Cloud Functions should add support for new programming languages in order to bridge the gap with competitors."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bots-and-cyber-security-8e1331de7ccd?source=user_profile---------309----------------",
        "title": "Bots and Cyber-Security \u2013 Jesus Rodriguez \u2013",
        "text": "Bots are ones of the most popular consumer technology trends in the industry. From chatbots to digital assistants, bots are an important enabler for user-computer interactions. As a result, bots have been increasingly becoming the target of cyber-security attacks. As a new technology trend, many of the attacks and malicious techniques in bot technologies are relatively unknown to cyber-security platforms.\n\nConsidering that bots rely on mechanisms such as natural language and voice interactions as the fundamental user interface mechanism, they pose some serious security challenges to users in ways we haven\u2019t seen before. As a result, many of the traditional cyber-security protection techniques need to be adapted to the bot world. In order to be efficient in the bot space, cyber-security platforms will have to address some of the following challenges:\n\n\u2014 Unpredictable Behaviors: By leveraging natural language processing techniques, attacks on bots can exhibit almost infinite combination of behavior that are conducive to the same malicious result. That characteristic contrasts with the rather predictable behavior of most malware code.\n\n\u2014 Impact in the Physical World: Bots that attack technologies such as digital assistant can have an immediate impact in the physical world. Imagine a bot that can infect Amazon Echo devices with malicious code to start altering sensors or home-devices connected to the assistant.\n\n\u2014 Many Forms of Attack: Cyber-security attacks targeting bots can leverage many interaction mechanisms depending whether they are using voice or textual interaction models or whether they are executing on messaging platforms or IOT devices. That characteristic makes the task of cyber-security platforms extremely hard.\n\nAs you can see, many of the aforementioned areas are uncharted territory for most cyber-security technologies. But, what are the top forms of cyber-security attacks on bots? Here is an initial list:\n\nBot viruses are a type of attack that will leverage natural language interactions to inject malicious code into a host such as a messaging client runtime. These type of attacks could simply use variations of existing viruses that leverage bots as a transmission mechanism.\n\nDenial of service attacks on bots will infect popular bot hosting platforms such as Amazon Echo in order to launch new attacks to online of physical targets. We\u2019ve seen some example of this type of attacks in recent months.\n\nBot phishers are a type of attacks in which a fake bot will leverage natural language interactions to obtain critical information about a user such as credentials, SSN, credit cards and other relevant information about its target. by leveraging natural language processing techniques, bot phishers can impersonate many actors in order to obtain the target sensitive information.\n\nBot Spywares are a version of that traditional cyber-security attack adapter to the bot world. In essence, a bot spyware will infect a client such as a messaging tool and use it as a host to obtain sensitive information about a user.\n\nbot Sniffers are focused on intercepting user-bot communications in order to track sensitive data. considering that most of the communication between users and bots uses natural language in the form of text or voice, bot sniffers techniques can obtain a lot of meaningful data."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-obvious-predictions-about-the-iot-platform-market-in-2017-5d1e2aa452d?source=user_profile---------310----------------",
        "title": "Some Obvious Predictions About the IOT Platform Market in 2017",
        "text": "Continuing with our series of predictions about technology markets in 2017, today I would like to focus on the internet of things(IOT) platform space.\n\n2016 was a very active year in the IOT platform market with plenty of new releases, acquisitions and innovative technologies. During last year, incumbents such as GE, Amazon, IBM and Microsoft solidified their market positions while many innovative startups came to market trying to focus on specific capabilities of IOT platforms. 2017 promises to be a year driven by the mainstream adoption of IOT platforms in industrial environments as well as the proliferation of platforms for areas such as wearable\u2019s and home automation.\n\nLet\u2019s look at some general predictions about the IOT platform market in 2017.\n\n3 Obvious Predictions About the IOT Market in 2017\n\n1 \u2014 IOT Platform Incumbents Extend Their Market Dominance: IBM, GE, Microsoft, Amazon, PTC are some of the IOT platform incumbents which are likely to continue thriving in 2017 increasing their market lead over other companies and startups in the space.\n\n2 \u2014 AI Becomes an Integral Component o fIOT Platforms: Artificial Intelligence(AI) will become an essential component of IOT platforms in the form of integrated cognitive services in areas such as vision, voice, natural language, etc.\n\n3 \u2014 M&A and Market Consolidation Continues: The number of IOT platform startups with innovative technologies that have failed to achieve market relevance and the healthy balance sheet of the IOT incumbent companies continues contributing to a favorable climate for M&A in 2017.\n\nLet\u2019s now look at some predictions for some of the IOT platform leaders.\n\n1 \u2014 Cognitive Services Integrates with Azure IOT Suite: It is very likely that this year Microsoft will add AI-first capabilities to the Azure IOT Suite powered by the integration with the Microsoft Cognitive Services stack.\n\n2 \u2014 Azure IOT Suite Goes On-Premise: This year Azure IOT Suite should be added to the Azure Stack hybrid platform.\n\n3 \u2014 A Windows-based, IOT-First OS: A version of Windows optimized for wearable\u2019s sounds interesting. Something to compete with Android Things.\n\n1 \u2014 Greengrass Becomes a Favorite of IOT Device Manufacturers: Launched in 2016, AWS Greengrass is a unique offering for IOT device manufacturers which is likely to see a lot of traction this year.\n\n2 \u2014 Cognitive Services Integrate with AWS IOT: This year is likely that AWS will integrate its new suite of cognitive-AI services into its IOT platform.\n\n3 \u2014 New IOT Serverless Middleware: With technologies such as Lambda Step Functions, AWS is in a unique position to deliver a new type of serverless middleware to IOT solutions.\n\n1 \u2014 New IOT Vertical Solutions: This year, we should expect new industry solutions powered by the Watson IOT platform.\n\n2 \u2014 Watson IOT Goes On-Premise: In 2017, IBM should streamline Watson IOT support for on-premise infrastructures.\n\n3 \u2014 Watson IOT Hardware: Don\u2019t be surprised if we see a new generation of industrial devices powered by the Watson IOT platform.\n\n1 \u2014 New AI Services: Given GE\u2019s recent acquisition such as Wise.io it is likely that we will see a new group of cognitive services added to the Predix platform.\n\n2 \u2014 More Industrial Hardware: In 2017, GE should continue investing in hardware solutions to simplify the implementation of Predix in industrial environments\n\n3 \u2014 New IOT Vertical Solutions: No surprise here\u2026In 2017, GE will continue investing on industry-specific IOT solutions powered by the Predix platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-obvious-predictions-about-artificial-intelligence-in-2017-fef267b9a9d2?source=user_profile---------311----------------",
        "title": "Some Obvious Predictions About Artificial Intelligence in 2017",
        "text": "I am not a fan of yearly technology predictions but they seem to be inevitable this time a year even though technology markets constantly defy the logic of analysts.\n\nInstead of writing general predictions about the technology market, during the holidays I\u2019d summarized a series of somewhat obvious predictions for individual tech markets that drove in 2016 such as artificial intelligence(AI), blockchain, cyber-security, internet of things(IOT) and a few others. By somewhat obvious I am referring to predictions that can be clearly backed up by market signals today and don\u2019t rely on a lot of speculation. I\u2019ve divided the predictions between general market analysis and predictions relevant to a specific company or product. Today, let\u2019s start with the AI market.\n\n2016 was a really active year for the AI space and 2017 promises to be very exciting as well. Here is my list of obvious predictions for AI in 2017\n\nObvious Predictions about the AI Market in 2017\n\n1 \u2014 AI M&A Continues to Grow: Market consolidation and acquisitions should continue trending up this year. Acqui-hires and talent-related acquisitions might be more common than product-IP related acquisitions.\n\n2 \u2014 AI Platform Incumbents Increase Their Market Share: The AI platform space seems to be a big boys game. In 2017 incumbents such as Amazon, Google, Facebook, Microsoft and IBM should increase keep distancing themselves from other competitors.\n\n3 \u2014 AI Hardware Becomes a Relevant Trend: In 2017 vendors such as NVidia, Intel or ARM-Softbank should achieve certain level of mainstream adoption of their AI-first hardware technologies. Similarly, we should see more innovation in the space.\n\nLet\u2019s now look at some of the obvious predictions for AI vendors\n\n1 \u2014 Azure ML Goes On-Premise: In 2017, Azure ML should be included as part of the Azure Stack hybrid cloud\n\n2 \u2014 More CortanaPowered Devices: This year we might seen a new generation of devices powered by Cortana digital assistant.\n\n3 \u2014 Office365 and Dynamics365 Launch AI Capabilities: Somebody has to compete with Salesforce Einstein.\n\n1 \u2014 DeepMind Releases More Tools and Frameworks: Alphabet cares deepely about developers embracing DeepMind technologies.\n\n2 \u2014 TensorFlow Distances Itself from Other Deep Learning Frameworks: Better toolit and algorithms will help TensorFlow distance itself from competitors such as Tehano, Caffe, Torch, etc.\n\n3 \u2014 New Cognitive Services: We should expect to see more cognitive services in Google Cloud in 2017.\n\n1 \u2014 Watson Keeps Going Vertical: We should expect IBM to cnotinue Watson\u2019s verticalization efforts this year.\n\n2 \u2014 More In dsutry-Specific Acquisitions: IBM is likely to continue acquiring boutique consultancies to train Watson on specific industries.\n\n3 \u2014 New Cognititive Services & Training Tools: In 2017, IBM should add more congnitive services to Watson and release additional training and management tools.\n\n1 \u2014 New Alexa-Powered Hardware: We should expect to see new devices powered by Amazon Alexa very soon.\n\n2 \u2014 New AWs Cognitive Services: Amazon released its first group of cognitive cloud services at AWS re:Invent. In order to catch with Microsoft and IBM, we should expect new services to be added to AWS cognitive portfolio in 2017.\n\n3 \u2014 AWS ML Gets an Upgrade: The AWS ML platform is long overdue for an update.\n\n1-New Facebook Messenger cognitive Services: Wit.ai was incredibly successful in 2016. New cognitive services are likely to join the family this year.\n\n2- Facebook Digital Assistant: Is not crazy to envision Facebook working on a digital assistant similar to Echo or Home but focused on social interactions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/apples-dives-into-unsupervised-ai-bf9d34a59282?source=user_profile---------312----------------",
        "title": "Apples Dives Into Unsupervised AI \u2013 Jesus Rodriguez \u2013",
        "text": "Apple is the biggest name missing in the artificial intelligence(AI) and machine learning(ML) emerging technology ecosystem but that seems to be changing. A few days ago, researchers from Apple\u2019s ML group published a paper that describes a new simulated and unsupervised learning technique to improve the quality of synthetic training images.\n\nThe paper is one of Apple\u2019s most visible recent releases in the AI-ML space and one that indicates that the company expect to be competitive in a field that has been dominated by companies such as Microsoft, IBM, Amazon, Facebook and Google. The subject of the paper is also very pragmatic from Apple\u2019s technology standpoint.\n\nVision intelligence is one of the capabilities that is essential to modern IOS apps. Synthetic images are a very popular approach to train vision ML models as it is less costly and more flexible than using real images. The main challenge with synthetic images is that the quality is sometimes inferior than real images which an affect the effectiveness in the training of vision intelligence models. Apple is trying to address this limitation by leveraging a technique called Generative Adversarial Networks(GANs).\n\nIn a nutshell, GANs are based on adversarial and competitive dynamics between different neural networks. In the case of vision intelligence, GAN\u2019s algorithms use a simulator that generate synthetic images that are sent to a refiner which improves them and routes them to a discriminator whose task is to distinguish real images from synthetic ones.\n\nApple\u2019s paper proposes an approach that improves over traditional GANs algorithms by trying to minimize the differences between synthetic and real images while also minimizing the differences between synthetic and refined images. The \u201cadversarial\u201d notion of the algorithm comes from the fact that the different neural networks are actively \u201ccompeting\u201d to minimize the maximum possible loss on any given iteration.\n\nIt seems obvious that Apple\u2019s interest on GANs to improve vision intelligence techniques could be relevant to the IPhone and IPad ecosystems. Beyond the obvious improvements on the cognitive capabilities of some Apple applications, it would be interesting to see how Apple enables new AI-ML capabilities. In my opinion, I would like to see cognitive capabilities as a first-class citizen of the IOS stack. Here are a few ideas of what we might see from Apple in the AI-ML space in the short term:\n\n\u2014 Cognitive Services: Apple might soon add cognitive services in areas such as vision, natural language, speech, knowledge, etc to it cloud services portfolio.\n\n\u2014 IOS Cognitive Toolkit: Following the approach of frameworks such as IOS Health and Home Kits, I would like to see a Cognitive Toolkit that makes it easier for developers to incorporate cognitive capabilities such as vision intelligence, natural language processing, speech processing and other intelligent features to IOS applications.\n\n\u2014 Siri Skills: Most likely this won\u2019t happen but wouldn\u2019t be cool if you could add new cognitive skills to Siri just like we extend services such as Alexa, Cortana or Allo?"
    },
    {
        "url": "https://medium.com/@jrodthoughts/bringing-deep-learning-frameworks-to-the-enterprise-20fb7ed14138?source=user_profile---------313----------------",
        "title": "Bringing Deep Learning Frameworks to the Enterprise",
        "text": "The deep learning space has seen a tremendous level of innovation in the last couple of years. From new versions of established frameworks such as Caffe, Torch or Theano to new entrants in the market such as Microsoft Cognitive Toolkit or the ultra-popular TensorFlow, not a week goes by without some important development in the big learning space. The rapid evolution of deep learning frameworks has enable its adoption but some of the top artificial intelligence(AI) stacks in the market such as DeepMind which was originally built on Torch and recently switched to TensorFlow.\n\nDespite the excitement about deep learning technologies, most of the relevant developments are taking place in the consumer or B2C markets while the enterprise remains cautious about the architecture and models that need to be put in place to adopt big learning technologies. Part of the slow progress in the enterprise is caused by the fact that some deep learning cloud platform s offer a very easy, entry point fro the implementation of basic deep learning scenarios such as image recognition or sentiment analysis which cause many organizations to initially leverage those cloud deep learning services instead of more complete open source deep learning frameworks. The second and most important factor contributing to the slow adoption of deep learning frameworks in business solutions is the fact that, currently, there are no robust enterprise distributions of those technology stacks.\n\nDriving some lessons from popular open source technology movements in the enterprise such as Hadoop or Docker, we can easily see that the deep learning market could benefit from some enterprise platforms that expand frameworks such as TensorFlow, Caffe or Torch with enterprise-ready capabilities. From that perspective, the market needs the equivalent to a Cloudera or Hortonworks for the deep learning frameworks. The more interesting question to explore how would enterprise distributions of deep learning frameworks look like.\n\nCopying some ideas from popular enterprise distributions of open source technologies as well as from the deep learning cloud platforms, I\u2019ve put together a few ideas of capabilities that should be considered relevant in an enterprise deep learning distribution:\n\n1 \u2014 Enterprise support: Different support models are key in order to make enterprise comfortable with the adoption of deep learning frameworks.\n\n2 \u2014 Management & Training Tools: Deep learning models require constant maintenance and training. An enterprise deep learning distribution should provide a toolset that enables these capabilities in a way that can be used by devops and domain experts.\n\n3 \u2014 Model Monitoring: Tracking the performance of deep learning models as well as other relevant operational analytics is another essential capability for the adoption of deep learning frameworks in the enterprise.\\\n\n4 \u2014 Deep Learning APIs: Taking a page out of the cloud deep learning platforms playbook, I believe an enterprise deep learning distribution should enable seamlessly expose models via APIs that can be easily consumed by third party applications.\n\n5 \u2014 security Security is an omnipresent element in enterprise distributions of open source technologies. An enterprise deep learning distribution should include relevant security capabilities such as authentication, access control, auditing while also integrating with mainstream enterprise security infrastructures such as Microsoft Active Directory .\n\nWho Will Bring Deep Learning Frameworks to the Enterprise?\n\nFrom the existing players in the market, I believe the enterprise big data platforms such as Cloudera, Hortonworks or MapR are on an enviable position to deliver an enterprise distribution of open source deep learning frameworks. Of course, we can always count on new startups entering the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-raise-of-conversational-apis-ca879e39f057?source=user_profile---------314----------------",
        "title": "The Raise of Conversational APIs \u2013 Jesus Rodriguez \u2013",
        "text": "Conversational interfaces are one of the most popular topics in the artificial intelligence(AI) technology ecosystem. The raise in popularity of conversational interfaces technologies such as natural language processing(NLP) na natural language understanding(NLU) has been accelerated by the fast growth of bot technologies.\n\nThe influence of bots in the development of NLP-NLU stacks has gotten to the point that most conversational interfaces are developed exclusively as part of specific bots. Conceptually, bots can be clearly divided between the front-end interface that sits in a messaging client and the NLP-NLU backend APIs that process the natural language messages from users. In a typical bot solutions, both components are tightly coupled and highly dependent on each other. In spite of the existence of popular platforms that enable the creation of conversational APIs such as Facebook Wit.ai, Google API.ai, Microsoft LUIS or AWS Lex, most conversational interfaces are typically used in the context of a specific bot solution. Think about, how many Wit.ai APIs, Alexa Skills or API.ai agents do you know that are being used by multiple bots or applications?\n\nAs voice evolves as one of the fundamental forms o fuser interface, NLP-NLU solutions are likely to start being used closers to the way we use APIs today. From that perspective, many systems of applications will expose conversation APIs that will be leveraged by bots on different platforms on diverse domains. That model drastically contrasts with the single-bot, single purpose model of today\u2019s NLP-NLU APIs.\n\nSome Ideas to Streamline the Adoption Conversational APIs\n\nThere are some important elements that are needed to make conversational APIs a reality. Let\u2019s discuss a few technological pieces that might be relevant in order to streamline the adoption of conversational APIs:\n\n\u2014 Conversational API Description: Conversational APIs should expose metadata descriptions that detail its capabilities. Descriptions should include relevant elements of conversational interfaces such as entities, intents, sample input-output messages and many other aspects that can help client applications understand and start using the API.\n\n\u2014 Discovery Interface: A conversational API discovery interface will be responsible for matching APIs with the specific requirements of client applications. WE can think about the discovery services as a conversational API responsible for answering questions such as \u201cWhat APIs can help me answer this question? \u201c After receiving that inquiry, a description service should return pointers to the description service of different conversational APIs that can help to answer the target question.\n\n\u2014 General-Purpose Testing Tools: Platforms such as Wit.ai, API.ai, LUIS or Lex include testing tools to validate the functionality of NLP-NLU conversations. However, I believe more general-purpose testing tools will be required in order to work with APIs created on any conversational platform.\n\n\u2014 Support for Voice Messaging: Excepting AWS Lex, most conversational API technologies are mostly focused on textual conversational and use voice mostly as an intermediate format that can be translated to text. However, when thinking about conversational APIs, voice is as important as text as a message encoding format. Voice conversations are a more effective mechanisms to communicate contextual aspect such as emotion, ethnicity or many other elements that can enrich a conversational experience."
    },
    {
        "url": "https://medium.com/@jrodthoughts/about-android-things-and-googles-iot-strategy-3eef3fdd18cd?source=user_profile---------315----------------",
        "title": "About Android Things and Google\u2019s IOT Strategy \u2013 Jesus Rodriguez \u2013",
        "text": "Last week Google announced Android Things, a new platform for building internet of things(IOT) devices on top of Android and Google Cloud Services. Android Things could be considered the next iteration of Brillio, an Android-based IOT OS that was announced around a year and a half ago but that has seen very limited success. The launch of Android Things surfaces some important aspects about Google\u2019s IOT strategy that I think are worth discussing.\n\nAndroid Things allows developers and device manufacturers to leverage familiar frameworks and tools such as Android Studio, Android SDKs, Google Cloud Services or Google Play Services to build IOT applications Other interesting capabilities such as the integration with Google Weave have been already announced as part of the roadmap.\n\nA few months ago, Google hinted its intentions of launching an IOT-first OS. During that time, I published a series of questions and reflections about the implication of such release for the IOT space. Android Things certainly answers many of the questions I previously raise but, more importantly, it reveals some important elements of Google\u2019s IOT strategy.\n\nThe IOT market today can be divided into three main groups:\n\n\u2014 IOT Platform Providers: Platforms that provide backed services used by IOT solutions.\n\n\u2014 IOT Infrastructure Providers: Solutions that enable IOT infrastructure areas such as networking, traffic routing, communication protocols and other elements relevant to IOT solutions.\n\nThe release of Android Things have interesting implications for each of these groups and certainly give us an idea of Google\u2019s vision of the IOT market.\n\n1-Devices are More Important than IOT Cloud Platforms\n\nWhen comes to IOT capabilities, Google Cloud is lagging other PaaS incumbents such as Microsoft, Amazon and IBM and even IOT clouds from companies such as PTC[ThingWorx] and GE[Predix]. The release of Android Thing indicates that, at the moment, Google cares more about becoming the platform of choice for device manufacturers compared to bridging the gap in the IOT cloud space.\n\nBy enforcing compatibility with Android tools and APIs, Google is trying to attract its large mobile developer community to Android Things. Brillio notoriously struggle with adoption in the developer community and Google seems to have taken note.\n\n3-Beating Apple and Microsoft in the IOT OS Space is More Important than Beating IBM and Amazon in the IOT Cloud Space\n\nThe release of Android Things could give Google an early advantage in the IOT market over long term rivals in the OS space such as Apple and Microsoft. At the moment, dominating the IOT OS market seems more relevant to Google than catching up with IOT PaaS leaders such as Amazon and IBM.\n\n4-Consumer Devices Seems More Relevant than the Industrial Enterprise\n\nThe launch of Android Things set Google\u2019s focus on the consumer wearable\u2019s and IOT consumer device space. At the moment, Google seems more focused to achieve relevance on that market than in the industrial enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/edge-computing-is-the-last-mile-for-iot-solutions-eff86627064c?source=user_profile---------316----------------",
        "title": "Edge Computing is the Last Mile for IOT Solutions \u2013 Jesus Rodriguez \u2013",
        "text": "A few days ago, the Wall Street Journal ran a piece about GE Digital\u2019s investment in IOT hardware devices in order to improve the edge computing capabilities of its Predix platform. From GE\u2019s perspective, integrated hardware devices can help to address the \u201clast mile problem\u201d about integrating PRedix with intelligent industrial equipment.\n\nThe race for dominance in the IOT platform market is becoming a contest between two main groups of technologies. On one side we have platform as a service(PaaS) providers such as AWS, Azure and Bluemix that have added native IOT services to its platforms. The other category of technologies includes industrial powerhouses such as PTC or GE Digital that have released outstanding IOT offerings. While the IOT PaaS providers are focused on providing robust horizontal IOT platform capabilities, the industrial vendors are banking on their domain expertise to build capabilities and solutions that improve the viability of their platforms in industrial environments. To both groups of technologies, edge computing and the integration with industrial devices is one of the biggest challenges in order to streamline the adoption of their IOT platforms.\n\nWithout exception, all the top IOT platforms in the market have developed some form of edge computing mostly on the form of device discovery and management gateways. While those capabilities are certainly relevant, they are hardly sufficient to address the challenges of integrating sensors on an IOT industrial environment with a specific IOT platform. In those scenarios, the integration of legacy industrial equipment with modern IOT platforms requires a monumental amount of work. That process is also hard for IOT device manufacturers that are constantly looking to make their devices work with the new generation of IOT platforms.\n\nIn order to address some of the aforementioned edge computing challenges, GE Predix has been building hardware devices that integrate with legacy industrial equipment and broker the communicating with the instances of the Predix platforms running on that industrial environment., GE\u2019s solution also includes other relevant edge computing IOT capabilities such as storage and messaging.\n\nSolving the \u201clast mile\u201d integration on IOT topologies is an absolute requirement to streamline the adoption of IOT platforms in industrial environments, However IOT edge computing solutions are far from trivial and should include some really sophisticated capabilities in order to be effective. Let\u2019s explore a few of those capabilities that are required in order to streamline edge computing IOT solutions.\n\n\u2014 Device Adapters: IOT Edge computing solutions should provider hardware-software adapters to collect data from sensors and devices in industrial environments. Adapters should support IOT protocols such as MQTT, XMPP, etc.\n\n\u2014 Data Caching: IOT Edge Computing solutions should enable the caching and storage of data generated by IOT devices.\n\n\u2014 In-device Computing: IOT Edge Computing solutions should provide local, in-device computation capabilities. Technologies such as AWS Greengrass are a good model for that type of solution.\n\n\u2014 Bidirectional Communication: IOT Edge Computing solutions should support bidirectional communication between device adapters and the main IOT platform.\n\n\u2014 Device-to-Device Communication: IOT Edge Computing should enable autonomous communication between devices on an IOT network as well as with the centralized IOT platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-ideas-could-be-part-of-microsoft-artificial-intelligence-roadmap-e1c2bb30be23?source=user_profile---------317----------------",
        "title": "These Ideas Could be Part of Microsoft Artificial Intelligence Roadmap",
        "text": "Microsoft has been steadily growing into one of the powerhouses of the modern artificial intelligence(AI) and machine learning(ML) ecosystems. With fierce competition from companies such as Amazon, IBM, Google or Faceboof heating up, innovation and rapid iteration are essential for Microsoft to maintain its leadership position in the space.\n\nIn this post, I would like to discuss some ideas that might be relevant to the short-term roadmap of Microsoft\u2019s AI-ML technologies. The ideas explored here are a combination of market requirements, capabilities that can fill a gap with the competition as well as natural evolutionary steps for the Microsoft AI-ML stack. Before brainstorming about the roadmap, let\u2019s explore Microsoft\u2019s current AI-ML capabilities.\n\nMicrosoft has been actively innovating on diverse areas of the AI-ML ecosystem ranging from cloud cognitive services to deep learning frameworks. The following list summarizes some of the main components of Microsoft\u2019s AI-ML stack:\n\n\u2014 Azure Machine Learning: Azure ML is a native cloud service that enables the implementation and management of ML solutions and expose them via APIs. Azure ML provides native support for languages such as R and Python.\n\n\u2014 Microsoft Cognitive Services: Microsoft\u2019s Cognitive Services are a series of cloud APIs that provide AI capabilities in cognitive computing areas such as vision, speech, text and knowledge.\n\n\u2014 Microsoft Cognitive Toolkit: Microsoft Cognitive Toolkit is an open source deep learning framework that supports the implementation of AI application on different languages such as C++ or Python.\n\n\u2014 R Server: Microsoft R Server enables the implementation of R-based AI-ML solutions. The newest release adds a new package called Microsoft ML that includes a series of new ML algorithms implemented natively on R.\n\nLooking at the current state of the market and the current capabilities of Microsoft\u2019s AI-ML technologies, I\u2019ve listed a few ideas that might relevant to Microsoft\u2019s short-term AI-ML roadmap:\n\n\u2014 On-Premise Azure ML: Supporting Azure ML as part of Azure Stack will open a window to new scenarios for ML solutions in the enterprise that require on-premise infrastructures. An on-premise version of Azure ML will be a strong competitive advantage with other cloud ML offerings.\n\n\u2014 Cognitive Services Training Tools: Microsoft has done a great job opening up the training stack for its Language Understanding Intelligence Service (LUIS). Similar AI training tools for other Microsoft Cognitive Services APIs would be a nice addition to the platform.\n\n\u2014 Cognitive Toolking Integration with Azure ML: Just as Google provides integration with its open source deep learning framework TensorFlow and the Google Cloud ML platform, Microsoft should explore a similar strategy to integrate Azure ML and the Cognitive Toolkit framework. That approach will enable the implementation of hybrid deep learning applications for enterprise using the Microsoft stack.\n\n\u2014 Azure ML Integration with Deep Learning Frameworks: This might sound controversial but I believe Azure ML would benefit from the integration with some of the top deep learning frameworks in the market such as TensorFlow, Torch, Caffe, Theano, etc. That level of integration will expose Azure ML to a broader set of applications and will serve as a differentiator with the competition.\n\n\u2014 C# AI Frameworks: The number of AI-ML frameworks that support C# pales in comparison to other languages such as R or Python. Microsoft recently announced C# support in the Cognitive Toolkit framework but it should expand its effort to provide stronger AI capabilities in its marquee language. That strategy will allow Microsoft to leverage the large C# developer and partner community in the implementation of AI applications and will reduce the challenge of enterprises looking to onboard AI talent."
    },
    {
        "url": "https://medium.com/@jrodthoughts/six-ideas-to-improve-the-training-of-ai-systems-301ce51b3792?source=user_profile---------318----------------",
        "title": "Six Ideas to Improve the Training of AI Systems \u2013 Jesus Rodriguez \u2013",
        "text": "As discussed on a previous post, the training og AI systems is one of the most challenging aspects of modern AI solutions. To some extend, the technologies and capabilities fro training AI systems have been evolving at a slower pace than AI frameworks themselves.\n\nWhile the AI market has been exploding with new frameworks, cloud services and industry-specific solutions, the tools and platforms for training AI systems are still on very early stages. Just recently, AI industry leaders such as DeepMind or OpenAI have started efforts to try to streamline the training of AI systems.\n\nThe process of building more complete and sophisticated AI training solutions usually requires many building blocks. Some of these foundational pieces are just now being explored by the AI community. I\u2019ve put together a few ideas that I consider could be relevant when comes to the training of AI systems.\n\nSome Ideas of Improve the Training of AI Systems\n\nBuilding general-purpose tools and frameworks for training AI systems is absolutely essential to streamline the knowledge building mechanisms for those type of solutions. By general-purpose, I am referring to tools that can be used to train different AI algorithms sometimes even on different domains.\n\nSemi-supervised learning models seem to be a practical approach to simplify the training of AI solutions in the short term. These type of models an infer relationships between knowledge concepts by using proximity inference techniques. Tools such as Google Expander are a great example of this approach.\n\nMost AI frameworks use similar data structures [graphs] to represent training knowledge used on AI algorithms. Leveraging these similarities to create standards that can be used across different AI platforms can drastically improve the training of AI systems.\n\nOne of the most efficient ways to train AI systems is by inferring knowledge from \u201cobserving\u201d human experts operate a generic system. Examples of AI problems that can be solved with that type of training strategy are tasks such as playing video games, manipulating Excel spreadsheets or interacting with CAD files. Creating general-purpose AI tools that infer knowledge derived from observing experts can cover a large spectrum of the training requirements of AI systems.\n\nKnowledge is the essential element for training AI systems. When comes to AI, more knowledge is almost always better. Created highly curated knowledge repositories that can be programmatically accessed by AI training tools and frameworks can exponentially improve the processes and algorithms for training AI systems.\n\nJust like we humans have created many mechanisms for validating areas of knowledge, AI training solutions should provide the infrastructure and tooling to evaluate the efficiency of a specific training process. Additionally, AI platforms should constantly monitor the behavior of AI systems, identify knowledge gaps and adjust the training mechanisms accordingly. Tools for monitoring and evaluating the training of AI solutions are essential for the mainstream adoption of AI training models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-technologies-are-helping-make-ai-training-mainstream-31a858a7377f?source=user_profile---------319----------------",
        "title": "These Technologies are Helping Make AI Training Mainstream",
        "text": "OpenAI and DeepMind have made available a set of training tools that can, to some extend, be used by other artificial intelligence(AI) solutions. The releases attempt to address the increasingly complex challenges that AI developers are experiencing building comprehensive training experiences for AI solutions.\n\nOpenAI Universe allows developers to training AI applications using human centric interfaces such as websites, games and other applications. The thought process is that as AI systems learn more like humans they can better resemble human intelligence. At a high level, OpenAI Universe is an example of a platform that is trying to build generally-intelligent systems that can master different types of knowledge.\n\nOne of the biggest challenges of AI training is that the training processes are built for specific AI applications and focused on the application\u2019s specific domain. Obviously, that approach constraints training models to very specific scenarios and prevents any type of knowledge reusability. From an anthropological standpoint, those models of training are the antithesis of human learning and intelligence development processes.\n\nPlatforms such as OpenAI Universe are trying to build generic AI training infrastructures that can be adapted to different types of AI knowledge. That model is a stepping stone towards building more \u201cgenerally intelligent\u201d systems.\n\nIf we assume that AI is going to be the foundational component of the next generation of software applications and that companies are going to be building many AI solutions in the near future, then we should assume that building individual training processes for each applications is a very inefficient strategy that is unlikely to scale very well. From that perspective, there are several challenges that we can identify on the current approach to AI training. Let\u2019s explore a few:\n\n\u2014 Knowledge Reusability: The current generation of AI systems uses representation of knowledge that are built almost at the application code level. as a result, there is minimum or no reusability of knowledge between AI systems even if they exist in the same domain.\n\n\u2014 Cost: Domain-specific AI systems training can be incredibly expensive. In today\u2019s AI ecosystem, companies such as IBM and Google are spending fortunes acquiring industry experts that can efficiently train AI solutions. That approach is prohibited for most companies that don\u2019t enjoy IBM or Google\u2019s healthy balance sheets.\n\n\u2014 Tooling: The AI training tooling ecosystem is still in its infancy and is growing slower compared to AI frameworks and platforms. As a result, AI solutions spend considerable time and effort building basic training tools over and over again. Most of those AI training tools are not reusable across systems which results on a very limited training experience for the ecosystem in general.\n\n\u2014 Knowledge Monitoring: AI systems training is a continuous process. However, most AI solutions experience challenges monitoring the quality and efficiency of they knowledge and improvements based on the training. As a result, most systems evolve without quantifiable methods to monitor and evaluate the efficiency of its knowledge.\n\n\u2014 Lack of Standards: There is a strong consensus within the AI community about the models that can be used to represent knowledge in an AI system but that hasn\u2019t translated onto standards that can be used across different AI platforms. Consequently, every AI system represents knowledge using its own proprietary models which are hardly reusable.\n\nThese are just some of the challenges about the training of AI systems. In a future post, we will discuss some possible solutions and technologies that are already tackling these challenges."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-unexpected-trends-that-are-driving-the-adoption-of-serverless-computing-2d1a8d0d3d11?source=user_profile---------320----------------",
        "title": "Five Unexpected Trends that Are Driving the Adoption of Serverless Computing",
        "text": "Serverless computing has quickly become one of the foundational pieces of modern distributed systems. An important component of platform as a service(PaaS) stacks, serverless computing is a very popular architecture style within the generation of cloud-first developers. Despite its popularity, here are questions about the paths that could help drive the adoption and ultimately monetize servile computing in the near future.\n\nThe subject of serverless computing scenarios has been long debated across technical communities. Most people associate serverless architectures with scenarios such as IOT or gaming but I believe those examples are too generic to infer specific paths to commercial adoption. Sometimes, identifying the monetization paths of low-level infrastructure technologies such as serverless computing is far from trivial. From that perspective, I would like to explore a few technology trends that I believe can help drive the commercial adoption of serverless technologies in the short term.\n\nAs strange as it might sound, blockchain as a service(BaaS) technologies can become one of the big drivers for the adoption of serverless technologies. Specifically, serverless stacks are a great solution to enable the access to off-chain data without violating the integrity of the blockchain. Ethereum\u2019s ORacles and Oriject Bletchey\u2019s Cryplets are good examples of the integration between serverless capabilities and BaaS stacks.\n\nBots technology is another trend that can drive the immediate commercial adoption of serverless stacks. In that scenario, serverless frameworks can be used to implement the business logic actions for a specific bot. Alexa Skills Kit and Azure Bot Service are example of that model.\n\nAnother example that might come across as surprising, deep learning can be another accelerator for the adoption of serverless computing technologies. Deep learning problems are typically modeled as async graphs on which nodes perform individual computation. For large scale deep learning solutions, serverless stacks can be used to implement the specific computation tasks connected asynchronously as part of a deep learning algorithm. Leveraging serverless computing as part of deep learning models mostly makes sense on large scale problems like the ones tackled by technologies such as Google\u2019s DeepMind or IBM\u2019s Watson.\n\nRecently, I\u2019ve written about how serverless technologies can become the new from of lightweight enterprise middleware. Trends such as IOT are driving new models of integration in the enterprise and serverless computing is becoming the default way to address many of the new generation of integration scenarios. Technologies such as Node-red or AWS Step Functions are showing the possibilities of leveraging serverless patterns in integration scenarios.\n\nHardware solutions are notoriously difficult to version an upgrade. Serverless stacks can drive new architecture models that can be used to improve the capabilities of IOT devices without the need to deliver new versions of the specific hardware. This approach is particularly relevant on invisible interfaces driven by sensors or voice commands. Amazon Echo family of devices is a great example of how IOT devices can leverage serverless computing to power invisible interfaces."
    },
    {
        "url": "https://medium.com/@jrodthoughts/can-ai-make-better-coders-part-ii-fe1cfff8f6a7?source=user_profile---------321----------------",
        "title": "Can AI Make Better Coders? Part II \u2013 Jesus Rodriguez \u2013",
        "text": "This is the second article on our series about the impact of artificial intelligence(AI) on software development. The first part of this series focused on the ecosystem of platforms and data sources that can be used to train AI algorithms to help produce better code. Today, I would like to explore how AI can help software engineers to write better code.\n\nBringing AI technologies in the existing ecosystem of software development tools and frameworks seems like an obvious first step on the journey towards building AI systems that can write code. Conceptually, AI can help to improve almost every aspect of the software development lifecycle such as testing, development, management among others.\n\nThe advancements on machine learning(ML) and AI together with the evolution of rich developer knowledge sources such as Stack Exchange or Github are opening a window to a world on which AI algorithms can improve developer\u2019s productivity. A great example of this intersection between AI and software programming is the recently announced bugspots tool [Google-w3C] that uses ML algorithms to determine whether a potential piece of code is flawed or not. Another good example is Emil Schutter\u2019s work leveraging stack Exchange to produce fully functional code based on the intentions inferred from existing code.\n\nIf we continue exploring the thesis that AI can help engineers produce better code, the next logical step is to identify which areas to tackle first. In my opinion, there are several developer productivity areas on which AI can help software developers produce better code. Let\u2019s explore a few ideas:\n\nFive Ways on Which AI Can Help Software Developers Write Better Code\n\nBy following some of the same principles of tools like bugspots, AI algorithms can analyze the intentions and structure of specific code and propose relevant optimizations that leverage knowledge from data service such as Stack Exchange or Github. Examples of optimizations include better algorithms for the existing program or code changes that may avoid potential bugs.\n\nAnother prototypical use case for leveraging AI algorithms is the generation of test cases for an existing piece of software. In that model, AI processes can understand the nature of specific code and automatically generate test code based on inferred uses cases.\n\nSecurity is one the areas that can immediately benefit from applying AI algorithms to software programming. AI is a very effective way to spot potential security vulnerabilities on a specific piece of code and recommend potential solutions.\n\nUsing AI to drive the next generation of compilers and intepreters is one of the fascinating areas of research in programming languages. soon, we could be writing code in environments in which compilers don\u2019t only understand the syntax and semantic of a program but also its purpose and intentions. In this model, compilers and interpreters will be able to dynamically improve the code and become more efficient over time.\n\nBug fixing is one of the areas that could be revolutionized with AI technologies. Tools such as bugspots show us that programs can leverage AI algorithms to auto-correct themselves with minimum intervention of a human programmer."
    },
    {
        "url": "https://medium.com/@jrodthoughts/can-ai-make-better-coders-part-i-94a76ec9c5a8?source=user_profile---------322----------------",
        "title": "Can AI Make Better Coders? Part I \u2013 Jesus Rodriguez \u2013",
        "text": "The role of artificial intelligence(AI) on the evolution of software development is an active subject of debate among AI thought leaders. A few weeks ago, I wrote about the impact that AI can have on areas of the software developer lifecycle such as application testing. Today, I would like to start a series that deep dives into a more profound question: can AI help to create better software developers?\n\nThe idea of AI bots writing code has been one of the ultimate goals of AI since the 1970s. With the recent advancements on AI technologies, it feels that we are getting closer to, at least partially, achieve that goal. In my opinion, the debate about whether intelligent systems can produce better code is a bit overloaded. To simplify the debate and avoid unnecessary speculations, let\u2019s break our augment into four fundamental questions:\n\n1-What platforms are available today that can train AI systems to write better code?\n\n2-Can AI systems help engineers to produce better code?\n\n4-What AI techniques can be used to implement intelligent systems that are able to write code?\n\nI believe the answer to the aforementioned questions provides a solid framework to understand the role of AI in software programming. Let\u2019s then start with the first question and explores what are the tools and data sources that we can use today to teach AI systems how to write better code.\n\nDespite the advancement on AI technologies, we wouldn\u2019t be talking about bots writing code if we didn\u2019t have the programming knowledge and tools needed of rate training and evaluation of those AI systems. In the last decade, the software industry has created many platforms that have allowed us to start dreaming about the possibilities of AI-powered solutions producing code. Let\u2019s review a few of those:\n\nFive Technologies that AI Bots will Use to Write Code\n\nStack Exchange\u2019s large repository of programming knowledge could result an indispensable asset for AI self-programming systems. AI algorithms could link Stack Exchange\u2019s threads to specific sections of programs or even address errors produced by compilers or interpreters.\n\nGithub\u2019s vast collection of open source code and projects could be used to train AI algorithms on the implementation of specific types of solutions. AI algos could correlated specific requirements or sections of a program with GitHub code that could be incorporated into a program.\n\nAPIs are one of the technological artifacts that can simplify the creation of AI algorithms that write code. APIs provide a consistent model to request data and execute business logic in systems in a way that can be easily adapted to AI programs.\n\nServerless computing stacks such as AWS Lambda or Azure Functions provide a universal model to develop and execute atomic functions that perform isolated tasks. AI algorithms could leverage serverless computing stacks to deploy and execute or even reuse specific parts of a program using a consistent runtime.\n\nAlgorithm repositories such as Algorithmia enables the discovery and execution of algorithms using a consistent protocol. AI bots could leverage algorithm marketplaces to discover algorithms based on a specific criteria or requirement of the target program."
    },
    {
        "url": "https://medium.com/@jrodthoughts/a-market-perspective-of-blockchain-platforms-in-the-enterprise-94a5251c955f?source=user_profile---------323----------------",
        "title": "A Market Perspective of Blockchain Platforms in the Enterprise",
        "text": "The enterprise space has long been rewarded as the crown jewel for blockchain technologies. From horizontal platforms that enable the implementation of blockchain applications to vertical blockchain solutions across different industries, the opportunities of blockchain technologies in the enterprise seem limitless. However, many things are still needed for the mainstream adoption of blockchain in business environments.\n\nOne of the interesting aspects for venture capitalists and startups dabbling into blockchain solutions is to figure out the evolutionary path that those technologies are going to follow in the enterprise. From that perspective I would like to explore a few ideas that might highlight how the enterprise space is likely to embrace blockchain stacks. Just to be clear, the ideas that we are discussing are related to the mainstream adoption of the blockchain. While there are isolated examples of enterprises adopting blockchain stacks, the market is still incredibly early.\n\nSome Thoughts About Blockchain in the Enterprise\n\nThe initial path of adoption of blockchain technologies in the enterprise is going to be driven by the uses cases of the early adopters as well as by the frictionless technology models that can deliver those use cases. Like other enterprise software movements, the early adoption of blockchains will create a series of platforms and companies that will capitalize on those initial scenarios and some of which will evolve to become household names in the enterprise blockchain ecosystem. Following that train of thought, we should then discover the initial market signs and opportunities that can be exploited by blockchain startups in the enterprise. Here are my top 5:\n\nBlockchain as a service(BaaS) technologies bring together the required elements to drive the early pilots and POCs of blockchain solutions in the enterprise. Many organizations are indirectly exposed to BaaS stacks as part of their enterprise cloud subscriptions. while PaaS incumbents such as Microsoft, Amazon oar IBM are driving the adoption of BaaS there is an opportunity for startups in the space.\n\nIntegrating blockchain code with off-chain systems remains a challenge in enterprise solutions. Technologies such as Ehtereum address this challenges with the concept of Oracles. The need for off-chain integration and the creation and commercialization of Oracles is likely to be the focus of new companies in the blockchain market.\n\nMost enterprise application requires a database and blockchain solution are not the exception. In order to achieve mainstream adoption in the enterprise, the blockchain ecosystem needs to create robust database technologies optimized for blockchain solutions. BigChainDB is an interesting technology in the space.\n\nIn order to attract mainstream developers, the blockchain space needs more and better development frameworks that abstract the implementation of common types of applications such as mobile or web. Eris and Ethereum have been pioneering some interesting ideas in that front.\n\nFrom the horizontal and infrastructure capabilities needed by enterprise blockchain applications, analytics is the one area that can have an immediate impact in the ecosystem and achieve relevant market share. While most blockchain platforms include some form of analytics, there are still relatively rudimentary which creates a lot of opportunity in this area of the market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/aws-greengrass-brings-serverless-computing-to-your-iot-device-6fc42f64ae72?source=user_profile---------324----------------",
        "title": "AWS Greengrass Brings Serverless Computing to your IOT Device",
        "text": "The release of AWS Greengrass was one of the most exciting announcements delivered at AWS re:Invent a few days ago. Greengrass is a new addition to te AWS Iot platform that enables the execution of Lambda functions, data cachine, messaging and computation capabilities on IOT devices.\n\nGreengrass ia a clear example of how AWS is expanding its IOT capabilities to edge computing and in-device scenarios. The new framework makes AWS IOT a more suitable platform for field services scenarios on which devices need to execute logic and perform computations locally without relying on internet connectivity.\n\nAWS Greengrass is fundamentally based on two components: Greengrass Core(GSC and the IOT Device SDK. Both of these components can run on devices supporting Linux on ARM or x86 architectures. GSC enables the execution of Lambda functions on IOT devices. Additionally, GSC provides authentication, data caching and messaging capabilities to IOT architectures. The messaging features are particularly interesting as it enables the exchange of data between Greengrass-devices without relying on a centralized hub.\n\nThe Greengrass IOT Device SDK abstracts the capabilities of the platform and allows developers to build in-device applications that leverage GSC. Another interesting aspect of Greengrass is its integration with AWS IOT Device Shadows. Greengrass uses \u201cShadows\u201d to cache the state of a device and the relevant changes over time.\n\nThe process of using AWS Greengrass is incredibly simple for developers. You can start using Greengrass by simply registering a new hub of devices, select the Lambda functions to be executed and generate a deployment package that can be used on in-device applications.\n\nThe announcement of AWS Greengrass has some interesting implication for the enteprise IOT space. Let\u2019s discuss a few ideas:\n\nAWS Greengrass is an incredibly strong addition to the AWS IOT and one that can become a strong differentiator in the highly competitive market. AWS IOT competes with IOT platforms such as Azure IOT Suite, Watson IOT, Xively, Thingworx or GE PRedix. Among those platforms, only IBM and Microsoft have developed strong serverless computing capabilities that can compare with AWS Lambda but none of the platforms include a capability similar to Greengrass.\n\nAWS Greengrass offers a great framework for device manufacturers to enable the implementation of in-device applications. From that perspective, it is safe to expect to see AWS very active establishing partnerships with device manufacturers in order to increase the adoption of Greengrass.\n\nIOT Developers should welcome Greengrass with open arms as the platform solves many of the complex aspect of in-device applications such as backend logic, security, messaging or data caching. Based on the initial feedback, we should expect to see a very active community around AWS Greengrass."
    },
    {
        "url": "https://medium.com/@jrodthoughts/this-tool-is-googles-response-to-microsoft-powerapps-d453c72c42ee?source=user_profile---------325----------------",
        "title": "This Tool is Google\u2019s Response to Microsoft PowerApps",
        "text": "A few weeks ago, Microsoft announced the general availability of PowerApps, a self-service mobile application development platform included in Office365 and Dynamics365. At the time, PowerApps represented a strong differentiator with competitive offerings such as Google G Suite. Just a dew days ago, Google announced its alternative to PowerApps called App Maker. Thw new platform enables the self-serivce implementation of mobile apps that leverage data from the G Suite platform.\n\nTiming and capabilities make App Maker a clear response to Microsoft PowerApps but the release also opens a series of interesting posibilities for G Suite applications. The new platform allows a business user or citizen developer to implement a mobile application using a drag and drop interface that complies with Google\u2019s famous Material Design model. App Marker also provides new backend services such as Google Tables, a structured database based on Google Drive. Additionally, App Maker enables out-of-the-box integration with dozens of Google Services such as Gmail, Google Forms, Google Drive, BigQuery and many others. Testing, distribution and analytics are also capabilities included in App Maker platform.\n\nThe Second Act of Self-Service Mobile App Development Platforms\n\nSelf-service mobile app development platforms have been part of the enterprise mobile space for years. Despite the excitement generated by some of the early self-service mobile app dev platforms, we can argue that none of them have been very successful or have dominated the market. Now technologies such as App Marker, PowerApps and others [App Cloud, Mendix, Appian, etc] are driving a new iteration of this model for the implementation of mobile apps.\n\nPlatforms such as Google App Maker or Microsoft PowerApps bring a unique value proposition that could help mitigate some of the challenges experienced by the first-generation of self-service mobile app development stacks:\n\n\u2014 Large Distribution: G Suite and Office365 counts millions of businesses worldwide as customers which offers a unique distribution channel for platforms such as App Maker or PowerApps.\n\n\u2014 Service Integration: Technologies like App Marker and PowerApps include integration with dozens of services in the G Suite and Office365 platforms respectively which are actively used by millions of users.\n\n\u2014 Using a Familiar Interface: G Suite or Office365 are more than simple distribution channels for technologies such as App Maker or PowerApps; the platforms also offer a familiar environment for users/developers to implement mobile applications without learning a new toolset.\n\n\u2014 Robust Infrastructure: Infrastructure aspects such as security, scalability or monitoring are enabled by App Maker and PowerApps using the same underlying infrastructure powering G Suite and Office365.\n\nWhat Could be Next for App Maker?\n\nGoogle app Maker seems like a very robust first iteration of a self-service, data-drive mobile app development platform. There are some interesting idea that could be a great addition to its next version:\n\n\u2014 Google Cognitive APIs Integration: Leveraging Google Cloud Natural Language Processing, voice and speech APIs from App Maker apps could be interesting in many business scenarios.\n\n\u2014 Firebase Integration: Some of Firebase\u2019s services such as data sync could be relevant to App Maker apps.\n\n\u2014 Alllo Integration: Processing Allo\u2019s commands in App Maker will offer users a new channel to interact with the platform.\n\n\u2014 A/B Testing: Simple A/B testing services for developers building applications on App Maker could help to improve the long-term viability of the platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/aws-lightsail-and-low-cost-developer-clouds-3deb8a4bb53d?source=user_profile---------326----------------",
        "title": "AWS Lightsail and Low-Cost Developer Clouds \u2013 Jesus Rodriguez \u2013",
        "text": "Last week at AWS re:Invent, Amazon announced the release of Lightsail, a low-cost offer for developer to have access to virtual private servers(VPS) as part of the AWS infrastructure. The initial prices for Lightsail VPSs are starting as low as $5.\n\nLightsail provides a simple entry-point for developer building or prototyping cloud applications that don\u2019t require AWS services un areas such as security, storage, integration and many other of the fundamental services of the AWS platform. At the moment, Lightsail can also be considered a strong differentiator for AWS compared to other cloud incumbents and it definitely represents a direct competitor of startups like DigitalOcean which have been focused on that market for years. Overall, the launch of Lightsail has some very interesting implications for the cloud platform space. Let\u2019s explore a few ideas:\n\nWhat Does Lightsail Means for AWS?\n\nThe addition of Lightsail, gives AWS another channel to attrack developers looking to get started in their cloud journey without committing to a larger investment. Lightsail also offers a very viable transition path to more complex cloud applications that leverage the full capabilities of the AWS platform. Additionally, Lightsail represents a strong competitive differentiator against platforms such as Bluemix, Azure and Google Cloud which currently don\u2019t offer a similar capability.\n\nWhat Does Lightsail Means for the PaaS Market?\n\nThe announcement of Lightsail puts pressure puts pressure on two important elements of the PaaS market: PaaS incumbents and VPS-focused clouds like DigitalOcean.\n\nThe PaaS market has recently developed a pattern in which AWS, Azure, Google Cloud and Bluemix are trying to match each other almost feature by feature. Taking that aspect into consideration, the entrance of AWS Lightsail could have the following short-term side effect in the PaaS market:\n\n1-Microsoft, IBM and Google are likely to soon provide Lightsail alternatives.\n\nWhat Does Lightsail Means for DigitalOcean?\n\nDigitalOcean is a fantastic low-cost, VPS-focused cloud platform for developers. In the last few years, DigitalOcean has built a impressive customer and developer communities. Despite DigitalOcean\u2019s relevance in the market, AWS entrance in the game with Lightsail is and should be considered a serious threat to DigitalOcean\u2019s long-term business.\n\nLightsail\u2019s announcement can have positive and negative impacts for DigitalOcean. Arguably, Amazon\u2019s entrance in the low-cost developer cloud space represents a strong validation of DigitalOcean\u2019s model. However, Lightsail can become a formidable competitor for DigitalOcean. From that perspective, AWS Lightsail has various unique assets that should make it incredibly competitive in the space:\n\n\u2014 AWS has a very rich portfolio of cloud services that can enable a seamless transition of Lightsail applications onto more sophisticated cloud solutions.\n\n\u2014 AWS already has a strong footprint in the enterprise and it can represent an ideal entry point for cloud applications built at the departmental level.\n\n\u2014 AWS Lightsail can immediately take advantage of AWS\u2019 rich geographical footprint which can also streamline its adoption throughout the world.\n\nThe release of Lightsail can also increase DigitalOcean\u2019s stock in the eyes of potential acquirers such as Microsoft, Google and IBM. Specifically, Microsoft and Google has been very acquisitive when comes to the cloud space and its focus on developers aligns with DigitalOcean\u2019s strategy."
    },
    {
        "url": "https://medium.com/@jrodthoughts/re-invent-shows-that-aws-remains-as-innovative-as-ever-62f3703102f9?source=user_profile---------327----------------",
        "title": "re:Invent Shows that AWS Remains as Innovative as Ever",
        "text": "AWS re:Invent took place last week and the announcements have brought a breath of fresh air to the cloud computing platform. In the past, I\u2019ve written about how, despite of remaining the undisputed leader in the cloud platform space, AWS has been recently lagging in innovation in emerging technology areas such as artificial intelligence(AI), machine learning(ML), internet of things(IOT), containers, application integration and a few others. The slow pace of innovation in AWS allowed rivals such as Azure, Google Cloud or Bluemix to gain relevent market share in those sectors via the release of innovative offerings in their cloud stacks. re:Invent clearly showed that AWS is determined to now allow Microsoft, Google or IBM to easily lead in those emerging technology sectors and that is looking to, at least, level the plain field in terms of technological capabilities.\n\nThe Technical Equilibrium of the Cloud Platform Space\n\nIn the platform as a service(PaaS) market, Amazon, Google, Microsoft and IBM are immersed on a frantic race to match each other feature y feature. From that perspective, none of the PaaS incumbents seems comfortable letting the competition lead on a specific area without providing a competing offering. As a result, no new service or innovation from a PaaS provider goes very long without being matched with similar capabilities from the other incumbents.\n\nWhen Amazon launched its Lambda service, it was only a few months before IBM released OpenWhisk followed by Microsoft and Google releasing Azure Functions and Google Cloud Functions respectively. Similarly, IBM\u2019s Watson Developer Cloud was quickly matched by Microsoft\u2019s Cognitive Services followed by Google\u2019s release of its cognitive, speech, voice and image APIs. The result of this competition is that, at least from the technical perspective, AWS, Azure, Google Cloud and Bluemix look incredibly similar. Following this logic, it was just a matter of time before Amazon started to bridge the gap in emerging areas such as AI or ML that were dominated by some of its competitors. re:Invent\u2019s announcements definitely confirmed that theory but also brought a lot of innovation to new areas of AWS.\n\nAs mentioned before, many of the announcements at re:Invent were focused on bridging the gap with competitors in emerging technology areas while others opened new fronts of innovation for AWS. Let\u2019s review a few of the most relevant announcements that fit that criteria.\n\nAWS Green grass is a new service that extends AWS Lambda with functions that can be executed locally in IOT devices. Using Green grass, developers can write Lambda Python functions that can be executed across devices in an IOT topology without requiring any cloud roundtrips.\n\nAWS Lightsail offers a low cost option for developers to start using AWS virtual private servers. In some context, Lightsail can be considered an alternative to cloud platforms such as DigitalOcean and it could become a strong differentiator of rAWS moving forward.\n\nAWS Glue finally brings ETL capabilities to the AWS cloud. This service compares with products such as Azure Data Factory, AWS Data Pipeline or Google Dataflow.\n\nAmazon unveiled a groupf of AI services such as Lex [natural language processing], Rekognition [image analysis] and Polly [text to speech] that allow developer to incorporate cognitive capabilities into their applications. These services can be considered an alternative to Watson Developer Cloud, Microsoft Cognitive Services and Google Cloud NLP, voice and speech APIs.\n\nAWS Blox is a series of open source container management tools for the EC2 Container Service. Developers can use Blox to integrate EC2 with other container schedulers such as Apache Mesos.\n\nAWS Pinpoint is a new mobile analytics service thaintegrateses with AWS Mobile Hub. This service expands the already existing mobile analytics capabilities in the AWS platform and competes with technologies such as Google Mobile Analytics or MixPanel."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-ai-technology-ecosystem-a-market-taxonomy-28f3d14d0b75?source=user_profile---------328----------------",
        "title": "The AI Technology Ecosystem: A Market Taxonomy \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) and machine learning(ML) are growing in popularity in the technology ecosystem. Just a few months ago, it was relatively simple to keep up with the developments in the AI and ML markets. Today, that seems like a daunting task for most technologists as the space have been evolving incredibly fast.\n\nThe explosion of AI and ML platforms have created a very crowded market in which is very hard to distinguish signal from noise. However, despite the large number of AI technologies and startups, we can identify a few main categories that provide a good taxonomy to better understand the AI-ML markets. Let\u2019s take a look:\n\nCognitive API platforms abstract capabilities such as image, text and vision analysis using pre-trained AI models exposed as APIs.\n\n\u2014 Some Platforms in the Space: Watson Developer Cloud, Microsoft Cognitive Services, Google Cloud, NLP, Speech APIs\n\n\u2014 Good For: Performing well-defined tasks in areas such as text analytics, image processing and audio analytics.\n\nCloud ML platforms are cloud services that abstract the creation and execution of ML applications.\n\n\u2014 Some Platforms in the Space: Azure ML, Google Cloud ML, AWS ML.\n\n\u2014 Not Great For: Integration with on-premise data sources, custom algorithms\u2026\n\nOn-premise ML platforms enable the implementation of ML applications both on cloud and on-premise infrastructures.\n\n\u2014 Some Platforms in the Space: Spark ML, Flink ML, H2O.ai\n\n\u2014 Some Platforms in the Space: Apache Jupyter, Apache Zeppelin, Google Cloud Datalab\n\nDeep learning frameworks are developer frameworks that provide the fundamental constructs to build deep learning applications.\n\n\u2014 Some Platforms in the Space: TensorFlow, Torch, Caffe.\n\n\u2014 Not Great For: Basic deep learning models [ex: image recognition, etc]\u2026\n\n\u2014 Some Platforms in the Space: BigML, GE Wise.io\n\nVertical AI solutions focus on the implementation of industry-specific, complex AI solutions powered by some of the aforementioned technologies.\n\n\u2014 Some Platforms in the Space: IBM Watson, DeepMind.\n\nAs a group, AI-ML marketplace technologies enable the cataloguing, management and monetization of AI-ML assets such as algorithms, data sets, etc.\n\n\u2014 Some Platforms in the Space: Algorithmia\n\n\u2014 Good For: Discovering and using custom AI algorithms"
    },
    {
        "url": "https://medium.com/@jrodthoughts/iot-is-the-next-cyber-security-frontier-94f823417d59?source=user_profile---------329----------------",
        "title": "IOT is the Next Cyber-Security Frontier \u2013 Jesus Rodriguez \u2013",
        "text": "IOT is the Next Cyber-Security Frontier\n\nThe recent wave of cyber security attacks that have targeted smart devices such as cameras or wireless routers has delivered a strong signal to the market indicating that IOT is the cyber-security battleground. As more IOT devices expose their capabilities online, they are likely to become the target of cyber-security attacks.\n\nCyber-security hasn\u2019t been a strong focus of traditional smart device manufacturers. With hackers rapidly developing new techniques to exploid vulnerabilities in IOT runtimes, cyber-security platforms must adapt to these new world. However, the IOT space brings new dimensions in terms of complexity and new challenges to the cyber-security space in ways we haven\u2019t seen before.\n\nThere are many cyber-security challenges that we are about to start facing in the new world of connected IOT devices. For starters, IOT increases the complexity of many cyber-security problems by a large multiple. Also, many of the traditional cyber-security techniques can\u2019t be easily adapted to the IOT world.\n\nLet\u2019s explore a few of the most notorious challenges:\n\nThe large number and variety of IOT devices directly translates on an equally large number of potential cyber-security threats. Even worse, these attacks take place on many runtimes that are likely unknown to cyber-security technologies.\n\nCyber-Security Tools are not Optimized for IOT Platforms\n\nAttacks targeting IOT devices are a new dimension in the cyber-security space. Most cyber-security tools and platforms haven\u2019t seen these types of attacks and vulnerabilities and, consequently, haven\u2019t developed robust defenses.\n\nCyber-security attacks such as DDOS on IOT devices can be exploited to a much larger scale than similar attacks targeting computers or servers. The large number of IOT devices operating in a network can become a dream field scenario for hackers.\n\nIOT cyber-security attacks would be easier to prevent and control in cases on which devices are controlled by a centralized hub. However, many IOT solutions rely on M2M models in which devices autonomously interact and communicate with each other. This type of communication can be used to propagate malicious code from one device to another scaling the magnitude of the attack.\n\nImmediate Impact on the Physical World\n\nMany traditional cyber-security attacks are constrained to the digital world and target digital resources such as documents, log files, etc. Comparatively, IOT cyber-security attacks can have an immediate impact on the surrounding physical environment, Consider and attack that turns off sensors on a regulated facility that trigger different fake alarms. The impact of that type of attack is immediately visible in the physical and digital worlds.\n\nBelow, I\u2019ve listed five ideas that are worth exploring when comes to cyber-security in the IOT space.\n\nDevice manufacturers must start developing security protection methods directly embedded in the firmware of their devices. This point is particularly relevant for vendors such as Intel or QUALCOMM that develop chips that are ubiquitously used across IOT devices.\n\nMachine learning(ML) techniques can play a pivotal role detecting anomalous IOT traffic activity that follows patterns of cyber-security attacks. These techniques are even more viable in IOT scenarios that generate considerable volume of traffic.\n\nM2M communication channels should implement trust and security protocols to avoid the rapid propagation of cyber-security attacks.\n\nCyber-security platforms provided by top vendors such as Palo Alto Networks or Cisco should start including capabilities to support IOT devices and architectures. This will allow organizations to reuse their existing cyber-security infrastructure to protect their IOT solutions.\n\nIn this early days on which IOT cyber-security techniques/attacks are just being understood, data auditing plays an essential role to understand potential malicious threats and develop the corresponding defenses."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-next-enterprise-technology-wave-will-require-hardcore-developers-a213899499c?source=user_profile---------330----------------",
        "title": "The Next Enterprise Technology Wave Will Require Hardcore Developers",
        "text": "Enterprise software technology is evolving faster than ever before but is also becoming more complex. While previous inflection points in enterprise software were driven by technologies such as web, mobile or cloud computing now we are entering the era of artificial intelligence(AI), blockchain technologies and the internet of things(IOT). From that perspective, the level of complexity and sophistication of the skills required to build solutions will these technologies is exponentially higher than previous trends. As a result, the new wave of enterprise software solutions is going to require some hardcore engineering skills.\n\nThe increase in complexity and sophistication of enterprise software technologies can have a profound impact across different areas of the ecosystem from venture capitalists to large organizations looking to onboard talent in these areas. The priorities in the enterprise software space are starting to shift from mobile and web solutions that were created by mainstream developers to IOT, drones and AI solutions that are likely to require deep knowledge of computer science and, in some cases, even hardware engineering.\n\nOne of the aspects that makes the shift to this new wave of enterprise software technologies so challenging is the lack of a clear transition path for the mainstream engineering talent onto those new technologies. A few years ago, when enterprises started to embrace mobile technologies, web developers and devops were able to adapt their skills from the web world because of the many commonalities shared between the two technology stacks. Something similar has happened with cloud computing platforms that have been embraced by enterprise developers and IT professionals reusing skills from previous waves. In those cases, developers were able to make the transition to new technologies by reusing skills they have acquired from previous technologies. Those types of transition paths are not clear when we start talking about technologies such as IOT, blockchain or AI. Consequently, the adoption of the new technology wave is likely to pose major challenges to mainstream enterprise software developers.\n\nThe increase in the complexity of technologies is likely to increase the demand for high-end professional services firms specialized in areas such as blockchain technologies, IOT, AI, etc. Don\u2019t be very surprised if we start seeing boutique professional firms raise institutional financing rounds from venture capitalists looking to get their piece of the next wave of enterprise solutions.\n\nVenture capitalists(VC) funding enterprise software companies in areas such as IOT or AI are likely to seen an increase in the price of early stage rounds driven by the cost of hiring hard core engineering talent.\n\nEnterprise software startups in the new enterprise technology areas should experience longer time to market and sale cycles than the current generation of enterprise technologies. Finding and attracting engineering talent is also likely to become a constant challenge.\n\nThe friction between the need to embrace new technologies in order to stay competitive and the talent gap in IT departments could become a challenge for most enterprises. Recognizing that the new wave of enterprise software technologies will require a new type of engineering talent and implementing the strategies to hire or nurture that talent will determine front-runners from lagers in the next phase of enterprise software solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-second-act-of-api-marketplaces-d99f698b547?source=user_profile---------331----------------",
        "title": "The Second Act of API Marketplaces \u2013 Jesus Rodriguez \u2013",
        "text": "RapidAPI, a startup that has developed a marketplace for publiccly available APIs, recently announced a $3.5 million round led by VC power-house Andreessen-Horowitz with firms such as SV Angel and 500 startups also participating in the round.\n\nThe funding even might come as a surprise as the API marketplace concept is far from novel and it wasn\u2019t exactly super successful in its first iteration. However, somehow the API management space has come full circle and API marketplaces are experiencing a successful. To understand this, it might be useful to take a quick review to the recent history of API technologies.\n\nA few years ago, API marketplaces were proliferating with companies such as Mashery, Apigee or Mashape dominating the space. During those days, the focus of API marketplaces was to help API providers to market and monetize their APIs. Despite its popularity, the business model of the first generation API marketplaces was only partially successful and the monetization channel proven to be ineffective.\n\nThe rapid raise of APIs in the enterprise caused many of the early marketplaces to focus on that new channel. Apigee emerged as the undisputed leader of that phase of the market with platforms like Mashery of Layer7 as not-so-close seconds. Mulesoft\u2019s Anypoint also became a relevant platform in the enterprise for Mulesoft customers.\n\nThe acquisitions of Mashaery bu Intel and Layer7 by CA marked the initial wave of consolidation in the API market. Throughout this phase, Apigee rapidly expanded and modernized its Edge platform consolidating its leadership in the enterprise space.\n\nPaaS incumbents such as Amazon, Microsoft and IBM all launched AI management technologies as part of its cloud platforms. Those stacks have become widely adopted by developers building solutions on those PaaS stacks.\n\nA pivotal moment in the API management market was the IPO of Apigee in April 2015. Even though the stock has had a tough ride in public markets, the IPO certainly consolidated Apigee as the clear leader in the API management space.\n\nA simpler, more modern, highly extensible, open source and developer-focused generation of API management technologies have started to capture the attention and favor of developers worldwide. Technologies such as Tyk and Mashape\u2019s Kong are examples of those technologies that are slowly but steadily capturing relevant market share.\n\nA second wave of consolidation started to take place in the API management market a few months ago. After acquiring Mashery, Intel sold the platform to Tibco. RedHat acquired API management platform 3Scale to expand the API capabilities of its enterprise stack. A few weeks ago, Google acquired Apigee which is likely to become a very very relevant component of the Google Cloud platform.\n\nTechnologies such as RapidAPI mark the return of the API management space to the marketplace segment. The key to this new iteration of the API marketplace model is to drive the right balance between API providers and consumer developers. The focus on developers in areas such as API discovery, testing and monitoring is, in my opinion, essential to make this new phase of API marketplaces successful."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-natural-language-integration-2d2a24ba580b?source=user_profile---------332----------------",
        "title": "Some Thoughts About Natural Language Integration \u2013 Jesus Rodriguez \u2013",
        "text": "Conversational interfaces are driving a new wav of innovation in user experience(UX) technologies. Just like many of its predecessors, conversational interfaces come with new requirements to integrate with back-office systems. This type of model of relying on natural language to integrate with line of business systems is a completely new paradigm in the integration space and, consequently, it is likely to drive a new series of patterns and technologies to address the new requirements.\n\nNatural language integration leverages natural language constructs to access data or perform actions on back-office systems. this new integration paradigm will connect natural language based systems such as digital assistants or bots with many APIs or line of business systems. Needles to say that traditional integration platforms and patterns don\u2019t apply when using natural language as the integration protocol. As a result, we need to rethink and adapt traditional integration models to the new natural language world.\n\nTo understand the implications of conversational, natural language integrations, it might be useful to explore some of the characteristics of this new integration model.\n\nNatural language integration solutions should be able to process both text and voice command and translate them into call to APIs or line of business systems. This type of model entails that the integration solution should effectively derive the object and intent of natural language sentences and translate into a backend action.\n\nIn natural language integration solutions, at least of the endpoints will be a bot running on systems such as messaging platforms, wearable\u2019s or digital assistants. This model contrasts with the traditional system-to system integration architecture which is the basics of traditional integration platforms.\n\nAPIs are the detaul integration mole for most modern line of business systems. In the world of natural language integration, we are likely to see the emergence of new types of APIs optimized to process natural language, text and voice requests. Similarly, the concept of connectors in traditional integration systems will have to be extended to support natural language integrations.\n\nSelf-Service Integration Platforms will Drive in the Conversational world\n\nSelf-service integration platforms such as IFTTT or Microsoft Flow are uniquely positioned to power natural language integrations. The simple, one-to-one nature of self service integration platforms could address a large percentage of the natural language integration scenarios.\n\nStateless models became the architecture hallmark of traditional integration scenarios. In the conversational world, however, most integrations are stateful in nature as the context and state of the dialog are relevant on each step.\n\nIn the conversational integration paradigm, state machines will the default model to architect workflows and integrations . Conceptually, state machines are a natural model to abstract an natural language conversation. In that model, each state represents would represent an interaction of the dialog between the user/bot and the back-office integration system.\n\nThese are some of my initial ideas about natural language integrations. I plan to cover more about this subject in a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ai-serverless-computing-to-dominate-the-highlights-of-aws-re-invent-f6709c9d4a16?source=user_profile---------333----------------",
        "title": "AI, Serverless Computing to Dominate the Highlights of AWS re:Invent",
        "text": "AWS marquee conference re:Invent will be running this week in Las Vegas. As always, Amazon is likely to not disappoint with exciting new releases. Without driving too much speculation, initial signs pint that technology trends such as artificial intelligence(AI) and serverless computing will be at center stage at re:Invent.\n\nPlaying Catch Up on the Cloud AI Platform Space\n\nAWS remains the undisputed leader in the cloud platform space with a market share bigger than the rest of the relevant players combined. However, when comes to artificial intelligence(AI) and machine learning(ML), AWS still trails platforms such as Azure, Bluemix or Google Cloud.\n\nIs not that AWS hasn\u2019t invested heavily on AI and ML technologies but the quality and dominance hasn\u2019t been to the levels of other platform areas. A couple of years ago, AWS announced the release of the AWS ML platform which enables the implementation of custom ML applications. Similarly, AWS released the Alexa Skills Kit which powers AI-driven devices such as Amazon Echo or Dash. Despite this level of activity in the AI-ML fields, Amazon\u2019s competitors such as Microsoft, IBM and Google have out-innovated AWS which continuous released in areas such as cognitive cloud services, cloud ML platforms, deep learning frameworks, vertical AI solutions and even AI-driven hardware.\n\nAt re:Invent, Amazon is rumored to make the machine learning technology that powers Alexa available to developers. That type of release could provide AWS developers with sophisticated voice-AI capabilities similar to those included in cognitive platforms such as Watson Developer Cloud, Microsoft Cognitive Services or Google Natural Language Processing(NLP) APIs.\n\nIn addition to the release of the Alexa ML stack, there are other AI-related areas that could help to improve AWS\u2019 position in the market. EC2 could add GPU-optimized instances which are essential to run large scale AI and deep learning applications. Microsoft recently added similar capabilities to its Azure platform. Also, complementing Alexa\u2019s ML stack with other cognitive services in areas such as image analysis, NLP, or knowledge analysis could also be a key and simple addition to the AWS platform.\n\nAWS Lambda remains the most popular serverless platform in the market and Amazon keeps adding more capabilities to its marquee service. Recently, AWS introduced the Serverless Application Mode also known as Project Flourish which enables the implementation of really sophisticated event-driven applications.\n\nThere are many interesting ideas that could be included in the next version of the AWS Serverless Application Model. For starters, we should expect to see more robust integration of serverless capabilities and the anew AI-ML services. Also, enhanced serverless computing features can benefit other AWS services such as AWS IOT which relies heavily on serverless architecture models.\n\nIn addition to AI and serverless computing, there are other areas that could help to make AWS re:Invent a very exciting show. Bots, VR, drones are some of the trends that might drive new capabilities of the AWS platform in its quest to continue dominating the cloud platform space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bigchaindb-and-the-emergence-of-blockchain-databases-f0b396dd2dc9?source=user_profile---------334----------------",
        "title": "BigChainDB and the Emergence of Blockchain Databases",
        "text": "Databases are one of the first use cases that come to mind when thinking about blockchain technologies. Paradoxically, blockchains are really limited when comes to database capabilities. Recently, some technologies have emerged to address those limitations. Among those, BigChainDB is becoming one of the essential components of modern blockchain applications.\n\nThe excitement about blockchains and databases is logical as many people associate the blockchain with a decentralized storage ledger. In that sense, blockchains seem like an ideal candidate to power decentralized database architectures. While the theory about decentralized, federated databases has been around for a while, most popular database technologies are based on traditional centralized, service-side architectures. The blockchain certainly provides a highly-scalable data storage model but its capabilities as general purpose database are really limited.\n\nIf we analyze the capabilities of blockchains from the perspective of traditional database technologies, we can identify some very well-known challenges and limitations:\n\n\u2014 Write Latency: Confirming write operations in a decent-size blockchain network can take several minutes to complete.\n\n\u2014 Capacity: Blockchains are designed to just store a few dozen GBs which can prove insufficient in many database scenarios.\n\n\u2014 Throughput: Blockchains can only support a few concurrent operations which contrasts with the high concurrency requirements of web and mobile database solutions.\n\n\u2014 Inconsistency: Because write operations can take a long time to complete, blockchain networks can remain in an inconsistent state for minutes at a time.\n\n\u2014 Data Partitioning: Traditional data partitioning techniques are very difficult to implement in the blockchain as each node maintains a copy of the entire network.\n\nDespite some of these challenges, blockchains include many attractive capabilities that can enable a new generation of decentralized technologies. Platforms such as BigChainDB are starting to capitalize in this model.\n\nBigChainDB offers a decentralized database model powered by the blockchain. The platform uses some clever engineering techniques that combine an enterprise-grade distributed database with a blockchain infrastructure.\n\nBy leveraging a blockchain infrastructure, BigChainDB inherits some of the traditional benefits of blockchains such as asset transfer, tamper resistance and, of course, decentralized control and storage. These capabilities are incredibly relevant in modern database scenarios that power solution in emerging areas such as IOT or Virtual Reality. Complementarily, BigChainDB also inherits other benefits from using an underlying database infrastructure.\n\nBy using a distributed, decentralized database, BigChainDB overcomes some of the major limitations of the blockchain when comes to database capabilities. From that perspective, BigChainDB enables capabilities such as a full-featured NOSQL query language, high throughput data flow, high capacity, effective data partitioning and many other benefits of traditional NOSQL databases. Even more relevant is teh fact that BigChainDB enables these features without violating the consistency of the blockchain model. BigchainDB can also coexist with other decentralized storage models such as IPFS.\n\nIn a very short time, BigchainDB has become an incredibly relevant element of blockchain solutions. The database platform is already being included in many frameworks such as Eris or Ethereum. As blockchain platforms evolve, BigChainDB has the opportunity to establish itself as one of the essential components of the blockchain ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/oracle-is-acquiring-dyn-on-a-m-a-path-to-cloud-relevance-f682219ff2f6?source=user_profile---------335----------------",
        "title": "Oracle is Acquiring Dyn on a M&A Path to Cloud Relevance",
        "text": "This week Oracle announced its plans to acquire domain service provider Dyn. The acquisition follows a turbulent time for Dyn becoming the target of several cyber-security attacks. Dyn represents a great addition to Oracle Cloud and one that differentiates the Oracle stack from market leaders such as AWS, Azure, Google Cloud and IBM Bluemix.\n\nNone of of the PaaS leaders in the current market include a domain service that compares with the technical sophistication and market traction of Dyn. AWS Route 53 is certainly a great technical solution but trails Dyn in terms of capabilities and market relevance. The acquisition of Dyn could be part of a broader Oracle strategy focused on bridging the gap with the cloud platform leaders via M&A.\n\nOracle\u2019s acquisition of Dyn brings a much needed momentum to Oracle Cloud. Currently, Oracle could be considered a distant fifth in the cloud market trailing Amazon, Microsoft, Google and IBM by a large margin. While the four market leaders are currently trying to out-innovate each other with new platform service capabilities, Oracle Cloud still needs to bridge the gap on the infrastructure as a service(IaaS) space.\n\nOne of the few advantages of Oracle in the coud race is its unique talent for enterprise deals and M&A as well as its healthy balance sheet. With two deal makers as Co-CEOS and with Ellison leading the efforts related to Oracle Cloud, the acquisition of Dyn could be the beginning of a M&A spree to gain relevance in the cloud space. If that\u2019s the case, there are a few areas and companies that might help Oracle close the gap with the cloud platform leaders. Let\u2019s explore a few ideas:\n\nOracle Cloud identity management capabilities are far less sophisticated than similar services in platforms such as AWS , Azure and Bluemix. With a few strong standalone companies in the cloud identity management space, M&A could be a way to stay competitive with the market leaders.\n\nOracle Cloud\u2019s messaging and integration services could also benefit from some fresh IP. PaaS leaders such as Azure and Google Cloud have notably innovated in these areas.\n\nOracle Cloud has started some aggressive IOT initiatives but its current technology stack is very limited compared to platforms such as Watson IOT, Azure IOT Suite or AWS IOT. Currently, the are a few companies in the IOT market that may help Oracle to achieve much needed relevance in the space.\n\nOracle Cloud is already trailing other PaaS in the emerging market of data science and machine learning cloud platforms. Google Cloud, Azure and AWS have built very innovative technologies in the space. The large number of startups in the AI-ML market makes this segment very attractive for M&A\n\nContainers is another space in which Oracle cloud can make a splash by acquiring some of the market leaders. AWS, Azure and Google cloud have all recently launched native container services but the market remains pretty open at this point."
    },
    {
        "url": "https://medium.com/@jrodthoughts/deep-learning-hardware-41a7ea161ed1?source=user_profile---------336----------------",
        "title": "Deep Learning Hardware \u2013 Jesus Rodriguez \u2013",
        "text": "Deep learning is one of the most exciting disciplines of the artificial intelligence(AI) landscape. While we have recently seen an explosion on the number of deep learning frameworks such as TensorFlow or Microsoft cognitive Toolkit, the battle for dominance in the deep learning market has also extended to the hardware space.\n\nIn recent days, IBM and Nvidia announced a collaboration focused on deep learning technologies. as part of that effort, IBM announced a new deep learning toolkit called PowerAI that is optimized to run on the IBM Power S822LC server which features Nvidia NVLink technology.\n\nIBM is not the only deep learning software vendor getting closer to the hardware space. Intel and Google are also collaborating in some interesting initiatives. Microsoft is also making inroads in the space as recently announced that the OpenAI foundation selected Azure as its primary cloud provider. Azure offers Nvidia NSeries GPU instances which are optimized for deep learning applications. OpenAIis currently using thousands of those machines as part of its deep learning pilots.\n\nHardware is called to play a relevant role in this initial phase of the deep learning technology ecosystem. While the specifics are yet to be determined, there are some interesting ideas about the role of deep learning hardware in the near future.\n\nSome Thoughts About the Immediate Future of Deep Learning Hardware\n\nVendors such as Nvidia and Intel have been taking some very active steps to dominate the deep learning hardware space. Nvidia is closely collaborating with IBM and Microsoft while Intel has its efforts centered on Google. as the deep learning hardware space evolves, we should expect to see p more partnerships between the chip vendors and AI power-houses such as Microsoft, Google, Amazon or IBM.\n\nGPU-optimized infrastructure will become a more common element of PaaS stacks. Following Azure\u2019s steps, Google Cloud, AWS nad IBM are likely to start offering compute instances powered by deep learning chips in order to efficiently execute deep learning programs.\n\nAs deep learning hardware evolves, it is likely that frameworks such as TensorFlow, Caffe, Torch and others will create specific versions optimized for specific chips. Those optimizations are likely to become relevant as deep learning hardware vendors can indirectly drive the adoption of deep learning stacks.\n\nComplementing the previous point, some deep learning hardware toolkits are likely to optimize its architecture for the execution of programs built on specific deep learning frameworks. Also, some specialized deep learning hardware toolkits might embed specific deep learning programs as part of its default configuration.\n\nThe relationship between deep learning hardware and software is creating an opopeningor new startups that can combine both architectures to power the next generation of deep learning devices and applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/r3-and-vertical-blockchains-939f3ab75540?source=user_profile---------337----------------",
        "title": "R3 and Vertical Blockchains \u2013 Jesus Rodriguez \u2013",
        "text": "A few days ago, I wrote about a pilot solution conducted by the R3 banking consortium using Ripple\u2019s digital currency. R3 is a consortium of some of the most important financial institutions in the world that have been promoting scenarios for the adoption of blockchain technologies within the financial industry. R3's has made consistent progress in blockchain solutions and, a few weeks ago, two of its member achieved a major milestone by successfully delivering the first cross-border transaction between banks powered by the blockchain.\n\nWells Fargo(WFC) and the Commonwealth Bank of Australia(CBA) engaged in a trade that resulted on shipment of cotton to China from The United States. The transaction totaled $35,000.00 and was enabled by Autralia\u2019s Brigham Cotton Marketing through one of its subsidiaries in Texas. The whole process was enabled by a blockchain solution.\n\nThe WFC-CBA transaction is another example of how blockchain technologies can simplify cross-border financial transactions. Many experts catalog this event as the first cross-border blockchain transaction between banks. Even though R3 wasn\u2019t part of the implementation, the solution was based on some of the ideas that the banking consortium has been evaluating to apply blockchain technologies to financial services. Additionally, the WFC-CBA is an example of another emergent trend: the vertical blockchain.\n\nOne of the most powerful thesis about the future of the blockchain is that the market will have a handful of general-purpose blockchain platforms and many industry-specific blockchain infrastructures. From that perspective, we should expect to see the raise of blockchain frameworks in industries such as finance, manufacturing, legal, etc. That theory has been particularly popular with the emergence of consortium blockchain architectures and industry groups such as R3.\n\nIn this context, vertical blockchain won\u2019t look as blockchain but rather as a group of industry specific business processes powered by decentralized architectures. While consortiums such as R3 are making a lot of progress envisioning a blockchain focused on financial services, we should soon expect to see similar efforts on other industries.\n\nAs blockchain technologies evolve, we can envision the emergence of dozen of consortium blockchains that enable common B2B processes on specific industries. Those processes will be implemented as Smart-Contracts and will be extended with off-chain, industry-specific regulatory and compliance processes.\n\nOrganizations in vertical blockchains will own a series of smart-contracts as well as digital assets that sometimes will be translated into physical assets [ex: Cotton]. Also, vertical blockchains sometimes will need to interoperate with each other in order accomplish specific task. For instance, a manufacturing blockchain will interact with an entity in a financial services blockchain in order to place an order for a specific equipment.\n\nThe emergence of vertical-focused blockchains is a natural step for the mainstream adoption of those technologies. from the platforms in the market, Ethereum is in a unique position to enable the first-generation of vertical blockchains."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-bot-discovery-d9c4a554d2a7?source=user_profile---------338----------------",
        "title": "Some thoughts About Bot Discovery \u2013 Jesus Rodriguez \u2013",
        "text": "Discovery is becoming one of the main challenges for the evolution of bot technologies. The Achilles\u2019 heel of mobile apps, discovery models can also become a challenge in the bot world.\n\nThe rapid proliferation of messaging bots and the increasing number of messaging platforms is translating into a discovery nightmare for the ecosystem. As a bot developer, how could I ensure that my bots are surfaced to the correct users? as a bot user, how can I discover the best bots for my current needs? These are some of the main questions surrounding the bot discovery space. I would like to use the rest of this post to explore some ideas in this area.\n\nThe \u201capp store\u201d is the model that most developers associate with asset discovery. Consequently, different vendors have tried to recreate the app store model for the bot ecosystem and have created different \u201cbot store\u201d solutions. While the bot store model works well in scenarios in which the users know the specific bot they are looking for, its incredibly inefficient for organic discovery scenarios. Similarly to the app store, for bots to be visible in this model they will have to make it to the \u201cTop 10\" of the bot store, a premise that is not achievable by most bots. To address some of the challenges of the bot store model, I believe we can turn to one of the best friends of bot technologies: artificial intelligence(AI).\n\nImagine that you are using a messaging platform such as Facebook Messenger or Skype, and you would like to check airfares for an upcoming business trip. Instead of searching for a travel bot upfront in the bot store, you can simply type a natural language question such as \u201cwhat flights are available departing NYC to London next week?\u201d. Automatically, a set of flight options will popup on your IM window together with some recommendations of bots such as Kayak or American Airlines that might help you complete the process. The model I just described feels more natural than the bot store equivalent and also takes advantage of natural language processing(NLP) techniques.\n\nA simple way to start enabling better bot discovery processes could be for bots to express their capabilities using a metadata description language. By capabilities, I am referring to some of the most common questions, entities, intents or other aspects related to the functioning of the bot. Bot developers could include that metadata with their bots and automatically publish it to the different bot platforms. In our example, the Kayak and AA bots will express their capabilities using a description language and deploy it as part of the solution.\n\nThe second component of our model is a bot that uses natural language to discovery other bots. Our discovery bot will match the user intent with specific bots based on the capabilities expressed in those bots\u2019 description language. In our example, the discovery bot will recommend Kayak and AA as possible bots based on the user intent [booking a flight].\n\nA bot discovery model could also take advantage of AI and NLP to improve the discoverability of bots based on its interaction with users. In that models, as more users interact with a specific bot, the platform could enrich its description language and discovery criteria to associate the bot with new users.\n\nBot discovery is becoming a focal point of platforms in the space. Microsoft has been vocal about exploring the idea of building a search engine for bots. Also, the bot startup Intento is pioneering some interesting innovation in the bot discovery space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cloudfoundry-ethereum-a-winning-combination-for-baas-ee1c519b814f?source=user_profile---------339----------------",
        "title": "Cloudfoundry + Ethereum: A Winning Combination for BaaS",
        "text": "The debate about private vs. public blockchains have been very active in the blockchain community. Recently, we have gotten a glimpse about the viability of the private blockchain model as some household names such as Citi or Credit Suisse have embraced it as part of their initial set of blockchain solutions. One of the factors that is helping accelerate the viability of private blockchains is the emergence of the blockchain as a service(BaaS) model.\n\nBaaS refers to an architecture style that enables the creation of private blockchains as part of platform as a service(PaaS) infrastructures. IBM and Microsoft have taken the lead in the BaaS trend with the release of technologies such as Hyperledger and Project Bletchey respectively. Additionally, AWS and Google Cloud are expected to enter the BaaS race soon.\n\nThe current generation of BaaS technologies are fundamentally based on public cloud infrastructure such as Azure or Bluemix. In the future, some BaaS stacks might be available as private cloud solutions like Azure Stack but we are still far from the adoption of that model. The dependencies on public PaaS is, in my opinion, a limiting factor for BaaS as many of the same arguments keeping customers for adopting public blockchains might still apply to blockchains running on public clouds.\n\nMore than any other technologies running on PaaS stacks, blockchains can really benefit from an architecture that ensures portability and consistency between different cloud and on-premise platofrms. From the technologies available today, the combination of Cloudfoundry and Ethereum can be a winner to address some of the challenges with the BaaS model.\n\nThe combination of Cloudfoundry and Ethereum [CFBaaS] is a very intriguing architecture for BaaS solutions. For starters, the model will ensure 100% open source distribution of both the BaaS stack as well as the underlying PaaS. Similarly, a CFBaaS stack will ensure portability across different public and private cloud infrastructures. From a functional standpoint, Ethereum will expand Cloudfoundry with the capabilities and services required to build blockchain solutions. Complementarly, Cloudfoundry\u2019s infrastructure and platform services will expand the capabilities of Ethereum solutions in areas such as data storage, security, middleware and many other components of general-purpose applications.\n\nThe CFBaaS model will bring an interesting set of benefits compared with the current group of BaaS platforms. Let\u2019s explore a few ideas:\n\n\u2014 Open Source Distribution: A BaaS model based on Cloudfoundry and Ethereum will ensure 100% open source distribution of the blockchain technologies as well as the underlying cloud platform.\n\n\u2014 BaaS Portability and Interoperability: A CFBaaS architecture will ensure portability across different public PaaS such as Azure or AWS as well as on-premise environments.\n\n\u2014 Ethereum Oracles for Cloudfoundry Services: A CFBaaS architecture will enable Ethereum\u2019s Oracles for Cloudfoundry services in areas such as storage or messaging which will allow developers to build really robust blockchain solutions.\n\n\u2014 Decentralized Cloudfoundry solutions: Leveraging Ethereum as part of Cloudfoundry will enable the implementation of fully descentralized applications that combine different capabilities of the Cloudfoundry stack.\n\n\u2014 Merging Two Dynamic Developer Communities: A CFBaaS solution will bring together two of the most exciting developer communities in the market.\n\n\u2014 Commercial Adoption:Many customers in regulated industries that are currently evaluating blockchain technologies have already adopted Cloudfoundry as their PaaS solution. A CFBaaS model will simplify the adoption of Ethereum and blockchain technologies without requiring new investments on infrastructure or engineering resources."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ibm-brings-watson-to-iot-with-project-intu-34d91b4cc52c?source=user_profile---------340----------------",
        "title": "IBM Brings Watson to IOT with Project Intu \u2013 Jesus Rodriguez \u2013",
        "text": "IBM\u2019s Watson Developer Conference(WDC) brought a lot of exting announcements about IBM\u2019s efforts in the cognitive and artificial intelligence(AI) fronts. Among those announcements, Project Intu is a new initiative looking to bridge the gap between Watson and smart IOT devices.\n\nConceptually, Project Intu simplifies the experience of integrating Watson cognitive services into applications running on heterogeneous IOT devices. Even though Intu\u2019s scope goes beyond devices, IOT integration is certainly the most relevant component of it. While IBM has already made signitificant efforts to integrate Watson into IOT solutions (they even rebranded their IOT suite was Watson IOT Platform), Project Intu has taken these efforts to another level by tailoring and optimizing the Watson experience to different device platforms.\n\nThe current approach of integrating Watson with smart devices requires a considerable amount of work by IOT developers. Even though many of the capabilities of Watson are available via APIs, developers still need to do a considerable effort on aspects such as collecting the input data from cognitive sensors, transform it, process the response from Watson, etc. For instance, an application running in a 360 camera might need to capture and process many frames before having the best image that can be processed by Watson\u2019s Vision Services. Project Intu simplifies developer experiences such as our example by tailoring the framework to different IOT toolkits ranging from Unity to RasperryPi.\n\nFive Reasons Why Project Intu is Relevant\n\nThere are many reasons for the Watson community to be excited about Project Intu. Fundamentally, the main benefit of Intu is the way it bridges the IOT and cognitive worlds by simplifying the experience of embedding Watson capabilities in IOT in-device applications. Let\u2019s look at some of the main benefits of Project Intu:\n\nProject Intu allows IOT developers to leverage AI capabilities provided by Watson as a native component of IOT stacks. From that perspective, IOT developers will start thinking about Watson capabilities in the same way that today they think messaging, device data or other native features of IOT applications.\n\nProject Intu will expand the channels for Watson solutions to be distributed as part of IOT devices. Similarly, device manufacturers will be able to expand the value proposition of their hardware devices by leveraging cognitive capabilities.\n\nBy providing a deeper integration IOT devices, Project Intu will be able to gather better data that can be used to improve the training of Watson solutions in the future.\n\nProject Intu will allow IOT developers to incorporate cognitive capabilities into their in-device solutions without being concerned about aspects such as data collection, transformation, API interoperability among other aspects that are very specific to each IOT device runtime.\n\nWithout a doubt, Project Intu is a very interesting initiative by IBM that brings together two of the biggest technology trends in the industry. It would be interesting to see how the IOT community receives Project Intu and the first generation of applications that it powers."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-cloud-ml-brings-a-unique-angle-to-the-machine-learning-cloud-d152dc42a0c7?source=user_profile---------341----------------",
        "title": "Google Cloud ML Brings a Unique Angle to the Machine Learning Cloud",
        "text": "Google Cloud Machine Learning (Cloud ML) is a new addition to the cloud machine learning market. While PaaS leaders such as AWS and Azure have released their ML stacks more than a year ago, Google Cloud certainly has taken its time to enter the space. However, the first version of the cloud ML service already provides some unique differentiators that can push it to a leadership position within that segment of the ML market.\n\nConceptually, Cloud ML can be seen as a native cloud service for hosting TensorFlow applications. Cloud ML provides an architecture based on concepts such as projects, models, versions and jobs that enables the implementation of really sophisticated ML applications.\n\nCloud ML is entering a very competitive market with incumbents such as Amazon and Microsoft leading the charge with very innovative offerings. Azure ML is Microsoft\u2019s ML cloud service which offers some interesting technical capabilities such as visual model building and strong support fo rR and Python ML scripts. Similarly, AWS ML excels at the simplicity of its programming model and the strong support for advanced statistical methods.\n\nDespite the initial traction of both Azure ML and AWS ML bot platforms have well-known limitations that constrains its usage to relatively simple ML scenarions. Today, is really complicated to build a sophisticated ML solutions using those services exclusively due to limitations in areas such as extensibility. support for custom algorithms, integration with on-premise data sources, etc. Google Cloud ML provides a unique model that addresses some of those limitation without sacrificing the simplicity of the programming model.\n\nTensorFlow is one of the most popular open source deep learning frameworks in the market. by leveraging Tensorflow, cloud ML allows developers to implement really sophisticated and highly extensible ML programs without investing in complex infrastructures.\n\nGoogle\u2019s DeepMind recently adopted TensorFlow as its underlying stack. The complexity of the AI problems that DeepMind is attacking is likely to translate into improvements for the TensorFlow stack and subsequently Cloud ML.\n\nGoogle Cloud continues making steady progress on the AI space. The recent releases of capabilities such as natural language processing (MLP) APIs or Speech APIs are an example of the rapid growth in the Google Cloud AI ecosystem. Even though competitors such as Azure offer the same levels of AI and ML services as part of its platforms, other PaaS such as AWS and Bluemix are still trying to structure a cohesive platform for both types of capabilities.\n\nAs a side effect of using Tensorflow, Cloud ML customers can develope solutions completely on-premisee and deploy it and scale it in cloud environments. That llevelof symmetry is aabsentof other cloud ml stacks.\n\nFinally Cloud ML integration with unique Google Cloud services such as Datalab (self-service data science) or Bigquery enables and implementation of really robust ML solutions.\n\nGoogle Cloud ML is a very young but also exciting addition to the cloud machine learning ecosystem. While Amazon, Microsoft and IBM still lead the field, Google Cloud ML has the potential of becoming a relevant solution in the space in a very short time."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ai-and-the-human-brain-creativity-and-imagination-56ca99198d06?source=user_profile---------342----------------",
        "title": "AI and the Human Brain: Creativity and Imagination \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) is actively making progress in its quest to recreate some of the models of the human brain. More specifically, AI\u2019s focus has been centered on recreating patterns of the neocortex region of the brain which is responsible for many of the human intelligence capabilities.\n\nAs AI makes progress to recreate the neocortex, an idea that is keeping researches busy is the possibility of creating AI models that resemble transcendent abilities of the brain such as fear, creativity, imagination, aptitude among other behaviors that are key to the human identity. Many of these behaviors are the result of well-known patterns in the neocortex so is not crazy to think that AI systems can be successful imitating them. As matter of fact, there have been some AI research efforts that have shown some progress recreating transcendent abilities of the human brain. Today, I would like to focus this post in two transcendent abilities of the brain that were thought impossible to recreate by AI systems: creativity and imagination.\n\nThe neocortex specializes in recognizing patterns using a complex net of hundreds of billions o interconnected neurons. Groups of neurons in the neocortex specialized on recognizing specific patterns that could be as simple as a letter or as complex as the solution to an algebra problem. This notion of pattern recognition is the common denominator to many of the brain\u2019s transcendent abilities.\n\nCreativity can be described as the ability of finding great metaphor. In the context o the neocortex, a metaphor is a patterns that could be related to another pattern despite differences on details and context. The neocortex is a great metaphor association machine with the ability of recognizing over 30 billion metaphors per second.\n\nIf AI systems can be trained to be creative, they could get better at skills like creating narratives or analyzing complex problems by drawing analogies from other well-known problems.\n\nImagination can be described as the ability to anticipate patterns that could be related to other patterns in the future. Strategic thinking is a very clear sign of a strong imagination.\n\nAI systems have already shown tremendous progress imitating human imagination. During game 3 of the recent match between DeepMind\u2019s AlphaGo and Go\u2019s number one world player Lee Sedol, AlphaGo shocked experts by finding an incredibly imaginative solution move 37. As a matter of fact, many experts believe that we will remember that specific event [game 3, move 37] as the moment when AI systems became truly creative and imaginative.\n\nCreativity and imagination are tow of the human brain\u2019s transcendent abilities that are possible to recreate with today\u2019s AI technologies.\n\nThe key to enable AI creativity is to model a specific pattern [image, text, speech, etc] as a series of common constructs so that they can be used to determine its association with another patters [metaphor]. Easier said than done but an idea nonetheless. A creative AI system could be a good solution for problems such as finding treatments for a specific condition based on know treatment for other diseases.\n\nThe key to enable AI imagination is to constantly evaluate future patterns [outcomes] based on existing sets of patterns. DeepMind solution to reduce cost on Google\u2019s data centers is a good example of AI imagination even though, of course, we will always have move 37."
    },
    {
        "url": "https://chatbotsmagazine.com/bot-talks-intent-based-vs-flow-base-conversations-798788dc9cf6?source=user_profile---------343----------------",
        "title": "Bot Talks: Intent-Based vs. Flow-Base Conversations",
        "text": "The evolution of bot technologies has helped to drive a revolution in natural language processing (NLP) and natural language understanding(NLU) technologies . Just a few years ago, NLP-NLU technologies were confided to the academic circles. Today, NLP-NLU stacks have become one of the pillars of artificial intelligence(AI) platforms.\n\nWhile there are many NLP-NLU innovations and that have been related in recent years, the market attention continues focused on the platforms released by incumbents such as Microsoft, Face book, IBM, Google or Amazon/ From that perspective, platforms such as Face book\u2019s Wit.ai, Watson\u2019s Conversation Service, Microsoft\u2019s Language Understanding and Intelligence Service or Google NLP API have drive a lot of attention from developers and customers. Part of that attention is based on the fact that many of those stacks are integrated with bot platforms such as Face book Messenger, Microsoft Bot Framework or Google\u2019s Allo.\n\nDespite the excitement about bots and NLP-NLU stacks, it is important to recognize that the majority of those technologies are in very early stages when comes to replicate the sophistication of human conversations. With a couple of exceptions, most NLP-NLU technologies are focused on determining the intent and object of isolated sentences in a conversation. However, analyzing natural language sentences in the context of broader conversations is still a work-in-progress are for most NLP-NLU technologies. Using AI terminology, the current generation of NLP-NLU stacks are enabling intent-based analysis capabilities but they should gravitate towards powering flow-based analysis models.\n\nIntent-based analysis\u2019 goal is to determine the entities and intent of natural language sentences. For instance, if we analyze the following sentence: \u201cI would like to book a Dr\u2019s appointment\u201d, an intent-based NLP algorithm will determine the intent of the sentence as \u201cbooking an appointment\u201d while the main entity remains \u201cthe Doctor\u201d.\n\nIntent-based analysis is the foundation of most NLP-NLU technologies but is hardly sufficient to simulate intelligent conversations. Using the previous example, the response of an intelligent bot could be different depending of the state of the conversation, location and many other aspects. The bot could provide a more detailed answer if it knows the information of the user\u2019s regular physical or the fact that the user is currently traveling in The UK. Those contextual elements could change the dynamics of conversations driven by NLP-NLU stacks.\n\nIntent-based analysis techniques should be performed factoring in the specific context and state of a conversation. State can be identified as data points from previous statements in the conversation. For instance, if I mention that I have been experiencing blurry vision in recent days, after I request a Dr\u2019s appointment the bot will refer me to an ophthalmologist. Context refers to environmental conditions surrounding a dialog. For example, if the NLP stack understanding that I am traveling in London, is going to attempt to find me an ophthalmologist in that city.\n\nFlow-based analysis is the next logical evolution of NLP techniques. Flow-based models while extend intent-based algorithms by combining multiple utterances in a state machine model that imitates a conversation flow factoring in the appropriate state and context. Each state of a flow-based NLP model will leverage intent-based analysis techniques and will determine the next stage based on the outputs. Using flow-based analysis, we can model a conversation using a state machine model which can enrich the nature of conversations between users and bots.\n\nFlow-based analysis is far from being a theoretical excursive. Platforms such as Wit.ai are already doing some very impressive work in this area."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-expander-and-the-emergence-of-semi-supervised-learning-1919592bfc49?source=user_profile---------344----------------",
        "title": "Google Expander and the Emergence of Semi-Supervised Learning",
        "text": "Google Research recently announced another important addition to its AI portfolio: Expander, a framework to enable semi-supervised learning in machine learning (ML) algorithms.\n\nFor years, the ML world has been divided into two main types of algorithms: supervised and unsupervised. Supervised algorithms can be seen as models with predictive capacity based on training using large amounts od data. On the other hand, unsupervised models such as clustering algorithms are able to operate without previous training.\n\nWhile most experts agree that unsupervised algorithms are the future of ML, supervised models are more common and efficient in the current state of the market. Despite its popularity, supervised algorithms often run into the challenge of having to collect enough high quality data for the training processes. This is precisely the problem Google is trying to solve with Expander.\n\nConceptually, the goal of Expander is to power ML algorithms with some but minimum supervision. To enable that capability, Expander leverages new techniques known as semi-supervised learning that bridges the gap between known and unfamiliar data. Semi-supervised learning merges known and novel data as part of the training process and infers relationships between those data sets. This approach highly contrasts with supervised ML models such as neural networks that need to be trained upfront using high-quality, well-labeled data.\n\nFunctionally, Google Expander leverages large-scale, graph-based learning to infer knowledge about a specific data source. Specifically, Expander builds a multi-graph representation of a data source on which nodes correspond to objects or concepts and edges connect nodes that share similarities. The graph should contain both known and unknown data.\n\nThe magic of semi-supervised learning relies on the efficiency of labeling the unknown data sets by leveraging the characteristics of its neighbors in the graph. Expander tackles this problem by using an optimization technique called streaming approximation. This technique uses a streaming algorithm to process information propagated from neighboring nodes in a way that can be scaled to large graphs.\n\nTo get an idea of how semi-supervised learning works, let\u2019s use an example of a sentiment analysis process. When analyzing a text, the first step will be to create a graph in which the nodes are the words and the edges the relationship between them. After that, the algorithm will start labeling known words that express specific emotions and proceed to apply the streaming approximation techniques to label the unclassified words. During that process, the algorithm will create links between the newly labeled words and the words that represent specific emotions they are related to.\n\nGoogle Expander is already being used in large scale systems such as the Allo assistant and we should expect to see more of these techniques in the near future. Semi-supervised learning offers an exciting middle ground that can help improve the applicability of many of the well known ML techniques to p-ractical problems."
    },
    {
        "url": "https://chatbotsmagazine.com/alexa-is-coming-to-the-enterprise-c453d4a8a0e?source=user_profile---------345----------------",
        "title": "Alexa is Coming to the Enterprise \u2013",
        "text": "Amazon\u2019s Alexa is powering some of the most successful consumer electronic devices of all time. Recently, developer have been steadily extending Alexa\u2019s capabilities into the enterprise.\n\nA few days ago, a company called SoftServe delivered VoiceMyBot, a solution that integrates Alexa with popular enterprise messaging tool HipChat. Using VoiceMyBot, companies can use Alexa-powered devices such as Amazon Echo to interact with a HipChat room by using voice commands.\n\nSolutions like VoiceMyBot are possible because Amazon designed Alexa with extensibility as a first-class-citizen since the first day. Alexa Skills Kit is the main extensibility point of the platform and developers are starting to use it to integrate Alexa with enterprise systems and business processes.\n\nAlexa-powered devices such as Amazon echo can become an efficient digital assitant in the enterprise. New Alexa skills can be created to rapidly access information and improve collaboration using conversational interfaces. We can imagine an enterprise deploying Echo devices on every conference room to improve meetings and collaborative activities between its employees.\n\nAlexa has the potential to become a conversational interface gateway for common back-office systems. For instance, there are already efforts to integrate Alexa with common line of business systems such as Salesforce or Workday. As more line of business systems provide this type of conversational capabilities powered by Alexa, the can for enterprise deployments of Amazon\u2019s devices will become more viable.\n\nEnterprise messaging platform such as HipChat or Slack as well as newcomers such as Facebook Workplace or Microsoft Teams remain the obvious first choice to enable Alexa integrations. Those messaging platforms already include thousands of bots that can be easily extended to integrate with the Alexa platform.\n\nDon\u2019t expect Amazon to try to introduce Alexa to the enterprise by themselves. Amazon will be more successful by enterprise software vendors such as Salesforce, Microsoft, Slack, Atlassian, ec. Alexa-powered enterprise solutions are unlikely to become mission-crititcal in the enterprise any time soon but can be a very simple add-on to mission critical enterprise systems.\n\nWhat About the Competition?\n\nIf there is a market for office digital assistants, Amazon is in a unique position to dominate it. No other voice platform combines hte market penetration, extensibility and developer communiyty to be able to make a strong transition into the enterprise. Sophisticated voice software platforms such as Watson and cortant lack hardware devices with the popularity ofAmazonn Echo to be considered relevant in the enterprise at this point. Google Home is an interesting choice but, at the moment, Amazon Echo enjoys a solid lead."
    },
    {
        "url": "https://medium.com/@jrodthoughts/powerapps-flow-office-365-is-becoming-a-platform-bdd6a7b15098?source=user_profile---------346----------------",
        "title": "PowerApps, Flow, Office 365 is Becoming a Platform!",
        "text": "Last week, Microsoft announced the general availability of two major additions to its Office 365 suite: Flow and Powerapps. The addition of these products represents a continuation of a trend that empowers citizen developers and shadow IT groups to build applications without the need to general-purpose programming knowledge or IT resources. From the perspective of Office 365, the release of Flow and PowerApps marks a transition from an information worker suite to a platform that supports the implementation of custom applications.\n\nPowerApps enables the creation of data-driven mobile applications directly from Office 365 data sources. Using PowerApps, a developer can start building an app using a specific template and customize the screens based on the specifics of the data source. Powerapps currently supports IOS, Android and Windows Apps.\n\nThe concept of enabling self-service mobile application creation is certainly not a new one. The mobile market is full of rapid app development(RAD) suites none of which have been able to achieve meaningful market share. PowerApps has a few unique characteristics that may help it to be successful in this ultra-competitive field.\n\nOne of PowerApps biggest advantages is its narrow focus on powering self-service mobile apps to extend Office 365 processes. The constrained scope might help PowerApps to become a friendly tool to build Office 365 specific application without attempting to become a general purpose mobile app development platform. Additionally, PowerApps is focused on the creation of mobile apps directly from business data. To accomplish this, PowerApps introduces the notion of the Common Data Model(CDM), a canonical and extensible representation of common business data entities such as contacts, accounts, tasks, etc delivered as a secured Azure database.\n\nMicrosoft Flow focuses on self-service data integration adn workflow scenarios. From that perspective, Flow competes with technologies such as IF-THIS-THEN-THAT(IFTT) or Zapier. Similarly to PowerApps, Flow\u2019s focus on Office 365 workflows and the use of CDM can result on strong differentiation with other technologies in the space.\n\nDespite ot its unquestionable technical benefits, the biggest competitive differentiator of technologies like Flow and PowerApps is Office 365 itself. The strong distribution and customer base of Office 365 almost guarantee the strong adoption of these technologies. With the addition of these technologies, Office 365 continues is transition from an information worker suite to an information app platform.\n\nOffice 365 is, arguably, the most popular information worker suite in the market. the next logical phase for Office 365 is to extend its capabilities by enabling the implementation of custom applications that automate business processes related to the suite. That type of capabilities will empower line of business units to build custom Office 365 solutions without relying on IT departments. However, differently from other \u201cshadow IT\u201d products, Office 365 seems to strike the right balance by delivering powerful app development tools such as PowerApps or Flow while enforcing constraints that will minimize the overlap with enterprise IT capabilities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/move-aside-bitcoin-zcash-and-appcpoms-are-stealing-the-highlights-in-the-cryptocurrency-world-b83c22b419f5?source=user_profile---------347----------------",
        "title": "Move Aside Bitcoin! ZCash and Appcpoms are Stealing the Highlights in the Cryptocurrency World",
        "text": "While Bitcoin continues battling its challenges such as network limitations or internal battles in the community, new crypto-currencies are capturing the highlights and the minds of software developers. A few weeks ago, the R3 bank consortium announced a partnership with Ripple to use its digital currency in international transactions. More recently, crypto-currencies such as Appscoin and Zcash have aggressively entered the market trying to address ome of the limitations of Bitcoin. Both Zcash and Appcoin represent very exciting development of the world of digital currencies.\n\nAnnounced just a few days ago, Zcash( Zero Cash) have raised a lot of expectations in the digital currency community for its use of cutting edge cryptography. Among its many exciting features, Zcash excels at enabling unprecedented levels of anonymity and privacy for its users. From the technical standpoint, Zcash can be considered a major breakthrough in the digital currency space and not just another release of the same type of technology.\n\nZcash accomplished its privacy and anonymity levels by using a technique called \u201caero knowledge proofs\u201d or zk-SNARKs. In a nutshell, zk-SNARKs algorithms allow the Zcash network to verify transaction without learning any private details about the entities involved in it.\n\nThe Zcash model can be considered an evolution of the Bicoin pseudonymity architecture. On the Bitcoin network, a person is represented by an address and all transaction related to that address are publicly available. On the Zcash network, the person\u2019s address will remain private based on zk-SNARKs encryption. Other aspects such as the amount of the transaction and the destination can also be obscured.\n\nThe reasons behind Zcash are questionable and, if it works, we can imagine is going to be widely adopted in the black market and other illegal activities. However, there are also many benefits that come from a completely anonymous crypto-currency including the inability of prioritize transactions based on the origin, destination and amount.\n\nAppcoins is a concept that I thought was going to take off after the launch of Ethereum. While it has take a while the digital currency community seems to be warming up to the idea.\n\nConceptually, Appcoins are crypto-currencies embedded within a specific app that us used to pay for goods and services that the app offers. Ether can be considered Ethereum\u2019s Appcoin and it was used to crowfund the project.\n\nAppcoins are a super exciting concept but it also raises many concerns from the ethical standpoint, First, crypto-currencies created for a specific app may lack the rigor of a general purpose digital currency infrastructure and, consequently, are likely to be more vulnerable to cyber-security attacks (ex: Ethereum DAO attack). Also, Appcoins are subjected to the temptation of mining/selling too many coins upfront in order to raise initial funds for the app (kind of an overvalued seed round :) ).\n\nThere are plenty of positive and negative arguments that can be used for any specific cryptocurrency. However, even the most skeptical of the digital currency market can\u2019t deny the new and exciting innovations happening in the space. Is certainly not about Bitcoin anymore!"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-emergence-of-the-ai-first-mobile-app-bfbc6423c8a8?source=user_profile---------348----------------",
        "title": "The Emergence of the AI-First Mobile App \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial Intelligence(AI ) is changing the software world and mobile is not an exception. Recently, many high profile mobile apps have started to leverage cognitive of AI capabilities in areas such as natural language processing(NLP) or cognitive vision. Despite the impressive progress, the transformation of mobile apps using AI technologies is in very early stages. In the near future, AI has the opportunity of becoming a native element of mobile apps. We might be entering the era of the AI-First mobile app.\n\nThe idea of the AI-First mobile app is conceptually simple despite the catchy term. As AI evolves, mobile apps will start leveraging cognitive toolkits as natively as they use constructs such as UX events, OS interactions or geo-location APIs today. In other words, AI will become a native component of mobile apps and mobile OSs. Incorporating AI capabilities into mobile apps goes beyond using APIs to process input from cognitive data sources. AI could change the way we design mobile apps to enable intelligent interactions with users.\n\nThere has been plenty of speculation about how mobile apps will incorporate AI capabilities. From new forms of UX design to the processing or cognitive inputs, the ideas are endless. However, there are a few areas that are closer to other to become an important part of AI-First mobile apps in the immediate future.\n\nProcessing inputs from cognitive data sources such as language, text, vision or speech will become a key capability of aI-First apps. There type of cognitive inputs will complement the explicit input in the form of UI events that drives most of mobile UX design techniques today.\n\nComplementing the previous point, we can single out NLP from other cognitive capabilities as conversational interfaces are going to become an essential factor on AI-First mobile apps. In the near future, mobile apps are likely to combine natural language dialog with explicit UI elements to provide a more natural user experience.\n\nContextual UIs has been part of mobile apps for a few years but it could be take to the next level with AI techniques. In addition to traditional contextual elements such as location or time zone, AI-First mobile apps can leverage techniques such as sentiment analysis or intent analysis to uber-personalize the experience for users.\n\nAI-First mobile apps can become very effective performing background tasks on behalf of a user. As AI-First mobile apps become more intelligent in aspects such as user preferences or behaviors as well as complementary social, economic or environmental aspects they will be able to accomplish tasks on behalf of the users without being explicitly directed to do so.\n\nAI-First mobile apps can become the first generation of truly self-learning mobile apps. While today, the concept of self-improving apps is constrained to aspects such as user preferences, AI techniques can leverage other elements such as sentiment analysis, user intent or environmental conditions to learn and \u201creason\u201d in order to improve the user experience."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-cognitive-toolking-can-give-tensorflow-some-headaches-16fe092297cf?source=user_profile---------349----------------",
        "title": "Microsoft Cognitive Toolking Can Give TensorFlow Some Headaches",
        "text": "Last year, Microsoft announced the release of an open source framework called Computational Network Toolkit(CNTK to enable the implementation of deep learning capabilities. Last week, CNTK got an update and a new name: Microsoft Cognitive Toolkit.\n\nThe new version [2.0] expands the scope of its learning capabilities and the support for Python 3. Previous versions of the Cognitive Toolkit were solely based on C++ which affected its adoption by the developer community.\n\nCognitive Toolkit 2.0 adds other improvements including support for Visual Studio and the adoption of reinforcement learning algorithms. The latter is a particularly relevant event as reinforcement learning is becoming one of the most popular deep learning methods for training machine learning models. Microsoft also announced that new versions of the Cognitive Toolkit will include support for R and C#.\n\nMicrosoft Cognitive Toolkit is entering the crowded and yet emergent deep learning platform space that includes frameworks such as TensorFlow, Caffe, Torch, Paddle and a few others. Google\u2019s TensorFlow is a stack that has made lot of progress recently with the release of the Google Cloud Machine Learning as well as the implementation of several mission critical solutions by Alphabet\u2019s subsidiary: DepeMind. With this new release Microsoft Cognitive Toolkit can become a serious contender in the market. Specifically, Microsoft Cognitive Toolkit can become relevant t enterprises entering the machine learning and deep learning space. However, in order to achieve that, Microsoft still has some work to do with the Cognitive Toolkit stack\n\nSome Ideas That Can Uniquely Differentiate Microsoft\u2019s Cognitive Toolkit\n\nBecoming a relevant deep learning platform in the enterprise requires more than a robust technology stack. However, Microsoft\u2019s Cognitive Toolkit is on a very unique position to differentiate from some of the other leaders in the space. Let\u2019s explore a few ideas that can help Microsoft\u2019s Cognitive Toolkit accomplish that goal:\n\n\u2014 Integration with Microsoft\u2019s Cognitive Services: Integrating Microsoft\u2019s Cognitive Toolkit and Microsoft\u2019s Cognitive Services can provide a strong model for enterprises building deep learning and artificial intelligence solutions.\n\n\u2014 Integration with Azure ML: Similarly to the model followed by Google Cloud ML, Microsoft should enable the execution of Cognitive Toolkit programs as part of Azure ML. This model will provide strong cloud and on-premise symmetry for Microsoft\u2019s deep learning solutions.\n\n\u2014 Integration with PoweBI: Integrating Microsoft\u2019s Cognitive Toolkit with PowerBI will enable rich visualizations to enrich the output of Cognitive Toolkit algorithms.\n\n\u2014 Server-Side Infrastructure and Tooling: In order to be more competitive with frameworks such as torch or TensorFlow, Microsoft\u2019s Cognitive Toolkit should enable a more robust server side infrastructure and tooling to execute and manage programs created with the framework.\n\n\u2014 C# and R Support: The support for R and C# can drastically increase the adoption of the Microsoft Cognitive Toolkit as well as attract a large developer community. This capability seems to already be on the roadmap of the framework"
    },
    {
        "url": "https://medium.com/@jrodthoughts/what-is-wall-streets-favorite-cloud-platform-a711068368db?source=user_profile---------350----------------",
        "title": "What is Wall Street\u2019s Favorite Cloud Platform \u2013 Jesus Rodriguez \u2013",
        "text": "The cloud platform leaders: Amazon, Microsoft, Google and IBM reported earnings in the last ten days. The results were incredibly positive across the board with all companies reporting strong growth in their cloud platforms. From the stock perspective, the result were mixed: Microsoft and Google\u2019s earning reports were incredibly well received and the stocks picked in after hour trading. IBM\u2019s strong cloud numbers were shadowed by another revenue declined and the stock paid the consequences. Amazon Web Services(AWS) revenues were the shinning starting of the earnings report but the stock also traded down based on a decline in profits due to heavy investments in the retail business.\n\nThe diverse market reactions fo rthe different cloud platform incumbents raises an interesting question: what cloud platform has the most potential from Wall Street\u2019s perspective. Amazon continues to be the undisputed leader in teh space but that doesn\u2019t always translate into Wall Street love. Public market analysts need to evaluate a cloud platform not only from the technology and growth standpoint but also taking into consideration other factors such as the impact or dependencies on other business units [Amazon\u2019s example], the revenue impact based on specific international markets or currency dependencies as well as other unexpected factors that can affect future growth.\n\nWith that in mind, I\u2019ve put together a few ideas about the lead cloud platforms from a public market perspective that might help to illustrate some of these points. For each platform, I\u2019ve tried to provide an analysis from a Wall Street perspective as well as stating key questions that should be consider and factors that can drastically change the perspective on the stock\n\nMicrosoft\u2019s Azure consolidate its position as the number two cloud platform in the market. Azure reported an outstanding 116% year-on-year revenue growth. Microsoft\u2019s Intelligent Cloud segment that includes Microsoft\u2019s server products and Azure posted revenues of $6.4 billion. Overall, Microsoft\u2019s investments in new areas such as artificial intelligence(AI) or internet of things(IOT) continues to make Azure one of the most exciting technologies in the market.\n\n\u2014 Key Questions: Can Microsoft bridge the gap with Amazon? How would the acquisition of Linkedin affect Azure\u2019s growth?\n\n\u2014 X Growth Factors: Office 365 grew 51% year-on-year and its adoption continues to be an accelerator for the adoption of the Azure platform. Window\u2019s and Surface\u2019s adoption are also other factors that can influence the Azure growth.\n\nAWS posted an impressive $3.2 billion in revenue for the quarter and an increasing profit. However, the stock was punished based on lower than expected margins in the retail sector. From a public market perspective, the main question about AWS is whether it can sustain or increase its lead over rivals such as Microsoft and Google that have been successful out innovating Amazon in emerging technology ares such as IOT, AI or virtual reality.\n\n\u2014 Key Questions: Can Wall Street objectively delineate the dependencies between Amazon\u2019s retail adn cloud businesses? If AWS gets big enough, should it become a standalone company?\n\n\u2014 X Growth Factors: Devices such as Amazon Echo or the future drone delivery business can accelerate the adoption of AWS.\n\nAlphabet doest not yet break down revenues of Google Cloud which makes the growth numbers subjected to speculation. However from a public market perspective, Google Cloud\u2019s upside potential is the subject of exigent. Alphabet\u2019s stock traded higher after earnings but the exigent was ,mostly related to better than expected growth in the ad business.\n\n\u2014 Key Questions: What are the real numbers for Google Cloud? Can Google cloud become a leader in the AI field?\n\n\u2014 X Growth Factors: There are many factors that can influence the growth of Google Cloud: G-Suite, Android, Pixel, Home are some of the technologies that can increase the adoption numbers for Google Cloud in the near future.\n\nIBM also reported strong numbers for its cloud platform group which Bluemix and Softlayer. However, IBM\u2019s stock was affected based on the decline in some of the traditional business units. The rapid growth of IBM Watson and its development cloud services in Bluemix are positive highlights for public market analysts. For IBM, the number one goal has to be to pass Google Cloud for the number three spot in the market and to close the gap with Microsoft Azure.\n\n\u2014 Key Questions: How much longer will IBM\u2019s transformation take? Can IOT and AI turn into big differentiators against Amazon, Google and Microsoft? Is IBM being valued correctly considering and investment and growth in the new areas compared to the traditional business?\n\n\u2014 X Growth Factors: Watson is definitely the biggest factors that can influence the immediate growth of the IBM cloud platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/20-key-points-about-ethereum-part-iv-830d068cbde1?source=user_profile---------351----------------",
        "title": "20 Key Points About Ethereum Part IV \u2013 Jesus Rodriguez \u2013",
        "text": "This is the final post on our series of key observations about the Ethereum platforms. Like the previous ones, we are covering a few elements that are often misunderstood about Ethereum. On purpose, we are not trying to provide in depth explanations of any topic but rather highlighted as an point that should be considered for people learning more about Etheruem. Today we cover points 16 to 20:\n\nEthereum supports the execution of smart contracts outside the blockchain. this pattern is based on storing the opscode and data for the contracts in the blockchain while the execution is handle by an outside process.\n\n17-Ethereum is Technology Behind Many BaaS Platforms\n\nMost blockchain as a service(BaaS) stacks such as Bluemix, Azure or AWS are based on or related to Ethereum. From the market perspective, this represents a very strong validation of the capabilities of Ethereum.\n\nThe well-documented DAO heist that took place a few months ago was a major moment for Ethereum. After the incident, the Ethereum community spitted in two and a new project was born: Ethereum Classic.\n\n19-Ethereum is Supported by Different Companies\n\nMost notably, the Ethereum Foundation, EtCore and Consensys. Each of those companies support different components of the Ethereum platform. Other organizations are also taking ownership of new elements of the project.\n\nIn the last few years, Ethereum has nurture a very dynamic developer community. Complementary, Ethereum has been able to establish partnerships with top software companies such as Microsoft, IBM or Amazon as well as system integrators such as Accenture or Infosys. All these developments represent a strong validation of the Ethereum technology and its market.\n\nI hope you enjoyed this series of posts about Ethereum. If you did, feel free to send me or share your feedback."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-key-points-about-ethereum-part-iii-8fa4acaa5a62?source=user_profile---------352----------------",
        "title": "Some Key Points About Ethereum Part III \u2013 Jesus Rodriguez \u2013",
        "text": "Continuing our series about the Ethereum platform, today we will cover some other key points that are often the subject of confusion in the mainstream media. Here are points 11 to 15.\n\nEther is the main digital currency in the Ethereum. However, Ethereum provides the framework and infrastructure to implement and support other currencies. There are even projects that propose and implementation of Bitcoin on top of Ethereum.\n\n12-Ethereum Scripts can\u2019t Access Data or Resources Outside the Blockchain\n\nAllowing that will become a potential compromise in the state of the blockchain. Functionally, Ethereum\u2019s Oracles are the cleanest model to access off-chain data. Oracles is a rapidly growing area of interest within the Ethereum community.\n\nEthereum seamlessly supports private blockchain architectures. To create a private blockchain, you can use the main Ethereum client with a new genesis block and a new network.\n\nIn a private blockchain, the network is protected by traditional methods which undermines the need for currency miners. In those architectures, Ethereum substitutes miners with a concept called validators that are responsible for evaluating the state of the blockchain.\n\nGas is Ethereum concept used to calculate the cost of a transaction in Ether which will be subsequently paid to miners. Each Ethereum transaction has a number of Gas units associated with it which are also used to avoid problems such as infinite loops, dead locks, etc."
    },
    {
        "url": "https://medium.com/@jrodthoughts/20-key-points-about-ethereum-part-ii-e44c0a127b6f?source=user_profile---------353----------------",
        "title": "20 Key Points About Ethereum Part II \u2013 Jesus Rodriguez \u2013",
        "text": "Continuing with the series about Ethereum, today I would like to cover 5 new key capabilities of the blockchain platform. The idea of this series is to present 20 points that highlight important aspects of the Ethereum platform that are often misunderstood. Today we cover points 6 to 10:\n\n6-Ether is the Main Currency of Ethereum but the Platform Supports Others\n\nEther is, essentially, what applications pay for using Ethereum. However, Ethereum supports other digital currencies and provides the framework and infrastructure for building new ones.\n\n7-DAOs are the Main Abstraction that Represent the Owner of One or Many Smart-Contracts\n\nDecentralized, autonomous, organizations (DAO) are abstractions for business entities that own smart contracts and live on the blockchain.\n\nSolidity( based on JavaScript) is the most popular language of Ethereum. However, the platform supports other languages such as Serpent( Python-Like), Mutan(Go-Like) or LLL(Lisp-Like). Similarly, Ethereum provides clients written in 9 other different programming platforms.\n\nOracles are the components of the Ethereum platform responsible for providing or accessing off-chain data required by Smart-Contracts. Oracles can take diverse forms ranging from IOT devices to APIs.\n\nThe Ethereum Virtual Machine(EVM) is what executes decentralized code, Smart-Contracts and DApps as well as any other relevant transaction on the blockchain. Ethereum stores scripts[decentralized code] using a structure called opcodes that are what the EVM ultimately executes.\n\nI hope you found these useful. More to come in the next post\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/20-key-points-about-ethereum-part-i-ae3e7ffcb7ec?source=user_profile---------354----------------",
        "title": "20 Key Points About Ethereum Part I \u2013 Jesus Rodriguez \u2013",
        "text": "Blockchain technologies are rapidly becoming an important trend in the modern technology ecosystem. Within the blockchain space, Ethereum has become one of the most important platforms in just a few years. However, with popularity comes risk. There are many misconceptions about Ethereum and many people/media still associates it with the Bitcoin blockchain. To address some of those misconceptions, I\u2019ve written four articles that summarized 20 of the most important points about Ethereum. Each article covers 5 key points about the platform.\n\nDespite its generic architecture, the Bitcoin blockchain remains as an infrastructure optimized for payments. Ethereum expands the concepts of the blockchain with a modern architecture that enables the implementation of general purpose applications.\n\n2-Ethereum is Based on Three Main Concepts: Smart-Contracts, Decentralized Applications and Decentralized Autonomous Organizations\n\nThere many important concepts in the Ethereum platform but, fundamentally, it focuses on enabling the implementation of descentralized applications [DApps] that exchange digital assets between descentralized autonomous organizations [DAO] using Smart-Contracts. Any Ethereum application can be seen as a combination of those three elements: DApps, DAO and Smart-Contracts.\n\nDecentralized code is code stored in the blockchain. Ethereum scripts are stored and executed in the blockchain and, consequently, replicated across many nodes which makes it extremely hard to tamper them.\n\n4-Ethereum Applications are a Combination of Decentralized Backend with a Centralized Front-end\n\nIts pretty hard to write general purpose applications 100% on the blockchain. Typically, an Ethereum DApp combines descentralized code to enable backend, blockchain-based capabilities combined with user interface delivered using the traditional centralized mechanism of web applications.\n\nSmart Contracts are, arguably, Ethereum\u2019s biggest contribution to the blockchain ecosystem. Conceptually, Smart Contracts are Ethereum Scripts [descentralized code ] that executes based on a condition and exchanges digital assets.\n\nMore to come tomorrow\u2026."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-riiple-r3-deal-and-some-thoughts-about-digital-currencies-19bf85ce542e?source=user_profile---------355----------------",
        "title": "The Riiple:R3 Deal and Some Thoughts About Digital Currencies",
        "text": "Digital currencies continue to achieve relevant milestones. Last week, the digital currency company Ripple and a consortium known as R3 which includes over a dozen of banks announced a partnership to reduce settlements on international payments. The R3 consortium includes household names such as Barclays and BMO which adds a lot of credibility to this effort.\n\nThe trial solution looks to leverage Ripple\u2019s XRP digital currency to avoid or reduce the usage of \u201cnostro-accounts\u201d in international transactions. That type of accounts are typically used to hold foreign exchange assets such as British Pounds in order to settle international transactions. The usage of \u201cnostro-accounts\u201d is widely adopted within the banking community but the process can result very expensive and lengthily. By using Ripple\u2019s XRP, R3 has been able to reuce settlement times and expedite liquidity by a significant order of magnitude.\n\nRipple is a great choice for this type of scenario as its network does not only process XRP but also traditional currencies. The Ripple-R3 pilot is a major milestone for the digital currency space and is also very relevant that the solution is based on a currency other than Bitcoin. The deal also brings some important lessons for the digital currency market.\n\nSome Thought About the Digital Currency Space\n\nThe Ripple-R3 deal has sparked some debate and ideas about digital currencies that I think is worth discussing. Here are some key points:\n\nWe Are Headed Towards a Multi-Digital-Curency World\n\nBy now, it is very obvious that we are transitioning towards a world with multiple digital currencies. A few years ago, it seemed that Bitcoin was going to become the sole dominant digital currency but other alternatives have emerged and capture a meaningful share of the market. As a result, aspects such as digital currency exchange models will become increasingly important in the near future.\n\nIs Not All About the Blockchain\n\nEven though both Ripple and R3 leverage blockchain technologies, the core of the pilot was based on the capabilities of XRP as an foreign exchange asset. The trial represents an important achievement for digital currencies independently of the blockchain infrastructure.\n\nThe Blockchain Will Become Even More Important on a Multi-Digital-Currency World\n\nIn a world with multiple digital currencies, the blockchain will become even more relevant as the underlying network powering most of those digital assets. The blockchain can guarantee interoperability and seamless exchange between many different digital currencies.\n\nDecentralization is one of the key capabilities of digital currencies such as Bitcoin. However, many times people mistakenly associate decentralization with deregulation. The lack of a central authority does not necessarily negate the regulation of a digital currency. as the Ripple-r3 pilot shows, regulation is required to make digital currencies more applicable in mission critical and large scale scenarios for digital money exchanges.\n\nMulti-currency Networks Might be the End Winners\n\nComplementing some of the previous points, networks such as Ethereum and Ripple that can support different digital currencies might be better positioned than single-currency networks like Bitcoin for a multi-currency world. As companies adopt different digital currencies, the consistency of the underlying platform/network will become increasingly important."
    },
    {
        "url": "https://medium.com/@jrodthoughts/serverless-is-the-new-enterprise-lightweight-middleware-3cc32bf7268?source=user_profile---------356----------------",
        "title": "Serverless is the New Enterprise Lightweight Middleware",
        "text": "The idea of lightweight middleware platforms has been a powerful idea in enterprise software for decades. A few years ago, Forrester\u2019s analyst Michael Facemire published a brilliant piece in which he proclaimed that mobile backend as a service(mBaas)could become the next enterprise lightweight middleware. Even though the prediction didn\u2019t turn out correct, Facemire\u2019s ideas expressed in the article remain incredibly valid. A few year after the mBaaS movement, a new technology is seriously positioned to power lightweight middleware capabilities in the enterprise.\n\nServerless computing has become a relevant capability of modern platform as a service(PaaS) stacks. Brought to mainstream adoption by technologies such as AWS Lambda and followed by the releases of competitive stacks such as Google Functions, Bluemix OpenWhisk or Azure Functions, serverles patterns are one of the most popular architecture styles in modern software applications.\n\nFrom an enterprise perspective, many of the most common scenarios for serverless architectures can be expressed as traditional middleware patterns that execute specific integration logic in response to events. From that standpoint, serverles stacks are already playing some middleware role in the enterprise. Differently from previous lightweight middleware pretenders, there are many characteristics of serverless technologies that can help this trend to succeed as a lightweight middleware stack in the enterprise.\n\nTechnology Perspective: 5 Reasons Why Serverless Can Become the Next Lightweight Enterprise Middleware\n\nTechnologically, serverless architectures can, many times, result on a more efficient model to implement enterprise middleware patterns by leveraging some of the following characteristics that contrast with the tradititional heavy enterprise middleware technologies.\n\n\u2014 Developer Friendliness: Serverless stacks are vert veryearn by mainstream developers and rarely require integration specialists.\n\n\u2014 Event-Driven: Serverless architectures are event-driven in nature which makes it easily adaptable to different enterprise middleware scenarios.\n\n\u2014 Extensible: Extensibility (or the lack thereof)is one of the main challenges of traditional middleware solutions. Serverless stacks are highly extensible by definition [they are based on defining new atomic functions that execute via events] which enables the implementation of complex middleware scenascenarios.Multi-Language: Serverless stacks typically support atomic functions written on several different languages. From an enterprise perspective, this capability can streamline the developer adoption of serverless technologies.\n\n\u2014 Hybrid: Serverless architectures can be deployed on-premise and cloud infrastructures which facilitates their adaptability to different enterprise middleware scenarios.\n\nMarket Perspective: 5 Reasons Why Serverless Architectures can Become the Next Lightweight Enterprise Middleware\n\nComplementing the previous section, there are several market elements that favor the adoption of serverless stacks in enterprise middleware scenarios:\n\n\u2014 Driven by Cloud Incumbents: Differently from some of previous attempts to capture the enterprise lightweight middleware space, serverless stacks are mostly driven by cloud incumincumbents as Google, Amazon, Microsoft or IBM which adds strong credibility to the space.\n\n\u2014 Pricing: The pricing of serverless platform is a race to the bottom and this is a factor that can really influence its adoption in the enterprise.\n\n\u2014 IOT: The evolution of IOT middleware scenarios is catalyzing the adoption of serverless stacks in the enterprise.\n\n\u2014 Lack of Innovation in Traditional Middleware Technologies: Recent years have seen very small, incremental innovation in traditional middleware plaplatformsich have kept enterprises looking for innovation. Serverless technologies are certainly a fresh and modern approach in a space that hasn\u2019t seen much movement in the last few years.\n\n\u2014 Talent Availability & Cost of Ownership: Serverless architectures are easily understood by mainstream developers. This is an attractive factor in the enterprise spspeciallyompared with tethexpensive cost of traditional integration engineering talent. Also the cost of ownership and infrastructure required to run serverless solutions is almost neglectable."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-balance-between-nlp-bots-and-privacy-aeb7880f4610?source=user_profile---------357----------------",
        "title": "The Balance Between NLP, Bots and Privacy \u2013 Jesus Rodriguez \u2013",
        "text": "Natural language processing(NLP) and bots are two of the fastest growing trends in the current tech ecosystem. NLP and some of its variations such as natural language understanding(NLU) enable language intelligence in bot platforms making the interactions with users more natural from an anthropological standpoint. While NLP-NLU technologies provide incredible benefits to end users, they also introduce challenges including one that has been at the center of the public debate in recent months: data privacy.\n\nIn order to successfully process natural language constructs, bot platforms need to access the sentences in clear test which prevents any type of encryption techniques. This model contrast with the approach followed by traditional social networks in which the majority of the information is encrypted by default.\n\nThe most concerning part of unencrypted bot communication is precisely the fact that we are dealing with natural language conversations. Entities with access to the dialog data could gather a level of intelligence arguably superior to what\u2019s available today in social networks. Conversational communication elements such as intentions, reasoning, thinking patterns, preferences or feelings at any given time, etc. Mining that information is the equivalent to listening to phone calls, except that the platforms for analyzing text data are available to anybody and they are getting better.\n\nUnprotected communications with bots opens the door to some major risks from the data privacy standpoint. Fundamentally, different brands could have access to large volumes of transcripts of conversations with its users which opens to door for some complicated scenarios:\n\n\u2014 Government Subpoenas: If a person is the target os a criminal investigation, the goverment could request access to his conversations with different bots. This problem is very similar to what the bit internet email providers are facing today, except that the information might be richer, delivered in near real time and clearly communicating aspects such as intention, etc.\n\n\u2014 Hackers: Not much explanation is needed here. If malicious actors hack into a bot, they could have access to very valuable information about its users. A good ananalogy might be the recent situation Yahoo is facing in regards to the hacking of email accounts.\n\n\u2014 Abusive Advertisement: When comes to bots and privacy we need toassumet that some brands will cross the privacy line and share user and conversation information with potential advertisers.\n\n\u2014 Government Surveillance: The surveillance programs of goverment agencies such as the NSA or GCHQ in domestic territories have been the center of heated debates in the highest political circles. Without taking sides on those debates, we shoulassumeme that unencrypted bot communications could open the door to similar types of surveillance.\n\nThe data privacy debate in bot technology is really complex and I don\u2019t pretend to have ansolutionsos. However, based on the lessons learned with previous technologies, I believe some of the following ideas might be worth considering:\n\n\u2014 Legislation: At some pointgovernmentsts might have to pass legislation that regulates the nature of encrypted bot communications.\n\n\u2014 Secure Backups: Bot providers should enable mechanisms tsecurelyly backup user conversations and only retain metadata associated with it.\n\n-Switching Between Encrypted anUnencrypteded Modes: Bot platform should provide seamless mechanisms to turn encryption communication on/off depending of the context of the conversation."
    },
    {
        "url": "https://medium.com/@jrodthoughts/financial-institutions-are-leading-the-adoption-of-the-blockchain-who-will-follow-a26bb68c4622?source=user_profile---------358----------------",
        "title": "Financial Institutions are Leading the Adoption of the Blockchain. Who will Follow?",
        "text": "Banks and other financial institutions continue to spread love for blockchain technologies. Last week, Dubai\u2019s largest bank, Emirates NBD announced that is working with India\u2019s ICICI on a blockchain pilot for global remittances and trade finance which will target banks in the Middle East and India. The initial results of the pilot are showing significant improvements on the transaction times while also enabling near real time transfer of invoices and purchase orders fro trade finance purposes.\n\nEmirate NBD\u2019s announcement is the latest on a series of developments highlighting how financial institutions have been adopting blockchain technologies. In recent weeks, banks such as J.P.Morgan, Citi Group, Credit Suisse and others have announced different blockchain solutions. Similarly, Bank of America recently announced that is partnering with Microsoft to build a blockchain-based framework that can be adopted by other financial institutions.\n\nWhile the news of banks adopting blockchain platform is encouraging, they certainly contrast with the limited adoption of those technologies in other industries. Finance institutions are natural adopters of blockchain technologies because they were exponsed very early to the capabilities of Bitcoin. However, we should expect other industries to catch up soon:\n\nWhat are the Ideal Scenarios for Early Blockchain Solutions in the Enterprise?\n\nThere is no question about the tremendous potential of blockchain solutions across different industries. However, the initial development of blockchain pilots by financial institutions have surfaced some key characteristics of the scenarios that can be ideal early adopters of blockchain solutions. Let\u2019s explore a few of those characteristics.\n\n\u2014 Mission Critical: Adopting a new and immature technologies like the blockchain requires real commitment from customers. Typically, that level of commitment is directly proportional to the criticality of the business solution being delivered. By focusing on mission critical scenarios such as trade settlement, the financial industry has made significant progress in the adoption of blockchain technologies. Eventually, the industry will mature and blockchain solutions will expand to mainstream scenarios but, at the moment, blockchain startups and technology providers will be better served by focusing on mission critical scenarios that will drive the attention of enterprises.\n\n\u2014 Exchange of Financial Assets: Many of the pilot scenarios for blockchain solutions in the financial industry included the exchange of financial assets. This is one of the key capabilities of blockchain platforms and one that is applicable to solutions in other industries.\n\n\u2014 Visibility: The initial blockchain pilots in the financial industry have also focused on enabling visibility on complicated business processes across different business parties or regulatory entities. An example of this could be J.P.Morgan project Quorum that is planning on offering trading data to regulators via Ethereum. These type of scenarios are very relevant in other industries.\n\nWhat Industries are Likely to be the Next Big Adopter of Blockchain Solutions?\n\nBased on the lessons learned and the unique characteristics of the scenarios for the first wave of blockchain solutions in the finance industry, we can start speculating about the next industries to go big into the blockchain space. Here are a few ideas:\n\n\u2014 Supply Chain: Visibility and verification are some of the main challenges in mission-critical supply-chain processes that an be affress by blockchain platforms.\n\n\u2014 Insurance: Many business processes in the insurance industry have a strong asset-exchange component that resemble the blockchain scenarios implemented by the big banks. As a result, the insurance industry can also be a strong early adopter of blockchain technologies.\n\n\u2014 Pharmaceutical: Offering regulators to have visibility into pharmaceutical processes is one of the mission-critical solutions that can be enabled by the blockchain in the pharmaceutical industry.\n\nThere are many industries that can immediately benefit from the adoption of blockchain platforms. However, in this early stages, it is very important to focus on the scenarios and vertical that can drive immediate business value and consolidate the position of the blockchain as a technology that can enable a new wave of innovation in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/modal-vr-and-the-some-ideas-for-enterprise-vr-space-257ad97ab95e?source=user_profile---------359----------------",
        "title": "Modal VR and the Some Ideas for Enterprise VR Space",
        "text": "Modal VR is a new virtual reality(VR) platform launched by the creator of Atari Nolan Bushnell. differently from other VR initiatives, Modal VR is focused on enabling immersive experiences for enterprises. Even though the vast majority of VR efforts have been targeted to the consumer market, the enterprise remains as an area with real potential.\n\nThe Modal VR platform enables businesses to setup new VR experiences that are life-size and life-scale. Enterprise can use the platform to create their own VR experiences to visualize, plan, train and collaborate with each other. Nolan\u2019s VR brainchild platform includes both hardware and software components.\n\nBeyond the excitement of the release of a new VR platform, Modal VR introduces some concepts such as application distribution and collaboration which should become incredibly relevant in the enterprise VR space. As mentioned in previous posts, VR has the potential of driving a new wave of user experience in the enterprise but the platforms and applications are still in very early stages. At this point, the market is still trying to figure out what will be the relevant capabilities of an enterprise VR solution.\n\nEnabling VR experiences at an enterprise scale will require some foundational building blocks that are not necessarily relevant in the consumer VR market. While consumer VR is mostly focused on creating great immersive experiences, enterprise VR solutions might require some additional capabilities in areas such as analytics, distribution, security and many other relevant elements of enterprise solutions. Even though enterprise VR solutions are in very early stages, platforms such as Modal VR have shed some light into capabilities that are likely to become relevant in the enterprise.\n\nUnderstanding that some of these ideas are pure speculation, I\u2019ve listed a few concepts that I believe could become relevant for enterprise VR solutions and how they related to well know enterprise companies.\n\nGreat VR content authoring tools and platforms will be key element for the adoption of VR technologies in the enterprise. Many VR business solutions will require domain experts in areas such as marketing or training to continuously create content that can be used in immersive experiences.\n\nAn efficient VR application distribution model can enable organizations to engage with customers, partners and employees in a more consistent manner. The app store metaphor can very well be applicable in the VR space.\n\nFor enterprise, managing and securing VR hardware can become a key requirement for the implementation of immersive experience solutions. If we assume that large enterprises will live in a world in which employees will use different types of VR hardware, providing a consistent infrastructure for managing and securing those devices could become a serious challenge.\n\nMeasuring relevant metrics that describe user and application behaviors in VR application is another concept relevant to the enterprise VR world. Just like in web and mobile solutions, metrics such as user engagement, application downloads, active users and many others will be very relevant in the enterprise VR space.\n\nContent privacy , access control or threat analysis are some of the security factors that are likely to be considered for enterprises adopting VR experiences. Just like other enterprise software trends, security will play a very important role in the adoption of VR in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/can-ai-redefine-software-testing-30e29be53e8c?source=user_profile---------360----------------",
        "title": "Can AI Redefine Software Testing? \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) is redefining the software industry as we know it. From improving the intelligence of mainstream technologies such as databases to driving new technology trends such as bots, AI is becoming a foundational piece of the new generation of software technologies. One area that I am particularly intrigued about the potential of AI is software testing.\n\nIf we oversimplify our view of the software building process, we can identify two main groups: creation and testing. From those two groups, I believe the current stage of AI technologies have the opportunity to drastically improve software testing and make it more intelligent. From the AI standpoint, software creation require capabilities such as creativity, intuition or imagination that are still in very early stages in AI technologies. Software testing, however, is mostly driven by th ecreation adn execution of data driven rules. That\u2019s precisely the type of scenarios that can immediately benefit from AI technologies in its current form.\n\nIf we try to dissect software testing processes today, we can argue that is hasn\u2019t changed tremendously in the last 20 years. Despite the rapid changes in software technology, the software testing methodologies haven\u2019t evolved that much.\n\nFrom a conceptual standpoint, software testing processes are based on defining a set of rules that validate well-known uses cases on a specific software solutions. I know I am oversimplifying a bit but almost every testing methodology can be modeled as a variation of that approach. The introduction of AI as a complement of a test engineer can bring some interesting benefits to those processes.\n\nSoftware testing stacks can leverage AI to create new test cases based on an initial set of observations about the runtime behavior of the software. In this approach, testers will train AI algorithms on the expected behavior of a software solution based on an initial set of tests and runtime data points. After that, AI testing algorithms can leverage runtime information to formulate new test cases that better resemble the production behavior of the software.\n\nChaos Monkey is a very popular testing methodology that causes random failures in a software system. AI technologies can improve chaos monkey models by understanding the data describing the runtime behavior of the different components of a software as well as the hidden dependencies between them.\n\nSimulation takes several AI concepts applied to software testing to a complete different level. Using AI technologies, we could create simulation models that represent the future runtime behavior of a software system based on a well defined set of scenarios.\n\nThe objective of software testing is to validate the behavior of a software solution using a well-known set of rules [test cases]. AI can use the results of tests to not only validate the functioning of a software but also gather insights and understanding about the current state of a software solution. By gaining that level of intelligent, an AI testing stack could accurately predict conditions that will cause failures in the software and recommend appropriate solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/serverless-in-the-enterprise-f9fc32a1c6fe?source=user_profile---------361----------------",
        "title": "Serverless in the Enterprise \u2013 Jesus Rodriguez \u2013",
        "text": "I\u2019ve been writing about serverless architectures for the last few months. In a previous post, we explored how the serverless model is becoming one of the fastest growing components of Platform as a Service(PaaS) stacks. From a growth perspective, the vast majority of the early adoption of serverless architectures have taken place in the consumer market in areas such as faming, wearable\u2019s technologies, etc. However, in the near future, we should expect that balance to change as the enterprise becomes a major adopter of serverless technologies.\n\nTraditionally, it has been hard to benchmark the market potential of a specific architecture style (vs. a technology) but in the case of serverless architectures the opportunities within the enterprise are clearly tremendous. From some perspectives, serverless computing represents the answer to challenges that have plagued enterprise solutions and IT departments for the last two decades.\n\nWe are still in the early days of the adoption of serverless architecture models and trying to enumerate the benefits of this trend in the enterprise might seem premature. However, if we look deeper at the adoption serverless computing technologies within the consumer market, we should be able to extrapolate some clear benefits for the enterprise. Let\u2019s explore a few of those ideas:\n\nServerless architectures provide an open, developer-friendly model for building event driven solutions. The even driven paradigm has been one of the most popular architecture styles in the enterprise but it has proven to be challenging for most organizations to implement it at scale.\n\nServerless computing models offer enterprises a model of leveraging multiple programming languages in an application while maintaining certain level of consistency in aspects such as lifecycle management, monitoring, scalability, testing, etc. Traditionally, enterprises have struggled adopting different programming languages because they require investments on different types of infrastructure and engineering talent.\n\nDevelopers in enterprise environments are painfully aware of the infrastructure requirements of their applications. Even when using cloud platforms, IT developers need to request the appropriate infrastructure to run their applications. Serverless architectures provide a model that truly abstracts the infrastructure requirements from the application code.\n\nCode reusability has been an elusive goal for most enterprises. Serverless architectures enable reusability at the core of the platform. A developer writing a serverless application can simply browse the available serverless functions relevant to the application domain and start using them. As a side effect, serveless architectures provide a simpler mechanism for onboarding engineers and make them immediately productive.\n\nAchieving certainly level of architecture symmetry between cloud and on-premise solutions is a permanent goal of most IT departments. However, most cloud technologies have no on-premise equivalent. Serverless architectures fundamentally rely on the authoring of atomic functions which enables a very viable model for on-premise reusability. Additionally, serverless stacks such as Azure Functions or Bluemix OpenWhisk should be available as part of Microsoft\u2019s and IBM\u2019s private cloud technologies respectively."
    },
    {
        "url": "https://medium.com/@jrodthoughts/these-technologies-can-become-the-next-open-source-success-in-the-enterprise-73bc56f7fa95?source=user_profile---------362----------------",
        "title": "These Technologies can Become the Next Open Source Success in the Enterprise",
        "text": "Open source has had a long love-hate relationship withthe enterprise. Often ignored in favor of closed-source commercial products, open source technologies have come a long way to become universally accepted in the enterprise space.\n\nDespite the challenges over the years, some open source projects have been incredibly sucessful in the enterprise and have created impressive wealth along the way. From early successes such as Redhat or JBoss to the recent triumps of big data distributions such as Cloudera or Hortonworks there are plenty of examples of open source successes in the enterprise. The pattern is relatively consistent: when an open source project becomes highly popular, it creates an opportunity to attract corporate clients by offering more sophisticated management tools, enterprise support models, professional services focused on setup and implementation, SLAs, security capabilities among many other requirement relevant to enterprise applications.\n\nThe open source pattern in the enterprise have been repeated many times over the last few decades and it seems like a well accepted recipe for success. Thinking around those lines and looking at the current state of the technology market, there are several projects that might attract venture capitalists and startups looking to build the next big open source success in the enterprise. Let\u2019s explore a few:\n\nArtificial intelligence(AI) is going to rule the next few years of enterprise software but its adoption in the enterprise remains relatively small compared to the consumer market. Popular open source AI projects such as TensorFlow, Torch of Caffe have developed impressive communities of hundreds of thousands of developers but very few enterprise clients. An enterprise distribution of those frameworks with the corresponding management-security tools and implementation services can be very well received in the enterprise.\n\nMany of you might be surprised to see NodeJS in this list. However, its inclusion is well justified as many enterprises are just now starting pilots of NodeJS solutions. However, the number of NodeJS enterprise distributions remains relatively small. IBM\u2019s Strongloopis certainly a solid NodeJS enterprise framework but the market could use a few more competitors.\n\nThe number of sucessful open source microservices technologies released in the last few years is nothing but remarkable. While infrastructure components of microservices stacks such as Docker have made solid inroad in the enterprise, higher level capabilities of microservices solutions such as the ones enabled by the Netflix OSS project remain relatively unknown in the enterprise. An open source, microservices stack that combines some of the technologies released by companies such as Netflix, LinkedIn, Facebook, Twitter or many other of the big internet vendors could be a winner in the enterprise. Frameworks such as Spring Cloud or Lagom have been making progress in that area but the window of opportunity remains pretty much open.\n\nWe keep discussing how the blockchain can be one of the greatest trends in enterprise software but without solid enterprise distributions is hard to envision how we will get passed this early adopter phase. Ethereum is by far the front runner in terms of blockchain platforms but it can still use some help to penetrate the enterprise. An Ethereum distribution that includes new management, security and monitoring tools as well as the corresponding implementatation and support services could also be the missing bridge to get enterprises to adopt blockchain technologies."
    },
    {
        "url": "https://medium.com/@jrodthoughts/cross-platform-opportunities-for-bots-22fac2b0c2ea?source=user_profile---------363----------------",
        "title": "Cross Platform Opportunities for Bots \u2013 Jesus Rodriguez \u2013",
        "text": "Bot platforms are rapidly proliferating in the technology ecosystem. In the past, I\u2019ve written about the increasing fragmentation in the bot platform space and how it could become a problem for the market. From bot platforms delivered by messaging platforms such as Facebook or Slack(Botkit) to cross-platform bot development frameworks such as Microsoft\u2019s Bot Framework, Howdy or Dexter, bot development technologies are emerging everywhere making it hard for developers and organizations to select a single platform for their efforts.\n\nLike its mobile and web market predecessors, the large number of bot platforms creates new opportunities for cross-platform frameworks in different areas. Technologies such as Google Analytics or MixPanel in the analytics space or IF-THIS-THEN-THAT in the integration area have established themselves as cross-platform solutions for mobile and web applications. The current fragmentation in the bot space, creates an opening for venture capitalists and startups looking to build the next generation of cross platform capabilities in areas such as security, analytics or testing applied to the bot market.\n\nThere are several market opportunities for cross platform technologies in the bot space. Extrapolating lessons from the mobile and web ecosystems, there are a few areas that offer immediate opportunities to enable cross-platform capabilities in an already fragmented bot ecosystem.\n\nAnalytics is one of the massive areas of opportunity in the bot market. Functionally, cross-platform bot analytic frameworks should extract metrics and intelligence from natural language interactions. A robust cross-platform bot analytic solutions can also become the key to unlock new markets such as advertisement in the bot space.\n\nA/B Testing is another cross-platform area that is experiencing some serious challenges in the bot technology ecosystem. A cross-platform bot A/B testing framework that validates the effectiveness of new features or natural language commands should become a strong addition to the current bot market.\n\nManaging the lifecycle of content used by bots across different messaging platforms is another are of opportunity in the bot market. Similarly to the web and mobile content management systems(CMS), a bot content management solution should control the lifecycle and process of content that will be delivered as a response to specific natural language commands. Additionally, a bot CMS should be responsible for formatting the content based on the capabilities of specific messaging platforms.\n\nNatural language integration(NLI) is a fairly new field. In the context of bot platforms, an NLI framework should enable the communication with line of business systems and other services using natural language sentences. This type of framework can enable consistency in the integration interfaces across different bot platforms.\n\nBot models bring new challenges from the security standpoint. From data privacy, access controls or detecting new threats, security should be a foundational component of bot development frameworks. The current market offers new opportunities for a cross-platform bot framework that enables consistent security models across different bot platforms."
    },
    {
        "url": "https://medium.com/@jrodthoughts/mobile-vr-could-deliver-the-killer-app-for-the-enterprise-b71c03cb37e?source=user_profile---------364----------------",
        "title": "Mobile VR Could Deliver the Killer App for the Enterprise",
        "text": "Virtual Reality(VR) has been a hot topic in the news recently. From the announcement of Google\u2019s Daydream platform to the Oculuc Connect conference, there have been plenty of excitement in the VR in the last few days. Lile many other ground breaking technologies, the early adoption cycles in VR have been focused on the consumer market while the enterprise have remained observant but cautious about embracing this new technology.\n\nIf we use traditional enterprise software market models as a reference, there is a strong posibility that the initial adoption of VR technologies in the enterprise might not be driven by high-end PC-based VR headsets such as the Oculus Rift or Microsoft Hololens but by mobile VR hardware like the Samsung Gear or Google Daydream.\n\nThe opportunities for VR in the enterprise are tremendous. From basic scenarios like virtual travel to complex training and simulation in industries such as public safety or defense, VR can drive the next user experience revolution in the enterprise. However, more than one killer app might be needed to launch the VR era in the enterprise and mobile VR might be the best opportunities to produce those initial winners.\n\nPC-VR vs. Mobile-VR in the Enterprise\n\nIn order to anallyze/predict the adoption of VR technologies in the enterprise, it might be helpful to make a distinction between the scenarios for PC-VR and mobile-VR solutions.\n\nPC-VR solutions in the enterprise will be delivered by high-end headsets such as the Oculus Rift or Microsoft Hololens. Eventually, those enterprise experiences will transition to standalone VR headsets [no PC required] such as the upcoming Oculu s Santa Cruz.\n\nConsidering the high price point and the complexity on the setup of PC-VR solutions, the initial adoption in the enterprise might focus on scenarios with snall number of users that can drive value from a full VR experience. Some of the following might be a good fit for PC-VR experiences:\n\n\u2014 Trade Shows: VR can enable a new level of digital user experience demonstrating products in trade shows and conferences.\n\n\u2014 Retail Stores Industries like fashion can leverage PC-VR experiences to attract customers in the stores.\n\n\u2014 Training: Expensive and dangerous training in industries such as defense, public safety or healthcare can be simplified by leveraging PC-VR experiences.\n\nContrary to the Pc-VR experiences, enterprise mobile VR solutions are better suited for scenarios with large user bases that might not necessarily require a full VR experience. Here are some ideas of those scenarios:\n\n\u2014 Education: Mobile-VR is a great solution for improving digital experiences in the education space.\n\n\u2014 Content Marketing: Mobile-VR allow brands to connect with users in a completely new experiences.\n\n\u2014 Enterprise Collaboration: Mobile-VR can enable new collaboration experiences in the workplace.\n\nMobile-VR can Win First in the Enterprise\n\nUnderstanding the difference scenarios for PC-VR and Mobile-VR in the enterprise, we can start theorizing about the possible paths for the adoption of these technologies. For venture capitalists and startups focused on enterprise VR solutions, Mobile-VR offers the best opportunities to deliver an early winner solution. Despite the user experience benefits of PC-VR solutions, Mobile-VR offers a few advantages that can result key in its adoption in the enterprise.\n\n\u2014 Pricing: Mobile-VR solutions are really affordable compared to PC-VR hardware.\n\n\u2014 Users: Technologies such as Samsung Gear VR already claims over a million active users which makes Mobile-VR a more effective vehicle to reach mainstream users.\n\n\u2014 Developers: Mobile developers should be able to easily transition into Mobile-VR technologies which can become an important talent asset in the enterprise.\n\n\u2014 Distribution: Mobile-VR can take advantage of mainstream app distribution channels like app stores which are regularly used by enterprise users."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-is-becoming-an-ai-first-company-52056b9100d6?source=user_profile---------365----------------",
        "title": "Microsoft is Becoming an AI-First Company \u2013 Jesus Rodriguez \u2013",
        "text": "Microsoft\u2019s transformation in the last few years has been nothing but remarkable. Under Satya Nadella, the Redmon giant has regained its momentum as one of the lead innovators in new technoogy markets such as virtual reality, internet or things or artificial intelligence(AI). Nadella\u2019s famous slogan of Microsoft becoming a \u201ccloud-first, mobile-first company\u201d guided Microsoft\u2019s strategy in recent years. However, Microsoft\u2019 has been slowly shifting its attention to a new and ambitious goal of becoming an AI-First company.\n\nNot a week goes by in which we don\u2019t hear about another important AI initiative by Microsoft. A new AI foundation, the release of an AI-First testing tool or a corporate reorg to improve the focus on AI technologies have been some of the highlights of recent weeks. Let\u2019s do a quick recap:\n\n\u2014 Project Springfield: Under the radar, Microsoft announced the release of Project Springfield. Incubated by Microsoft Research, Project Springfield is a cloud service optimized for \u201cwhite fox buzz testing\u201dthat uses AI to generate different inputs to a software in order to uncover vulnerabilities or induce failures.\n\n\u2014 New AI and Research Group: Recently, Microsoft announced the creation of a new division that combines Microsoft Research and more than 500 engineers working on AI technologies at the company. The goal of of the new group is to improve the collaboration between research and engineering on Microsoft AI products.\n\n\u2014 New Partnership on AI: Together with Facebook, Google, IBM and Amazon; Microsoft announced the Partnership on AI, a new foundation to advance AI research as well as to improve the regulatory environment around it.\n\nThese are just some of the most recent headlines on Microsoft\u2019s AI strategy. While the race in the AI technology market is intensifying with companies such as Facebook, Google, IBM or Amazon as well as dozens of AI startups, Microsoft has some very unique assets that can result in a competitive advantage in the space.\n\nFive Key Assets of an AI-First Microsoft\n\nBy incorporating Cortana an dother AI technologies, Windows is starting a transition towards becoming an AI-First OS. The widespread adoption of Windows in the enteprrise can result on a very unique distribution channel for Microsoft\u2019s AI technologies.\n\nThe release of cloud services such as Azure Machine Learning(ML), Microsoft Cognitive Services or even the recently announced Project Springfield are examples of Azure\u2019s transformation towards an AI-First cloud platform. While Microsoft is facing strong competition from PaaS providers such as Google, Amazon and IBM, it has already managed to achieved meaninful traction in the space.\n\nOffice 365 and other SaaS products such as CRM Online has been steadily incorporating AI capabilities. With companies like Salesforce entering the AI-First SaaS race, we can expect Microsoft to become more active and competitive in this market.\n\nLanguage translation, bots and natural language processing(NLP) are some of hte recnet AI capabilities added to Skype. the popularity of Skype as well as its global user base can become a unique distribution channel for Microsoft\u2019s AI technologies.\n\nIf Microsoft is able to complete its acquisition of LinkedIn, it will add several very sophisticated AI and data intelligence capabilities to its technology portfolio. Recently, LinkedIn has been aggressively investing on AI technologies in areas such as messaging, recruiting and sales tools."
    },
    {
        "url": "https://medium.com/@jrodthoughts/is-healthcare-the-next-ai-battleground-25bf46cae5b4?source=user_profile---------366----------------",
        "title": "Is Healthcare the Next AI Battleground \u2013 Jesus Rodriguez \u2013",
        "text": "On Sunday, 60 Minutes dedicated half of its program to discuss the rapid evolution of artificial intelligence(AI). Most of the interviews and case studies presented were related to the health care industry which clearly illustrates how that industry is becoming one of the key areas of focus for AI technologies.\n\nVertical solutions are called to pay a pivotal role in the next phase of AI. While the initial phase of the AI market has been centered on general purpose platforms, the focus has been slowly shifting towards industry-specific solutions. Among those industries, healthcare has been a very early adopter of AI technologies and has helped to push the innovation in the space.\n\nIn recent weeks, we\u2019ve seen announcements from IBM and Google about large investments to leverage their Watson and DeepMind technologies respectively to assist oncologists and researches in the fight against cancer. For obvious reason, curing cancer is a very high profile healthcare problem which is likely to attract many headlines. However, the healthcare industry is full of challenging scenarios that can immediately benefit from AI and cognitive computing techniques. From improving medical research to optimizing diagnosis, AI can play a pivotal role in the next phase of medical technology solutions.\n\nWhat Makes Healthcare An Exciting Market for AI Platforms?\n\nThere are a few factors that make healthcare a prototypical market for many AI capabilities. Let\u2019s explore a few ideas:\n\nMost of healthcare data can be considered \u201cblack data\u201d in the sense that it can\u2019t be easily analyzed. There is a world of knowledge accumulated in physician notes, images, voice, session recordings and many other data sources that are incredibly hard to analyze using traditional BI methods. AI algorithms that can process text, speech, audio and vision can be very effective extracting knowledge from these data sources.\n\nModern AI platforms already have the capability of learning from the knowledge of top experts on a specific medical field. That knowledge is typically accumulated in the form publications in medical journals or in historical diagnosis records. Using Training AI algorithms to acquire that knowledge and applying to combining it with Doctor\u2019s expertise can drastically improve the effectiveness of a specific diagnosis techniques.\n\nModern medical research leverage vast amounts of data from heterogeneous data sources. In many scenarios, the empirical analysis techniques used by traditional BI platforms is simply insufficient to have an impact in medical research processes. AI models can exponentially increase the levels of intelligence obtained from those data sources that can directly be applied to medical research initiatives.\n\nWe are entering the golden era of medical device technology. These days, patients can have small devices implanted in their bodies that are constantly gathering data relevant to specific set of medical conditions. While these devices are mostly use as data recorders today they will soon incorporate AI techniques to intelligently interpret the collected data and make appropriate decisions based on the training provided by experts on that medical field. From that perspective, AI will act as a sort of bridge between digital data and human knowledge."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ai-foundations-are-the-latest-tech-fashion-f71339fca8fd?source=user_profile---------367----------------",
        "title": "AI Foundations are the Latest Tech Fashion \u2013 Jesus Rodriguez \u2013",
        "text": "Last week a team of rivals got together to announce a new foundation for artificial intelligence(AI). Amazon, Facebook, Microsoft, Google and IBM announced the creation of a nonprofit organization called \u201cPartnership of Artificial Intelligence to Benefit People and Society\u201d or \u201cPartnership on AI\u201d for normal people :) . The new foundation will be focused on \u201cadvance the public understanding of artificial intelligence\u201d, conduct research and recommend best practices related to \u201cethics, fairness and interoperability, collaboration between people and AI systems\u201d. The nonprofit also makes it clear that it does not intend to play an active role lobbying governments or policy making bodies.\n\nThe fundamental objective behind the Partnership on AI is to address some of the main challenges and concerns with the adoption of AI technologies and bring together the top commercial vendors in the space. The organization will be led by a board composed or representatives from the AI initiatives in the software giants as well as members of the academic community.\n\nThe creation of a nonprofit organization such as the Partnership on AI is an important step to mitigate some of the concerns the public and governments have expressed with the rapid raise of AI technologies. A few months ago, Elon Musk, Sam Altman and other leaders of the technology industry founded the OpenAI foundation based on similar goals. Ironically, one of the main objectives behind OpenAI was to prevent that advanced AI technologies were controlled by a handful of giant software companies (go figure).\n\nIn the past, I\u2019ve written about the impressive progress made by OpenAI in areas such as reinforcement learning. The very well-funded nonprofit has been using its initial capital to attract some of the top minds in the AI research space and help them to advance some of their ideas without any links to commercial interests. From that perspective, we can\u2019t avoid but wonder if the Partnership on AI is really needed or if Microsoft, IBM, Google, Amazon and Facebook should have tried to merge their efforts with the OpenAI foundation.\n\nTaking into consideration that we are going to live in a world with multiple AI foundations pushing different agendas, I was thinking about some of the key principles and objectives that [beyond the trivial ones] should be shared among those organizations. Here are a few ideas:\n\n\u2014 Advance AI Research: Everybody agrees on this one. Advancing AI research should be the main goal of any AI non profit organization.\n\n\u2014 Open Source New AI Tools and Frameworks: In addition to conducting research, an AI foundation should commit to open source frameworks and tools that validation that research and that can be incorporated into other technology stacks. OpenAI has been doing a remarkable job in that regard with solutions like the OpenAI Gym.\n\n\u2014 Work with Government Agencies on the Right Policy Framework for AI Solutions: I feel that AI is one of those areas in which goverment and the tech industry should collaborate closely and continuously to create the appropriate regulatory environment and avoid unpleasant surprises.\n\n\u2014 Validate AI Stacks on Aspects Like Ethics or Trustworthiness: An AI foundation could be an ideal body to conduct periodic tests that validate different AI technology stacks in relevant areas such as ethics, transparency, privacy, trustworthiness among other aspects that could be a concern in this emerging technology space.\n\n\u2014 Standards and Interoperability: I know this will be really hard to enforce but I still feel there are areas within AI that can benefit from certain level of compliance with industry standards and interoperability. Some examples might include areas such as message exchange protocols [between nodes in a AI graph] or neural network models. An AI foundation could play a key role driving the creation and validation of those standards."
    },
    {
        "url": "https://medium.com/@jrodthoughts/imagining-a-multi-platform-bot-development-framework-1be4b93f6aaf?source=user_profile---------368----------------",
        "title": "Imagining a Multi-Platform Bot Development Framework",
        "text": "Dexter, the Betaworks incubated self-service integration platform, recently shifted its focus to become a bot development platform and announced a new round of funding. When reading the news a few weeks ago, it made me think about the viability of cross-platforms bot development technologies as a market for startups.\n\nIn the past, I\u2019ve written extensively about the challenges that the bot market poses for startups. A market in which the incumbent messaging platforms control not only the runtime but the distribution and monetization channles is certainly a difficult environment for startups to blossom. Having said that, the idea of a robust cross-platform bot development framework is certainly an interesting one.\n\nWhen we talk about cross-platform software development frameworks, we automatically go back to the mobile space. After its acquisition by Microsoft, Xamarin resulted the big winner in the mobile cross-platform development space in which technologies like Reach Native also managed to develop an impressive level of traction. However, with some of those exceptions, most of the mobile cross-platform stacks failed to developed into meaninful companies. From that perspective,there are a few lessons that might be applicable to the bot market.\n\nThe bot space presents some very tangible differences-challenges with the cross-platform mobile market that are relevant that should be considered when evaluating the viability of a cross-platform bot development stack. For starters, the number of messaging runtime is a multiples higher compared to the number of mobile OS plaforms. That difference translates into a richer and larger number of distribution channels, management tools and monetization models that need to be included in bot solutions which can result on a nightmare for developers. A cross-platform bot development framework, that alliviates these challenges could certainly be welcomed in the market.\n\nLike the previous example, there are a few ideas that might work in a bot development platform. Let\u2019s explore a few:\n\n\u2014 Shared Business Logic \u2014 Different UI:One of the challenges in the bot market is the UI-UX differences between the different messaging platforms. Taking a page out of Xamarin\u2019s book, a model that allow developers to tailor the user experience to the different bot platforms while reusing the business logic might be a clever approach to tackle this challenge.\n\n\u2014 Support for Different Programming Languages: Supporting different programming languages for implementing cross-platform bot solutions could be a strategy to build a strong developer community. Developing a multi-language platform for bots is exponentially easier compared to the mobile space.\n\n\u2014 Support for Different NLP Stacks: Imagine that you are developing a bot and you are able to choose between different natural language processing(NLP) stacks such as Watson, Wit.ai, Microsoft Cognitive Services or Google NLP. That model will offer developers the flexibility to leverage the top NLP stacks on the market into their bot solution instead of be tied to a single one.\n\n\u2014 Cross-Platform Analytics and Management: Providing a uniform platform and tools to track analytics across the different bot runtimes as wel as consolidating the management experience can also be an interesting idea for a cross-platform bot development framework."
    },
    {
        "url": "https://medium.com/@jrodthoughts/j-p-morgan-project-quorum-loves-the-public-blockchain-f764c56824f7?source=user_profile---------369----------------",
        "title": "J.P.Morgan Project Quorum Loves the Public Blockchain",
        "text": "For years, J.P.Morgan\u2019s CEO Jamie Dimon has been one of the most vocal critics of Bitcoin. However, that position doesn\u2019t seem to have prevented him from betting big on the technology underneath Bitcoin: the blockchain. More impressively, J.P.Morgan seems to really like PUBLIC BLOCKCHAINS. This week, J.P.Morgan announced a new project called Quorum that relies on the public Ethereum network to share information relevant to regulators and other entities involved in a trade.\n\nApparently, J.P.Morgan\u2019s engineers have been working with Ethereum to create a model that allow to restrict access to information stored in the Ethereum blockchain to a number of relevant parties. This approach contrasts with the models followed by other banks which have been increasingly relying on private or consortium blockchains. Just a few days ago (I blogged about it here), a group of banks led by Citi announced that they have been piloting a consortium blockchain architecture for sharing reference data related to trades.\n\nJ.P.Morgan\u2019s Quorum represents a huge vote of confidence on the Ethereum platform. This is the same blockchain network that experienced the DAO hack a few months ago which resulted in losses of about $55 million. By leveraging Ethereum, J.P.Morgan\u2019s Quorum is delivering one of the first mission critical applications in a heavily regulated industry to ever run on a public blockchain.\n\nThe key to Project Quorum seems to be a security model developed to J.P.Morgan\u2019s engineers that restricts access to blockchain data to group of relevant parties. Needles to say that Bitcoin-Blockchain purists will find this idea outrageous as it negates some of the fundamental transparency principles of the public blockchain.\n\nDespite the theoretical arguments. the Quorum\u2019s strategy might be the best alternative to the proliferation of private blockchain models. Assuming that information privacy is an issue that needs to be addressed for the mainstream adoption of the blockchain, then the industry needs to decide which model is more acceptable: private blockchains or private sections in public blockchains?\n\nJ.P.Morgan seems committed to be a good citizen of the blockchain community and announced that it will open source parts of Quorum\u2019s technology. This step will not only help with the transparency of the project but, if successful, will provide a stepping stone for other companies to use the Quorum technology as part of their projects.\n\nThe fact that I found most interesting in the strategy followed by the Quorum project is that it avoid bringing to market another private blockchain for trade settlements. I personally believe that the consortium blockchain model makes a lot of sense for trade settlements but the \u201cconsortium\u201d needs to exist. If every banks comes up with their own blockchain solution for trade settlement without following any standards or interoperability tests, we might end up in a situation not much different that the current state of the market.\n\nEthereum Continues to be the Best Alternative to the Bitcoin Blockchain\n\nJ.P.Morgan\u2019s Quorum is a strong validation for the Ethereum platform that continues achieving milestones to become the best blockchain platform in the market. With all the recent challenges expressed by the Bitcoin blockchain, Ethereum has become the favorite platform for enterprises exploring solutions that rely on public blockchain models."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ibm-bets-big-on-watson-verticals-with-the-acquisition-of-promontory-73522efea1f1?source=user_profile---------370----------------",
        "title": "IBM Bets Big on Watson Verticals with the Acquisition of Promontory",
        "text": "IBM Bets Big on Watson Verticals with the Acquisition of Promontory\n\nIBM continues to bet big on Watson industry solutions. A few days ago, big blue agreed to buy Promontory Financial Group, one of the most well-known financial consultancies in the world, to expand Watson\u2019s capabilities in the financial advisory space. Specifically, IBM disclosed plans to form a new unit to advise clients on financial regulation combining Watson and Promontory\u2019s experts. The new unit will be called Watson Financial Services.\n\nPromontory was founded in 2001 by Eugene Ludwig, a former. U.S Controller or the Currency. Over the years, Promontory developed a reputation as one of the top financial firms in the world of financial regulation. The Wall Street firm made the headelines right after the 2008 financial crisis when regulators paid them more than $900 million to search for errors in mortgage foreclosures in big banks.\n\nBy combining Promontory\u2019s expertise with Watson\u2019s artificial intelligence(AI) capabilities, IBM is aiming to building smarter financial services solutions that can detect fraudulent transactions or other irregular activities. IBM plans to leverage Promontory experts to train Watson on hte incresingly complex regulatory environment. Without a doubt, the acquisition represents an important step in the verticalization of AI and it also highlighted some important lessons of the evolution of the space.\n\nIBM is not the only company that has been spending big dollars on the training of AI systems. After paying $650 million for AI startup DeepMind, Google hired Go European champion Fan Hui to train DeepMind\u2019s new AlphaGo system. The result of that training materialized when AlphaGo defeated Go world\u2019s number one player Lee Sedol in a match in Seoul earlier this year.\n\nWhether we are talking about financial systems, healthcare or Go, training AI systems could be a very expensive excercise. Consequently, incumbents such as Google, Microsoft, IBM, Amazon or Facebook can leverage their big wallets to get an advantage in the space.\n\nExpert Systems Continue to be the Low Hanging Fruit for Vertical AI\n\nWatson Financial Services will focus on building systems that combine the knowledge of Promontory\u2019s experts with Watson\u2019s ability to analyze large volumes of information. That type of expert systems which combines human domain knowledge with AI algorithms continues to be the prototypical scenario for AI vertical solutions. Other type of AI systems that rely on more complex cognitive aspects such as creativity or imagination might become more popular as AI technologies evolve.\n\nIBM is Dead Serious About Verticalizing Watson\n\nThe acquisition of Promontory is a strong indicator of IBM\u2019s intentions to continue verticalizing Watson. While the first initiatives in that realm have been focused on the healthcare industry, now IBM is able to provide a series of unique solutions in the financial services space. Other industries that rely heavily on expert systems such as insurance, education or pharmacauticals could be the next target for IB Watson."
    },
    {
        "url": "https://medium.com/@jrodthoughts/wechat-mini-apps-reimagining-hybryd-apps-with-messaging-7d2a36f49078?source=user_profile---------371----------------",
        "title": "WeChat Mini-Apps: Reimagining Hybryd-Apps with Messaging",
        "text": "Last week, messaging giant WeChat unveiled the latest innovation innovation in its messaging platform: Miniapps. Conceptually, Miniapps are very simple web applications embedded in the WeChat messaging client. Using this model, WeChat hopes to partially address the distribution challenges of mobile applications. More importantly, WeChat Miniapps have some important implications for hybrid mobile apps and chatbots.\n\nDistribution has long been one of the biggest challenges of mobile applications. Every time an app provider needs to release a new version of a mobile app, they need to undergo extensive periods of testing and be subjected to the complex distribution processes of mobile app marketplaces like the Apple App Store. Despite these challenges, native apps alternatives such as web and hybrid apps have failed to become a viable option for mission critical apps. With Miniapps, WeChat hopes to rethink that equation.\n\nMiniapps can be considered a hybrid model using messaging as the underlying runtime. From that perspective, users will discover and launch Miniapps [simple web applications] directly from the messaging client. Wechat will also provide the infrastructure for publishing, creating and distributing Miniapps.\n\nUsing messaging as the runtime is a very intriguing approach for hybrid apps. For starters, WeChat\u2019s huge popularity guarantees the distribution of Miniapps to hundreds of millions of users that engage on WeChat on a regular basics. Additionally, WeChat\u2019s natural language processing(NLP) capabilities could simplify the discovery of Miniapps. For instance, WeChat could analyze the object and intent of user\u2019s conversations and recommend Miniapps relevant to that dialog.\n\nAt its names indicates, the featureset of Wechat\u2019s Miniapps should be, well, very small based on the constraints of the user interface [it has to run inside a messaging client] and the shorts amounts of time users spends on a messaging client at any given time. From that perspective, Wechat\u2019s Miniapps need to deliver a very effective and simple user experience.\n\nFrom a conceptual standpoint, WeChat\u2019s Miniapps can be seen as hybrid mobile apps in which the native component is the WeChat messaging client. That level of consistency should remove some of challenges experienced by hybrid apps in terms of a native user experience expectations. Also, by constraining the runtime to the WeChat messaging app, Miniapps can be more effective that traditional hybrid apps.\n\nWhen reading about WeChat\u2019s Miniapps, we need to wonder about its overlap with chatbots and whether this overlap is going to cause a lot of confusion for users. Miniapps certain offer a model to reuse a lot of content ad functionality available today in websites. However, advanced bot frameworks such as Facebook Messenger provide a user interface model that could result very similar to Miniapps. From the initial description of Miniapps, it seems that WeChat is going to have to do some work clarifying the scenarios for each technology.\n\nThe success of Miniapps could cause other messaging platforms to jump into the space. However, its certainly too early to make any predictions in that regard. While offering a new model for the distribution of mobile apps and expanding the capabilities of messaging clients is attractive, we need to wait how well received Miniapps are within WeChat\u2019s developer and user communities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/salesforce-acquisition-spree-sends-some-important-signals-to-the-market-e8be8368f568?source=user_profile---------372----------------",
        "title": "Salesforce Acquisition Spree Sends Some Important Signals to the Market",
        "text": "Salesforce Acquisition Spree Sends Some Important Signals to the Market\n\nSalesforce has been on an acquisition spree in the last years. The news that the SaaS giant is eyeing an acquisition of Twitter is the latest on a very active M&A season. Just in the last 6 months, Salsforce has spent over $4 billion in acquisitions in key areas for its next generation platform. This series of acquisitions are accelerating Salesforce\u2019s entrance in new markets such as artificial intelligence(AI) and solidifying its position in other sectors such as ecommerce. Let\u2019s take a look to Salesforce\u2019s recent M&A path:\n\n\u2014 Demandware: Salesforce reportedly paid $2.8 billion for ecommerce business Demandware. This acquisition will provide a bridge fo rthe Salesforce stack into the ecommerce market.\n\n\u2014 Quip: Salesforce acquired information worker technology startup Quip for $750 million. Quip\u2019s mobile word processing tools should be a great addition to Salesforce\u2019s collaboration stack.\n\n\u2014 BeyondCore: Enterprise analytics startup BeyondCored was acquired by Salesforce for a reported $110 million. That acquisition should expand Salesforce\u2019s Wave Analytic capabilities.\n\n\u2014 Prediction.IO: Salesforce acquired the open source machine learning platform Prediction.IO for an undisclosed amount. The technology is presumably being used in Salesforce\u2019s newest flagship product: Einstein.\n\n\u2014 YourSL: The Berlin-based digital consultancy was acquired by Salesforce to build its presence in Germany.\n\n\u2014 MetaMind: Salesforce acquired MataMind for $32.8 million to expand it natural language processing capabilities. This should be another addition to the Einstein platform.\n\n\u2014 SteelBrick: Salesforce bought SteelBrick for $360 million to offer quick quotes to customers.\n\n\u2014 ImplicitInsights: Another Salesforce acquisition in the artificial intelligence space. The amount of the transaction was not disclosed.\n\nWhat can we Learn from Salesforce Acquisitions?\n\nBeyond the impressive numbers, there are a few lessons we can learn from Salesforce\u2019s acquisition spree.\n\n\u2014 Strong Focus on AI-ML: The large number of acquisitions in the artificial intelligence(AI) and machine learning(ML) space reaffirm Salesforce\u2019s commitment to that market. We should expect to see some of the acquired IP as part of the Einstein platform.\n\n\u2014 Moving Faster than Competitors: $4 billion in acquisition sin six months are another indication that Salesforce is just moving much more faster than the rest of the SaaS market. From that perspective, Salesforce should be consider in the same territory as enterprise software incumbents such as SAP, Oracle, Microsoft or IBM.\n\n\u2014 Its M&A Season: The strong earnings posted by several enterprise software incumbents, the uncertainty in the public markets and the recent corrections in late state private financing are some o fhte factors conspiring to create a favorable climate for M&A and Salesforce is certainly capitalizing on it.\n\n\u2014 AI Market consolidation i sharpening Faster than Expected: In six months, Salesforce acquired several companies in the AI and ML space. Other software giants such as Microsoft, Apple, Google and Twitter has also been active acquirers in the space. All these factors are a sign that the AI space is consolidating much faster than experts expected."
    },
    {
        "url": "https://medium.com/@jrodthoughts/salesforce-acquiring-twitter-is-the-perfect-response-to-the-microsoft-linkedin-deal-8b8e85e6b925?source=user_profile---------373----------------",
        "title": "Salesforce Acquiring Twitter is the Perfect Response to the Microsoft-Linkedin Deal",
        "text": "Yesterday, some reports surfaced the news that Salesforce.com was exploring an option to acquire Twitter. There are many perspectives that can be used to analyze a potential deal between the two tech giants. At first glance, it seems that an acquisition of Twitter could be the perfect response to the Microsoft-LinkedIn deal.\n\nIt is not secret that Salesforce was very competitive trying to acquire Linkedin and placed several bids before finally loosing to Microsoft. By acquiring Twitter, Salesforce can take a second, and somewhat different, approach to merge a rich social media ecosystem into its current platform. In some aspects, Twitter could be a more natural complement to Salesforce\u2019s current product portfolio than LinkedIn.\n\nA potential acquisition of Twitter won\u2019t come without headaches for Salesforce. In the eyes of the public markets, Twitter has struggled to produce significant user growth and the stock has lost a considerable amount of its value. However, I believe the potential deals has many positive elements.\n\nFive Reasons Why Salesforce Acquiring Twitter is a Good Idea\n\nIs All About Data\n\nTwitter\u2019s rich data sources could represent a gold mine for various Salesforce products. With Salesforce\u2019s recent investments on artificial intelligence(AI), we can see Twitter becoming a powerful source of data insights for several products in the Salesforce platform.\n\nSalesforce Marketing Cloud seems to be immediate beneficiary on a potential acquisition of Twitter. By integrating Twitter with the platform, Salesforce marketing cloud can better identify prospects, leads and can do a more effective job enabling content and inbound marketing strategies.\n\nIn Periscope, Twitter has one of the most valued assets in terms of real time video streaming. Video is a relatively unexplored area for Salesforce and Periscope\u2019s technology can be a great way to bridge that gap.\n\nBoth Twitter and Salesforce have been active acquirers in the AI space. Combining the data intelligence capabilities of Salesforce with Twitter\u2019s machine learning efforts in areas such as content delivery and advertisement can create one of the most sophisticated AI stacks in the market.\n\nBy acquiring Twitter, Salesforce will be exposed to revenue channels in the consumer market that have been untapped by the enterprise software giant. Twitter\u2019s revenue is still impressive and the social vendor has been able to ink strong content and advertisement deals with household names like the NFL.\n\nThe might be other companies that could be interested on competing with Salesforce for the Twitter deal. Verizon is always an intriguing option after acquiring Yahoo. In the tech space, there aren\u2019t many companies with the balance sheet and the appetite to acquire Twitter but Google could be an option. Private equity firms could also be interested on taking Twitter private via an acquisition."
    },
    {
        "url": "https://medium.com/@jrodthoughts/whats-next-for-ibm-watson-c4223f9b5112?source=user_profile---------374----------------",
        "title": "What\u2019s Next for IBM Watson? \u2013 Jesus Rodriguez \u2013",
        "text": "IBM Watson is one of the most impressive technologies released in the last few years. Focused on enabling cognitive and artificial intelligence(AI) capabilities, Watson has become the cornerstone of IBM\u2019s strategy for the next decade. Big Blue has been pouring billions into the development and commercialization of Watson and has made it a key piece of some of other important solutions such as the Watson IOT Platform.\n\nFunctionally, Watson enables a series of APIs that abstract cognitive capabilities such as speech, text, vision, knowledge and data analysis. These APIs are exposed via the Watson Developer Cloud(WDC) which is a combination of home ground Watson technologies and smart IBM acquisitions such as Alchemy.\n\nWhile IBM Watson remains the undisputed leader in the cognitive computing space, some of its rivals have been delivering interesting technologies that could become relevant competitors in the near future. The early success of Watson and the rapid growth of the AI market has made companies such as Google and Microsoft to enter the space with really innovate offerings.\n\nDuring the past couple of years, Microsoft Research incubated a cognitive platform under the name Project Oxford. A few months ago, Oxford became generally available as Microsoft Cognitive Services which has become the AI and cognitive computing arm of Microsoft\u2019s Cortana Intelligence suite. Similarly, Google has been releasing different AI capabilities for the last decade. However, Google\u2019s AI efforts have redoubled recently with the release of platforms such as the Natural Language Processing, Vision and Speech APIs. Microsoft and Google\u2019s decades of experience building highly scalable, mission-critical system can certainly make them contenders in the cognitive computing space.\n\nWhile Microsoft and Google have been very public about their AI platforms, Amazon has remained somewhat quiet in terms of its AI initiatives. However, we are already seeing flavors of Amazon\u2019s AI capabilities in the form of the Alexa platform that powers Amazon\u2019s Echo assistant. AWS\u2019s large developer, customer and partner ecosystems will be a strong factor pushing Amazon\u2019s AI initiatives.\n\nIn terms of functional capabilities, Microsoft Cognitive Services and Google AI APIs look very similar to Watson. IBM\u2019s advantage in the market has been Watson\u2019s early adoption, market traction and impressive revenue numbers. With rivals rapidly closing the gap, we can expect IBM to enhance Watson with new and differentiated capabilities.\n\nFive Capabilities that Could be Included in Watson\u2019s Roadmap\n\nThe roadmap of the Watson platform must be incredibly ambitious if it intends to continue its dominance in the highly competitive AI market. Based on the current state of the AI ecosystem, I\u2019ve outlined a few ideas that could be included in the short term roadmap of the Watson platform.\n\nGoogle is doing a remarkable job creating industry solutions based on the DeepMind AI platform. Microsoft has also been successful penetrating different industries with its Cognitive Services solution. Being the market leader in the space, IBM has a unique opportunity to deliver a new generation of industry-specific solutions powered by the Watson platform. While IBM has already made some progress in this area, it should be a strong segment of focus in the near future. Verticalizing Watson in the form of industry-specific solutions can result in a very unique competitive advantage in the next phase of the AI market.\n\nNew cognitive areas such as handwriting recognition or video analytics could be excellent additions to the Watson platform. As Watson expands, it is important that continues ahead of its immediate competitors exploring new cognitive capabilities.\n\nToday, applications interact with Watson via APIs. Any business logic about what actions to take based on the results of a cognitive algorithm live within the client application. That form of interaction highly contrasts with the way the human brain works. Neurons in the brain\u2019s neocortex process information from different sensors [vision, speech, audio], recognizes appropriate patterns and take actions accordingly. In the near future, Watson can evolve to enable custom server side programs that combine different cognitive capabilities of the Watson platform. Currently, the combination of Watson and OpenWhisk almost accomplishes this goal but it would be nice if the next version of the Watson platform included these capabilities as part of the default feature set.\n\nThe current group of Watson knowledge APIs it leverages Wikipedia almost as the exclusive data source. Expanding knowledge APIs with other sources [ex: WebMD, Library of Congress, etc] on different verticals would enrich Watson\u2019s applicability on different domains.\n\nModel training remains one of the big challenges of the Watson platform and other competitive cognitive platforms. Although IBM has released a couple of tools for training Watson, they are pretty basic and fairly expensive for mainstream adoption. Improving the current toolset for training Watson models should be part of the short-term roadmap of the Watson platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/salesforce-einstein-and-the-emergence-of-the-ai-first-saas-47dc060f8570?source=user_profile---------375----------------",
        "title": "Salesforce Einstein and the Emergence of the AI-First SaaS",
        "text": "Salesforce Einstein and the Emergence of the AI-First SaaS\n\nDreamforce is around the corner and Salesforce is once again set to unveil some major technology releases. While topics such as mobile, IOT and analytics have dominated previous editions of Dreamforce, this year the focus seems to be 100% around artificial intelligence(AI) and the newest member of the Salesforce family: Einstein.\n\nBased on initial press coverage, Einstein will enable AI capabilities in a large number of products of the Salesforce platform. The introduction of Einstein should be seen as a new phase in the Salesforce platform using AI as a first class citizen. From the perspective of the SaaS ecosystem in general: the release of Einstein could mark the beginning of the AI-First SaaS.\n\nAI offers a new canvas to reimagine many of the existing SaaS capabilities and create new ones using AI as the foundational element. There are many interesting features that could be relevant to AI-First SaaS platform. Here are some ideas that I believe are worth considering.\n\nAn AI-First SaaS should include predefined machine learning(ML) models that improve existing business processes. In the case of Einstein, it is conceivable that the platform will include ML models that operate against Salesforce marketing or sales data to enable new capabilities such as predictive sales forecast, funnel optimization, personalized product offering among many other relevant capabilities of sales and marketing processes.\n\nIn addition to executing predefined ML models, an AI-First should provide the capability of building, running and managing custom ML models. In the case of Salesforce Einstein, it would be interesting if the platform supports the execution of custom R or Python models against Salesforce data extending the default ML feature set.\n\nIn order to support mission-critical business processes, an AI-First platform should enable the continuous performance monitoring and training of ML models. In the case of Salesforce Einstein, the platform could include tools within the Salesforce management console to retrain the existing models, monitoring its runtime behavior and evaluate its effectiveness.\n\nAn AI-First SaaS should take advantage of the recent developments in deep learning technologies to enable the analysis of cognitive and unstructured data sources such as text, vision and speech. In the case of Salesforce Einstein, we can envision the platform enabling new analytic capabilities using image, audio or text which are highly relevant in sales and marketing processes.\n\nAn AI-First SaaS should expose APIs that allow third party applications to leverage AI and ML models. In the case of Salesforce Einstein, its conceivable that the new AI capabilities will exposed a new set of APIs for programmatic interactions with other applications.\n\nThese are just some intriguing ideas for Salesforce Einstein. I am definitely looking forward to Dreamforce to see Salesforce\u2019s strategy to lead the AI-First market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/salesforce-einstein-and-the-emergence-of-the-ai-first-saas-57246d0fe0e0?source=user_profile---------376----------------",
        "title": "Salesforce Einstein and the Emergence of the AI-First SaaS",
        "text": "Dreamforce is around the corner and Salesforce is once again set to unveil some major technology releases. While topics such as mobile, IOT and analytics have dominated previous editions of Dreamforce, this year the focus seems to be 100% around artificial intelligence(AI) and the newest member of the Salesforce family: Einstein.\n\nBased on initial press coverage, Einstein will enable AI capabilities in a large number of products of the Salesforce platform. The introduction of Einstein should be seen as a new phase in the Salesforce platform using AI as a first class citizen. From the perspective of the SaaS ecosystem in general: the release of Einstein could mark the beginning of the AI-First SaaS.\n\nAI offers a new canvas to reimagine many of the existing SaaS capabilities and create new ones using AI as the foundational element. There are many interesting features that could be relevant to AI-First SaaS platform. Here are some ideas that I believe are worth considering.\n\nAn AI-First SaaS should include predefined machine learning(ML) models that improve existing business processes. In the case of Einstein, it is conceivable that the platform will include ML models that operate against Salesforce marketing or sales data to enable new capabilities such as predictive sales forecast, funnel optimization, personalized product offering among many other relevant capabilities of sales and marketing processes.\n\nIn addition to executing predefined ML models, an AI-First should provide the capability of building, running and managing custom ML models. In the case of Salesforce Einstein, it would be interesting if the platform supports the execution of custom R or Python models against Salesforce data extending the default ML feature set.\n\nIn order to support mission-critical business processes, an AI-First platform should enable the continuous performance monitoring and training of ML models. In the case of Salesforce Einstein, the platform could include tools within the Salesforce management console to retrain the existing models, monitoring its runtime behavior and evaluate its effectiveness.\n\nAn AI-First SaaS should take advantage of the recent developments in deep learning technologies to enable the analysis of cognitive and unstructured data sources such as text, vision and speech. In the case of Salesforce Einstein, we can envision the platform enabling new analytic capabilities using image, audio or text which are highly relevant in sales and marketing processes.\n\nAn AI-First SaaS should expose APIs that allow third party applications to leverage AI and ML models. In the case of Salesforce Einstein, its conceivable that the new AI capabilities will exposed a new set of APIs for programmatic interactions with other applications.\n\nThese are just some intriguing ideas for Salesforce Einstein. I am definitely looking forward to Dreamforce to see Salesforce\u2019s strategy to lead the AI-First market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/salesforce-einstein-and-the-emergence-of-the-ai-first-saas-4a17482a633f?source=user_profile---------377----------------",
        "title": "Salesforce Einstein and the Emergence of the AI-First SaaS",
        "text": "Dreamforce is around the corner and Salesforce is once again set to unveil some major technology releases. While topics such as mobile, IOT and analytics have dominated previous editions of Dreamforce, this year the focus seems to be 100% around artificial intelligence(AI) and the newest member of the Salesforce family: Einstein.\n\nBased on initial press coverage, Einstein will enable AI capabilities in a large number of products of the Salesforce platform. The introduction of Einstein should be seen as a new phase in the Salesforce platform using AI as a first class citizen. From the perspective of the SaaS ecosystem in general: the release of Einstein could mark the beginning of the AI-First SaaS.\n\nAI offers a new canvas to reimagine many of the existing SaaS capabilities and create new ones using AI as the foundational element. There are many interesting features that could be relevant to AI-First SaaS platform. Here are some ideas that I believe are worth considering.\n\nAn AI-First SaaS should include predefined machine learning(ML) models that improve existing business processes. In the case of Einstein, it is conceivable that the platform will include ML models that operate against Salesforce marketing or sales data to enable new capabilities such as predictive sales forecast, funnel optimization, personalized product offering among many other relevant capabilities of sales and marketing processes.\n\nIn addition to executing predefined ML models, an AI-First should provide the capability of building, running and managing custom ML models. In the case of Salesforce Einstein, it would be interesting if the platform supports the execution of custom R or Python models against Salesforce data extending the default ML feature set.\n\nIn order to support mission-critical business processes, an AI-First platform should enable the continuous performance monitoring and training of ML models. In the case of Salesforce Einstein, the platform could include tools within the Salesforce management console to retrain the existing models, monitoring its runtime behavior and evaluate its effectiveness.\n\nAn AI-First SaaS should take advantage of the recent developments in deep learning technologies to enable the analysis of cognitive and unstructured data sources such as text, vision and speech. In the case of Salesforce Einstein, we can envision the platform enabling new analytic capabilities using image, audio or text which are highly relevant in sales and marketing processes.\n\nAn AI-First SaaS should expose APIs that allow third party applications to leverage AI and ML models. In the case of Salesforce Einstein, its conceivable that the new AI capabilities will exposed a new set of APIs for programmatic interactions with other applications.\n\nThese are just some intriguing ideas for Salesforce Einstein. I am definitely looking forward to Dreamforce to see Salesforce\u2019s strategy to lead the AI-First market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/blockchain-love-big-banks-are-relying-on-the-blockchain-for-trade-data-tests-6d56d3f1c1c1?source=user_profile---------378----------------",
        "title": "Blockchain Love: Big Banks are Relying on the Blockchain for Trade-Data Tests",
        "text": "Blockchain Love: Big Banks are Relying on the Blockchain for Trade-Data Tests\n\nOne of the biggest blockchain applications not related to bitcoin is undergoing some serious tests. This week, a group of banks announced they are testing a solution that leverages blockchain technologies for validating reference data in financial trades. The early adopters includes sme of the biggest names in teh banking industry including Citigroup Inc, Credit Suisse AG and HSBC Holdings PLC.\n\nReference data is one of the most important aspects of trade settlements. In equity or bond trading, trade settlements can take an average of several days to complete. Banks have long expressed interested in the blockchain as a potential solution to reduce the settlement times to a few hours. Validating reference data is an incredibly important step towards that goal.\n\nThe process of validating reference data in near-real time will translate into big savings for banks. In a typical or bond trade, banks maintain reference data in their own databases which causes a lot of challenges in terms of data reconciliation. Additionally, banks contract third parties such as Bloomberg to host and access the data produced in the trade process. Some recent studies estimate the costs associated with the validation of trade reference data to be about $2 billion annually.\n\nUsing the blockchain, banks can now host individual nodels of a blockchain network that stores reference data related to a trade in a secure way that can be verified by the other parties involved in the trade without the need of a centralized authority. Based on the initial reports, banks have been developing a pilot solution to validate reference data in bond trades. Some of the reference information include elements such as interest payment rates of issuer name.\n\nThe trade settlement pilot, represents a big win for the consortium blockchain model. Often the ignored child in the public vs. private blockchain debate, consortium blockchains advocate a model for a blockchain network in which nodes are hosted by the different entities involved in a B2B transaction. From that perspective, consortium blockchains can be considered a middle-ground between public and private blockchains.\n\nFor years, Bitcoin-Blockchain purists have been vocal against consortium blockchain architectures claiming that it undermines some of the original promises of bitcoin. Beyond the philosophical argument, even the purest bitcoin advocates should acknowledge the great milestone that represent for those big banks to embrace blockchain technologies in such a mission critical solution. In addition to trade settlement, consortium blockchains represents a viable model for many well-known B2B scenarios such as supply chain, ecommerce, etc.\n\nWhat Does this Means for Blockchain Startups\n\nThe technology used for the blockchain trade settlement solution was originally developed by blockchain startup Axoni. Beyond the great validation for Axoni\u2019s technology, this pilot can be taken as a positive development for the blockchain startup ecosystem in general. For starters, the Axoni-powered solution represents a confirmation for the viability of blockchain technologies in the financial industry. In addition to trade settlement, other financial service scenarios such as lending or credit could soon adopt blockchain technologies.\n\nIn addition to startups, the bond trading blockchain pilot also represents encouraging news for investors in the blockchain technology ecosystem. Many of the banks included in the pilot have been active investor in blockchain startups. Hopefully, these news will drive more venture capitalists and corporate investors to actively invest in the blockchain ecosystem."
    },
    {
        "url": "https://medium.com/@jrodthoughts/oracle-seems-delusional-about-the-cloud-9cd520098c05?source=user_profile---------379----------------",
        "title": "Oracle Seems Delusional About the Cloud \u2013 Jesus Rodriguez \u2013",
        "text": "Oracle Open World (OOW) is here and, what else is new, we keep hearing the rhetoric message that they are better, faster and more scalable than everybody else. Yesterday, however, Oracle too its message a step further and, while unveiling a new group of cloud technologies, proclaimed that \u201cAmazon lead was over\u201d a message that took by surprise to even the most hard core Oracle fan boys.\n\nOther than making for a good headline in The Wall Street Journal, Oracle\u2019s statements seems completely out of context. Oracle is certainly capable of capturing a meaningful market share in the cloud space. However, Ellison\u2019s statement about Amazon still seems ridiculous. Without getting passionate about the topic, let\u2019s try to present a pragmatic analysis of the market share and advantages of Oracle Cloud offering and you can drive your own conclusions from there.\n\nAWS is not the Right Target\n\nLogically speaking, focus on competing with AWS seems like the wrong objective for Oracle. Currently, AWS controls over 30% of the market and Oracle barely appears on the charts trailing not only Microsoft, IBM and Google Cloud but also the offerings from companies like Pivotal or HP. The right goals for Oracle Cloud should be, first, to establish a solid #5 position in the market and, after that, focus on competing with Google and IBM for the #3 spot. Both IBM and Google are really focused on the enterprise cloud market which makes them a viable target for Oracle Cloud. If after achieving those goals, AWS and Azure haven\u2019t been able to consolidate their market leadership position, then Oracle can focus on competing with those cloud offerings.\n\nPutting aside the current state of the market, let\u2019s try to analyze the pros and cons of Oracle Cloud\n\n\u2014 Large Gap on Basic Capabilities: Currently, there is still a large gap between Oracle Cloud and the cloud market leaders on basic capabilities such as storage, compute, database support, etc.\n\n\u2014 No Traction in the Consumer Market: Cloud platforms such as Google Cloud, AWS and Azure have developed meaningful traction within the consumer market. Oracle Cloud is solely focused on the enterprise which makes it extremely difficult to displace the aforementioned players.\n\n\u2014 Lack of Emerging Technology Services: Oracle Cloud doesn\u2019t include relevant services in emerging technology areas such as machine learning, IOT, artificial intelligence, blockchain or other areas that will drive innovation in the next decade of cloud platforms.\n\n\u2014 Small Developer Community: Oracle Cloud\u2019s developer community is relatively small compared to the equivalent in the cloud market leaders.\n\n\u2014 Missing Unique Technology Offerings: Bluemix\u2019s Watson, Google Cloud\u2019s BigQuery, Azure\u2019s Service Bus are some examples of unique cloud services that have helped to attrack developer and customers to those cloud platforms. Currently, Oracle Cloud is still missing that unique technology offering and will increase the relevance of its cloud offering.\n\n\u2014 SaaS Offering: Oracle\u2019s large SaaS portfolio is likely to indirectly influence the adoption of Oracle Cloud.\n\n\u2014 Enterprise Sales Mastery: Oracle can leverage its extensive sales organization to efficiently position Oracle Cloud in large enterprises.\n\n\u2014 Partner Community: Oracle\u2019s large system integrator partner community could be a strong asset to accelerate the implementation of Oracle Cloud.\n\n\u2014 Oracle DB and Weblogic Migrations: There are many enterprises that could take advantage of Oracle Cloud to port their existing Oracle DB or Weblogic solutions to a cloud infrastructure.\n\n\u2014 Cloud Solutions in Regulated Industries: Oracle\u2019s strong presence in regulated markets such as finance, defense or public sector can result in a unique position to drive the adoption of solutions powered by Oracle Cloud."
    },
    {
        "url": "https://medium.com/@jrodthoughts/regional-cloud-platforms-still-matter-3251caf1871c?source=user_profile---------380----------------",
        "title": "Regional Cloud Platforms Still Matter \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, Chinese telecom giant Huawei announced its intentions to enter the cloud computing space by providing equipment for cloud data centers. This is a market vastly dominated by companies like Cisco Systems. However, Huawei\u2019s strong customer base in China, Europe and Latin-American could help to make it a relevant player in the space. If successful, Huawei will be another example of cloud computing technology providers that have achieved relevance on specific geographic regions.\n\nThe phenomenon of regional cloud providers is certainly interesting. Globally, the platform as a service(PaaS) market have become a four-company race between Amazon, Microsoft, IBM and Google. However, players such as Alibaba in China, Dimension Data in Australia-New Zealand and a handful of other players in geographies such as Brazil, Russia, South Africa and other fast growing economies, have managed to stay incredibly competitive in those regional markets. Even more importantly, the cloud incumbents have struggled finding effective ways to compete against those regional players.\n\nThe challenges of international expansion for US tech companies are widely documented. Just a few weeks ago, car-sharing giant Uber raised the white flag by partnering with its arch-rival in China Didi. This mode was the final chapter of year of efforts by Uber trying to penetrate the Chinese market which resulted in losses of as much as $1 billion per year.\n\nDespite the numerous examples of challenges and failures experienced by US tech companies expanding onto emerging markets, the raise of regional cloud providers remains a very unique phenomenon. Cloud platforms such as AWS or Azure are global by definition and the leaders in the space are companies with decades of experience penetrating and developing international markets. Then how is it possible that regional cloud providers can stay so competitive?\n\nFive Reasons Why Regional Cloud Providers are Still Relevant\n\nRegional cloud providers are typically very effective navigating the compliance the regulatory environment of their target geography. Different regions of the world are subjected to very particular regulations in areas such as data transfers, security, compliance policies and other artifacts that are completely foreign to US companies. As a result, the cloud platform incumbents have been forced to devote time and resources to be compliant with those requirements which has given the regional cloud providers a clear advantage in terms of time to market.\n\nIn many areas of the world, governments have intervened to favor the adoption of regional cloud providers by local companies. Some people might think about this type of intervention as anti-free market by many governments consider it the responsible thing to do. This level of goverment intervention has made it challenging for cloud incumbents to penetrate markets in which many businesses are influenced or even dependent on the goverment.\n\nAs we\u2019ve seen in other technology areas, markets such as China, Southeast Asia or Brazil as sufficiently big to build large companies. Regional cloud providers such as AliCloud have done a masterful job providing support for popular local internet services in areas such as messaging, storage, games which are incredibly popular in the region but not very well known for cloud incumbents. Regional cloud providers have used this level of service as a competitive advantage to capture the local market.\n\nMany of the regional cloud providers have been able to nurture substantial developer and system integrator communities within their target region. As a result, many of this cloud providers are able to onboard client faster than the cloud incumbents and have the support of a local developer community.\n\nPatriotism, regionalisms are some of the often ignored influences in the adoption of enterprise software technologies in international markets and cloud computing is not the exception. AliCloud is a cloud platform built in China for Chinese customers. Despite the obvious gaps in capabilities between AliCloud and incumbent platforms such as AWS, Azure, Bluemix or Google Cloud Chinese enterprise customers feel better represented by adopting a Chinese cloud solution and perceive that as a support for the local tech industry."
    },
    {
        "url": "https://medium.com/@jrodthoughts/serverless-is-the-new-black-107fcccbdc43?source=user_profile---------381----------------",
        "title": "Serverless is the New Black \u2013 Jesus Rodriguez \u2013",
        "text": "Serverless computing is one of the new hottest trends in modern software development. Conceptually, serverless computing leverages micro-containers o execute atomic functions as response to specific events.\n\nIn just a few years, serverless computing services have become a first class citizen of major platform as a service(PaaS) such as AWS, Azure, Bluemix and Google Cloud. AWS was the first PaaS platform to incorporate serverless computing capabilities with the release of its Lambda service. Inspired by functional programming artifacts, AWS Lambda remains the undisputed leader in the serverless architecture space but is seen increasing competition from other PaaS providers as well as from startups such as PubNub.\n\nWhat is Causing the Popularity of Serverless Computing?\n\nThere are several factors contributing to the raising popularity of serverless architecture. From the simplicity of the implementation model to the influence of other high growing trends such as the internet of things (IOT), several factors are contributing to establishing serverless models as one of the architecture styles of modern software applications.\n\nAbstracting infrastructure from code has always been one of the promises of cloud computing but serverless architectures take this to a complete different level. Serverless solutions require no dedicated infrastructure or VMs. The underlying platform will dynamically provision micro-containers required to run specific business logic as a reaction to specific events.\n\nArchitecturally, serverless architectures represent an evolution of the multi-tenancy paradigm. In some context, we can say that serverless architectures provides a level of abstraction of multi-tenant infrastructure focused on the execution of atomic functions.\n\nIOT solutions are the prototypical use case for serverless architectures. The event-driven and continuously-evolving nature of IOT solutions fits perfectly the serverless model in which new functions are added and executed in response to specific events. Some of the most popular IOT solutions like Amazon Echo already rely on serverless architectures.\n\nServerless stacks have quickly become one of the most popular technologies in PaaS stacks. Part of the reason for this phenomenon is the intrinsic simplicity of serverless platforms that allow a developer to start using a cloud platform by simply writing individual functions.\n\nBuilding multi-cloud solutions have been a permanent challenge for companies embracing PaaS stacks. The serverless model provides a viable reusability mechanism for cloud solutions as most of the platforms in the market have a similar feature set and functions and events from one platforms can be easily transferred to a different PaaS while maintaining the core architecture of the solution consistent."
    },
    {
        "url": "https://medium.com/@jrodthoughts/azure-service-fabric-and-the-evolution-of-the-microservices-paas-5f2dd1a3f465?source=user_profile---------382----------------",
        "title": "Azure Service Fabric and the Evolution of the Microservices PaaS",
        "text": "A few months ago, Microsoft announced the general availability of the Azure service Fabric: a new platform for developing and running microservices. Functionally, Azure Service Fabric provides some of the most common building blocks of microservices solutions such as the modeling and implementation of stateless-stateful services, messaging, persistence, stateless-stateful actors, service discovery among other relevant capabilities.\n\nThe release of the Azure Service Fabric marks an important milestone in the evolution of cloud microservices architectures. At the moment, azure service Fabric is the only platform among the top PaaS -AWS, Azure, Bluemix, Google Cloud- that provides an end to end infrastructure for building and operating microservices. Some experts are considering the Azure Service Fabric the foundation for the next version of Microsoft Azure and the model the framework for the next generation PaaS.\n\nIf we analyze the evolution of microservices capabilities across the major PaaS we can come up with the following timeline\n\nAWS, Azure, Bluemix and Google Cloud have all released services for deploying and managing containers such as Docker or Rocket. Google Cloud has been particularly innovative in this area with the incubation of platforms like Kubernetes that have become some of the most important building blocks of the container ecosystem. One aspect that adds credibility to Google Cloud\u2019s container offering is the fact that Google itself has been running containers at scale for years.\n\nLambda functions is a generic cloud term to designate a micro-container responsible for running an atomic function. Azure Functions, Bluemix OpenWhisk, Google Functions and AWS Lambda represent some of the main technologies in the space. Even though some of these technologies look very similar in terms of capabilities, AWS Lambda is the undisputed leader in the space in terms of market traction.\n\nWhile Lambda Functions and Containers are certainly relevant building blocks of microservices architectures, they are not sufficient to implement sophisticated microservices solutions. Other functional areas such as service authoring, discovery, data persistence, messaging, etc are common citizens in microservices solutions. The Azure Service Fabric is the first technology among the PaaS providers that provides an end-to-end experience for the development and management of microservices. If successful, the Azure Service Fabric is likely to become the foundation for new services in the Azure platform. Today technologies like SQL Azure are already leveraging Service Fabric as its underlying stack. From that perspective, technologies such as the Azure Service Fabric are called to become a core element of the next generation PaaS."
    },
    {
        "url": "https://medium.com/@jrodthoughts/baas-and-the-fragmentation-of-the-blockchain-7c141f60ba3e?source=user_profile---------383----------------",
        "title": "BaaS and the Fragmentation of the Blockchain \u2013 Jesus Rodriguez \u2013",
        "text": "BaaS and the Fragmentation of the Blockchain(BaaS) is one of the most interesting developments in the blockchain technology ecosystem. With incumbents such as IBM and Microsoft releasing the first versions of their BaaS stacks and Amazon announcing its intentions to enter the space, we can safely assume that BaaS is going to become a key element in the next phase of the platform as a service (PaaS) wars.\n\nThe emergence of Baas has been one of the strongest validations for the blockchain technology market since its inception. However, BaaS has also introduced a new set of challenges that will need to be addressed by the blockchain community. Among those, I believe fragmentation is one of the BaaS side effects that could result really disruptive to the evolution of the blockchain.\n\nIn the past, I\u2019ve written extensively about the fragmentation challenges in the blockchain ecosystem. I think BaaS is one of the factors that is helping to increase the complexity of fragmentation in the blockchain space. To better understand this phenomenon, we should try to answer the following questions:\n\n\u2014 How is BaaS contributing to the fragmentation of the blockchain?\n\n \u2014 Why is the fragmentation of the blockchain relevant?\n\n \u2014 How can the blockchain community address the immediate fragmentation challenges?\n\n3 Reasons Why BaaS is Contributing to the Fragmentation of the Blockchain\n\nThe fragmentation challenges in the blockchain precede the emergence of BaaS stacks. However, BaaS platforms have certainly contributed to increase the complexity of this phenomenon. Below there are of the main characteristics of BaaS that could contribute to the fragmentation of the blockchain:\n\n\u2014 Private Blockchain Implementations: As part of their BaaS stacks, both Microsoft and IBM have released proprietary implementations of private blockchains in the form of Project Bletchey and Hyperledger respectively. If this continue, we might soon have dozens of relevant private blockchain implementations which introduces challenges in terms of interoperability and portability.\n\n\u2014 Proprietary Extensions: The BaaS stacks provided by the PaaS incumbents go beyond the implementation of private blockchain models and introduce new extensions to enable capabilities such as middleware or enterprise security which are not included in the public blockchain stack. Even though the incumbents have done a remarkable job open sourcing those technologies and building the community around it, the proprietary extensions introduce a marked difference between the different BaaS stacks with the consequent interoperability challenges.\n\n\u2014 Optimized for Cloud Infrastructures: The BaaS stacks implemented by companies like IBM and Microsoft are really optimized to run in the Bluemix and Azure PaaS respectively. This is obviously expected as the main benefit of BaaS modes are to simplify and abstract the underlying infrastructure required to run and operate blockchain solutions. However, the level of dependency on a specific PaaS makes it impractical t use that BaaS stack in other infrastructure such as on-premise data centers.\n\n3 Reasons Why We Should Care About Blockchain Fragmentation\n\nDespite the fragmentation challenges introduced by the BaaS stacks, we should question whether those [challenges] are relevant at this point of the blockchain market. Here are a few ideas to consider:\n\n\u2014 Portability Matters in the Blockchain: Fragmentation is a very common challenge of open source projects adopted by enterprise software incumbents. However, the case of the blockchain is different. the promise of the blockchain is to operate completely decentralized and trustless networks. In that model, portability and interoperability between different blockchain networks is essential and that could be challenging in a very fragmented market.\n\n\u2014 The Risk of Incumbents Owning the Blockchain: The introduction of BaaS brings up the risk that one of the incumbent\u2019s implementations becomes the dominant platform in the market and captures the majority of the market share. Even though that could be seen as one of the positive sides of competition, a blockchain market dominated by a large incumbent might kill the promise of the blockchain.\n\n\u2014 Private Blockchains Evolving Faster than Public Blockchains: BaaS foments the adoption of private blockchains. With IBM, Microsoft and Amazon entering the market, there is a risk that private blockchain stacks in BaaS platform will evolve faster than the public blockchain. To illustrate this challenge in another context, imagine what would have happened if the adoption of private networks would have evolved faster than the internet.\n\nI don\u2019t believe there are any silver bullets to address the blockchain fragmentation created by BaaS stacks. However, there are a few ideas that might be worth considering:\n\n\u2014 Standardizing on Ethereum: Even though there are several blockchain application development platforms, Ethereum has clearly become the market leader. More importantly, many experts are looking at Ethereum to address some of the well-known challenges in the public blockchain.Without proclaiming game over in the blockchain development platform race, I think there are some tangible benefits if the BaaS space would standardize on the Ethereum platform. This is the equivalent of what happened in the Hadoop community when the enterprise distributions adopted a basic tech stack.\n\n\u2014 Cloudfoundry + Ethereum: The combination of Cloudfoundry and Ethereum can provide an open source BaaS stack that can be used as the baseline for other BaaS implementations. This could be the equivalent of the Docker model for the blockchain ecosystem.\n\n\u2014 BaaS Interoperability Tests and Standards: I am not a big fan of using standards to enforce interoperability but something like that might be needed to address the fragmentation challenges in the blockchain. The idea of a third party organization conducting regular interoperability tests and building a series of standards to be followed by the BaaS providers is an interesting idea at this stage of the market. Obviously, the BaaS providers would need to be active participants in this exercise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/goldman-calls-bot-overhyped-but-are-they-196b0f4fb493?source=user_profile---------384----------------",
        "title": "Goldman Calls Bot Overhyped but Are They? \u2013 Jesus Rodriguez \u2013",
        "text": "Last week, Goldman Sachs included bot technologies as part of its famous buzzwords series that highlight overhyped technologies in the market. Goldman explained that bots are still in the very early statages of its growth cycle and explained that the majority of bots in the market haven\u2019t experienced beyond ordinarily traction. \u201cBots are poised for continuous maturation for a couple of reasons. The first is that the channels are in place\u201d Goldman said. \u201cMessaging platforms are broadly adopted in The US and globally. The second [reason] is that the technology behind bots -machine learning- is starting to mature rapidly over the next few years\u201d In plain words, bots are a promising technology trend but, at the moment, they are overhyped.\n\nI am very bullish of bots. In the past, I\u2019ve written extensively about the subject and I firmly believe the space is going to evolve rapidly. I believe that, from an anthropologic standpoint, natural language and voice are a more natural mechanism to interact with software systems than the current generation of user interface models. Having said that, it is hard to completely disagree with Goldman\u2019s points. In the current market, bots have been terribly overhyped as a technology trend and the space hasn\u2019t yet deliver any winners.\n\nReading Goldman\u2019s report made me thing about some of the main challenges for bot technologies in the current market and some possible solutions.\n\nDespite the explosion of bots being released in the last few years, the vast majority of them have experience little or moderate traction. Many experts believe that the development of the bot market is a classic \u201cbig link\u201d problem in the sense that the market needs to produce a few bots that experience a massive level of user engagement and adoption.\n\nI believe gaming is one of the areas that is likely to produce a few early winners in the bot market. The viral nature of games makes it an ideal candidate to breakthrough the initial bot adoption barriers.\n\nOne of the elements that helped the adoption of mobile apps was the introduction of a brand new runtime -mobile OS- and new hardware -mobile OS-. Bots, on the other hand, are sharing a runtime and hardware infrastructure with mobile applications which means that users are splitting time between bots and mobile apps which many times makes it easier for users to just use mobile apps.\n\nMessaging platforms are the undisputed runtime for bot solutions. However, I believe that expanding onto other software and hardware platforms could help with the adoption of bots. To use an example, bots can be a natural fit for wearable\u2019s in which the user experienced is severely more constrained than mobile apps. Platforms like the Amazon Echo ecosystem are becoming an interesting option as a bot runtime.\n\nMonetization channels are another of the well known challenges in the bot market. Is really hard to think about solving the monetization problem when we are still trying to figure out how to improve the adoption of the technology but you can rest assured that VCs investing in the bot space are definitely thinking about it. In general, is hard to grow a technology market without establishing the proper monetization channels.\n\nBots represent a new channel for brands to engage with customers. AS a result, bots have a unique opportunity to drive new forms of advertisement and marketing based on natural language and voice interactions. From that perspective, advertisement and other forms of marketing can become the first effective monetization channel for bot platforms.\n\nAs mentioned before, I remain super bullish about bot technologies and I some of the challenges listed in this article are just the natural evolution of a disruptive technology trend in an already over hyped market. Despite the challenges, bots should definitely play an important in the next decade of software development."
    },
    {
        "url": "https://medium.com/@jrodthoughts/iot-3d-printing-are-making-ge-cool-again-720ebae614a4?source=user_profile---------385----------------",
        "title": "IOT, 3D Printing are Making GE Cool Again \u2013 Jesus Rodriguez \u2013",
        "text": "In case you haven\u2019t seen the ridiculous GE TV commercials, you know that GE is immersed in a transformation to become a more software driven company but, more importantly, to be at the forefront of technology innovation to power the next generation of industrial enterprise solutions.\n\nThis week, GE announced its intentions to acquire two 3D printing companies: SLM solutions based in Germany and Arcam based in Sweden. The acquisition price for SLM was value at 38 Euros per share for a total of $762 million. SLM makes laser machines for metal 3D printing. Arcam is also actively working on metal 3D printing and is the company associated with inventing the election beam melting machine. GE agreed to pay 285 Swedish Crowns per share for a total of $865 million. With both acquisitions, GE will be spending almost $1.4 billion to become one of the leaders in the industrial 3D printing space.\n\nGE\u2019s new acquisitions are another milestone n a strategy focused on embracing modern technologies and adapting it to industrial solutions. 3D printing is certainly nothing new but the potential of applying at the scale of GE\u2019s operations in industries like healthcare, aerospace or solutions is certainly a strong validation for the 3D printing space.\n\n3D printing is not the only modern technology relevant to GE\u2019s strategy. The internet of things (IOT) is, arguably, GE\u2019s strongest area of focus. In the IOT space, GE is immersed in a battle with technology giants like IBM, Microsoft and Amazon to establish a leadership position in that emerging market.\n\nIn just a few yeas, GE\u2019s Predix IOT platform has achieved a market leadership position claiming over $9 billion in revenue in 2015 and forecasting $20 billion by 2020. Predix is based on Cloudfoundry, the open source private platform as a service (PaaS) which represents another example of GE\u2019s investments in modern technologies.\n\nWhat\u2019s the Next Cool Tech Market for GE\n\nAs an industrial powerhouse, there are many emerging technology markets that should be in GE\u2019s radar. Here are some ideas:\n\n\u2014 Drones: GE could become one of the most influential players in the drone technology market by applying it to industrial scenarios like asset management or surveillance in verticals such as oil & gas or agriculture.\n\n\u2014 Augmented Reality: Augmented Reality (AR) could be another area of focus for GE in the near future. By augmenting worker\u2019s view of their environment with digital information GE could help power a new generation of solutions that improve business processes in industries like manufacturing, healthcare or automotive.\n\n\u2014 Robots: No much explanation is needed here. The robot market is experiencing a renaissance across different sectors. With his knowledge of industrial enterprise solutions, GE is in a unique position to become a pioneer of solutions that bring robots to the modern workforce."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-ai-first-enterprise-869ab352aa46?source=user_profile---------386----------------",
        "title": "The AI-First Enterprise \u2013 Jesus Rodriguez \u2013",
        "text": "Artificial intelligence(AI) i experiencing a much anticipated renaissance. Even though some of the most important AI developments of recent years have taken place in the consumer market, the enterprise space is steadily embracing AI technologies.\n\nThe opportunities for AI in the enterprise are tremendous. From infrastructure to powering a brand new generation of business processes, most of the capabilities of today\u2019s enterprise can be re-imagined using AI as a foundation. From that perspective, AI has the potential power the next decade of enterprise software. Without a doubt, we are entering the era of the AI-First enterprise.\n\nWhat is the AI-First Enterprise?\n\nThe AI-First enterprise is a business and technical transformation movement that attempts to incorporate AI as a first class citizen of the vast majority of business processes and software solutions in the enterprise. Conceptually, the AI-First business processes evolve from traditional business processes by transforming data into intelligence.\n\nEven though we should think about the AI-First enterprise as a holistic incorporate, there are a few areas that are already becoming relevant in the enterprise. From infrastructure to new AI capabilities in SaaS systems, AI is becoming more and more present in the current generation of enterprise solutions. Let\u2019s explore some of the groups of enterprise software technologies that are rapidly embracing AI.\n\nsome of the most relevant software as a service (SaaS) platforms in the market such as Salesforce.com or WorkDay have been actively incorporating AI capabilities into their current stack. Salesforce has been on a shopping spree acquiring AI startups and is about to announce a new AI platform at the upcoming dreamforce conference. WorkDay has not only added AI capabilities to its platform but it also launched a new venture fund focused on machine learning and AI startups.\n\nIn the next few years, it is expected that the majority of top SaaS providers will enhance their current feature set with AI-First capabilities. Without a doubt, SaaS providers will be among the first group of mainstream platforms to introduce AI into enterprises.\n\nTechnologies such as IBM Watson, Microsoft Cognitive Services or Google Natural Language Processing API enable incredibly sophisticated AI capabilities for analyzing text, speech and vision using simple API calls. This model simplifies the entry point for organization looking to leverage AI capabilities into their applications without investing in complex infrastructures.\n\nAI is often seen as a high level application capability. However, some of the most exciting developments in the enterprise AI space are taking place in infrastructure solutions. areas such as networking, threat analysis(security) or log processing (APM) have been quick to embrace AI capabilities as a foundation to their next generation solutions.\n\nDatabases are another element of the enterprise software portfolio that is rapidly incorporating AI capabilities. The recent release of SQL Server 2016 includes the former Revolution Analytics stack. By expending their feature set with new AI capabilities, databases are in a unique position to influence the adoption of AI in the enterprise.\n\nIn addition to leveraging AI features from SaaS systems, infrastructure components or databases, enterprises will slowly start incorporating custom AI solutions as part of their portfolio. We think these AI solutions are likely to start as departmental efforts and slowly move onto enterprise scale solutions.\n\nThere are other areas that can also influence the adoption of AI in the enterprise. the ones listed in this article are based on the initial areas of focus of enterprise startups. One thing is certain. In the next few years, AI is called to become of the foundational pieces of enterprise solutions and one that can transform the enterprise we know today."
    },
    {
        "url": "https://medium.com/@jrodthoughts/understanding-conversational-interfaces-b19b86fb7617?source=user_profile---------387----------------",
        "title": "Understanding Conversational Interfaces \u2013 Jesus Rodriguez \u2013",
        "text": "Conversational interfaces are becoming a fast growing trend in the technology ecosystem. Conceptually, conversational interfaces leverage natural language processing (NLP) techniques to process voice or text data when interacting with a software system.\n\nWhile the NLP theory has been an area of focus of artificial intelligence(AI) researches for decades, it is only recently that it has material on practical industry applications. The relevance of NLP and conversational interfaces has certainly catalyzed by the raising popularity of bot technologies. In many aspects, conversational interfaces can be considered the fundamental user interface(UI) of bot software solutions.\n\nWhen thinking about conversational interfaces as a user form of user experience(UX), it is important to understand some of its unique characteristics. In the history of the software industry, the release of a major runtime typically brings new forms of user interface. The web introduced the concept of hyperlinks as well as hundreds of UI controls. Mobile came up with new user interaction models such as touch, tap or swipe. Similarly, conversational interfaces include very distinctive user interface concepts. Without attempting to provide an exhaustive list, I\u2019ve included some of the concepts I think should be considered when leveraging conversations as a UX model:\n\nIn mobile and web UIs, user actions are fundamentally deterministic. When a user clicks or touch a button, the underlying application already includes business logic that will be executed as a response to that action. Conversational interfaces can\u2019t follow deterministic models as a user can execute an infinite number of phrases in a dialog. Alternatively, conversational interfaces use NLP algorithms to infer the \u201cuser intent\u201d of a specific phrase and execute the corresponding action. From that perspective, conversational interfaces use probabilistic vs. traditional deterministic models.\n\nIn mobile and web UIs, each user action is abstracted using a finite (and typically very small) number of UI constructs. There are only a reduced number of ways in which you can place an order in Amazon.com In conversational user interfaces, the same action can be expressed by an infinite number of sentences. That makes conversational user interfaces much more challenging to model and implement.\n\nAll constructs of mobile and web UIs are encapsulated in a version of a mobile app or website respectively. If the UI of a mobile app or a website needs some changes, that typically building and distributing a new version of the solution. Well-designed conversational interfaces should always be improving the syntactic and semantics to interact with users. A conversational UI platform will typically record all phrases sent by users and enable self-training algorithms to improve the efficiency of the conversation over time. From that perspective, a conversational UI is always-evolving its capabilities.\n\nMobile and web UIs are modeled as finite state machines with a number of screens organized in a structured flow. In that model, a user can only arrive to a screen following a well-known path included in the flow. contrasting with that model, conversational interfaces followed an unstructured flow. Like in a human dialog, conversational interfaces should be designed to support arbitrarily combination of natural language phrases. This characteristic is key when modeling the expected user flow in conversational interfaces."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-key-reasons-why-google-clouds-strategy-continues-to-win-in-the-enterprise-2c3840ec7e35?source=user_profile---------388----------------",
        "title": "Five Key Reasons Why Google Cloud\u2019s Strategy Continues to Win in the Enterprise",
        "text": "A few days ago, CNBC broke the news that PayPal is favoring Google Cloud to become its cloud provider. Although the report made it clear that PayPal hasn\u2019t yet made a final decision, the market interpreted the news as another strong validation for Google Cloud.\n\nWhether the agreement with PayPal materializes or not, this is another sign that Google Cloud is becoming more and more competitive under Diane Green\u2019s leadership. In just a few months, Google Cloud has announced several high profile customers including Home Depot, Spotify and Snapchat just to name a few.\n\nThe impressive progress of Google Cloud in the enterprise space is result of a strategy focused on narrowing the distance with market leaders such as Amazon and Microsoft while also aggressively investing and taking a leadership position in new technology fronts. There are many things that Google Cloud is doing well. Let\u2019s list a few:\n\nIn recent months, Google Cloud has aggressively invested un areas such as compliance and security which are essential to win in highly regulated enterprise environments. Additionally, Google Cloud has been able to establish key partnerships to expand its trusted distribution channels within the enterprise.\n\nThe prices for IaaS and PaaS technologies is a race to the bottom but Google Cloud regularly remains as the most affordable PaaS in the market. The aggressiveness of the pricing model has allowed Google Cloud to become extremely competitive in the enterprise market.\n\nBy powering large scale consumer platforms such as Snapchat, Spotify and now possibly PayPal, Google eCloud is establishing credibility as a highly scalable and robust cloud platform. That level of credibility is essential to penetrate the enterprise market.\n\nGoogle has made it clear that machine learning and artificial intelligence will be the cornerstone of the future of Google Cloud. The investment in these new areas has been a strong differentiator of Google Cloud compared to some of its competitors.\n\nThe press continues to focus on Google Cloud rivalry with AWS. However, it is very clear that the core of Google Cloud\u2019s current strategy has been focused on displacing IBM\u2019s Bluemix and Microsoft\u2019s Azure as the 3rd and 2nd PaaS platforms in the market respectively.\n\nThere are other reasons that we can list as of why Google Cloud is becoming successful within enterprise customers but these 5 are certainly relevant. For now, Diane Green\u2019s strategy is certainly having a visible positive impact."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-questions-about-an-iot-first-os-ae58e7203275?source=user_profile---------389----------------",
        "title": "Five Questions About an IOT-First OS \u2013 Jesus Rodriguez \u2013",
        "text": "In a previous post, we discussed some of the key characteristics of an IOT-First operating system(OS). That post was inspired by the news that Google seems to be working on a brand new OS optimized for IOT capabilities. \n\nBeyond the initial hype, the possibility of a new OS for IOT raises some very interesting questions that are worth discussing. Here are some of the questions that I came up with while thinking about this topic:\n\nWill we see a universal IOT-First OS or OSs optimized for different IOT categories?\n\nDifferent IOT categories such as drones or autonomous vehicles have evolved using very unique hardware. From that viewpoint, is worth questioning if a universal IOT-First OS will be such a good idea. Alternatively, we can see different OSs addressing various IOT categories such as drones, wearable\u2019s or home sensors.\n\nWhat is the right user interface for an IOT-First OS?\n\nMobile brought new user interface concepts based on touch, notifications, apps etc. However, that UI model might not be the best fit for IOT scenarios. It would be interesting to see whether an IOT-First OS leverages an extension of the mobile UI concepts or create a brand new user interface model.\n\nCan we avoid recreating the Android fragmentation problem in IOT\n\nThe number of IOT device manufacturers in the market makes a strong case for an open source distribution model of an IOT-First OS. However, that approach can also create a lot of fragmentation in the IOT ecosystem as each manufacturer will be able to customize and distribute its own version of the OS.\n\nIf Google launches an IOT-First OS, will Amazon and Microsoft follow?\n\nGoogle, Microsoft, IBM and Amazon are immersed on a frantic battle to dominate the cloud including the IOT platform services space. If Google launches an IOT-First OS, it would be interesting to see whether Microsoft, and Amazon become partners to attempt to deliver their own competitive products.\n\nWhat will Apple do?\n\nFollowing the previous question, Apple has dominated the latest wave of innovation in operating systems but not without a though competition with Google. With Google venturing into the IOT-First OS space, it would be interesting to see how/if it influences Apple\u2019s position."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-wants-an-iot-first-os-how-would-it-look-like-93141d83103?source=user_profile---------390----------------",
        "title": "Google Wants an IOT-First OS. How Would it Look Like?",
        "text": "In recent days, there have been some speculation in the market about Google starting an effort for creating a new operating system (OS) optimized for the internet of things (IOT). The news were somewhat surprising as Google\u2019s efforts around IOT have been centered around the Android platform. However, if we did did a little deeper, the premise of a new OS starts to make sense.\n\nGoogle\u2019s initial efforts to adapt Android to IOT scenarios seems logical as they have been mostly focused on wearable\u2019s. The similarities between the user experiences in mobile and wearable\u2019s as well as the part that many wearable\u2019s rely on mobile apps as the main user interface mechanism make Android an ideal candidate to power the first generation of wearable\u2019s. . However, the Android model falls short when we start considering other IOT scenarios such as industrial enterprise solutions or autonomous vehicles. In order to become a viable option for IOT , an OS must have some very specific characteristics. Here are a few ideas:\n\n\u2014 Adapter for device components: An IOT OS should provide an adapter mechanism that allow manufacturers to integrate their IOT devices with the OS.\n\n\u2014 Frameworks for well-known device components: In addition to the adapter framework, an IOT-First OS should include default functionality for well-known components such as camera, accelerometer, clock and other key components of IOT devices.\n\n\u2014 In-Device Application framework: An IOT-First OS should enable the mechanisms for developing, deploying and running applications in an IOT device. It would be interesting to see if the \u201capp\u201d metaphor of the mobile OS still remains in the IOT era. \n\n \u2014 Access to relevant external data sources: An IOT-First OS should abstract the access top data sources that are commonly used in IOT solutions. Weather forecast is a great example of a commonly used data source in IOT applications.\n\n\u2014 IOT cloud services integration: In the same way that mobile OS such as Android and IOS provide integration with a default group of cloud services, an IOT-First OS should provide out-of-the-box integration with cloud services from platforms like AWS, Azure, Google Cloud or Bluemix.\n\n\u2014 User Interface: While we all agree that an IOT-First OS should provide some sort of user interface, it would be interesting to see if this one is a brand new concept or simply an extension of the \u201capp\u201d model used in mobile OS.\n\nThere are just some of the concepts I think could be relevant in an IOT-First OS. The idea seems incredibly intriguing but there are some important questions that need to be address. More about that in a future post :)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-industrial-enterprise-space-is-exploding-4ba3adf1e8be?source=user_profile---------391----------------",
        "title": "The industrial enterprise space is exploding. \u2013 Jesus Rodriguez \u2013",
        "text": "From innovative startups to well-established incumbents, the enterprise is being reimagined from the ground up for the IOT era. Despite the unquestionable levels of innovation in the enterprise IOT space, the process of selecting an IOT platform remains a very complex endeavor for most enterprises. Factors such as lack of familiarity with IOT architectures, limited number of IOT engineers as well as the intrinsic complexities of IOT solutions make the evaluation of IOT platforms very challenging for most organizations.\n\nThe enterprise IOT space shares many of the common characteristics of fast growing enterprise software markets: it is incredibly crowded but only a small number of IOT platforms can demonstrate real traction in terms of customers, partnerships and revenue. From the large number of IOT platforms in the market, we can group the leaders in some of the following categories:\n\n\u2014 IOT startups that have achieved meaningful market share and are well capitalized to compete with the incumbents. \n\n \u2014 Industrial powerhouses that have built robust IOT platforms leveraging their unique domain expertise. \n\n \u2014 Enterprise software and cloud platform providers that have expanded their offering with robust IOT services.\n\nWhile the IOT platform market is incredibly crowded, there is a small group of companies that have achieved market leadership in the space. Here is an initial list:\n\nComparing these platforms could be an incredibly challenging exercise as they overlap in many capabilities. However, we think a starting point could be understanding the key strengths and weaknesses of each platform. Let\u2019s take a look:\n\n-Key Strenghts: Xively as developed a very impressive customer and partner base. Also, the experience of getting up and running and operating the Xively platform is relatively simple compared to its competitors.\n\n-Key Weaknesses: Xively provides very limited extensibility models to incorporate new capabilities into the platform. Additionally, Xively\u2019s cloud-only model could result limited in some industrial scenarios.\n\n-Key Strenghts: thingWorx\u2019s team bring very deep knowledge and expertise of the industrial enterprise solutions. ThingWorx has also achieved meaningful traction with partners and customers. Additionally, the ThingWorx platform provides unique capabilities such as model driven development and machine learning.\n\n-Key Weaknesses: The complexity of the setup as well as the lack of extensibility are two of the main limitations of the ThingWorx platform.\n\n-Key Strenghts: IBM\u2019s Watson IOT platform offers several technical competitive advantages such as cognitive computing and stream analytics. IBM\u2019s strong professional services arm and expertise across different industries is also a strong plus.\n\n-Key Weaknesses: Watson IOT\u2019s developer community is still relatively small. Also, the capabilities of the Watson IOT platform is very limited on on-premise environments.\n\n-Key Strenghts: Predix is, arguably, the IOT platform that has achieved the biggest market traction reporting around $9 billion in revenue last year. The open source distribution model based on Cloud Foundry is also a strong plus.\n\n-Key Weaknesses: The infrastructure setup and operational model of Predix results very complex for most organizations embarking in their IOT journey.\n\n-Key Strenghts: AWS IOT is tightly integrated with other services in the AWS platform which facilitates the implementation of really sophisticated IOT solutions. AWS broad partner and developer communities are also a strong asset of its IOT offering.\n\n-Key Weaknesses: AWS IOT is a cloud-only platform which results very limiting in some IOT scenarios.\n\n-Key Strenghts: Azure IOT Suite is deeply integrated with other services in Microsoft\u2019s Azure platform which facilitates the implementation of really sophisticated IOT solutions. Microsoft\u2019s strong developer, partner and enterprise sales presence is also a strong plus.\n\n-Key Weaknesses: Azure IOT Suite is still not equipped to operate in on-premise environments which results limiting in many IOT scenarios. Additionally, the current release of Azure IOT Suite is still missing several important building blocks of IOT solutions."
    },
    {
        "url": "https://medium.com/@jrodthoughts/5-key-elements-of-a-blockchain-platform-6b203d5c1f51?source=user_profile---------392----------------",
        "title": "5 Key Elements of a Blockchain Platform \u2013 Jesus Rodriguez \u2013",
        "text": "The evolution of blockchain technologies is one of the most fascinating developments in the modern technology ecosystem. While blockchain became relevant as the infrastructure powering the bitcoin cryto-currency; it has evolved as one of the fastest growing application development paradigms of recent years. However, despite the its popularity, blockchain platforms need to cross a remaining chasm in order to become mainstream development technologies.\n\nToday, the blockchain ecosystem has evolved from a backend infrastructure to a sophisticated infrastructure that powers the implementation of the next generation decentralized applications. From development platforms like Ethereum to blockchain as a service (BaaS) platforms or even proprietary implementation of private blockchains like IBM\u2019s Hyperledger, the blockchain technology ecosystem seems to be exploding. However, for the most part, blockchain technologies still need to capture the hearts and minds of mainstream software developers. In order to address that challenge, the industry needs a blockchain app development platforms that includes some of the fundamental building blocks of modern software applications. What are the key capabilities that should be included in such a platform? Let\u2019s explore a few ideas.\n\nA blockchain platform should abstract the implementation of some of the main types of software applications like mobile, web, background services, etc. Providing a simple model to build those types of applications will lower the entry point for mainstream developers venturing into the blockchain world.\n\nMiddleware capabilities have been an important element of application development technologies for the last two decades. similarly, blockchain applications will require traditional middleware patterns such as message passing, pub0-sub communication or even integration with line of business systems. Technologies such as Microsoft\u2019s Project Bletchey are already starting to implement these patterns.\n\nMonitoring and analyzing the runtime behavior of applications is another important capability of the next generation of blokchain platforms. The decentralized nature of the blockchain drastically increases the complexity related to efficiently monitoring and tracking analytics of blockchain solutions. As a result, analytics is becoming an essential element of the value proposition of the new group of blockchain platforms.\n\nSimplifying the lifecycle management of blockchain applications is another relevant aspect of these type of platforms. \n\nApplication deployment, testing, monitoring, packaging are some of the ALM capabilities that should be an important element of the next generation of blockchain platforms.\n\nBlockchain technologies are likely to be a component and not the entire backed of software applications. As a result, blockchain platforms can benefit from the interoperability with mainstream technologies such as line of business systems, databases, popular deployment frameworks, cloud infrastructures and other components of modern software applications."
    },
    {
        "url": "https://chatbotsmagazine.com/the-bot-market-is-exploding-but-it-could-be-challenging-for-startups-part-ii-opportunities-1fe65cb07a05?source=user_profile---------393----------------",
        "title": "The Bot Market is Exploding but it Could be Challenging for Startups Part II: Opportunities",
        "text": "The first part of this article explored some the challenges for startups entering the bot technology market despite the rapid growth and the abundance of venture capital in the space. Specifically, we listed five potential hurdles that startups can experience in the bot market:\n\n\u00b7 Competition with the messaging platform providers which control distribution\n\n\u00b7 The market sees bots as extensions of mobile apps which makes it harder for new bots to gain traction\n\n\u00b7 Incumbents like Microsoft or Facebook have entered the game really early with strong technology propositions\n\n\u00b7 The enterprise market remains relatively inactive in the bot space\n\nThese are, without a doubt, hurdles need to be analyzed by startups and investors entering the bot market. Despite the challenges, bots have created new opportunities in several segments of the market that could experience high growth in the near future.\n\nNatural Language Processing(NLP) and Natural Language Understanding(NLU) are becoming a foundational element of bot technologies. While incumbents like IBM, Microsoft, Amazon, Facebook or Google are actively competing in the space, there are plenty of opportunities for startups that can simplify the experience of authoring and processing conversations and integrate them with bot frameworks.\n\nDevelopment platform are a tricky segment of the bot market for startups as there are over a dozen very popular messaging platforms that have released their own bot development frameworks. However, I believe there is still opportunity in the market specially for startups that pioneer new forms of user interface and end to end development models for bots.\n\nIn addition to the development frameworks, backend services in areas such as integration, data storage, analytics, security, etc are required by many bot solutions. Even though is expected that PaaS incumbents will provide relevant bot backend services solutions, there might be a window for startups operating in the space.\n\nAnalytics and performance monitoring is an exciting area of opportunity in the bot market. Bot\u2019s new user interface models based on conversations and simple UI constructs requires new forms of monitoring and analytics. For instance, a bot analytic platform should be able to track the sentences produced in recent user interactions, analyze sentiment, concepts, determine error processing rates, etc. Those unique characteristics are likely to catalyze a new group of startups in the space.\n\nBot security models are likely to become increasingly relevant if you consider that they could be used to protect sensitive conversations between users and systems. While the security architectures of the web and mobile focused in areas such as authentication, authorization and federation; the opportunities in bots security technologies are likely to be in areas such as data privacy, compliance or access control.\n\nEven though the enterprise market remain relatively passive in terms of the adoption of bot technologies, I believe there is opportunity for startups leveraging bots in specific industry domains. Areas such as education, hospitality, public safety or field services seems like a great fit for the adoption of bot solutions. Startups with the right industry expertise have an opportunity to capitalize in this nascent."
    },
    {
        "url": "https://chatbotsmagazine.com/the-bot-market-is-exploding-but-it-could-be-challenging-for-startups-part-i-d1742aeca774?source=user_profile---------394----------------",
        "title": "The Bot Market is Exploding but it Could be Challenging for Startups. Part I",
        "text": "Dexter, the bot platform incubated by Betaworks, announced last week that it had raised $2.3 million to accelerate its bot platform. Originally started as an workflow automation platform, Dexter recently shifted its focus onto the bot market. Dexter\u2019s funding is the latest addition on a large series of VC funding events in the bot space. Despite the VC appetite for bot technology companies, the bot market might be proven to be a tough environment for startups.\n\nThe previous statement doesn\u2019t pretend to be an apocalyptic prediction for the bot startup ecosystem. Quite the opposite, I am incredibly optimistic about the potential of the space. However, differently from mobile or IOT, the bot technology space exhibits some very unique characteristics that could result in a challenging ecosystem for startups.\n\nMessaging platforms like Facebook Messenger, Telegram or WeChat are becoming some of the most popular runtimes for bots. These platforms play a dual role as distribution channels but also as bot technology providers. By controlling distribution, the messaging platform incumbents are in a unique position attract developers and become more and more dominant in the space.\n\n99% of Bots Will be Hard to Monetize\n\nOne of the challenges of the bot technology space is that is relying on the same monetization channels established by the mobile and web markets. In other words, until now the bot market hasn\u2019t developed new monetization channels. If we draw a parallel to the mobile space, we should assume that the vast majority of bot startups will have a challenge monetizing or developing meaningful user traction.\n\nMany Bots are Just Extensions of Mobile Apps\n\nIn this nascent bot market, a significant percentage of the popular bots have been extensions of well-established mobile applications. Those brands are attempting to expand the engagement model of their mobile apps to a new channel. That model has a negative side effect for bot startups as most of the popular markets that were uncovered in the mobile market will remain unavailable to bot startups.\n\nDifferently from mobile, the incumbents have entered the market since the very beginning with innovative technology offerings. In the current market, incumbents are leading the two main areas of the bot market: natural language processing (NLP) technologies and bot development platforms. Consequently, bot technology startups will be forced to compete with large technology incumbents since the very beginning which could result incredibly challenging.\n\nThe enterprise has been a significant element in the development of the mobile and web markets. In the case of bot technologies, it is unclear about the path to penetrate the enterprise space. While there are many industry scenarios that can be improved with bot technologies, there are many challenges that need to be overcome to establish bots in the enterprise.\n\nDespite many of the factors listed in this article, we believe there are a few areas that should be interesting for bot startups. More about that in the next article."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-necessary-evil-enterprise-iot-needs-a-new-middleware-8532c4cfad5c?source=user_profile---------395----------------",
        "title": "The Necessary Evil: Enterprise IoT Needs a New Middleware",
        "text": "The original article was published at CIO.com\n\nThe Internet of Things (IoT) has become one of the fastest growing technology trends in the enterprise in the last few years. From productivity wearables to extremely sophisticated industrial deployments of sensors, enterprise IoT solutions are dominating the technology agenda of modern enterprises. The emergence of enterprise IoT has brought together a new set of integration challenges connecting the new world of smart devices with existing line of business systems.\n\nThe integration challenges created by enterprise IoT topologies have been unprecedented in the enterprise. Never before have companies encountered integration scenarios involving such a large number of endpoints, such large volumes of data, and such heterogeneous environments. Quickly, enterprises are discovering a new reality: IoT requires a new type of middleware\n\nWith decades of history implementing expensive integration technologies, enterprises are sure to be hesitant about embracing a new middleware stack for IoT solutions. However, after examining the characteristics of enterprise IoT solutions, organizations quickly realize that they require very unique integration capabilities that are not available in traditional middleware solutions.\n\nThe argument that enterprise IoT requires a new type of middleware is far from being just a theoretic exercise. In the last few years, the industry has produced a series of technologies that can be considered the first generation of enterprise IoT middleware platforms.\n\nDeveloped by the National Security Agency (NSA), Apache NiFi is a platform for real time data integration. Many of the capabilities of NiFi such as real time multi-directional communication, data provenance, seamless scalability, and support for IoT protocols has quickly made it a favorite for IoT data integration solutions.\n\nIn August 2012, Hortonworks announced the acquisition of Onyara, the company behind Apache Nifi. Shortly after, Hortonworks announced a commercial distribution of Apache NiFi known as Hortonworks DataFlow (HDF). From a functional standpoint, DataFlow expands the Hortonworks platforms with stream data processing and integration. The addition of the DataFlow platform puts Hortonworks in a great position to be the first big data platform vendor to make a smooth transition into the IoT space.\n\nKaa is one of the most popular open-source IoT platforms focused on providing a complete set of backend capabilities for building and managing IoT solutions. Integration is a key element of the Kaa platform providing seamless communication between smart devices and backend systems.\n\nOne of the most decorated IoT projects in the market, OpenRemote offers an open source IoT middleware that supports most of the relevant protocols used by smart devices. OpenRemote also includes very sophisticated integration management capabilities.\n\nmicroServiceBus is a new and exciting entrant in the IoT integration space. Built on the Microsoft Azure platform, microServiceBus provides bi-directional integration capabilities between smart devices and enterprise systems. The platform seems to be designed for enterprise IoT from the ground up and includes sophisticated capabilities such as management, monitoring, security, heterogenous deployment topologies, and other fundamental elements of enterprise IoT solutions.\n\nIntegration is called on to become one of the pillars of enterprise IoT solutions. While still early, we can already see the first generation of platforms optimized to address the integration challenges in enterprise IoT topologies. As a technology trend, IoT middleware will become the 4th generation enterprise integration solutions.\n\nThe first generation of mainstream enterprise integration platforms was based on extract-transform-load (ETL) solutions. The service oriented architecture (SOA) movement brought us the enterprise integration servers and the enterprise service bus (ESB) integration platforms. The cloud triggered the integration platform as a service (iPaaS) trend. Now IoT is redefining the enterprise integration landscape.\n\nWe just need a better acronym \u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/intel-is-dead-serious-powering-the-next-hardware-revolution-and-these-technologies-prove-it-40dc4b5c6962?source=user_profile---------396----------------",
        "title": "Intel is Dead Serious Powering the Next Hardware Revolution and These Technologies Prove it",
        "text": "The Intel Developer Forum(IDF) is running this week in San Francisco. The two day event serves to highlights Intel\u2019s latest innovations for developers and to provide a glimpse to the technologies that the chip maker is expected to release in the near future. Despite its relevance, recent editions of IDF have failed to create excitement within the developer community and have reinforced the stigma that Intel was falling behind innovative rivals like QUALCOMM or NVIDIA. However, this week\u2019s IDF have brought the excitement back to Intel\u2019s developer community with a clear message: Intel wants to power the next hardware revolution.\n\nAfter missing the mobile computing wave, Intel is set on no repeating the same mistakes and is rapidly jumping into new trends such as drones, IOT and virtual reality. More importantly, Intel is set to make developers an important element of its next generation of products. Certainly, that seems to be the intention of yesterday\u2019s announcements. Let\u2019s take a look:\n\nJoule is a new board designed to prototype and implement high performance computer vision products. Joule\u2019s goal is to provide a seamless transition from prototype to at-scale implementations of machine vision heavy solutions like robotics or drones. At its core, Joule includes a maker board with an Intel RealSense deep sensing camera optimized for IOT scenarios.\n\nProject Alloy is Intel\u2019s entrance in the \u201cmerged reality space\u201d. Intel\u2019s version of this new industry buzzword includes involves an untethered, wireless VR headset with depth sensing and five-finger tracking thanks to a forward-facing RealSense camera that enables users to move through a space and manipulate it using their hands.\n\nAnother highlight of the first day of IDF was the Aero, a new quadcopter drone aimed at software developers. The Aero is powered by a new Compute Board running a Linux OS with support for Real Sense cameras. The board is also equipped with AirMap technology to enable capabilities such as autonomous flying."
    },
    {
        "url": "https://medium.com/@jrodthoughts/why-workday-partnered-with-ibm-cloud-67e34ff85bf0?source=user_profile---------397----------------",
        "title": "Why Workday Partnered with IBM Cloud? \u2013 Jesus Rodriguez \u2013",
        "text": "Yesterday, Workday and IBM announced a strategic partnership to run Workday\u2019s development and testing services on IBM\u2019s cloud. The seven-year agreement represents a major win by IBM Cloud particularly at a time in which Wall Street was questionings IBM\u2019s abilities to win major cloud customers against market learners like AWS or Microsoft Azure. The agreement is even more relevant if we consider that Workday has been a very large AWS customer for the last few years.\n\nBeyond the initial hype, there are a few interesting elements that might help to explain Workday\u2019s decision to partner with IBM Cloud. The initial phase of the agreement will focus on leveraging IBM Cloud part of Workday development and testing infrastructures which indicates that the production workloads will remain on AWS. Also, if we look at the agreement from Workday\u2019s perspective, IBM Cloud brings a number of tangible benefits that are hard to match by Amazon, Google or Microsoft.\n\nBy expanding beyond AWS, Workday is adopting a multi-cloud strategy which has been proven by many internet giants like Netflix or eBay. Running development and testing workloads on IBM Cloud will offer Workday a more cost-effective and flexible model than relying on AWS IaaS or running its own infrastructure.\n\nThe IBM-Workday partnership is more about IaaS than PaaS. The acquisition of Softlayer, drastically expanded the IaaS capabilities of IBM Cloud. Today\u2019s IBM Cloud has a global infrastructure that expands over 50 different locations in 17 countries and 6 continents. While IBM\u2019s Bluemix is still running behind AWS and Azure in terms of capabilities and market share in the PaaS market, IBM Cloud can be considered a serious contender in the IaaS space.\n\nConsulting services can be considered the X factor in the Workday-IBM partnership. IBM\u2019s recent acquisitions of preferred Workday implementation services like Meteorix and Bluewolf puts it in a unique position to deliver sophisticated Workday solutions\n\nI believe the cognitive capabilities of IBM Cloud are an important element of the IBM-Workday long term strategy. Workday has been actively investing in machine learning and artificial intelligence to the point of launching a venture fun dedicated to machine learning and data science capabilities on the Workday platform.\n\nFollowing Oracle\u2019s acquisition of Netsuite, Workday was listed as one of the M&A targets by Oracle competitors like SAP, Microsoft or, surprise, IBM. By establishing a strategic alliance with IBM, Workday solidifies its position as a standalone company and makes it harder for other enterprise software incumbents to pursue acquisition options."
    },
    {
        "url": "https://medium.com/@jrodthoughts/is-edge-computing-the-next-battleground-for-iot-6d43361c599c?source=user_profile---------398----------------",
        "title": "Is Edge Computing the Next Battleground for IOT? \u2013 Jesus Rodriguez \u2013",
        "text": "This weekend I was reading about the upcoming release of the Onion Omega2, a $5 computer specialized for IOT scenarios. The Omega2 is about the size of a credit card, can run a full version of Linux, enable connectivity via WiFi or Bluetooth and support different programming language interfaces. This IOT-specialized computer is the latest development on an old technology trend that is been revitalized with the emergence of IOT: \u201cedge computing\u201d.\n\nAs its name indicates, edge computing moves the frontier of software applications, data and services to logical extremes of a network. This model contrast with paradigms like cloud computing that focused on centralizing computing models. While this computing paradigm has been around for a while is just recently that has come back to the forefront of technology innovation.\n\nEdge computing is an essential element of IOT solutions. In many aspects, edge computing can be considered in IOT to be the equivalent of frontend technologies in the mobile and web paradigms. In that respect, edge computing enables a series of capabilities of perform autonomous computing tasks on individual nodes in an IOT network while also integrating with the centralized IOT hub.\n\nEdge computing models are relevant in any type of IOT applications but are particularly important in decentralized IOT architectures. In those models, the absence of a centralized hub should make nodes in an IOT network to be able to operate autonomously and interact with each other without depending on a centralized authority. From vehicle telematics to the systems operating aircrafts and oil and gas platforms, decentralized IOT is a fast growing technology area that doesn\u2019t get the same level of publicity of centralized IOT platforms.\n\nWith the race for backend IOT platforms being consolidated to the handful of vendors, edge computing will become a new area of focus for IOT startups. Conceptually, edge computing has the opportunity to become the next big computing revolution powering entire industries such as robotics, industrial enterprise or autonomous vehicles. For now, the innovation in edge computing is reduced to a number of platforms like Arduino, RasperryPI or Omega2. Building on the foundation provided by those technologies, we can expect edge computing to become one of the most important IOT battlegrounds of the next decade."
    },
    {
        "url": "https://chatbotsmagazine.com/these-five-platforms-will-make-your-bots-language-intelligent-634556750abd?source=user_profile---------399----------------",
        "title": "These Five Platforms Will Make Your Bots Language-Intelligent",
        "text": "Natural language is a fundamental element of bot technologies. As a result, there has been a direct correlation between the evolution of bot platforms and natural language processing platforms. While the evolution of bot technologies is been mostly driven by the messaging platform vendors such as Facebook or WeChat, the main advancements in natural language processing technologies seems to be coming from the cloud platform and service providers like Google or IBM. As a result, most bot developers spend time integrating their frontend bot applications with natural language processing services provided by a different platform.\n\nFrom a conceptual standpoint, there are two main natural language programming techniques that have become popular with bot technologies:\n\n\u00b7 Natural Language Processing (NLP): In the artificial intelligence(AI) context, NLP is the overarching umbrella that encompasses several disciplines that tackle the interaction between computer systems and human natural languages. From that perspective, NLP includes several sub-disciplines such as discourse analysis, relationship extraction, natural language understanding and a few others language analysis areas.\n\n\u00b7 Natural Language Understanding (NLU): NLU is a subset of NLP that focuses on reading comprehension and semantic analysis.\n\nThe combination of NLP and NLU technologies is becoming increasingly relevant on different software areas today including bot technologies. While there are many vendors and platforms focused on NLP-NLU technologies, the following technologies are becoming extremely popular within the bot developer community.\n\nThe Watson Developer Cloud provides several services focused on language processing. Watson\u2019s Conversation Service(WCS) is specially focused on automating interactions between systems and end users. Using WCS users can define NLP aspects such as intents, entities and simulate entire conversations. WCS is typically used in conjunction with other Watson NLP services such as Alchemy Language or Natural Language Classifier.\n\nFor more: Building an IBM Watson Powered AI Chatbot\n\nMicrosoft\u2019s Language Understanding Intelligence Service(LUIS) is a component of the Microsoft Cognitive Services focused on creating and processing natural language models. LUIS provides a sophisticated toolset that allow developers to train the platform in new conversation models. LUIS can also be used in conjunction with other text processing APIs in MCS such as linguistic analysis and text analytics. The platform provides a deep integration with Microsoft\u2019s Bot Framework and can be used by other bot platforms.\n\nGoogle Natural Language(NL) API is a recent addition to Google Cloud focused on NLP and NLU capabilities. The NL API enables capabilities such as intent-entity detection, sentiment analysis, content classification and relationship graphs. The NL API also includes sophisticated tooling for training and authoring new NL models. Google NL platform is actively used by several high profile services such as Google\u2019s Assistant.\n\nWit.ai is the platform behind the NLP-NLU capabilities of Facebook Messenger platform. Facebook acquired Wit.ai in January 2015 and, since then, has rolled out major updates to the platform. One of the best capabilities of Wit.ai is the sophisticated toolset that can be used to train the platform in new conversation models as well as monitoring the interactions between users and the platform.\n\nApi.ai provides a platform that allow developers to design and implement conversational interfaces that can be integrated into external applications like bots. Functionally, Api.ai includes capabilities such as speech recognition, fulfillment and NLU as well as a robust management toolset. Api.ai provides integration with several bot platforms and is particularly popular within the Slack community.\n\nFor more on this, check these out\u2026"
    },
    {
        "url": "https://medium.com/@jrodthoughts/artificial-intelligence-and-machine-learning-are-entering-a-time-of-massive-market-consolidation-abc7f820d08e?source=user_profile---------400----------------",
        "title": "Artificial Intelligence and Machine Learning are Entering a Time of Massive Market Consolidation",
        "text": "Yesterday, Intel announced the acquisition of machine learning startups Nervana Systems for a rumored $400M. This move is intended to improve Intel\u2019s artificial intelligence(AI) and machine learning (ML) capabilities in its next generation architecture. The acquisition follows the news of Apple\u2019s acquisition of Seattle-based AI startup Turi for about $200M. These series of M&A events are signaling that we are entering a time of consolidation in the AI and ML markets.\n\nThe volume of M&A activity in the AI-ML space has to be one of the most active in recent technology trends. Typically, technology markets require certain level of maturity and development before entering a phase of consolidation. From that perspective, the AI-ML market can be considered an outlier as it has triggered large levels of M&A activity since the very early days. The following matrix summarizes some of the high profile AI-ML acquisitions of 2016.\n\nThe M&A trends in the AI-ML space are likely to accelerate in the near future. With AI becoming an increasingly important competitive differentiator, the frenzy for AI-ML talent and technology is not likely to stop any time soon. More importantly, the M&A activity in the AI-ML markets is not constrained to a specific sector. The following list examines some of categories of companies that are likely to remain very active acquiring AI_ML talent:\n\n\u00b7 Internet Companies: Internet power-houses like Twitter, Facebook or Amazon are actively investing in AI-ML technologies as a competitive differentiators. Some of those companies have very healthy balance sheets from their performance in the public markets which should make them very active acquirers.\n\n\u00b7 Traditional Enterprise Software Vendors: Companies like SAP or Oracle are running behind in the AI-ML space and are likely to bridge that gap with acquisitions.\n\n\u00b7 SaaS Vendors: Salesforce has been incredibly aggressive investing in AI-ML capabilities. Other SaaS platforms like Workday, Box or Zendesk could also become acquisitive in the space.\n\n\u00b7 Cloud Platform Providers: Microsoft, Google, Amazon and IBM have been rapidly building their AI-ML capabilities. With large cash reserves, these companies are likely to be active acquirers in the AI-ML market.\n\n\u00b7 Chip-Device Manufacturers: GPU-based architectures are at the forefront of the AI-ML battle. Intel, Qualcomm, NVIDIA are some of the companies competing for dominance in the space and they should be an attractive destination for AI-ML startups.\n\n\u00b7 Large System Integrators: Companies like Accenture, Wipro or Infosys have recently announced new services and solutions in the AI-ML space. Those vendors are likely to rely on proprietary software platforms as a unique differentiators and could be active acquirers in the space.\n\n\u00b7 Big Data Platform Providers: The next chapter of big data platform providers like Cloudera, Hortonworks or MapR is certainly going to be influenced by AI-ML. These companies can also become more acquisitive in the AI-ML markets."
    },
    {
        "url": "https://medium.com/@jrodthoughts/5-reasons-why-enterprise-iot-is-a-tough-market-for-startups-c1fdf13ac80d?source=user_profile---------401----------------",
        "title": "5 reasons why enterprise IoT is a tough market for startups",
        "text": "The original article was published at CIO.com\n\nThe IoT platform market has been growing at a record pace. Just a couple of years ago, the market only counted a few early vendors that were starting to court enterprises and device manufacturers. Today, the IoT platform space is a hypercompetitive market encompassing a broad set of companies from telecommunication operators to platform as a service (PaaS) providers. However, for being such as fast-growing, emerging market, the enterprise IoT platform space hasn\u2019t seen a large number of startups become relevant. Today, the bulk of the innovation in that arena appears to be coming from big corporate labs instead of garages.\n\nThe patterns in the enterprise IoT platform sector certainly challenge the conventional wisdom of how fast-growing enterprise technology markets evolve. Traditionally, the initial wave of innovation and early adoption in an enterprise software market is driven by innovative startups that are able to move faster than the incumbents. As the market develops, incumbents enter the fray, relying heavily on acquisitions helping to consolidate the market. That wave of M&A activity is a clear sign of a mature enterprise software market that is approaching its peak. Subsequently, the market evolves into a phase dominated by the incumbents and a handful of startups that survived the M&A phase and became strong independent companies.\n\nFrom every angle, the enterprise IoT platform space is challenging the traditional enterprise software market cycle. Almost since its inception, incumbents like GE, Microsoft, IBM and Amazon are leading the innovation in the enterprise IoT market. More importantly, despite a handful of early platform vendors like Xively or ThingWorx, the IoT platform market is lacking startups that can claim significant market share. Here\u2019s a look at the factors contributing to the enterprise IoT market\u2019s unique dynamics.\n\nEnterprise IoT systems are incredibly complex and often involve integration with existing enterprise technologies and processes. Consequently, many enterprise IoT systems require a significant level of professional services in the form of consulting and implementation assistance. This factor is challenging for many startups that don\u2019t have the resources to invest in large professional services groups or haven\u2019t developed the sufficient number of strategic alliances with system integrators and IoT professional services firms.\n\nPartnerships with device manufacturers are slow and challenging\n\nMany industrial or enterprise IoT systems start with the goal of deploying specific types of hardware and sensors that can optimize enterprise business processes. In these scenarios, hardware manufacturers can be incredibly influential in recommending and selecting an enterprise IoT platform for the solution. This dynamic typically favors enterprise IoT incumbents like GE or IBM that have spent significant resources developing strong strategic alliances with device manufacturers and optimizing the interoperability of their platforms with those specific devices. IoT platform startups would have to devote precious resources to nurture relationships with smart device manufacturers so they are not at a disadvantage with the incumbents in the space.\n\nDevelopers of industrial IoT systems are trying to reimagine existing mission-critical business processes and solutions or implement brand-new business processes. From this standpoint, enterprise IoT systems typically require a certain level of domain or industry knowledge in order to have a meaningful impact. Companies like GE, IBM or Microsoft have decades of experience across dozens of industries \u2014 which is very relevant in enterprise IoT scenarios. In contrast, enterprise IoT platform startups often have to travel the tortuous path of developing strong credibility in specific industries before they are considered serious contenders in the enterprise IoT segment.\n\nEnterprise IoT solutions are notoriously complex and many times require significant investment from the buyer. This translates into long sales cycles and never-ending pilots and proof-of-concept implementations. Many of the self-service models that disrupted other enterprise software markets simply don\u2019t apply in the enterprise IoT space. Over the years, incumbents have mastered the long sales cycle game as a way to challenge leaner and more innovative startups in that market. In the enterprise IoT market, long sales cycles are the rule and not the exception. Consequently, enterprise IoT startups are forced to recruit B2B-savvy sales executives to be effective competing with bigger companies.\n\nUnlike other enterprise software markets, incumbents like IBM, Microsoft, Amazon and GE managed to enter the IoT market from the very beginning. More impressively, these incumbents managed to build incredibly innovative platforms that can compete with some of the more advanced offerings of IoT startups. Beyond companies like Xively, ThingWorx and a handful of other early IoT platform startups that managed to establish a relevant market share, the rest of the enterprise IoT platform startup ecosystem is extremely challenged when it comes to competing with larger and truly innovative IoT incumbents. As a result, many of these early IoT platform startups are likely to become M&A targets in the near future which will help to consolidate the market even more.\n\nNot necessarily but it is important to recognize that the enterprise IoT platform market is exhibiting unique characteristics. In order to stay relevant, IoT platform startups should build very strong network effects in areas that can have a big impact and might not be the immediate focus of the incumbents. Here are some ideas:\n\nThere are other factors that can help IoT platform startups to remain competitive in the enterprise. However, recognizing the unique DNA of the enterprise IoT platform ecosystem is vital to developing comprehensive business models that allow startups to become and stay relevant in this important enterprise software market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/amazon-is-dominating-the-cloud-but-is-it-really-out-innovating-its-rivals-f38db45dadb2?source=user_profile---------402----------------",
        "title": "Amazon is Dominating the Cloud but is it Really Out-innovating its Rivals?",
        "text": "Amazon just posted a monster quarter in which AWS reported second-quarter revenues of $2.9B. That number represents an impressive 58.2% year-over-year growth and 12.5% growth from the previous quarter. These numbers accentuate AWS lead in the highly competitive cloud computing space. Many analyst claims that today AWS holds about 31% market share which is more than Microsoft, Google and IBM combined. The following chart provides an overview in the current cloud computing market distribution.\n\nOne of the areas that is often overlooked when comes to AWS and that can result interesting and concerning at the same time is that AWS doesn\u2019t seem to move as fast into new technology areas as some of its rival. On the contrary, if we explore some of the newest technology trends, we will see that companies like IBM, Microsoft or Google have been quicker than Amazon to release new technologies and established themselves earlier in the market. Let\u2019s explore this thesis by looking at four of the hottest technology areas in the current market.\n\n\u00b7 Artificial Intelligence(AI): IBM currently dominates the AI cloud space with the release of the Watson developer cloud. Microsoft recently announced the general availability of its cognitive services suite with over 20 AI APIs. Google has been steadily adding AI capabilities to Google Cloud with the release of the Google Vision, Speech and Natural Language Processing APIs. Additionally, Google open sourced its TensorFlow engine that has quickly become one of the most popular deep learning frameworks in the market. To this day, AWS doesn\u2019t include native AI capabilities.\n\n\u00b7 Blockchain Technologies: Microsoft and IBM have been quickly to announce their blockchain as a service (BaaS) initiatives. Both technology giants have also invested in the release of their own blockchain technologies in the form of the Hyperledger and Betchley porojects respectively. AWS has hinted some initial impressions to enter the space but no concrete technology has been announced.\n\n\u00b7 Microservices: The recent release of the Azure Service Fabric represents Microsoft\u2019s first attempt to provide a general purpose framework for the development and management of microservices at cloud scale. Google has also been active in the space with technologies like Kubernetes. Today\u2019s AWS support for microservices is constrained to containers and technologies like AWS Lambda.\n\n\u00b7 Bot Technologies: Even though Amazon Echo is one of the most successful bot technologies in the market, companies like Microsoft and Google have been more active investing in general purpose AI and bot technologies that can be used across different channels.\n\nThe following matrix summarizes the technology investments in the areas described above.\n\nAWS\u2019 slow innovation pace in some of these new technology areas should not be a cause for a concern at the moment. Obviously, AWS is still capitalizing big time in more established technology segments and some of these new areas account for a very small percentage of the overall cloud revenues. The increasing relevance of these technology areas might help Microsoft, IBM and Google to close the gap with AWS in the near future."
    },
    {
        "url": "https://chatbotsmagazine.com/fragmentation-could-be-the-achilles-heel-of-bot-technologies-30993e1de3e7?source=user_profile---------403----------------",
        "title": "Fragmentation could be the Achilles\u2019 heel of bot technologies",
        "text": "The original article was published at CIO.com\n\nBots are becoming one of the most popular trends in the modern technology ecosystem. Driven by popular messaging platforms like Facebook Messenger or Slack, bots are establishing new principles in user experience and user-to-system communications. However, with explosive growth comes new challenges, and the bot technology ecosystem is certainly facing a few hurdles as it transitions from early to mainstream adopters. Among the potential challenges of current bot technology, nothing is more concerning than the high levels of fragmentation in the market.\n\nFragmentation is a necessary evil in fast-growing tech markets. From one perspective, fragmentation is a clear sign of innovation in a particular technology space. At the same time, too much fragmentation can stall the growth in the development of a technology sector when no vendor gains enough market share to take innovation to the next level. Fragmentation is typically considered to be riskier in platform markets like mobile, cloud or bots because they are laying the foundation for a new generation of applications. This is the case with bot technologies, which are mostly delivered as part of messaging platforms. Messaging has expanded way beyond a new communication mechanism, and many experts have catalogued messaging platforms as the \u201cthird application runtime\u201d in the history of technology.\n\nBots today run mostly as part of messaging platforms like Slack or Facebook Messenger. From this perspective, a messaging platform is to a bot what a browser is to a web application. If we extrapolate the analogy a bit further, we can think about messaging as a succession of browsers and mobile operating systems as the third major runtime in modern end-user applications.\n\nThis previous analogy gets even more interesting if we look at it from the perspective of the fragmentation of the ecosystem. Both the web and mobile are very consolidated ecosystems with a small number of lead runtimes in the form of web browsers and mobile operating systems. Messaging, on the other hand, was built on top of mobile operating systems but has created dozens of potential runtimes. In other words, we went from a nonfragmented runtime (web) to another nonfragmented runtime (mobile OS) to a massively fragmented runtime (messaging).\n\nDifferent from the mobile world in which Android and iOS were the only two major application runtimes, the bot market already includes dozens of runtimes in the form of messaging platforms. From global messaging platforms like Skype or Facebook Messenger to local players such as Line or WeChat, most relevant messaging platforms in the market have launched their own bot technologies. Even more interestingly, each of these bot technologies introduces user experience and communication models that are very specific to the underlying messaging platform. As a result, most popular bots are really optimized for only one or two messaging platforms and rarely cover the rest of the ecosystem.\n\nThe obvious answer to the high number of bot messaging platforms is to create a killer multiplatform bot framework. This approach worked relatively well in the mobile space with platforms like Xamarin or React Native becoming extremely popular within mobile developers. Despite some interesting efforts in the space, like the Microsoft Bot Framework or Pandorabots, cross-platform bot technologies are still very limited when it comes to delivering sophisticated user experiences.\n\nThe fragmentation in the bot technology market doesn\u2019t stop with messaging platforms. Sophisticated bots are highly dependent on artificial intelligence (A.I.) and natural language processing (NLP) technologies, and these are also very fragmented ecosystems. Even more interesting is the fact that most of the leading A.I. and NLP technologies in the market are produced by vendors like IBM or Google that don\u2019t own a messaging runtime. From that perspective, A.I. and NLP technologies add a second wave of fragmentation to the bot technology ecosystem.\n\nLike other hot technology areas, the bot market has experienced a huge flow of early-stage venture capital which has resulted in an explosion in the number of startups providing bot technologies. In addition to traditional institutional financing vehicles, messaging platforms like Slack have started separate venture vehicles to fund companies building bots on their platforms.\n\nTechnology fragmentation should be expected in fast-growing technology markets like the bot ecosystem. To address the challenges that fragmentation poses to the bot technology market, we can borrow a few ideas from the predecessors.\n\nThere are other interesting ideas that can help with the fragmentation of the bot technology ecosystem. While a necessary evil, fragmentation in the bot market is a multiple higher than its mobile and web predecessors. As bot technologies evolve, it will be interesting to see whether the vendors try to address the fragmentation of the ecosystem or accept it as a new reality."
    },
    {
        "url": "https://medium.com/@jrodthoughts/five-deep-learning-frameworks-that-you-should-know-about-and-some-data-to-back-it-up-4480d31c86a8?source=user_profile---------404----------------",
        "title": "Five Deep Learning Frameworks that you Should Know About and Some Data to Back it up",
        "text": "Deep learning is one of the hottest trends in the technology ecosystem. Every week. From IBM Watson learning about music to Google\u2019s Deep Mind optimizing energy costs in a datacenter, every week we are reading about new solutions that are improved using deep learning capabilities. Similarly, there are new startups and technologies that are trying to provide deep learning capabilities to power the next generation of solutions in the space.\n\nWhen thinking about the deep learning technology ecosystem, we can identify two main groups:\n\n\u00b7 Platform as a Service Providers: Deep learning services included as part of PaaS solutions. Technologies like IBM Watson Developer Cloud, Microsoft\u2019s Cognitive Services or Google\u2019s Natural Language and Vision APIs fall are some of the best examples of this group.\n\n\u00b7 Deep Learning Frameworks: Libraries and programming models that enable the fundamental constructs to build deep learning applications. This is a rapidly growing category that is seeing a tremendous level of innovation.\n\n\u00b7 TensorFlow: Google\u2019s TensorFlow deep learning framework has been in development for years as proprietary software. It was developed originally by the Google Brain Team for conducting research in machine learning and deep neural networks. The framework\u2019s name is derived from the fact that it uses data flow graphs, where nodes represent a computation and edges represent the flow of information \u2014 in Tensor form \u2014 from one node to another.\n\n\u00b7 Torch: Torch was originally developed at NYU, and is based upon the scripting language Lua, which was designed to be portable, fast, extensible, and easy to use in development. Lua was also designed to have an easy-to-use syntax, which is reflected by Torch\u2019s syntactic ease of use. Torch features a large number of community-contributed packages, giving Torch a versatile range of support and functionality.\n\n\u00b7 Theano: Very popular within the academic research community, Theano is considered grand-daddy of deep-learning frameworks, which is written in Python. Theano is a library that handles multidimensional arrays, like Numpy. Used with other libs, it is well suited to data exploration and intended for research.\n\n\u00b7 Caffe: Caffe is a well-known and widely used machine-vision library that ported Matlab\u2019s implementation of fast convolutional nets to C and C++. Caffe was developed at the Berkeley Vision and Learning Center (BVLC). Caffe is useful for performing image analysis (Convolutional Neural Networks, or CNNs) and regional analysis within images using convolutional neural networks (Regions with Convolutional Neural Networks, or RCNNs). Caffe is not intended for other deep-learning applications such as text, sound or time series data. Like other frameworks mentioned here, Caffe has chosen Python for its API.\n\n\u00b7 CNTK: CNTK is Microsoft\u2019s open-source deep-learning framework. The acronym stands for \u201cComputational Network Toolkit.\u201d The library includes feed-forward DNNs, convolutional nets and recurrent networks. CNTK offers a Python API over C++ code. While CNTK appears to have a permissive license, it has not adopted one of the more conventional licenses, such as ASF 2.0, BSD or MIT.\n\nThere are plenty of analysis that compares these different deep learning frameworks in terms of capabilities. However, I thought it would be a good idea to take a look at some data points to evaluate the market traction. Here is an initial analysis from Google and Linkedin data:"
    },
    {
        "url": "https://medium.com/@jrodthoughts/ibm-is-eating-its-own-blockchain-food-4e0ff3e739c1?source=user_profile---------405----------------",
        "title": "IBM is Eating its Own Blockchain Food \u2013 Jesus Rodriguez \u2013",
        "text": "One of biggest challenges for the adoption of the blockchain has been the absence of large scale applications beyond bitcoin. Even though many industries are pioneering blockchain-based solutions, we are still missing large scale solutions that validate the promise of the decentralized ledger. IBM now wants to address this by implementing a solution for its Global Financing arm that leverages blockchain technologies to resolve disputes with customers and partners.\n\nIBM has been one of the enterprise software incumbents to invest heavily in blockchain. Recently, big blue open sourced its Hyperledger implementation of the blockchain and also launched a blockchain as a service (BaaS) series of services as part of its Bluemix cloud. By leveraging the blockchain as part of the dispute-resolution system for IBM Global Financing, IBM will provide one of the biggest implementations of blockchain technologies and will bring a much needed validation to the space.\n\nTo get an idea of the scale of the problem IBM is trying to solve using the blockchain, we should look at some numbers. IBM\u2019s blockchain-based dispute resolution will handle 4000 suppliers and customers and process about 3 million transactions per year worth about $44 billion. Based on historical figures, IBM expects that the new blockchain solution will handle about 25,000 financial disputes and free up about $100 million in capital tied up at any given time in transaction disputes. In initial tests, the blockhain solution has been able to reduce the time required to solve a dispute from 44 days to 10 days.\n\nBeyond the scale of the operation, IBM\u2019s blockchain-based dispute-resolution solution will provide strong validations for IBM\u2019s Hyperledger technology as well as for the BaaS and private blockchain models. While technologies like BaaS and private blockchains provide a logical value proposition, many blockchain-purists remain skeptical about the fact that those technologies haven\u2019t been as battle tested as the public blockchain. For now, IBM make it clear that they are pretty serious about blockchain technologies."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-new-world-of-microservices-development-platforms-ef2298afd086?source=user_profile---------406----------------",
        "title": "The New World of Microservices Development Platforms",
        "text": "Microservices are becoming the architecture style of choice of modern, large scale distributed systems. While microservices have typically been associated with container platforms like Docker, CoreOS or Kubernetes, there have been a gap in the market in terms of programming models and frameworks that allow developers to seamlessly implement microservices solutions.\n\nTraditionally, the well-known microservices implementations have been associated with highly sophisticated engineering teams from internet giants like Netflix, LinkedIn or Uber that have the culture nad talent to assemble different open source technologies to provide a robust experience for developers authoring microservices solutions. The next phase in the evolution of microservices is provide platforms that enable those key building blocks and patters allowing mainstream developers implement robust microservices solutions. In recent months, the focus in the microservices space seems to be shifting from infrastructure to development interfaces.\n\nAs the theory about microservices evolves, we are discovering new and interesting capabilities that are relevant in microservices solutions. From the first generation of microservices implementations, there are a few capabilities that have become essential building blocks microservices solutions. Here is an initial list:\n\n\u00b7 Service Authoring: Development interfaces that abstract the core patterns of microservices solutions.\n\n\u00b7 Service Discovery: Infrastructure for dynamically publishing and discovery microservices in a specific domain. Technologies like Consul.io or Etcd have become popular choices in this area.\n\n\u00b7 Service Description: Metadata models for describing the capabilities of microservices. Technologies like Swagger or Thrift are good examples of these capabilities.\n\n\u00b7 Persistence: Microservices require isolated data persistence models to maintain its state. NOSQL databases are the technology of choice in this area.\n\n\u00b7 Messaging Middleware: Queuing, pubsub and other fundamental message exchange patterns should be enabled in microservices solutions. Technologies like RabbitMQ or Kafka are popular options in this area.\n\n\u00b7 Deployment Automation: Microservices technologies should abstract the process of packaging and deploying microservices in container technologies. Technologies like Kubernetes or Racher are a good choice in this domain.\n\n\u00b7 Others: API Gateways, messaging monitoring, testing are other relevant capabilities that should be considered in microservices solutions.\n\nThe space for microservices development platforms is relatively new. However, already there have been major developments in this area including the first versions of some of the following platforms:\n\n\u00b7 Spring Cloud / Cloud Foundry: The combination of Spring Cloud and Cloud Foundry is a popular choice for the implementation of microservices solutions. Spring Cloud provides a robust framework that abstracts the core capabilities of microservices and it provides native integration with popular open source microservices technologies such as Netflix OSS. Cloud Foundry provides the core infrastructure building blocks for deploying and running microservices built with Spring Cloud.\n\n\u00b7 Lagom: Created by the authors of the popular Akka framework, Lagom is a microservices platforms that enables the implementation of microservices solutions. Lagom combines popular open source technologies like Akka, Cassandra, Kafka, etc in a simple programming model that abstract the implementation, deployment and runtime management of microservice solutions.\n\n\u00b7 Azure Service Fabric: With the release of the Azure Service Fabric, Microsoft becomes the first incumbent to enter the microservices development platform space. These new addition to the Azure platform, provides the infrastructure and programming model to author microservices solutions that can be deployed both on-premise or on the Azure platform. The Azure Service Fabric abstracts some of the key components of microservices solutions including discovery, description, messaging, persistence, etc."
    },
    {
        "url": "https://medium.com/@jrodthoughts/if-the-blockchain-if-the-next-internet-then-we-should-answer-these-five-questions-769f70e34015?source=user_profile---------407----------------",
        "title": "If the Blockchain is the Next Internet then we Should Answer These Five Questions",
        "text": "Comparing the blockchain to the internet is a popular analogy within blockchain proponents. At the end, the blockchain represents one of the major breakthroughs in computer science since\u2026.well, the inception of the web. Instead of exchanging content, the blockchain provides the building blocks for exchanging other assets such as money or trust. The International Monetary Fun (IMF) recently published a study calling the blockchain The Internet of Trust.\n\nJust like the internet in the 1990s, the infrastructure of the blockchain is being built these days. Just like the internet, we should expect the blockchain to power a new generation of companies that create technologies that transform entire generations and become pivotal in the world\u2019s socioeconomic affairs.\n\nWel, if we subscribe to the theory that the blockchain can be a new type of internet, we should try to think about what are going to be those technologies and companies that will become foundational to the blockchain. Here are a few ideas\u2026\n\nIf the blockchain is the next internet, what will be the next browser. Netscape expanded the access of information via the internet beyond the constrainsts of academic institutions or research facilitiaties. Today, the access of information of the blockchain is constrained to domain-specific applications. Certainly, the idea of a universal browser for the blockchain makes a lot of sense.\n\nGoogle is organizing the world\u2019s information and making it available through simple search mechanisms. In the same way, finding information in the blockchain requires very specific skillsets. Indexing and enabling searching data in the blockchain will open the door to a new generation of applications.\n\nAmazon and EBay made e-commerce a reality. The blockchain provides the foundation for a new type of e-commerce without the need to centralized authorities. Just like Amazon and EBay, we should expect a new group of companies to transform e-commerce using the blockchain as the underlying infrastructure.\n\nHTML and Javascript made web programming possible for millions of engineers. Today, the blockchain developer community only includes a few thousand hackers that are skillful enough to program in the complicated programming frameworks and infrastructures that are required today to build blockchain applications. As the blockchain evolves, we should expect that the emergence of new programming languages and frameworks that will become the universal language of the blockchain.\n\nThe Cisco name is a resemblance of communication. For three decades, Cisco\u2019s equipment has been powered networking infrastructure worldwide. In the blockchain world , we should expect a new generation of companies that power the infrastructure to enable blockchain communications around the world."
    },
    {
        "url": "https://medium.com/@jrodthoughts/which-paas-is-winning-the-machine-learning-and-artificial-intelligence-race-2640e1e96eed?source=user_profile---------408----------------",
        "title": "Which PaaS is Winning the Machine Learning and Artificial Intelligence Race?",
        "text": "Machine learning(ML) and artificial intelligence(AI) are becoming pivotal elements on the next wave of innovation in the platform as a service space. PaaS incumbents like AWS, Azure, Bluemix or Google Cloud are constantly trying to out innovate each other with new ML and AI capabilities. While the first wave of PaaS innovation was focused on core infrastructure and application platform services, this new wave is driven by data insights and knowledge. In the near future, ML and AI services will be as common as data and infrastructure in PaaS applications.\n\nIf we think about AI and ML as general categories, we will conclude that PaaS AI and ML capabilities are still in its infancy. The current race in the PaaS space has been focused on a very specific types of AI and ML capabilities and it seems to remain very consistent across all PaaS leaders. A few months after a PaaS platform announces a new AI-ML service, we can expect some of its competitors to release similar features.\n\nWhat are the current AI-ML areas of focus in PaaS technologies. The following list is a good starting point:\n\n\u00b7 Machine learning platforms: Native cloud services that enable authoring, executing and managing traditional machine learning models (ex: classification ,clustering, regression, etc)\n\n\u00b7 Natural language processing service: Services that enable the syntactical and sematic analysis of natural language sentences. Some of the common disciplinice in this category include sentiment analysis, intend analysis, conversation modeling, etc.\n\n\u00b7 Vision analytic services: Services that provide understanding the content of images. Some of the common techniques in this category include automatic image classication, emotion analysis etc.\n\n\u00b7 Speech processing services: Services that enable speech analytic capabilities such as translation, conversion to text, etc\n\n\u00b7 Knowledge services: Services that complement data with knowledge performing operations such as concept extraction, entity linking etc.\n\n\u00b7 Data insights services: Services that provide insights about target data sources. Some of the common techniques in this category include tradeoff analysis, news analysis, etc\n\nHow are the top PaaS incumbents compared in these different areas. The following matrix provides an initial analysis:"
    },
    {
        "url": "https://medium.com/@jrodthoughts/from-papers-to-robots-openai-is-making-ai-research-cool-again-c668b970c366?source=user_profile---------409----------------",
        "title": "From Papers to Robots: OpenAI is Making AI Research Cool Again",
        "text": "Last week, OpenAI announced one of its first practical applications. The non-profit disclosed that is reprogramming robots developed by Fetch Robotics with algorithms that allow them to train themselves by trial and error. The new robots used a technique called deep reinforcement learning that has been one of the first areas of focus of OpenAI.\n\nWhen I first learned about OpenAI months ago, I thought it was a very interesting idea that wasn\u2019t going to get passed the typical bureaucracy of non-profit organizations. At the end, most of the breakthroughs in software history have been designed with commercial purposes even is they followed open standards or open source distribution models. With AI being at the center of the efforts by powerhouses like Microsoft, Google, Facebook or IBM, how effective can OpenAI be? The answer? Very very effective.\n\nIn just a few months, OpenAI has released several products and some incredible research about AI disciplines. In addition to the work with Fetch Robotics, in April OpenAI launched the OpenAI Gym: a toolkit for measuring and comparing reinforcement learning algorithms. The AI non-profit has also published some incredibly insightful research on unsupervised learning and generative models. Those are some very impressive milestones for an eight-month-old company but is is enough to succeed? In the ultra-competitive AI market, the success of OpenAI might as much dependent on network effects than to the quality of its technology. Here are a few ideas that I think are going to be key for the success of OpenAI.\n\n\u00b7 Attracting top AI research talent: OpenAI must continue attracting top AI research talent that prefers to advance AI without the constraints of specific commercial goals.\n\n\u00b7 Partnerships with software and hardware companies: Similar to the partnership with Fetch Robotics, it will be key that more software and hardware companies start leveraging OpenAI tools nad frameworks in their products.\n\n\u00b7 Powering AI startups: Similar to the previous point, OpenAI research and software can become an incredible asset for AI startups that don\u2019t have the resources of Google or Facebook to attract top AI research talent.\n\n\u00b7 Nurturing a developer community: Attracting developers and building an open source community around OpenAI products should be another area of focus for the OpenAI team.\n\nThese are just some ideas that might play a role in the success of OpenAI. Without a doubt, the non-profit is off to a fast start and has the potential of leveling the playing field between AI-powerhouses and the rest of the world."
    },
    {
        "url": "https://medium.com/@jrodthoughts/hey-watson-google-is-coming-c1688eb2c1c0?source=user_profile---------410----------------",
        "title": "Hey Watson: Google is Coming! \u2013 Jesus Rodriguez \u2013",
        "text": "Google Cloud keeps accelerating its machine learning capabilities and bridging the gap with cloud market leaders AWS, IBM and Microsoft. Under Diane Green\u2019s leadership, Google has been very clear about its plans to dominate the machine learning platforms space. Yesterday, Google announced the beta release of two new machine learning services: Google Natural Language and Cloud Speech API.\n\nThe new Google Cloud Natural Language API in open beta is based on our natural language understanding research. Cloud Natural Language lets you easily reveal the structure and meaning of your text in a variety of languages, with initial support for English, Spanish and Japanese. It includes:\n\nNatural language processing is a key capability of cognitive computing platforms. This type of capability is becoming increasingly relevant with the emergence of technology trends like chatbots which heavily rely on natural language understanding. The alpha release of the Google Speech API was being used by more than 5000 companies including:\n\n\u00b7 HyperConnect, a video chat app with over 50 million downloads in over 200 countries, uses a combination of our Cloud Speech and Translate API to automatically transcribe and translate conversations between people who speak different languages.\n\n\u00b7 VoiceBase, a leader in speech analytics as a service, uses Speech API to let developers surface insights and predict outcomes from call recordings.\n\nGoogle also announced the availability of its Cloud Speech API. The new product provides text-to-speech conversion in over 80 langguages. According to Google, the new platform uses voice recognition technologies that have been powering products like Google Search and Google Now.\n\nWith this release, Google brdiges the gap with rival platforms IBM Watson Developer Cloud or Microsoft\u2019s Cognitive Services both of which include natural language and speech processing capabilities. IBM has placed cognitive computing at the center of its transformation strategy and Watson has become the undisputed leader in the space. However, Google Cloud is rapidly becoming a relevant player in the market.\n\nA few months ago, Google Cloud didn\u2019t have a SINGLE MACHINE LEARNING SERVICE. Since then, Google Cloud has boosted its machine learning portfolio making it one of the most complete offering among the PaaS market leaders. Some of the recent milestones include the open sourced release of the TensorFlow deep learning framework, the alpha release of the Google Cloud Machine Learning platform and now the beta release of new natural language and speech processing capabilities. Additionally, Google\u2019s Deep Mind keeps delivering impressive results ranging from playing Go to optimizing cost in data center infrastructures."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-new-ibm-beats-the-street-with-the-help-of-watson-cloud-and-iot-cbf15785b8a1?source=user_profile---------411----------------",
        "title": "The New IBM Beats The Street With the Help of Watson, Cloud and IOT",
        "text": "Yesterday, for the first time in a long time, International Business Machines (IBM) reported quarterly earnings that beat analyst expectations. Even more impressively, IBM delivered its turnaround quarter by keeping its focus on transformational technologies like cloud, IOT and cognitive or artificial intelligence(AI).\n\nBig Blue beat Street consensus again on Monday, reporting earnings of $2.95 per share and revenue of $20.2 billion for the second quarter of 2016. Those numbers easily beat the analyst estimates of $2.89 in earnings per share and $20.03 in revenue. However, IBM also reported a decline on year on year revenue for the 17th straight quarter. In general, the stock seems to have reacted positively rallying up 1.7% in after-hours trading.\n\nBeyond the general numbers and the stock reactions, there are some interesting lessons to be learned from IBM\u2019s earnings report. This quarter will be considered by many analysts as a turnaround moment in the IBM\u2019s continued transformation to focus on new technology areas such as cloud, AI and IOT while still managed to continuously deliver decent quarterly numbers.\n\nCloud computing was the shining star of IBM\u2019s earnings report with revenue growing over 30%. Even though Bluemix still trails AWS and Azure in cloud market share, it has established itself as a solid competitor. More importantly, Bluemix is actively innovating in areas such as IOT, AI and blockchain technologies which can offer an edge over the market leaders.\n\nThe Watson cognitive platform continues to be a strong area of focus for IBM. Even though the specific numbers for Watson are a bit hard to extrapolate analysts are forecasting revenues around $4.5B for the next 12 to 18 months. IBM also reported a 300% increase in the number of developers using the Watson platform. If those numbers are remotely correct, Watson will be by far the market leader in enterprise AI technologies.\n\nIBM is a very active in M&A. Big Blue reported 11 acquisitions so far in 2016 for a combined $5 billion which represents a record in the company\u2019s history. More importantly, IBM has done a very solid job integrating the new acquisitions into the cloud, IOT and AI pipelines.\n\nWith this earnings report, IBM can claim that the investment in transformational digital technologies is already an important part of IBM. Today, the \u201cstrategic imperatives\u201d: cloud, mobile, social, security and Watson and analytics already account for 38% of IBM\u2019s overall revenue. Very very impressive.\n\nI think is safe to say that for the next 12\u201324 months IBM is going to continue doing what has done so well until now: investing in new, disruptive technologies in its core areas of focus. Without speculating too much, here are 4 key ideas about what we can expect from the new IBM in the near future:\n\n1. Continue bridging the gap with AWS and Azure in the cloud platform space.\n\n2. Establish Watson and the market leader in enterprise AI technologies.\n\n3. Continue growing the Watson IOT platform to rival the efforts of market leaders such as GE\u2019s Predix.\n\n4. Invest a one new \u201ccore imperative\u201d. Blockchain seems like a great fit ;)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-emergence-of-the-algorithm-as-a-service-model-960755725592?source=user_profile---------412----------------",
        "title": "The Emergence of the Algorithm as a Service Model \u2013 Jesus Rodriguez \u2013",
        "text": "Algorithms are hot again and now we need a marketplace model for them! The algorithm as a service (AaaS) is triggering a lot of buzz and interest in the industry. Conceptually, AaaS provides a model for distributing, operating and monetizing algorithms that can be used from third party applications.\n\nWhile the AaaS model was mostly seeing as a theoretic exercise, platforms like Algorithmia have helped to make it a reality for developers and algorithm authors. Just a few hours ago, Algorithmia announced a partnership with In-Q-Tel to provide a private algorithm sharing platform for the intelligence community. While Algorithmia is just one platform, its recent popularity have served as a strong validation of the AaaS space.\n\nAaaS is far from being a new concept but is just recently that it has been achieved meaningful relevance within the cloud space. From a market perspective, there are several factors that are contributing to the momentum in AaaS technologies. Let\u2019s explore a few of those factors:\n\nWe are Living in the Golden Era of Algorithms\n\nWithout a doubt, we are experience an renaissance in the algorithm space. Rapidly growing technology segments such as IoT, machine learning, mobile, big data are increasingly relying on algorithms to deliver a unique value proposition. As a result, we are seeing an explosion in the creation of new algorithms as well as a reduction of the times to productize algorithms.\n\nThe Growth of Machine Learning and Artificial Intelligence\n\nMachine learning(ML) and artificial intelligence(AI) are the two main drivers behind the emergence of the AaaS model. While a few years ago, ML and AI stacks were based on a well-known set of algorithms, today we are constantly seeing new breakthroughs in AI or ML algorithms which are actively used in production-ready systems. If you visit an algorithm marketplace like Algorithmia, you will find that 90% of its algorithms are focused on ML and AI problems.\n\nThe AaaS model represents a natural bridge between the algorithm authors and app developers. Traditionally, the process of productizing complex algorithms in software products could take years and, many times, the algorithms were hidden behind some specific product feature. The AaaS model offers native mechanism for authoring, publishing and operationalizing algorithms in a few hours without the need of investing in heavy infrastructure.\n\nAaaS offers a monetization model for algorithms which simplifies the commercialization of these artifacts. Traditionally, there hasn\u2019t been a clear path in academic or industry environments that allow researchers to monetize algorithms in an easy manner.\n\nFrom Algorithms to APIs in No Time\n\nCreating unique algorithms is hard but using them programmatically could also be painful. AaaS offers native mechanisms to expose algorithms via programmatic APIs that can be used from any language or platform. Additionally, AaaS enables the mechanisms for monitoring and controlling the runtime behavior of algorithms without requiring any additional infrastructure.\n\nThese are just some of the ideas I believe are contributing to the recent popularity of the AaaS model. One thing is for certain, the best times for AaaS are still ahead of us."
    },
    {
        "url": "https://chatbotsmagazine.com/the-biggest-tech-ipo-you-have-never-heard-of-6766c2fde426?source=user_profile---------413----------------",
        "title": "The Biggest Tech IPO You Have Never Heard Of \u2013",
        "text": "There is a lot of excitement in public markets in the US today: LINE, the ultra-popular Japanese messaging app is set to start trading in the New York Stock Exchange (NSE). Based on the dual Japan-US listing, LINE could end up raising more than $1.1B on what it could be the biggest tech IPO of the year. The IPO could value LINE at about $6.9B.\n\nLINE was originally created in the aftermath of the devastating Tohoku earthquake to facilitate communications after the bulk of the telecommunication infrastructure nationwide was severely affected. The application became extremely popular in a very short time and today\u2019s it counts more than 218 million users around the world being particularly popular in Japan, Indonesia, Taiwan and Thailand.\n\nOne of the most interesting things about LINE\u2019s IPO is the dual listing in stock exchanges in Japan and The United States. This model could be a huge advantage considering the LINE\u2019s popularity in Asian markets. Initial reports are claiming that the IPO was almost 25 times oversubscribed.\n\nLINE\u2019s user base is certainly impressive but still small compared to competitors like SnapChat, WhatsApp or Faceboo Messenger. However, one are that LINE seems to be far ahead of everybody else is the revenue generation channels.\n\nIn 2015, LINE generated approximately $1 billion in revenue, making it the most lucrative messaging apps in the industry. LINE\u2019s revenue\u2019s come from four different segments: stickers, games, advertising and merchandise licensing. The sticker sales accounted for about a quarter of LINE\u2019s almost $1 billion revenue last year, and it makes around 40% from games. The following chart clearly illustrates LINE\u2019s impressive revenue growth trajectory..\n\nLINE\u2019s IPO certainly represents a major milestone for the Japanese tech industry. It\u2019s been decades since a Japanese company IPOs at these levels. We think LINE\u2019s IPO is one of the great side effect from the Alibaba\u2019s public offering last year. At that time, Alibaba clearly showed the that tech companies created in Asia with a focus for the Asian market can have a massive global impact. Certainly, LINE IPO will have a similar effect for Japanese tech companies."
    },
    {
        "url": "https://chatbotsmagazine.com/analytics-integration-language-understanding-the-bot-ecosystem-is-exploding-cb60aed2524e?source=user_profile---------414----------------",
        "title": "Analytics, Integration, Language Understanding: The Bot Ecosystem is Exploding",
        "text": "The bot ecosystem continues growing at an incredible pace. This week bots seems to be taking over the MobileBeat conference in San Francisco and every day we are seeing new announcements about new and exciting technologies in the space. Interestingly enough, a lot of the recent efforts in bot technologies seem to be focused on enhancing the robustness of bot solutions. While a few months ago the emphasis seem to be in bot creation platforms like Microsoft\u2019s Bot Framework or the Facebook Messenger Platform, these days we are seeing more effort around complementary technologies in areas like security, analytics, integration and other elements that are necessary for the mainstream adoption of bot solutions.\n\nLike any other technology trend, bots are likely to trigger a new generation of platforms to address the new challenges of the ecosystem in areas such as security, integration, analytics and others. If we follow recent trends like mobile or IOT, these type of platforms are likely to evolve as standalone offerings and eventually be incorporated into broader bot platforms provided by messaging incumbents like Facebook, Telegram, WeChat, Microsoft, etc.\n\nDashbot is a new platform focused on enabling analytics for smart bots. Conceptually, Dashbot is trying to set the standard for bot analytic technologies just like platforms like Mix Panel or Google Analytics did it for mobile and web respectively. Functionally, Dashbot provides the bot-equivalent to well-known KPIs such as user sessions, engagement or retention but also introduces new types of analytics such as sentiment analysis or conversation transcripts which are more specific to bot solutions.\n\nYesterday, Facebook Messenger Bot platform provider Chatfuel announced that is expanding its solution with new connectors to integrated bots with external data sources. This capability will allow Chatfuel users to author bots that seamlessly access data from line of business systems such as databases, SaaS, APIs, etc. Following the Chatfuel\u2019s rapid development model, the usage of the new connectors require no specific coding skills.\n\nPat is an artificial intelligence platform provider that is pioneering a technique known as natural language understanding (NLU) to improve conversational models. Functionally, Pat uses neural networks to detect intend and meaning in sentences but it factors in different elements of conversations such as interruptions, changes on subject etc. Yesterday, Pat announced that it has raised $2,5M seed round to help developed it NLU technology."
    },
    {
        "url": "https://medium.com/@jrodthoughts/5-key-points-about-the-ge-microsoft-iot-partnership-de5b3ce50921?source=user_profile---------415----------------",
        "title": "5 Key Points About the GE-Microsoft IOT Partnership",
        "text": "Yesterday, at the Microsoft Worldwide partner conference, Microsoft and GE announced a strategic alliance to bring the Predix IOT platform to the Azure cloud. While the partnership is certainly relevant I was surprised by the immediate excitement about the news that included coverage in major media outlets and an exclusive interview by Microsoft CEO Satya Nadella and GE CEO Jeff Imme in CNBC. GE\u2019s and Microsoft\u2019s stocks both reacted slightly positive to the news.\n\nThe partnership is another step towards making GE\u2019s Predix platform supported in mainstream cloud infrastructures such as AWS or Azure. Beyond the hype, there are some interesting points about the Microsoft-GE that I think are worth discussing.\n\nThe strategic alliance with Microsoft is a major step towards making the Predix IOT platform available in mainstream platform as a service (PaaS). A few weeks ago, GE announced a similar alliance with HP Enterprises (HPE) to distribute Predix as part of the Helion Stackato platform (I wrote about that partnership here). This type of partnership provides Predix with a new distribution channel and a large ecosystem of system integrators and developers.\n\nThe announcement of the partnership with Microsoft comes a few hours after the publication of a report from analyst firm Lux Research in which Predix was portrayed as \u201ca fledgling startup, has underdeveloped technology and lags in market penetration compared to its marketing.\u201d While I don\u2019t agree with many of the points of the report, it\u2019s undoubtedly that Predix\u2019s underlying infrastructure is relatively unsophisticated compared with PaaS incumbents like Azure, AWS or Bluemix. As a result, running Predix in other PaaS infrastructure allows GE to alleviate some of those concerns and focus on innovating in the IOT capabilities of the platform.\n\nFrom the IOT market perspective, the GE-Microsoft partnership is another example of how standalone IOT platforms are having a difficult time competing against the IOT offering included provided by the cloud incumbents such as Azure IOT Suite, AWS IOT or Watson IOT Platform. While many of the IOT capabilities can be considered comparable between standalone IOT platforms and PaaS IOT services, the latter offer a broader number of infrastructure and platform services that enable the implementation of more robust IOT solutions.\n\nThe obvious question about the Microsoft-GE partnership are the implications for the Azure IOT Suite which technically competes with GE Predix. The answer is very simple: anything that increases the market penetration of the overall Azure platform is more important than any individual capability. From Microsoft\u2019s perspective, the goal is to dominate the cloud market and not necessarily the IOT space.\n\nFirst HPE, now Microsoft, should we expect to see new Predix partnership with other mainstream cloud platform providers? Amazon, Google and IBM are the obvious candidates. AWS seems to be a clear choice as they are in a similar position as Microsoft in terms of IOT market penetration. Google also seems like a good option as they currently don\u2019t provide IOT capabilities as part of its cloud platform. IBM might be a harder sell as they seem to be really invested in dominating the IOT market and they have put significant investments towards enhancing its Watson IOT platform."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-thoughts-about-private-blockchains-747ebfa7fef0?source=user_profile---------416----------------",
        "title": "Some Thoughts About Private Blockchains \u2013 Jesus Rodriguez \u2013",
        "text": "In recent months, private blockchains have emerged as one of the most popular trends within the blockchain ecosystem. The challenges in the existing bitoin\u2019s blockchain infrastructure as well as the rapid raise of movements like the blockchain as a service (BaaS) have contributed to the relevance of the private blockchain movement. Additionally, new software and services companies that are focusing exclusively in the implementation of private blockchain solutions.\n\nWhile there are many arguments in favor of private blockchain models, there are no lack of detractors. The public vs. private blockchain debate is certainly one of the most interesting developments in the current blockchain community. From that perspective, the adoption of blockchain technologies can be categorized in three main groups:\n\n\u00b7 Public Blockchains: A public blockchain is open for read access to any application. In general, public blockchains are considered to be fully decentralized. The most notorious example of this model is the blockchain that powers the bitcoin crypto-currency.\n\n\u00b7 Private Blockchains: A private blockchain restricts the write permissions to a single organization and read permissions to an authorized group of third parties.\n\n\u00b7 Consortium Blockchains: A consortium blockchain is a blockchain infrastructure controlled by a set of nodes or organizations. This model is becoming a favorite in highly regulated industries such as finance or healthcare.\n\nIn some scenarios, consortium blockchains can be seen as a specific type of private blockchains. Undoubtedly, both models are attempts to address the limitations of the public blockchain. While these blockchain models have many apparent benefits, they also introduce plenty of challenges. Many detractors of the private blockchain model often compare it with the private network models that predated the emergence of the internet. In any case, there are plenty of arguments in favor or against the private blockchain movement. Instead of fueling this debate, I thought it would be interesting to summarize some observations about private blockchains that are relevant in the current state of the market.\n\nThe private blockchain ecosystem is currently experience an explosion in the number of tools, frameworks and complete platforms that enable the implementation of blockchain-powered applications. From that perspective, the experience for developers building applications for private blockchains is very sophisticated compared to the public blockchain model.\n\nMost of the successful consumer and B2C solutions powered by the blockchain are currently relying in public models. Some examples might include decentralized eCommerce platform OpenBazaar or blockchain-base remittance app Abra. This type of solutions has helped to test public blockchains in highly scalable industry scenarios.\n\nThe BaaS model has been a tremendous validation of the private blockchain ecosystem. With companies like Microsoft, IBM and Amazon launching BaaS initiatives, millions of developers can now leverage private blockchain infrastructures in their favorite cloud platform. More importantly, BaaS provides the private blockchain with a most needed scalable and global infrastructure.\n\nThere are more private blockchains that we can keep track of. That level of fragmentation is hurting the portability and interoperability of blockchain solutions. Not to mention that selecting a private blockchain platform is becoming a nightmare for most organizations.\n\nPrivate and consortium blockchain are a more popular option to build industry specific solutions. From that perspective, private blockchains are easier to extend and customize to support standards or specific components required in industry solutions.\n\nDespite its recent popularity, private blockchains haven\u2019t been tested in highly scale applications like bitcoin. From that perspective, the private blockchain model still needs a few year of evolution before it can process a volume of transactions compared to the public blockchain. However, is not crazy to think that public blockchains will remain a favorite of consumer or B2C solutions while private blockchains will be mostly adopted in industry specific or private enterprise"
    },
    {
        "url": "https://medium.com/@jrodthoughts/dumb-money-is-hurting-the-blockchain-65fc983210da?source=user_profile---------417----------------",
        "title": "Dumb Money is Hurting the Blockchain \u2013 Jesus Rodriguez \u2013",
        "text": "Yesterday at the CB Insights Future of Fintech Conference, Union Square Ventures partner Fred Wilson delivered a very thoughtful analysis about the state and adoption of the blockchain. In Fred\u2019s typically unique perspective, the explosion of early stage and corporate financing for blockchain technologies in hurting the ecosystem. From angel investors to early stage venture funds dedicated to the blockchain to the venture arms of financial institutions, everyone seems to want to own a piece of the blockchain ecosystem. Using Fred\u2019s own words \u201cthe dumb money has shown up for the blockchain\u201d.\n\nAfter watching Fred\u2019s sessionI was thinking on the implications of a crowded blockchain startup ecosystem from the technology perspective and how it can affect the evolution of blockchain technologies. Here are some minor observations:\n\n\u00b7 Vertical blockchain solutions are evolving faster than platforms: The rush in early stage financing is causing blockchain vertical solutions to evolve faster than the underlying blockchain platforms. As a result, many of these companies are building their own proprietary infrastructure.\n\n\u00b7 There are many implementations of the blockchain being created: Ethereum, IBM\u2019s Hyperledger, Microsoft\u2019s Project Bletchey are some of the recent implementation of the blockchain. This phenomenon is causing a significant level of fragmentation in the blockchain space.\n\n\u00b7 There are no winners in the blockchain platform space and incumbents are quickly catching up: None of the blockchain platform and infrastructure startups have become a clear winner in the space and that has opened the door for incumbents like IBM. Microsoft and Amazon to enter the space and become increasingly relevant.\n\n\u00b7 Other than bitcoin, we are still missing the killer app for the blockchain: Despite the rush in early stage financing and number startups in the blockchain ecosystem, we are still missing another killer app that emulates the success of bitcoin. A blockchain solution that get mainstream adoption is a needed catalyst for establishing the blockchain as a relevant technology trend for the next decade.\n\n\u00b7 Blockchain platform are still missing many important building blocks: Important infrastructure areas such as testing, security, monitoring, etc are still missing in very early stages. This is a problem if we consider than most blockchain solution are likely to be missing many of those aspects."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-case-for-and-against-deep-learning-chips-89e6c6ba5d39?source=user_profile---------418----------------",
        "title": "The Case For and Against Deep Learning Chips \u2013 Jesus Rodriguez \u2013",
        "text": "Deep learning has become of the most relevant trends in modern software technology. From a conceptual standpoint, deep learning is a discipline of machine learning that focuses on modeling data using connected graphs with multiple processing layers. In the last few years, deep learning has become a pivotal technology to power uses cases such as image recognition, natural language processing or even powering some of the capabilities of self-driving vehicles. The popularity of deep learning has expanded beyond just software and now the industry is starting to talk about the first generation of hardware with deep learning capabilities: a deep learning chip.\n\nA few months ago, at its I/O Conference, Google announced the design of an application-specific integrated circuit (ASIC) focused on deep learning capabilities and neural nets. Google called this chip the Tensor Processing Unit (TPU) because it underpins TensorFlow, Google\u2019s open source deep learning framework. While Google\u2019s TPU is not the first industry attempt to create a deep learning chip it is certainly the most famous one. However, is a deep learning chip a good idea?\n\nThe answer is related to the current time in the evolution of deep learning technologies. While moving deep learning capabilities of hardware is certainly a great concept, there are some doubts whether this is the right time in the evolution of deep learning technologies to pursue such an endeavor. Looking beyond the hype, we can identify solid argument in favor and against the creation of deep learning chip at this moment in the industry.\n\nThe explosion of deep learning technologies has been possible in part because of the breakthroughs in GPU technologies of the last decade. From an execution standpoint, deep learning is an intrinsically parallel model in which an algorithms are based in the parallel execution of concurrent tasks. Before GPUs, it was almost impossible to efficiently execute complex deep learning algorithms using mainstream hardware. GPUs made possible the execution of highly parallelizable tasks and opened the door to the evolution of deep learning.\n\nA great example of how GPUs have helped deep learning can be found in the the ImageNet Large Scale Visual Recognition Challenge, which has been running since 2010 and which has seen the error rate for image classification drop dramatically as the use of GPUs has risen.\n\nAs mentioned before, nobody doubts that deep learning chips are going to be a trend in the future but the question remains whether this is the right timing in deep learning technologies to make that transition. Some of the arguments in favor of a deep learning chip include:\n\n\u00b7 Everything works faster in silicon: A deep learning chip can really optimize the execution of deep learning algorithms and optimize it for specific devices.\n\n\u00b7 Eventually we want deep learning capabilities in our smartphones: A deep learning chip should be a catalyst to execute deep learning algorithms directly in mobile phones which opens the door to many interesting applications.\n\n\u00b7 Powering the next generation of deep learning hardware: We have to assume that in the future there will be entire hardware infrastructures focused on executing deep learning processes. If that\u2019s the case, a deep learning chip can be a key component of those infrastructures.\n\nThere is a segment of the deep learning community believes deep learning chips are a bit ahead of its time. Some of the most common arguments against this approach include:\n\n\u00b7 Support for unsupervised machine learning: Most of the deep learning models still rely on supervised models that need to be trained. A deep learning chip is better suited for unsupervised models that can learn independently.\n\n\u00b7 Algorithms are changing too fast: The rapid pace of evolution of deep learning technologies poses a challenges for a deep learning chip as the hardware might not be optimized for future algorithms.\n\n\u00b7 We don\u2019t know the winner algorithms yet: Complementing the previous point, the deep learning industry is still in a relatively nascent state in which we still don\u2019t have clear winners that can benefit from hardware level optimizations. From that perspective, the creation of a deep learning chip feels like an optimization for problems that we don\u2019t know if need to be optimized yet ;)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-five-tribes-of-machine-learning-c74d702e88da?source=user_profile---------419----------------",
        "title": "The Five Tribes of Machine Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Machine learning is on its way to become one of the foundational disciplines for the next decade of software development. In both the enterprise and consumer markets, machine learning is helping reimagine how software application interpret and process data. However, more often than not, people refer to machine learning as a big discipline when in reality is an overarching theme that groups different schools of thoughts.\n\nIn his recent book The Master Algorithm, computer science researcher Pedro Domingos uses a taxonomy based on five major schools of thoughts in machine learning:\n\n\u00b7 The Symbolists: This group of machine learning practitioners focus on the premise of inverse deduction. Instead of the classical model of starting with a premise and looking for the conclusions, inverse deduction starts with a set of premises and conclusions and works backward to fill in the gaps.\n\n\u00b7 The Connectionists: This subset of machine learning is one of the most well-known as their focus on re-engineering the brain. The most famous example of the connectionist approach is what today we call \u201cDeep Learning\u201d. At a high level, this approach is based on connecting artificial neurons in a neural network. Connectionist techniques are very efficient in areas such as image recognition or machine translation.\n\n\u00b7 The Evolutionaries: This machine learning discipline focuses on applying the idea of genomes and DNA in the evolutionary process to data processing. In essence, evolutionary algorithms will constantly evolve and adapt to unknown conditions and processes.\n\n\u00b7 The Bayesians: Another well-known group within machine learning, the Bayesians focus on handling uncertainty using techniques like probabilistic inference. Vision learning and spam filtering are some of the classic problems tackled by the Bayesian approach. Typically, Bayesian models will take a hypothesis and apply a type of \u201ca priori\u201d thinking, believing that there will be some outcomes that are more likely. They then update a hypothesis as they see more data.\n\n\u00b7 The Analogizers: This machine learning discipline focuses on techniques to match bits of data to each other. The most famous analogizer model is the \u201cnearest neighbor\u201d algorithm which can give results to neural network models.\n\nEven though each tribe represents a different school of thought within the machine learning space, they are often combined to attack problems from different angles. As a result, most of the modern machine learning platform leverage algorithms from all five school of thoughts often combining them to enable robust machine learning capabilities."
    },
    {
        "url": "https://medium.com/@jrodthoughts/why-private-companies-should-understand-public-markets-6d6664389afa?source=user_profile---------420----------------",
        "title": "Why Private Companies Should Understand Public Markets",
        "text": "I published this post about a year ago but I think is very timely with the recent events affecting public markets: Brexit, etc.\n\nA few days ago, during a dinner with a few experienced tech executives, we had a super interesting discussion about the current state of the public markets and its relationship with the venture industry. One of the topics we were debating was the value of understanding and following the state of public markets as an entrepreneur and CEO of a private company.\n\nThe discussion was particularly interesting to me as I have been advocating the value of knowing to speak the language of public markets for private company CEOs. In my opinion, understanding the dynamics of public markets can be incredibly useful for a variety of reasons:\n\nSocks, bonds, options, etc are statistical principles that describe the state of a company, industry, a country or the entire world. Understanding those principles can result incredibly beneficial during negotiations with potential large customers or investors. Whether you are a technologist, business person or an investor, I\u2019ve found that understanding the language of public markets tends to be a very complementary skill that can become helpful is various situations.\n\nIf you are raising money for your startup, it doesn\u2019t hurt to validate the current state of public markets. Whether you like it or not, venture capitalists (VC) typically look at public market valuations as a way to calibrate the valuations of their investments. This is particularly true if your company is on a trajectory to go public at some point.\n\nPublic markets are the ultimate representation of an economic downturn. The indicators of difficult economic times ultimately affect the VC circles. If you were around during the 2000s or 2008 crisis, you might remember that it was impossible to raise a round of VC funding regardless of the quality of the investment.\n\nIn the last few years, a number of hedge funds and private equity firms have started to make inroads in the vC market. Those public market investors are typically lured by the opportunity to invest in fast growing private companies before a potential public offering. As a result, many startups are now raising institutional rounds from traditional public equity investors. In those circumstances, the understanding of public market dynamics can result incredibly helpful.\n\nThese are just some of the reasons why I believe developing an understanding of pubic markets can be incredibly valuable in your career. At the end, public markets are a language that you should know how to speak and that will expand your perspectives of your work, industry and even your life."
    },
    {
        "url": "https://medium.com/google-cloud/github-and-the-power-of-open-source-data-b43b34c1beb6?source=user_profile---------421----------------",
        "title": "GitHub and the Power of Open Source Data \u2013 Google Cloud Platform \u2014 Community \u2013",
        "text": "Yesterday, Github announced that was making available the activity data for 2.8 million open source repositories as public datasets in Google Big Query. This will allow users to execute SQL queries against Github data and provide sophisticated, near-real time analytics about open source projects.\n\nYesterday\u2019s announcement is another example of GitHub\u2019s commitment to open source data. In 2012, GitHub announced the release of the GitHub Archive project which provided an initial set of analytics and insights about the way developers us GitHub. The BigQuery datasets can be considered, in many ways, an extension to the GitHub Archive project.\n\nGitHub\u2019s BigQuery data set in an incredibly valuable source of data to understand the characteristics of open source projects. By analyzing the data using BigQuery, we can determine interesting usage patterns of a specific project, contributors, user preferences etc. However, I think the GitHub announcement has a more profound meaning if we think about what can achieved if other companies follow the same path.\n\nYesterday, GitHub did a little bit more than just releasing a bunch of historical data sets. By leveraging BigQuery, GitHub released the data in a platform that is optimized for analytical workloads and also interoperates with some of the most popular analytic platforms in the market.\n\nI certainly applaud GitHub for the thoughtful way they approached the released of their proprietary data sources. I think this release is certainly going to expand the conversation about open source data. Here are a few interesting points that I think are worth considering:\n\nIf more companies follow GitHub\u2019s example, we could soon have a public marketplace in which data can be aggregated in real time using simple SQL constructs. Imagining combining, GitHub\u2019s project data with data from LinkedIn to correlate to correlate the job history of a developer with his open source commitments.\n\nMany companies make their data available through APIs but that\u2019s rarely enough to enable sophisticated analytics. For starters, more APIs just provide the current view of a specific data asset and don\u2019t focus on historical data. Additionally, most APIs don\u2019t use data access protocols that are compatible with analytic tools.\n\nOpen sourcing data is more than just releasing a bunch of CSV files for download. By leveraging a platform like Google\u2019s BigQuery, companies can now combine and aggregate data using simple SQL constructs and expose those queries as new data sources that can, in turn, be used in other queries to enable more sophisticated analytic workloads.\n\nData is one of the most precious assets of any company. From that perspective, we can think it would be crazy for many institutions to release their data sources. However, by making their data available and allowing data scientists to combine it with other public or private data sources, organizations can obtain new insights and intelligence about their business in levels that were not possible before.\n\nFrom privacy to IP challenges, there are many arguments that can be used against open sourcing data. For the most part, those arguments are very similar to the ones that have been used against open sourcing code for decades. While today the benefits of open source code are undeniable, there were not well understood a few decades ago. Similarly, I believe open source data will have to go through several iterations before we fully capitalize on the benefits."
    },
    {
        "url": "https://medium.com/@jrodthoughts/iot-platform-wars-the-battle-for-the-4th-enterprise-platform-97bb58b95a82?source=user_profile---------422----------------",
        "title": "IoT platform wars: The battle for the 4th enterprise platform",
        "text": "The original article was published in my CIO.com column\n\nInternet of Things (IoT) platforms are set to be an important component of the next decade of innovation in the enterprise. Just like the previous generation of platforms focused on connecting systems and people, IoT platforms are starting to power solutions that connect smart devices, enterprise systems, and people. From that perspective, IoT is raising a new set of challenges across the traditional enterprise spectrum in areas such as security, analytics, data storage, messaging, and many other fundamental elements of enterprise solutions. As a result, organizations of all sizes are starting to embrace IoT platforms as a foundational component of the next generation of enterprise solutions.\n\nThe rapid rise of IoT in the enterprise has triggered an explosion in the number of providers offering complete stacks that provide backend and infrastructure capabilities required in enterprise IoT solutions. From innovative IoT startups to enterprise software incumbents the market is inundated with platforms that promise to be the silver bullet for enterprise IoT challenges.\n\nIoT has all the characteristics of becoming a multi-decade transformational movement in the enterprise. From this perspective, IoT platforms can be considered the 4thfoundational generation of enterprise software platforms. The first generation platforms were powered by the emergence of the web, which brought together a new group of platforms in areas ranging from databases to user interface frameworks.\n\nThe web movement was followed by the cloud and SaaS platforms that have completely changed the way enterprises architect and develop solutions. The mobile revolution hasn\u2019t been as relevant in the enterprise as its cloud and web predecessors \u2014 but it can still be considered a transformational movement when it comes to powering a new wave of solutions and technologies. While the cloud and mobile platforms are still developing and garnering adoption in the enterprise, we are now entering the era of IoT platforms.\n\nEvaluating IoT platforms in an enterprise context can be an exhausting endeavor. As mentioned previously, the market is crowded with sophisticated platforms that provide the backend and infrastructure capabilities required by IoT solutions. However, the IoT platform landscape is not as complicated as it might seem on the surface.\n\nBeyond the crowded ecosystem, there are only a handful of vendors that have achieved relevant traction with customers, developers, and partners in the enterprise. More importantly, many of the enterprise software incumbents have entered the IoT race with very innovative platforms and attractive distribution models. This factor alone should help to compact the IoT platform space as many startups will have a lot of difficulty remaining competitive in the long term against the incumbents. When evaluating IoT platforms, we can group the options in different categories as listed below.\n\nLike many other areas in enterprise software, innovation in the IoT space was driven by the emergence of a robust startup ecosystem. While many startups have come to market with technologically innovative IoT platforms, a few have achieved meaningful traction within the enterprise. Platforms like Xively and ThingWorx have certainly distinguished themselves from the group, capturing relevant market share within the early adopters of enterprise IoT solutions.\n\nAmazon, Microsoft, and IBM have entered the IoT space by extending their platform as a service (PaaS) offerings with IoT-specific capabilities. This model has given the PaaS providers a competitive advantage as the feature set of their IoT platforms combined with their PaaS services far exceeds the capabilities of any standalone IoT offering in the market. Additionally, these groups of IoT platforms can leverage the strong distribution models as well as the sophisticated partner ecosystems developed by the PaaS incumbents.\n\nEnterprise IoT solutions require deep industry expertise which is typically not delivered by IoT startups nor the PaaS incumbents. As a result, many industrial solution providers have attempted to leverage their domain knowledge to enter the IoT platform race. GE Predix stands out as the most relevant IoT platform from that group. GE Predix has developed a clever model combining existing open source infrastructure platforms like Cloud Foundry with a unique set of industry specific capabilities. As a result, GE Predix has achieved record setting revenues in the IoT platform space posting $6 billion in revenue last year and forecast to hit $15 billion by 2020.\n\nIntegration platforms have been a key element of enterprise software solutions for the past few decades. EAI, ESB, and iPaaS platforms are an omnipresent piece of enterprise software portfolios and now these platforms are attempting to expand into the IoT space. While we are still in the early days of the IoT platform movement, it\u2019s interesting to see how the majority of integration platform providers have struggled to make a smooth transition into the era of connected devices. WSO2 seems to be an exception to the rule. The middleware and SOA platform provider has been able to deliver a very innovative, open source IoT platform that is starting to achieve meaningful traction in the market.\n\nThe race in the IoT platform space is just getting started but we can already foresee the frontrunners. As IoT evolves in the enterprise, we are likely to see new platforms emerge and some of the current leaders lose traction. Unlike the web, cloud, and mobile predecessors, many relevant enterprise software incumbents have jumped in the race very early and are driving innovation at a frantic pace. The next few years promise to be an exciting time for the IoT platform space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-x-for-machine-learning-business-model-2d2286e186b1?source=user_profile---------423----------------",
        "title": "The X with Machine Learning Business Model \u2013 Jesus Rodriguez \u2013",
        "text": "Every few years a new movement becomes transformational in the technology industry driving a brand new generation of startups and new businesses. Some of those movements can be technological in nature like social, mobile, cloud or IOT while others like crowdsourcing or the gig economy are more transformational from the social standpoint. Each one of those movements creates many companies that attempt to leverage its principles in a specific domain. How many \u201cFacebook for X\u201d, \u201cAWS for X\u201d or \u201cUber for X\u201d have we seen in the last few years.\n\nThese days, the new Machine learning and artificial intelligence are capturing the imagination of the technology industry. These 2 technology trends seem to be the force behind a new generation of startups in both the consumer and enterprise industry. Differently from other transformational technology movement, machine learning seems to be more efficient at reimagining existing business models than in creating brand new ones.\n\nLet\u2019s setup the right context for the previous statement. There are certainly plenty of new business models powered by machine learning. However, if we pay close attention to the space, we are going to see how machine learning is being used to power the next iteration of many established business and technology solutions. I like to call that the \u201cX with Machine Learning\u201d business model.\n\nThe \u201cX with machine learning\u201d business model focuses on leveraging machine learning principles to optimize existing business or consumer solutions. Across the board, we are seeing how incumbents in different markets are releasing the new version of their software solutions using machine learning technologies. Additionally, there are also plenty of startups that are trying to reimagine existing business models using machine learning as a first class citizen. Let\u2019s look at some of the most notable market categories that are rapidly incorporating machine learning:\n\n\u00b7 SaaS: Many SaaS platforms are incorporating machine learning to optimize their business processes. From that standpoint, we should expect machine learning to become a native capability of the most popular SaaS solutions.\n\n\u00b7 Infrastructure Technologies: Security, operational monitoring, networking are just some of the infrastructure areas that have been optimize with the usage of machine learning technologies. These areas have produced a new generation of startups that have gained meaningful market share in their respective areas.\n\n\u00b7 Vertical Solutions: Healthcare, travel, public safety are some of the industries that are rapidly incorporating machine learning and artificial intelligence technologies. As a result, the vertical solution providers in those industries are reimagining their solutions using machine learning as a core component.\n\n\u00b7 Hardware: From technologies like Amazon Echo to telematics systems in cars, hardware solutions are being optimized using machine learning and artificial intelligence technologies. Combined with the innovations in hardware, this trend should become more and more relevant in the next few years"
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-blockchain-as-a-service-needs-cloud-foundry-1804461e8c08?source=user_profile---------424----------------",
        "title": "The Blockchain as a Service Needs Cloud Foundry \u2013 Jesus Rodriguez \u2013",
        "text": "Blockchain as a service (BaaS) is the latest hot trend in the blockchain ecosystem. From a conceptual standpoint, BaaS provides enables the capabilities of the blockchain as a series of services that can be incorporate into applications. More importantly, BaaS leverages the power of cloud computing to enable the provisioning, management and scalability of blockchain solutions without requiring any proprietary infrastructures. Recently, cloud market leaders like IBM and Microsoft announced the first releases of their BaaS solution powered by the Bluemix and Azure cloud respectively.\n\nThe BaaS movement is a great catalyst for the adoption of the blockchain but is also contributing to the fragmentation of the ecosystem. With other cloud leaders like Amazon or Google quickly embarking in BaaS initiatives the industry desperately need an open BaaS model. To accomplish that, the industry should leverage the platform that has become the standard for hybrid, open source, multi-cloud platform as a service (PaaS) capabilities: Cloud Foundry.\n\nA BaaS model powered by Cloud Foundry is far from being a trivial endeavor but, if successful, can bring tremendous benefits to the blockchain movement. There are a few factors that I believe are rapidly contributing to the need of a Cloud Foundry BaaS model\n\nAs IBM, Microsoft and others expand the capabilities of their BaaS capabilities, the need for a multi-cloud BaaS model is becoming essential to ensure certain level of portability and interoperability between different BaaS stacks. A Cloud Foundry BaaS solution would not only ensure an open standard BaaS stack but it will allow organizations to enable BaaS capabilities in their private cloud infrastructure.\n\nThe emergence of BaaS is accelerating the fragmentation of the blockchain. In just a few months, both IBM and Microsoft have released proprietary blockchain stacks such as Hyperledger and Project Bletchey. A Cloud Foundry BaaS model can help to set a common set of capabilities across the different BaaS technology stacks.\n\nEvery blockchain solution needs infrastructure or platform services beyond the blockchain. A BaaS stack powered by Cloud Foundry will allow developers to build applications that combine the capabilities of the blockchain with existing Cloud Foundry services like storage, messaging, microservices and many others.\n\nIn order to remain competitive with public PaaS offerings, Cloud Foundry should enter the blockchain space. Despite the complexity and fragmentation of the market, everything indicates that the blockchain can become a pivotal technology trend for the next decade of cloud computing. Similarly to other technology trends like mobile or IOT, BaaS capabilities should have a place in the Cloud Foundry stack.\n\nThe internet of things (IOT) is one of the trends that can immediately benefit from the decentralized, trustless capabilities of the blockchain. Incorporating BaaS capabilities into Cloud Foundry will expand the possibilities for Cloud Foundry IOT solutions or platforms such as GE Predix."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-looks-to-take-the-blockchain-to-the-next-level-with-project-bletchey-8adaae971bd7?source=user_profile---------425----------------",
        "title": "Microsoft Looks to Take the Blockchain to the Next Level with Project Bletchey",
        "text": "The blockchain continues getting adoption within the enterprise software incumbents. In her recent appearance at the Code Conference, IBM\u2019s CEO Ginni Rometty mentioned that the market around the blockchain was comparable or bigger than the artificial intelligence market. A few days ago, Microsoft made it clear that they are serious about the blockchain solution market with the release of Project Bletchey.\n\nThis is not Microsoft\u2019s first contribution to the blockchain space but is certainly the most impactful one. Last November, the Redmond giant announced the releases of its blockchain as a service (BaaS) technology powered by Microsoft Azure. Project Bletchey takes the blockchain capabilities within Azure to a different level by expanding the distributed ledger with a series of building blocks that will enable enterprises to build business solutions powered by the blockchain.\n\nWith Project Bletchey, Azure will serve as the distributed fabric to enable distributed blockchain applications across its 24 global regions. Additionally, Azure will support blockchain native protocols such as Unspent Transaction Output-based protocols (UTXO) like Hyperledger or Ethereum\u2019s Smart Contracts. Project Bletchey expands the core capabilities of the blockchain with a sophisticated architecture that will simplify the implementation of enterprise-ready blockchain solutions. The following figure shows a high level architecture of Project Bletchey.\n\nThe most important contribution of Project Bletchey is the introduction of two new concepts that are very relevant in enterprise blockchain solutions: cryplets and blockchain middleware.\n\nCryplets are a new building block in Microsoft\u2019s vision of the blockchain. Functionally, cryplets enable the communication between the blockchain and external data sources. In classic blockchain, if external data is needed to execute a smart contract then an \u201coracle\u201d is required. However, there is no standard way to supply \u201coracle\u201d data securely. Executing code outside a smart contract or blockchain in general is breaking the trust barrier threatening the authenticity of the dependent transactions. Cryptlets supply this functionality.\n\nCryptlets are off-chain code components that are written in any language, execute within a secure, trusted container and communicated with using secure channels. Cryptlets can be used in smart contracts and UTXO systems when additional functionality or information is needed and provided without violating the integrity of the blockchain.\n\nThe blockchain middleware expands the blockchain with a series of core services that enable essential building blocks of blockchain applications. The first release of the blockchain middleware includes the following services:\n\n\u00b7 Identity and Certificate Services: Enables key identity management capabilities such as authentication, access control or key issuance.\n\n\u00b7 Cryplet Services: Provides hosting and execution of cryplets.\n\n\u00b7 Blockchain Gateway Services: Enables interoperability between different blockchain ledger systems like Hyperledger or Smart Contracts.\n\n\u00b7 Data Services: Enable access to key data services like file systems or databases.\n\n\u00b7 Management and Operations: Set of tools for managing and deploying blockchain solutions.\n\nProject Bletchey is the first iteration of Microsoft\u2019s broad vision for adopting blockchain technologies in enterprise solutions. Certainly, the additions of concepts like cryplets and middleware represent interesting innovations in the blockchain space. Hopefully, the blockchain technical community will be receptive to this new architecture principles. Regardless, the first release of Project Bletchey bring us a step closer to making blockchain technologies in the enterprise a reality."
    },
    {
        "url": "https://chatbotsmagazine.com/bots-vs-bots-platforms-in-5-questions-ec0b295a024e?source=user_profile---------426----------------",
        "title": "Bots vs. Bots Platforms in 5 Questions \u2013",
        "text": "Every time the tech industry produces a new hot technology trend, it makes investors and customers theorize about what aspect of that trend will capture the market first: end user solutions or infrastructure platforms. We see it all the time, SaaS vs. cloud platforms, mobile apps vs. mobile platforms and now we have bots vs. bots platforms.\n\nBots are becoming one of the hottest trends in technology. As any new trend, venture funds are flowing into startups developing bots that can become the killer app of the bot market. At the same time, platforms that enable the creation of smart bots across different messaging stacks are rapidly emerging in a very competitive market. For being such a new trend, the bot platform market is already a pretty crowded ecosystem:\n\nOne of the biggest unanswered question of the bot movement remains whether there is a viable market for bot platform startups. While I don\u2019t pretend to have the answer, I\u2019ve participated in enough debates about this that I decided to summarized a few ideas that I think are worth exploring.\n\nThere are many parallels between the bot and mobile markets and some of them might help us think about the viability of bot platforms. In the mobile space, Android and IOT remain the two biggest runtimes and also the owners of the most popular mobile app development platforms. With some exceptions like Xamarin, I don\u2019t think the mobile industry has produced successful mobile app development platforms that have become a real threat to Apple and Google\u2019s dominance.\n\nBots need a killer app to become a real market. A popular bot that attracts millions of users can be the biggest possible catalyst to the nascent technology movement. The first generation of popular bots will also be a key indicator of the capabilities that will be relevant in bot platforms.\n\nA very unique aspect of the bot market is that the incumbents are, in a vast majority, startups. With the exception of Facebook, most popular messaging runtimes can still be considered startups and they are moving fast building their own bot platforms. From that perspective, bot platform startups will have to compete with incumbents that not only own the messaging runtime but that are still able to innovate and execute relatively fast.\n\nThe number of popular messaging platforms in the market is an argument in favor of a \u201ccross platform\u201d bot platform. However, we should consider that many aspects of smart bots like the user interface are very specific to the messaging runtime and not easily abstracted in a \u201ccross platform\u201d solution.\n\nGames were a massive catalyst for the mobile market and they can also play a key role in the bot space. Bot games have the potential of rapidly building a large user base. The native messaging and collaboration capabilities of bots creates a very favorable environment for the emergence of popular games in the space."
    },
    {
        "url": "https://medium.com/@jrodthoughts/open-source-and-iot-a-match-made-for-the-enterprise-810fd9f0458d?source=user_profile---------427----------------",
        "title": "Open source and IoT: A match made for the enterprise",
        "text": "This article was published in my CIO.com column\n\nThe Internet of Things (IoT) is one of the most competitive spaces in the enterprise software market. From horizontal platforms to solutions in specific areas such as networking, security, analytics or integration, the market has exploded with platforms that promise be the silver bullet for the adoption of smart devices in the enterprise. Typically crowded technology markets are a catalyst for the adoption of open source technologies and the IoT space should not be different. We think open source IoT platforms will, eventually, become more dominant in the enterprise.\n\nWhile the case for the adoption of open source IoT technologies makes tremendous logic sense, most of the traction of IoT technologies in the enterprise have been centered on either cloud platforms or closed source commercial solutions. This is a very typical phenomenon in complex and nascent enterprise software markets.\n\nSome of the initial IoT platforms that have gained traction in the enterprise come from the traditional IT school that favors closed source, commercial distribution models. Cloud IoT platforms are also a great fit for enterprises in these early days given that they removed many of the complexities associated with an IoT infrastructure. However, as the enterprise requirements evolves, we think open source IoT platforms will become more and more relevant in the enterprise.\n\nThe enterprise IoT space is changing an order of magnitude faster than any other enterprise software trend in the last decades. This factor makes it very difficult for IoT platforms maintained by a single vendor to keep up with all the new standards, requirements and technologies could be incorporated into the platform. An open source developer community can help IoT vendors to keep up with the changes in the market and evolve their technology at a faster pace.\n\nEnterprise IoT solutions present incredibly complicated requirements that very often fall outside the capabilities of an IoT platform. Open source IoT technologies allow enterprises to extend and modify the underlying platform to tailor the platform to their specific requirements.\n\nInteroperability with IoT devices is an essential element of enterprise IoT platform. However, no single vendor can possibly maintain SDKs or adapter for the tens of thousands of IoT devices in the market. Open source distribution models will allow device manufacturers to control and evolve the interoperability with different IoT platforms and use that as a distribution channel for their smart devices.\n\nThe developer communities created by open source IoT technologies will play a key role in the evolution and adaptability of these platforms. This factor will also allow enterprises to access the talent required to implement IoT infrastructures and solutions without solely relying on expensive system integrators.\n\nIndustry specific IoT solutions are experiencing a tremendous adoption in the market. Even though these solutions are very effective addressing industry specific scenarios, they often lack the robust infrastructure capabilities provided by horizontal IoT platforms. An open source model will allow ISVs to build their solutions on top of sophisticated IoT platforms and, as a result, leverage the developer and partner communities created by those open source IoT platforms.\n\nAs the IoT market evolves, we are witnessing the evolution of cool open source projects and platforms in the space. Some of these platforms have the potential of becoming extremely relevant in enterprise IoT solutions. Here are 5 cool open source IoT projects that are worth keeping an eye on.\n\nKaa is an open source, for building, managing, and integrating smart IOT devices. Kaa provides a standardized approach for integration and interoperation across connected products. In addition, Kaa\u2019s powerful back-end functionality greatly speeds up product development, allowing vendors to concentrate on maximizing their product\u2019s unique value to the consumer. Kaa is a great solutions for enterprises adopting IoT middleware solutions.\n\nGE PRedix is an open source IoT PaaS model for the industrial enterprise. Based on Cloud Foundry, GE Predix adds a new group of services and capabilities relevant to IoT industrial solutions. Specifically, GE Predix extends Cloud Foundry with IoT specific services such as asset management, device security, real time analytics, and other capabilities relevant in IoT. By many metrics, GE Predix can be considered the most successful IoT platform in the market claiming $6B in revenue last year. In any case, GE Predix is a very strong validation of Cloud Foundry as one of the platforms that can become pivotal in the next generation of IoT solutions in the enterprise.\n\nMacchina.IO is an open source framework for building embedded applications for the Internet of Things that run on Linux-based devices like the Raspberry Pi, Beaglebone, RED Brick or Galileo/Edison. Macchina.IO is a great solution for enterprises looking to connect smart devices with their cloud services and solutions.\n\nNetBeast is an open source, hardware independent, JavaScript based platform that allows technology to interact regardless of brand or technology. Netbeast builds on their developer community to grow on their support of IoT products through a scalable API that allows developers to declare new ways of connecting with brands and protocols.\n\nAnother open source integration framework, Node-RED is a tool for wiring together hardware devices, APIs and online services in new and interesting ways. Node-RED provides a browser-based flow editor that makes it easy to wire together flows using the wide range nodes in the palette. Flows can be then deployed to the runtime in a single-click."
    },
    {
        "url": "https://medium.com/@jrodthoughts/some-factors-that-are-making-ibm-cool-again-in-the-enterprise-c513aca66793?source=user_profile---------428----------------",
        "title": "Some Factors that are Making IBM Cool Again in the Enterprise",
        "text": "Last week I was watching IBM CEO Gini Rometty interview at the Code Conference and I couldn\u2019t avoid thinking how different she sounded compared to her predecessors. If we removed the references to IBM technologies you could hardly tell that this was the CEO of IBM as the conversation centered around modern enterprise technology trends such as artificial intelligence, IOT or the blockchain.\n\nUnder Rometty\u2019s leadership, IBM has started a very aggressive transformation process moving from a traditional services and on-premise software model into new and exciting areas. This transformation process is even more impressive if you consider that has done in the eye of the public markets reporting earnings that Wall Street considers disappointing as revenue shifts from the old model to the new technologies. Recently, in an interview in CNBC, a prominent venture capitalist in Silicon Valley even mentioned that buying IBM was \u201cbetting against the future of America\u201d.\n\nDespite the doubters (myself included), the IBM transformation process seems to be working. What is even more impressive, IBM is once again becoming a cool vendor in the enterprise capturing the hearts and minds of developers and customers. There are many factors that are contributing to IBM\u2019s successful transformation but here are some that I think are worth highlighting.\n\nCloud and big data are areas in which IBM has been aggressively closing the gap with the market leaders. The Bluemix cloud platform is typically placed right next to Google Cloud as a third place in the market following AWS and Azure. IBM\u2019s Open Platform and Big Insights have become very compelling big data distributions embraced by thousands of customers all over the world. This picture was unconceivably a few years ago when IBM wasn\u2019t anywhere close to relevant in those markets.\n\nIBM is not particularly well-known for jumping first in new technology trends. However, that seems to be changing. The software giant seems is leading the charge in transformational movements in the enterprise such as IOT, cognitive computing and even the blockchain. In those markets, IBM\u2019s is not only leading many of the enterprise software incumbents but also holding its ground against innovative startups that are trying to become leaders in those segments.\n\nIBM\u2019s commitment to open source technologies has increased dramatically over the last few years. From aggressively contributing to lead open source technologies such as Apache Spark to starting popular open source projects like Node-Red or Hyperledger, IBM is leveraging open source to attract millions of developers to its technology offerings.\n\nBeing smart about acquisitions is also been a key element of IBM\u2019s recent transformation in the enterprise. The acquisitions of popular PaaS technology providers like Strongloop and Compose has drastically helped to improve the adoption of Bluemix within enterprise developers. The high profile acquisition of the The Wheather Company provides IBM with a unique asset in the IOT space. More recently, IBM acquired cloud professional services leader Blue Wolf to bring fresh talent to the implementation of its cloud offerings."
    },
    {
        "url": "https://medium.com/@jrodthoughts/linkedin-madness-and-3-reasons-why-m-a-is-hot-in-the-saas-space-6fd18cce8535?source=user_profile---------429----------------",
        "title": "LinkedIn Madness and 3 Reasons Why M&A is Hot in the SaaS Space",
        "text": "Yesterday the tech industry was shocked by the news that Microsoft was buying Linked by an astonishing $26 billion. The acquisition represents one of the largest deals in the history of the tech industry and by far Microsoft\u2019s biggest M&A event to date:\n\nRegardless of the magnitude of the Linkedin sale, we shouldn\u2019t see it as an isolate it event. In the last few months the technology sector and SaaS companies specifically have become active M&A targets. Just this month, SaaS market leaders Marketo and Qlik were bought by private equity firms while Salesforce acquired ecommerce leader Demandware. This increase in M&A activity in the SaaS technology space is based on a combination of unique factors that seem to be affecting many companies in the space:\n\nOne of the interesting details about LinkedIn\u2019s acquisition, is that the conversations with Microsoft seem to have started in February this year. Interestingly enough, that seems to align with the collapse of the LinkedIn stock after February earnings report.\n\nLinkedIn is not an isolated example. Public SaaS stocks have been underperforming and under pressure since the beginning of the year which makes them an attractive target for acquisition.\n\nGrowth is one of the main metrics used to evaluate publicly traded SaaS companies. In many cases, growth has been slowing down and consequently affecting the performance of the stocks. In order to improve growth, SaaS companies tend to increase the spend in areas like sales and marketing which contributes to the negative perception of the public markets.\n\nMicrosoft will use debt mechanism to finance the LinkedIn acquisition. This might come as a surprise considering that Microsoft has declared that it has more than $100 billion in cash and cash equivalents. By using a debt mechanism, Microsoft will avoid paying the 35% tax required to repatriate that cash from overseas and could deduct interest payments which could help with the US tax bill.\n\nThe Microsoft model is an example of how debt mechanism are both available and very cheap for big technology companies like Apple, Google, IBM, Oracle, etc with big cash positions overseas. Also, the strong cash position of these companies is another factor favoring the M&A climate.\n\nA lot has been speculated about who will follow LinkedIn as the next big acquisition of the year. Twitter seems to be the most popular name within the tech analyst community. However, a group of Goldman Sachs\u2019 tech analysts just published a list of 12 companies that could be acquisition targets. Some of the names in the list might surprise you."
    },
    {
        "url": "https://medium.com/@jrodthoughts/steve-case-is-right-about-the-third-wave-and-the-blockchain-and-iot-proves-it-2beaecb7afe8?source=user_profile---------430----------------",
        "title": "Steve Case is Right About the Third Wave and the Blockchain and IOT Proves It",
        "text": "Steve Case\u2019s The Third Wave is a fascinating book that outlines a playbook for companies building the next generation of technology solutions. In the book, Case argues that we are entering the \u201cThird Wave\u201d of the internet. While the first wave focused on connecting customers to the internet and the second wave on building internet services on top of that infrastructure, the third wave will leverage technology to transform major industries such as transportation, healthcare of education.\n\nPart of what makes Case\u2019 third wave theory fascinating is that it highlights the importance of often ignored aspects such as partnerships, government or understanding of the regulatory environment as fundamental elements to be successful with the next generation of technology companies. Even though the book focuses on industry specific solutions, horizontal technology movements like the blockchain and the internet of things (IOT) are clear examples of third wave technology movements.\n\nIOT, in and out itself, has been often called the third wave of the internet. While the IOT space has seen an explosion in the number of startups providing hardware, software and solutions for vertical industries, the market has been dominated by incumbents such as GE, Microsoft, IBM or Amazon. These incumbents have reacted effectively to the change driven by the IOT movement and released very innovative technology offerings in the space but you can argue that their initial success has been based on their ability to execute the third wave playbook.\n\nA significant part of the adoption of IOT technologies has come from solutions in the industrial sector or in regulated industries such as healthcare or insurance. In those environments, the ability of companies like GE, Microsoft, IBM or Amazon to establish the right partnerships, address the compliance and regulatory requirements and establish strong strategic alliances have been key to their success in those markets compared to, arguably, more innovative startups.\n\nThe blockchain is another example of a third wave technology movement. At the recent Code Conference, IBM\u2019s CEO Gini Rometty referred to the massive opportunities in blockchain technologies often comparing it to IBM\u2019s work in the cognitive computing space in which technologies like Watson are redefining entire industries.\n\nInterestingly enough, most of the lead blockchain platforms in the market is being produced by startups and not bug enterprise software companies. However, following the third wave\u2019s principles, companies like IBM and Microsoft have enabled blockchain technologies as part of their cloud offerings starting the \u201cblockchain as a service\u201d (BaaS) trend. Additionally, both IBM and Microsoft have developed impressive partner ecosystems around their BaaS offerings and are starting to see adoption within regulated industries like legal or finance.\n\nThe blockchain and IOT are some of the most notable examples of third wave technology movements. In other to be successful in those markets, startups will have to develop effective partnerships and understand the regulatory environment in specific industries. Disruption in those markets is likely to be more challenging than the second wave technologies but the impact can be also be much more profound and relevant."
    },
    {
        "url": "https://chatbotsmagazine.com/chatbots-go-vertical-with-the-help-of-microsoft-and-salesforce-dbffc008f3e4?source=user_profile---------431----------------",
        "title": "Chatbots Go Vertical with the Help of Microsoft and Salesforce",
        "text": "Yesterday, customer service support platform Helpshift announced that it has raised $23 million venture funding to expand its platform. In the announcement, Helpshift makes it clear that it will start leveraging modern chatbot technologies to improve and automate the interactions between brand and customers. The round included two new strategic investors which are themselves very invested in the chatbot market: Microsoft and Salesforce.\n\nHelpshift\u2019s funding round is a great example of chatbot solutions starting to get traction in vertical markets. In the last years, chatbots have become one of the hottest trends in the technology market with technology giants like Google, Facebook and Microsoft releasing new platforms in the space. However, while the battle for chatbot platforms will continue to heat up between the big messaging platforms and a handful of upcoming startups, the initial sources of revenue might be in vertically specialized chatbots that leverage conversational interfaces and natural languages to solve very specific industry problems.\n\nThe funding round for Helpshift should not come as a surprise. In addition to the remarkable traction that the company has seen in the last few years, it is operating in a market that is ideal for the introduction of smart chatbots. Customer service solutions present a few characteristics that make it a strong target for leveraging chatbot and AI technologies:\n\n\u00b7 Conversational nature: Customer service solutions are conversational in nature. From that standpoint, chatbot solutions that leverage natural language processing can be improve the interactions between brands and customers.\n\n\u00b7 Interactions can be improved by learning: Customer service interactions can be improved by actively learning about customer preferences, historical interaction patterns etc. Many times, that information is not timely available to customer service agents. Smart chatbot platforms can actively process natural language and formulate answers by combining thouhsands of data points that can be relevant to that specific customer.\n\n\u00b7 It doesn\u2019t require complete automation: Differently from many other scenarios, chatbots in the customer service space can combined human and AI-powered interactions. In some scenarios, chatbots can formulate answers directly to a customer while in others can assist the customer service agent with relevant information to formulate the correct answer.\n\nThe fact that Microsoft and Salesforce opted for participating in Helpshift\u2019s funding round is also a very relevant point. Both vendors are expected to be very active in the bot technology space. Microsoft has already released very innovative bot solutions such as the Microsoft Bot Framework, Cortana and even a couple of \u201csmart bots\u201d such as Tay and Rowe. Salesforce hasn\u2019t yet released any specific bot technology but we should expect bots to be a natural extension of Salesforce\u2019 product such as CRM or Service Cloud. By investing in bot solutions like Helpshift, Microsoft and Salesforce are increasing their options to be a dominant force in the smart bot revolution."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-open-source-movement-that-beat-all-incumbents-6c4379ba7b7d?source=user_profile---------432----------------",
        "title": "The Open Source Movement that Beat all the Incumbents",
        "text": "The Open Source Movement that Beat all the Incumbents\n\nYesterday, Microsoft announced that it was expanding its support to the Spark technology stack by shipping a providing different versions of its R Server technology running on the popular MPP engine. This is the latest example of the level of support that the open source big data movement (Hadoop, Spark, etc) has received from enterprise software incumbents. A few years ago, the picture of fierce enterprise software competitors like Oracle, IBM, Microsoft, HP, EMC, SAP, etc universally lining up efforts behind an open source project that neither one of them control was completely unheard of. Somehow Hadoop changed everything.\n\nFrom the late 90s to the late years of the past decade, many popular open source movements repeatedly failed to be widely adopted by big enterprise software vendors. In many cases (ex: MySQL, JBOSS, etc), the incumbents shipped alternative technologies with more sophisticated support and commercial distribution mechanisms. In other cases, one incumbent will create the primary commercial distribution of the technology and all its competitors will provide alternative solutions. To that, you should add that, until recently, open source was a bad word within enterprise software giants like Microsoft, SAP or HP.\n\nThere are a series of factors that contributed to the universal adoption for Hadoop and its successors in the big data space by the enterprise software incumbents. At the beginning, it seemed that the Hadoop movement was going to follow the same path of previous open source movements. Oracle and Microsoft continuously tried to ship technologies that directly competed with Hadoop and the adoption by other enterprise software incumbents was not very impressive at the beginning. However, over time a series of factors combined to make Hadoop a universal favorite of the enterprise software giants:\n\n1. Too Big to Fight: At some point, the Hadoop developers and customer communities started growing to a level on which it made more sense for the incumbent to embrace it than to fight it.\n\n2. The alternatives sucked: Let\u2019s face it, Hadoop\u2019s story would have been very differently if any of the enterprise software incumbent would have managed to ship a platform that came anywhere close to its capabilities. After a few failures, the incumbents were convinced that embracing Hadoop was a more viable economic model than to continue trying to compete.\n\n3. The Hand of the Big Internet Companies: Typically, big data was a problem associated with big internet companies like Google, Yahoo, EBay, etc. The fact that most enterprises were looking at the internet giants as reference and the fact that those companies were incredibly supportive of Hadoop helped with the adoption of the big data stack within traditional IT departments.\n\n4. Microsoft\u2019s Help: Make no mistake, Hadoop\u2019s trajectory could have been way more difficult if Microsoft would have decided to continue competing with it. By partnering with Hortonworks and providing Hadoop as a first class service in the Azure cloud, Microsoft put a stamp of approval on the big data movement that has helped catalyzed its adoption in the enterprise.\n\n5. Startups Provided the Top Hadoop Commercial Distributions: One unique factor about the Hadoop movement is none of the top commercial distributions were owned by the enterprise software incumbents. Companies like Cloudera, Hortonworks or MapR still dominate the commercial Hadoop space. Without commercial domination, many of the incumbents to were forced to actively partner with these companies which tremendously helped with the adoption and distribution of Hadoop\n\nMany other factors have contributed to the universal adoption and support of Hadoop by big enterprise software incumbents. Hopefully the lessons learned from the Hadoop movement would be replicated by other open source technologies in order to improve its adoption by enterprise software giants."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ai-will-be-hot-in-the-enterprise-but-where-is-the-money-today-98548048a9af?source=user_profile---------433----------------",
        "title": "AI will be Hot in the Enterprise but Where is the Money Today?",
        "text": "Artificial intelligence (AI) is becoming the next big battleground in enterprise computing. With technology giants like Amazon, Google , IBM and Microsoft actively innovating in the space, the race for becoming the dominant AI technology provider is becoming a fascinating one. Despite all the hype, the levels of adoption of AI in the enterprise are very low compared to other hot technology trends.\n\nThe friction between the excitement around AI technologies and the still small adoption rates in the enterprise poses an interesting question for startups trying to become relevant in the space: In these early days, where are companies spending money in AI? From the initial case studies and evidence, there are 3 main areas in which enterprises are actively leveraging AI technologies:\n\n\u00b7 Bots and natural language processing: Smart bots are becoming a phenomenon in the B2C space and many brands are leveraging natural language processing technologies to interact with customers via conversational interfaces.\n\n\u00b7 Cognitive computing and document analysis: Extracting intelligence from large volumes of text is powering very innovative AI solution in industries like legal or health care. Additionally, we are seeing the first generation of startups in those industries that take advantage of cognitive computing to extract intelligence from documents that previously required humnan intervention.\n\n\u00b7 Video and image analytics: Public safety, agriculture and oil and gas are some of the industries that have been producing a lot of interesting work in the video and image analytics space leveraging AI and cognitive science.\n\nThe race for AI is going to be, without a doubt, a very intense one. However, in this early days, most of the real traction in the enterprise is coming from the work that IBM is doing with Watson. IBM\u2019s industry expertise has helped to adapt Watson to vertical scenarios faster than the competition. Additionally, IBM has done a remarkable job expanding Watson\u2019s capabilities into other industry trends such as cloud and mobile. In this early days, Watson is still the king of enterprise AI."
    },
    {
        "url": "https://medium.com/@jrodthoughts/video-of-the-week-mary-meekers-internet-trends-report-487692560513?source=user_profile---------434----------------",
        "title": "Video of the Week: Mary Meeker\u2019s Internet Trends Report",
        "text": "Every year I look forward to Mary Meeker\u2019s internet trends report. Mary is one of the thoughtful, analytical thought leaders in the technology space. Different from other presentation that rely on subjective opinion, Mary\u2019s analysis is always strongly backed by numbers.\n\nThis year\u2019s presentation was remarkable. Within the 213 slides, there are a few key points that were clearly highlighted:\n\nYou can see the full video and slide deck below:"
    },
    {
        "url": "https://medium.com/@jrodthoughts/innovation-is-hard-quarter-to-quarter-marketo-and-qlik-go-private-be862322e4e2?source=user_profile---------435----------------",
        "title": "Innovation is Hard Quarter to Quarter: Marketo and Qlik Go Private",
        "text": "Innovation is Hard Quarter to Quarter: Marketo and Qlik Go Private\n\nThis week two publicly traded, high flying technology companies have been acquired by private equity firms. Monday, the online marketing vendor Marketo announced that it was being acquired by Vista Equity Partners on a deal estimated in $1.79B. Just yesterday, Qlik Technologies technologies announced its acquisition by Thoma Bravo LLC for $3B. Both cases are examples of how tech stocks have been affected by the turbulence in public markets.\n\nDespite posting strong numbers, both Marketo and Qlik have been under constant pressure in the public market. Marketo recently reported strong growths in revenue but also an increasing net loss as well as a weak guidance.\n\nQlik has recently been downgraded by several analysts firms including RBC Capital and Citigroup.\n\nMarketo and Qlik Technologies can be considered leaders in their respective markets. However, both operate in highly competitive spaces filled with startups coming up with innovative and more affordable solutions. In that climate it is very hard for the incumbents to compete with that level of innovation while also keep up with the pressure of reporting strong quarterly earnings.\n\nMarketo and Qlik were not the only SaaS tech companies acquired this week. Salesforce.com also announced that it was acquiring Demandware for $2.9B. With tech stocks under constant pressure, the climate should be more favorable for M&A in the SaaS space. From that perspective, we could be witnessing the beginning of a strong wave of consolidation in the SaaS space.\n\nThis week\u2019s acquisitions confirm that private equity are incredibly active in the M&A for public SaaS companies. Previously, other SaaS companies like SciQuest and Cvent were also acquired by PE firms. This highly constrast with the lack of appetite for legacy, on-premise technologies like Tibco or Informatica which were PE targets on the previous years."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-aws-tax-and-the-innovators-dilemma-9bb6735cdecc?source=user_profile---------436----------------",
        "title": "The AWS Tax and the Innovator\u2019s Dilemma \u2013 Jesus Rodriguez \u2013",
        "text": "The AWS Tax and the Innovator\u2019s Dilemma\n\nThis week I participated in a super interesting debate about whether the innovator\u2019s dilemma have changed in the era of cloud and mobile platforms. Certainly, there are a few companies that have become masters at gaming the innovator\u2019s dilemma. The most notorious example: Amazon and the AWS cloud.\n\nFor decades, the innovator\u2019s dilemma has been one of the axiomatic principles of enterprise software markets since the industry\u2019s inception. In his famous book, Clayton M. Christensen explains how big companies are often disrupted by smaller, more innovative startups creating an almost unavoidable dynamic in competitive markets. The innovator\u2019s dilemma is applicable to any industry but has been incredibly relevant in the software and technology space in which changes tend to happen incredibly fast compared to other sectors. Despite the relevance of Christensen\u2019s theory, AWS seemed to have found the formula to solve the innovator\u2019s dilemma.\n\nWith the emergence of cloud computing, AWS has by far become the most dominant player in the space. Depending of the source, you will find that AWS owns about 60%-80% market share and that seems to still be growing at the same pace or faster than competitors. The growth doesn\u2019t only translate in adoption but also in revenue as shown in the following chart.\n\nWith its dominance, AWS seems to be taking every necessary step to avoid falling into the innovator\u2019s dilemma. From the pricing perspective, AWS has started a race to regularly decrease the price of its infrastructure services making it virtually impossible for competitors to offer a substantially better price. From the innovation perspective, AWS seems to be constantly releasing new infrastructure and platform services to power solution in new areas such as IOT, machine learning, etc. From the network effect standpoint, the IOT developer, customer and partner communities seem to be growing stronger than ever. AWS dominance is so remarkable that investors have recently coined a new term for this model: the AWS Tax.\n\nThe notion of the AWS tax is very simple. If more and more startups and established companies rely on AWS to build its software solutions and products, they are effectively sharing a portion of their financial and growth success with Amazon: they are paying the AWS tax. With software growing to become a multi-trillion dollar industry, the value of a company that owns the infrastructure and services powering the market is pretty much incalculable.\n\nIn addition to the strong network effect there are other factors that have allowed AWS to effectively game the innovator\u2019s dilemma. By providing the platform hat powers some of the most innovative startups in the world, AWS is becoming an important participant on any new technology trend not only from the technology standpoint but also from the pricing and adoption perspective. In that sense, AWS has created a model that doesn\u2019t only allow to avoid being disrupted by competitors by to allow their success."
    },
    {
        "url": "https://medium.com/@jrodthoughts/microsoft-is-dead-serious-about-machine-learning-4393739b32b1?source=user_profile---------437----------------",
        "title": "Microsoft is Dead Serious About Machine Learning \u2013 Jesus Rodriguez \u2013",
        "text": "Microsoft is Dead Serious About Machine Learning\n\nThis Thursday Microsoft will be hosting a demo day of its Accelerator Program entirely dedicated to machine learning. The news seemed very impressive consider the number and quality of companies focusing on machine learning Microsoft has nurture in a very short period of time. While there are other acclerators around the world focused on enterprise software, this one is one of the first programs entirely focused on machine learning. Let\u2019s take a look at the companies.\n\n\u00b7 Agolo \u2014 Connecting news, documents and your enterprise data to create summaries in real time.\n\n\u00b7 simMachine \u2014 Predictions with the WHY that include an intuitive and actionable visualization of the analysis.\n\n\u00b7 DefinedCrowd \u2014 Helping data scientists get better data, faster, by solving the pain point of data gathering and enrichment for AI researchers and developers.\n\n\u00b7 Plexuss \u2014 A machine learning platform that radically changes the way universities discover and recruit students.\n\n\u00b7 Affinio \u2014 Marketing intelligence platform that leverages the interest-graph to understand the culture of today\u2019s consumers.\n\nAs you can see, many of the companies are focused on applying machine learning to well-known industry problems. This focus will complement Microsoft\u2019s broad group of machine learning technologies.\n\nMicrosoft\u2019s investment in machine learning technologies expands across different of its products and platforms. The following list is just an example of some of the most established machine learning technologies coming from the Redmon giant:\n\n\u00b7 SQL Server 2016 R Analytics: The new version of the Revolution Analytics suite now distributed as part as SQL Server.\n\n\u00b7 Microsoft Cognitive Services: Microsoft\u2019s Watson competitor offers over 20 APIs that abstract cognitive capabilities such as text, vision, voice data analysis.\n\n\u00b7 Microsoft\u2019s Bots: Microsoft has been actively releasing Bots such as CaptionBot or Tay (not the greatest example) that actively leverage machine learning to optimize its interactions with users.\n\nMicrosoft\u2019s continuous investments is machine learning technologies is starting to impact mainstream products like Windows, Office, Xbox or future consumer products like Hololens. By leveraging these unique distribution, Microsoft in a unique position to expand the footprint of its machine learning offerings. In the near future, we should expect machine learning to be a first class citizen of every modern Microsoft technology."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-blockchain-on-rails-efd6248e460e?source=user_profile---------438----------------",
        "title": "The Blockchain on Rails \u2013 Jesus Rodriguez \u2013",
        "text": "I received a tremendous amount of interesting feedback from my recent post about \u201c6 Things That The Blockchain Needs to Become Mainstream\u201d. One of the points that seems to be the subject of debate is the need for mainstream programming tools and frameworks. In the post, I make the point that the blockchain needs the equivalent of a Ruby of Rails movement.\n\nThe Rails movement remains one of the primary examples of transforming an already powerful technology (the Ruby programming language) into a mainstream movement. By addressing some of the main technical and business limitations for the adoption of Ruby, Rails became a movement that presented a simpler, fresher alternative for web development to established platforms like .NET and J2EE.\n\nToday, we can trace many parallels between the path of adoption of blockchain technologies and the challenges faced by the Ruby community a few years ago. I know some of the comparisons might seem extreme but hopefully you will be able to see the analogy. Let\u2019s explore some of the key aspects that the blockchain could learn from the Ruby on Rails movement.\n\nOne of the key things that made Ruby on Rails successful was the automation of key elements of web applications such as DB access, web page rendering, etc. Similarly, a blockchain development platform should abstract key application building blocks like data storage, backend services, messaging and other prototypical parts of blockchain applications.\n\nFrom the technology to the marketing messages, Rails screams simplicity. This was a key factor to attract non-Ruby developers to the platform. Functionally, the blockchain is an extremely complex technology that can result intimidating to many developers. Lowering the entry point for developers building blockchain application will be essential to improve the adoption of the technology.\n\nRuby gems became one of the most popular elements of the Rails framework. The ability of packaging and provisioning functionality using a simple command line tool made it extremely easy for developers to leverage new capabilities released by the Rails community. At the moment, blockchain development frameworks can really benefit from simple packaging and distribution mechanisms that streamline the modularization of blockchain applications.\n\nSince the early days, the Ruby on Rails was incredibly smart about integrating the framework into some of the most popular IDEs in the market such as Eclipse or Netbeans. This allowed developers to implement Rails applications using a familiar set of tools and processes. Currently, blockchain applications are still missing a decent level of integration with popular IDEs and corresponding tools. Enabling this will be another step to lower the entry point for developers building blockchain applications.\n\nOne of the key aspects to the success of Ruby of Rails was that it was able to incorporate modules and libraries developed in other Ruby frameworks. At the moment, the interoperability between the different blockchain frameworks is limited to say the least. The number 1 goal of blockchain development frameworks today should be to streamline adoption of blockchain technologies and, for that, they can benefit for better levels of interoperability.\n\nThese are just some of the factors that, I believe, will be needed for successful blockchain development frameworks. Borrowing a few pages from successful development frameworks such as Ruby on Rails can definitely be helpful to build a development movement around blockchain technologies. At the end blockchain on rails doesn\u2019t sound that bad, does it?"
    },
    {
        "url": "https://medium.com/@jrodthoughts/6-things-that-the-blockchain-needs-to-become-mainstream-fe2360097e4f?source=user_profile---------439----------------",
        "title": "6 Things That The Blockchain Needs to Become Mainstream",
        "text": "6 Things That The Blockchain Needs to Become Mainstream\n\nThe blockchain is one of the most fascinating technologies of the last few years. Notoriously for powering the infrastructure behind Bitcoin, the blockchain offers a unique set of capabilities to enable decentralized, trustless architecture models that were impossible to conceive a few years ago. From industries like healthcare to legal, the blockchain can redefine some of the most traditional business applications that rely on centralized authorities and control.\n\nDespite the technical value of the blockchain, most industries are still in very early evaluation stage of the technology and we can\u2019t claim that its become mainstream within developer communities. In order to deliver to its full potential and become a relevant technology trend for the next decade, the blockchain community and early adopters will have to develop a series of foundational aspects that have little to do with technology.\n\nWith the uncertainty surrounding bitcoin, I think the blockchain will benefit from the emergence of another consumer application that can highlight the capabilities of the technology in the eyes of non-early adopters. Bitcoin has certainly been a revolutionary technology but it also remains the only large scale application built on the blockchain.\n\nComplementing the previous point, the adoption of the blockchain within vertical industries will be accelerated if we can created a large-scale vertical solution powered by the blockchain. While many startups are creating super innovative blockchain application, the adoption within large enterprises remains relatively small. From all the sectors experimenting with the blockchain, financial institution seem like an idea candidate to create that first killer industry solution.\n\nIBM and Microsoft have taken the first steps towards blockchain as a service (BaaS) models by distributing blockchain technologies as part of the Bluemix and Azure PaaS respectively. I believe BaaS is a very important step to remove the complexities of operating private blockchain and expose the technology to millions of developers.\n\nSystem Integrators (SI) will be essential for the adoption of the blockchain in highly regulated industries which, ironically, are the majority of the industries experimenting with the blockchain. Establishing solid strategic alliances with large SI will add a much needed credibility to blockchain solution and it will accelerate its distribution.\n\nIn recent years, we have seen the emergence of very impressive blockchain tools and frameworks. Ethereum remains the best well known blockchain platform in the markets but there are other incredibly impressive frameworks such as Lisk, IBM\u2019s Hyperledger, etc. More and better tools and frameworks will be needed for the blockchain to become mainstream. TO put it in blunt terms: we need a Ruby on Rails for the blockchain.\n\nThe blockchain developer community has been steadily growing over the last few years but its still relatively small compared to other software development platforms. Nurturing and growing a strong developer community will be essential to make the blockchain mainstream in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/hpe-and-dell-crazy-similarities-from-pcs-to-services-to-software-2dce6d8e4ee1?source=user_profile---------440----------------",
        "title": "HPE and Dell Crazy Similarities: From PCs to Services to Software",
        "text": "This week, HP Enterprises (HPE) announced that it was going to merge its IT services unit with CSC in an effort to focus on its software and infrastructure efforts. Wall Street reacted incredibly positive to the news with HPE and CSC stocks soaring 7% and 15% respectively.\n\nWhile reading the news, I couldn\u2019t avoid thinking about the similarities of HPE\u2019s strategy with its archrival Dell. While Dell and HP have been competing fiercely for the last 30 years, it\u2019s shocking to see how similar their strategies have been at any given time. The competition between the two giants has expended different sectors of the technology markets such as PCs, professional services, cloud, infrastructure software, etc. Let\u2019s take a look.\n\nDuring the late 1990s and early 200s, both Dell and HP alternated the number 1 spot in PC sales worldwide. The competition had its peak with HP and Compaq merger in 2002, a disaster that became an example of failed M&A in business schools.\n\nAfter 2005, Dell and HP expanded their competition into the IT services and business solutions market. This competition translated into massive M&A activity like HP acquiring EDS for $14B in 2008 and Dell acquiring Perot Systems for $3.5B in 2009.\n\nTheir relentless focus on dominating the laptop retail market caused that both Dell and HP missed the mobile revolution. Since the launch of the IPhone in 2007, Dell and HP started seeing steady declines on retail sales. This decline became critical at the end of 2011 when smartphone sales passed soared passed PC sales for the first time in history.\n\nBoth Dell and HP attempted have been attempting to become relevant players in the infrastructure and platform as a service spaces. Both companies focused their strategies on building on open source initiatives such as OpenStack and Cloud Foundry. While both Dell and HP have made important progress in their cloud efforts, they have failed to become a first tier player in the space. Last year, HP announced that it was abandoning its public cloud platform efforts to focus on the hybrid and private cloud space.\n\nIn recent years both HP and Dell struggled with constant pressure from public shareholders which became a challenge for their aggressive transformation efforts. That level of pressure forced both companies to make bold moves: Dell decided to go private in 2014 with the help of Silver Lake Management and HP split into two public traded companies HPE and HP INC.\n\nAfter 30 years of competition, Dell and HPE are going at it again by reinventing themselves as enterprise software and infrastructure services. Dell is in the middle of a mega merger with EMC that can end up with one of the most impressive enterprise infrastructure portfolios in the market. By spinning out its enterprise services unit, HPE is now a leaner $32B company focused on enterprise software and infrastructure."
    },
    {
        "url": "https://medium.com/@jrodthoughts/who-will-first-monetize-ai-at-scale-c9dfff846f8f?source=user_profile---------441----------------",
        "title": "Who Will First Monetize AI at Scale \u2013 Jesus Rodriguez \u2013",
        "text": "Who Will First Monetize AI at Scale\n\nThe battle in the artificial intelligence(AI) market has been heating up. IBM, Microsoft, Amazon, Apple, Facebook and Google are all continuously releasing impressive technologies in the space that are capturing the minds of developers and customers. From a market perspective, AI is called to become a pillar of the next generation of software technologies. Without a doubt, we can expect all those software giants to capture segments of the AI space. However, the most interesting question is who can monetize AI at scale first.\n\nMonetizing a technology at scale goes beyond its technical capabilities. Typically, the path to monetization at scale is a combination of different factors such as the following:\n\n\u00b7 Leveraging well-established asset like user or customer community as the main distribution mechanism.\n\n\u00b7 Expand the offer across different distribution channels.\n\n\u00b7 Provide a compelling value proposition for prospects to become buyers.\n\n\u00b7 Build network-effects into the product so that paying customers can attract other paying customers.\n\nThere are other factors that can influence the monetization at scale of a specific technology but the aforementioned ones must be definitely considered when evaluating a monetization model. In the AI space, the picture is pretty complicated as the top vendors already enjoyed certain level of success and impressive access that can be devoted towards the monetization of AI. We\u2019ve tried to summarized those factors in the following matrix:\n\nThe previous matrix clearly highlights the potential of Amazon, Facebook, Apple, IBM, Microsoft and Google to monetize AI. However, we think in the short term Google has a bit of an edge and more options to quickly monetizing AI at scale. Here are a few points that might help to explain that reasoning:\n\n\u00b7 Wider AI Assets: Google has been investing in AI across different technology areas such as mobile, cloud, DeepMind and even chips.\n\n\u00b7 Google Search Distribution: We can\u2019t underestimate the power of Google Search as a distribution channel.\n\n\u00b7 Consumer and Enterprise Presence: Google is incredibly well positioned to monetize AI in both the consumer and enterprise markets.\n\n\u00b7 Google Car: This is an incredibly unique asset that has no equivalent among the other vendors"
    },
    {
        "url": "https://medium.com/@jrodthoughts/innovation-in-the-enterprise-is-coming-from-the-big-corp-labs-not-only-from-garages-b1c29442855b?source=user_profile---------442----------------",
        "title": "Innovation in the Enterprise is Coming from the Big Corp Labs not Only from Garages",
        "text": "Innovation in the Enterprise is Coming from the Big Corp Labs not Only from Garages\n\nLas week during its IO conference, Google made a series of announcements that signal to the market that it intends to be a contender in new markets such as artificial intelligence, digital assistants, IOT, etc. From that perspective, Google continues an aggressive competition with technology giants Microsoft, Amazon, IBM, Salesforce or Facebook trying to become the dominant force in new technology areas.\n\nThis picture was unconceivable a decade ago in which the technology market was dominated by incumbents that were too slow to innovate and compete with smaller startups. Today that small group of companies is driving a lot of the innovation and entering first into new technology markets such as virtual reality, cognitive science, cloud computing, IOT platforms, etc. From that perspective, the corporate innovation labs of those companies are doing a phenomenal job keeping up and competing with the startup ecosystem. The following chart might help to illustrate this picture:\n\nContrary to the traditional mantra of enterprise software innovation, the incumbents have been able to enter these markets with in-house innovations rather than via pure M&A. Even though the aforementioned areas have been very active from the M&A perspective, the acquisitions have focused to expand and accelerate existing platforms. Let\u2019s look at a few examples:\n\n\u00b7 After launching IBM Watson, IBM acquired Alchemy to accelerate the capabilities of the IBM Watson platform. Today\u2019s Alchemy is part of the Watson Developer Cloud.\n\n\u00b7 After releasing AWS Kinesis, Amazon acquired IOT startup 2lemetry to expand its IOT offerings. Today, 2lemetry is part of the AWS IOT Hub. Facebook acquires w.ai\n\n\u00b7 After announcing its efforts around the Facebook Messenger platform and the M digital assistant, Facebook acquired Wit.ai to expand its efforts in the area of artificial intelligence."
    },
    {
        "url": "https://medium.com/@jrodthoughts/google-is-shifting-from-mobile-first-to-ai-first-1c20926f04bd?source=user_profile---------443----------------",
        "title": "Google is Shifting from Mobile-First to AI-First \u2013 Jesus Rodriguez \u2013",
        "text": "Google is Shifting from Mobile-First to AI-First\n\nThis week was full of exciting announcements at Google IO. Beyond the hype, Google outlined a new vision for the future of technology evolving around a central component: artificial intelligence. In a world in which many of the top software companies are still battling for dominance in established areas such as mobile and cloud, Google is banking heavily on AI as the fundamental driver of future technology trends.\n\nThe AI-related announcements at Google IO varied from digital assistant to AI-powered chips. That\u2019s an indication that Google is looking at AI as a ubiquitous functional block of future technology trends regardless of the specific area. Let\u2019s take a look at some of the cool announcements:\n\n\u00b7 Google Assistant: A new messaging app with the capability of understanding natural language and respond to user\u2019s input. Google\u2019s Assistant is also context-aware which means that factors elements like location or time in order to interpret the requests from users and produce more accurate responses.\n\n\u00b7 Google Home: A smart speaker with always-listening microphones, Google Home is a direct competitor or Amazon\u2019s Echo. Google Home leverages Google\u2019s Assistant to interpret and process user requests.\n\n\u00b7 Google AI-Chip: One of the most exciting announcements of IO was the announcement of a new ASIC (application-specific\u2013 integrated-circuit) for deep neural nets. Neural nets are a key component of deep learning used for tasks such as identifying objects in photos or natural language commands. Google calls its chip the Tensor Processing Unit, or TPU, because it underpins TensorFlow, the software engine that drives its deep learning services.\n\nThese series of announcements, followed the ones made at the GCP Next Conference in which Google released the new version of Tensor Flow and announced the Google Cloud Machine Learning platform. One thing is clear: from IOT, to mobile, to cloud, Google is backing in the AI-first software era."
    },
    {
        "url": "https://medium.com/@jrodthoughts/android-instant-apps-is-awesome-and-it-changes-so-many-things-about-mobile-5e409ffe7e56?source=user_profile---------444----------------",
        "title": "Android Instant Apps is Awesome and It Changes So Many Things About Mobile",
        "text": "This week, at the IO conference, Google announced some very innovative technologies in the mobile and IOT space. Among those, Android Instant Apps seems to be capturing a lot of the headlines. Conceptually, Android Instant Apps provides a mechanism for launching apps directly from a deep link without the need to physically install it in the device.\n\nAs you can imagine, Android Instant Apps blurs the line between native and mobile-web applications opening new possibilities for mobile apps. The magic of Instant Apps is based on Google Play new mechanisms to only download and run the module of the app required by the deep link information. This would be possible because Instant Apps will be highly modularized compared to traditional Android Apps. However, this new models doesn\u2019t entail any major changes for developers.\n\nAs a developer, you can use the same source to extend an Android app with Instant App capabilities. The main effort required is to modularized the app in a way that Google Play can download parts of it on the fly. As you can imagine, Instant Apps can bring a profound change to many aspects of traditional mobile app development. Here are some aspects that I think could be reimagined by the adoption of Android Instant Apps:\n\nDiscovering mobile applications in traditional app marketplaces is an extremely challenging endeavor. With Instant Apps, app makers can explode traditional content distribution mechanisms such as websites, email or instant messaging to reach users and drive them to their mobile applications. From that perspective, traditional discovery mechanisms such as SEO could even more applicable to the discovery of mobile apps.\n\nThe Role of the App Store\n\nSince the launch of the IPhone, app marketplaces have become the main distribution mechanism for mobile apps. As a result, the battle for visibility in the app store is a constant struggle for most mobile app providers. Android Instant Apps could change the role of the app store from the solely distribution mechanism to a repository hosting the binaries for mobile applications. Additionally, Instant Apps might enable the emergence of other types of app catalogs in the form websites or messaging apps that will allow users to consume mobile apps without having to download them from the app store.\n\nAndroid Instant Apps relies on the execution of modules within a mobile app. With the evolution of the technology, we should expect developers to put more effort into partitioning mobile apps into smaller modules that can perform atomic functions. From that perspective, it is possible that the new form of Android App will be smaller and very focused on a specific task in order to take advantage of the distribution and discovery benefits of Instant Apps.\n\nFrom certain perspective, Android Instant Apps can be seen as a step towards Google\u2019s dominance in mobile search. By leveraging deep links as a description mechanism and taking advantage of traditional models as distribution, Google can now more effective index and discover mobile apps using traditional changes mechanisms.\n\nUntil now, mobile advertisement has focused on delivering targeted content within specific mobile applications. Using Android Instant Apps, deep links to mobile apps can be distributed via traditional channels such as websites, emails, messaging platforms, SMS etc. That fact can profoundly change the role of mobile advertisement as app makers can start leveraging those traditional channels to improve the discoverability of their mobile app. Additionally, the modularization of Instant Apps opens the door for more targeted advertisement mechanisms.\n\nDownloads, active sessions, recurrent users, etc are some of the traditional metrics in mobile analytics. The entire mobile analytics model has been conceived based on the notion that a user will download an app from a marketplace and open it on a regular basics. Android Instant Apps introduces new forms for launching mobile applications without having to install the full app. That model brings a series of new metrics to describe the user behavior in mobile apps.\n\nThese are just some of the elements that I think would evolve with the lunch of Android Instant Apps. While the technology is in very early stage, the possibilities are incredibly encouraging."
    },
    {
        "url": "https://medium.com/@jrodthoughts/bots-are-the-new-apps-voice-is-the-user-interface-ai-is-the-protocol-and-messaging-apps-are-the-3c9c5cfcfa77?source=user_profile---------445----------------",
        "title": "Bots are the New Apps, Voice is the User Interface, AI is the Protocol and Messaging Apps are the\u2026",
        "text": "Bots (or chatbots) seem to be taking the technology world by storm. Not a week goes by without some exciting announcements related to chatbots. Just yesterday at the F8 conference, Facebook announced a new chatbot platform for its messenger app. This announcement comes just a few days after Microsoft\u2019s release of its Bot Framework at the Build Conference. While we are still in the early days of the \u201cBot revolution\u201d, we can clearly see how chatbots are going to become an integral part of the consumer an enterprise software ecosystem.\n\nThe raise of chatbots have been catalyzed by the increasing advancements in artificial intelligence(AI) and voice platforms that are called to power a new generation of software applications. From that perspective, chatbots can be considered a 3rd generation platform following the web and mobile apps.\n\nIn this new world, we can think about voice as the new user interface, bots as the new apps and AI as the new protocol.\n\nRecently, I\u2019ve written extensibility about how conversational interfaces in general and voice interfaces specifically are called to play a pivotal role in the next generation of software applications. From that perspective, voice can be considered the next evolution of the user interface. The metaphor applies if we think about conversational interfaces as a new mechanism to guide the interactions of a user with a software application.\n\nIn a conversational user experience, a user will interact with software application by using semantically rich commands and very simple user interfaces. Differently from its predecessors, a conversational UX can express the same action using a large number of language variations using constructs like synonymous, slang phrases etc. Additionally, a conversational UI should leverage linguistic analysis and artificial intelligence to gradually improve as users interact more with it.\n\nIf voice and conversation is the new UX then bots can be considered the new apps. From that perspective, bots abstract a specific tasks or processes that can be accomplished using a conversational UX. Differently from traditional apps, chatbots typically run in a messenger application which, very ironically, can be considered an app from the \u201cprevious generation\u201d. I know, crazy\u2026\n\nFrom the functional standpoint, chatbots should be able to issue voice and text commands and receive responses in the form of text of simple user interfaces. While most people consider chatbots text-only interfaces, we are already seeing the first iterations of simple UX models that can be used in bots solutions. As chatbots evolve, we should expect to see new platforms that automate important elements of its lifecycle such as testing, monitoring, discovery, security, etc.\n\nAI is an essential component of chatbot solutions. While we should expect to see plenty of \u201cdumb\u201d bots, the really good ones will leverage AI techniques such as linguistic analysis, image recognition, concept inference, sentiment analysis, text enrichments and many other techniques in order to enrich the user experience. Just as humans, intelligent bots are supposed to improve the communication and efficiency as they interact more with users.\n\nMessaging applications such as Slack, Skype or Facebook Messenger are called to play the role of a \u201cbrowser\u201d for chatbot solutions. From that perspective, messaging apps don\u2019t only provide the container for chatbots but also provide mechanisms such as discovery or provisioning that are essential to effectively use bot solutions. Additionally, messaging apps bring native distribution channels to bot applications. While some bots are going to be optimized for specific messenger applications, we should expect to see bot solutions that work across different messaging solutions.\n\nThese are just some ideas about how I think about the new world of bot solutions. Undoubtedly, bots will become an important element in the future of consumer and enterprise apps and give us the opportunity to completely re-imagine how we interact with software applications today."
    },
    {
        "url": "https://medium.com/@jrodthoughts/how-can-google-cloud-win-in-the-enterprise-f858be89d7a0?source=user_profile---------446----------------",
        "title": "How can Google Cloud Win in the Enterprise ? \u2013 Jesus Rodriguez \u2013",
        "text": "Last week was packed with exciting announcements from Google Cloud targeted to increase its presence in the enterprise. From exciting technologies in areas such as machine learning or security to great customer announcements with top brand like Apple, Home Depot, Disney, Macy\u2019s or Spotify, Google Cloud made it clear that they are serious about the enterprise.\n\nDespite the recent excitement, Google Cloud has a difficult path ahead to become a dominant platform in the enterprise. Currently Google Cloud is still a distant number 4 player in the enterprise cloud space beyond AWS, Azure and IBM Bluemix. However, under Diane Green\u2019s new leadership, Google Cloud is starting to made serious inroads to appeal to enterprise customers. From that perspective, I believe there are 4 clear points that can make Google Cloud a top enterprise cloud platform:\n\nLast week we finally heard a consistent message for all Google Cloud services: faster, simpler and able to operate at Google\u2019s scale. This is Google playing to their strengths. The same way Azure\u2019s identity is about Microsoft\u2019s understanding of enterprise scenarios or Bluemix\u2019s is strong in regulated industries due to IBM\u2019s penetration in those markets, Google Cloud is relying on core elements of Google\u2019s DNA: speed, simplicity and scalability.\n\nIn order to become a dominant enterprise cloud platform, Google Cloud needs to breach gaps with AWS, Azure and Bluemix in some very specific areas. The list below includes some of the that should be included Google Cloud to be able to compete more aggressively with the lead enterprise PaaS solutions.\n\nIn addition to bridging the gap with competitors in some of the areas listed above, we can expect Google Cloud to start out-innovating competitors in new areas. Without speculating about a specific directions, some of the following areas\n\nIn addition to delivering unique capabilities, Google Cloud should start expanding its distribution models using some of the unique strengths of the Google brand. Below are some of the segments that I think can improve Google Cloud\u2019s distribution model in a unique way."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-innovator-s-dilemma-and-enterprise-iot-platforms-5e51bc3d5d24?source=user_profile---------447----------------",
        "title": "The Innovator\u2019s Dilemma and Enterprise IoT Platforms",
        "text": "The original article was published on CIO.com\n\nThe innovator\u2019s dilemma has been one of the axiomatic principles of enterprise software markets since the industry\u2019s inception. In his famous book, Clayton M. Christensen explains how big companies are often disrupted by smaller, more innovative startups creating an almost unavoidable dynamic in competitive markets.\n\nFrom databases to CRM systems, the innovator\u2019s dilemma has been a golden standard in enterprise software markets. Recently, the enterprise Internet of Things (IoT) platform space has developed patterns that seem to be defying some of the principles of Christensen\u2019s theory. The enterprise IoT market is witnessing how incumbents like Microsoft, Amazon, and IBM are constantly delivering innovative solutions that are disrupting the early players in the space.\n\nEnterprise IoT platforms are one of the most important segments of the IoT market. From the functional standpoint, enterprise IoT platforms focus on enabling backend capabilities such as device management, stream data processing, messaging, or analytics that are essential elements of enterprise IoT solutions.\n\nIn the early day of enterprise IoT, the market was incredibly crowded with startups delivering from individual services to complete platforms that enabled backend capabilities for IoT solutions. From that perspective, it seemed like the enterprise IoT market was destined to follow the traditional innovator\u2019s dilemma model in which startups disrupt established incumbents by rapidly innovating in a specific space. However, in just a year, the enterprise IoT platform has completely changed with companies like Salesforce, Microsoft, IBM, and Amazon releasing some of the most innovative enterprise IoT platforms in the market, making it incredibly difficult for startups to compete in the long run.\n\nIn mature enterprise software markets, there are several factors that allow innovative startups to disrupt incumbents while driving a new wave of innovation in the space. Superior technology, pricing, traction in specific geography, strong developer or partner communities, and simpler distribution models are some of the factors that can help startups to disrupt incumbents in established enterprise software markets. These dynamics are the foundation of the innovator\u2019s dilemma. The enterprise IoT market is experiencing an interesting phenomenon in which incumbents have become masters at gaming the innovator\u2019s dilemma factors. Let\u2019s take a look:\n\nDelivering more innovative technologies is the main factor that helps startups to disrupt incumbents in the enterprise software market. The enterprise IoT platform space is defying this principle, exemplified in incumbent solutions such as Azure IoT Suite, AWS IoT, IBM IoT Foundation, and Salesforce IoT Cloud which have delivered some of the most innovative technologies in the space. From a certain perspective, the IoT platforms provided by the big incumbents are disrupting the market share gained by IoT startups in previous years. Additionally, by including IoT suites as part of PaaS solutions, incumbents are providing a very broad and sophisticated set of capabilities that is hard to emulate by IoT startups.\n\nFlexible pricing models are another mechanism that startups use to disrupt incumbents in enterprise software markets. In the enterprise IoT platform space, incumbents seem to have implemented simple pricing models that make it incredibly affordable for organizations to start building IoT solutions on their platforms. More importantly, lead IoT platform providers such as IBM Bluemix, Microsoft Azure, and AWS seem to have embarked in a race to constantly reduce the cost of IoT services. Like any other cloud platform services, incumbents are more interested in acquiring a large number of enterprise customers instead of signing large deals. These pricing dynamics make it incredibly difficult for IoT startups to disrupt the incumbent platforms in the space.\n\nMany enterprise software startups are able to disrupt established incumbents by gaining traction in a specific geographic market. Language barriers, regulations, and understanding of the local business development models are some of the factors that prevent enterprise software incumbents from rapidly expanding their international presence. However, geographic traction doesn\u2019t seem to be a disruptive factor in the enterprise IoT space as platforms like AWS IoT, Azure IoT, Salesforce IoT Cloud, and IBM IoT Foundation are building in their respective cloud platforms which are available and operating in a large number of countries. Contrary to conventional market dynamics, global availability is a factor helping enterprise IoT platform incumbents to prevent the entrance of new startups in the space.\n\nStrong developer communities have become a disruptive factor in enterprise software markets. By nurturing large developer communities, startups can penetrate large organizations in ways that can be challenging for enterprise software incumbents. In the enterprise IoT platform space, incumbent solutions such as AWS IoT, Azure IoT, Salesforce IoT Cloud, or IBM IoT Foundation have built impressive developer communities that are, arguably, a multiple larger than the ones built by IoT platform startups.\n\nSimple distribution models are another disruptive element in enterprise software markets. In the enterprise IoT platform space, incumbents like Microsoft, Amazon, Salesforce, and IBM have developed robust distribution channels including partnerships with device manufacturers, system integrators, and IoT ISVs. The ubiquitous distribution makes it challenging for IoT startups to exploit specific distribution channels as a disruption mechanism.\n\nDespite the factors enumerated in the previous section, it would be foolish to assume that the enterprise IoT platform market is already defined by a race between AWS IoT, Azure IoT Suite, IBM IoT Foundation, and Salesforce IoT Cloud. The market is certainly young enough to accommodate the entrance of new players. However, it is a fact that the enterprise IoT platform incumbents have become masters at gaming the innovator\u2019s dilemma. From this perspective, startups will have to be incredibly creative and aggressive to remain relevant in the increasingly competitive enterprise IoT platform market."
    },
    {
        "url": "https://medium.com/@jrodthoughts/scaling-enterprise-software-companies-is-harder-than-ever-567338dca35a?source=user_profile---------448----------------",
        "title": "Scaling Enterprise Software Companies is Harder than Ever",
        "text": "There is a common misconception within the startup community that building companies is easier than ever. Part of the argument is the amazingly cheap costs of infrastructure available with cloud infrastructures such as AWS or Google Cloud, the relatively easy access to early stage capital as well as the free distribution and commercialization channels available to any company. More importantly, this argument has been fueled by some large exits recently experienced by small companies such as Instagram or Whatsapp in the consumer space.\n\nWhen we think about this argument, we can is about 75% true. If we divide the process of building a company between early stage (building) and late stage (scaling) and then we segment that universe between consumer and enterprise solutions. We can arrive to the following conclusions:\n\nWithout getting into a detailed analysis of the factors that contribute to this phenomenon, we can list a few usual suspects:\n\nThe size of the enterprise software markets have drastically expanded over the last few years. As a consequence, companies need to capture a bigger size of the market to be relevant on any particular space which results in a harder endeavor compared to the equivalent task a few years ago.\n\nToday, enterprise software is a global business. The commoditization and globalization of distribution channels as well as the flexible global trading laws, have allowed customers in emerging economies to have access to the same enterprise software solutions than their peers in first world economies. As a consequence, every scalable enterprise software companies is faced with the challenge of acquiring customers in emerging markets which results in large sales and marketing operations.\n\nWith the evolution of enterprise software comes the complexity on the requirements of new solutions. As businesses have evolved they have faced more complex business dynamics that are rarely addressed by default in enterprise software packages. In order to acquire those types of customers, enterprise software companies need to spend more and more time and resources providing the right levels of customizations of their solutions.\n\nBecause starting an enterprise software company is relatively easy, you find a lot of early stage (post-seed, pre-Series A) companies in any segment of the market. As a result, competition is constantly intense which requires companies to deploy the right level of resources to stay competitive. Additionally, newcomers in the space always lower the price and try to simplify the customer acquisition model which poses new challenges for companies in growth mode.\n\nI hope some of the factors below make sense. The enterprise software space is more exciting than ever but, as mentioned before, I often think there is a strong misconception about efforts that take to fully scale a modern enterprise software business. Reading this, you have to ask yourself: are you sure you don\u2019t want to build a messaging application? ;)"
    },
    {
        "url": "https://medium.com/@jrodthoughts/bi-4-0-is-business-intelligence-entering-its-4th-generation-46312b58be2d?source=user_profile---------449----------------",
        "title": "BI 4.0: Is Business Intelligence Entering its 4th Generation?",
        "text": "This week, I had a very interesting conversation with a thought leader in the business intelligence (BI) space about whether we are starting to see the first glimpses of the 4th generation BI platforms. I am not a big fan of attaching version numbers to industry trends and in this case is particularly hard considering that predecessor trends (BI 2.0 and BI 3.0) are still evolving strong. However, I thought BI 4.0 offers a good umbrella to group some of the transformative developments we are experiencing in the BI space.\n\nIn the last couple of years, the BI ecosystem has seen an explosion in the number of machine learning and cognitive data technologies that are finally making data science a reality for enterprises. This new world of intelligent data solutions focus on capabilities that were not present in the previous generation of BI technologies and are pushing the boundaries of the BI space to new levels. Entering BI 4.0.\n\nThe first generation of BI technologies were based on on-premise, client-server models in which reports were produced by IT groups based on specific business requirements. From the data infrastructure standpoint, this type of BI technologies were tied to relational and multi-dimensional database models that were the foundation of IT data architectures. This generation of BI Platforms was dominated by incumbents like Microsoft Reporting Services, IBM Cognos or SAP Business Objects.\n\nThe emergence of cloud computing and the evolution of NOSQL and big data database models were the catalyst for the second generation BI platforms. This new series of solutions focused on leveraging cloud enablement models to remove the friction of on-premise infrastructures and integrate with emerging data sources such as SaaS business systems or social networks. BI 2.0 also capitalized on the raise of big data and NOSQL platforms to provide solutions that analyze large amounts of semi-structured or unstructured data. Platforms like GoodData, Birst, Grow etc led the BI 2.0 movement.\n\nThe creation of self-service, visually appealing dashboards is the fundamental element of the third generation of BI technologies. BI 3.0 shifts BI processes from IT-centric to business-centric by enabling the authoring of visual dashboards by business users in a self-service model. BI 3.0 was also accelerated by the emergence of the enterprise mobile and collaboration trends. From that perspective, BI 3.0 solutions allow users to consume dashboards from mobile devices and applications and actively leverage coloration models to capture collective knowledge about a specific solutions. Solutions like Tableau and QlikView led the BI 3.0 movement.\n\nThe BI 4.0 movement (if we can agree on the term) is being led by the emergence of machine learning technologies as well as real time data analysis catalyzed by the evolution of trends like the internet of things (IOT). From the capability standpoint, BI 4.0 solutions extend traditional report techniques with predictive and proactive analytic models that enable additional levels of intelligence about business data sources. From that perspective, BI 3.0 focus less on creating reports that represent well-known situations in the past and more on discovering unknown insights and predictive outcomes about data in the future.\n\nThe real time analysis of data streams is also a key element of BI 4.0 solutions. In that sense, stream analytic solutions that collect and aggregate real time data signals from sources like smart devices or social networks are a foundational component of BI 4.0 suites. Finally, cognitive computing and deep learning capabilities that enable the analysis of text, images or voice data sources is becoming increasingly common in this new generation of BI solutions.\n\nWhile the BI 4.0 is still in its infancy, we can already identify platforms that are leading the movement. IBM Watson, Microsoft Cortana Analytics, Apache Spark, AWS Kinesis are some of the well-known technologies in the space. Also a new generation of platforms like Dato, Databricks or H20.ai are rapidly emerging with unique innovations and solutions in the BI 4.0 space.\n\nHonestly, I have no idea and I hate playing analyst games but I think the idea if definitely worth exploring. From the capability standpoint, BI 4.0 focus on areas that are notably different from its predecessors. Also, we are seeing the emergence of brand new players in the space which is always a good sign that a new movement is forming.\n\nWhile the term BI 4.0 is certainly debatable, the fact that machine learning, cognitive computing and real time data analysis are transforming the landscape of BI solutions is very obvious. The best times for the BI space are certainly ahead of us."
    },
    {
        "url": "https://medium.com/@jrodthoughts/5-tech-trends-that-will-drive-the-next-wave-of-mobile-innovation-in-the-enterprise-f9d565ec7246?source=user_profile---------450----------------",
        "title": "5 tech trends that will drive the next wave of mobile innovation in the enterprise",
        "text": "The original article was published in CIO.com\n\nMobile continues to be an important point on the agenda of most CIOs. While some trends like mobile device management (MDM) have seen mainstream adoption within business applications, the adoption of mobile technology platforms have been considerably slower in the enterprise than in the consumer market. However, innovation in the mobile space hasn\u2019t stopped. In recent months, the industry has produced a series of technologies that will play an important role in the next successful generation of mobile enterprise solutions.\n\nThe list of emerging mobile technologies that may become relevant in the enterprise is incredibly large to cover in a single article and, many times, requires making assumptions about a market that has more than once proven to be unpredictable. For the purpose of this article, we have focused on technologies that, although new, are already enjoying a significant level of adoption within mobile applications in the consumer market and that are immediately applicable to enterprise scenarios. Specifically, we think the following mobile technologies can have an impact in the enterprise in the near future.\n\nThe evolution of machine learning, stream and predictive analytic technologies is starting to power the next generation of mobile analytic solutions. The first wave of mobile analytic platforms focused on basic business metrics such as user sessions, retention or engagement, as well as operational metrics such as app crashes, API calls, etc. The emergence of machine learning, stream data processing, and predictive analytics allows businesses to gain insights about mobile data that weren\u2019t possible before.\n\nModern stream analytic technologies allow the executing real time queries over mobile data streams containing hundreds of thousands, or even millions of events. Machine learning technologies enable the prediction of real time actions in a mobile application, or accurately selecting the content to display on a specific section of a mobile application. Even though applying machine learning to mobile analytics is a relatively new concept, mobile advertising platforms seem to have taken the lead in the space. Platforms likeMixpanel and Yahoo\u2019s Flurry are also in a great position to expand their mobile analytic platform with machine learning and predictive models.\n\nApplication streaming created a multibillion-dollar market for desktop application and its potential is even higher for mobile apps. The ability to stream data, content or entire apps on demand from secured and centralized locations could be a catalyst for the adoption of mobile apps in the enterprise on a larger scale.\n\nIn recent months, we\u2019ve started seeing breakthroughs in app streaming technologies from companies like Google that are providing the first signs of the applicability of these technologies to mainstream scenarios. While users are already benefiting from mobile app streaming technologies in the consumer market, the implications in the enterprise can be significant and address many of the challenges in areas such as security and distribution which are common in enterprise mobile solutions.\n\nDeep linking is becoming one of the most popular trends in modern mobile computing. Conceptually, mobile deep linking specifies a format to launch a mobile application with specific configurations, such as home screen, images, user profile, etc. Deep linking has become the foundation of relevant mobile capabilities, such as app discovery or search.\n\nIn the context of mobile enterprise solutions, deep linking will allow organizations to deliver a group of specific mobile applications interconnected using deep links. Using this model, enterprise mobile apps can focus on specific tasks and evolve independently while communicating with other mobile apps via deep links. Platforms like Deeplink.meand Branch already represent viable options to enable deep linking in the context of enterprise mobile apps.\n\nMost mobile enterprise applications focus on accessing and displaying business data from enterprise systems. From that perspective, the number of business scenarios from accessing corporate data from a mobile app is vastly larger than the number of apps that can be effectively produced by mobile development teams in an enterprise. To address those challenges, enterprises can benefit from platforms and tools that enable the self-service creation of mobile apps.\n\nTo be effective in the enterprise, self-service mobile application platforms need to combine the seamless authoring of mobile front-end with sophisticated back-end capabilities to access data from corporate systems in a secure way. After a few years of struggle, platforms likeMicrosoft\u2019s PowerApps, Capriza and AppGyver\u2019s Supersonic seem to have found the right formula to enable self-service, data-driven mobile applications.\n\nNative and cross platform mobile app development has a special place in any enterprise mobile strategy. For the last few years, solutions like Xamarin or Appcelerator, have been the main choices for enterprises developing mobile apps. Despite the great value proposition provided by those technology stacks, many developers prefer to rely on native stacks such as Android and IOS to implement enterprise mobile applications.\n\nAfter a few years of evolution in cross platform mobile application technologies, the enterprise space might be ready for a new mobile technology stack. To be successful in the enterprise, a cross platform mobile app technology doesn\u2019t only need to provide a simple experience for authoring mobile apps, but also robust infrastructure capabilities in areas such as testing, distribution, security, as well as a sizable developer community. Recent efforts like Facebook\u2019s React Native seem to have the right combination of simplicity, robustness, and developer traction to become relevant in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-blockchain-as-a-service-is-coming-to-a-cloud-near-you-1d5ccb214b91?source=user_profile---------451----------------",
        "title": "The Blockchain as a Service is Coming to a Cloud Near You",
        "text": "The bitcoin blockchain is becoming one of the most exciting enterprise software technologies of this decade and now is becoming available as part of popular platform as a service(PaaS) technologies. In recent weeks, both IBM and Microsoft have announced the availability of private blockchain as a service (BaaS) technologies as part of the Azure and Bluemix cloud respectively.\n\nThe blockchain is popularly known as the technology that powers the infrastructure of the bitcoin cryptocurrency. From a functional standpoint, the blockchain provides a decentralized, time stamped, ordered record of all transactions in a Bitcoin network that can be verified at any time. These simple capabilities represent the first practical answer to profound computer science problems based on the trust of nodes in a decentralized network.\n\nDespite the popularly if bitcoin, most experts are convinced that the opportunities around the blockchain are exponentially larger that the market developed by popular crypto-currency. Industries like legal, asset management, decentralized B2B, trade settlement and many others are starting to be disrupted by the blockchain. To become mainstream, the blockchain requires general programming models and distribution mechanisms included in popular software development platforms. Enter the world of the blockchain as a service (BaaS).\n\nThe emergence of blockchain based programming platforms such as Ethereum or Eris Industries allows the creation of software solutions powered by the blockchain. However, the provisioning, scalability and maintenance of private blockchain environments is far from being an easy endeavor. This problem gets even worse if we consider that high scale applications are likely to leverage multiple blockchains for different tenants, geographies etc. From some perspective, the magic of the blockchain relies on the model for storing and querying data and not on the infrastructure behind it.\n\nTo address those challenges, companies like Microsoft and IBM have started including blockchain capabilities as part of their PaaS offerings. This model allows developers to provisioning, scale and operate blockchain environments without being concerned about the underlying infrastructure. Additionally, devops will leverage a consistent and familiar PaaS management experience to operate blockchain solutions.\n\nA few days ago, IBM announced the availability of its blockchain as a service (BaaS) solution as part of which includes devops services as part of IBM Bluemix. IBM also announced the open source availability of the Hyperledger project which attempts to make the blockchain completely open source and availability to enterprise developers.\n\nMicrosoft has also actively working in a BaaS initiative as part of the Azure PaaS. Recently, Microsoft announced a partnership with Consensys to enable Ethereum as part of Azure environments. Since then, Microsoft has been very active adding some of the top blockchain solution providers in the market to its BaaS partner network.\n\nThe BaaS model represents a very important step towards the mainstream adoption of blockchain technologies. Even though IBM and Microsoft will be the first to admit that BaaS is still highly experimental, we can already see some of the tangible benefits of this model such as the following:\n\nIBM and Microsoft are leading the charge in the adoption of BaaS architectures. Based on the popularity of blockchain technologies, we should expect popular PaaS providers like AWS, Google and Salesforce to quickly join the movement. Making BaaS a first class citizen of mainstream PaaS technologies will only help to increase the adoption of the blockchain as one of the building blocks of enterprise applications."
    },
    {
        "url": "https://medium.com/@jrodthoughts/shadow-it-is-the-new-black-and-it-comes-with-new-opportunities-45388175ffc9?source=user_profile---------452----------------",
        "title": "Shadow IT is the New Black and it Comes with New Opportunities",
        "text": "Shadow IT is becoming one of the most fascinating phenomenon in the enterprise software world. Having evolved as a result of the friction between the rapid evolution of line of business applications and the rigidness of traditional IT departments, shadow IT is a movement that is here to stay. In that sense, its common to see business units increasingly adopting and building business applications without the blessing of IT departments.\n\nDespite being often portrayed as a chaotic movement, shadow IT offers some of the most exciting opportunities for startups and investors looking to power the next generation business applications. The opportunity behind shadow IT combines an increasingly growing market that impacts every medium to large organization in the world. To better understand the opportunity behind shadow IT, we can start by analyzing the causes behind this phenomenon.\n\nThe consolidation of SaaS models as the main delivery mechanism for line of business applications has been a key factor in the emergence of shadow IT solutions.\n\nWhile the more established SaaS platforms such as Salesforce.com, Sucessfactors, Workday etc have developed the necessary integration, security and compliance capabilities to be considered IT-ready, many SaaS applications haven\u2019t achieved that level of enterprise sophistication. As a result, IT departments typically struggle to support those capabilities and business units end up either implementing or hiring their own support unit.\n\nComplementary to the previous point, the emergence of cloud computing infrastructures has allow business units to implement custom solutions without requiring servers or infrastructure provided by IT departments.\n\nWhile most IT departments have developed the expertise to manage cloud infrastructures, the knowledge about application development best practices using platform as a service (PaaS) architectures still remains new to those groups. As a result, business units rarely rely on IT departments for the implementations of custom cloud applications. Instead, they build or hire development teams or firms to assists with those efforts.\n\nTogether with cloud infrastructures, mobile computing has been one of the transformative movements in the recent history of enterprise software. With IT department lacking the skills to develop world class mobile experiences, line of business units turned to digital agencies or incubated small teams to develop mobile applications for their partners and customers. From that perspective, mobile app development is another one of the factors that causes shadow IT silos within organizations.\n\nThe Increasing Gap Between Modern Technologies and IT Talent\n\nThe two previous points are examples of an overarching theme related to the increasing gap between the skillset of IT departments and modern technologies. While this gap is not a new phenomenon, it has certainly increased exponentially during the last few years. The emergence of so many technology trends such as mobile, cloud, big data, IOT etc has drastically disrupted the skillsets required to build modern software applications. As a result, business units have developed their own internal teams or partnered with third party agencies in order to build modern software applications.\n\nIn recent years, enterprises have seen a proliferation of mainstream cloud and mobile products being adopted within different business units. This phenomenon is commonly known as the \u201cconsumerization of the enterprise\u201d and is a reflection of employees adopting consumer products to perform business activities. Obviously, a large majority of mainstream consumer products are not supported by IT organizations. As a result, many business units have developed their own mechanisms for implementing and supporting those consumer solutions within their environment.\n\nComplementing the previous point, IT departments typically tend to challenge solutions that use new technologies because they are difficult to support. As a result, a large number of the software solutions developed by IT organizations lack the innovation and flexibility of new technology stacks. To deal with that challenge, business units have developed small teams with the right knowledge and expertise to support modern software solutions.\n\nSome of the factors explained in this section have caused shadow IT to become a permanent piece of every modern organization. Despite the challenges introduced by shadow IT movement, we believe it also presents unique opportunities for IT organizations to innovate is what has become a new standard for modern IT.\n\nThe shadow IT phenomenon has, undoubtedly, disrupted the traditional dynamics between business and IT. However, beyond the initial set of challenges, shadow IT offers a new set of opportunities to IT groups to innovate in many areas that can set the foundation for the new dynamics in the modern enterprise.\n\nFrom that perspective, the shadow IT movement has been catalyst for the adoption of cloud, mobile and big data technologies in the enterprise and is forcing IT groups to rapidly build up those necessary skillsets and to create new solutions to support the new wave of business solutions. As a result, we are seeing very innovative solutions from IT groups in some of the following areas:"
    },
    {
        "url": "https://medium.com/@jrodthoughts/slack-hipchat-and-the-embedded-messaging-apps-revolution-in-the-enterprise-2406c95fc11b?source=user_profile---------453----------------",
        "title": "Slack, Hipchat and the Embedded Messaging Apps Revolution in the Enterprise",
        "text": "Slack, Hipchat and the Embedded Messaging Apps Revolution in the Enterprise\n\nMessaging applications are becoming an important part of our daily lives. While platforms like Facebook Messenger or Snapchat are serving hundreds of millions of active users, technologies like Slack or Hipchat are becoming very common in enterprise environments. In both the consumer and enterprise scenarios, messaging applications are expanding its focus from being standalone solutions to complete platforms that provide messaging capabilities for other applications.\n\nWhile this evolution from tools to platforms can be seen as relatively obvious in the consumer market, it has certainly come up as a surprise in the enterprise space. In the last few months, we have seen companies start developing business models around build applications for popular messaging stacks such as Slack or HipChat. Just in the last few weeks, there have been some relevant developments in the space:\n\nAll these new developments have raised an interesting level of debate within VCs and analysts circles about the viability of embedded messaging apps as a new enterprise software trend.\n\nSolving the Distribution Problem in the Enterprise\n\nThe main value proposition of embedded messaging apps is that they will be available via established distribution channels such as Slack or HipChat. Distribution, is one of the hardest problems to solve in enterprise software as every major organizations gets daily bombarded with new product offerings for any imaginable problem. By building on platforms with a large enterprise audience like Slack or HipChat, embedded messaging apps can leverage a well-established distribution channel.\n\nBringing the App to the Collaboration Engine Instead of Collaboration to the App\n\nCollaboration has been one of most popular buzzwords in the enterprise software ecosystem for the last decade. In the traditional approach to enterprise collaboration, line of business systems have started to build collaborative capabilities within their stacks. Although relevant, these capabilities are not comparable with complete collaboration platforms like Slack or HipChat. Embedded messaging apps offers an interesting alternative to that model in which the apps are built on top of an existing collaboration and messaging engine. In this new model, the users will start leveraging applications in the context of a collaboration exercise within a messaging platform. I find this new approach incredibly intriguing.\n\nEmbedded messaging apps facilitate the integration with line of business systems using simple commands. Those commands can be composed to achieve more complex tasks. For instance, you could issue a command requesting recent leads from Salesforce.com and another command that exports those leads into a Google Spreadsheet. That simple command experience could become an easier and intuitive model for users to interact with enterprise systems for simple tasks.\n\nToday\u2019s embedded messaging apps are exclusively used within a messaging platform like Slack or HipChat. In the future, we can think of leveraging embedded messaging apps directly from line of business systems such as Salesforce.com or Marketo. In that scenario, you can imagine a user exploring recent leads in Marketo and using that information to start a Slack conversation with his colleagues directly from the Marketo portal.\n\nOne of the top value proposition of embedded messaging apps is that they can capture collective knowledge about specific line of business records. The interactions and collaborations about specific data sources in Slack or HipChat can be captured in the specific line of business systems for future references.\n\nDespite the excitement about embedded messaging apps, the main question remains whether they can become a viable business model within the enterprise software space. While messaging platforms like Slack and HipChat are enjoying a great adoption in the enterprise, they are still far from becoming completely mainstream. Additionally, embedded messaging apps will have to deal with the risks of being dependent on a third party platform which make them subject to new distribution policies, financial agreements etc.\n\nRegardless of whether embedded messaging apps will become a relevant trend in enterprise software, we can all agree is a very intriguing one."
    },
    {
        "url": "https://medium.com/@jrodthoughts/5-tech-trends-that-will-drive-the-next-wave-of-mobile-innovation-in-the-enterprise-4a3ec6a2b313?source=user_profile---------454----------------",
        "title": "What enterprise IoT will look like in 2016 \u2013 Jesus Rodriguez \u2013",
        "text": "The original article was published in CIO.com\n\nIt was an interesting year for the enterprise IoT space in 2015 and 2016 promises to be even better. In 2015 we witnessed the launch of brand new IoT platforms by major software vendors and startups as well as an increasing activity of consolidation and M&A in the space. As a result, 2016 should bring us a lot of activity in enterprise IoT initiatives. This article presents a taxonomy of the enterprise IoT market in 2016 that will help organizations evaluating this type of solutions and platforms.\n\nHow will the enterprise Internet of Things (IoT) market in 2016 help enterprises evaluate IoT solutions? Let\u2019s start by taking a look at some of the\n\n2015 was an incredibly active year for IoT in the enterprise. The emergence of new platforms and solutions, the decline of others and the increase of M&A activity dominated the headlines of 2015. In general, 2015 can be seen as a year in which the enterprise community have come to accept IoT as one of the trends that will be pivotal in the next decade of enterprise software. Trying to summarize the enterprise IoT space in 2015 in five points is not easy, but here are some of the key developments in the space.\n\n2015 saw big platform as a service (PaaS) providers like Microsoft Azure, AWS, Salesforce, and IBM launch new IoT platforms. While PaaS solutions have included IoT services for a while, they didn\u2019t have complete IoT platform offerings. This changed completely in 2015, Salesforce announced its IoT Cloud solution at Dreamforce, Microsoft released Azure IoT Suite, and Amazon also announced its AWS IoT solution. More recently, IBM expanded its IoT Foundation with cognitive services powered by IBM Watson.\n\nAll these releases are very effective attempts to compact the enterprise IoT space, as the aforementioned PaaS solutions can leverage their mainstream distribution within enterprise customers. Additionally, the entrance of PaaS vendors in the IoT space is going to make it more challenging for new startups to gain mainstream market share in an increasingly competitive market.\n\nGE is all in\n\nNot trying to highlight a single vendor, but the commitment and performance of GE\u2019s industrial IoT solution is rather impressive and a strong validation of the space. Based on statements from a few months ago, GE was predicting that its Predix IoT platform will generate over $5B in 2015. Those revenue multiples are significantly larger than any other players in the space.\n\nFrom an enterprise perspective, GE commitment of the IoT space represents an important step bringing industrial solutions to the digital age. Predix is certainly a robust platform from the feature standpoint and it includes many industry-specific capabilities that are not present in mainstream IoT offerings.\n\nEnterprise IoT startups are emerging everywhere\n\n2015 saw the emergence of a large number of IoT startups in the enterprise space. Like many other fast growing enterprise trends, new startups are trying to capture meaningful market share in the IoT space. From isolated infrastructure services to complete platforms, the enterprise IoT startup ecosystem includes all aspects of enterprise IoT solutions.\n\nThe rise of the number of startups targeting enterprise IoT scenarios is driving a lot of innovation in the space and forcing the big enterprise platform vendors to keep innovating. However, the amount of new offerings have crowded the enterprise IoT space making it highly difficult for enterprises to select technologies to power their IoT solutions.\n\n2015 was a very active year in terms of mergers and acquisitions in the enterprise IoT space. Some reports claim over $1.2B deployed in M&A activity related to enterprise IoT solutions. Citrix acquiring Octoblu, and Amazon acquiring 2lemetry are some of the key examples of M&A activity in the enterprise IoT system. As the enterprise IoT ecosystem continues to evolve, we should expect to see an increase in the M&A activity as well.\n\nAs enterprises start their IoT efforts in 2016 they will be faced with an overwhelming number of options for technologies and platforms. However, there are 5 main categories that effectively covered most of the enterprise IoT technologies in the space and can help enterprises in their evaluation of enterprise IoT technologies.\n\nAs mentioned in a previous section, the incumbent PaaS vendors currently include complete IoT platforms as part of their offerings. This model allows enterprises to build IoT solutions that not only leverage IoT specific services, such as device management or stream analytics, but also take advantage of infrastructure services included in PaaS solutions. When evaluating IoT PaaS solutions, enterprises should consider the following elements:\n\n-Strengths: IoT PaaS offerings are a very attractive solution for enterprises which are already leveraging PaaS solutions such as AWS, Azure, Bluemix, Salesforce.com, etc. The combination of IoT specific with infrastructure and platform services enables the implementation of very sophisticated IoT solutions using a single technology stack.\n\n -Weaknesses: As any general purpose solution, PaaS IoT platforms are not likely to include vertical-specific capabilities or even distribution models that are relevant to specific industries. Additionally, the fact that these platforms work exclusively in a public or hybrid cloud model can still be considered a challenge in many industries.\n\n -Some Relevant Examples: AWS IoT, Azure IoT Suite, Salesforce IoT Cloud and IBM IoT Foundation are some of the PaaS IoT platforms that could be relevant to enterprises in 2016.\n\nThis category includes some of the early IoT platforms in the space which focus on providing backend and infrastructure capabilities to enterprise IoT solutions. Differently from the PaaS IoT group, these solutions are commercialized as independent IoT platforms with no defined dependencies on any PaaS solution. When evaluating this type of IoT solution, enterprises should consider the following elements:\n\n -Strengths: As early IoT platforms in the space, this group has managed to be relevant within the early adopters of enterprise IoT solutions. From this perspective, these types of platforms typically include many relevant use cases or even industry specific capabilities derived from their experience in real world implementations.\n\n -Weaknesses: Compared to the IoT PaaS solutions, standalone IoT platforms can seem more limited as they don\u2019t include general purpose services which can be relevant in enterprise IoT solutions. Additionally, these types of platforms typically require a decent amount of professional services as they still haven\u2019t built sizable communities of developer or solution implementers.\n\n -Some Relevant Vendors: Xively, ThingWorx and Jasper are some examples of standalone IoT platforms that should be relevant in the enterprise in 2016.\n\nSecurity, stream messaging, and device management are some of the examples of infrastructure capabilities that are key to enterprise IoT solutions. Very often, enterprises don\u2019t require a complete IoT platform, but rather need a specific service that enables a handful of capabilities in a very effective way. This role has been fulfilled by IoT infrastructure service solutions that focus on enabling a single, or a small number of, related infrastructure services in IoT solutions. When evaluating IoT infrastructure services, enterprises should consider the following factors:\n\n-Strengths: IoT infrastructure services are typically very specialized in the capabilities they provide including a large number of edge cases that are hard to find in general IoT platforms. Additionally, these offerings typically provide very robust and yet simple developer and DevOps experience, simplifying the experience for enterprises adopting these IoT capabilities.\n\n -Weaknesses: Many times a single capability product becomes a feature or a larger solution. From this perspective, enterprises can find it challenging to justify an investment in a single IoT infrastructure service solution when they can acquire more complete IoT platforms. The interoperability with other IoT platforms should also be taken into consideration when evaluating this type of IoT service, as they will likely be a component of a much broader solution.\n\n -Some Relevant Examples: PubNub, Mocana and Robomq are some relevant providers of standalone IoT capabilities.\n\nLike any other relevant enterprise software trend, IoT will produce a number of industry-specific solutions that can become successful by themselves. As a matter of fact, we are already seeing some of the big industrial players trying to address mainstream IoT scenarios like asset management, vehicle telemetry, smart energy consumption, etc., with specific IoT hardware-software solutions. When evaluating IoT vertical solutions, enterprises should consider some of the following factors:\n\n-Strengths: Industry-specific IoT solutions avoid many of the frictions related with the adoption of IoT solutions in the enterprise. Also, this type of solution enables many vertical specific capabilities and use cases not present in general-purpose IoT platforms, and can be really hard to build from the ground up.\n\n -Weaknesses: Like any other vertical solutions, enterprise IoT industry applications can be very challenging to modify and extend. The interoperability with other technologies often poses a challenge when adopting this type of solution.\n\n -Some Relevant Examples: GE Asset Performance Management, Intel\u2019s In-Vehicle Solutions and Cisco\u2019s Connected Factory are some of the relevant examples of industry-specific IoT solutions.\n\nData, not hardware, is the crown jewel of enterprise IoT. Processing, analyzing, and taking action based on the high volumes of data produced in an IoT infrastructure are the ultimate value drivers of enterprise IoT solutions. As a result, enterprise IoT solutions typically include data processing and analytic capabilities in areas such as stream data processing, real time analytics, etc. When evaluating IoT Data Services, enterprises should consider the following factors:\n\n-Strengths: IoT data services can be very effective when enabling stream processing and real time analytic capabilities. These technologies are typically optimized to work with a large number of endpoints generating large volumes of data. They can also integrate with mainstream analytic and big data platforms simplifying the adoption curve in the enterprise.\n\n -Weaknesses: IoT data services can be difficult to implement in enterprise scenarios. This challenge is even bigger if we are talking about technologies that are not part of mainstream big data or analytics suite.\n\n -Some Relevant Examples: Apache Storm, Spark Streaming, AWS Kinesis and Azure Stream Analytics.\n\nI believe 2016 won\u2019t be the year that starts the mainstream adoption of IoT technologies in the enterprise. The market remains incredibly crowded and most enterprises still haven\u2019t developed the necessary level of knowledge and awareness of enterprise IoT solutions to become adopters. However, we think that in 2016 IoT will establish itself as a foundational piece of the next generation of enterprise software solutions. Additionally, I think the market will experience a decent level of consolidation, and this will clearly identify front-runners from second places."
    },
    {
        "url": "https://medium.com/@jrodthoughts/machine-learning-will-power-the-next-generation-of-enterprise-software-2281e0141f38?source=user_profile---------455----------------",
        "title": "Machine Learning Will Power the Next Generation of Enterprise Software",
        "text": "Machine learning is rapidly becoming one of the most important trends in the enterprise software ecosystem. A combination of Moore\u2019s law about GPU performance, the raise of big data and the evolution of technology stacks, have finally made the promise of machine learning a reality for many enterprises. However, the promise of machine learning extends beyond a standalone discipline and has the opportunity to power the next wave of innovation in the enterprise.\n\nThe last decade has seen a renaissance of innovation in enterprise software powered by movements like cloud, mobile and big data. With those technologies established as mainstream capabilities, the market is turning its attention to technologies that can become the next big thing in enterprise software. From the current fast growing technology trends in the market, machine learning seems to offer a seamless path to power the next wave of innovation in the enterprise.\n\nThere are many factors contributing to the adoption of machine learning technologies in enterprise environments. The rapid evolution of the machine learning stacks, the adoption of big data technologies as well as the explosion in the volumes of data processed by organizations are just some of the elements that are conspiring to embrace more advance data analysis techniques. For a technology movement to become transformational trend in the enterprise, it has to combine a strong technical value proposition with elements such as distribution, market maturity or cost of adoption. From everything we can see, machine learning has all the ingredients to become the next power the next wave of innovation in the enterprise.\n\nAfter almost 20 years of evolution of machine learning stacks, they have finally reach a point in which they are being widely adopted by developers and incorporated into third party applications. In that sense, some of the machine learning platforms and frameworks based on technologies like R and Python enjoy large and active developer communities that accelerating the level of innovation in the data science space.\n\nThe explosion in the volumes of data stored by organizations has drastically improve the viability and efficiency of machine learning models. As you can imagine, machine learning supervised and unsupervised algorithms tend to be more effective as they process larger data sets.\n\nFor the last 30 years, enterprise applications have been built using relational database models optimized to store internal data. The explosion of social and mobile technologies have completely changed that scenario requiring applications to process diverse set of unstructured and semi-structured data. In that context, machine learning algorithms tend to be very effective to analyze large volumes of external data and correlate it with internal data sources.\n\nAs the volume of information processed by organizations increase, machine learning models will become essential to extract intelligence from those data sources using techniques like statistical regression, classification or clustering. From that perspective, machine learning solutions are becoming the channel to transform raw information into knowledge that can be leveraged in enterprise business processes.\n\nOne of the greatest things about machine learning solutions in the enterprise is that they can leverage existing distribution channels as part of SaaS systems or other line of business applications. In that context, SaaS systems can be extended with specific machine learning models to provide better insights and predictions about its data.\n\nReplace X with your favorite industry and you have a solid business model ;)\n\nThe rapid evolution machine learning stacks is taking place not only on the platform side but in the form of industry-specific solutions that are leveraging data science to enable additional levels of data insights and intelligence. In this model, machine learning is serving as an enabler to advanced domain specific capabilities. Below we can find some examples of sectors that are being transform by the use of machine learning and data science.\n\nOne of my good friends always jokes that some of the best minds of our generation are spending their days finding better ways to place advertisement. That\u2019s\u2019 just one of the best examples of how machine learning is transforming marketing. Predictive lead scoring or intelligent ad and content placement are some of the new and popular marketing techniques that are actively rely on machine learning models.\n\nForecasting analysis, customer sentiment analysis, customer churn predictions are some of the examples of machine learning disrupting traditional sales processes. These techniques are starting to be included in traditional sales tools such as CRMs and ERPs to create more intelligent sales processes.\n\nMachine learning is powering the next generation of innovation in the enterprise security space. Techniques like security Threat analysis, malicious pattern recognition are actively used in modern security platforms to provide more intelligence about potential security risks in enterprise operations.\n\nFinancial technology is being completely disrupted by the emergence of data science and machine learning. Equity investment, high frequency trading, financial planning etc are some of the most innovative use cases that are leveraging machine learning in the financial industry.\n\nThe lead platforms in the application performance and operational monitoring space are starting to leverage machine learning to obtain additional insights about system logs or application activities. Additionally, many of these platforms are starting to leverage machine learning to proactively predict failures about specific business processes and adapt accordingly.\n\nMachine learning has all the characteristics of becoming one of the most transformational forces in the next generation of enterprise software solutions. Even though the space is still in very early stages, we are already witnessing the transformational impact that machine learning is having in several enterprise sectors. As the space continues evolving, we should starting to see many of the traditional enterprise software systems being completely architected to leverage machine learning techniques. There is certainly a decade-long opportunity ahead."
    },
    {
        "url": "https://medium.com/@jrodthoughts/beyond-net-and-j2ee-the-emergence-of-a-third-application-development-platform-in-the-enterprise-347819d7ab5e?source=user_profile---------456----------------",
        "title": "Beyond .NET and J2EE: The Emergence of a Third Application Development Platform in the Enterprise",
        "text": "For the last fifteen years, the enterprise IT space has relied on two main application development platforms: .NET and J2EE. While other platforms like Ruby on Rails or Python has certainly gained some adoption in the enterprise, their market share remains relatively small compared to the adoption of .NET and J2EE. After almost 2 decades of developing solutions almost exclusively in two platforms, there are a number of factors conspiring to facilitate the emergence of a third application development platform in the enterprise.\n\nDespite the numerous innovations in the .NET and J2EE platforms, their dominance in the enterprise IT space can be partly attributed to its commercial channels. For the last 2 decades, the combination of Microsoft and J2EE vendors like IBM, Oracle, Tibco, etc accounted for a large percentage of enterprise IT deals. However, many of the factors that established the dominance of .NET and J2EE have either disappeared or changed and, at this point, I believe enterprise IT can benefit from the emergence of a third enterprise-ready application development platform.\n\nBetter Application Models for the Cloud\n\nToday, many enterprise IT applications are being developed using cloud platforms such as Azure, Bluemix or AWS. In those infrastructures, the level of support for new application development platforms like NodeJS, Python or Ruby is as good, if not sometimes better than J2EE and .NET. This level of support removes some of the concerns in terms of enterprise-ready tooling that has traditionally blocked open source application development platforms from entering the enterprise.\n\nMobile application development is becoming a relevant item in any CIO\u2019s agenda. In the mobile space, platforms like NodeJS have become the platform of choice for enabling backend APIs used by mobile applications. In that sense, many organizations building mobile applications or using mobile platforms are already leveraging platforms like NodeJS instead of traditional J2EE or .NET stacks.\n\nOpen source technologies are becoming more prevalent in the enterprise. Movements like the big data platforms or mobile application development stacks are vastly dominated by open source solutions. Typically, open source server stacks provide a great support for platforms like NodeJS, Python or Ruby in the form or SDKs, samples etc. Consequently, as more organizations embrace open source server platforms they are likely to leverage technologies other than .NET or J2EE for building applications in that platform.\n\nA New Generation of Developers and Professional Services Agencies\n\nAs application development stacks like NodeJS and Python continue gaining momentum with the developer communities, more and more developers are likely to favor those stacks instead of traditional .NET or J2EE platforms. Is not a surprise that many of the modern software development agencies are actively hiring developers with skills in prominent open source application development platforms like NodeJS, Ruby or Python. Those agencies are actively evangelizing the benefits of those platforms in enterprise IT settings and playing and important role in the adoption of those new application development platforms in the enterprise.\n\nThe explosion of innovation in the enterprise software startup scene is forcing big organizations to start embracing technologies from early stage startups in order to stay competitive. Many of the most innovative enterprise software startup platforms leverage application development stacks other than .NET and J2EE. As a result, many enterprise IT organizations are starting to indirectly leverage those platforms as part of broader enterprise software solutions.\n\nIs NodeJS the One?\n\nWithout getting into predictions, is hard to talk about the emergence of a third application development platform without talking about potential candidates. From the existing platforms in the market, NodeJS seems to have all the ingredients to become relevant in the enterprise.\n\nToday, NodeJS enjoys a vibrant development community and is the platform of choice of many enterprise software startups. Additionally, NodeJS is widely supported by all enterprise cloud and mobile platforms and is being slowly adopted by some of the top professional services agencies in the world.\n\nWhile getting to the level of dominance that .NET and J2EE enjoy in today\u2019s enterprise IT environment is going to require more than the aforementioned factors, I believe NodeJS has a very strong opportunity to become a third application development platform in the enterprise."
    },
    {
        "url": "https://medium.com/@jrodthoughts/the-enterprise-public-cloud-wars-are-over-let-s-talk-about-what-s-next-eda2df0c4f04?source=user_profile---------457----------------",
        "title": "The Enterprise Public Cloud Wars Are Over. Let\u2019s Talk About What\u2019s Next",
        "text": "The Enterprise Public Cloud Wars Are Over. Let\u2019s Talk About What\u2019s Next\n\nLast week there were some very interesting developments in the public cloud space. First, Microsoft, Amazon beat Wall Street expectations and reported monster numbers associated with their public cloud offerings.\n\nAlso, HP announced that it will be stopping the efforts about the Helion public cloud to focus on the private and hybrid cloud offerings. These news come after two years of sustained efforts and large investments in their public cloud platform.\n\nThese new developments has made many questioned whether the enterprise public cloud race is essentially over. While the public cloud space remains really competitive within a few platforms, it\u2019s pretty obvious that we can already identify winners in the enterprise public cloud space.\n\nAmazon and Microsoft by a mile with Google, Salesforce and IBM being relevant second places. Amazon\u2019s AWS and Microsoft\u2019s Azure have managed to develop the most complete offerings in the enterprise public cloud space. Today, AWS and Azure not only provide a larger of number of capabilities than their competitors but also more complete offerings enterprise-ready areas such as security, compliance etc.\n\nIf we apply Clayton M. Christensen\u2019s innovator dilemma thesis to the enterprise public cloud space we need to assume that, at some point, a new generation of startups will challenge the well-established enterprise public cloud platforms. However, looking at the near future, it\u2019s hard to imagine what factors will be able to disrupt the lead established by the enterprise public cloud incumbents. In principle, a new entrant in the enterprise public cloud space can try to establish traction by disrupting some of the following areas:\n\nHowever, after analyzing the current state of the enterprise public cloud platform market, its hard to imagine how any of those factors can be relevant enough for a new entrant to cause disruption in the space. Let\u2019s explore that analysis.\n\nFrom the enterprise capability standpoint, the Azure and AWS cloud are far ahead of every other platform in the space. Ranging from basic infrastructure to sophisticated capabilities such as machine learning or integration, both Azure and AWS are providing native services for every imaginable capability that can be relevant in the enterprise. Salesforce, IBM and Google are also rapidly growing the feature set of their public cloud offerings. In that sense, it\u2019s hard to conceive a new enterprise public cloud platform that will be able to compete with the incumbents in the short term.\n\nThe enterprise public cloud offering is a race down to 0. Amazon, Microsoft and Google keep lowering the price of their offering in order to not allow any other vendor to gain competitive advantage. In that sense, it will be incredibly difficult for a new enterprise public cloud offering to disrupt the space with a more attractive pricing model.\n\nAWS, Azure, Heroku and Google Cloud are some of the examples of enterprise public cloud platforms that are enjoying growing developer communities. By leveraging and embracing open source technologies, incumbents have been able to attract millions of developers actively building applications in their platforms. As a result, new platforms in the space will have to build similar developer communities to even be competitive with the incumbents.\n\nAnother element that seems to be a non-factor. Platforms like AWS, Azure and Google Cloud have not only become dominant offers for large enterprises but they have captured the hearts of new enterprise software startups that keep relying on those platforms to power their offerings. Those startups represent a new and vibrant distribution channels for the adoption of the incumbent platforms and will make it extremely hard for a new offering in the space to leverage that channel.\n\nPlatforms like AWS and Azure have developed an incredibly impressive global footprint with locations that offer viable options in almost every country in the world. Additionally, the services provided by those platforms are available in a large number of languages. This factor makes it almost impossible for new entrants to develop a relevant presence in specific geographies.\n\nThe dominant enterprise public cloud platforms have played a masterful game developing a large number of distribution channels from partner networks to whitelabel offerings. The network effects of these channels will make it extremely hard to new offerings to disrupt the enterprise public cloud space by developing new distribution channels.\n\nWith the competition in the enterprise public cloud space almost over, the attention has shifted to private and hybrid cloud platforms. Currently, that space remains overly competitive with platforms like Pivotal\u2019s Cloudfoundry, HP Helion, Aprenda and even public cloud incumbents like Azure and AWS trying to create comprehensive offers for enterprises. That will be the subject of a future post."
    },
    {
        "url": "https://medium.com/@jrodthoughts/ibm-watson-and-cognitive-data-as-the-future-of-information-data-systems-6a61b5354c03?source=user_profile---------458----------------",
        "title": "IBM Watson and Cognitive Data as the Future of Information Data Systems",
        "text": "IBM Watson is slowly becoming an important piece about IBM\u2019s vision of the future of computing. A few weeks ago, big blue announced that is launching another business unit centered on Watson solutions. The investment in this new unit is estimated to be around $1B but, more importantly, it reinforces IBM\u2019s commitment to Watson and cognitive data as the future of enterprise data solutions.\n\nA lot has happened since Watson made news winning the television quiz show Jeopardy by beating legends Ken Jennings and Brad Rutter. At the time, Watson was a sophisticated natural language processing machine but didn\u2019t have a lot to offer in other areas of cognitive computing.\n\nSince the jeopardy days, Watson has added a significant number of services in areas such as data insights, vision processing, image recognition, natural language processing, text analytics and other important areas of cognitive science. More importantly, IBM is making Watson available through the series of APIs via the Watson Developer Cloud which allow developers to leverage Watson is third party applications.\n\nIBM\u2019s efforts around Watson are, undoubtedly, the most important steps to establish cognitive data as a mainstream trend in the technology arena. While big data technologies have certainly disrupted the information management space, data processing applications remain mostly ignorant when comes to understanding and reasoning through the data they store. This is where cognitive data becomes important by helping expert systems enhance, understand and reason through structured and unstructured data sets in order to make intelligent decisions.\n\nData is Becoming Contextual in Nature\n\nModern data is becoming more contextual every day. While data sets can be considered static in nature, they have different interpretations depending on contextual aspects such as time, location, environmental aspects, etc. Cognitive computing is a necessary step to make information systems more context aware by augmenting static data sources with dynamic contextual data and reason and learn from it.\n\nBig Data is Just a Lot of Dumb Data\n\nToday, big data systems are becoming an important element of software systems by storing large amounts of static data. Despite the advances in data storage and process, data systems remain essentially unintelligent when comes to understand, optimize, augment and reason through the data they store. In that sense, organizations are constantly building new systems to make data \u201cmore intelligent\u201d. Cognitive data presents a powerful alternative to traditional data systems by providing a layer of intelligence to modern information systems.\n\nData Scientists are not for all Scenarios\n\nData scientists are the most common answer when comes to gather insights about specific data sets. However, data scientists are fundamentally inefficient in areas such as real time vision analysis, image recognition, speech analysis and other fundamental aspects of cognitive systems. Cognitive data and platforms like IBM Watson will help to expand the capabilities of traditional data science to provide more sophisticated intelligence over traditional data sources.\n\nVideo, Images, Text and Speech are Becoming Increasingly Important\n\nComplementing the previous point, data signals such as video, text, images and speech are fundamentally difficult to process by traditional data systems. Platforms like IBM Watson and other cognitive data solutions excel at the understanding and processing of these type of data points making an ideal extension of traditional data systems\n\nActions are as important as Data Insights\n\nIn modern data systems, actions related to the data are typically hardcoded as a bunch of rules within an applications. However, automatically taking actions based on data insights is becoming an increasingly important aspect of modern applications. Cognitive data is a fundamental step towards enabling intelligent decision making based on data insights on software applications.\n\nCognitive science is starting to revolutionize healthcare. The intelligent processing of unstructured healthcare data such as images, videos, speech etc is leading the charge in modern healthcare applications ranging from treatment recommendations to decease pattern analysis. Not surprisingly, healthcare remains the number one vertical for IBM Watson applications.\n\nCognitive data can help better reason through real data points in the form of video, images, sounds and text commonly encountered in public safety scenarios. Using cognitive data systems, public safety operators can improve their decision making process by interacting with systems that will help them reason through contextual data in their environments.\n\nFrom fraud detection to financial package recommendations, cognitive data is increasingly becoming relevant in financial systems. Reasoning through large amounts of semi-structured and unstructured data, cognitive data systems can help improve financial decisions such as trading, fraud analysis, etc.\n\nCognitive data is a key element of the future of recommendation systems and other user engagement marketing processes. Rapidly reasoning through the text on an email or the tone on a phone call, will help organizations to recommend better products to their customers while also enhancing the understanding of their marketing data.\n\nThis is an obvious one. Cognitive data will be essential to improve defense operations by better reasoning through the millions of data signals collected by soldiers and equipment on the field. Additional, cognitive science will help to build more intelligent defense equipment such as drones or robots that are becoming an integral part of modern warfare."
    },
    {
        "url": "https://medium.com/@jrodthoughts/beyond-bitcoin-how-the-blockchain-can-power-a-new-generation-of-enterprise-software-67df4e84531?source=user_profile---------459----------------",
        "title": "Beyond Bitcoin: How the Blockchain can Power a New Generation of Enterprise Software",
        "text": "Bitcoin has become one of the most intriguing and revolutionary technologies created in the last few years. From a functional standpoint, the crypto-currency has challenged the most fundamental principles of the world\u2019s financial systems by providing a decentralized, secured and trusted model to process financial transactions. To enable its magic, Bitcoin relies on an architecture powered by a groundbreaking technology known as the Blockchain.\n\nWhile Bitcoin has clearly become the most important implementation of the Blockchain, it is just one of many practical applications that can be powered by the Blockchain. From the conceptual standpoint, the blockchain provides a series of capabilities that can change some of the well-established architectures in the digital world.\n\nThe blockchain is Bitcoin\u2019s public ledger. From a functional standpoint, the blockchain provides a decentralized, time stamped, ordered record of all transactions in a Bitcoin network that can be verified at any time. These simple capabilities represent the first practical answer to profound computer science problems based on the trust of nodes in a decentralized network. One of the most popular and ancient problems that can be solved by the blockchain is the \u201cthe Byzantine Generals Problem\u201d. To review this problem, let\u2019s take some snippets from Lamport, Shostack and Pease\u2019s seminal paper of that name:\n\n\u201cWe imagine that several divisions of the Byzantine army are camped outside an enemy city, each division commanded by its own general. The generals can communicate with one another only by messenger. After observing the enemy, they must decide upon a common plan of action. However, some of the generals may be traitors, trying to prevent the loyal generals from reaching agreement. The generals must have an algorithm to guarantee that\n\nA. All loyal generals decide upon the same plan of action.\n\nThe loyal generals will all do what the algorithm says they should, but the traitors may do anything they wish. The algorithm must guarantee condition A regardless of what the traitors do. The loyal generals should not only reach agreement, but should agree upon a reasonable plan. We therefore also want to insure that\n\nB. A small number of traitors cannot cause the loyal generals to adopt a bad plan.\u201d\n\nThe blockchain can solve the B.G.P because it provides a trusted and decentralized exchanges over an untrusted network. Generalizing this value proposition means that the blockchain can be used for different parties to exchange digital information in a trusted, secure and decentralized model in which each party can validate the legitimacy of the transfer and no party can challenge it.\n\nThe decentralized, autonomous, trusted and secured capabilities of the blockchain that can redefine of the foundational patterns of enterprise applications. While the principles of the blockchain are well understood patterns in enterprise solutions, until now we have lacked practical implementations that validate its functionality at an enterprise scale. The blockchain opens a new set of opportunities to enterprise scenarios that weren\u2019t possible before.\n\nThe internet of things (IOT) is becoming one of the most important trends in modern enterprise software. While many IOT platforms are based on a centralized model in which a broker or hub control the interaction between devices, this model has proven to be impractical for many scenarios in which devices need to exchange data between themselves autonomously. That specific requirement has been the fundamental principle behind decentralized IOT platforms. Those decentralized models are fundamentally powered by a trusted ledger of exchanges between smart devices fundamental to power real world IOT solutions.\n\nThe blockchain provides foundational capabilities of decentralized IOT platforms such as secured and trusted data exchange as well as record keeping. In this type of IOT architectures, the blockchain will serve as the general ledger keeping a trusted record of all the messages exchanged between smart devices in an IOT topology.\n\nPublic Key Infrastructure (PKI) has been one of the fundamental technologies powering data signatures. PKI models rely on a central authority to stamp and validate signatures on a data payload. While PKI models have been incredibly successful, the dependency on a central authority presents serious limitations for large scale scenarios and is also vulnerable to attacks involving quantum computation.\n\nThe characteristics of the blockchain can help to overcome some of the limitations of PKI models with a keyless security infrastructure (KSI). A KSI model uses only hash-function cryptography, allowing verification to rely only on the security of hash-functions and the availability of a public ledger commonly referred to as a blockchain.\n\nArchiving historical data in a secure and trusted manner has been a permanent challenge of enterprise IT. Companies like EMC have become one of the most iconic enterprise software companies in history by providing robust storage and archiving solutions. More recently, cloud platform vendors like Amazon have provided alternative data archiving solutions. However, in both cases, data archiving solutions rely on a centralized storage model which possess very well-known limitations in enterprise scenarios in areas such as security and privacy.\n\nDecentralized and autonomous data archives models such as the ones provided by the blockchain can be an interesting alternative to centralized data storage solutions. This model will eliminate the dependency on a centralized authority and will allow distributed and trusted storage across nodes in a blockchain network. More importantly, using the blockchain as a data archive will allow any nodes to validate the authenticity of the archived data without relying on central hub.\n\nB2B exchange models are one of the foundation of modern commerce. In those scenarios, transaction tracking, auditing and reconciliation processes are essential capabilities of B2B processes. Traditional B2B platforms enable these capabilities by providing centralized transaction tracking models that will be used by the different B2B endpoints to log relevant events of a specific transaction. These centralized tracking models have proven to be unpractical to address many of the typical challenges of B2B transaction tracking processes in areas such as auditing and reconciliation.\n\nLeveraging the blockchain as a decentralized, secured and trusted transaction ledger could be a more effective model to address the challenges of B2B transaction tracking solutions. Using the blockchain, each party in a B2B process could autonomously track the events related to a B2B transaction without the need to rely on a centralized authority. Additionally, the security capabilities of the blockchain will facilitate the implementation of more sophisticated reconciliation and auditing processes.\n\nLegal Proof of Existence or Proof of Possession\n\nValidating the existence or the possession of signed documents is an incredibly relevant element of legal solutions. The challenge of traditional document validation models is that they relied on central authorities for storing and validating the documents which presents some obvious security challenges but also becomes more difficult as the documents become older.\n\nThe blockchain provides an alternative model to proof of existence and possession of legal documents. By leveraging the blockchain, a user can simply store the signature and timestamp associated with a document in the blockchain and validate it at any point using the native blockchain mechanisms.\n\nCloud file storage solutions like Box, Dropbox or One Drive are becoming regular citizen of modern enterprise environments. Despite its popularity, cloud file storage solutions typically face challenges in area such as security, compliance and privacy in order to be adopted in enterprise environments. Those concerns are all rooted behind the fact that enterprises need to trust a third party cloud system with their confidential documents.\n\nCentral Security Depositaries (CSDs), has been an essential element of modern equity and bond trading. In the US equity market, following frequent bottlenecks during the late 1960s in the settlement of securities trades, CSDs smoothed the post-trade process for transferring share ownership by eliminating the exchange of paper certificates and recording transactions in central, computerised book-entry systems. The international CSDs, Euroclear and Cedel (now Clearstream) played a similar role in the Eurobond market from the 1970s onwards.\n\nThe centralized nature of CSDs is essential to a successful bond and equity trades. However, the settlement process via CSDs is incredibly expensive and slow averaging two or three days per trade settlement.\n\nThe blockchain offers an interesting alternative to traditional CSDs as a decentralized ledger that can keep records of transactions without relying on a central authority. The query capabilities of the blockchain will allow the settlement of trades in minutes or even seconds and at a fraction of the cost of the current CSD solutions.\n\nCounterfeiting remains as one of the biggest challenges in modern commerce. Segments like luxury goods, pharmaceutical or electronics are constantly affected by counterfeiting. As a result, the demand for anti-counterfeiting remains one of the hottest topics in the digital commerce world. Unfortunately, most solutions in the market require a trust in the third party authority which introduces a logical friction between merchants and consumers.\n\nThe decentralized and security capabilities of the blockchain can enable an interesting alternative to traditional anti-counterfeiting platforms. In that sense, we can envision a model in which brands, merchants and marketplaces are part of a blockchain network with nodes storing information to validate the authenticity of specific products. In this model, brands don\u2019t have to trust on a central authority with their product authenticity information and can rely on the security and decentralized trust models of the blockchain.\n\nGovernments all over the world are investing deep resources to digitalize many of their existing processes. Many of these processes deal with sensitive information that require sophisticated levels of traceability, privacy and security. Inevitably, the digital collaboration process rely on trust on centralized authorities.\n\nThe blockchain capabilities provide a robust option to enable the digital collaboration between government agencies and citizens. In this model, different government agencies can store records in blockchain nodes so that it can be accessed and verified by other government parties and citizens in a secure and trusted way.\n\nTraditional ecommerce business models are based on the presence of a centralized entity that control activities such as order processing, inventory management, catalog access etc. In order to buy and sell goods, ecommerce marketplaces need access to sensitive user information such as credit card information, user profile data etc. This information often becomes the target of cyber security attacks and many other security and regulatory challenges.\n\nThe architecture of the blockchain can enable the first effective peer to peer (P2P) ecommerce network in which buyers and sellers can interact directly without the need of a central authority. The absence of a central marketplace eliminates many of the restrictions of ecommerce models such as fees, regulated transactions etc.\n\nThe blockchain represents one of the most important advancements in computer science of the last few years. The ability to enable decentralized, secure, trusted and highly scalable architectures opens the door to a new group of enterprise software solutions on a large number of industries. Blockchain powered solutions have the opportunity to challenge some of the fundamental architecture principles of enterprise solutions in areas such as security, data storage, trust, etc. Similar to Bitcoin, we should expect to see spectacular platforms in the enterprise software space powered by the blockchain."
    }
]