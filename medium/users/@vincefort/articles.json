[
    {
        "url": "https://becominghuman.ai/representation-learning-and-language-63bfa4f91f1f?source=user_profile---------1----------------",
        "title": "Representation learning and language \u2013",
        "text": "Given these intuitions, we can try to understand what the VQ-VAE does: It is a variational autoencoder, meaning it maps inputs into a latent space and reconstructs them probabilistically, but at the same time it also performs vector quantization on that latent state!\n\nThat means that the VQ-VAE learns a mapping from inputs to latent representations and then in turn maps these representations to their respective nearest prototype representation. The decoder then has to learn to reconstruct the input from this prototype.\n\nEncoder, decoder and prototypes (called embeddings in the paper) are learned more or less simultaneously, such that the encoder can learn to map similar inputs to the same prototype and the prototypes can match the density of latent representations.\n\nGoing back to our semiotic model, we now start to see many parallels. We could for instance take a photo of a dog (referent) with our smartphone, which would yield a digital encoding of what that dog looks like (reference).\n\nWe can now view the VQ-VAE as an act of communication between the encoder and decoder networks. The encoder gets the image of the dog (which is as adequate a reference as any digital photo arguably) and has to find a correct symbol to facilitate successful communication. It therefore has to map the input (reference) to the correct prototype (symbol) in the latent space (vocabulary), such that the decoder can map it back to an image (reference) which is as close as possible to the input.\n\nIt should be emphasized that the encoder and decoder learn the symbols and the mappings to the references at the same time, much like two children inventing their own words for objects and sharing them by pointing at the respective things. If news about neural networks inventing their own secret language would ever be appropriate, they should report about the VQ-VAE!\n\nNotably, because of the vector quantization\u2019s density matching property, the learned symbols are dependent on the input distribution: A VQ-VAE trained with many pictures of dogs and only a few pictures of cats might invent numerous symbols for different kinds of dogs, but only a handful of symbols for cats, much like human dog breeders with their specialized vocabulary or graphics designers who have many names for different color nuances, because they encounter these kinds of referents and references more often.\n\nWe can therefore conclude that the vector quantised variational autoencoder with its discrete latent representations can be described in the terminology of the semiotic triangle and is therefore arguably the deep learning model with the closest similarity to human communication. This suggests many exciting avenues for research, for instance regarding the interpolation between different prototypes in the VQ-VAE\u2019s latent space and how this operation could be understood semiotically.\n\nAnother interesting idea would be to use the VQ-VAE for human language instead of images. This has indeed been tried by the authors of the paper and led to an unsupervised discovery of certain phonemes in speech data.\n\nFuture research regarding the VQ-VAE and similar models promises deeper insights into semiotically plausible data encoding and generative modeling."
    }
]