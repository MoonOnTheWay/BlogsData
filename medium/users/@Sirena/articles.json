[
    {
        "url": "https://medium.com/@Sirena/vantage-point-tree-does-careful-selection-of-vantage-point-make-sense-c74bbd6d77e9?source=user_profile---------1----------------",
        "title": "Vantage Point Tree: does careful selection of vantage point make sense?",
        "text": "Vantage Point Tree is very old algorithm for making fast search within tree. Off course nowadays we have so many tools for working with big data, but sometimes we face with problem where big data storage cannot provide us with good performance or another solution is cheaper.\n\nI used this algorithm for find k nearest embeddings that represent image itself. Practically this algorithm showed good result and persuaded that with little modification in performance it can work in production.\n\nI want to consider different approaches for selecting vantage point and show that simple approach is working very well comparing with proposed in paper that more time consuming.\n\nBriefly describe this algorithm: in paper they talk about tree that we can use for fast searching. Every node of tree is so called vantage point that split the metric space into two subspaces \u2014 left and right. The first subspace contains closest points to vantage point and the second one is the most distant. For every point we construct subtree that also divide space into two subspaces. At the end we get the tree where we can find the nearest points for the given one.\n\nThey propose selection of vantage point from random sample that will spread the space better. The bigger second moment defines the best spread. What does it mean?\n\nIn paper they also propose heuristic search algorithm. But I want to consider different approaches that use people for selecting vantage point. Also I tested search within constructed tree for finding tree nearest neighbors.\n\nFor testing I used 50 embeddings (dimension is 128) and euclidean distance for calculating distance between embeddings.\n\nI used T-SNE for visualization, hence all cases will have a little bit different view. But for what I want to pay attention:\n\n2. Finding 3 nearest neighbors time and the distance from given point to neighbors.\n\nThis approach has mathematical justification that described in paper.\n\na) For the first case every iteration vantage point was selected from all points that weren\u2019t chosen as vantage points yet.\n\nOff course time for building tree will be the greatest.\n\nDistances from given point to neighbors:"
    },
    {
        "url": "https://medium.com/@Sirena/override-tensorflow-backward-propagation-1a7e2bb3f516?source=user_profile---------2----------------",
        "title": "Override Tensorflow backward-propagation \u2013 Sirena \u2013",
        "text": "Tensorflow is a great tool that works with deep learning. There are a lot of operations that you easily can implement and make good model that solves needed problems. But sometimes there are models that have own specific computations.\n\nI faced with one of them. When you create neural network architecture you can find that some operations do not flow in backward-propagation. On a piece of paper you can compute gradient and derive the formulas that are participated in backward-propagation, but Tensorflow due to its complexity cannot resolve the gradient and as a consequence you cannot train neural network.\n\nAs I said Tensorflow is a great tool and it proposes the ability to override gradient and write own custom gradient that can flow in backward-propagation. But how to do it and make it really works?\n\nFirstly, I will explain it using simple network just for understanding this process. And then I will show real case where I had to have to override the gradient.\n\nImagine that this part cannot be calculated in backpropagation \u2014 Tensorflow returns None for such gradients:\n\nIt means that it\u2019s not so obvious for Tensorflow how to compute the gradient in backpropagation. But you know that this is a differentiated model and on a piece of paper you can derive the formula. So what you need \u2014 just tell Tensorflow how to do it.\n\nIn add_grad you return the function that overrides gradient. The py_func looks like this:\n\nAs you see Tensorflow has own wrapper for python functions \u2014 tf.py_func. But at the same time it means that forward propagation you have to implement without Tensorflow operations. Because if you use Tensroflow operations in function that afterwards you pass to tf.py_func \u2014 it\u2019s going to fail.\n\nI couldn\u2019t find the way how to implement forward propagation using Tensorflow operations, but I think it should be for having better performance. Please, share with me if you know.\n\na) What should be in forward pass (forward_func):\n\nIn forward_func you have to implement forward propagation using python operations.\n\nAs you see d variable is redundant in this method, but you cannot avoid using it, because it will be needed in backprop. It means that forward and backprop are at the same bunch \u2014 they share variables. You can notice that in py_func you declare all variables that are needed in both methods.\n\nb) What you want to get in backpropagation (backprop_func):\n\nFinally, in backprop_func we can implement the custom gradient. But custom gradient you do not pass to any wrapper, so you have to do it with Tensorflow operations.\n\nNotice, that we have to return gradient for each variable that was passed to that function \u2014 it is partial derivatives. I do not show how to calculate the gradient for each variable. Please do it by yourself.\n\nop contains all passed variables; grad \u2014 the flown gradient from the back propagation.\n\n3. Then explicitly call compute gradients and apply them when you initialize graph:\n\nThe work is done. But to be sure that computations will be without errors, you can check firstly calculating on a peace of paper and then run code. For that example we can call tf.add instead of add_grad and remember values, and then call add_grad to compare the outputs. I got the same result."
    },
    {
        "url": "https://medium.com/@Sirena/%D0%BF%D1%80%D0%BE%D0%B4%D1%83%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D1%81%D1%82%D1%8C-%D0%B8-%D1%87%D1%82%D0%BE-%D1%82%D0%BE-%D0%B5%D1%89%D0%B5-fb7e6c15977f?source=user_profile---------3----------------",
        "title": "\u041f\u0440\u043e\u0434\u0443\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c \u0438 \u0447\u0442\u043e-\u0442\u043e \u0435\u0449\u0435 \u2013 Sirena \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    }
]