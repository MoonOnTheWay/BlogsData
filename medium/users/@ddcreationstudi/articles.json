[
    {
        "url": "https://towardsdatascience.com/machine-learning-basics-part-4-anomaly-detection-recommender-systems-and-scaling-b8bbf0413aa9?source=user_profile---------1----------------",
        "title": "Machine Learning Basics \u2014 Part 4 \u2014 Anomaly Detection, Recommender Systems and Scaling",
        "text": "In this article I revisit the learned material from the amazing machine learning course by Andre Ng on Coursera and create an overview about the concepts. The article is not designed as a tutorial but rather to fresh up on the basic ideas.\n\nAll quotes refer to the material from the course if not explicitly stated otherwise.\n\nAnomaly detection tests a new example against the behavior of other examples in that range. This idea is often used in fraud detection, manufacturing or monitoring of machines. It is always useful if the goal is to detect certain outliners.\n\nUsing a Gaussian distribution algorithm implies that the example x is distributed with a mean Mu and variance Sigma squared.\n\nThe formula for Mu and Sigma squared are:\n\nThe formula for calculating the probability is:\n\nThe steps to build the algorithm are\n\nWhen the algorithm is implemented it is important to introduce a real-number evaluation metric.\n\nAs always, it is advisable to split the data set into a training, cross-validation and testing set (60\u201320\u201320).\n\nThe steps to build the system would be:\n\nAn anomaly detection system should be used if\n\nIf a classification can easily be done, ie having large numbers of positive and negative examples and future examples will be similar, it is advisable to use a supervised learning algorithm. (eg SPAM, cancer classification)\n\nTo analyse errors it makes sense to plot the features and see if they behave Gaussian. If not, constants (like log(x)) can be added, to try to make it look as Gaussian as possible.\n\nThe basic assumption for using anomaly detection system is to have few anomalous examples and many normal ones. If this is not met, the misclassified example should be inspected for behavior that allows to come up with a new feature.\n\nIn certain cases the normal Gaussian distribution is not enough the accurately flag anomalies. A multivariat Gaussian distribution calculates the probability model of x at once, instead of modelling the probabilities for each feature alone. It uses a covariance matrix instead of Sigma squared.\n\nThe formula looks like:\n\nThe multivariate Gaussian model is worth to be considered when the number of examples is much larger than the number of features. It captures correlations between features but is computational expensive. When it is obvious what feature combinations can capture the anomalies, it is advisable to first implement those with the original Gaussian model.\n\nA recommendation system is one of the most common and most successful practical examples for applying a machine learning algorithm in real life.\n\nAssuming you have a content-based recommender system. First, a problem has to be formulated. This can be something like predicting the rating of a certain product of a certain user.\n\nGiven the ratings of a movie, to learn the parameter Theta for a certain user, the optimization algorithm can look like this:\n\nThis is the basic cost function of a squared error with regularization summed up for different users (Theta j).\n\nAnd using gradient descent (multiplying the learning rate alpha with the partial derivative with respect to your parameter of the optimization objective) to gradually minimize the result. Note, that Theta 0 for k = 0 should not be regularized (as explained in linear regression).\n\nGiven the parameters Theta of each user for a certain movie, the feature vector of a movie can be estimated with the optimization algorithm:\n\nOne way to address the problem of what vector to calculate first (feature vector of a movie or the parameter vector fo a user), is to guess the parameter vector for a user and then use the estimation to define a (better) feature vector for a movie.\n\nThis implementation is called collaborative filtering because with each rating of a user the algorithm is able to define better movie feature vectors and improves the output for all users.\n\nTo use collaborative filtering simultaneously (updating Theta and x at the same time), the following formula can be used:\n\nThis leads to the following gradient descent implementation:\n\nTo implement this formula, you have to\n\nAfter implementing the collaborative filtering system another step can be to suggest related movies/products.\n\nThis is easily done since we have already calculated a feature vector x. Now to find related movies/products, we simply have to find the ones with the smallest distance, like:\n\nNote, that if you have a user or movie/product with no rating at all, you should perform mean normalization before implementing the learning algorithm. To accomplish this, first the mean should be subtracted from the result matrix and re-added when predicting the rating. But you should always ask yourself if it makes sense to recommend something to a completely undefined unit anyways.\n\nWhen having a case with very large numbers of examples (~100 Mio) always ask yourself if it is possible to reduce the dataset with keeping the results.\n\nOne way is to plot a learning curve for a range of values of m and verify that the algorithm has high variance when m is small. When th algorithm already has a high bias, increasing the dataset does not help.\n\nOn large training sets gradient descent becomes very computational expensive. A way to address this problem is to use stochastic gradient descent.\n\nInstead of iterating through all trainings examples at once, you shuffle your dataset randomly and perform gradient descent on a single example as follows:\n\nThis allows to improve the parameters on every single example and therefore takes much less time than improving them on all examples at once. (On the cost that it might not converge at all \u2014 but ends up close enough for most practical use cases).\n\nAs a middle way between going through all examples or just 1 example in each gradient descent iteration, mini-batch allows to set a certain number b of examples per iteration. The adapted loop could look like this:\n\nTo test if either mini-batch or stochastic gradient descent are converging the cost function can be plotted and checked.\n\nWhereas for mini-batch gradient descent the cost function of the number of iterations can just be plotted, for stochastic gradient descent the cost function (on a certain example) has to be plotted on the average of multiple examples.\n\nIf the algorithm fails to converge try to slowly decrease the learning rate Alpha.\n\nIn the idea of online learning data is considered to be endless and free. For example getting a stream of user data on a website. In this case, gradient descent can be performed on one example at each time for endless times. With each incoming example the algorithm is improved and this way the algorithm can also adapt according to changes in user preference.\n\nAnother way to address huge data sets is to use batch gradient descent but splitting it to different sub sets, allowing multiple machines to work on their own set of data. Afterwards the results can simply be added together to fit the original formula (basically using the sums of functions).\n\nAnalyse what part of your pipeline is worth spending time for improvements by comparing the accuracy improvements."
    },
    {
        "url": "https://towardsdatascience.com/machine-learning-basics-part-3-vector-machines-unsupervised-learning-and-principal-component-5b51aac6dd0c?source=user_profile---------2----------------",
        "title": "Machine Learning Basics \u2014 Part 3 \u2014 Vector Machines, Unsupervised Learning and Principal Component\u2026",
        "text": "In this article I revisit the learned material from the amazing machine learning course by Andre Ng on Coursera and create an overview about the concepts. The article is not designed as a tutorial but rather to fresh up on the basic ideas.\n\nAll quotes refer to the material from the course if not explicitly stated otherwise.\n\nInstead of regularizing the second term with lambda like we did in the original cost function:\n\nNow we want to regularize the first term with the parameter C and adding a new cost function (cost1 and cost0) for transpose theta:\n\nPlotting the cost1 and cost0 function looks something like this:\n\nHence, if we want a result y = 1 theta transpose X must be greater than 1 and if y = 0 theta transpose X must be smaller than -1.\n\nIn essence, we just have simplified the cost function in order to use geometry for further steps.\n\nIn case of linearly separable data, the SVM algorithm chooses the line that separates the classes with the largest margin.\n\nUsing calculus the length of a parameter can easily be retrieved from the initial formula.\n\nBasically, the projection of vector X is multiplied by the length of parameter theta and optimized to be a maximum/minimum. This results in always returning a line that seems to separate 2 classes evenly.\n\nNote, that in order to neglect outliners it helps to decrease the value of C (regularizing).\n\nSince polynomial features can be computational expensive, common practice introduces Kernels. For this, new features which depend on similarity of features and examples, are computed. It is like putting landmarks on the plot and calculating the similarity with the Gaussian Kernel formula. If the similarity is 1, the training example is close to the picked landmark.\n\nThe choose for the value of the parameter sigma determines the boundary for similarity.\n\nIntroducing the landmark-similarity system allows to classify data that is not linear.\n\nTo compute the landmarks we adapt the cost function to the following:\n\nKeep in mind that for the regularizing part, instead of n (number of features) m (training examples) should be used. This makes sense, since we want to calculate the landmarks which are related to the examples.\n\nAlso note, that you can implement the concept of Kernels on logistic regression as well but the mathematical benefits of SVM cannot be utilized properly and the implementation will likely be slower.\n\nAnother term for kernel is \u201csimilarity-function\u201d.\n\nTo address over- and underfitting, the parameters lambda (in C) and sigma can be used.\n\nIncreasing C (essentially minimizing lambda) or decreasing sigma squared improves underfitting (high C leads to higher variance).\n\nIn a supervised learning problem a set of labels is given to fit a hypothesis to it. In contrast, in the unsupervised learning problem we\u2019re given data that does not have any labels associated with it.\n\nThe goal of the algorithm is to find structure (clusters) within the data set.\n\nTo put this algorithm in simple terms:\n\nThe cost function, which tries to minimize the mean of the squared distance between an example point and the location of the corresponding cluster centroid, looks like the following:\n\nIn order to avoid local optima, the following steps should be implemented multiple times:\n\nTo choose the number of clusters k the \u201celbow method\u201d can be used, which plots the cost function to the number of clusters and uses the number where the curve shows an \u201celbow\u201d. However, since this method can be difficult to use on certain graphs, another way would be to simply select the number according to a later/downstream purpose (like desired product sizes \u2014 small, medium, large).\n\nReducing data from multiple dimensions to 2 or 3 dimensions through data compression allows to plot data and give valuable additional insight. Simply reducing data can speed up the running time of a learning algorithm and reduces the space needed for storage.\n\nThe most common algorithm is principal component analysis. The idea behind it is to reduce a dimension by finding a direction (vector) onto which to project the data to minimize the projection error. When plotted, the algorithm might look similar to the linear regression model. However, it is important to note that in linear regression the variable y is predicted by the variable x, whereas in PCA the different variables x are treated equally.\n\nTo implement a PCA algorithm, you normally\n\nTo decompress the data and harness the real power of this concept, it is possible to reconstruct the (approximated) original by simply multiplying the U matrix with the z vector again.\n\nTo choose the variable k (number of principal components) the following formula can be used:\n\nThe idea is to divide the average squared projection error (which we try to minimize) by the total variation in the data.\n\nThe practical implementation would be to try the PCA algorithm with k = 1 and test if the condition for the retained variance is fulfilled, and if not the procedere with an increased k should be continued. Or to take the S matrix, which resulted from using the singular value decomposition on sigma and testing it like the following:\n\nTo speed up a supervised learning case, you should\n\nNote that, PCA should only be used on the training set and not the cross validation or testing set. Afterwards the resulted mapping from x to z can be applied to the cross validation and testing set as well.\n\nBe careful to NOT use PCA when your model has a problem of overfitting. Although reducing features helps in addressing the problem, the concept of PCA throws away some amount of information without knowing the values of y. This can lead to bad results. It is better to use regularization instead.\n\nLastly, always try to train your algorithm with original data. PCA should only be applied if the normal machine learning architecture is not sufficient!"
    },
    {
        "url": "https://towardsdatascience.com/machine-learning-basics-part-2-concept-of-neural-networks-and-how-to-debug-a-learning-algorithm-8a5af671d535?source=user_profile---------3----------------",
        "title": "Machine Learning Basics \u2014 Part 2 \u2014 Concept of neural networks and how to debug a learning algorithm",
        "text": "Machine Learning Basics \u2014 Part 2 \u2014 Concept of neural networks and how to debug a learning algorithm\n\nIn this article I revisit the learned material from the amazing machine learning course by Andre Ng on coursera and create an overview about the concepts. All quotes refer to the material from the course if not explicitly stated otherwise.\n\nFor neural networks we take the findings from exploring the statistical regression and try to put it in brain-like architecture.\n\nThe used terms change a little as the logistic function is often referred to as the sigmoid activation function and the theta parameters as weights. The underlying concept stays the same. Instead of the bias term theta 0, now a bias unit with the value of 1 is used.\n\nThe neural network architecture is made of at least 3 layers. That is\n\nlayer. (Many neural networks have more than 1 hidden layer though)\n\nIn an activation unit, the weighted input of each unit in the previous layer is re-calculated and re-measured. You can say that neural networks can basically implement the concept of a statistical regression multiple times with more and more advanced input.\n\nOf course this concept can also be applied using vectorization. Therefore we use a new variable, that encompasses the weight parameters inside our g function as an activation unit. Here it is really important to track and visualize the dimensions of your matrices, since it can get quickly very complex (depending on your neural network architecture).\n\nCheck out this incredible article, that explains the concept very good with nice graphics.\n\nA great introduction example is the XOR Problem. This article explains it well.\n\nFor a logistic regression to be used in a neural network, the cost function has to be extend to hold the output units K and the regularization part needs the number of layers, the number of nodes in the current layer (plus the bias term) and the number of nodes in the next layers to localized the theta value correctly.\n\nWhereas forward propagation (activation of nodes) takes in the theta parameters of each node in the previous layer, backpropagation does basically the opposite. An error for each node is calculated by comparing the activation node\u2019s output with the calculated output of the node. Afterwards this error is minimized gradually by adapting the used parameter theta.\n\nThe formula for calculating the error is:\n\nSince some, more advanced, algorithms need vectorized versions for computation. Unrolling matrices into vectors is a great way for calculating the cost function and getting the vector of the calculated parameters and reshaping the result back into matrices.\n\nTo ensure that your backpropagation works as intended you should check your gradient. This is done calculating an approximation in respect to theta with the following formula:\n\nIf the result is similar to the gradient vector the implementation works correct.\n\nTo use gradient descent in a neural network the initial values for theta cannot be symmetrical and must be initialized randomly. Using symmetrical initialization always lead to the same learning result, since the is no variety provided.\n\nSometimes the learned algorithm produces large errors. The following strategies help you debugging.\n\nThe first steps you can always take is to get more test data, increase or decrease features or your regularizing lambda.\n\nAfter that split the data into a training set (~70%) and a test set (~30%). This technique give you immediate feedback on how well your hypothesis is performing.\n\nTherefore the data can be split into 3 sets:\n\nThis allows us to 1. calculate the optimal parameters, 2. apply it to different polynomial models and find the one with the smallest error and 3. estimate the general error of the best model.\n\nThe bias vs. variance problem describes the issue of the hypothesis under-, or overfitting a data set. Whereas a high bias underfits the data, a high variance overfits it.\n\nFor diagnostics, the errors of the sets can be compared. If the errors of the cross-validation and the test set are high the hypothesis is suffering from high bias. If the cross validation sets shows a much higher error than the training set the problem is most likely a variance problem.\n\nThese problems can be addressed using different regularizing lambda parameter.\n\nRemember that, a lambda of the value 1 equals a completely biased hypothesis (underfitting), whereas a lambda of 0 is essentially high variance one (overfitting).\n\nTo apply this in practice it is useful to create a list of lambdas (eg. 0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24) and supply them when working on the different polynomial models in the trainings set and pick the one with the smallest error. It\u2019s important to note, that when computing the errors of the cross-validation set to not use regularization again, since it would distort the result.\n\nWith increasing size of a set the errors will increase until a certain point where it plateaus.\n\nIf the algorithm is suffering from high bias, getting more data won\u2019t help as it is already underfitting. However if the problem is a overfitting one with high variance, getting more data is likely to improve the algorithm.\n\nHigh bias can be addressed by\n\nHigh variance can be addressed by\n\nImportant questions one have to ask themselves:\n\nA recommended approach to design a machine learning system is to\n\nSkewed classes appear when one class is over-represented in the data set.\n\nTo test if your data is suffering from this problem implement precision and recall tests. You are essentially testing the true positives of all predicted positives (precision) and compare it top all true positives of all actual positives.\n\nDepending on the goal of your classification problem, the way of weighting precision and recall varies. As the hypothesis returns the probability between 0 or 1, the set boundary threshold decides whether to classify an outcome as positive or negativ.\n\nOften the starting point is 0.5, ie. everything under 0.5 is classified as negative. Depending whether you want to predict very confidently or rather avoid missing many cases, it makes sense to test different values for 0 and 1 (eg 0.3, 0.5, 0.7, 0.9) and compare the resulting algorithms. As you will have 2 values (one for Precision, one for Recall), the desired threshold can afterwards be calculated with the F-Score formula:\n\nTo achieve the highest possible accuracy it is best to have as much useful(!) data as possible (low variance), but also to have an algorithm with many features or parameters (low bias)."
    },
    {
        "url": "https://towardsdatascience.com/machine-learning-basics-part-1-concept-of-regression-31982e8d8ced?source=user_profile---------4----------------",
        "title": "Machine Learning Basics \u2014 Part 1 \u2014 Concept of Regression",
        "text": "In this article I revisit the learned material from the amazing machine learning course by Andre Ng on coursera and create an overview about the concepts. All quotes refer to the material from the course if not explicitly stated otherwise.\n\nLinear regression tries to fit points to a line generated by an algorithm. This optimized line (the model) is capable of predicting values for certain input values and can be plotted.\n\nWe want to set the parameters in order to achieve a minimal difference between the predicted and the real values.\n\nGradient descent keeps changing the Parameters to reduce the cost function gradually. With each iteration we shall come closer to a minimum. With each iteration the parameters must be adapted simultaneously! The size of a \u201cstep\u201d/iteration is determined by the parameter alpha (the learning rate).\n\nChoosing the value of alpha is crucial. If it is too small the algorithm will be slow, if it is too large it will fail to converge.\n\nWhen specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived, where m is the size of the training set. Again both parameters must be updated simultaneously.\n\nNow, instead of one feature/variable that is responsible for a certain outcome we have multiple ones.\n\nTherefore the hypothesis changes accordingly and takes multiple parameters into account. The same applies for the gradient descent. It simply is an extension by the additional parameters, which must be updated.\n\nTo make sure that all values of features are on a same scale and have the same mean it\u2019s necessary to use Feature Scaling and Mean Normalization.\n\nTo choose a suitable learning rate, gradient descent has to be plotted and \u201cdebugged\u201d.\n\nIf J(0) stops to decrease significantly in an iteration step convergence can be declared.\n\nFeatures can be improved by re-defining the hypothesis function into a quadratic, cubic or square root function.\n\nIn this case, extra emphasize must be applied to feature scaling!\n\nInstead of using gradient descent for gradually minimizing the cost function, the normal equation sets the derivatives to zero.\n\nThe normal equation doesn\u2019t need a learning rate alpha and no iteration at all, but requires the transpose of the design matrix. When you have a large number of features (eg 10000) the calculation will take longer than the iterative process with gradient descent. To improve the quality of the normal equation algorithm features should be regularized and redundant features deleted.\n\nTo classify data the result shall eiter be 0 or 1 (binary classification). From a regression point of view this can mean to classify output, that is >= 0.5 as 1 and output that is < 0.5 as 0 (whereas 0,5 is the decision boundary).\n\nThe adapted hypothesis, using the logistic/sigmoid function, would now be:\n\nIt returns the probability for the output being 1!\n\nDue to the use of the sigmoid function, the cost function has to be adapted accordingly by using the logarithm. Since the goal is now not to minimize the distance from a predicted value, but rather to minimize the distance between the output by the hypothesis and y (0 or 1).\n\nHowever, gradient descent stays the same because the formula uses the derivative part of the hypothesis!\n\noften allow faster computation with no need for picking a learning rate alpha.\n\nThe previously described classification problem solving only works for binary classification. Having more possible outcome than n=2 is called multiclass classification. To apply the concept on multiple classes the \u201cone-vs-all\u201d method is used, which is essentially applying the binary classification on each class (one class is positive, all the rest is negative). Instead of setting y to either 0 or 1, y is set to i, which itself is tested against all the other classes. Basically the process is twofold:\n\nIn the case of overfitting, the model captures the data structure perfectly, whereas in underfitting the model captures not enough of the data structure (ie. the graph of the model barely touches all of the data points).\n\nTo solve the problem of overfitting either the features can be reduced or the magnitude of their values can be regularized.\n\nFor regularizing a model, a parameter (lambda) has to be added to the cost function. It de- or inflates the parameter Theta.\n\nConsequently applying it to the logistic regression looks like this:\n\nNote how the regularizing parameter starts at 1 \u2014 not regularizing the bias term Theta 0."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/tips-for-finishing-the-machine-learning-course-by-andrew-ng-on-coursera-cc7735bdc4c8?source=user_profile---------5----------------",
        "title": "Tips for finishing the Machine Learning course by Andrew Ng on Coursera",
        "text": "The complexity of this course is twofold.\n\nTo fully grasp the use of all concepts in this course I think it is necessary to do more than just following along. Going though the course and finishing everything is just one step. I think the real value lies in revisiting all topics and trying to apply it to your own use cases. That\u2019s important to keep in mind.\n\nSince I haven\u2019t studied math or statistics I can\u2019t really give advise on that.\n\nBut if you are discouraged along the road that everything seems to be too complicated, try to focus on the very relevant parts of the learning week and it\u2019s tests. The professor says this in the videos anyways and always points out the important parts.\n\nThis is tough. Especially if you are not familiar with programming. But even if you have no experience with any programming language, this course provides a soft introduction to it and allows to apply basic principles for powerful results.\n\nI have used Matlab for all the challenges. I simply wanted to try it and thought there must be good documentation behind this product. And I wasn\u2019t disappointed.\n\nAs someone who learned programming on his own, I have dealt with this problem before. One important thing is to READ THE DOCUMENTAION. This is always the most important step.\n\nFor this course this applies for using Matlab features. The reason Matlab and Octave are recommended, is because they already offer a good variety of computing features with a solid performance.\n\nWhen you are trying to multiply vectors ( and you are going to multiply many vectors ) just reading this documentation helps to prevent a lot of problems. ( As I often have encountered and seen in forums )\n\nEspecially as it says in the description:\n\nIt is really easy and provides a lot of insight.\n\nIf debugging is not enough and you need a better visualization try to draw them out. This is especially useful when you have multiple errors in a longer formula calculation.\n\nThe PDF file with the assignments contains not only valuable tips on how to solve a problem, but also gives sometimes Octave/Matlab syntax to simplify code. Be sure to read the assignments properly and the difficulty of the task is most of the times reduced significantly.\n\nThe quizzes are multiple- or single choice tests. You can re-take a test 2 times and then you are blocked for 8 hours before being able to re-take the quiz again.\n\nSince there is no time pressure you can easily examine the course notes and documentation to read them again. This is not only advisable but even encouraged. In my opinion this is where the learning starts. Being able to apply the learned material to different problems.\n\nSometimes, as normal with multiple choice, the questions can be very tricky and confusing. Then re-taking the quiz might be helpful to come to a correct solution. ( Be aware that the questions and answers can change )\n\nThe following I found to be worth mentioning:\n\nIn order to get a certificate you need to verify yourself. This ensures quality and credibility. Just finish the process and wait for review.\n\nIf it takes too long you can send a mail to the support team, who resolve the issue very fast. ( In my case the support was fantastic! )\n\nPayment is done without problems with a credit card. I was so amazed by the quality of this course that I found it worth to buy the certificate. Not only to have credibility for the work, but also to support the people behind it.\n\nThe honor code shall ensure academic integrity and has to be agreed upon when doing the course.\n\nIn short, it prohibits actions, that will \u201cdishonestly improve your results or dishonestly improve or damage the results of others\u201d.\n\nThis is important to note, since it does also not allow to copy and share results. It even says on the website:\n\nOf course this is hard on the internet. Keep always in mind that this course is for you, you alone. Dishonoring the code doesn\u2019t add any value to your learning experience and harms open projects like this.\n\nHere is my certificate. If you have any questions feel free to reach out :) Thanks Andrew Ng, Stanford and the Coursera platform for making this happen. Additionally I was very surprised on how well teaching can be done. Professor Ng really is a great personality and a role model for teaching."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/install-tensorflow-with-virtuelenv-and-visual-studio-code-on-mac-6b9f93f0fb08?source=user_profile---------6----------------",
        "title": "Install Tensorflow with Virtuelenv and Visual Studio Code on Mac",
        "text": "Install Tensorflow with Virtuelenv and Visual Studio Code on Mac\n\nThe more detailled guide from Tensorflow\u2019s website broken down. I will use the VirtuelEnv, Python 2.7 and zsh. Enjoy!\n\nThis should show \u2018Hello, TensorFlow!\u2019 in the console.\n\nIf not, check out the official homepage for a solution.\n\nFor more details, see the official site.\n\nWhen the setup settings are not working, simply activate the virtualenv in the terminal with"
    },
    {
        "url": "https://medium.com/@ddcreationstudi/eu-wettbewerbsrecht-ae1898cc13ba?source=user_profile---------7----------------",
        "title": "EU \u2014 Wettbewerbsrecht \u2013 Daniel Deutsch \u2013",
        "text": "This is a quick overview of the competition law in the european union. This article will be in german, since it is used as a learning abstract."
    },
    {
        "url": "https://medium.com/createdd-notes/eu-der-raum-der-freiheit-der-sicherheit-und-des-rechts-a44bda9a11bd?source=user_profile---------8----------------",
        "title": "EU \u2014 Der Raum der Freiheit, der Sicherheit und des Rechts",
        "text": "This is a quick overview of the Area of freedom, security and justice in the european union. This article will be in german, since it is used as a learning abstract."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/reflecting-on-2017-the-legal-tech-student-perspective-8837738051dc?source=user_profile---------9----------------",
        "title": "Reflecting on 2017 \u2014 The legal tech student perspective",
        "text": "Most of the time I have a well defined set of goals for the next year.\n\nFor 2017 some of those were:\n\nIn the following lines I will examine the progress of each goal in more detail.\n\nThis was huge for me. In May 2016 I quite my job in tax advisory to get into programming. Since then I was studying and learning very hard to develop the skill set to work as a developer.\n\nI worked through the Free Code Camp curriculum and connected with local developers as much as possible. Each day I was watching videos, reading articles, programming small algorithms or attending some programming-related meetups.\n\nAt the end of 2016 I thought I was ready to apply for a job in this field. Luckily I was already connected to some programmers in the local community, which acted as a gateway for an interview.\n\nOne important note here: I was only able to connect to local programmers because I was introducing myself as a beginner on events and offering volunteer work to THEIR projects. I did this many times and followed the projects that had a good working flow and learning experience.\n\nDue to all the work with local people, online presence and some sort of presentation skill I was able to get my first job as a developer pretty quickly in March.\n\nIt was surprising to me how fast this goal could be accomplished.\n\nHere is a video of a talk me and Robert gave during one of our non-profit events.\n\nWith this goal I wanted to stay on track with all tech related news. Also I wanted to get into the habit of writing more in english (which is not my native language) and build an online presence.\n\nI also think that writing has always been very powerful, but is even more important in this era. As an article is written, it can be very easy to share it across multiple platforms and get feedback from different communities.\n\nWriting for me is an important tool to learn things. Formulating a thought on paper with your own words is much different than simply repeatedly read information.\n\nHowever, I came to acknowledge the time investment that writing regularly demands. Quality suffers incredibly when not enough time is invested. That\u2019s one of the reasons my articles constantly lack depth. But this year quantity was more important than quality for me in terms of writing articles.\n\nI found medium.com to be a great platform for articles in general and hashnode.com for more programming related stuff.\n\nGiving back is always important. So many opportunities and relationships simply arise because of non-profit work. This year I wanted to do something non-profit in the tech sector.\n\nSince Free Code Camp helped my a lot when starting to program, I wanted to give back to this organization. Free Code Camp has several local groups, where the students come together and exchange on their progress.\n\nSo I started to contribute regularly to host all the local meetups in Vienna for this year. A separate article can be found here.\n\nIn short: I was able to create value for many, many people in the programming community in Vienna \u2014 success! :)\n\nBuilding a habit is one of the most important things when to learning a new skill. As Zig Zigler put it very eloquently:\n\nFor me it meant to code whenever possible. Even just a few lines of code is enough to stay on track. Of course this goal was a lot easier to achieve when I started to work as a developer.\n\nSince learning is literally the most important thing in life, I like to \u201cofficially\u201d commit myself to learning in a public learning institution. In my case, this is university. It is especially beneficial when your studies are about different things than programming. It provides a perspective and allows you to see things from a different view.\n\nThis goes very well for law. As I see it, law is the science of organizing societies, and therefore is a great extension for my work in computer engineering.\n\nThis year\u2019s focus was on:\n\nI also love the dynamics of having different social settings. Working half-time as well as studying the rest of the time allows my to build different relationships with different minds. It\u2019s amazing to see how people from different fields think differently.\n\nReading is one of the most valuable learning experiences for me and therefore each year a goal. It is important to note that this goal aims at reading books, which are different than those I have to read for university or work. I try to enrich my mind as much as possible with different mindsets and opinions in order to sharpen my mind.\n\nSome book recommendations from this year:\n\nThis one was very easy for me, since I am used to do more sport per week anyways.\n\nThe challenge I found in this year was to balance motivation between workouts and pursuing my programming goals. Aiming for a balanced schedule is the real challenge when you constantly expose yourself to new ideas.\n\nThe last months I came to the conclusion that focusing on more balanced activities like stretching, strength and stamina is more powerful for health than simply building strength. Especially Yoga keeps being a great addition for my sport schedule and benefits my life enormously.\n\n2017 was an incredible year and I am excited for the next year with all the new challenges. I am especially eager to use all the new technology that keeps arising."
    },
    {
        "url": "https://medium.freecodecamp.org/reflecting-on-hosting-meetups-in-2017-5d28d1db074d?source=user_profile---------10----------------",
        "title": "What I\u2019ve learned hosting Meetups in 2017 \u2014 and why I\u2019m looking forward to 2018.",
        "text": "What I\u2019ve learned hosting Meetups in 2017 \u2014 and why I\u2019m looking forward to 2018.\n\nAs 2017 comes to an end, it\u2019s time to reflect on the non-profit work I have done.\n\nAs soon as I learned the basics of programming with the help of freeCodeCamp, I was eager to give something back. I figured out that I could probably do the most by strengthening the local group of the organization. I wanted to help individuals on the same path, and provide a framework of exchange for these groups of people.\n\nEven though I am doing more than just organizing meetups, I want to focus on the freeCodeCamp Local Meetup in Vienna in this article.\n\nRobert Axelsen had the courage and took the initiative to start the local group in Vienna. Robert is an amazing human being and we immediately connected. Since the start of this year, we\u2019ve both organized the meetup and enjoyed all highs and lows of organizing.\n\nThe meetup itself currently focuses around collaborative coding. We talk about programming, the presentation of projects, and updates and news from the development world.\n\nI believe that managing an organization is one of the most rewarding you can do. Not because of the feedback you receive, but rather because of the complexity of the task itself.\n\nWhen organizing meetups and events, one must not only handle event-specific tasks such as preparing locations, sponsors, talks, and content. You must also stay in contact with all the people involved in the process and get yourself into the discussed topics as well.\n\nThe complexity itself demands a lot from the organizer and schools him on many aspects of life. As I see it, it is the perfect preparation for starting a business. Although it can be hard to fit into the day-to-day schedule, it is perfectly doable when the basics of time management are applied.\n\nAnother reason organizing events is great is because it forces you to increase your self-awareness, which is key in life in general. Knowing who you are, what your strengths and weaknesses are, and how other people perceive you is very important to develop a better self.\n\nBecause how can you improve yourself if you are delusional about yourself?\n\nDuring the journey, it seemed necessary to formalize the work through a non-profit entity. We made this decision after careful due diligence. Setting up a business-like structure involves many new aspects in organizing, such as correspondence with local authorities, being aware of legal pitfalls (especially regarding tax law and competition law), and being liable to certain actions.\n\nIt introduces and demands a new field of competence and expertise but also allows for additional rewards. Some of them are:\n\nThe takeaway here is to carefully audit the possible advantages and disadvantages and always calculate the hidden costs.\n\nI have learned that people are really different. We have a variety of different people from different countries, different fields of expertise, different social backgrounds, and of course with different personalities.\n\nThat said, I think one of the most important abilities someone can have is to be flexible and adaptable to any situation. And that\u2019s another reason why organizing meetups is great \u2014 because you learn to be more and more flexible with people.\n\nI really started to understand this during a coding workshop we did. We wanted to keep it as flexible as possible to provide a good experience for all attendees. And even though we expected it could be difficult, we witnessed astonishing results.\n\nIn the workshop, we decided to divide the attendees into three different groups and encouraged them to develop a project in a collaborative effort. Only one group was able to form a coherent unit with the ability to get into a flow and build a great project.\n\nI think what makes a good leader is being able to identify strengths and give people social boundaries to allow them to unfold their potential. Every time a group is not able to get a workflow going it is either because:\n\nRandomly forming groups of people neglects the personality traits of each individual and is therefore prone to failure. There has to be an individual who is capable of taking on the lead, who is also competent enough to do it successfully.\n\nIn a collection of random people, the only way to increase the possibility of a successful outcome is to try to arrange the inhomogeneity of the group as high as possible, so that natural grouping can occur freely."
    },
    {
        "url": "https://medium.freecodecamp.org/favorite-vs-code-extensions-2017-786ea235812f?source=user_profile---------11----------------",
        "title": "Favorite Visual Studio Code Extensions of 2017 \u2013",
        "text": "Here is a list of some extensions I come to enjoy with Visual Studio Code (VSCode). Since I work a lot in the front-end, most of these extensions will be useful for web developers. I have been working previously with Atom, Visual Studio and Webstorm but VSCode suits me best and is just incredible. The developer did a great job ( and still do! ). Try it for yourself and enjoy!\n\nAutomatically add an HTML/XML close tag, same as Visual Studio IDE or Sublime Text does.\n\nAutomatically rename a paired HTML/XML tag, same as Visual Studio IDE does.\n\nThis extension adds rich language support for the HTML Markup to VS Code, including: Full HTML5 Tags, Colorization and Snippets.\n\nThis VS Code extension automatically shows Markdown preview whenever you open new Markdown file. If you feel annoying to type \u201cCtrl+K V\u201d or \u201c\u2318+K V\u201d (preview side-by-side) many times, this extension helps you.\n\nSee more\n\nGenerate TOC (table of contents) of headlines from a parsed markdown file.\n\nSee more\n\nA set of themes based on SublimeText-Markdown/MarkdownEditing.\n\nSee more\n\nA basic spell checker that works well with camelCase code.\n\nSee more\n\nDebug your JavaScript code in the Chrome browser, or any other target that supports the Chrome Debugger protocol.\n\nIntegrates ESLint into VS Code.\n\nSee more\n\nThis extension contains code snippets for JavaScript in ES6 syntax for Vs Code editor (supports both JavaScript and TypeScript).\n\nSee more\n\nA basic spell checker that works well with camelCase code.\n\nSee more\n\nIntegrates the tslint linter for the TypeScript language into VS Code.\n\nSee more\n\nvscode-ext-color-highlight. This extension styles css/web colors found in your document.\n\nSee more\n\nCustom CSS to your VS Code. Based on Roberto Huertasm\u2019s vscode-icons.\n\nEditorConfig helps developers define and maintain consistent coding styles between different editors and IDEs. The EditorConfig project consists of a file format for defining coding styles and a collection of text editor plugins that enable editors to read the file format and adhere to defined styles. \n\nSee more\n\nVisual Studio code extenstion that allows to quickly create new files based on defined templates.\n\nSee more\n\nView git log along with the graph and details. View the history of a file (Git log) or the history of a line in a file (Git Blame). View a previous copy of the file. Compare a previous version with the version in the workspace or another. View commit log details for a selected commit. Compare commits.\n\nThe Material Icon Theme provides lots of icons based on Material Design for Visual Studio Code. \n\nSee more\n\nProvide rainbow colors for the round brackets, the square brackets and the squiggly brackets.\n\nSee more\n\nVS Code package to format your JavaScript / TypeScript / CSS using Prettier.\n\nSee more\n\nManage your projects right inside Visual Studio Code. Easily access and switch between them.\n\nSee more\n\nMetrics, insights, and time tracking automatically generated from your programming activity.\n\nSee more\n\nSynchronize Settings, Snippets, Themes, File Icons, Launch, Keybindings, Workspaces and Extensions Across Multiple Machines Using GitHub Gist.\n\nSee more\n\nThanks for reading my article! Feel free to leave any feedback!"
    },
    {
        "url": "https://medium.com/createdd-notes/implement-linear-regression-in-react-d7e539814fe5?source=user_profile---------12----------------",
        "title": "Implement linear regression in React \u2013 Createdd Notes \u2013",
        "text": "Here I have used public available data from Austria. In this example the number of marriages of all people living in Salzburg (a city in Austria) are gathered over time. It allows to show differences in age, years, wifes or husbands.\n\nFor creating the web application I used React with the create-react-app boilerplate. Visualization is done with Uber\u2019s React-vis library. It integrates nicely with a React app and allows a fast development of charts and plots. The regression calculation is done with Regression.js, a library for calculating the actual regression line and additional information.\n\nThe provides the entry for the app. It renders , which renders the following:\n\nIn essence, it just calls the components, prepares the data, calculates the regression from the prepared data, and builds the plot accordingly.\n\nAfter the preparation of the data it can be easily used with the regression library to build the regression data:\n\nThis is of course the heart of the app \u2014 the visualization.\n\nSince the regression curve always has to be calculated from the change in data I modularized it in an own function:\n\nThe rest of the Plot rendering is:\n\nNote: This return statement can/should be modularized as well, since it is not that clear from the start what it does. (Just realized this when writing this article :D)\n\nAs can be seen from the import statement\n\nThese are all react-vis components, which I have configured and adapted to my needs.\n\nKey for rendering the Scatterplot or MarkSeries is this:\n\nThe is the prepared open source data passed down from the App.js component, is used for the Crosshair, and the allows smooth movements\n\nNow you have witnessed how easy it is to get going with visualizations in React. I encourage you to try it out and build your own application with it, since it can\u2019t really be any easier.\n\nI have also started to understand that many machine learning implementations are NOT restricted to Python. It\u2019s perfectly possible to start out with JavaScript. And this encourages me to do more with it. :)\n\nAnother important note: This is a very basic and not really sufficient example in terms of data outcome. This implementation of the linear regression is not suitable for timelines. Part of the linear regression is to find the point where the regression curve meets one axis. In this case this is simply not practical since it takes year 0 as the point of reference."
    },
    {
        "url": "https://medium.com/createdd-notes/ml-libraries-in-javascript-b2aed674d390?source=user_profile---------13----------------",
        "title": "ML libraries in JavaScript \u2013 Createdd Notes \u2013",
        "text": "You come from a JavaScript background and don\u2019t want to go through all the Python related setup to get going with some machine learning? Check out libraries for JavaScript, there are a few!"
    },
    {
        "url": "https://medium.com/createdd-notes/online-text-summarizers-2017-3c80e4b2862c?source=user_profile---------14----------------",
        "title": "Online Text Summarizers 2017 \u2013 Createdd Notes \u2013",
        "text": "The project is under development according to the homepage.\n\nI assume that the core algorithm is similar to the one used in SMMRY (since there are some core and widely used libraries)\n\nThis tool is a little bit more sophisticated then the previous systems. Here you can choose to add additional criteria like:\n\nPossibility to set to output to a certain number of sentences. Core algorithm is assumable similar to the previous mentioned websites."
    },
    {
        "url": "https://medium.com/createdd-notes/make-a-difference-a-reminder-54b5a5403294?source=user_profile---------15----------------",
        "title": "Make A Difference \u2014 A Reminder \u2013 Createdd Notes \u2013",
        "text": "What is the secret to achieving goals? How do you put it down so everyday you know if you are going in the right direction of success? Is it your genetics, is it your potential?\n\nWhen it comes down to it, success has nothing to do with potential. It is all about the perseverance in somebody, that will override any endeavor. If you throw shit against the wall eventually something will stick.\n\nGuys who have this potential or don\u2019t have this potential. That shit dies. What continues to last forever is the perseverance to always show up. That\u2019s what champions do. Every single Champion is the same as every ordinary person. The only differential is they show up to the event every single day.\n\nThey see failure as a learning curve and welcome it. You will learn more from failure than you ever could from success. So showing up getting knocked on your ass finding the intestinal fortitude to stand back up and face that endeavor is going to be the overriding factor that makes the difference.\n\nHow do you know when you are doing those things?\n\nThe small things in life add up to those big monumental things. When I say small things, I mean the character building blocks that your name means something. You hold value to your name. When you drop trash on the ground you pick it back up because it is your responsibility you hold value to yourself.\n\nWhen you shake someones hand you look them in the eye and give them a firm handshake because you are here for a purpose. Everything that you do, you do it to the best of your ability. It doesn\u2019t matter what you are doing. It is the fact that you are doing it, so therefore it means something to you. That\u2019s going to build a legacy.\n\nYou know footprints behind you, that are left motivation for someone to follow. Legacy is built daily. Through the character, willpower, code of conduct within somebody. That\u2019s the perseverance of showing up every single day.\n\nThat will always achieve the goal. It doesn\u2019t matter what you are born with, your potential, how much of a silver spoon or money you have.\n\nAll that can be attained if you\u2019re willing to risk failure for success."
    },
    {
        "url": "https://medium.com/createdd-notes/quick-reminder-on-cognitive-biases-4f51af1e35b6?source=user_profile---------16----------------",
        "title": "Quick reminder on Cognitive Biases \u2013 Createdd Notes \u2013",
        "text": "Two of the most famous people talking about human misjudgment are Charlie Munger and Warren Buffett. The Vice Chairman and Chairman of Berkshire Hathaway both have talked about their efforts of overcoming cognitive fallacies in order to make decisions that yield great investments and made them some of the richest men in history.\n\nRemember that even things we are completely unaware of influence our behavior. Conscious and subconscious exposure to an idea \u201cprimes\u201d us to think about an associated idea. When we have been talking about food for many hours we are more likely to act \u201cfoodrelated\u201d.\n\nA ver general rule for the brain: Things that are easier to compute, more familiar, or easier to read seem more true than things that require hard thought, are novel, or are hard to see. Repeating wrong statements over and over makes them very likely to believe.\n\nThe human brains strives for coherence. This is very necessary to survive. We have to \u201cconnect the dots\u201d to make sense of the world. But often this leads to conclusions that have no valid base. They merely make sense to our story \u2014 \u201cit has to be that way\u201d. They most common mistake is to confuse causation with correlation. Just because similar things happen in similar places does not mean one causes the other.\n\nThis behavior is deeply rooted into our past. Humans do more of things that they like and do less of things they don\u2019t like. This is very simply, but also very strong. It\u2019s so obvious that many people neglect it.\n\nIs the tendency to like or dislike everything about a person \u2014 including things you have not observed. Humans let information based on impressions and intuitions cloud there judgment. Not only is the overall decision biased, but also finding further information is anchored to the first information and therefore will be experienced differently.\n\nHumans are heavily rely on the first piece of information they get. Sales negotiations evolve around the first price that was made. Plausible information is even referenced when there is completely no reason to use it. (Tested in questions about scaling objects).\n\nPersonally my favorite one. The easier information is to retrieve the more important we qualify it. And emotional experience enhances the effect. People that got robbed estimate the probabilities of robberies significantly higher than non-robbed people. Smokers often denial the threat of cancer with a personal example reference of somebody, who did not get cancer and smoked a lot.\n\nAnother massive one. The tendency to search for and find confirming evidence for a belief while overlooking counter examples. An amazing example for that is the discussion about climate change. It is incredible hard to have intelligent conversations about the topic, because each party only looks for evidence supporting their position.\n\nThe chances of adopting a belief increases with the amount of other people holding the belief. It is the engine of groupthink and causes unproductive meetings."
    },
    {
        "url": "https://medium.com/createdd-notes/5-practical-tips-for-my-time-management-2ea54a7f343f?source=user_profile---------17----------------",
        "title": "5 practical tips for my time management \u2013 Createdd Notes \u2013",
        "text": "This is always the most important step. Try to optimize as early and often as possible. There is no optimal solution for time management because your day and routines are always changing and evolving.\n\nRoutines are the key for any success. Therefore I try to get into a routine and then keep improving it until I am at an efficient level.\n\nNote that this is subjective. Your improvements have to work for you and not someone else. Hence take time to revisit your progress and past experience.\n\nI want to start with work because most people are dependent on income and therefore naturally have to weigh work as very important.\n\nIt is key to know your worth in the company you are working in. Identify your core value for the firm and build around it. In case you are a software developer, focus on your code. Are you a project manager? Focus on the process around projects. It\u2019s nice to provide additional value for the company, but always make sure your core competence is covered.\n\nAgain, try to optimize as much as possible. When you are faster and better in you job chances are high your employer likes your changes. Try to improve all the time. Revisit past process, change and build up from it.\n\nFor me university is additional knowledge. Unfortunately in Austria many universities require physical attendance, which is often good for your learnings, but can be too much if you have many other things to do. Therefore I invest more time at the start of a semester to plan everything accordingly.\n\nAs a practical example this can be to merely being physically present in each class but working on other things. P Preparing only for the exam is most of the time sufficient. I stick to basic literature with principles. All in-depth books are great but not necessary to get through a course.\n\nNow learning is the most important part of all your activities. It separates you from the crowd. Allows you to step out of average and ultimately enjoy life much more. I try to spend as much free time as possible on that. This is pleasure time. While others enjoying entertainment in movies I enjoy learning new things. Not only will I be able to combine it with established knowledge, but also acts as a gateway for further improvements.\n\nSince private learning is the most flexible of all your areas, I fit it in my schedule whenever possible. This can mean, 1 hour before your class starts, lunch breaks or right before you go to bed.\n\nHowever, with this flexibility comes temptation. Be sure to remind yourself how important and interesting your desired learning material is in order to stay motivated and avoid distracting consumption.\n\nI try to incorporate as much real life as possible in line with my learning goals. For example when I started to code I tried to surround myself with programmers, contributing to open source and applying for a software engineer job. In addition to that comes my writing. I try to document as much as possible and aim for publishing it. Not only does this improve my learning, but also gives me credibility.\n\nI always schedule 2\u20133 times of sports activity in my week. Currently this is 2 times strength training and 1 yoga session. I love sport and therefore force myself to not overdo it. I consider this the bare minimum. As I am working as a developer and sitting at university and learning the whole day, my body needs movement.\n\nI could really write a book about why sport is so incredibly important for a healthy happy life, but let\u2019s focus on the most important thing here: balance. Sport balances all your sitting and thinking with movement. It allows you to give you the extra ability to see everything different and use your body to the best possible.\n\nEverything else falls into the category \u201cothers\u201d. This is the hard truth. Everything else I schedule behind behind my main goals. This can be very unrewarding and unsatisfying, but it is necessary since every day has only 24 hours and my body is just a human body as everybody elses.\n\nEspecially socializing, friends, relationships, family often come too short. That\u2019s why I try to fit them into breaks. Whenever I don\u2019t need to think hard or focus deliberately on tasks I get some socializing in. This can be a phone/video call, Whatsapp text, or a meeting scheduled for the break like lunch or dinner.\n\nI will keep this schedule for the next 6 months and review it\u2019s fruits afterwards. In the time of writing I expect it to be a little bit too much pressure due to some deadlines but I am happy to push my boundaries. I already see the lack of \u201cnon-thinking time\u201d or \u201crelaxation time\u201d to be a problem for the future. Especially when exams are coming I see the lack of breaks risky for achieving all goals. It will be a great experience to see how I react to the rise in pressure and obligations.\n\nThe reason why I try to push the limits as much as possible is because I fortunately was able to experience great achievements in the past. It is really true: If you want to have results like nobody else has you have to do things differently than most people."
    },
    {
        "url": "https://medium.com/createdd-notes/introduction-to-natural-language-processing-with-python-294988dbae56?source=user_profile---------18----------------",
        "title": "Introduction to Natural Language Processing with Python",
        "text": "A typical classification workflow consists of testing data using numerical attributes, training the model with data and at the end test the model with other test data.\n\nTo apply any machine learning we need data. The data will be a set of articles.\n\nIn those articles a certain theme will be identified. Those themes will be assigned to the new articles.\n\nFor a new article the model will be used and applies a corresponding theme.\n\nIn this example I am going to get the paragraphs of an article from a ruling of the European Court of Justice.\n\nI will display the most important paragraphs with the abstract extraction method.\n\nAnd classify the articles with the K-Means technique."
    },
    {
        "url": "https://medium.com/createdd-notes/introducing-data-visualization-in-python-f9682689b2e1?source=user_profile---------19----------------",
        "title": "Introducing Data Visualization in Python \u2013 Createdd Notes \u2013",
        "text": "Histograms help you understand the distribution of a numeric value in a way that you cannot with mean or median alone."
    },
    {
        "url": "https://medium.freecodecamp.org/chart-the-stock-market-with-react-redux-react-vis-and-socket-io-18caf312693c?source=user_profile---------20----------------",
        "title": "How I built an app that follows the Stock Market for a challenge.",
        "text": "How I built an app that follows the Stock Market for a freeCodeCamp challenge.\n\nIt looks like this:\n\nFor this particular challenge, I had to build an app that would allow monitoring of various stocks. You can read more about the full challenge here . Now let\u2019s get started.\n\nI was working on an app from the FreeCodeCamp curriculum , and thought others might find it interesting. In this article, you can read the full documentation for the building process. Enjoy!\n\nWhen I made my last full-stack app, I learned that starting with the back end can cause some issues when you are working on the front end later on. So this time, I decided to start with the front end and finish with the back end.\n\nI going to highlight the key cornerstones \u2014 this isn\u2019t a step-by-step tutorial.\n\nFor this project, I wanted to use this boilerplate because I have used it many times before but never on a full-stack project. Although it has some limitations with the pre-configured structure, the benefits outweigh the problems by a mile.\n\nBasically it provides an environment that:\n\nPretty early on, I had to eject the configuration ( = opening the environment configuration for changes) to modify the WebPack config.\n\nThe problem was that I wanted to add jQuery for Materializecss \u2014 and there were always issues.\n\nHere are some solutions:\n\nThis time, I wanted to use react-vis for visualizing the chart. It is a visualization library based on D3 and developed by Uber. To summarize and quote their docs:\n\nSome practical issues I came across and solved were:\n\nAt this point the app was already pretty nice. Now I had to check the last User Story, which displays real-life changes using a \u201cweb socket\u201d back end.\n\nFor the data, I used the open API from Quandl.\n\nSimply set up the mLab account and create a collection for the new app. Make a mongoose model to simplify interactions with the database, such as this one:\n\nThen connect the express server to the mLab.\n\nTo solve the warning about the deprecated mongoose open connection, use openURI.\n\nFor more, see here.\n\nSet up a route so that, on default, the production build index.html is consumed. Set up another route to check the database for its content and return it in the response.\n\nUse the Socket docs to set up listeners to:\n\nMake sure to integrate the listener function with the mongoose model to harness the power of MongoDB.\n\nOn a side note \u2014 because I spent literally one week on this issue:\n\nUse to send the message to ALL sockets!\n\nSee more here.\n\nThe \u201cproblem\u201d you have to overcome here is to render the components accordingly to the emitted actions of the socket.\n\nFor these configurations, it\u2019s key to handle the problem in the component itself and in the ducks (Redux files).\n\nI solved it by wiring up the container component with a socket.io client and listening for changes. I did this with the lifecycle. Every time a message is emitted by the socket, the component consults the database by dispatching actions to the Redux files.\n\nIn the Redux files, I fetched the data from the database and compared it with the current store of the application. Depending on this comparison, the app fetches all data again from the Quandl service. This way, every new socket client can check for themselves and always has the most up-to-date data.\n\nPlease note: I am not sure if this is best practice for a Redux/react application, since I handle much logic in the async action. Feel free to point out mistakes or misunderstood concepts! :)\n\nFor the deployment to Heroku it\u2019s important:"
    },
    {
        "url": "https://medium.com/@ddcreationstudi/introducing-relay-classic-b648e6f14d9c?source=user_profile---------21----------------",
        "title": "Introducing Relay (Classic) \u2013 Daniel Deutsch \u2013",
        "text": "To make a request to a server a query has to be sent. Data can be accessed by the identifier of an item ( ) or by properties of a certain user ( object).\n\nContainers are high-order components. They check if the data is available and update the component when the required data has been updated.\n\nFragments allow to compose components to queries. The are used by containers to define its own data requirements by creating a list of fragments (Note, that container can also use fragments defined by other containers!).\n\nConnections are relations between models. Relations between models or nodes are called \u2018edges\u2019 in Relay.\n\nModifying or deleting data in the store is called mutation. Mutations consist of two steps: writing data to the store and reading all changed data from the store.\n\nRelay employs a client-side cache, which means that whenever a mutation is sent to the server, Relay needs to know how to update the cache with the mutation query result. Hence it\u2019s necessary to add mutation types to the array.\n\nThose types can be:\n\nThe new API offers \u201ccompat mode\u201d (which allows to adopt an existing Relay app into Relay Modern). It:"
    },
    {
        "url": "https://medium.com/createdd-notes/programming-the-pragmatic-approach-e4c46896383?source=user_profile---------22----------------",
        "title": "Programming \u2014 the pragmatic approach \u2013 Createdd Notes \u2013",
        "text": "There are already many summaries of this book. But the concepts are important and worth repeating. At the end you will find a list with other summaries, in case you want to read other opinions as well.\n\nThe book divides itself into the following:\n\nBefore going into it\u2019s concepts I would like to revisit it\u2019s definition and quote Wikipedia:\n\nIn the first chapter of the book general concepts and approaches are described, like\n\nAlways stay as DRY as possible (don\u2019t repeat yourself). Avoid duplicating code, information or documentation. Every piece of knowledge should be a single, unambiguous, authoritative representation within a system.\n\nFollow the principle of orthogonality. Set a small set of primitive constructs, which can be combined in a small number of ways. It allows to:\n\nUse tracer bullets and prototyping to evaluate an environment and adapt it\u2019s tools accordingly. Whereas tracer bullets (can be algorithms, techniques, languages, or libraries) should penetrate a bigger area, prototyping provides great feedback when exploring a more focused area of the project (can be new features in an existing system, contents of external data/tools, user interface design).\n\nRegarding tools stick to powerful basics. Use GUIs wisely. They might be easier to start with but are limited. Plain text is always on top in terms of speed and opportunity. Choose one editor that covers the basics (configurable, extensible, syntax highlighting, etc.) and always use source/version control.\n\nAim to write code, that writes code (for example uses JSX).\n\nDon\u2019t overestimate yourself. Nobody alone writes perfect code. Create assertions where they are absolutely necessary. Exceptions should only be used for exceptional problems.\n\nNever sacrifice the bigger picture for specialization. Remind yourself of the big picture whenever possible."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/introducing-typescript-with-a-section-on-jsx-5bb21e908446?source=user_profile---------23----------------",
        "title": "Introducing TypeScript (with a section on JSX) \u2013 Daniel Deutsch \u2013",
        "text": "Types are annotated using syntax. (For example )\n\nInterfaces are the core way in TypeScript to compose multiple type annotations into a single named annotation.\n\nIn languages like C# and Java, one of the main tools in the toolbox for creating reusable components is generics, that is, being able to create a component that can work over a variety of types rather than a single one.\n\nWhile using any is certainly generic in that will accept any and all types for the type of arg, we actually are losing the information about what that type was when the function returns.\n\nT allows us to capture the type the user provides (e.g. number), so that we can use that information later.\n\nis a pattern in JavaScript where you take two objects and create a new one that has the features of both these objects.\n\nIntersections allow to define those objects.\n\nFiles that contain JSX have to end with instead of only to be transpiled correctly.\n\nDepending on the project setup you can enable three JSX modes: preserve, react, and react-native.\n\nThe fact that React renders strings or classes is essential for TypeScript.\n\nIntrinsic elements can be checked with interfaces, like\n\nWhereas value based elements are identified in their own scope, like\n\nChecking on attribute types on intrinsic elements is:\n\nWhereas attributes on value based elements are checked like:"
    },
    {
        "url": "https://medium.com/createdd-notes/understanding-machine-learning-92f13d03d309?source=user_profile---------24----------------",
        "title": "Understanding Machine Learning \u2013 Createdd Notes \u2013",
        "text": "ML finds patterns in data and uses them to predict the future.\n\nNow it\u2019s easy to find patterns. But it is not easy to find patterns that are correct. Increasing the size of data allows to predict outcome that is more and more correct.\n\nCommon programming languages used for ML are:"
    },
    {
        "url": "https://medium.com/createdd-notes/easy-javascript-machine-learning-algorithm-a056f9acc9b6?source=user_profile---------25----------------",
        "title": "Easy JavaScript Machine Learning algorithm \u2013 Createdd Notes \u2013",
        "text": "In this article I am simply going to build something similiar to that from Burak Kanber\u2019s article \u201cMachine Learning: Introduction to Genetic Algorithms\u201d\n\nIn his article he not only explains fundamentals very well but also uses his knowledge in a JavaScript example. I was very enlighted and amazed. Visit his homepage for more great stuff. :)\n\nWe are programing an algorithm in Javascript that reproduces the word \u201cJavaScript\u201d.\n\nThis is an example for understanding basic concepts. It is very basic and even contrived, since the algorithm itself contains the desired outcome (the typed word).\n\nThere are many possible outcomes for building the desired string. Assuming a certain length for the solution, like 10 characters long, will reduce the amount of candidates.\n\nThese would all be possible candidates for a solution regarding their length, but obviously only the last one is correct.\n\nA cost function helps us to minimize the cost (the difference to the desired outcome).\n\nTo get to our desired goal to reproduce the string we are aiming for a cost of 0.\n\nIn this basic example it is safe to assume that the algorithm can be stopped after it had reached the cost of 0. Be aware that other, more complex problems might need to run a certain time and evaluate their own minimized result.\n\nNext we need to combine and compare the results.\n\ncan be cut in half and afterwards combining one string with the other like:\n\nThe result now shows one correct string and one that is not.\n\nIn order to avoid in-breeding we need to alter the candidates after combining.\n\nThis situation will never yield improving results, since they are the candidates are exactely the same.\n\nWe need to alter at least one of them a little to evolve. For example \u201cJaeaScript\u201d would fit well to continue a successful evolution.\n\nThinking in object oriented programming we can lay out the following:\n\nWe have a candidate class with\n\nWe will choose a group size and evolve the candidates inside. The group has to experience different stages. In those stages we need to\n\nFirst we set a class with a string as constructor and set a method for building a random string:\n\nNext we need to add the cost function, which finds the differences between the ASCII code and squares them.\n\nAfter that we build the combine function, which takes a candidate as an argument, finds the middle and returns an array of two new children.\n\nNext we need to alter a chracter from the string. Therefore we pick a random position in the string and randomly increase the character by 1 or -1. Afterwards we replace the old string with the new string.\n\nNext we need to build a group of candidates. The class constractor takes the target string and the size of the group as arguments and fills it with random candidates.\n\nAfter that we need to sort the Candidates by their cost score.\n\nThen we need to write a simple display function to actually build some HTML on the page. Basically we want to display the stage we are in and all the current candidates of the group.\n\nThe next step is to actually create a stage. Therefore we calculate the costs, sort the candidates, display the result, combine the best results and mutate the result. Then repeat the cycle. We set the break with an if-statement when the string of member equals our goal.\n\nLast thing we have to do is to form a new group with the desired goal of the string and the size of the group as arguments. Then call the stage function and kickstart the calculations.\n\nAs you can see I wasn\u2019t changing much in the code. Simply because I think it\u2019s straight forward and understandable. The whole algorithm gets his concept across and offers a great entry into some basics of machine learning.\n\nIn case of any questions, feel free to ask!\n\nThanks for reading my article! Feel free to leave any feedback!"
    },
    {
        "url": "https://medium.com/@ddcreationstudi/learnings-from-my-first-full-stack-app-in-javascript-fbb5656af39f?source=user_profile---------26----------------",
        "title": "Learnings from my first full-stack app in JavaScript",
        "text": "Again, especially for beginners of interest, my overall time spent coding from May till now (mid August):\n\nRemember that this is only a very small scope of my efforts.\n\nAlone from the Github Repo you can see, that I have easily spent more than 200 hours on this application. Here you also have to take into account that I was learning a lot on the way \u2014 so I actually was improving a lot and becoming much faster with the time.\n\nI was also doing other tutorials and projects, watching videos and writing articles on the side to understand concepts better.\n\nMaybe this sounds a lot to you, maybe it sounds not much for you. Doesn\u2019t matter. Key thing here is to see how things can be quantified in the development area.\n\nSpending more than 250 hours coding (+ side projects and code at work) in 4 months leads to approximately 60 hours per month and to 15 hours per week.\n\nSo when you want to embark on this journey and you see people spending months on projects, keep those numbers in mind.\n\nSee what it takes to progress in an area you had no idea or knowledge of. These underestimated 15 hours are equal to a part time job. So if you think that progress is slow and poor, realize what it takes.\n\nI am no genius, but certainly not dumb. (At least according to some tests :D)\n\nSee that consistency is everything. You can\u2019t do a project like this on one weekend. Make yourself aware how long the journey is. Realize that it is hard and remind yourself where you are going. Constantly!\n\nAnalyzing the app a little bit in depth you will realize it is pretty unfinished. I myself have openend issues and see many things to improve.\n\nNow why is that?\n\nFor me, each project has it\u2019s own key learnings. In this project it was the connection of frontend and backend and using Redux in React. To keep my eyes on the learning path I force myself to tackle the next app. Reuse the things I have learned and be able to see new problems in a different light.\n\nContinuing this app and powering it up with more features, more functionality and tests would take a lot of time but diminish my learning results. It\u2019s open source and always available. If I want to continue my work I can do it easily.\n\nThanks for reading my article! Feel free to leave any feedback!"
    },
    {
        "url": "https://medium.freecodecamp.org/building-the-free-codecamp-voting-app-1a6fdce1f4a8?source=user_profile---------27----------------",
        "title": "How to build the Voting App project \u2014 an in-depth tutorial",
        "text": "How to build the freeCodeCamp Voting App project \u2014 an in-depth tutorial\n\nalso known as the \u201cMERN-Stack\u201d.\n\nIn this tutorial, will use:\n\nI didn\u2019t find any tutorials or examples that broke this challenge down with up-to-date tools. So I decided to document my process of building it.\n\nThe voting app challenge on freeCodeCamp was the first freeCodeCamp project in the curriculum that struck me as really hard. I just couldn\u2019t do it as easily as all the other challenges. So much knowledge in of so many concepts is necessary to build it.\n\nI will describe the process of building the voting app for the freeCodeCamp challenge.\n\nThis is not an optimized example for building the application. I am open for feedback of any kind. I am still a beginner and also left some things open.\n\nThis is not designed as a tutorial! It\u2019s simply a documentation I wrote while building the app.\n\nI will divide this article into sections of back-end, front-end, data visualization and the deployment process. The project will be available as open source code on GitHub. That is where you can follow up with commits and the end result.\n\nFirst I will set up my environment:\n\nHere is my commit on GitHub after the setup.\n\nFor me, the back-end is most difficult. So that\u2019s where I\u2019ll start.\n\nHere\u2019s my commit on GitHub after this setup.\n\nRevisit the User stories and lay out your routes accordingly.\n\nAs an unauthenticated user I want to:\n\nAs an authenticated user I want to\n\nWhen setting up Schemas think about how you want to structure the documents that you will store in the database. In this example we need to store the user for the authentication process and polls with answers.\n\nFor polls we need:\n\nBe aware that MLab creates \u201cSystem Collections.\u201d They throw \u201cduplicate key error index dup key: { : null }\u201d error in postman, when creating new polls. Until now I haven\u2019t found a solution but deleting all collections allows us to start again.\n\nBe Sure To Read the Docs if you are stuck. This part is pretty hard when you haven\u2019t done a lot with mongoose and MongoDB!\n\nHere\u2019s what my commits looked like on Github after these steps.\n\nI want to use the twitter sign-on as an OAuth provider to authenticate. It provides better user experience and I also got to explore OAuth.\n\nOAuth is a standard protocol that allows users to authorize API access to web and desktop or mobile applications. Once access has been granted, the authorized application can utilize the API on behalf of the user.\n\nOf course I found the great article on how to set up the authentication process in Nodejs. After I failed implement it properly in my app and it took me a whole day, I decided to dive straight into the documentation of passport!\n\nI love the quote they put up there:\n\n\u201cDespite the complexities involved in authentication, code does not have to be complicated.\u201d\n\n\u2b50 Again, as a reminder: Read the Documentation!\n\nCheck out my commit on Github after these steps.\n\nAfter that, connect the authentication process to your database\n\n\u2b50 Tip: Use for your callback and testing always instead of , since it solves a lot of problems, that might occur using passport-twitter. \ud83d\ude09\n\nThe implementation can look like this:\n\nAfter that your authentication and authorization with Twitter is done.\n\nHere\u2019s what my commits looked like on Github after these steps.\n\nThe next step is to authenticate locally. There is actually not much to it, since we have already set up the environment.\n\nI had a main issue which I was only able to resolve after many hours of searching. Here is the example from the docs:\n\nPassing in the authentication in the callback function provided enough flexibility for displaying errors. But it\u2019s very important to create the session explicitly with !\n\nI spent so many hours on an Error that I want to display it here: MongooseError: Cast to ObjectId failed for value \u201cfavicon.ico\u201d at path \u201c_id\u201d\n\nI solved it through checking all middleware which had a major error, and routes. It turned out that setting a route to (\u2018/:pID\u2019) is not good when working in development.\n\nCheck out my commit on GitHub after the back-end setup.\n\nOf course at this point the back-end is not perfect. But it\u2019s stable enough to go to the next step, the front-end.\n\nFirst of all think about what you want to create. Draw out some sketches to visualize what you want to build.\n\nThen consider appropriate frameworks. I will choose React.js and the state management library Redux. The size of this application does not necessarily require the use of Redux.\n\nI want to build it as a single page experience. I want to have scalability and I like to practice the use of Redux. So, it\u2019s a good fit.\n\nStart planning everything out thinking in React.\n\nIt\u2019s important to realize that Babel and Webpack are not too complicated to set it up yourself. There are so many tutorials for both that you can do it easily yourself.\n\nFirst I want to structure my front-end without the back-end to connect the whole front-end with the back-end at the end. This is because right now I don\u2019t know how my Redux implementation will look. So progressively connecting to the back-end wouldn\u2019t be efficient.\n\nHere\u2019s what my commits looked like on Github after these steps.\n\nI sketched everything out on a paper and came to the conclusion that I need to build 14 components:\n\nThat layout was for the start and should provide an overview. It is very natural to adapt the component structure when the application is evolving.\n\nTip: For 100vh on your main content use this inline style on a div. It fits perfectly into the Materialize flexbox:\n\nCheck out my commit on GitHub after the components are built and styled\n\nHere is a list of painful learnings I had to undergo throughout this process:\n\nThe Principles of Redux are:\n\nKeep in mind, that local state doesn\u2019t need to take part in Redux when it\u2019s state isn\u2019t used by other components.\n\nNow that State is available through Redux, it\u2019s time to create the event handlers and render everything properly. Now you should validate your your as well.\n\nFor displaying the results I chose between:\n\nAfter skimming all docs and trying a few things out I ended up choosing React-Google-Charts. Google provides many options and the React wrapper makes it easy to implement in a React application.\n\nWith the React Wrapper this step was super easy and fast.\n\nAs this was my first real full-stack app, connecting the front-end and back-end was a mystery to me. I found a good answer to my question on Stack Overflow.\n\nTo summarize and quote the answer of Stijn:\n\nTo read more of his comments click here.\n\nIn the end I went with the catch-all solution: See in my routes.js file.\n\nIt was easy and fast to implement and covered the basic problems.\n\nTo understand that, the best way is to take a look at my package.json file.\n\nThe script builds the files on the client and server side.\n\nThe script serves everything in a development environment and (hot) reloading. Everything is as fast and smooth as possible, when changing the codebase.\n\nThe script actually starts the back-end server, which also consumes the built and bundled front-end HTML, CSS, JavaScript, presenting the whole application.\n\nFor deploying the app, Heroku once again has proven to be the way to go.\n\nUsing the Heroku CLI, the command helps a lot. I always had trouble setting up my app on the platform. But after solving all the errors the logs show, it becomes very easy.\n\nAs you can see my documentation for this article gets worse and worse with the progress of the app. This is due to the fact that I got completely overwhelmed with Redux. I did other projects on the side and wasn\u2019t able to keep track.\n\nBut don\u2019t worry! I tried to name my commits as clear as possible. So you can traverse all commits for details in my Repository. See Commits here.\n\nIf you have questions feel free to ask :)\n\nMany, many thanks to Edo Rivai, who gave very valuable tips along the way. :)\n\nThanks for reading my article! Feel free to leave any feedback!"
    },
    {
        "url": "https://medium.freecodecamp.org/publishing-an-organization-homepage-on-github-pages-347dbd700f4e?source=user_profile---------28----------------",
        "title": "Publishing an organization homepage on GitHub Pages",
        "text": "I am organizing a local group meetup of FreeCodeCamp called FreeCodeCamp Vienna. Months ago we decided to create a simple homepage to represent the group and it\u2019s progress online. But we never seemed to find the time to do it.\n\nFollowing the idea \u201cbetter a quick homepage than no homepage at all\u201d I decided to create one and publish it on GitHub Pages. It allows us to host our static page and also serves as a perfect example for how easy it is to publish something online.\n\nWhen publishing to GitHub Pages choosing the right repository name is crucial.\n\nThis page from GitHub explains it perfectly:\n\nYou need to name the repository exactly like the organization with \u201c.github.io\u201d at the end:\n\nAfter creating the repository build your homepage with HTML, CSS and JavaScript.\n\nTip: I was using CodePen during development. It is REPL (Read\u2013Eval\u2013Print Loop). This allows you to receive instant feedback from the code you are writing.\n\nTo speed up the layout process and add cool features I was using Materialize. I have used it in the past and always had been happy with the results.\n\nNext, put your files on GitHub following the instructions.\n\nBe sure to have the files on your \u201cMaster\u201d branch\n\nAnd choose the source of your GitHub Pages for the Master branch.\n\nYour settings should look like this:\n\nFollow the provided link or type your organization name with \u201c.github.io\u201d in the URL bar.\n\n\u27a1\ufe0f GitHub Repo is available here \u2b05\ufe0f\n\nThanks for reading my article! Feel free to leave any feedback!"
    },
    {
        "url": "https://medium.com/@ddcreationstudi/are-expectations-killing-your-success-31b03a77636b?source=user_profile---------29----------------",
        "title": "Are expectations killing your success? \u2013 Daniel Deutsch \u2013",
        "text": "It doesn\u2019t matter in what field you excel. Whether it\u2019s sport or programming or any endeavor in life. Often we encounter success followed by failure. How can we overcome the temporary discomfort and keep our eyes on the goal?\n\nMost of us work towards a goal we set ourselves. Accomplishing the goal sets expectations for our next achievement. And that\u2019s where we have to be careful.\n\nWe compare the previous journey to the one that\u2019s ahead. We give our actions a new frame. We already know what it\u2019s like to be on top. We develop a sense of ownership to that goal.\n\nWe start to think and act differently. We \u201cknow\u201d what had led to previous success. We start to redefine our approach to the problems without giving it all.\n\nAnd that\u2019s where we start losing. The moment we think we are entitled to something, we stop going all in.\n\nBeing entitled to something and owning something only can lead to loss. There is nothing more to win, since you already have it.\n\nYou change your mentality. You\u2019re up there. You only can look downwards. You lost the drive that was needed to get you up there.\n\nYou also stop to respect the competition, since you already own it. You stop giving credit for trying and failing. You levitate yourself in a state of superior presence."
    },
    {
        "url": "https://medium.com/developersrising/introduction-to-licensing-open-source-projects-on-github-e77062c81a70?source=user_profile---------30----------------",
        "title": "Introduction to licensing open source projects on Github",
        "text": "Before you write any code it\u2019s very beneficiary to rethink your goals for the project. Are you planning to write a small application just for yourself and feedback, or are you planning to build a large application with hundreds of contributors? The bigger your application gets, the more important your thoughts about the best suitable license are!\n\nAs a core contributor or maintainer of the project be sure to acquire knowledge about licensing yourself. Since code projects can grow extremely quick over night be sure to address licensing better sooner than later.\n\nWhen you are at a point where someone is making money with your project it is time to get some professional legal advice. Money spent in advance will help you tremendously with upcoming issues and gets you on the safe side.\n\nI hope many people know that platform, because I was really astonished when I saw it the first time.\n\nThis was the first site for the breaks down the complexity of licensing in easy understandable terms and provides an amazing overview.\n\nThe home route instantly presents the most important licenses for the average developer. Those are the\n\nMoving further on the page, they also provide a very good and precise overview over other licenses:\n\nThe simplicity and structure makes it the perfect page for a first overview.\n\nHowever, there is a reason why licenses are formulated the way they are. Wording is key and very complex in legal aspects. So always make sure to really understand each of them in depth when using. Most of the pages provide links to the original terms. Use it ;)\n\nGithub does a lot to provide as much help as possible for developers to understand the legal aspects of open source.\n\nThey provide a help page reagarding licensing your repository and even a complete open source legal guide.\n\nFirst of all:\n\nIn my experience people seem not to be aware of the following. And I am here quoting their page:\n\nAnd also check the Github terms of service, which include:\n\nAny change in licenses leads to\n\nIn short: It demands much mure legal work.\n\nSo what does that all mean? Simple: Know where you want to go with your project. Most copyright laws (depending on your country) see tight connections to publishing content. In many cases you lose a significant amount of rights after your intagible assets are made public."
    },
    {
        "url": "https://medium.com/developersrising/fetching-gtihub-with-react-and-redux-3f5dac82994c?source=user_profile---------31----------------",
        "title": "Fetching Github with React and Redux \u2013 DevelopersRising \u2013",
        "text": "I am going to build a simple app, that fetches repositories from Github by typing the name of the Github user:\n\nTo quickstart the the configuration I used the React Slingshot boilerplate by Cory House. It provides nice linting and feedback during the whole building process.\n\nFirst I started out with defining basic React Components. I used the provided structure and adapted it for a home page and an about page. For jumping across routes I also used the provided React Router features because it\u2019s simple and fast.\n\nThe next step was adding some basic styling. I wanted to use Material-UI but quickly realized that I have to dive into the framework. After some minutes with bugs, I decided to stay with MaterializeCSS, which I used in the past. It provides great documentation and simple CSS components. It\u2019s the CSS framework I enjoy working with the most.\n\nAfter that I wired up a basic Redux flow, providing a store, actions and a reducer. One way when working async in Redux is to use redux-thunk. I have choosen this way because it\u2019s fast and reliable. (I didn\u2019t want to tackle Redux-Saga, since I need more knowledge on Promises)\n\nThat\u2019s the whole magic. Returning a function instead an action. It allows to wait for an answer after a http call (or whatever call) and dispatching the action after receiving the data.\n\nThis was a little bit more complicated, since I needed to make the fetch depended on another user action. But that\u2019s why Redux is so great.\n\nThe key thing was to regulate the flow with the store in the index.js, because I wanted to subscribe to the store and only dispatch an action when a certain change in state has occured. I found the \u201chandleChange\u201d helper function as solution:\n\nNow the fetching of data was called only when the state of user changed in the store. Heureka!\n\nThen I adapted the other files accordingly:"
    },
    {
        "url": "https://medium.com/developersrising/automate-email-settings-with-javascript-aff253dc976b?source=user_profile---------32----------------",
        "title": "Automate email settings with JavaScript \u2013 DevelopersRising \u2013",
        "text": "The Meetup.com page requires me to check on/off each checkbox for an email notification of each group.\n\nI don\u2019t waste my time clicking through all my groups. Meetup.com offers an option to disable all notifications, but I want to receive updates from some selected groups. Another thing is that they have \u201cReminders\u201d, that require even more clicking with a dropdown menu. This dropdown menu can\u2019t even be handled by the console code, that I have shown in the previous article.\n\nTherefore I decided to write an automated script that does all that for me.\n\nSelenium allows to use a webdriver to go through the browser and performs actions, that a human being could also do (like clicking on elements).\n\nThe process of automating is simple:\n\nIn this example I am using the Selenium webdriver.\n\nThe setup in Node.js is pretty easy:\n\nTo get to the notifications section I simply go to their login page, send my credentials to log in and click all the way to the settings.\n\nI identify all checkboxes and dropdowns and call a function ( ) on each element.\n\nThe function actually clicks the elements and tests if the boxes are already unchecked (since we don't want to simply click everything, but rather uncheck all boxes).\n\nIf you gained something from this article let me know with a comment or heart. Make sure to follow for more :)"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/reduce-your-time-clicking-elements-on-the-web-915ed2129efa?source=user_profile---------33----------------",
        "title": "Reduce your time clicking elements on the web \u2013 Of All Things - Tech Progress \u2013",
        "text": "The fact that all webpages are or can be controlled by JavaScript provides additional opportunities for those who are capable of using it in the console.\n\nIn order to change the email notification settings for each meetup you have to click on each meetup and the uncheck each of those boxes. When I am now a member of many groups I have to go through the process many times, which offends me in some way since my time is very valueable.\n\nSo to solve that task programmatically, I identify the checkbox element in the chrome inspector:\n\nAfter that I am using the to grab those elements and store it in an array:"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/are-you-still-using-expensive-contract-structures-in-the-it-sector-3afb1a2f2af5?source=user_profile---------34----------------",
        "title": "Are you still using expensive contract structures in the IT sector?",
        "text": "As I have seen most of the contracts are written poorly, because not enough time is spend writing them. Always make sure to stay on the right side of the track and cover it with contracts!\n\nA main distinction has to be made between whether a product or a service is owed under the contract. Each one has different consequences for the contract parties. Now the problem that arises in the IT sector, is that you cannot always determine the product or service at the beginning of the cooperation.\n\nMost of the current solutions are single documents that describe the service or product as accurate as possible. Payments are stipulated on these terms.\n\nChanges in conditions or the environment forces the contracting parties to re-evaluate the terms, set up a new contract and reconcile completed payments and transactions. This is very time consuming and costs a lot. What might be remunerative for the lawyer, isn\u2019t really cost-efficient for the entrepreneur.\n\nTo minimize costs and increase overall consulting value from your lawyers try this way:\n\nThis concept follows the idea of modularization, which is already established in the programming world.\n\nWhen writing code and trying to keep it as small and sufficient as possible, incredible positive scaling effects can be achieved.\n\nIt\u2019s not different with contracts. This structure allows to keep the relationship between the parties clear and organized, but also extremely flexible.\n\nCreating single \u201csub\u201d contracts under a master agreement, results in a bigger initial setup but enables the contract parties to add, adapt or remove parts of their cooperation without the necessity to change other areas.\n\nThe real power of this structure will be visible in long-term relationships and big cooperation projects. After more than 10 years of work with a dozen projects, the legal effort for stipulating new projects will be a breeze for both parties and money spent on lawyers will be very concise and effective.\n\nCombining powerful concepts from different areas often result in exponential results. The same applies in Law and Tech. Unifying the stability of jurisdiction with the innovation of programming allows to stay on top of fast developing world."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/rate-questions-with-react-and-redux-a-baby-example-9d6d737732f4?source=user_profile---------35----------------",
        "title": "Rate Questions with React and Redux \u2014 A baby example \ud83d\udc76",
        "text": "Another small application to understand Redux and React. It feels like it\u2019s the 100th app trying to grasp Redux. But 1 month without Redux and you start at basically nothing again. I am like: \u201cYeah I have heard about that\u201d \u2014 and that\u2019s it. Action, Action Creators, Reducers, Dispatch, blabla. Too many things to understand :D So once again \u2197\ufe0f\n\nStructure the components in order to fit perfectly into a Redux application.\n\nDecide which components should take part in the Redux store. -> In this application only the questions have to be made available to all components.\n\nFind what events happen in your application for this specific state. -> In this application it is\n\nReducers are pure functions, that change state according to the action type.\n\nThe reducer function provides different switch statements on how change the state. (Make sure to never change the state itself! It should be a pure function! #immutability)\n\nFor example for adding a question:\n\nCreate a store in your index.js passing it the main reducer and wrap it around your scoreboard component in order to provide the store to the whole application.\n\nNow we want to display details to each question\n\n\u27a1\ufe0f See the commit with the implementation of the detail component on Github \u2b05\ufe0f\n\nFor smaller apps the ducks concept can help to develop a Redux application faster. Basically instead of keeping everything modular (actions, reducers, actionCreators), we can also keep them in one file to have a better overview.\n\nThis file looks like:\n\n\u27a1\ufe0f See the commit with the implementation of ducks on Github \u2b05\ufe0f\n\nThe DevTools help to develop and debug your Redux app. Check out this article for more."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/2-easy-ways-to-get-data-from-unsplash-com-in-react-b4835e0335fc?source=user_profile---------36----------------",
        "title": "2 easy ways to get data from Unsplash.com in React \u2013 Daniel Deutsch \u2013",
        "text": "To set up the basics, I use the code base from another project I did, using:\n\n\u27a1\ufe0f See the Github Repo after those steps \u2b05\ufe0f\n\nFetching can also be accomplished by one of many libraries. I will use axios, since it provides cool features like:\n\nSo the next steps are:\n\nVery easy and works well:)\n\n\u27a1\ufe0f See the Github Repo after those steps \u2b05\ufe0f\n\n\u27a1\ufe0f See the Github Repo after those steps \u2b05\ufe0f"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/summary-of-the-second-machine-age-28f5ad99c7bb?source=user_profile---------37----------------",
        "title": "Summary of \u201cThe second machine age\u201d \u2013 Of All Things - Tech Progress \u2013",
        "text": "History shows that with the development of the steam machine in 1765 the human social development started to rise very quickly This was the first machine age \u2014 it was possible for the first time to produce massive amounts of mechanical power. Now comes the second machine age, where we use computers for doing mental work. Currently we live in a world, where we experience tremendous progress in digital technologies, the changes will be very beneficial for humans but there will arise new threats as well.\n\nComputers nowadays are capable of more than just calculating numbers, they process symbols. Everything that can be reduced to the simplicity of rules (algorithms) the computer can solve. Pattern recognition is still an area where humans are much faster and better than machines. Google\u2019s car, Apple\u2019s voice assistant and the Jeopardy! computer are good examples of how capabilities increased steadily and then suddenly. The warehouse robot Baxter shows the immense advantages a robot has over mechanical human workers.\n\nMoore\u2019s law: \u201eThe complexity for minimum component costs has increased at a rate of roughly a factor of two per year.\u201c His \u201elaw\u201c was merely an observation in those days and hold up very well ever since. One factor is the amount of work people put in the development of the computer industry. The anecdote of the emperor and the chessboard full of rice shows that exponential growth leads to staggeringly big numbers. And that\u2019s what\u2019s happening right now in the machine age \u2014 we have arrived at the second half of the chessboard. But not only the power, also the range in various effected fields lead to much faster growth.\n\nDigitization is the work of turning all kinds of information and media, text, sound, photos, video, data from instruments and sensors \u2014 into the ones and zeros, the native language of computers. Digitization allows to exploit economic properties of digital information like non-rivality and close to zero marginal cost of reproduction. Now business models evolve around the fact that, information is costly to produce but cheap to reproduce (like Google search). Statistics will even more important, since the amount of input being created and analyzed increases.\n\nInnovation today is almost everything. A country\u2019s ability to improve its standard of living over time depends almost entirely on its ability to raise its output per worker.Innovation is how the productivity growth happens. Whereas the Internet provides great fun for us, compared to historical achievements it\u2019s performance is not really economically significant till now. (compared to for example electricity, internal combustion machine, etc.) Mostly innovation happens through recombining existing solutions in order to make them more valuable. Innovation is enhanced by the number of eyeballs and computers and that leads to great predictions for the future.\n\nFirst examples of AI (camera that interprets images) and digital interconnection of humans promise accelerated growth.\n\nConsidering trends and looking at previous achievements, we can see, that overall living standards have increased enormously. Just working more hours doesn\u2019t improve productivity, but organizational and business changes made through technology does. Positive correlations between business productivity and the use of IT has been found several times.\n\nThe information age with it\u2019s mostly free services and improvements provides different economics and special measurement problems. The price of null makes these services invisible in official statistics (like the GDP) but nevertheless add value to the economy. Hence GDP equals not economic growth. A way to measure would be the consumer surplus: How much would a consumer be willing to pay? Another important factor in economic measurement are intangible assets, like human capital, intellectual property, organizational capital and user-generated content.\n\nWith this new age, income is very spread. Meaning there is the way to make millions having a new idea, or just competing with machines and get paid nearly nothing. New software doesn\u2019t often needs more than a few programmers and designers. The result can be replicated and updated easily. It can be delivered to millions at almost zero cost. The best way to use new technologies is not to replace human workers with machines, but restructure processes. Jobs with routine tasks will fall and be replaced by machine workers, however non-routine jobs (mental or manual) like financial analysts or hairdresser, will held up.\n\nTechnology has supercharged the ability to leverage their talents via digitization and globalization. In winner-takes-all markets the relative performance determines the success. Writing a slightly faster code might be enough to dominate a market, whereas the 10th fastest code is completely forgotten. Like Joseph Schumpeter wrote in \u201ecreative destruction\u201c: each innovation not only creates creates new value, but also kills previous incumbents.\n\nBoth bounty and spread will grow in the future. In the result everyone will benefit, but not all benefits are the same. Thank to innovation and technology especially low-income and middle-income groups are better off today than in any previous period. Technology increases productivity and productivity increases employment. However, strong points can be made that changing working fields need an adaption for workers that cause, at least temporarily, unemployment. As long as there are unmet needs and wants in the world, unemployment is a loud warning that we simply aren\u2019t thinking hard enough about what needs to be done.\n\nEven though computers are much faster in computing certain tasks, at this time, the don\u2019t even come close to reach the complexity and speed of human brains. One thing that computers can\u2019t do is being creative and coming up with new ideas. To remain a valuable knowledge worker in the future work to improve the skills of ideation, large-frame pattern recognition, and complex communication instead of the three \u201eR\u201cs (reading, writing, arithmetic). Research also showed, that today most students only spend 9% of their time studying (reading and writing). Most of the time is used for socializing, recreating and other.\n\nFocus on education. Not only what is taught but how it is taught. Focus on Startups. Entrepreneurship stems from innovation and digitalization allows much more innovation to happen. Hence, increased efforts to boost entrepreneurship will lead to more innovation and productivity. Focus on matching employees and employers. Focus on science. And lastly, adapt taxation accordingly.\n\nAs voltaire said: \u201eWork saves a man from the three great evils: boredom, vice, and need\u201c. So the most important thing to focus on is to keep people working. Always adapt to new technologies as soon as possible and find meaningful work for people.\n\nThe two most important changes we will have are: The creation of true machine intelligence and the connecting all humans over digital networks. Risks will increase, but so do opportunities to solve and handle them. The true singularity like in \u201eMatrix\u201c is not yet to come. Technology brings opportunities. Technology is not destiny. We shape our destiny.\n\nThe Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies\n\nIf you gained something from this article let me know with a comment or heart. Make sure to follow for more :)"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/components-components-components-react-redux-a-reminder-7ca7cbc4f2ae?source=user_profile---------38----------------",
        "title": "Components, Components, Components \u2014 React/Redux (A reminder)",
        "text": "Planning your application and components before you start writing code will help you save a lot of time later on. With all the possible features React components can have, they clutter very fast and become soon not manageable. Dividing the purpose and functionality of your components will significantly improve your workflow when your app starts to grow.\n\nMake sure to read the article from Dan Abramov, where he explains the key ideas between those components in detail.\n\nPresentational ComponentsContainer ComponentsPurposeHow things look (markup, styles)How things work (data fetching, state updates)Aware of ReduxNoYesTo read dataRead data from propsSubscribe to Redux stateTo change dataInvoke callbacks from propsDispatch Redux actionsAre writtenBy handUsually generated by React Redux\n\nSee this article for a great example."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/why-you-should-keep-coding-49687cb2d176?source=user_profile---------39----------------",
        "title": "-why you should keep coding- \u2013 Daniel Deutsch \u2013",
        "text": "Exactly 1 year ago I decided to quit my job and started to learn to code. I knew that it was right. I never looked back. The start was easy. A lot of motivation and endless ideas. So far it was a great experience just to realize what it means to pursue a dream on the side. Studying, working and just being exposed to all the great things this world has to offer makes it freakin\u2019 hard. What I\u2019ve learned so far:\n\nBoy I had no idea what that meant. But I sure do now. Read it again. Ask yourself what it means for your life.\n\nI can tell you what it meant for me: It sure is a lonely road. When you are working 20 or 40 hours a week. Still studying, having a relationship, a family or contributing regularly to a community, you will have \u201cno time\u201d. You are exhausted and want to relax. Your body wants everything except doing what\u2019s necessary to achieve your goal. You have certain habits. And those keep you from getting your goal.\n\nAsk yourself: When you come home after an 8 hour day, are you sitting down and start working on that dream of yours? No? Why not? Is it a thing or just an excuse? Most of the time it\u2019s an excuse.\n\nBe prepared to disappoint friends and family. Because you don\u2019t have the time to go out for another drink. You don\u2019t have time to go to another birthday party. You have a dream. You have a goal. And for that it\u2019s necessary to take cuts. And it\u2019s amazing what happens afterwards. They start doubting you. As soon as you start to focus on yourself you\u2019re losing their support. Many times I was enchanted when that happened. It doesn\u2019t bothered me a bit, since my dream is bigger than their crying, but it was mesmerizing to see it happen each time.\n\nThat\u2019s especially important for family. All of them have their own vision for you. Mostly very conservative. Maybe you\u2019re excelling in a certain field. Maybe you are already successful. Maybe you lose everywhere. Maybe everything you touch turns to shit. Doesn\u2019t matter. Be sure that your new dream and change of the status quo will bother people.\n\nThis goes even more for coding. You WILL spend a lot of time in front of your computer. Doesn\u2019t matter how many classes you take, hackathons or pair programming you do. Coding is learnt where it\u2019s done \u2014 on your seat in front of a display doing a lot of think in your own head.\n\nSo get comfortable being alone. :)\n\nThis is true for nearly any endeavor in life, but goes very well for coding. OMG I freaking love it when I\u2019m sitting hours for 10 lines of code and when I\u2019m finished everything breaks."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/5-steps-to-build-a-rest-api-in-node-js-with-mongodb-e1f2113a39bd?source=user_profile---------40----------------",
        "title": "5 Steps to build a REST API in Node.js with MongoDB",
        "text": "REST APIs handle the server side of the web application. That means that the backend is built once and can provide content or data for frontend, mobile, or other server-side apps. A great example is the google calendar API.\n\nREST stands for Representational State Transfer and is a way how a web server should respond to requests. This allows to not only read data, but also do different things like updating, deleting or creating data.\n\nI\u2019m going to build an API that allows to create questions and create, edit, vote and delete answers.\n\nFor programming the API it is key to structure the routes properly.\n\nTherefore we need to be able to program routes to:\n\nIn this example here I will use\n\nFollowing packages are used\n\nThe tutorial will be structured in:\n\nStructure what kind of data has to be stored in a database and what type of relation the data has. I will use Mongoose to set the data handling for MongoDB. Schemas allow to define the data in JSON format.\n\nIn this case this is best implemented using only question objects with answer properties. However, bare in mind, that documents have a storage limit and therefore the amount of answers is limited."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/starting-with-authentication-a-tutorial-with-node-js-and-mongodb-25d524ca0359?source=user_profile---------41----------------",
        "title": "Starting with Authentication (A tutorial with Node.js and MongoDB)",
        "text": "There is much more to add but logging out and destroying the session is important for each authentication system! That\u2019s why I\u2019ve included it here as well.\n\nMiddleware runs after a request is received, but before a response is sent back. In this example the body-parser package is used as middleware. It converts incoming requests into a format that is easy to use for a JS program.\n\nMiddleware functions can be chained after each other and fit into the request/response cycle of the application. When writing custom middleware, always has to be called at the end of that middleware to move to the next one in the cycle.\n\nMiddleware can be used in many cases in this example, however, for simplicity reasons, I just reference an example to give an idea.\n\nExample: Creating middleware that requires a login for certain pages.\n\nWriting your own middleware gives you the freedom for ultimate flexibility when refining authentication routes.\n\nCurrently sessions are stored in RAM. To store have more size we can connect the session store to MongoDB. I\u2019ll use the connect-mongo package for that.\n\nCheckout my repo on github for the code.\n\nThat\u2019s how easy an authentication system can be implemented with Node.js and MongoDB.\n\nIf you want to follow along with my Github repo, be aware that I was refactoring my files constantly to fix issues and improve. So I\u2019d suggest to just look at the finished version. Also note that my current develop environment is not optimized \u2014 I just started with VS Code and didn\u2019t set up a lot, which is why many errors are overseen. It was more of a quick introduction to get the point about authentication across.\n\nThis is also covered in more detail on treehouse:\n\nIf you gained something from this article let me know with a comment or heart. Make sure to follow for more :)"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/a-simple-dynamic-node-js-site-treehouse-profile-finder-d13771a92a76?source=user_profile---------42----------------",
        "title": "A Simple Dynamic Node.js Site \u2014 Treehouse Profile Finder",
        "text": "The course encourages you to start with the 4 P\u2019s of Problem Solving:\n\nI read about this solving strategy multiple times and like the approach when tackling building applications. So that\u2019s why we are doing it here as well. \u27a1\ufe0f\n\nAlways go through the Node.js docs to see examples and get help if you\u2019re stuck."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/3-things-to-level-up-your-motivation-c95d2b3abbd4?source=user_profile---------43----------------",
        "title": "3 things to level-up your motivation \u2013 Of All Things - Tech Progress \u2013",
        "text": "Nothing is as important as staying consistent. Whether it\u2019s writing code, practicing examples for your studies or writing articles.\n\nThe simple act of just doing it consistently, repeatedly, gets your mind into the state where it looks for more experiences. Humans get bored very easily. The brains searches for new stimulants all the time, but especially when the current situation doesn\u2019t provide any new stimuli.\n\nThe paradox here is: The more you get into something, they easier you get bored, but also the you\u2019re looking for more new things in that certain topic.\n\nSo make sure to harness that ability and attack new things immediately. New things provide new motivation.\n\nA great article from Thomas Oppong describes the importance of persistency in detail \u27a1\ufe0f.\n\nDon\u2019t let the noise of disbelievers distract you\n\nNot everyone shares your believes. Not everyone likes your way of thinking. And that\u2019s ok.\n\nIt\u2019s important to treat it properly. Set yourself up for the best of you can be. Outside factors are temporary \u2014 your mindset is for eternity.\n\nIt happens to me at university and business all the time. Many assure you that \u201cthings are not meant to be\u201d, \u201cit\u2019s impossible\u201d or \u201cthings won\u2019t work out that way\u201d. It took me a while to understand that most people talk a lot. Without knowledge. They just deliver unqualified opinions. Not more, not less. Developing a mindset to simply acknowledge these messages as not significant helps a lot when pursuing your vision.\n\nThe hard part is to have your mind open enough for letting innovation take place, but closed enough to ignore bullshit.\n\nYour environment influences your behavior and way of thinking. So make sure to create one that supports your goals. Select friends accordingly. Stay with people that are doing what you like to accomplish in the future as well.\n\nAlways challenge yourself. When you\u2019re the smartest person in a room, you\u2019re in the wrong room.\n\nBut not only People. Change literally everything in your surroundings to support your goal. Your house/apartment/room, your desktop/mobile wallpapers, your working place. Get to places that inspire your creativity \u2014 cafes, libraries, rooftop bars. What ever gets you going. Be sure to be there and let creativity ignite your greatness.\n\nTo conclude, a few things to stay motivated:"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/introduction-to-e-commerce-shops-8325dab19056?source=user_profile---------44----------------",
        "title": "Introduction to E-Commerce Shops \u2013 Of All Things - Tech Progress \u2013",
        "text": "Now there are literally hundreds of possibilities to create your own web shop.\n\nHosted ecommerce software doesn\u2019t need your technical understanding at all. There a fixed features you can use and combine to build your store. The user experience is mostly designed for simple drag and drop. It is a fast setup but not really flexible to your personal wishes. The following services are the biggest in my opinion:\n\nThe most famous one is Shopify.\n\nThey provide different pricing models depending on your desired size, scalability and features.\n\nStart your Shopify experience right here\n\nBigCommerce is the biggest competitor to Shopify and provides pretty similar features. BigCommerce provides more features in the basic version than Shopify and adds some specialized features for promotion in certain \u201csales channels\u201d. Due to the fact that Shopify is so large and well-known it provides overall a little less options in my opinion. Nevertheless they provide a lot and should definitely be considered when building your own web store.\n\nWix is well known for their services since they put a lot of money in their marketing. Their shop system suits beginners and smaller businesses perfectly. They are purely drag and drop, and are very well-versed in that. Very fast and easy users can create very professional and good looking shop interfaces with basic features. They are also a great fit for test driving your business ideas.\n\nPricing isn\u2019t really that transparent though. It depends on your pricing model, time frame, amount of features, storage, etc. For me as user it takes time to actually compare that to other web shop services like BigCommerce or Shopify.\n\nSelf-hosted shops require technical and coding understanding or a developer to build something. It\u2019s the counterexample for hosted shop software. They provide a lot of flexibility but aren\u2019t that easy to set up without knowledge of the corresponding necessary services.\n\nA good way to start is using Open Source Software. They require you to install them into your own host \u2014 so you\u2019ll have to set up, configure and manage your own hosting service. After that you need to install a shopping cart software into your hosting account. Some hosting services provide a 1-click installation process, but be aware to invest time for this process.\n\nAfterwards you can design your own shop appearance the way you want. (Templates can reduce time and still provide great looks)\n\nAnything else, for example any functionality features can added accordingly to your needs, which provides great flexibility.\n\nMagento knows its main market \u2014 it encourages intermediate developers to build their site.\n\nMagento is your all-in-one solution for e-commerce, offering a ton of features with basically nothing missing from the platform.\n\nOr, as Liz Hull concluded in her article:\n\nCheck out this guide for more.\n\nOpenCart fits great for starting your first self-hosted shop service, since it\u2019s easier and cheaper compared to it\u2019s bigger competitors.\n\nThese are just some examples for frequently used software.\n\nIn my opinion estimated growth is an important factor for choosing your platform.\n\nAs Jeremy Wong argues in his article:\n\nHis article really addresses the key aspects of E-Commerce software . In the end, businesses have to weigh price, effort and scalability for their ultimate decision."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/introduction-to-webcrawling-with-javascript-and-node-js-f5a3798ee8ac?source=user_profile---------45----------------",
        "title": "Introduction to Webcrawling (with Javascript and Node.js)",
        "text": "In the tutorial \u201cScraping the web with Node.js\u201d by Scotch.io following frameworks are used to simply traverse a film review website:\n\nThat\u2019s a very good example of how easy it actually can get. I list these, because they are actually the most used ones in most of the tutorials available.\n\nThese are just some examples! Check out this comprehensive collection from potentpages.com.\n\nThe discussion about crawlabilty of JavaScript rendered websites reaches back many years and mostly discussed in terms of search engine optimization (SEO). An easy answer for writing your own solution are HTML-rendering-engines, that allow you to act the same way as a normal browser. Whereas there are many tools that allow you to meme such behavior, a practical example would be a webdriver used by Selenium.\n\nWeb scraping is an amazing way to gather much data with comparably low effort. Using and analyzing the collected data may provide advantages on a competition aspect und gives great insights on how a platform behaves.\n\nFirst thing to look for are terms of use. Some Site explicitly address the possibility of using their website with scraping APIs. Always be sure to take a look at these before.\n\nCopyright, privacy, competitive and civil law aspects may be violated depending on each case. It\u2019s important to see the difficulties between court rulings in different countries (especially America and Europe) and simply missing legislation caused by the fast progression of \u201cinternet cases\u201d.\n\nIt\u2019s safe to say that, if you have the feeling that some web scraping actions are not legal, they probably aren\u2019t. Websites and, or databases often protected by simple intellectual property law. Which means that others are not allowed to use the data that is presented on the website. This makes perfect sense because people put effort and knowledge into their online presentation and created data.\n\nThis extends to social media platforms in particular. Using their data and creating automated bots violate their fundamental principle of human interaction. It\u2019s therefore safe to assume that any kind of bots violate some applicable law.\n\nThis article from 2013 shows the legal complexity in more detail.\n\nHaving that said, be prepared to face the consequences when site operators ban or sue you for infringing their principles."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/secrets-of-a-javascript-ninja-book-summary-dc194b0e91d0?source=user_profile---------46----------------",
        "title": "Secrets of a JavaScript Ninja \u2014 book summary \u2013 Of All Things - Tech Progress \u2013",
        "text": "Understanding the foundations of client-side web applications will help you improve your development skills. JS as a language is very functional oriented:\n\nThis book focuses on core JS mechanisms such as functions, function closures, prototypes, generators, promises, proxies, maps, sets and modules.\n\nThe HTML code received by the browser is used as a blueprint for creating the DOM, an internal representation of the structure of a client-side web application. JavaScript is used to dynamically modify the DOM and bring dynamic behavior to web applications. There are 2 phases for executing client-side web applications:\n\nJS is a functional language and functions are first-class objects. Therefore they can be\n\nCallback functions are functions that will be called later and are often used in event handling. Passing properties to a function allows to store functions in functions to call later or to create a cache (memorization). Types of functions are:\n\nA parameter is a variable that is listed as part of a function definition, whereas an argument is value that is passed when invoking a function. Rest parameters enable to reference the remaining arguments that don\u2019t have matching parameter names. Default parameters enable to specify default parameter values that will be used if no value is supplied during function invocation.\n\nImplicit parameters are and arguments. The arguments parameter is a collection of arguments passed to the function. The parameter represents the function context, an object to which the function invocation is associated. How this is determined can depend on the way a function is defined as well as on how it\u2019s invoked.\n\nFunctions can be invoked as:\n\nFunction invocation and the value of :\n\nThe bind method creates a new function. It has the same body, but it\u2019s context is always bound to the passed in argument (a certain object), regardless of the way it\u2019s invoked.\n\nClosures allow a function to access all variables that are in scope when the function itself was defined. It ensures that the function has all it needs even when the scope of creation is gone. Closures are especially useful for:\n\nJS engines track function execution through an execution stack and identifiers with lexical environments (scopes). Variables can be globally-scoped, function-scoped and block-scoped:\n\nGenerators are functions that generate sequences of values \u2014 not all at once, but on a per request basis. Unlike standard functions, generators can suspend and resume their execution. Within the body of a generator, the yield keyword yields a value and suspends the execution of the generator. Calling a generator creates an iterator object through which we control the execution of the generator. New values are requested with the next method and exceptions are thrown with the throw method.\n\nA promise is a placeholder for the results of a computation; most often asynchronous computation. A promise can either succeed or fail, and after it has done so, no more changes will be made. Promises simplify the handling of asynchronous tasks significantly as interdependent asynchronous steps by using the then method to chain promises. The method allows parallel handling of multiple asynchronous steps.\n\nWhen combining promises and generators, asynchronous tasks can be handled elegantly with the simplicity of synchronous code.\n\nJS objects are simple collections of named properties with values. Every object can have a reference to a prototype, an object to which a particular property is delegated, if the object itself doesn\u2019t have the searched-for property. A prototype can have it\u2019s own prototype, forming a prototype chain. Prototypes are closely linked to constructor functions. A function\u2019s prototype object has a constructor property pointing back to the function itself and this property is accessible to all objects instantiated with that function.\n\nES6 allows the class keyword that enables to mimic classes in JS (still based on prototype inheritance). The extends keyword enables elegant inheritance.\n\nObjects can be monitored with getters, setters and proxies. Accessor properties can be defined by using or syntax as part of the object literal or ES6 classes. A method is implicitly called whenever a value is read, a set method is called whenever a value is assigned to the matching object\u2019s property. Getter methods are used for defining computed properties, whereas setter methods are used for data validation and logging.\n\nProxies are ES6 features that allow to control other objects in JS. They enable to define custom actions that will be executed when an object is interacted with. All interactions have to go through the proxy, which traps specific actions. Proxies are used for logging, performance measurements, data validation, auto-populating object properties and negative array indexes. Be aware that proxies are not fast and can effect performance.\n\nArrays are a special type of object with a length property and an as their prototype. Common methods for modifying an array are:\n\nSetting or methods allow to reuse built-in array methods on objects.\n\nMaps and dictionaries are objects that contain mappings between a key and a value. Objects aren\u2019t made for mapping because only string values can be used as keys and therefore running the risk of accessing prototype properties. Use the map collection instead. Maps are collections that can be iterated over using a for\u2026of loop. Sets are collections of unique items.\n\nRegular Expressions trivialize the process of tearing apart strings and looking for information. Commonly they are used for:\n\nRegEx can be created using literals (/test/) or the RegExp constructor ( new RegExp(\u201etest\u201c)). Flags can be used to qualify your target:\n\nEvery string has access to the match function, which takes in a regular expression and returns an array containing the entire matched string along with any matched captures. The replace function, which causes a replacement on pattern matches rather than on a fixed string.\n\nModules are larger units of organizing code and allow to divide a program into more understandable , easier maintainable and improved reusable clusters of code. Before ES6 modules has only been created by combining immediately invoked functions with closures. The immediate function created a new scope for defining variables and closures kept the variables alive from the outside. Two other module pattern are Asynchronous Module Definition (AMD) and CommonJS.\n\nES6 modules combine the features of CommonJS and AMD:\n\nConverting an HTML string into DOM elements includes the following steps:\n\nDOM attributes can be handled by or , DOM properties can be used with object property notation. The style element property is an object that holds properties corresponding to the style values specified in the element markup.\n\nEvent-loop tasks represent an action performed by the browser. Tasks are grouped into two categories:\n\nJS works with a single-threaded execution model with at least two queues. (One for macrotasks and one for microtasks) Timers can be used to break up computationally expensive code into manageable chunks.\n\nAn event that occurs on an element is usually propagated through the DOM. There are two propagation mechanisms:\n\nWhen calling event handlers, the browser passes in an event object. Elements can be accessed with the target property, and the this keyword is used to refer to the element on which the action has been registered. Dispatch with the method to reduce compiling between different parts of your application.\n\nBrowsers aren\u2019t bug-free and usually don\u2019t support web standards consistently. Since it\u2019s not possible to support all combinations, quality should never be sacrificed for coverage. Cross-browser development involves:\n\nTechniques like feature detection with polyfills assure that the code is complete and protect against attacks from different directions.\n\nAs you can see, the books covers all the basics of JavaScript and explains it pretty well. What\u2019s of course missing in this summary are all graphics and the good examples. Those things actually makes the book so good. Learning a programming language is not about theory only, it\u2019s about practice. In this book you get both. \ud83d\ude09"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/hosting-a-static-website-with-amazon-web-services-aws-11735ee17f8c?source=user_profile---------47----------------",
        "title": "Hosting a static Website with Amazon Web Services (AWS)",
        "text": "Firstly create an AWS account \u2014 simply follow the instructions on their homepage.\n\nNext set up an \u201cIdentity and Access Management\u201d (IAM) to create access keys and not being forced to use your own account credentials. Use the IAM console to add a new user and a new group.\n\nThe buckets need to have the same name as your domain to be resolved properly.\n\nTo create the bucket use the S3 console.\n\nS3 delivers the files in the bucket to the web browsers as if they were hosted on a server. Permissions have to be granted to make the files accessible for everyone.\n\nUse the S3 console to change permissions and properties of the bucket.\n\nLogging allows to track the number of visitors, that are accessing the website.\n\nCreate and upload a Index and Custom Error document. Use the S3 console to upload your files to the bucket. It is also possible to create folders in the bucket itself.\n\nConfigure your bucket as a website, so that files are served as if they were hosted on a web server.\n\nRedirecting By redirecting traffic from the www subdomain bucket to the root domain bucket, you can maintain a single version of your website files in Amazon S3 while still supporting both the root and www subdomain versions of your website\u2019s address.\n\nTest To see if the deployment was successful navigate to the provided URL.\n\nAgain: Before you pay to register a domain name, check that the domain name that you used when you created your buckets in Amazon S3 (as described in Step 1: Create the Buckets for Your Website) is available with a domain name registrar.\n\nUse Amazon Route 53 as your DNS service, to associate a domain name with your website.\n\nTo do that us the Route53 console\n\nUse the CloudFront console to set up data centers around the world.\n\n\u2757 Don\u2019t forget to update you record sets to point to the CloudFront distributions as well. \u2757\n\nThis again, is done in the Route53 console.\n\nThe guide shows how easy it actually is to set up a static hosting site. It can be done in a few hours and provides a lot of features. This first tutorial already demonstrates the power of AWS. Every beginner can easily publish his first website without complex knowledge of how to set up a hosting structure. I\u2019m pleased :)"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/introducing-amazon-web-services-aws-72c12547b9ff?source=user_profile---------48----------------",
        "title": "Introducing Amazon Web Services (AWS) \u2013 Of All Things - Tech Progress \u2013",
        "text": "As Amazon explains in their documentation:\n\nThe whole concept builds on top of the cloud computing principle. It provides IT infrastructure and other services over the internet.\n\nAnd it\u2019s commonly used for:\n\nThe following categories represent the core products of AWS.\n\nAmazon EMR (Amazon EMR) uses Hadoop, an open source framework, to manage and process data. Hadoop uses the MapReduce engine to distribute processing using a cluster.\n\nAWS can be accessed through:\n\nThere is a detailed guide on how to install and use each of these options in the documentation.\n\nAs you can see it takes a while to get familiar with each tool to get into some sort of workflow.\n\nAWS provides building blocks that you can assemble quickly to support any workload. With AWS, you\u2019ll find a complete set of highly available services that are designed to work together to build scalable applications.\n\nDiving into AWS requires you to understand their own keywords and concepts. There is really a whole cloud computing world waiting for you. I am eager to explore more, seeing that it steadily gains more popularity."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/starting-with-c-and-net-6c0b147b8107?source=user_profile---------49----------------",
        "title": "Starting with C# and .NET \u2013 Of All Things - Tech Progress \u2013",
        "text": "C# syntax provides some features like:\n\nC# is an object-oriented language, which means that a program consists of various objects that interact with each other by means of actions. Actions that are used by objects are called methods. Objects of the same kind are said to be in the same class. A simple program includes namespaces and classes, which are in it\u2019s widest sense objects that interact with each other.\n\nThese types are categorized into:\n\nIs converting one type of data to another type (also known as Type Casting). In C#, type casting can be implicit or explicit. Whereas explicit type conversion is done by using a pre-defined function, implicit type conversion relies on using the same type environment (e.g. from smaller to larger integral types).\n\nThese don\u2019t really differ much from other languages. In C# they are categorized into different types. There is a lot content on the internet with a full list of types (example).\n\nA variable is a name for a storage area that the program can manipulate.\n\nConstants are treated like regular variables except that their values cannot be modified after their definition.\n\nAn operator tells the compiler to perform specific mathematical or logical manipulations.\n\nAn array stores a fixed-size sequential collection of elements of the same type. An array is used to store a collection of data, but it is often more useful to think of an array as a collection of variables of the same type stored at contiguous memory locations.\n\nStrings are an array of characters. Most of time the string keyword is used to declare a string variable \u2014 it\u2019s an alias for the System.String class.\n\nMicrosoft provides an excellent definition of structs and classes:\n\nInheritance allows you to create new classes that reuse, extend, and modify the behavior that is defined in other classes.\n\nThe object-oriented principle of Encapsulation helps avoid duplicate relationships between information, allowing you to hide internal state and abstract access to it though type members such as methods, properties, and indexers.\n\nPolymorphism allows you to invoke derived class methods through a base class reference during run-time. This is handy when you need to assign a group of objects to an array and then invoke each of their methods.\n\nWell that sounds super complicated? Check out this amazing article, that explains it sooo well :)\n\nInterfaces contain only the declaration of the members and define properties, methods and events. The deriving class defines the members themselves accordingly to the laid out interface. In essence interfaces provide a standard structure that the deriving classes would follow.\n\nNamespaces are accessed through the keyword .\n\nThey instruct the compiler to preprocess the information before actual compilation starts.\n\nIn a real time environment, the preprocessor directives are very helpful to set conditional compilation like setting up of default parameters based on the defined symbol, and prompting developers in terms of building project, and making conditional warnings and errors, etc.\n\nCheck out the list of preprocessor directives to get a feeling what they can do."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/user-stories-the-practical-way-497c80489e27?source=user_profile---------50----------------",
        "title": "User Stories \u2014 The practical way \ud83d\udcdd \ud83d\udcc8 \u2013 Of All Things - Tech Progress \u2013",
        "text": "In short, User Stories are a description of the software functionality from the perspective of a user. In the past User Stories were simple notes written on small cards. Today most people use software with different types of issue system, but the concept remains:\n\nUse small units of tasks and group them in you project.\n\nUser Stories consist of acceptance criteria, which are even smaller tasks that can be checked off by the developers.\n\nYodiz provided an excellent list in their article, that these criteria should contain:\n\nUser Stories are used in an agile project management environment. cPRIME defines it as:\n\nYodiz\u2019s article provides a perfect introduction. They break down an agile scrum process into 12 steps:\n\nFor writing a good User Story it is an necessity for the writer to see things from the perspective of a actual user. This can be hard when you have already been working on the project and even wrote some code yourself.\n\nTry to get many different people to write User Stories, since each has a different view on the functionality aspect. The more input you have the better your project will be covered and in the end provide a result in the first result that is capable to fit a broad audience.\n\nDepending from which field you\u2019re coming, you tend to use jargon. That can lead to misunderstanding and slows down the processes of the project. The goal is to use as simple language as possible. Depending on the context language is interpreted differently. Be sure to stay neutral and to the point.\n\nThe component approach that is used in programming, can be used in this context as well. Try to write the User Story as small as possible. User Stories already fit in the bigger project management context \u2014 let them be small. They can be used like a checklist for the development team."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/quick-read-of-askgaryvee-a-summary-bce3588e3407?source=user_profile---------51----------------",
        "title": "Quick read of #AskGaryVee \u2014 a summary \ud83d\udcd6 \u2013 Of All Things - Tech Progress \u2013",
        "text": "He talks about the importance of have a clear big goal in mind always push to the edges (clouds and dirt) to receive it.\n\nBe thankful for the opportunities you have. Don\u2019t try to convince people, who don\u2019t like your product. Focus on the ones that already do. For the start you have to grind hard. Always deliver a lot of high quality content. For finding partners be self-aware and choose someone that compliments your weaknesses. Don\u2019t listen to excuses when it comes to investing in you. When they believe in you, they support you.\n\nMost things in life are taught in the school of life and not university. \u201eDon\u2019t be student, be a practitioner\u201c. The goal in business life should be to find your passion and spending your time realizing it. The willingness to take risks and try new things determine your success.\n\nBe emotional with people, but stay focused and rational with business.\n\nIs working hard and smart. Build yourself a lot of knowledge and experience, because people can tell if you\u2019re faking it. Don\u2019t listen to general assumptions of working hard. \u2014 Give in all that you have. Don\u2019t focus on the business itself, but on the bigger picture to stay healthy. Let your passion drive you. Be a 100% at work when at work and 100% at home when at home.\n\nThe quality of your brand is determined by the quality of your content. For social media: Respect the platforms and its audience. Length doesn\u2019t matter, but heart, message and fun does. Never abandon a platform entirely. It\u2019s all about depth not width. Pinterest is becoming a search engine in visual form. Never generate content or fake human interaction. For posts: Find a balance between the art and science (automation). Bet on your strengths instead of working on your weaknesses. Figure out whom you\u2019re trying to sell to, and story tell on the platform you love.\n\nJabs build a relationship with your audience, whereas a hook brings in the sale. Don\u2019t have expectations. -The absence of pressure and obligation makes people want to reciprocate. Communicate your Jabs and Hooks clearly! Always seek feedback directly through asking. Sell what is most important to the audience, sometimes they need your time to interact with them. Always start with emotion (heart), convince with rain and get paid afterwards.\n\nKeys for success: 1.Win the youth and 2. be extraordinarily useful. Better to risk to be an early mover in a new platform and fail, than not to try it at all. Don\u2019t be scared to innovate and try new things \u2014 that\u2019s the rule for today\u2019s marketing. Facebook Ads are extremely valuable right now. Focus on how much attention a user is paying to a platform. \u2014 Instagram has an extremely high attention level of consumers and therefore has a larger network than twitter. The trend is going to smart tech and Internet of things. \u2014 Interacting not only with your phone but day-to-day goods. Always use a mix of platforms and always adjust accordingly to trends to get success.\n\nAt the moment these ads give the highest ROI possible. Get in there and figure out what\u2019s the best option for you and analyze.\n\nThe 2 biggest opportunities are product and retail. Everybody is an influencer, everyone counts.- It\u2019s all about depth not width! Always let influencers do their thing. They know what they are doing and they are good at it. To become an influencer you have to have talent and put in the work.\n\nSince being CEO or an entrepreneur in general can be a very lonely job, gratitude is necessary in day-to-day life. Listen a lot and be thankful for everything. Expressing gratitude can be the only thing you can give and it will be enough.\n\nThe DNA stems from the top. It ensures that the values, beliefs and attitudes shape the culture to a productive, innovative, creative and happy environment. Most important advice: Your word is bond! Complaining fixes nothing, only action does. To stay motivated yourself, love what you do and be grateful every single day. Hire people who add a different skillset to your company and your skills. A good company culture builds on trust and openness. It\u2019s important to celebrate wins in the company. \u2014 Make sure to smell the roses from time to time, but sometimes you need to hand them out, too. Being nice to people is choice. It\u2019s independent of your busy schedule.\n\nThe happiness of your employees has to be more important than of your clients. For hiring: Find outstanding people of their fields in forums/twitter/etc, write them if they are open for a position, interview five and hire one. Hiring and firing are very important and emotional aspects of the company. Keep in mind that you are always dealing with human beings and think of other options before letting them go. When hiring creatives, make sure they know the business aspect as well. Keep meetings very short. \u2014 So it will be necessary to be well prepared. For interacting with employees very open and clear, communication is key at all times. Let creatives be successful and do their own things, don\u2019t suppress them. Delegate according to the 80/20 principle and when good enough actually is enough. Let people do things their way and encourage everyone to be an innovator.\n\nIt\u2019s important that the idea is phenomenal, but also the founders know what they do. And ask yourself \u201eHow would that person in a crisis handle those things?\u201c. Invest in areas in which you have intuitive strength or your interest matches your knowledge. It seems obvious, but the founders and VCs should always have a conversation about their expectations. Be aware that as company grow larger the requirement for the management changes as well!\n\nThe best and easiest way to get to know your strengths and weaknesses is just asking people. Make sure to have a good portion of humor as your personal traits, it\u2019s one of the most important but also one of the rarest. Focus on your goals while betting your strengths is most important. Execution matters, whether you are a shy nerd or an open entertainer. To keep self-confidence high, dream big and stop worrying about the little things. Always try to make others happy, but also look out for yourself. For sales, connections, references \u2014 just ask.\n\nBe yourself and punch people in their face with content and emotions.\n\nThink about your legacy and live on the offense. \n\nDon\u2019t be afraid to show your emotions and go for what you want. \n\nLife is about the climb. \n\nCare about your health.\n\nI think this book provides a really good introduction to entrepreneurship and the current marketing world. Many of his ideas are backed up in literature as well, but he knows how to bring his point across. I can definitely recommend reading this book \u2014 I enjoyed it a lot. Easy to read, down to earth examples and very good insights into the business world."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/fast-guide-on-the-todo-app-in-react-and-redux-48f6676766fb?source=user_profile---------52----------------",
        "title": "Fast guide on the Todo App in React and Redux \u269b \u23e9 \u2013 Of All Things - Tech Progress \u2013",
        "text": "Think about what you want to achieve in your app. As always think in React! Have an idea how your app is structured with components. Also decide which components have a presentational function (mainly for presenting data) and which have a container function (providing data and behavior). Check Dan Abramov\u2019s article for more.\n\nFind the code of Facebook\u2019s example.\n\nIf that\u2019s already overwhelming start with the basics.\n\nCut down you need:\n\nIn previous articles we learned what is all about. It's data that changes and cannot or should not be passed via props. Also, remember from Redux, which are information loads about events from user interaction.\n\nRevisit your components and think about theirs State and Actions:\n\nreturn an actual JavaScript object for your previously designed action-information-loads.\n\nReducers actually take the current State combine it with the actions and provide a new State. Each action needs a corresponding reducer. Be sure to put the reducer logic into container components to keep presentational components clean.\n\nWith reducers we have to:\n\nThe Store brings actions and reducers together, and allows the state being updated with dispatching actions. You should only have one Store in your application.\n\nFor dispatching make use of container components.\n\nAs we can see the core concept and ideas are really simple. It\u2019s just hard to stay focused and not get lost in the syntax specific issues when creating redux apps."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/6-cornerstones-of-react-62117ca14114?source=user_profile---------53----------------",
        "title": "6 cornerstones of React \u269b \ud83d\udca1 \u2013 Of All Things - Tech Progress \u2013",
        "text": "React relies on component-driven development. In \u201cThinking in React\u201d Facebook explains how to develop your app using components.\n\nThe difference between functional components and class components, is that functional components simply take props and provide a function, whereas a class allows many more features.\n\nIt is possible to compose or extract components to achieve the desired functional structure.\n\nHigh-order components (HOCs) are more advanced and are useful for:\n\nCheck out this article \u2b06\ufe0f for more.\n\nThis means that component is not allowed to modify it\u2019s own props.\n\nGet familiar with the react-router API since it provides a very easy and sufficient way of routing components on the client-side (but is also able to render on server-side!) Check out this great introduction if you are not familiar with it.\n\nOr as Christopher Pitt pointed out in his article\n\nWhen to use State\n\nIdentify the components that use State\n\nThe following method types are available:\n\nHandling Events in React is similar to handling DOM elements except events use camelCase and you pass functions as event handlers. When a function is passed as event handler, that is a method on class, and the context of the function changes.\n\nYou can bind callbacks automatically with property initializers or arrow functions.\n\n\u2757Keep in mind that binding with arrow functions can cause performance issues due to extra re-rendering of the according components.\n\nSharing a state is accomplished by moving a local state up to the closest common ancestor of the components that need it \u2014 the state is \u201clifted up\u201d. It is used when several components need to reflect the same changing data. This technique stems from one core principle of React:\n\nIn short, the following steps happen on every change:\n\nThe question whether to use composition or inheritance is basically a question of the use of JS classes. This article \u2b06\ufe0f by Steven Lowe goes into depth and he concludes:\n\nFacebook itself recommends using composition instead of inheritance, outlining it with examples.\n\nFor me the key points in understanding React is to understand components and State. These 2 fundamental concepts have to be understood in depth to fully grasp what React is about. This is also reflected in the focus of this article.\n\nDividing your application into many components, letting them communicate through props and manage them with State. That\u2019s my takeaway here."
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/8-steps-to-get-started-with-redux-and-react-a-roadmap-378807a1672e?source=user_profile---------54----------------",
        "title": "8 steps to get started with Redux and React \u2014 A roadmap \u269b \ud83d\udca1 \ud83c\udfc1",
        "text": "Set up your desired environment. React boilerplates \u27a1\ufe0f are a great way to get going. Be sure to understand the corresponding bundler at least a little bit.\n\nWhen creating your Components and how the fit together remind yourself to think in React.\n\nReact Router is the perfect tool for switching content components in your main components. Get yourself comfortable with the React Docs and understand how to handle and fit elements together (e.g. will Clone and return a new React element using element as the starting point. The resulting element will have the original element's props with the new props merged in shallowly. ).\n\nBe sure to include in your main component that is rendered in your main path, so props can be passed downwards.\n\nSet actions to handle data that is created in user interaction (e.g. clicking \u201clike\u201d).\n\nSet reducers to change the state accordingly to the happened actions. A reducer takes the action and a copy of the current state. Create a reducer for each state and combine all of them in a main reducer.\n\nUse react-redux to implement the state into the React router.\n\nConnect the router to the store with .\n\nEvery time you run an action, every reducer is going to run and actions will be dispatched.\n\nI wrote this roadmap while I was creating the \u201cReduxstagram\u201d-App. I think it\u2019s one of the better tutorials, as usual from Wes Bos, however I realized it\u2019s absolutely necessary to read the docs to understand the concept of Redux with React. I have also realized that my knowledge on React is also not good enough \u2014 make sure to be confident with React alone.\n\nI used the roadmap as guide for another app and it gave me a good direction for setting up a basic structure."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/free-code-camp-the-worlds-best-learning-platform-for-coding-61c8fb738639?source=user_profile---------55----------------",
        "title": "\ud83d\udcbb Free Code Camp \u2014 The world\u2019s best learning platform for coding?",
        "text": "The homepage itself explains quite well what they want to accomplish and provide. The FAQ also covers a lot. It says:\n\nSo in a nutshell it is another online source for learning to code.\n\nFirst and foremost, it\u2019s free, which is pretty amazing when you look at the quality they provide.\n\nAt the time of writing there are 4 certificates:\n\nWhat I really enjoyed was the fact that you can code real working projects with a very big community at your hand. There are easy chapters with a lot of guidance that allow you to get comfortable with the new syntax and problems. After that you have the opportunity to write something that is actually working. Something that you can present to your friends. Small projects like the Javascript Calculator are absolutely doable and \u201ccool\u201d enough to be presented to non-coding people :) Because from personal experience, when you tell people you are learning to code, they want to see results. It\u2019s pretty hard to present something you created yourself on other learning platforms. In my opinion the gap between guided theoretical coding and real life projects was too big.\n\nFree Code Camp itself provides various social media and chatting platforms. But the real value is in the people that learn and provide help for others. Especially in the beginning I was really delighted that there are so many well documented solutions from different people. It helped a lot to solve problems in different ways and see the opportunities in coding. It also shows how amazing open source projects can be. The whole platform has hundreds of contributors, who not only bring new content into the project, but also provide solutions for existing bugs and other issues. (See Github \u27a1\ufe0f)\n\nThe forum also provides great interaction with people, who are on the same journey as you are.\n\nAnother great thing are local meetup groups. People gather to share their experience in Free Code Camp with others in their cities. Get together with like-minded people to improve and easify your learning experience. :)\n\nThe \u201cabout\u201d section actually covers also a FAQ. It explains what the curriculum provides and how you can incorporate it in your personal life to get the most out of it. In my opinion the curriculum serves perfectly as a primary education source but also just for freshing up basics.\n\nThe navigation in the curriculum is simple, intuitive and on point. Dive into it and you I\u2019ll see quickly if it is for you.\n\nOf course I started with the . They are separated in small steps, that are easy to understand and easy to look up on the internet.\n\nAfter that I went through all of the . These are very important to understand logical programming and are much harder. I always tried to solve them with the references they provided. Looking up JavaScript methods and how to implement them. Here it is crucial to make up your own mind and NOT COPYING existing solutions. However, to broaden my comprehension, I looked up other solutions and tried to understand and reconstruct them. These challenges will take time! Be consistent and don't be afraid to spend more than a day on some of these!\n\nUltimately I did the . These are the most rewarding, but also most challenging ones. Look for ways how other people did it, to get going with your first ones. And then again: Keep looking, be consistent, create your own solutions and never give up!\n\nAfter finishing the Front End Certificate, you are able to attack the next challenges on your own. At that point you should have an understanding how to find solutions online to your own problems.\n\nThe and the just have projects to be solved. Currently the jump is too big. I am myself have been learning a lot on my own now to complete one of these challenges. They are very big compared to the Front End Challenges. However, when you master these you will be able to create something from scratch and truly mastered the basics of a full stack developer. \ud83d\ude80\n\nThe release of the new Free Code Camp platform will provide a lot of guided challenges on the Back End and Visualization part, which fill the current gap. Stay tuned \ud83c\udf1f\n\nCurrently there is a beta version of the new Free Code Camp platform. Check it out \u27a1\ufe0f. Unfortunately I didn\u2019t find any release date, but when you look at the challenges you see that there is coming a lot. It makes me really excited. In my opinion Free Code Camp brings online learning of web development to another level.\n\nThe Github repo shows recent pull requests and issues. You can easily see how far they got and where certain problems lie. If you have solutions don\u2019t hesitate to contribute!\n\nWhat I also really enjoy and actually is a good way of keeping up, are newsletters and articles from Quincy Larson and the Free Code Camp community.\n\nOn medium you\u2019ll also discover other amazing individuals that share their experience and knowledge. Definitely check it out!\n\nFree Code Camp helped me a lot to get going in a field I had no experience in. It provides a great entry point in the world of programming the web. Till now it is definitely the best learning experience on the internet for me. Make sure to check out the links and give it a try! :)\n\nAnd if you are from Vienna (Austria), join our local meetup group. \ud83c\udf86"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/how-to-set-up-atom-for-writing-b2a9f5bee1f7?source=user_profile---------56----------------",
        "title": "\u269b \ud83d\udcdd How to set up Atom for writing \u2013 Of All Things - Tech Progress \u2013",
        "text": "Style your syntax highlighting and themes as you please. Scroll through your core settings and configure it the way you like.\n\nFolders can be structured in books or series with submodules.\n\n\u2696 Makes sure to know your licenses and copyrights when publishing online! \u2696\n\nBecause Atom can be extended with user-created packages, it makes it easy to find specialized ones for writing. What I found useful are:\n\nWhat\u2019s missing till now are more integrations to online platforms like medium.com for example. However, I\u2019m pretty sure the community will provide something in the near future. \ud83d\ude04\n\nThere are many guides on how to write a good Readme file. Unfortunately not enough people take time to read them, which causes irritation in many coding projects. Github itself provides a detailed guide on how to write documentation on Github \u2139\ufe0f\n\nAs The Art of Readme suggests:\n\nThis not only applies to writing code, but also to writing in general (on Github).\n\nMake sure to provide an overview and sufficient information, but also excitement for visitors. \ud83d\ude09\n\nIn the end Atom is a text editor. One that you can setup the way you like, and that\u2019s the power of it. Learn your tools and get the best out of them. I am very open for further suggestions. \ud83d\ude04"
    },
    {
        "url": "https://medium.com/of-all-things-tech-progress/understanding-mvc-architecture-with-react-6cd38e91fefd?source=user_profile---------57----------------",
        "title": "\ud83d\udee0 \ud83d\udcd0\ud83d\udccf Understanding MVC Architecture with React \u2013 Of All Things - Tech Progress \u2013",
        "text": "MVC is a way of thinking to structure your web application. It\u2019s popular because it\u2019s used by many frameworks that implement that structure (rails, cakephp, django etc.).\n\nThe architecture stems from the traditional flow of a web application.\n\nDisplays visualization of the data to the user. Only connected to the controller.\n\nProcesses server-side logic and acts as a middleware between View and Model, i.e. controlling the flow of data.\n\nProcessing data from or to the database. Only connected to the controller.\n\nSee a practical example here \u27a1\ufe0f\n\nThe structure allows flexibility since responsibilities are clearly separated. This leads to\n\n, but also to\n\nReact is JavaScript library from Facebook, that is designed to create interactive UIs. The main features are that it\u2019s\n\nWhereas React is often referred to as the View in a MVC structure, Facebook presented their own architecture called Flux \u27a1\ufe0f. The problem with a MVC structure is it\u2019s bidirectional communication, which proved to be very hard to debug and understand when a change in one entity caused cascading effect across the codebase. Especially when the app is scaling into a much bigger one, like Facebook for example. The flow of data was not well enough or easy enough defined for large applications.\n\nFlux is made up of 4 key elements:\n\nContain the application\u2019s state and logic.\n\nListen to changes from the stores and re-render themselves.\n\nIt\u2019s important to notice and understand the unidirectional flow here.\n\nNow the differences to a MVC are:\n\nDespite the fact that some are calling MVC \u201cdead\u201d, I think Flux is more of a refined and enhanced MVC, and thus sympathizing withPaul Shan and his conclusion in his article.\n\nRedux builds on Flux and can be described in three fundamental principles:\n\nThe state of your entire application is stored in a single store.\n\nThe only way to change the state is to emit an action (an object describing what happened).\n\nSpecify the transformation by actions with reducers, which allow to navigate through states.\n\nAs the documentation already suggest, you should use the concept of redux after understanding React first. And:\n\nAs we could see, software design patterns are evolving with time. The use of certain architecture depends heavily on it\u2019s used frameworks and goals of each project. That being said, in the end, MVC, Flux or Redux are just tools. Be sure to know their tradeoffs and use them accordingly."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/how-to-write-an-article-and-use-words-in-2017-d19f2cd20e42?source=user_profile---------58----------------",
        "title": "How to write an article and use words in 2017 \u2013 Daniel Deutsch \u2013",
        "text": "Choose a topic you have been working on or some experience in. Most of the time people with interest in that topic will read your article. Educated people will spot guessing and bluffing immediately and call you out or stop reading. So make sure that you know the topic or build an opinion based on facts. Also keep the goal of your article in mind. Shall it educate, inform, inspire, provide solutions or be entertaining? Be sure to set your goal accordingly to your knowledge on that topic.\n\nMy definition of quality is determined by the amount of thoughts that have been put into an article. And of course, the quality of your thoughts themselves matter. You build your thoughts on experience. The more experience or research you put in, the higher the quality of your thoughts are. Look for sources that provide quality content themselves and always form your opinion on more than just one. Your own opinion stems from absorbing other opinions and critically reflecting in your own mind. Be aware that too often an author tries to inform, but unfortunately isn't able to reflect with a questioning attitude on what he had read. Thus continuing to provide poor knowledge.\n\nWork with structure! Deliberate precisely what you want to express in one paragraph and how it fits in your document structure. Make sure to identify your target audience and understand the language they use. For example: The term author in the context of writing means simply the creator of that certain text. Is the author in the context of writing programs the publisher, the writer, the graphic designer or the one who wrote the source code? Or: The term \"controller\" when programming an application can have very different meanings. Normal language use suggests a component that manages data flow, but in MVC structures this term has a clear defined purpose and must not be confused with \"controller\"-components in other architecture models. Be sure to choose a definition that fits in the context and provides clarity. It definitely pays off in legal disputes!\n\nAs Elon Musk said in his interview, he likes to reason from first principles rather than analogy. This simply means that you should create solutions on the basis of proven principles. Most people today take similar solutions, add their own input and provide a suboptimal result. Why is that? Because real existing solutions have a large amount of thought in them. Let's take a look into physics: In aviation you have variables and behavior that is acknowledged as proven principles (behavior of gravity, speed, pressure, density). When you build on the base of established products other companies you tend to neglect other possibilities as you see that the current solution is already working. It pays off to invest your thoughts into other aspects of mechanical, ballistic and buoyant flights and be able to provide radical new solutions.\n\nThe one thing we have to be aware of is attention. Technology gives us the ability to consume everything we want in every form we want to. With so many alternatives and a very short span of attention, you as a writer or marketer have to be direct, fast and interesting. As Gary Vaynerchuk puts it: Depth is more important than width . He preaches that connection to people as a human beings is so much more important than going for numbers and followers. And I think that's exactly the way how to write in this year. Focusing on quality and connecting with each reader as much as possible. Choosing titles and intros based on psychology and delivering content based on research. That looks like a good strategy for me. \ud83d\ude4f\n\nThis was a very, very short overview of some aspects of writing well. There are a lot of good books and articles on how to write better. Check out some of them to get going. Don\u2019t lose sight of what you are aiming at! Get good in writing but don\u2019t lose yourself in the process. It all comes down to communication of your thoughts. For myself I am sure that I will revisit my opinion and ideas on writing after the first articles. Revisiting and questioning basic principles and progression. It may pay off for you to do the same whether you are a professional for years or just started a few weeks ago."
    },
    {
        "url": "https://medium.com/@ddcreationstudi/5-reasons-why-i-start-writing-77312bbfdbf0?source=user_profile---------59----------------",
        "title": "\ud83d\udcd6 5 Reasons why I start writing \u2013 Daniel Deutsch \u2013",
        "text": "The advantages of using a PC are endless. So learning to improve your actual writing skills on keyboard seems like a logical next step for becoming a more efficient human being.\n\nIn Coding it\u2019s absolutely necessary to understand and use a very proficient text editor. Browsing through the web I came to the conclusion that atom is the most suitable for me. The more I use and write in it, the better I get in my coding endeavor.\n\nEnglish is key in every aspect of life. It\u2019s 2017 and we have to think in global and international scales. Thus improving the ability to express yourself in good english phrases is necessary to stay relevant in the business world.\n\nAlthough voice recordings and video journals are on the rise, nothing will trump writing. A level of comfort writing about certain topics will allow you to get out your experience and knowledge out to the world.\n\nThis last one is actually the most important one for me. It\u2019s learning on paper. Knowledge is power, and writing, yes thinking on paper, is the best way to learn about a topic (at least for me). It\u2019s easy to just read or consume information and knowledge. But putting it into action, into practice, connecting dots and subsume onto your life is a different story. it\u2019s also a great way to get your insights out to the world and be able to receive feedback in any kind of form."
    }
]