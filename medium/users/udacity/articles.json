[
    {
        "url": "https://medium.com/udacity/flying-car-news-may-5-2151e7e465aa?source=---------0",
        "title": "Flying Car News, May 5 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Drones save lives, an autonomous air ambulance, Miami flying car skyport, medical drones in the Himalayas, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nDrone manufacturer DJI has released a report indicating that 65 people have been rescued by drones in the last year, in 27 incidents, on 5 continents.\n\nResearchers at CalTech have developed a \u2155 scale prototype of an autonomous air ambulance that can fly up to 20 minutes per trip.\n\nBuilding developer Dan Kodsi has unveiled the Paramount Miami Worldcenter highrise, which includes a skyport for VTOL aircraft.\n\nThe Nepalese National Innovation Center has created the country\u2019s first medical drone, which is being used to provide medical care to hard to reach areas in the Himalayas.\n\nNasa has completed the first part of its 3rd phase of Unmanned Aircraft System Traffic Management, in partnership with private unmanned service providers including Google Project Wing and Airmap.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-may-4-edition-a7c3dfffae89?source=---------1",
        "title": "This Week at Udacity, May 4 edition \u2013 Udacity Inc \u2013",
        "text": "Fun fact for the 4th of May: Did you know that \u201cMay the Fourth Be With You\u201d actually originated as an ad in the London Evening News celebrating Margaret Thatcher becoming Prime Minister?\n\nAlways good to keep on learning!\n\nAnd in that spirit \u2026\n\nAlready got your sights set on a particular career? Well, if that career happens to have anything to do with Self-Driving Cars \u2026\n\nBut if you\u2019re still on the career fence, or seeking out new strategies for career success, consider mentorship!\n\nAnd speaking of success, what a beautiful week for student success across the globe!\n\nAnd as long as we\u2019re talking about tweets, we might as well get right to \u2026\n\nHard to resist this one, because really, is there better affirmation that you\u2019re on the right track with the learning services you provide, than to have your students blame your instructors for delivering too much value?\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity\n\nLightsaber image courtesy of: By DancingPhilosopher [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], from Wikimedia Commons"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-april-28-c005e77df2c2?source=---------2",
        "title": "Flying Car News, April 28 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Lilium hires Ferarri head of design, World Food Program uses drones, Uber designing flying taxi batteries, drone mosquito release system, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nFlying car company Lilium has hired legendary car designer Frank Stevenson of Ferrari and Maserati as the head of product design for their electric flying taxi.\n\nThe World Food Program will start using drones for humanitarian purposes and data collection.\n\nUber is designing advanced batteries for use by its flying car hardware partners to accelerate the development of the Elevate flying taxi service.\n\nThe International Atomic Energy Agency is partnering with the Food and Agriculture Organization of the United Nationals to utilize drones that release sterile mosquitoes, in a bid to limit the spread of diseases.\n\nDrone patents have more than quadrupled in the last year as companies worldwide position themselves for the future of autonomous flight.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-april-27-edition-b5d05e47a59?source=---------3",
        "title": "This Week at Udacity, April 27 edition \u2013 Udacity Inc \u2013",
        "text": "Have you checked out the latest episode from The Drawing Board, Udacity\u2019s podcast? If you\u2019re a Game of Thrones fan, this episode is for you!\n\nWhat do you get when you combine transformative, future-facing technologies and cutting-edge technical skills, with a record-shattering pop culture phenomenon? We didn\u2019t know the answer to that question either. But we knew who did!\n\nWho was the special guest? You\u2019ll have to listen to find out!\n\nOk, we\u2019ll give you a hint. It was NOT David Silver. But, David Silver certainly WAS busy this week. Our Evangelist-in-Chief (not real title!) for all things self-driving cars took a moment out of his jam-packed schedule to offer some great insights about career pathing for self-driving car enthusiasts\u2014if you\u2019re not sure how to gain the necessary skills and advance your career in this incredible field, this post is for you!\n\nAnd speaking of incredible fields, now that our new Computer Vision Nanodegree program has launched, Curriculum Lead Cezanne Camacho took to Medium to share a deep dive into the world-class curriculum:\n\nSpeaking of new Nanodegree programs, did you see the TechCrunch article about our upcoming Cybersecurity Nanodegree program? It\u2019s right here, just in case!\n\nBy the way, if you\u2019d like an even more personalized look at career paths and self-driving cars after you read David\u2019s post above, check out Kyle Martin\u2019s amazing story!\n\nAnd speaking of Student Success, it must be time for \u2026\n\nHow could we possibly resist this much enthusiasm and excitement? We can\u2019t!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/comparing-udacitys-self-driving-car-programs-63d749a9eab7?source=---------4",
        "title": "Comparing Udacity\u2019s Self-Driving Car Programs \u2013 Udacity Inc \u2013",
        "text": "Udacity has two excellent Nanodegree Programs for aspiring self-driving car engineers: the Self-Driving Car Engineer Nanodegree program, and the Intro to Self-Driving Cars Nanodegree program.\n\nWhich one is right for you?\n\nTo try and answer this question, I\u2019ll begin with a story. In October of 2016, Udacity welcomed the first class of students into our Self-Driving Car Engineer Nanodegree program. Since that historic debut, we have been delighted to enroll over 11,000 students around the world in this program!\n\nAlong the way, we learned that while people across the globe were thrilled at the prospect of being able to work on autonomous vehicles, not all of them were equipped to do so\u2014many of them needed additional training to get ready for the rigors and challenges of our curriculum.\n\nIn order to provide a viable point-of-entry for these eager learners, we built the Intro to Self-Driving Cars Nanodegree Program, and welcomed the first class of students at the end of 2017. This \u201cIntro\u201d program prepares students with the fundamentals in Python, C++, calculus, linear algebra, statistics, and physics that are necessary to become a Self-Driving Car Engineer.\n\nBoth Nanodegree programs are paths to a career in the self-driving car field, but the goals of each program are distinct, as are the skills one learns.\n\nThe Self-Driving Car Engineer (SDC) Nanodegree program is an advanced program in which students write programs in Python and C++, and learn new frameworks like ROS and TensorFlow. Students entering SDC should be able to write programs from scratch, and should be comfortable with both calculus and linear algebra. SDC does not require solving differential equations by hand, but does require that students be comfortable interpreting mathematical notation and translating it into code.\n\nThe Intro to Self-Driving Cars (iSDC) Nanodegree program is an intermediate program that requires entering students to have only minimal programming and math knowledge. Students entering iSDC should be comfortable reading and modifying code in at least one language (Python helps, since that is first language the program uses). Entering students should also be comfortable with high-school algebra. From there, iSDC teaches the trigonometry, calculus, linear algebra, statistics, and physics that are necessary to succeed in the advanced SDC program.\n\niSDC does not require an application to enroll, and everybody is welcome. However, students with no programming experience at all might consider starting their journey with Udacity\u2019s Intro to Programming Nanodegree program, and then proceeding on to Intro to Self-Driving Cars. A slightly more mathematical (and more challenging) alternative first step would be Udacity\u2019s Data Analyst Nanodegree Program.\n\nWhether you are ready for the Self-Driving Car Engineer Nanodegree program today or feel like you should cover the topics in Intro to Self-Driving Cars first, Udacity is the place to start on the road to becoming a Self-Driving Car Engineer. See you in the classroom!"
    },
    {
        "url": "https://medium.com/udacity/computer-vision-nanodegree-program-what-youll-learn-668dbfc3e5a3?source=---------5",
        "title": "Computer Vision Nanodegree Program: What You\u2019ll Learn",
        "text": "Computer Vision is a specialized branch of Artificial Intelligence focused on enabling machines to visually perceive the world, and respond to it. As with human vision, this is a process of taking in visual information, analyzing and processing that information, and correctly identifying objects contained within that information. Thanks to advances in the field of Computer Vision \u2014 and significant increases in available computing power \u2014 machines can now \u201csee\u201d thousands and thousands of images, and process them far more rapidly and accurately than a human could ever do.\n\nOur new Computer Vision Nanodegree program covers all the latest techniques. You\u2019ll learn about deep learning architectures like R-CNN and YOLO (You Only Look Once) multi-object recognition models, and you\u2019ll implement object tracking methods like SLAM (Simultaneous Localization and Mapping).\n\nThe applications of this pioneering technology are almost limitless, and Computer Vision is already having a profound impact on so many industries. Can you imagine being a cancer researcher, experiencing the power of Computer Vision for the first time? Using applications trained on thousands of images, doctors are now able to rapidly and accurately distinguish between cancerous and non-cancerous tissue, and diagnose patients much earlier.\n\nIn our new Computer Vision Nanodegree program, you\u2019ll learn the very same image processing techniques that are revolutionizing healthcare and saving lives.\n\nThe field of autonomous transportation depends on Computer Vision \u2014 it\u2019s the technology that enables self-driving vehicles to \u201csee\u201d the world around them. Self-driving cars are predicted to save millions of lives, and enable efficiencies that will significantly improve air quality, not to mention reducing traffic congestion! Already today, Computer Vision is being applied in real-world settings that include helping to eradicate malaria in Malaysia, supporting wildlife conservation in Canada, and aiding disaster relief efforts in Puerto Rico.\n\nIn this program, you\u2019ll learn how a self-driving vehicle uses visual input from laser sensors, radar, and cameras to safely navigate roads by itself. You\u2019ll explore the ways Computer Vision is used to analyze camera images, and to identify objects like other cars or pedestrians.\n\nThis is an incredible time to enter the field of Computer Vision. A recent report published by Indeed ranked Computer Vision Engineer as the #3 Best Job in the US in 2018! This is but one indication of how high demand is for Computer Vision talent \u2014 ZDNet recently put Computer Vision Engineer at the top of its list of jobs that will be most in-demand in 2020. TechRepublic identified Computer Vision Engineer as one of the 6 most in-demand AI jobs, and a recent article in Inc. declared that Computer Vision Will Be The Most Disruptive Innovation Driver.\n\nIn Udacity\u2019s new Computer Vision Nanodegree program, you\u2019ll learn the in-demand skills that will enable you to take advantage of the extraordinary opportunities in this exciting field.\n\nIf you\u2019re new to Computer Vision, but you have a working knowledge of machine learning and Python, the Computer Vision Nanodegree program is ideal for you. You\u2019ll learn all about the Computer Vision and deep learning techniques that are used to analyze images and spatial information. You\u2019ll start by learning to code image classifiers using Python code, and build up to using deep learning frameworks like PyTorch for more complex classification and regression tasks. You\u2019ll learn from a curriculum built in collaboration with Affectiva and NVIDIA, and you\u2019ll hear from experts in the fields of emotion recognition and scene understanding.\n\nThis course will also cover the latest in deep learning architectures used in industry, including region-based convolutional neural networks and fast object recognition algorithms such as YOLO (\u201cYou Only Look Once\u201d multiple object detection). With the practical skills you gain in this program, you\u2019ll be able to program your own computer vision applications, extract information from any kind of image and spatial data, and solve real-world challenges.\n\nThroughout the course, you\u2019ll use real data to inform your work and train your deep learning models. You\u2019ll complete three major computer vision projects, and build a strong portfolio in the process!\n\nThe Computer Vision Nanodegree program is comprised of 3 main sections, each with an associated project.\n\n1. Introduction to Computer Vision\n\nFirst, you\u2019ll learn the foundational math and programming concepts behind pattern recognition and classification tasks. This section will be all about creating algorithms that can: 1) isolate important, distinguishing information about an object in an image (like an object\u2019s unique shape or color), and 2) ignore irrelevant parts of an image (like a plain background or noise). You\u2019ll learn to program a green screen and define your own clothing classifier.\n\nProject 1: Facial Keypoint Detection\n\nCombine image processing techniques and deep learning techniques to detect faces in any image, and then detect facial keypoints, such as the position of the eyes, nose, and mouth on a face. In this project, you\u2019ll define and train a convolutional neural network to recognize these keypoints.\n\n2. Advanced Deep Learning & Computer Vision\n\nHere, you\u2019ll learn about the deep learning algorithms that have led to state-of-the-art advances in computer vision technology! This section covers architectures like Faster R-CNNs that identify where object are in an image. You\u2019ll get to work with a code implementation of YOLO, and learn about models that use recurrent neural networks for generating sequences of data. This section will be all about applications that aim to reach human levels of scene understanding.\n\nProject 2: Automatic Image Captioning\n\nImage captioning requires that you create a deep learning model with two components: a CNN that transforms an input image into a set of features, and an RNN that turns those features into rich, descriptive language. In this project, you\u2019ll focus on the part of the model that can generate descriptive sentences and demonstrate your mastery of deep learning architectures.\n\n3. Object Tracking and Localization\n\nTo conclude, you\u2019ll learn about object tracking techniques; using spatial information, gathered over time, you\u2019ll learn about predicting the location of an object and determining its movement. This is an ongoing area of research especially in the field of autonomous vehicles like self driving cars and drones!\n\nProject 3: Landmark Detection and Tracking (SLAM)\n\nImplement a robust method for tracking an object over time, using elements of probability, motion models, and linear algebra. Use feature detection and keypoint descriptors to build a map of the environment with SLAM (Simultaneous Localization and Mapping).\n\nUdacity offers you a wide array of support options to ensure you proceed through the program successfully. You\u2019ll have access to a personal guide through our Classroom Mentorship program, and you\u2019ll get detailed feedback on your project submission by one of our project reviewers. You\u2019ll be able to connect with your fellow students by joining a Slack community where you can engage with our Community Manager, your fellow students, and even your instructors.\n\nWe are now accepting new students to the Computer Vision Nanodegree program.\n\nThe program is comprised of a single three-month term. The tuition for the term is $799, paid prior to commencing your studies.\n\nTo learn more, you can also explore a Free Preview of this program (but don\u2019t delay on enrollment, and miss your chance to save). You\u2019ll meet your instructors, and explore some early lessons on pattern recognition. You\u2019ll even have the opportunity to experiment with our in-classroom programming environment.\n\nComputer vision is changing the way the world sees, and if you\u2019d like to incorporate this in-demand skill into your work and learning journey, this is your invitation to join. Come learn Computer Vision and start building your skills today!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-april-20-edition-9380b35766e1?source=---------6",
        "title": "This Week at Udacity, April 20 edition \u2013 Udacity Inc \u2013",
        "text": "It was a wonderful week for exciting announcements at Udacity! First up, an expansion of our wonderful student-focused relationship with the Amazon Web Services team, aka AWS Educate!\n\nThis was followed by a big new program announcements we\u2019ve just been itching to to tell you about!\n\nIf you\u2019ve any doubt why we\u2019re committing to teaching the next generation of Cybersecurity professionals, one look at recent reports from the Department of Labor ought to make things crystal clear:\n\n\u201cEmployment of information security analysts is projected to grow 28 percent from 2016 to 2026, much faster than the average for all occupations. Demand for information security analysts is expected to be very high, as these analysts will be needed to create innovative solutions to prevent hackers from stealing critical information or causing problems for computer networks.\u201d\n\nAnd speaking of transformative technologies, our own Luis Serrano offered up a deep dive this week into our incredible new Artificial Intelligence curriculum:\n\nAs to the tweet of the week, can we resist our own Sebastian Thrun sharing news about AMAZING salaries for skilled AI talent? No. No, we can\u2019t. And so, without further ado, here is \u2026\n\nThe Tweet of the Week!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-april-14-dc747d1a02a9?source=---------7",
        "title": "Flying Car News, April 14 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Volocopter\u2019s vision for flying taxi infrastructure, drones used in fight against malaria, Samson switchblade surpasses 600 orders, and more!\n\nRecent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nFlying Car company Volocopter has detailed their vision for VTOL landing stations in buildings which can handle up to 10,000 passengers per day,\n\nFlying car company Terrafugia has unveiled a new concept for a modular flying car named the TF-2 as they ramp up their workforce in their bid to introduce practical flying cars to the world.\n\nDrones are being used to help in the fight against malaria carried by monkeys in Malaysia.\n\nThe $140,000 Samson Switchblade flying car, which is being released in late 2019, has surpassed 600 preorders.\n\nDrones are replacing airplane surveys as tools for wildlife conservation efforts of bird rookeries in Charlotte Harbor, Florida.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-april-19th-2018-fc88317544b9?source=---------8",
        "title": "This Week in AI, April 19th, 2018 \u2013 Udacity Inc \u2013",
        "text": "In this thoughtful article by Michael Jordan (a leading figure in machine learning for decades), a call for human-centered AI:\n\nNew research out of OpenAI shows promise in speeding up the training of reinforcement learning agents, and improving performance on novel tasks. The new method is called Evolved Policy Gradients (EPG), where the model is able to learn how to learn, a process called metalearning.\n\nTypically an agent is given a static reward or loss function. With EPG, the loss function is also trained such that the agent is able to learn from past mistakes and use that knowledge in new situations.\n\nA team from MIT built a program that can generate maps from aerial images called RoadTracer. This program is intended to help map roads in areas where maps are frequently out of date.\n\nA major challenge with building machine translation systems such as Google Translate is the requirement of obtaining large datasets with the same text in multiple languages. In this article from the Facebook AI Research team, the authors demonstrate a technique for training a machine translation model using only monolingual examples. For a great summary of the paper and how this model works, check out this Medium post by Harshvardhan Gupta.\n\nHere\u2019s a report out of McKinsey about the business uses of AI and deep learning. As successful as deep learning has been in the past few years, there are still a lot of applications and business opportunities to be discovered. While there are ample resources for learning how to build deep learning applications, there is little out there on the product side.\n\nIn what might be the most time and frustration-saving application we\u2019ve yet seen, researchers in Singapore trained robots to put together IKEA furniture. The robots were able to construct the furniture in 20 minutes, after inventorying all the parts, making a plan, and finally executing the plan with common tools.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of the programs from our School of AI:"
    },
    {
        "url": "https://medium.com/udacity/visiting-apollo-abd5a8ef190f?source=---------9",
        "title": "Visiting Apollo \u2013 Udacity Inc \u2013",
        "text": "This past week I had the pleasure of visiting China for the first time in 20 years! I spent a few days working with colleagues at Udacity\u2019s office in Shanghai, and followed that with several days at Udacity\u2019s Beijing office. I was also able to take in some additional Beijing-based events. It was a whirlwind tour, and I loved it!\n\nMy traveling group was hosted by the terrific Apollo team at Baidu. Baidu is China\u2019s largest search engine company, and one of the largest Internet companies in the world. And Udacity is building a free self-driving car course with them!\n\nThis course will provide a conceptual overview of self-driving car technology, illustrated with the Apollo open-source self-driving car stack that Baidu is building.\n\nBaidu has invested heavily in self-driving cars and has rapidly become an important player in the ecosystem. They are already testing vehicles on their Beijing campus.\n\nTheir vehicles come in all shapes and sizes. Some of Baidu\u2019s vehicles look like Carla, Udacity\u2019s very own self-driving car.\n\nBut Baidu has 13 different types of self-driving vehicles, ranging from small cars to big trucks!\n\nBeyond autonomous vehicles, Baidu has a world-leading artificial intelligence group. In their lobby I got to play with one of their robots, which talked, snapped my photo, and walked around with me.\n\nThe Baidu team was also kind enough to arrange and host an on-camera interview for me, with CSDN, a Chinese software developer network.\n\nThe most important part of the visit, however, were the ping-pong matches. I played two matches and went 1\u20131 in my first international ping-pong competition. No photos, you\u2019ll have to take my word for it :-)"
    },
    {
        "url": "https://medium.com/udacity/artificial-intelligence-nanodegree-program-what-youll-learn-e9950bb8e8cc",
        "title": "Artificial Intelligence Nanodegree Program: What You\u2019ll Learn",
        "text": "What an incredible time of discovery and innovation this is! For the first time in history, we are pushing computer technology forward to the point where computers can develop abilities on par with humans \u2014 they can play complex games, accurately analyze and categorize images, and even understand spoken language.\n\nFor anyone interested in the history and future of Artificial Intelligence, the advances being made right now are simply astonishing. Best of all, more and more people are entering the field, bringing with them diverse perspectives, unique backgrounds, and powerful commitments to improving our world.\n\nBecoming a successful Artificial Intelligence practitioner means mastering the historical foundations of the field, even as you pursue the most future-facing possibilities. Every AI expert is grounded in the same core set of skills and techniques, and it\u2019s critical you learn these fundamentals as you build your AI career.\n\nThis is why we\u2019ve created the Artificial Intelligence Nanodegree Program \u2014 so that you can learn the most important Artificial Intelligence skills and techniques used in both industry and academia.\n\nThis is an ideal program for anyone interested in foundational AI knowledge, and it\u2019s especially beneficial if you\u2019re new to Artificial Intelligence, but have a working knowledge of mathematics, probability, and Python. In our new Artificial Intelligence Nanodegree Program, you\u2019ll learn the right tools to turn all this knowledge into a solid foundation in the field of Artificial Intelligence.\n\nBeing able to draw upon the right tool for the right challenge is so important in this field, and the last 50 years of AI research has produced dozens of key techniques that all AI experts continue to utilize. We\u2019re thrilled to offer a program that enables you to establish your AI toolkit in just 3 months!\n\nThe Artificial Intelligence Nanodegree Program is comprised of 7 sections.\n\nHere you\u2019ll meet the instructional team, including Sebastian Thrun, Peter Norvig, and Thad Starner, who will be teaching you about the foundations of AI. You\u2019ll get acquainted with the resources available in your classroom, and gather other important information about the program. In the project, you\u2019ll build a simple AI using Constraint Propagation and Search to solve Sudoku puzzles. You\u2019ll extend this to solve Diagonal Sudokus, and implement advanced Sudoku strategies such as the Naked Twins strategy.\n\nIn this section, you\u2019ll return to the techniques you used to solve Sudoku, as you explore how Constraint Satisfaction can be used to solve puzzles such as the map-coloring problem.\n\nHere, we\u2019ll cover Depth First Search, Breadth First Search, A* Search, and how to analyze heuristics. You\u2019ll get a chance to build a Pac-Man AI that finds the most efficient path through its world.\n\nIn this section, taught by Peter Norvig, you will learn how to build systems that can arrive at new, logical conclusions from a given set of facts. In particular, you\u2019ll explore First Order Logic, Propositional Logic, and how to use such logic to solve planning problems. In the project, you\u2019ll combine your knowledge of Logic, Planning, and Search, to implement a system that efficiently moves cargo from their origins to their destinations using the least number of flights. The system will use propositional logic to find a path to its goals given its start state and valid actions\n\nIn the fifth section, you\u2019ll learn the concept of iterative improvement problems, a widely used class of optimization techniques in AI. You\u2019ll learn about how to explore large state spaces using the biologically-inspired techniques of Simulated Annealing and Genetic Algorithms.\n\nGame playing is about teaching AI agents to act assuming a worst-case scenario \u2014 adversarial domains (ranging from Chess to Starcraft) in which other agents are directly working against your agent\u2019s goals. Agents can make better choices when they think about consequences before they act, which is fairly straightforward in classical search, but becomes much harder when an agent has to predict how the world will change when other agents can interfere. So game playing has been a focus of AI for decades, because the real world is an adversarial domain \u2014 even the simple example of route planning is \u201cadversarial,\u201d given that traffic and road construction have the potential to interfere with your travel. In this section, you\u2019ll start from the foundations of adversarial search by learning about minimax game trees, with optimizations like alpha-beta pruning, to dramatically improve results for your agent. For your project, you\u2019ll apply these ideas in the context of the game Isolation.\n\nIn this section, you\u2019ll start by learning Probabilistic Inference to calculate the probability of certain events occurring. We\u2019ll cover Bayesian Networks, Conditional Probability, and Bayes\u2019 Rule. This section is taught by Sebastian Thrun. Over the course of this section, you\u2019ll extend your knowledge of Bayesian Networks to cover Hidden Markov Models, where intermediate states can be unobserved. You\u2019ll be able to apply this knowledge to a well-known problem in Natural Language Processing: part-of-speech tagging. In the project, you\u2019ll build a Hidden Markov Model that, given a sentence, will be able to tag the parts of speech, such as noun and verb.\n\nUdacity offers you a wide array of support options to ensure you proceed through the program successfully. You\u2019ll have access to an AI expert through our Classroom Mentorship program, and you\u2019ll get detailed feedback on your project submission by one of our expert project reviewers. You\u2019ll be able to connect with your fellow students in the classroom by using our Chat feature. And, you\u2019ll join a Slack community where you can engage with our Community Manager, your fellow students, and even your instructors.\n\nWe are now accepting new students to the Artificial Intelligence Nanodegree program.\n\nThe program is comprised of a single 3-month term. The tuition for the term will be $799, paid prior to commencing your studies.\n\nTo learn more about the program, you can explore a Free Preview (but don\u2019t delay on enrollment, and miss your chance to save!). You\u2019ll meet your instructors, and even explore the lessons.\n\nThe world of AI is open to everyone, and this is your invitation to join. Come learn Artificial Intelligence, and start building your future career today!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-april-14-a248e9fe5fcc",
        "title": "Flying Car News, April 14 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Zipline\u2019s new generation of medical delivery drones, Festo\u2019s Flying Fox, NASA\u2019s TC3 UTM tests, AMSL Aero\u2019s Veri-plane, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nCalifornia startup Zipline, which has performed over 7000 blood delivery fights in Rwanda, has announced their 2nd generation of fixed wing delivery drones in their bid to provide high speed medical delivery for the planet.\n\nGerman automation company Festo has created a lightweight bionic flying fox using a flexible ultralight membrane, and machine learning, to mimic natural flight.\n\nNASA has completed their third testing stage out of four for their Unmanned Air System Traffic Management, in coordination with the FAA and industry.\n\nAustralian startup AMSL aero has demonstrated a \u2155 size prototype for their electric autonomous vtol called the Verti-plane.\n\nDrones were used by researchers to track caribou migration in the Canadian Arctic and learned new social behaviors of herds using computer vision technology.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-april-13-edition-d3c050f3a37b",
        "title": "This Week at Udacity, April 13 edition \u2013 Udacity Inc \u2013",
        "text": "One of the most exciting things to happen this week literally just happened! It was a new episode of Udacity Talks, with Sebastian Thrun as host, and featuring Kim Scott as special guest. Kim is the author of an incredible book entitled Radical Candor:\n\nHer conversation with Sebastian, and the questions she answers from viewers, make for a tremendously insightful episode, and you can watch it right here!\n\nPeople tuned in from all over the world for this wonderful episode\u2014Algeria, Norway, Portugal, South Korea, and more! If for no other reason than this, you HAVE to check in just to hear Kim deliver her reprimands of Sebastian\u2019s lateness to the interview (true story!) in the styles of \u201cRuinous Empathy,\u201d Manipulative Insincerity,\u201d \u201cObnoxious Aggression,\u201d and \u201cRadical Candor.\u201d Here\u2019s \u201cRuinous Empathy\u201d:\n\nIn other news, Luis Serrano, Curriculum Lead for the Artificial Intelligence Team at Udacity, took readers on a fascinating deep dive into what students of the new Natural Language Processing Nanodegree program can expect from the groundbreaking curriculum:\n\nWhile over in Careers country, we got our Zen on!\n\nAnd now, it\u2019s time for everyone\u2019s favorite part of the week!\n\nHow great is this?\n\nAnd THAT \u2026 is this week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-april-12th-2018-75240334840d",
        "title": "This Week in AI, April 12th, 2018 \u2013 Udacity Inc \u2013",
        "text": "A team from Berkeley developed an AI system that learns by imitating motion-capture data from humans. The agents can do flips, cartwheels, throw baseballs, walk on narrow paths, and much, much more. The behaviors learned by imitation can be combined with goals, such as throwing baseballs at specified locations.\n\nTypically, agents trained with reinforcement learning find solutions with strange artifacts such as jittering and flailing body parts. By imitating humans, these agents are able to learn much more realistic behaviors which transfer well to real-world applications.\n\nA team from Cornell University and Adobe Research developed a deep learning model that can seamlessly composite images into paintings. For example, here\u2019s Benedict Cumberbatch pasted into a classical painting, it\u2019s beautiful.\n\nI\u2019m really excited to see deep learning models show up in photo editing software like Adobe. There are tons of applications for this technology we haven\u2019t even thought of yet. It\u2019s great to see companies like Adobe driving research into the applied side of deep learning.\n\nJanelle Shane, who famously generated the best paint names, completed a new project bringing deep learning to knitting. Shane fed real knitting instructions into a neural network, which was then able to produce something that resembled knitting instructions. Neural networks tend to generate language that looks real, but is actually nonsense. Many of the knitting instructions generated from Shane\u2019s model were literally impossible to build, but the knitters didn\u2019t let that stop them from creating fun objects.\n\nHere\u2019s another great reflection on training deep reinforcement learning agents. Matthew Rahtz attempted to reproduce a deep reinforcement learning paper and found it was much more difficult than expected. Overall it took Rahtz 8 months (and about $850) to successfully implement the paper. Lots of really great insights to be learnt here.\n\nOpenAI\u2019s mission is to ensure artificial intelligence is used for the benefit of everyone. This week, the non-profit company released a charter to guide their work. In the charter, they emphasize distributed benefits, long-term safety, cooperation, and technical leadership. I personally believe that artificial general intelligence (AGI) is still a long way off, but biased AI systems are already negatively affecting society. The work of OpenAI and other groups can help AI benefit all of us, and prevent abuses.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of the programs from our School of AI:"
    },
    {
        "url": "https://medium.com/udacity/udacitys-self-driving-european-tour-fe32b50c69cf",
        "title": "Udacity\u2019s Self-Driving European Tour \u2013 Udacity Inc \u2013",
        "text": "A few weeks ago, I had the delight of visiting Europe with Udacity\u2019s Berlin-based European team, meeting both automotive partners and Udacity students. The trip was so much fun!\n\nWe started in Stuttgart, where we met with our partners at Bosch and toured their Abstatt campus. Their campus reminds me of a plush Silicon Valley office, except instead of overlooking Highway 101, they overlook vineyards and a European castle.\n\nThanks to Udacity student Tolga Mert for organizing!\n\nIn the evening, Bosch\u2019s Mirko Franke joined us at the Connected Autonomous Driving Meetup, organized by Udacity student Rainer Bariess.\n\nWe discussed the self-driving ecosystem and, of course, how to get a job working on self-driving cars at Bosch.\n\nThe next day we headed to Berlin to prepare for our deep learning workshop at Automotive Tech.AD. What a great collection of autonomous vehicle engineers from companies across Europe!\n\nIn the evening we hosted a Meetup for current and prospective Udacity students at our Berlin office. It is always a delight to meet students and hear firsthand what they love about Udacity, and how they feel we can improve the student experience.\n\nOur final stop was London, for an interview with Alan Martin at Alphr.\n\nThat evening, Udacity alumnus Brian Holt, Head of Autonomous Driving at Parkopedia, hosted us for at the London Self-Driving/Autonomous Car Technology Meetup. We had a blast talking about the future of self-driving (and even flying!) cars.\n\nWe learn what our students are working on, what excites them about self-driving cars, and about the difference Udacity has made in their lives. It\u2019s wonderful!\n\nIf you\u2019re interested in becoming a part of our global Self-Driving Car community, consider enrolling in one of our Nanodegree programs. No matter your skills and experience, we\u2019ve got a program for you!"
    },
    {
        "url": "https://medium.com/udacity/natural-language-processing-nanodegree-program-what-youll-learn-2eabd3cb10f7",
        "title": "Natural Language Processing Nanodegree Program: What You\u2019ll Learn",
        "text": "Natural Language Processing (NLP) represents one of the great technological breakthroughs in all of human history. For the first time, computers are developing the ability to understand human language as we speak it, and the implications are staggering.\n\nAs a democratizing influence, it\u2019s almost impossible to conceive of the potential impact Natural Language Processing can have. Think of all the valuable information there is housed on the world\u2019s computers, and then consider how difficult it has historically been for most people to access that information. Using NLP, accurate and meaningful information extraction becomes as simple as asking a question.\n\nAs a unifying force, Natural Language Processing has the ability to connect people and cultures in remarkable ways, because it can be used to solve formidable translation challenges. Imagine representatives from different countries hammering out global initiatives at the political table, able to rely on Natural Language Processing to ensure accurately translated communication in real time!\n\nNatural Language Processing is an amazingly flexible and effective tool for knowledge capture of all kinds. Imagine a world where doctors can dictate real-time patient analyses directly into a system, and have those details automatically stored for future retrieval. Consider the biologist in the field, who is able to describe observed phenomena for digital posterity with full accuracy. Consider the business that is able to capture every customer conversation, analyze them for relevant value, and archive them for future product-related reference.\n\nNatural Language Processing is a true revolution. It is admittedly early days, but as computers get faster and better, and as our understanding of machine learning algorithms gets stronger, there is no limit to where we can take this technology!\n\nAs a specialist in the field of Natural Language Processing, you will help shape the future, and define our relationship not just to technology, but to one another.\n\nFrom a career standpoint, you couldn\u2019t pick a better time to start mastering NLP skills. According to a recent report by Tractica, the Natural Language Processing market will reach $22.3 billion by 2025. The opportunities in this field are simply incredible. That\u2019s why we created the Natural Language Processing Nanodegree program. So that you have the skills and experience to enter this field, and take advantage of all this opportunity.\n\nIf you\u2019re new to Natural Language Processing, but you have a working knowledge of machine learning, deep learning, and Python, the Natural Language Processing Nanodegree program is ideal for you. You\u2019ll learn all the skills and techniques necessary to obtain a solid background in Natural Language Processing, and you\u2019ll become an expert in its main components, including speech recognition, sentiment analysis, and machine translation. You\u2019ll learn to code probabilistic and deep learning models, train them on real data, and build a career-ready portfolio as an NLP expert.\n\nThroughout the program, you\u2019ll be working with curriculum built in collaboration with IBM Watson and Amazon Alexa!\n\nThe Natural Language Processing Nanodegree program is comprised of 3 sections.\n\n1. Introduction to Natural Language Processing\n\nThis is where you learn the basics of Natural Language Processing. You\u2019ll discover ways to process text, including lemmatization and stemming, alongside several other techniques. You will also learn probabilistic methods such as hidden Markov models, and will be able to apply them to process language.\n\nAt the end of the lesson, you\u2019ll have a project to complete, in which you\u2019ll put all your newfound knowledge into practice, by building a model that tags words in a sentence with their corresponding parts of speech. You will start with a simple lookup table, and progressively add more complexity to improve the model using probabilistic graphical models. Ultimately you\u2019ll be using a Python package to build and train a tagger with a hidden Markov model, and you will be able to compare the performances of all these models in a dataset of sentences.\n\n2. Computing with Natural Language Processing\n\nHere, you\u2019ll learn some of the most exciting models used in Natural Language Processing. You\u2019ll cover everything from feature extraction and embeddings, to topic modeling, sentiment analysis, and deep learning attention mechanisms.\n\nFor your project, you\u2019ll build a deep neural network that functions as part of an end-to-end machine translation pipeline, using recurrent neural network architectures. Your completed pipeline will accept English text as input and return the French translation. First you will preprocess the data by converting text to sequence of integers. Then you will build several deep learning models for translating the text into French. As a final step, you will run this models on English test to analyze their performance.\n\n3. Communicating with Natural Language Processing\n\nIn the final section, you\u2019ll get an overview of Voice User Interfaces (VUI), focus on conversational AI, and learn how Alexa operates. Then you\u2019ll dive deeper into the exciting field of Speech Recognition, learning Signal Analysis and Phonetics, single word classification using Dynamic Time Warping, and sentence recognition using Hidden markov Models. You\u2019ll explore the cutting edge of Automatic Speech Recognition, leveraging deep neural networks, and you\u2019ll also have the chance to build an Alexa skill in a lab.\n\nFinally, in the concluding project, you\u2019ll have the chance to build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline. Your completed pipeline will accept raw audio as input and return a predicted transcription of the spoken language. You\u2019ll begin by investigating a dataset, that will be used to train and evaluate your models. Your algorithm will first convert any raw audio to feature representations that are commonly used for ASR. You will then build neural networks that map these features to transcribed text.\n\nUdacity offers you a wide array of support options to ensure you proceed through the program successfully. You\u2019ll have access to an AI expert through our Classroom Mentorship program, and you\u2019ll get detailed feedback on your project submission by one of our expert project reviewers. You\u2019ll also join a Slack community where you can engage with our Community Manager, your fellow students, and even your instructors.\n\nWe are now accepting new students to the Natural Language Processing Nanodegree program.\n\nThe program is comprised of a single 3-month term. Enroll by April 10, 2018, so you\u2019ll be able to enjoy big savings on your tuition!\n\nTo learn more, you can also explore a Free Preview of our program (but don\u2019t delay on enrollment, and miss your chance to save!). You\u2019ll meet your instructors, and explore the lessons.\n\nThrough our School of Artificial Intelligence, the world of AI is open to everyone, and the opportunity to specialize in the incredible field of Natural Language Processing is yours when you enroll in this unique program. Come learn Natural Language Processing, and start building your future career today!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-april-6-edition-c7f63a68ef9f",
        "title": "This Week at Udacity, April 6 edition \u2013 Udacity Inc \u2013",
        "text": "Intelsat I, informally knows as \u201cEarly Bird,\u201d launched on this day in 1965, as the first commercial communications satellite to be placed in geosynchronous orbit. As this was happening, Black Francis, future lead singer of alternative rock icons The Pixies, was being born.\n\nAnd speaking of \u201claunches,\u201d with our new School of Artificial Intelligence now officially in orbit, we can start sharing details with you about new programs on offer.\n\nWe began this week with a deep dive into our new AI Programming with Python Nanodegree Program, from curriculum lead Ortal Arel; you can read her amazing post here:\n\nWe counterbalanced these detailed curricular insights with a wonderful post from Mat Leonard, who heads up the School of AI, in which he covers some critical AI basics:\n\nAnd speaking of \u201calternative,\u201d we had the pleasure of highlighting a student this week who, after landing what was supposed to be his dream job, realized that he was altogether in the wrong role after all. Instead of giving up and giving in, he forged ahead with an alternative vision for his life, and built a whole new career for himself!\n\nQuestion for you, are you following us on Facebook? I hope so, as it\u2019s a great place to stay on top of exciting announcements. For example, some tremendous news this week for committed lifelong learners in Africa!\n\nAnd speaking of social media, we\u2019re at the point in the post when we come to the \u2026\n\nWe\u2019re going with this one, because we just can\u2019t resist heart eyes:\n\nThank you for learning with us!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity. His favorite Pixies song is \u201cMonkey Gone to Heaven.\u201d"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-april-5th-2018-2d5fcadcda91",
        "title": "This Week in AI, April 5th, 2018 \u2013 Udacity Inc \u2013",
        "text": "Researchers at DeepMind built an AI system that can navigate cities without using maps. Instead, it uses landmarks and remembers turns like humans do. Traditional navigation requires maps to be loaded beforehand. This system can potentially be deployed anywhere, and immediately find it\u2019s way around.\n\nAndrew Ng, famed Stanford professor and former Chief of AI at Baidu, is writing a book about structuring machine learning projects. From the website:\n\nLooks like this could be interesting for someone wanting to build machine learning applications.\n\nThis week, the TensorFlow team at Google announced that the deep learning framework will soon be available in JavaScript and Swift. This should make it easier to deploy machine learning models in the browser and on iOS. It\u2019s great to see deep learning frameworks expanding to more languages and platforms so that developers of all sorts can have access to the power of machine learning.\n\nOpenAI has opened a challenge and released a new set of environments to advance reinforcement learning research. The goal of the challenge is to train an agent on one level of a SEGA Genesis game, then have it perform as well as possible on another level of the same game. Currently, most agents are tested in the same environment they were trained in. This challenge is about designing agents that are able to transfer what they\u2019ve learned from one level to the next.\n\nA fund for AI projects, AI Grant, is accepting applications. The grant provides $2,500 in cash and $20,000 in GPU credits for your open source project. Apply today!\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of the programs from our School of AI:"
    },
    {
        "url": "https://medium.com/udacity/creating-map-animations-with-python-97e24040f17b",
        "title": "Creating Map Animations with Python \u2013 Udacity Inc \u2013",
        "text": "For last week\u2019s Intersect 2018 conference, I created a map visualization that was shown during the keynote speech from Vish Makhijani, Udacity\u2019s CEO. The visualization highlighted the explosive growth of graduates from our Nanodegree programs over the last year. Below you can see the animation playing behind Vish for about 20 seconds during his speech.\n\nAnimations like these are extremely powerful for telling stories that evolve across time.\n\nThe visualization I created highlights not just the overall number of alumni, but also the geographical distribution of our students. For example, Artificial Intelligence was massively popular in China, Japan, and India, while the School of Business (including our Data Analyst and Digital Marketing Nanodegree programs) exploded in Brazil. It was a fun project for me and I wanted to share how I built it, so you can use these techniques and approaches in your work.\n\nMy general strategy was to generate an image for each day in the dataset, then convert all those images into a video. To do this, I used Python and a few packages: Pandas, for loading and manipulating the data, Cartopy, for drawing the map, and Matplotlib, for plotting the data. After generating all the images, I used ffmpeg to combine the individual frames into the video you see above.\n\nBelow, I\u2019ll detail how I created this video so you can do the same in your projects. First off, I\u2019ll import the necessary packages.\n\nThe dataset I used consisted of four columns:\n\nI loaded the CSV file with Pandas and named each column appropriately. The graduation dates are read in as strings so I converted them to objects with .\n\nOnce I had the data, I created a figure and an axis with matplotlib using a figure size of 19.2 x 10.8 inches. I wanted the final video to have a resolution of 1920 x 1080 so I chose this size and saved the figures at 100 DPI (dots per inch). I created the axis using the Mercator projection with Cartopy.\n\nA projection is how you transfer the surface of the Earth (a sphere) to the flat plane of a map. There\u2019s no perfect way to accomplish this, so I stuck with the Mercator projection which is often seen in U.S. schools and apps like Google Maps. From there I added the background map image, taken from NASA\u2019s Blue Marble set, and defined the part of the map to display with . Also note that I used a low resolution image here\u2014this speeds up developing the code. When I was ready to generate the frames for the video, I used the full resolution background image.\n\nWe can use latitudes and longitudes, but Cartopy needs to know how to convert those to the appropriate locations on the map. For that, I used the projection. I\u2019ll use the same projection later in the code to place data points and text. At that point, I had the basic map which I can start adding to.\n\nOnce I had the map, I started adding data to it. I wanted each image to show the map background as well as dots indicating the location of students who graduated before some date. I set a date with (December 31st, 2017 for example) and got all the graduations before that date.\n\nWith the graduation data, I looped through each school and placed a dot indicating the location. I also wanted the size of the dot to indicate the number of graduates at that location. To do that, I used which groups by longitude-latitude pairs and counts up the number of graduates for each pair.\n\nWith the data plotted, it was time to add text for the date, the number of graduates, and labels matching colors and schools.\n\nWith the code to generate a single image, I can put it all in one function and loop through all the dates I\u2019m interested in, calling that function for each date.\n\nWhen I first wrote this I was creating a new figure and axis in each loop. However, this led to the memory usage exploding. Instead, I cleared the axis at the end of each loop with then replotted the map and data on the same axis.\n\nAfter generating all the images, I treated them like frames in a movie. There are a lot of different software options for converting images into a movie, I chose ffmpeg. I set the frame rate such that the video came out 20 seconds long and at 1920x1080 resolution.\n\nI hadn\u2019t worked with map data before this so it was a great learning experience for me. I actually started this project using Basemap instead of Cartopy to generate the map. However, Basemap isn\u2019t being supported anymore and doesn\u2019t work with the newest versions of Matplotlib. I had to change a few lines of code in the Basemap package to generate the video. After making the video, I ended up rewriting the map code with Cartopy for this blog post."
    },
    {
        "url": "https://medium.com/udacity/https-medium-com-udacity-ai-programming-with-python-nanodegree-program-what-youll-learn-eba80cb2de1e",
        "title": "AI Programming with Python Nanodegree Program: What You\u2019ll Learn",
        "text": "We are at an amazing point in history. We are witnessing the emergence of one of the most incredible technologies we have ever known. Artificial Intelligence is already advancing so many fields, and the best is yet to come. Today, you have the opportunity to journey into this fascinating world, master valuable skills, and not only build a career, but help influence the ways we apply all that AI makes possible.\n\nFrom a career standpoint, you couldn\u2019t pick a better time to start mastering AI skills. According to a recent Gartner report, AI-enabled tools will generate $2.9 trillion in business value by 2021. This means there is incredible opportunity out there that is literally yours for the taking.\n\nAI can seem infinitely complex, but no matter your level of knowledge or experience, there is a point of entry that is just right for you. We built our School of Artificial Intelligence \u2014 the world\u2019s first comprehensive AI learning program online \u2014 to ensure that every single person who wants to be a part of this amazing world, can.\n\nIf you\u2019re new to Artificial Intelligence, Python is where you want to start, and our new AI Programming with Python Nanodegree program is the right program for you. Prerequisites are minimal \u2014 only basic algebra and basic calculus skills are needed. Anyone with or without programming experience can enroll, though having some programming experience will help you complete the program with more ease.\n\nThrough our AI Programming with Python Nanodegree program, you\u2019ll learn all the skills necessary to obtain a solid background in programming, math, and deep learning. This in turn will enable you to become a future expert in almost any aspect of AI.\n\nThe core focus of this program is Python \u2014 one of the most widely-used programming languages in AI. We will focus on key library packages for Python, such as Pytorch (the most useful open-source machine learning library for Python). Neural networks are also central to the curriculum. They are the fundamental building blocks of modern AI systems. In our program you\u2019ll learn the math skills necessary to understand how to design and build these networks. You\u2019ll further learn how a neural network functions and how to train it. We will particularly focus on deep neural networks, as they are the driving force behind most modern AI systems.\n\nBy the end of this program you\u2019ll be able to build your own AI application \u2014 an image classifier \u2014 using a deep neural network that you\u2019ll have trained by yourself!\n\nThe AI Programming with Python Nanodegree program is comprised of 4 sections.\n\n1. Introduction to Python\n\nThis is where you learn Python. You\u2019ll discover why Python is unique, and come to understand the data types and operators it handles. You\u2019ll learn to use its built-in functions, and write your own functions to encapsulate a series of commands. At the end of your lesson, you\u2019ll encounter a lab where you\u2019ll learn how to use a pre-trained image classifier to write a script that identifies dog breeds.\n\n2. Jupyter Notebooks, Anaconda, Numpy, Pandas, and Matplotlib\n\nHere, you\u2019ll learn how to use Jupyter Notebooks to create documents combining code, text, images, and more. You\u2019ll be introduced to Python library packages such as: Anaconda (an environment manager built specifically for data), Numpy (to add support for large data), Pandas (used for data manipulation and analysis) and Matplotlib (which is used for data visualization).\n\n3. Linear Algebra Essentials\n\nThis is where you will experience the beautiful visual world of Linear Algebra firsthand, and discover why it\u2019s such an important mathematical tool in the world of AI. You\u2019ll learn about vectors, matrices, linear combinations, and linear transformations. You\u2019ll ultimately combine your new programming skills with visual linear algebra labs.\n\n4. Neural Networks\n\nIn this final section, you\u2019ll complete the process of establishing your solid foundation in deep learning and neural networks. You\u2019ll learn about techniques for improving the training of a neural network, and how to use PyTorch for constructing deep learning models.\n\nUdacity offers you a wide array of support options to ensure you proceed through the program successfully. You\u2019ll have access to an AI expert through our Classroom Mentorship program, and you\u2019ll get detailed feedback on your project submission by one of our expert project reviewers. You\u2019ll be able to connect with your fellow students in the classroom by using our Chat feature. And, you\u2019ll join a Slack community where you can engage with our Community Manager, your fellow students, and even your instructors.\n\nIt is only recently that deep neural networks have been shown to recognize images as well as we humans do. A short while ago, these were just dreams in the minds of innovators still wrestling with seemingly impossible challenges. But today, with the skills you master in our program, you\u2019ll be able to do this yourself!\n\nBy the end of our program you\u2019ll be ready to take the next steps. You will be familiar with the concepts and ideas needed to become an AI expert.\n\nIf you want to learn more about deep learning, our Deep Learning Nanodegree program is a great next step on your AI journey. We cover key topics such as recurrent neural networks and convolutional neural networks. Once you complete this program, you\u2019ll be able to teach a quadcopter how to fly!\n\nOur School of Artificial Intelligence offers many other programs for you to choose from, including Machine Learning, Computer Vision, Natural Language Processing, Self-Driving Cars and Flying Cars, and many more.\n\nWe are now accepting new students to the AI Programming with Python Nanodegree program.\n\nThe program is comprised of a single two-month term. The tuition for the term is $399, paid prior to commencing your studies.\n\nTo learn more, you can also explore a Free Preview of our program (but don\u2019t delay on enrollment, and miss your chance to save!). You\u2019ll meet your instructors, and explore the program\u2019s lessons. You\u2019ll even have the opportunity to experiment with our programming tools.\n\nThe world of AI is open to everyone, and this is your invitation to join. Come learn Python, the language of AI, and start building your future career today!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-march-31-50923e15f90a",
        "title": "Flying Car News, March 31 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: The launch of Udacity Universe, a massive collaborative simulation environment; Aeromobil\u2019s sporty new flying car concept; the largest commercial drone order ever; and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nAt the Intersect 2018 conference this week, Udacity announced Udacity Universe, a massive shared simulation environment for flying cars and self-driving cars, created in collaboration with Unity, Zipline, WRLD, and the Dubai Future Foundation.\n\nAeromobil, a flying car company based out of Slovakia, unveiled their sporty 5.0 VTOL flying car concept to complement their previously announced 4.0 STOL concept.\n\nTop Chinese drone manufacturer DJI and drone image processing platform Skycatch have reached an agreement with smart construction company Komatsu to deliver 1000 custom industrial drones for autonomous construction site mapping and surveying.\n\nThe Oregon-based Samson Sky Switchblade flying car, which already has over 600 order reservations and retails for $140,000, will begin road tests by the end of March; its first public test flight will be this summer; and they will start deliveries by the end of the year.\n\nAmazon has been granted for drones that can respond to human gestures or voice commands. An example in the patent included a person yelling and waving frantically to try and control the drone.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-march-30-edition-b0aaf856311d",
        "title": "This Week at Udacity, March 30 edition \u2013 Udacity Inc \u2013",
        "text": "Hard as it is to believe, Intersect 2018 has come and gone. But as noted in one of many posts written about the event:\n\nTuesday\u2019s Intersect 2018 event actually kicked off the night before, with an amazing Alumni VIP event at The Google Garage:\n\nAs to Intersect 2018 itself, we\u2019re going to expand our Tweet of the Week feature a bit, in order to give you a snapshot of the experience. Here are just some of the amazing tweets published during the conference:\n\nIt\u2019s testament to the absolutely unstoppable passion of our Udacity teams that literally the day after Intersect, our Robotics and School of AI teams were hitting the ground running. If you\u2019ve ever wanted to wire up a real robot and teach it how to learn, here\u2019s how it\u2019s done!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-march-29th-2018-ea934317dbdc",
        "title": "This Week in AI, March 29th, 2018 \u2013 Udacity Inc \u2013",
        "text": "An race to build hardware for deep learning is starting to heat up. So far, GPUs have provided the computational power necessary for deep learning models, but GPUs are designed for graphics. Chips built specifically for deep learning will improve performance and lead to more innovation. A lot of companies are betting on these chips including Google, Intel, and many more. This week, NVIDIA and ARM announced a partnership that will bring deep learning processors to the Internet of Things.\n\nIn some truly amazing work, researchers at Google Brain trained an agent that can learn from it\u2019s own dreams! The model learns to perform actions in an environment, such as driving on a race track, while also learning to represent that environment. From this representation, it can \u201cdream up\u201d images to use as information for the agent in place of images from the actual environment. Below is an example of an agent playing in a hallucination of a Doom level. (Hot tip: Twitter is the best way to stay up-to-date with deep learning and AI.)\n\nThe authors built a great interactive exploration of their model. Also, this is one of the best deep learning articles I\u2019ve ever read!\n\nJoy Buolamwini from the MIT Media Lab studied the performance of various facial recognition products on predicting gender from face images. She found that across services from Microsoft, IBM, and Face++, performance was worse for women than for men, and for darker-skinned subjects than for lighter-skinned subjects. Darker-skinned women fared the worst, with IBM and Face++ only achieving 65% accuracy. This is a trend across many machine learning systems. The danger is in the assumption that AI systems like these are neutral since they are just machines and can\u2019t be biased. But, humans built these systems and humans are biased. As AI powers more and more of our world, we\u2019ll need to remain diligent to ensure everyone receives the benefits.\n\nAlong with China investing heavily in AI, France is betting on AI to drive the global economy in the future. This week, the government announced an initiative to make the country a world leader in artificial intelligence research. The proposal includes new labs from DeepMind and Samsung, as well as an expansion of Fujitsu\u2019s research center. Along with more investment from Google and Facebook, France is in a great position to capitalize on the AI revolution.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of the programs from our School of AI:"
    },
    {
        "url": "https://medium.com/udacity/heard-at-udacity-intersect-2018-2501bb151407",
        "title": "Heard at Udacity Intersect 2018! \u2013 Udacity Inc \u2013",
        "text": "Udacity\u2019s COO Clarissa Shen opened the proceedings with brief remarks, and a wave to the cameras providing our livestream to listening parties in Berlin, Cairo, and London!\n\nWe\u2019re at the halfway point of #Intersect2018, and I\u2019m already full-to-the-brim with incredible insights, and feeling so inspired!\n\nWhat an extraordinary day today has already been!\n\nVish Makhijani, Udacity CEO, then took the stage to deliver the opening keynote. His speech was an epic journey, beginning in war-torn India, and culminating in a career committed to helping learners around the world achieve their dreams.\n\nHe made some incredible announcements as well, about new offerings from Udacity. Full details are available here:\n\nYou can also read about the new announcements in these articles:\n\nTo get a feel for what the KUKA Udacity Robot Learning Lab at KIT and Udacity Universe experiences will offer students, please enjoy these previews!\n\nI was sitting in the back of the room during Shiza Shahid\u2019s keynote, so I can\u2019t actually confirm the lack of dry eyes in the house, but I\u2019d be surprised if there were any \u2014 her words were so powerful. She was so gracious to the audience as well, and so genuine in her care and interest for the futures of those gathered.\n\nThe extent to which she was willing to share her personal story was perhaps most moving of all, and she stands as a living embodiment of one of her most moving statements:\n\nAs the conference segued into the panel discussions, watching social media feeds offered us a gratifying referendum on the actionable value on offer \u2014 so many great quotes, memories, and moments being shared!\n\nI\u2019m admittedly supposed to be \u201cworking\u201d this event, but I\u2019m certainly not above simply being a fan as well! Some of my personal favorite moments:\n\nThere are still many inspiring hours and experiences to come, so please tune in to the livestream, and track #UdacityIntersect on social to stay up on all the latest!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-march-24-87672f79ad5c",
        "title": "Flying Car News, March 24 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Walmart patents autonomous robot bees, an origami drone arm, Nasa considering using a drone on Mars, a heavy duty turbine-cleaning flying robot, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nWalmart has applied for six patents related to new drone technology for applications in agriculture in a bid to compete with Amazon for dominance of the grocery market.\n\nScientists from Seoul National University in South Korea have developed a folding robotic arm that drones can use to pick up objects in small openings.\n\nEngineers at the Jet Propulsion Laboratory have created an autonomous helicopter that is being considered to launch with the Mars Rover in 2020.\n\nY Combinator startup Aerones is developing heavy duty drones with 28 motors and 16 batteries which can carry up to 400 pounds, and which will be used for industrial applications from cleaning turbines and buildings to surveying wildlife and performing construction inspections.\n\nAmazon has received a patent for airbags, which will be used to protect packages that are dropped from heights of 5 to 25 feet by delivery drones.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-march-23-edition-a393b5fa5cea",
        "title": "This Week at Udacity, March 23 edition \u2013 Udacity Inc \u2013",
        "text": "Intersect 2018 is officially sold out! We are SO excited to welcome everyone next week! Time to get on \u2026 The Road to Intersect!\n\nAnd speaking of The Road to Intersect, we published two more great interviews this week:\n\nAline and Trae are just two of the many incredible speakers who\u2019ll be on hand to share insights with our guests.\n\nIf you got a ticket in time, then THIS is a post you\u2019ll DEFINITELY want to read:\n\nAnd speaking of making the most of things, here\u2019s a remarkable story about a remarkable group of lifelong learners who REALLY made the best of an opportunity:\n\nAnd speaking of opportunities, did you read this week\u2019s edition of This Week in AI, from Mat Leonard?\n\nIf you did, you\u2019ll know that the Reinforcement Learning team at Udacity is looking for an intern! And if you didn\u2019t read the article \u2026 well \u2026 better do it now!\n\nAnd speaking of Artificial Intelligence, why, here\u2019s a graduate from our AI Nanodegree program!\n\nAnd speaking of great posts on LinkedIn, this has to be one of my favorite quotes from a graduate about their experience:\n\nAnd that brings us to \u2026\n\nCan\u2019t help but pick this one, because it\u2019s such a perfect example of the lifelong learning ethos:\n\nNote, \u201cgraduation from my FIRST nanodegree\u201d program. Love it!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-march-22nd-2018-77e8c2b591dc",
        "title": "This Week in AI, March 22nd, 2018 \u2013 Udacity Inc \u2013",
        "text": "One limitation of artificial neural networks is that the architecture of a network is determined by the engineer building it. A given architecture is not necessarily the best architecture. We have tools for optimizing a network once it\u2019s designed, but how do we find the best design? A team at Google used evolutionary methods by mutating and combining neural networks. This allowed them to find state-of-the-art architectures for computer vision problems.\n\nAs I\u2019ve noted before, a lot of research is being performed on interpreting the inner working of neural networks. A team at DeepMind explored the impact of individual neurons by deleting them from a network and testing the resulting performance. It turns out that easily interpretable neurons, such as a neuron that specifically likes cats, aren\u2019t any better than neurons that appear to respond randomly. I find this interesting because we\u2019re putting in a lot of work to interpret what these neurons are doing, but it seems like it doesn\u2019t matter if humans can understand them or not.\n\nThe Magenta team at Google released more amazing work using machine learning to create music. They developed a model that can realistically and smoothly combine musical phrases for individual instruments, as well as generate multiple instruments playing together. The results sound like they were written by humans.\n\nAmazon is investing heavily in Alexa, the voice recognition system used in products like the Echo. As reported in this article from Forbes, Amazon is hiring more developers for Alexa than Google is hiring for all of it\u2019s teams. Amazon is positioning Alexa as the operating system for the home. It\u2019s showing up on platforms such as TVs and stereos and the ecosystem of programs on Alexa (called \u201cskills\u201d) is ever expanding.\n\nUnity\u2019s reinforcement learning research team is looking for an intern. They recently released version 0.3 of ML-Agents, a toolkit for training reinforcement learning agents in Unity environments. The team is doing a lot of really exciting work around multi-agent training and memory. You could be a part of it!\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-march-17-2718c852ecce",
        "title": "Flying Car News, March 17 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Larry Page\u2019s Kitty Hawk unveils flying car, Audi and Airbus collaborate on concept flying car, Switzerland to test UTM with Skyguide and Airmap, Pal-V flying car designed finalized, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nGoogle cofounder Larry Page\u2019s Flying car company Kitty Hawk has unveiled their flying car, named \u201cCora.\u201d The aerial taxi project which was previously in stealth mode under the name Zee.aero, and Zephyr Airworks is partnering with New Zealand to launch their air mobility service.\n\nAudi has partnered with Airbus on their Pop.up Next flying car concept, and they showed off a prototype at this year\u2019s Geneva International Auto Show.\n\nSwiss air traffic operating company Skyguide is partnering with Californian software company Airmap to integrate drones with the Swiss air traffic management system.\n\nFlying car company Pal-V showed off their production flying Car Liberty for the first time at the Geneva International Auto show.\n\nFord has filed a patent which would allow drones to augment sensors on self-driving cars.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-march-16-edition-96c33b5e7371",
        "title": "This Week at Udacity, March 16 edition \u2013 Udacity Inc \u2013",
        "text": "This was the week we launched our \u201cI Keep Learning Because_____\u201d campaign, and we\u2019ve been seeing some AMAZING responses. I wish we could give EVERYONE who responded a free Intersect ticket, but alas, just 10 lucky winners will win the coveted prize. Still, these answers!\n\nYou can see more of the beautiful tweets we\u2019ve collected here:\n\nAnd speaking of #StudentSuccess, did you read this story?\n\nWhat an incredible lifelong learner Anna is, and such powerful force in a world that needs strong voices like hers:\n\nAnd speaking of breaking down the walls of bias, Udacity\u2019s Mat Leonard, who heads up our School of AI, shared a really interesting story yesterday in his weekly This Week in AI column:\n\nIt\u2019s becoming apparent that AI systems are often biased, resulting from biased data, incomplete testing, and other issues. As these systems become more prevalent in our daily lives, we\u2019ll need to understand where these biases come from, and how to avoid them. Recognizing this need, DeepMind has created a new research team devoted to fairness in AI.\n\nBut let\u2019s get back to the tweets, right? Because it\u2019s time for \u2026\n\nI think we\u2019re going for this one. Yep, this one. Because, why SHOULD your learning goals be any less than saving the world?\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-march-14th-2018-e678ec9d10fc",
        "title": "This Week in AI, March 15th, 2018 \u2013 Udacity Inc \u2013",
        "text": "The Magenta team at Google has been working on the intersection of machine learning and art. Last year they released an AI that plays piano with you. The team just released an open source project for building a synthesizer that combines instrument sounds \u2014 the tones and timbre \u2014 using machine learning. These instruments are completely novel and greatly expand the sounds musicians can use in their art.\n\nA major issue with deep neural networks is the opaqueness of their inner workings. In many cases these networks are black boxes, it\u2019s almost impossible to interpret how they make decisions. To address this, the team at Distill developed a framework for understanding how a neural network views the world which you can explore yourself in this amazing interactive article.\n\nMachine learning is continuing to be used in amazing ways across all disciplines\u2014this time, in astronomy. Using data collected from hundreds of thousands of stars by the Kepler project, researchers trained a machine learning model to detect extrasolar planets. The model searched 670 stars and found two previously undetected planets.\n\nIt\u2019s becoming apparent that AI systems are often biased, resulting from biased data, incomplete testing, and other issues. As these systems become more prevalent in our daily lives, we\u2019ll need to understand where these biases come from, and how to avoid them. Recognizing this need, DeepMind has created a new research team devoted to fairness in AI.\n\nOne way to tackle the \u201cBias in AI\u201d problem is to ensure that the teams building the AI systems are diverse. Having a variety of backgrounds and experiences in the team helps eliminate blindspots that can lead to biased AI. OpenAI is addressing this through its scholars program, providing stipends for individuals from underrepresented groups to study deep learning.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/5-unorthodox-ways-to-celebrate-pi-day-be3f27305c70",
        "title": "5 Unorthodox Ways to Celebrate Pi Day \u2013 Udacity Inc \u2013",
        "text": "Yes, I had pie for breakfast. Let\u2019s get that out of the way right now. Montmorency Sour Cherry Pie, to be specific.\n\nIf you REALLY want to get into Pi Day, you need to take the road less traveled. So here are 5 Unorthodox Ways to Celebrate Pi Day!\n\nIf you REALLY want to make the Pi Day hall of fame, see if you can combine all the above simultaneously! The possibilities are endless. (See what I did there?)\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/i-keep-learning-because-7debd816dd44",
        "title": "I Keep Learning Because _____ \u2013 Udacity Inc \u2013",
        "text": "We took to Twitter today for what we thought would be a fun and inspiring way to give 10 people tickets to our Intersect 2018 conference.\n\nIt was just a simple prompt \u2026\n\nWe were hopeful we\u2019d receive some great responses. Little did we know how powerful those responses would be \u2026 Like this one, from Yana Lustina in Chicago, Illinois:\n\nOr this one, from Alphonso Sensley II in Oakland, California:\n\nThe range of responses has really been incredible\u2014ranging from the practical to the philosophical, and all points in between. The limited character count of a Tweet seems to function something like the tight form of a Haiku, pushing the authors to reveal the most powerful revelations from the most compressed of expressions. Some even sound like actual Haiku poetry, like this one from Aniket Satbhai, in India:\n\nOr this one, from Songtao, in Melbourne, Victoria:\n\nAs as contest, the whole affair is a straightforward one \u2026\n\nWe\u2019ll pick 10 winners randomly on 3/16. Each will receive 1 ticket and a registration code by 3/19. No travel/accommodations and 18+.\n\n\u2026 but the experience of witnessing so many heartfelt answers has been moving beyond anything we could have imagined.\n\nHonestly though, we should have known! The power of learning is an incredible thing, and lifelong learners are amazing!\n\nTickets to Intersect 2018 are very nearly sold out, and we can\u2019t wait to add 10 more inspiring lifelong learners to the guest list. Why do YOU keep learning?\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-march-10-5c9c387c8a8b",
        "title": "Flying Car News, March 10 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Boeing is developing an autonomous aerial taxi, drones identify trash in Norway\u2019s Fjords, Porsche is developing a flying car, augmented reality for aerial robots, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nBoeing\u2019s CEO Dennis Muilenburg believes that the onset of flying cars is coming sooner than people might expect. Aurora Flight Sciences, which was recently acquired by Boeing, is partnering with Uber for their aerial taxi project, and Boeing is investing heavily to shape this new aerial transportation system.\n\nNorway\u2019s government is soliciting bids for drone solution providers to map out trash piles underwater in its fjords.\n\nPorsche is beginning to develop an autonomous flying car, which is part of its efforts to \u201cshape the future of the sports car\u201d (this effort is called Strategy 2025).\n\nAugmented Reality company Edgybees has received 5.5 million dollars in funding to help bring AR to drones for first responders and emergency personnel.\n\nThe UAV company Windhorse Aerospace is designing a drone constructed using edible materials which will be used to deliver food to hard-to-reach areas in need of humanitarian aid.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-march-9-edition-e386ecaac6be",
        "title": "This Week at Udacity, March 9 edition \u2013 Udacity Inc \u2013",
        "text": "It\u2019s been a week of celebration at Udacity. We\u2019ve been overjoyed to share so many stories highlighting the achievements of our students. These extraordinary individuals, who choose to learn with Udacity, amaze us every day with what they accomplish. It is an honor to shine a light on these remarkable people.\n\nOn Wednesday, we joined our partners at Google in celebrating the achievements of scholarship recipients in three different U.S. cities \u2026\n\nOn Thursday, we joined the world in celebrating International Women\u2019s Day!\n\nWe were honored to share one post in particular this week that brought all these themes together: Celebrating our students, Celebrating our scholarship recipients, and Celebrating International Women\u2019s Day \u2026\n\nAnd THAT \u2026 bring us to THIS \u2026\n\nFor our Tweet of the Week, we\u2019ve selected one that seems to just sit right in with all our themes this week!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/women-who-learn-women-who-collaborate-women-who-code-d3d2fbb0dcf0",
        "title": "Women Who Learn, Women Who Collaborate, Women Who Code",
        "text": "Women Who Learn, Women Who Collaborate, Women Who Code How Google and Udacity scholarship recipients formed a dev-ops project team, collaborated, and collectively created a real-life mobile app dedicated to \u201cFamous Women\u201d\n\nMost programmers share a similar story \u2014 a story full of beginnings. Full of moments when everything feels new, when inspiration and motivation are to be found everywhere. In these moments, you know you are able to create something special, something original, something valuable. You make progress, and from progress comes more progress. Your knowledge grows, and you feel accomplished, satisfied, and proud.\n\nProgrammers also know there is another side to this story. In between the bright moments are the weary days. The days when the learning path seems to have no end. Always there is more to learn, more to study. Suddenly, your bright ideas don\u2019t seem so bright. Your goals seem impossible to accomplish. Problems overwhelm you, and motivation gives way to doubt. Around you, the remnants of good intentions pile higher, and what you once so passionately wanted to pursue, loses its appeal to you.\n\nThis swing from motivated to devastated and back again is something I\u2019ve experienced more times than I care to count. Each time I felt down, I asked myself why, and what happened. I\u2019ve asked myself these questions so many times that I don\u2019t remember my own answers.\n\nProgrammers are by nature \u201cdoers,\u201d so we keep on. We tell ourselves, \u201cThis time it\u2019s going to be different.\u201d Do we believe ourselves when we say this?\n\nI want to tell you a story about when it WAS different this time.\n\nThe story begins on the 6th of November, 2017. This date will stay with me forever. I had applied for a scholarship from Google and Udacity, and on this day, I was awarded a Google Developer Scholarship, and accepted into the program: Android Basics.\n\nThe opportunity came with a twist: I would get access to a learning program which would help me build my first Android app, but I would also join a community of other scholarship recipients, all of whom were aspiring Android programmers. The rules were simple: complete the course content within 3 months, do all the quizzes, and be active in the scholarship community. Ask questions, share technical problems, help and support others. In a nutshell, engage.\n\nI was skeptical \u2014 how would this time-consuming social involvement help me learn?\n\nSince being active was mandatory to be accepted to the next stage of the scholarship, and because engagement was highly recommended by the program mentors, I started in from the very first day. All the participants were invited to join a Slack workspace dedicated to Android-related chats, and I joined as well. It was so crowded at first, you almost got a bot impression. Fortunately, multiple Slack channels were subsequently created, and everything became manageable. From then on, the experience was incredible. Everyone \u2014 students, mentors, community managers \u2014 was so nice, so helpful, and so cheerful, that communication itself became a kind of learning experience. Getting and giving support was motivating.\n\nOne special group took on critical significance for me: \u201cwomen_tech_makers.\u201d This channel was created as an open space for all women in the program, who wanted to encourage each other, and explore ways to work together outside of the program.\n\nThere was a lot of talk early on about creating an app, but not much work got done. It was difficult to get started \u2014 there was no leader to take responsibility and delegate tasks. Many of us felt useless, with almost no knowledge. What could we do to help? Everyone waited for a sign to begin. Everyone, except Malgoska. She simply started working. She suggested using the Miwok application from the Udacity multiscreen course as an example app structure, and proposed her original design for a \u201cFamous Women\u201d app.\n\nSomething clicked in all our minds then, and we suddenly understood that collaboration is about taking initiative, and about everybody getting to work. We realized that you have to find a task for yourself to start something. You have to look for what you can improve, and what solutions you can suggest. That is how the real work started. After that, more women joined with their ideas and solutions. We continue to work this way today.\n\nWe learned an invaluable lesson. The key to great collaboration is taking the initiative, and understanding your own responsibilities; uncovering your personal strengths, and having the support of other members.\n\nWe all did a lot of research to make everything work in exactly the right way."
    },
    {
        "url": "https://medium.com/udacity/udacity-code-roadshow-lessons-learned-in-february-ea832096c550",
        "title": "Udacity Code Roadshow: Lessons Learned in February \u2013 Udacity Inc \u2013",
        "text": "Every month, Udacity and Google host Intro to Programming workshops in Germany. Every month, we learn something new about what motivates people to learn.\n\nSince September, Udacity has worked with Google\u2019s Zukunftswerkstatt to offer free Intro to Programming workshops across Germany. This month, we welcomed a new group of dedicated learners to workshops in Berlin, Hamburg, and Munich.\n\nOf the 85 total participants, 73 are working professionals. The remaining 12 are university students. I was curious to learn more about commonalities and differences between the different participants, and eager to understand what motivates them to pursue new learning opportunities like this one. Here\u2019s what I learned.\n\n\u201cWhat fascinates me most is how much I created in such a short amount of time,\u201d says Annelie, a business student who came to the workshop with VBA in Excel. \u201cI now want to learn HTML to expand my knowledge portfolio,\u201d she explains. When she graduates from HTW, Berlin\u2019s University of Applied Sciences, Annelie plans on becoming a strategic consultant for digital transformation.\n\nAngela, originally from Colombia, moved to Germany to study for her Masters of Public Policy. \u201cThrough the years I\u2019ve always been really curious about making things with computers,\u201d says Angela. \u201cBut with my background in social sciences I had absolutely no clue.\u201d By the end of the workshop, her mindset was already shifting. \u201cThe way HTML was taught today was amazing: I now feel that I\u2019m able to program and that there\u2019s no need to be afraid of computers! I\u2019m definitely motivated to continue learning and to do more.\u201d\n\nSophia, originally from Hamburg, studies marketing and is also gaining practical experience as an intern at a Marketing agency in Berlin. She attended the workshop in hopes of understanding what it takes to build a website. \u201cI now know the basics of HTML and understand that every feature on a website requires input from a programmer.\u201d Knowing this will definitely help me in my marketing career!\u201d\n\nEach of these workshop participants is pursuing their own unique career goal, but together they share an understanding of the role technical knowledge can play in their advancement. As they embark on their career journeys, these learners take with them newfound skills that will enable them to pursue their goals with confidence. None of them plan to be programmers, but each knows how critical it is to count foundational coding skills as part of one\u2019s skillset. Career success in the modern economy virtually requires it, and these learners have given themselves a significant advantage.\n\nThis article is part of a series that will highlight monthly lessons learned at Udacity\u2019s in-person coding workshops in Germany."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-march-3-c0eea87d65c2",
        "title": "Flying Car News, March 3 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Google Project Wing Delivers Food In Australia, Dolce & Gabbana Replaces Models With Drones, the Udacity Flying Car Nanodegree Classroom Officially Opens, Drones Help Restore Power In Puerto Rico, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nProject Wing, a drone delivery moonshot by Google X, is starting to test a drone delivery service in the Australian suburb of Tuggeranong which will lower food directly into customers\u2019 backyards using winches.\n\nDolce & Gabbana used autonomous drones on the runway during a fashion show in Milan.\n\nUdacity officially opened the Flying Car Nanodegree Program classroom on February 27th, and welcomed the historic inaugural class of students. Applications for future terms are open now. Follow Product Lead Jake Lussier and Student Experience Lead Tucker Dunn (Me!) on Twitter for updates about the program.\n\nPower company Duke Energy is using drones to greatly expedite running power cables in mountainous areas to bring power back to Puerto Rico.\n\nNokia is working with a university in Sydney to demonstrate their portable 4G UTM in a backpack in order to accelerate drone system innovation in Australia.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-march-2-edition-ce3ea9b9f6e7",
        "title": "This Week at Udacity, March 2 edition \u2013 Udacity Inc \u2013",
        "text": "For this edition of This Week at Udacity, we\u2019re going to work backwards and start with \u2026 today!\n\nOver on Udacity\u2019s home blog, we had the pleasure of sharing a wonderful #StudentSuccess story about a rather remarkable student\u2019s rather remarkable journey to career success. Anyone else out there spend time as a Navy cryptologist and world-traveling street performer before becoming a successful Android Developer?\n\nProbably our biggest news from the week was our announcement about the Panels and Speakers for this year\u2019s Intersect 2018 conference:\n\nWe are SO excited about the speakers we\u2019ve lined up for you! As but one example, here are our distinguished Keynote Speakers!\n\nThis conference is going to be simply amazing, and if you haven\u2019t purchased your ticket yet, now\u2019s the time! Intersect 2018 tickets are going fast!\n\nFor tips on making the most of your Intersect 2018 experience, check out this post:\n\nIn other news, we WILL confess to being a little excited about showing up in The New York Times this week:\n\nBut we\u2019re even MORE excited about sharing stories from our students! For example, check out this amazing LinkedIn post from Alankrutha Chandra below:\n\nOr this one, from Ay\u015fin Ta\u015fdelen:\n\nAnd now, we\u2019ll close out this edition of This Week at Udacity with the moment you\u2019ve all been waiting for \u2026\n\nOur own David Silver tweeted this one out; it\u2019s MORE great news about Udacity students!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-march-1st-2018-2816bbc20565",
        "title": "This Week in AI, March 1st, 2018 \u2013 Udacity Inc \u2013",
        "text": "OpenAI is well known for their Gym environments commonly used for reinforcement learning research. This week, they released a set of new environments focusing on robotics. One environment has a robotic hand that you can train to grasp and manipulate objects. The other has a robotic arm that can push, pull, and pick up objects.\n\nAlong with that announcement, OpenAI also released a paper on a new reinforcement learning method called Hindsight Experience Replay. This enables agents to learn from mistakes by pretending final incorrect actions were right all along. Learning from mistakes is a powerful tool for humans, this could prove to be crucial for reinforcement learning.\n\nAlong with Google and Baidu, Facebook has been hard at work on a neural text-to-speech model. Previously, these types of models required a lot of data to learn to generate new voices. The Facebook team built a model that can generalize to new voices using only a small amount of untranscribed audio. This means it can learn from \u201cin-the-wild\u201d recordings instead of needing controlled environments.\n\nA team at Kyushu University in Japan found a way to fool computer vision neural networks with a single pixel. By changing the color of a single pixel in an image, they were able to force a network to misclassify images it would otherwise predict perfectly.\n\nThis is known as an adversarial attack. It\u2019s been known for a while now that you can add imperceptible noise to an image and get pre-trained convolutional networks to predict whatever you want. The thing is, the images themselves look completely unchanged to humans. This can even be done with simple stickers which can effect computer vision systems in the real world (think automated cars).\n\nSimilar to the one pixel attack, researchers at Google Brain found a method to fool computers and humans.\n\nYann LeCunn and Christopher Manning (famed AI professors at Facebook/NYU and Stanford respectively) had an interesting conversation about imposing structure on neural networks. Do we build in connections as we do in convolutional networks and capsule networks, or do we let networks discover appropriate configurations themselves? Human brains are highly structured, so perhaps we should attempt to emulate them? On the other hand, at some point in the distant past, the animal brain was unstructured, and over a billion years of evolution, it developed structure.\n\nAshwin Ram, the lead for AI on Amazon Alexa, has joined Google as the technical director of AI for Google Cloud. Amazon, Microsoft, and Google are in fierce competition to capture the cloud market specifically with respect to AI. These companies, and plenty more with deep pockets, are fighting over AI talent, sometimes paying a million dollars for experienced practitioners.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/udacitys-intro-to-self-driving-cars-nanodegree-program-173d7ffa9d8f",
        "title": "Udacity\u2019s Intro to Self-Driving Cars Nanodegree Program",
        "text": "Udacity\u2019s Intro to Self-Driving Cars Nanodegree Program is for anyone in the world who ever dreamed of working on self-driving cars, but thought they never could.\n\nThis program covers the prerequisite skills necessary to advance to our career-ready Self-Driving Car Engineer Nanodegree Program, including:\n\nAs a student in the Intro to Self-Driving Cars Nanodegree program, you\u2019ll build your skills up over the course of a four-month curriculum path that tackles each of these areas at a pace that is both manageable and rewarding. Best of all, you\u2019ll practice putting these skills to work on the types of projects that real self-driving car engineers work on every day.\n\nIf you love self-driving cars, but thought you\u2019d never get the chance to work on them, then this is the program for you.\n\nCheck out a free preview of the program right now!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-february-24-928604596a98",
        "title": "Flying Car News, February 24 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Airbus Vahana Flying Car Video Footage, Green Drone Delivery, Samsung Drone Eye Detection Patent, Vodafone uses 4G for UTM, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nAirbus released the first video footage of the Vahana Flying Car which took off vertically and hovered for 53 seconds.\n\nA team of researchers from Carnegie Mellon, SRI International, and University of Colorado-Boulder conducted a study which found that drone delivery is capable of significantly reducing greenhouse gas emissions compared to current delivery methods.\n\nSamsung has patented a drone with an integrated display that can track human pupils and body gestures.\n\nVodafone is testing a UTM system with the European Aviation Safety Agency which uses 4G technology to track commercial drones which cannot be picked up on radar.\n\nThree Hundred drones performed an aerial light show in celebration of the Chinese New Year in the city of Xi\u2019an.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-february-22-2018-5c3c9839d57d",
        "title": "This Week in AI, February 22, 2018 \u2013 Udacity Inc \u2013",
        "text": "A team from NVIDIA released a new project with amazingly realistic style transfers. Previous versions I\u2019ve seen tend to have a lot of artifacts and strange textures, but these results are stellar.\n\nThese types of deep learning algorithms are showing up in photo-editing applications like Photoshop. Style transfer also has a lot of applications in the post-production of movies where directors can change the overall mood of shots using reference photos. You can find the code here and the arXiv paper here.\n\nA team at Google Brain published a paper on using a deep learning model to detect cardiovascular disease from retinal images. Using trained models, the authors were able to determine age, smoking status, blood pressure, and risk of cardiovascular events from retinal images alone. This is really exciting since capturing retinal images is a non-invasive method which can be employed in the doctor\u2019s office instead of sending blood samples to a lab.\n\nMIT Technology Review wrote a great profile of Ian Goodfellow, the inventor of Generative Adversarial Networks (GANs). I had the pleasure of working with Ian on Udacity\u2019s Deep Learning Nanodegree program. He has an amazing capability to explain the complex workings of GANs, truly one of the brightest innovators in AI and deep learning.\n\nA group of 14 organizations including OpenAI, the Electronic Frontier Foundation released a report on the malicious use of AI. The report attempts to identify future threats due to the use of AI and how best to prevent these threats. This is not about an AI system taking over the world, rather the use of AI by humans with ill intents.\n\nWe\u2019ve seen a lot of amazing performances from AI systems playing Atari games, chess, Dota 2, and more. In general, these AI systems are trained using reinforcement learning supported by deep neural networks. Examples like AlphaZero, easily beating the world\u2019s best in chess and Go, make it seem like artificial general intelligence is almost ready. However, all these attempts are constrained to the simple environments of games. Introduce the complexity of the real world and they start to look much less impressive. Read more in this great article by Joshua Sokol.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/amazing-self-driving-car-projects-d0599e2c2097",
        "title": "Amazing Self-Driving Car Projects \u2013 Udacity Inc \u2013",
        "text": "The talent and passion of students in Udacity\u2019s Self-Driving Car Engineer Nanodeegree Program regularly astounds me. Here are five independent projects that students did outside of the program to build their skills as autonomous vehicle engineers.\n\nCheck out the autonomous hardware package strapped to the top of this tiny red range rover! And the various test track configurations it navigates. Super cool.\n\nSpatial Transformers are modules that can be inserted into convolutional neural network architectures to focus the network on the most important object in the image. This is helpful because scale and rotation make object localization (finding an object within an image) a complex problem.\n\nThis is an awesome four-part series on building a miniature self-driving car from scratch, with a big emphasis on hardware and electrical engineering. Part 1 is ROS setup, Part 2 is the sensor suite, Part 3 is the microcontroller, and Part 4 is working with the NVIDIA Jetson TX1. This is quite the hacker project.\n\nI love watching videos that students shoot themselves. Here Karol is applying a Single-Shot Detector (SSD) network to identify other vehicles on the road.\n\nScaling up from miniature self-driving cars to human-sized self-driving cars, Bogdan outlines a self-driving car development platform accessible for under US$10,000. This does not include the sensor suite \u2014 just the drive-by-wire platform. He settled on the Renault Twizy and is looking for partners to work on this with him :-)"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-february-17-a83ec95a7175",
        "title": "Flying Car News, February 17 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Intel performs record-setting drone show at The Olympics, SpaceX launches Elon\u2019s Tesla into space, Skydio Releases R1 Autonomous Drone, Airbus demonstrates Skyways Delivery Drone, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nA record-setting 1218 Intel drones performed an awe-inspiring synchronized light show for the opening ceremonies of the winter olympics in Pyeongchang, South Korea.\n\nSpaceX launched it\u2019s Falcon Heavy Rocket from Cape Canaveral in Florida with Elon Musk\u2019s personal Tesla Roadster as payload, and a dummy astronaut named Starman in the driver\u2019s seat.\n\nSkydio released the R1 drone which includes 13 cameras and an NVIDIA Jetson to autonomously fly itself and avoid objects as it tracks and films with 4k video. I personally tested the drone out at Skydio\u2019s HQ and it is absolutely amazing!\n\nAirbus demonstrated its Skyways delivery drone\u2014which weighs 55 pounds, and can carry packages up to 9 pounds\u2014at the National University of Singapore.\n\nIn an interview with Techcrunch, Justin Erlich (Head of Policy, Autonomous Vehicles and Urban Aviation, Uber), laid out Uber\u2019s plan for the future of Flying Cars.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-february-16-edition-56b8b6b1df83",
        "title": "This Week at Udacity, February 16 edition \u2013 Udacity Inc \u2013",
        "text": "When you send out an email, and then you see that email posted on someone\u2019s LinkedIn account, it\u2019s a really great feeling, because it really reinforces that you\u2019ve been able to support that person\u2019s career aspirations. So we\u2019ve been feeling particularly happy all week long as we\u2019ve been watching all the LI posts from recent scholarship recipients. Here are some wonderful examples!\n\nNot only have we been happily celebrating these new scholarship recipients, we\u2019re also incredibly excited to start meeting the pioneering inaugural class of our Flying Car Nanodegree program! Why, here\u2019s one of them now!\n\nAnd now for something completely different! Don\u2019t let the Valentine\u2019s Day theme keep you from reading this post\u2014the advice here will serve you will at any time of the year. As but one example, on the subject of not getting the job:\n\nIt\u2019s been a heartwarming week, to say the least, and what better way to round it out than with an awesome story about an awesome student who is an awesome lifelong learner?\n\nAnd that brings us to to your favorite segment and mine, the \u2026\n\nCan we resist an irresistible gif? No, no we can\u2019t \u2026\n\nAnd THAT \u2026 is This Week at Udacity!\n\nLifelong Learners, don\u2019t forget to take advantage of Early Bird tickets for Intersect 2018!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-february-15th-2018-22e7e3f98c0d",
        "title": "This Week in AI, February 15th, 2018 \u2013 Udacity Inc \u2013",
        "text": "Alex Irpan, a software engineer at Google, wrote an excellent article on the current difficulties of getting deep reinforcement learning to work. For example, even after weeks of optimizing hyperparameters and explotation-exploration rates, these models are still highly sensitive to initial conditions. A 30% failure rate is seen as \u201cworking.\u201d\n\nIrpan makes the argument that most attempts with deep RL fail but no one talks about it publicly, we only see the few cases where the problems are simplified enough to be feasible. He\u2019s optimistic though. This is still a new field - the breakthrough Atari DQN paper was published only 3 years ago - so there is plenty of room for more research and advancement.\n\nFrom Denny Britz, a nice write up on using deep reinforcement learning for financial trading. This isn\u2019t a tutorial with code, but rather about the difficulties and where reinforcement learning can fit in to this problem. Even if you have very limited knowledge of trading (like me), this article is a great starting point in a really interesting area.\n\nThis week, Bloomberg reported on the extreme demand for AI experts. According to a report by Element AI, only 22,000 people are capable of building AI systems worldwide. Tencent recently reported the number to be around 200,000, so let\u2019s say it\u2019s more like 100,000 worldwide. This limited supply of AI practitioners and the high demand for them have led to salaries reaching $300,000. This demand will likely continue for the next few years as more applications for deep learning are discovered and more organizations learn what AI can do for them.\n\nMuch of the success of deep learning has come from the gains of high-performance computing on GPUs. So far this has mostly been done with CUDA and CuDNN, a library for deep learning build on CUDA. TensorFlow, PyTorch, and other current frameworks all run on CuDNN for efficient training and inference. As an alternative, Facebook announced Tensor Comprehensions, a C++ library that simplifies compiling machine learning applications for high-performance on GPUs and CPUs. While this still takes some computer engineering expertise, it should lower the bar for anyone looking to optimize their code.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/6-tips-for-falling-in-love-again-with-your-job-f5b3bdc48a2f",
        "title": "6 Tips for Falling In Love Again (With Your Job!) \u2013 Udacity Inc \u2013",
        "text": "I\u2019d like to introduce you to someone. Call them The Careers Bartender \u2014 a sort of in-house expert on skilling-up, finding a job, and staying relevant to the job market. I invite you to pull up a stool, order your favorite beverage, and fire away with your questions. The bar is stocked and our bartender is ready to listen \u2026\n\nIn honor of Valentine\u2019s Day, the bartender helps with a reader\u2019s labors in love.\n\nI\u2019ve fallen out of love. It\u2019s taken me a long time to admit that, even to myself. I wake up every day and I feel empty. I\u2019m going through the motions, pretending that everything is okay. But it really isn\u2019t. I\u2019m bored, unchallenged, and underwhelmed. The truth is, my job just doesn\u2019t excite me anymore.\n\nI want a role that makes me start each day feeling inspired and glad to be alive. My problem is I know it isn\u2019t going to happen where I am, but I feel overwhelmed when I think about making a change. How do I overcome this fear and find a job I love again?\n\nFalling out of love with your job can be tough, but remember that your future is filled with amazing opportunities. By contacting me, you\u2019ve already taken an incredible first step to getting there: you\u2019ve recognized you need a change, and you\u2019ve started considering how to make it happen! Here are my 6 Tips for Falling In Love Again (With Your Job!)\n\nBreaking up is never easy to do, but it really can be the best move for long-term job happiness. Stay focused on the exciting vision of what you want from your career, and you can ensure your next role is one you\u2019ll adore. Good luck, and see you at Happy Hour!"
    },
    {
        "url": "https://medium.com/udacity/udacity-self-driving-car-engineer-nanodegree-projects-12823ff1cd21",
        "title": "Udacity Self-Driving Car Engineer Nanodegree Projects",
        "text": "Students in our Self-Driving Car Engineer Nanodegree program engage in a project-based curriculum, and from the moment they enroll, they begin addressing key challenges and topics through building specialized projects. Here are all of the projects they build!\n\nThis is the first project students complete, one week into the program.\n\nThey learn to work with images, color spaces, thresholds, and gradients, in order to find lane lines on the road.\n\nStack: Python, NumPy, OpenCV\n\nIn this project, students train a convolutional neural network to classify traffic signs.\n\nTo do so, they use the German Traffic Sign Recognition Benchmark dataset. This particular student went above and beyond to train his network to not only classify signs, but also localize them within the image, and applied his classifier to a video.\n\nStack: Python, NumPy, TensorFlow\n\nHere, students record training data by manually driving a car around a track in a simulator.\n\nThen they use this camera, steering, and throttle data to train an end-to-end neural network for driving the vehicle, based on NVIDIA\u2019s famous research paper.\n\nStack: Python, NumPy, Keras\n\nBy applying advanced computer vision techniques, such as sliding window tracking, to a dashcam video, students are able to track lane lines on the road under a variety of challenging conditions.\n\nStack: Python, NumPy, OpenCV\n\nStudents use machine learning techniques and feature extraction to identify and track vehicles on a highway.\n\nStack: Python, NumPy, scikit-learn, OpenCV\n\nAn extended Kalman filter merges noisy simulated radar and lidar data to track a vehicle.\n\nStack: C++, Eigen\n\nAn unscented Kalman filter merges noisy, highly non-linear simulated radar and lidar data to track a vehicle.\n\nStack: C++, Eigen\n\nStudents develop a particle filter in C++ to probabilistically determine a vehicles location relative to a sparse landmark map.\n\nStack: C++\n\nStudents build and tune a proportional-integral-derivative controller to steer a vehicle around a test track, following a target trajectory.\n\nStack: C++\n\nStudents build and optimize a model predictive controller to steer a vehicle around a test track, following a target trajectory.\n\nStack: C++, ipopt\n\nIn this project, students construct a path planner for highway driving based on a finite state machine.\n\nThe planner has three components: environmental prediction, maneuver selection, and trajectory generation.\n\nStack: C++\n\nStudents train a pixel-wise segmentation network that identifies and colors road pixels to identify free space for driving.\n\nStack: Python, TensorFlow\n\nStudents build a prototype of a safety case for a lane-keeping assistance ADAS feature, including the safety plan, hazard analysis and risk assessment, functional safety concept, technical safety concept, and software requirements.\n\nFor this project, students form teams to drive a real self-driving car around the Udacity test track.\n\nThe car is required to negotiate a traffic light and follow a waypoint trajectory. Code is built first in the simulator, and then deployed to Udacity\u2019s self-driving car in California.\n\nStack: Python, ROS, Autoware, TensorFlow"
    },
    {
        "url": "https://medium.com/udacity/the-myth-of-inspiration-29b7533d5306",
        "title": "The Myth of Inspiration \u2013 Udacity Inc \u2013",
        "text": "Let\u2019s be honest. Inspiration is a fickle thing. It comes, it goes. It\u2019s not always there when we need it, and to add insult to injury, it often shows up when we can\u2019t take advantage of it. It\u2019s an unreliable partner, and banking on it for anything even remotely important seems foolhardy.\n\nYet every day, and from every direction, come voices exhorting us to get inspired. Get inspired to move faster, or slow down. Get inspired to change the world, or save it. Get inspired to invest, or save. Get inspired to change your career, or maintain it. Get inspired to learn something new, or rediscover something you forgot. If you listen long enough, you start to believe it takes inspiration just to get up in the morning.\n\nThis is all a myth. Not only is it a myth, it\u2019s a potentially dangerous one.\n\nDon\u2019t get me wrong. Inspiration is great. When it comes, by all means, milk it for all its worth. Just don\u2019t depend on it. Because we don\u2019t need it. What we need, is process. Process is what gets you through, when inspiration abandons you.\n\nAll of the above is particularly important to understand when we\u2019re talking about the work we do outside of our \u201cday jobs,\u201d or when our day jobs take place outside of structured environments.\n\nWhen you\u2019re in a structured environment, process comes with the territory, because deadlines and expectations are generally set for you by someone else, and the fact that you have to stay on track, makes it easier to stay on track. That\u2019s not to say this scenario doesn\u2019t have its own challenges when it comes to inspiration \u2014 it does. In a structured environment, it\u2019s easy to lose your spark.\n\nBut if you work independently as a freelancer or sole proprietor, you have to create all that structure all by yourself. And if you\u2019re engaged in a passion project outside of your day job \u2014 taking online courses, or prototyping a new product, or managing an online store, or working on a book/play/album/sculpture/painting, etc. \u2014 the same holds true; you have to create the structure yourself. That\u2019s where process comes in.\n\nI\u2019ve separated out these two use cases \u2014 structured vs. unstructured \u2014 for the sake of theoretical clarity, but in real life, lines blur. I can use myself as an example. I\u2019m a professional writer. So I write every day. I have to. It\u2019s how I feed my family and put a roof over our heads. How long would I last, if I only wrote when I felt inspired? I like to think I get a big idea every once in a while, but most days, I don\u2019t. Most days, the muse is on sabbatical. The muse is surfing. Or sleeping off the champagne. And I\u2019m alone with my typing fingers, and my uninspired brain, and I have to write.\n\nThat\u2019s when process shows up. Kind, loyal, process. Always there, always a friend. When I enter the writing room with process, I check my emotions at the door, then it\u2019s just me, and my process. Good ol\u2019 process.\n\nWriters and their processes can actually offer great examples of how to leverage process in the service of success.\n\nStephen King writes very every single day, and doesn\u2019t quit until he reaches 2000 words. Graham Greene, on the other hand, wrote with a black pen in small notebooks, and stopped at 500 words; even, it is rumored, if he was in the middle of a sentence. Maya Angelou kept a hotel room in her hometown where she went to write every morning. Albert Camus wrote standing up. Alice Munro writes seven days a week, but only for three hours a day. Vladimir Nabokov wrote only on index cards. Alexandre Dumas wrote novels on blue paper, and poetry on yellow.\n\nThese kinds of rituals and processes are what make work happen. They\u2019re what we can rely on when we don\u2019t feel inspired. You can follow the lead of these writers to build the processes that will support your important work.\n\nDo you work independently, or outside of a structured environment? Do you have outside projects you\u2019re passionate about? Do you struggle to find the inspiration to stay on track? Stop struggling, forget inspiration, and embrace process. Here\u2019s the secret sauce, distilled down to three essential ingredients: Time, Place, and Product.\n\nImportant things take time. Success takes time. A little bit of time every day, or one big chunk of time. Mainly, you need time.\n\nTreat your personal work time like it\u2019s an expensive session of post-surgical physical therapy. You wouldn\u2019t bail on that because you were sleepy, a friend called, or you just didn\u2019t feel like it, would you? And if that friend called, and invited you to a movie, and you said, \u201cI can\u2019t, I\u2019ve got physical therapy,\u201d your friend wouldn\u2019t try and cajole you into coming anyway, would they? The same should hold true about your personal work time. It\u2019s precious, and it can\u2019t be cancelled on a whim.\n\nYour environment is possibly the most important determinant of just how productive you\u2019re going to be during any given work session. Your space can support you, and it can destroy you. At minimum, your space should at least be neutral \u2014 it shouldn\u2019t affect you either way. But ideally, it should positively inform and influence your work experience. It should be comfortable, and distraction-free.\n\nMake a ritual out of entering and setting up your space. Get things the way you want them, before you start. Whether it\u2019s just a desk, or an entire room, make sure you have what you need, and that you don\u2019t have what you don\u2019t need. Set it up the same way, every day. Get in the habit of setting it up right, and then let that habit sustain you.\n\nLiterally, what you produce. Your output. Your results. It\u2019s all for naught if your personal work time doesn\u2019t produce \u2026 something. And remember, effort counts as something. Stephen King doesn\u2019t require that those daily 2000 words all go in the final novel. He just demands of himself that he produce them.\n\nWill you make 10 phone calls? Write 100 lines of code? Draw three new designs? Submit five new poems? Send 10 emails? Check in with three accounts? Pay two bills? Read 50 pages? The important thing, is that you plan for a result, and then you deliver that result.\n\nRay Bradbury famously once delivered a piece of writing advice that has since transformed into a sort of productivity challenge, known most commonly as \u201cThe Bradbury Challenge\u201d:\n\nThe point being, is that it\u2019s not about inspiration. It\u2019s about work.\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-february-10-cefd7f03ea05",
        "title": "Flying Car News, February 10 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Airbus Vahana completes first test flight, Ehang completes over 1000 human test flights, North Carolina DOT proposes medical delivery drones, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nAirbus completed the first test flight of its flying car Vahana at an airport in Oregon. The electric VTOL aircraft, which will have a range of 62 miles, rose to a height of 16 feet for 53 seconds.\n\nChinese drone maker Ehang has conducted over 1000 human test flights of its Ehang 184 autonomous passenger-carrying quadcopter. They have tested it with weights up to 500 pounds, and have achieved speeds above 80 miles per hour.\n\nJake Lussier, program lead for Udacity\u2019s Flying Car Nanodegree program, announced recommended drone hardware this week, as well as supplemental program resources that will guide students on how to port their own code to their own drones.\n\nThe department of transportation for North Carolina submitted a proposal to the FAA for a program to use autonomous drones to deliver medical supplies between hospitals and testing facilities.\n\nThe production version of the Dutch Flying Car Pal-V Liberty will be unveiled at the Geneva Motor show in mid March.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-february-9-edition-2f461914136a",
        "title": "This Week at Udacity, February 9 edition \u2013 Udacity Inc \u2013",
        "text": "Some weeks are just really fun at Udacity, and this was one of them! Alright, who am I kidding? It\u2019s always fun at Udacity, but this week held some special delights.\n\nFirst and foremost, we \u201cofficially\u201d kicked off The Road To Intersect 2018! This year\u2019s annual conference will be a celebration of Lifelong Learning, and while the event itself happens on March 27th, we got to start talking about it this week!\n\nPro Tip: Early Bird tickets are on sale now! And there are some seriously special reasons why you WANT an Early Bird ticket. Trust me. I know things.\n\nAs to what else was fun this week, I was especially happy that we had the chance to talk about so many DIFFERENT Udacity programs. For example, Jake Lussier, the Program Lead for our Flying Car Nanodegree program, shared some great insights about this pioneering learning experience:\n\nAnd over in iOS country, our own Kate Rotondo\u2014ace instructor in our iOS Developer Nanodegree program\u2014had the pleasure of announcing a new Core Data course:\n\nAnd that\u2019s not all! David Silver, the indefatigable Program Lead for our Self-Driving Car Engineer Nanodegree program, continued his quest to write up every single lesson in the entire program! This week, he introduced us to #9:\n\nFortunately, we weren\u2019t just talking about ourselves all week; other people were as well! Which brings us to \u2026\n\nSometimes, it\u2019s really hard to just choose one \u2026 so I\u2019m not going to! Here\u2019s a bunch of tweets we love!\n\nAnd we just HAVE to applaud the use of the term \u201cspaghetti code\u201d:\n\nAnd finally, just absolutely loved the poetry of this one:\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity."
    },
    {
        "url": "https://medium.com/udacity/your-first-two-steps-to-getting-hired-7fbbcd01a50e",
        "title": "Your First Two Steps To Getting Hired \u2013 Udacity Inc \u2013",
        "text": "Company blogs are underrated when it comes to interview prep. Often, when the subject of how to land a new role comes up, they don\u2019t even get mentioned. Which is a shame, because they can provide a wealth of critical information, and with what you find there, you can do a better job of delivering a compelling case for why you\u2019re the right person for the role.\n\nTo try and give you an idea of how and why company blogs can help you prepare for an interview, we\u2019ll look at a company blog from one of our partners: NVIDIA.\n\nJust by going to the landing page of the NVIDIA blog, we can learn some important things. From the navigation bar, we can learn the topics that are important to the company: Deep Learning, Virtual Reality, Driving, Graphics, Gaming, and Data.\n\nFrom the sidebar, we can learn that NVIDIA cares about social media, and likely has a big social footprint: everything from Facebook, Twitter, and LinkedIn, to Instagram, Tumbler, and Reddit, are all represented. Already, you have an action item. Go follow everything.\n\nLet\u2019s go into one of the navigation categories: Driving. Without even reading an article, we can already tell that for NVIDIA, \u201cdriving\u201d means two things; the driver experience (design), and autonomy. If you\u2019re a student in our Self-Driving Car Engineer Nanodegree program, then it\u2019s that second one you\u2019re particularly interested in. Again, without even reading an article, you can easily discern that autonomy levels are an important topic right now \u2014 two posts in January alone focus on this.\n\nNow, let\u2019s get into the real detective work. Let\u2019s look at this post: Dreaming of Driverless: What\u2019s the Difference Between Level 2 and Level 5. Specifically, let\u2019s look at the copy for Level 4:\n\nAccording to SAE guidelines, a level 4 car should be able to drive itself safely, \u201ceven if a human driver does not respond appropriately to a request to intervene.\u201d A level 4 car will slow down, pull over or park itself at a safe spot if the driver doesn\u2019t take control when requested, which might happen in tougher navigation like off-road driving or unmapped roads.\n\nIt\u2019s a task that will take enormous amounts of computing power. And today\u2019s autonomous test cars typically carry a trunk full of computing gear. That\u2019s changing, however. NVIDIA plans to enable level 4 autonomy with NVIDIA DRIVE Xavier SoC, which offers 30 trillion operations per second of performance in a compact package (see \u201cNVIDIA Xavier, World\u2019s Most Powerful SoC Brings Dramatic New Capabilities\u201d).\n\nThe first level 4 cars are scheduled to launch in 2021. And if the manufacturer\u2019s vision for its self-driving fleet is realized, these cars will not just be transport units, but will also resemble small offices, theaters or hotel rooms on wheels.\n\nOne blog post later, and you now have a clear snapshot of the work NVIDIA will be engaged in for the next 3 years: The first level 4 cars are scheduled to launch in 2021. That knowledge can come in very handy for everything from knowing what skills to learn and what projects to put in your portfolio, to knowing what to talk about in an interview.\n\nLet\u2019s jump over to Virtual Reality on the navigation bar. One look at the featured stories, and you feel like you know the story: GPUs. That\u2019s where NVIDIA connects to VR, and that\u2019s how you want to connect to NVIDIA. Which may mean \u2014 if you\u2019re more interested in creating VR experiences, and less so powering them \u2014 that NVIDIA may not be right for you.\n\nBut not so fast!\n\nLet\u2019s open one of those GPU posts up: All Greek to Me: GPUs Power Groundbreaking VR Experience. Here\u2019s how the post begins:\n\nIf you\u2019ve ever dabbled in Latin poetry, you may have stumbled upon Ovid\u2019s Metamorphoses. Its tales of transformation and reality have fascinated artists for centuries.\n\nIn a similar theme, a new artwork, La Dispersion du Fils, tells the story of Actaeon \u2014 a hunter who\u2019s turned into a stag by the goddess Diana and devoured by his own hounds.\n\nJust as Ovid\u2019s original work blurs the lines of reality, this new piece immerses viewers in the metamorphosis thanks to a 360-degree omnistereoscopic VR system and living 3D \u201ctapestries\u201d of moving images, constructed entirely in real time.\n\nThis may at first glance seem a bit headier than expected, but it\u2019s ultimately indicative of a genuine engagement with creativity and creators, and that\u2019s an important thing to know about NVIDIA\u2019s presence in the VR space\u2014especially if you\u2019re interested in pursuing a VR role with the company.\n\nLet\u2019s try one more category. This time: Data Center. There\u2019s a wealth of valuable information to be found here as well, everything from how a table tennis story 40 years ago led to a show-stopping demo at CES, to news about NVIDIA investing in 3 new Data Science companies. The post also includes a list of 10 other companies NVIDIA has invested in over the course of the previous year:\n\nIf I\u2019m you, and I\u2019m interested in NVIDIA, and in the employment opportunities in the spaces NVIDIA has a presence in, then that list above just turned into my next jobs-related research project!\n\nYes, there\u2019s a great deal to be learned about a company from their blog, and yes, what you learn can make a critical difference in how you perform during an interview, and even how you prepare for the job over the long-term. A 2017 article from CareerBuilder highlights 5 Things You Need To Know About A Company Before You Apply For A Job, which are:\n\nThis roughly squares with an informative article from IT recruitment specialists Inteqna, entitled: What You Should Already Know About The Company Before Your Interview. In that post, they highlight the following:\n\nThat last item is the critical one: The Role Itself. A blog can help with much of the above, especially things like culture and values, as well as recent news. But the job description is going to give you really critical details about the role itself.\n\nLet\u2019s circle back to that first persona scenario. Let\u2019s say you\u2019re a student in our Self-Driving Car Engineer Nanodegree program, and you\u2019re interested in NVIDIA. And let\u2019s say you find this open role:\n\nYou read down the description, and lo and behold, look what you find!\n\nWays To Stand Out From The Crowd\n\nThat\u2019s a great example of why NVIDIA is such a great company. It\u2019s also a great example of why you should read the company blog second, and the job description first!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/iosnd-news-core-data-update-c2f58dd1feb0",
        "title": "iOSND News: Core Data Update \u2013 Udacity Inc \u2013",
        "text": "On behalf of the entire iOS Developer Nanodegree program team, I am excited to announce an all-new version of our Core Data course! Core Data is a fundamental skill for any successful iOS developer, and this course teaches all the best practices and latest features. If you have some experience writing tableview-based applications in Swift, are excited to build apps that create or consume content, and don\u2019t want data management to slow you down, this is the course for you. I know firsthand, because I discovered the merits of Core Data during my own developer journey.\n\nThe first time I set out to learn Core Data, I was preparing to attend my first hackathon. It was still a couple of weeks away, but I already knew what app I wanted to build. It would be a visual schedule app to help special needs families manage daily routines. I was excited to build this app because at the time I used a laminated-cardstock-and-velcro tool from an occupational therapist that was a pain to carry around. I dreamed of having the tool as an app in my phone.\n\nAs I thought through the skills I would need to build the app \u2014 designing the user interface, working with collections \u2014 I realized there was a big roadblock in my way. I didn\u2019t know how to save an app\u2019s data. I was pretty sure I\u2019d be able to recruit a teammate to help on the UI side, but I didn\u2019t think I could count on finding someone who knew iOS persistence.\n\nI was going to have to learn it myself.\n\nTo be honest, I wasn\u2019t excited about the prospect of working with relational databases. I\u2019d first encountered them in a web programming class years earlier, and the nuts and bolts of managing tables and unique identifiers didn\u2019t exactly capture my fascination.\n\nSo it was with trepidation that I sought out resources on Core Data, which I\u2019d heard was Apple\u2019s way of handling persistence. I found the most approachable-looking tutorial I could (this was back in the Objective-C days), and settled in for what I anticipated would be a week of boring backend drudgery.\n\nTo my surprise, that week was transformative and energizing. It turned out that Core Data did not require me to interface directly with relational databases at all! I learned that Core Data manages the data layer, allowing developers to interface with the underlying store without having to worry about its implementation details.\n\nI wasn\u2019t going to have to become a database administrator to write my app after all!\n\nLong story short, I went to that hackathon, teamed up with a designer and a UI developer, wrote the data layer and persistence myself, and we won first place. Thank goodness for Core Data!\n\nEver since then, I\u2019ve been an enthusiastic advocate and teacher of Core Data as an incredibly useful skill to learn for iOS app developers.\n\nSo you can imagine how delighted I am to announce that today we launched a completely refreshed version of the Core Data course for the iOS Developer Nanodegree program.\n\nI built this course in collaboration with Udacity iOS Engineer Josh Svatek. Our process was to first rewrite the existing example app\u2019s codebase to use the best practices and most recent features from WWDC, then to build and script the lessons based on that experience.\n\nWe also tried to balance the text-heavy nature of most Core Data documentation. One thing that can be confusing at first is using so many classes with similar names: NSManagedObjectContext, NSManagedObjectModel, NSPersistentStoreCoordinator, NSPersistentContainer. We were determined to help differentiate these a bit more readily for beginners, through animations that bring them to life.\n\nWe also took care to walk through the practical details of working with Core Data in Xcode. We cover everything from setting up data in the model editor, to adding concurrency debugging to your scheme, through gently-paced screencasts like this one:\n\nOver the four-lesson course, we walk through developing a notes app called Mooskine. It starts out with all the functionality it needs except the ability to save. We begin by converting its model classes to a Core Data layer, and then using Core Data to add persistence. That would be enough for a minimum viable product we could launch in the app store, but we don\u2019t stop there. In the following lessons, we make the UI responsive to data changes, migrate users between data versions when we add a feature that changes the model, and prevent slow data work from freezing the user interface by moving it to the background.\n\nThe new course is available now as part of the iOS Developer Nanodegree program, which gives you access to code-reviewed projects, and personalized support and feedback on your progress. You can also see the new Core Data lessons in the free version of the iOS Persistence and Core Data course."
    },
    {
        "url": "https://medium.com/udacity/the-traffic-sign-classifier-project-1c85a2eb9db5",
        "title": "The \u201cTraffic Sign Classifier\u201d Project \u2013 Udacity Inc \u2013",
        "text": "Traffic Sign Classifier is the second project, and the ninth lesson, in the Udacity Self-Driving Car Engineer Nanodegree Program.\n\nIn this project, students build and train a deep neural network to classify images from the German Traffic Sign Recognition Benchmark dataset. There are about 40 different types of German traffic signs in the dataset, each 32x32 pixels big. That\u2019s not very big!\n\nNonetheless, each image is big enough for students to train a convolutional neural network to recognize what type of sign it is, with 95%+ accuracy. That\u2019s close to, or even better than, the accuracy that humans like you and I reach when we classify images by sight.\n\nThe lesson starts out with a tour of LeNet, one of the canonical network architectures for image classification. We step through how to implement LeNet in TensorFlow, highlighting data preparation, training and testing, and configuring convolutional, pooling, and fully-connected layers.\n\nWe also show students how to spin-up a GPU-enabled EC2 instance from our partners at Amazon Web Services. Thank you to AWS Educate for providing free AWS credits to Udacity students!\n\nAt the end of the lesson, students get to apply, tweak, or completely revamp LeNet to train their own classifier. If you want to compare yourself to Yann LeCun, here\u2019s how he did with the same dataset:\n\nReady to start learning how to build self-driving cars yourself? Great! If you have some experience already, you can apply to our Self-Driving Car Engineer Nanodegree program here, and if you\u2019re just getting started, then we encourage you to enroll in our Intro to Self-Driving Cars Nanodegree program here!"
    },
    {
        "url": "https://medium.com/udacity/three-steps-to-code-your-own-flying-vehicle-bc3d0683d620",
        "title": "Three Steps to Code Your Own Flying Vehicle \u2013 Udacity Inc \u2013",
        "text": "Applications for our Flying Car Nanodegree program close at 11:59 p.m. PST on February 7th. We\u2019re so excited to meet the engineers who will help build and define the future of flight! Apply today to join the pioneering inaugural class.\n\nIn this program, you\u2019ll immerse yourself in the full-stack of autonomous aerial systems \u2014 from low-level controls to massive-scale system coordination. You will begin with drones, advance to flying cars, and, ultimately, tackle the challenge of entire fleets.\n\nThe program is comprised of two terms: \u201cTerm 1: Aerial Robotics\u201d and \u201cTerm 2: Intelligent Air Systems.\u201d Across these two terms, you\u2019ll learn cutting-edge technologies from the world\u2019s leading flight pioneers, including Sebastian Thrun, Nicholas Roy, Angela Schoellig, and Raffaello D\u2019Andrea. Plus, thanks to new content partnerships announced below, you\u2019ll have access to software and hardware tools to gain hands-on experience and advance your career!\n\nIn this post, I\u2019d like to share the three-step development path we\u2019ve set up for you to get your own code on your own flying vehicle.\n\nThe first step towards real-world testing starts right in the Flying Car classroom. When you write Python code in a classroom Jupyter notebook, you can import Udacity\u2019s flight API and immediately see your results in a Unity visualizer.\n\nThis workflow is optimized for learning, iteration, and visualization (sometimes even using real maps from real cities). For certain planning and coordination tasks where it is OK to use high-level languages, this will also serve as a realistic environment similar to an aircraft companion computer or a ground station. For these projects, students may even be able to independently run their Python code directly on their drones.\n\nCertain low-level tasks require higher-fidelity testing in accurate and adaptable simulation. This is why we are extremely pleased to announce our content partnership with aerial drone maker, Fotokite! Fotokite is an innovative drone producer of reliable, easy-to-use drones that made headlines when they were selected for use by CNN.\n\nWith the benefit of Fotokite\u2019s deep expertise, we offer an open simulator, written in C++, that provides job-ready experience implementing layers of the autonomous flight full-stack.\n\nPorting code to an actual drone is an exciting step for a full-fledged autonomous flight engineer to take, and we\u2019ve augmented our core curriculum with supplemental lessons like \u201cBackyard Flier on a Drone\u201d that will support your independent efforts to engage in hardware testing outside of the program. Within the program, our focus is on flight autonomy software, and no hardware purchase or testing is required.\n\nIf and when you do elect to take this step, we want to ensure you\u2019re set up to succeed. You can choose any drone platform, but thanks to our colleagues at Bitcraze, we will have a special discount for the Bitcraze Crazyflie STEM drone bundle for students in our program! Once you\u2019re enrolled, keep an eye on your inbox for additional details.\n\nIn the classroom, we will provide thorough instructions for the Crazyflie and for the Intel Aero drone, and your code should work with any PX4 compatible drone. In fact, we\u2019ve designed our API\u2019s so that this can be as easy as changing a single line of code!\n\nIt\u2019s difficult to capture the magnitude of what students in this program will be working towards \u2014 to say you\u2019ll be building the future of flying cars hardly does justice to the full scope of what the next generation of engineers in this space stands to achieve. It\u2019s wild that something as remarkable as a flying car should actually only be one component in a much larger vision, and yet, this is exactly the case. What we\u2019re talking about is the future of mobility \u2014 literally, how and where we move.\n\nApply today to join the Flying Car community and build the future with us! I\u2019m jake.lussier@udacity.com. Hope to see you in the classroom!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-february-3-8a9cbb4757ad",
        "title": "Flying Car News, February 3 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Joby Aviation raises $100 million for flying cars, autonomous drones learn from cars, and Dorado Announces an ICO for drone deliveries. Plus, a new video about the Udacity Flying Car curriculum!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nFlying Car Company Joby Aviation announced that it raised $100 million from investors such as Intel Toyota and Jet Blue in their quest to create an eVTOL aerial taxi.\n\nThe University of Zurich and the National Centre for Competence in Research Robotics are developing a network called DroNet, which is attempting to navigate at low altitude in urban environments by learning from cars and bicycles.\n\nUdacity Instructor Raffaello D\u2019Andrea and Product Lead Jake Lussier discussed the newly-announced curriculum for our Flying Car Nanodegree Program.\n\nOn-demand delivery company Dorado announced a $55 million initial coin offering for its drone delivery service, which will use blockchain and chatbots to attempt to revolutionize the delivery solutions of the future.\n\nAirspace management platform Airmap is integrating with the FAA\u2019s Low Altitude Authorization and Notification Capability by offering it to 3rd party developers and making it available to the entire drone ecosystem.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-february-2-edition-eb58a7fb53fb",
        "title": "This Week at Udacity, February 2 edition \u2013 Udacity Inc \u2013",
        "text": "Coding on the road in Germany, a surplus of new career resources, the latest episode of Udacity Talks, Cheddar TV, and more!\n\nWe were all about career skills this week at Udacity. Our own Leah Wiedenmann took to the road to witness firsthand Udacity lifelong learners doing what they do best, and she filed her report here:\n\nIt\u2019s a wonderful article, and the video of the peanut butter & jelly explanation of computer programming is pure gold!\n\nWhile Leah did her learning on the road, you certainly didn\u2019t have to go that route to polish your skills, as we also published some great learning and career resources on our blog that you can access right from the comfort of home!\n\nAnd speaking of accessing resources from home, you don\u2019t have to have been in the studio audience to access all the insights on offer from the latest episode of Udacity Talks, featuring Sebastian Thrun, and Open AI Co-chairman Sam Altman! You can see the whole thing right here:\n\nFor the first week in what seems like quite a while, we didn\u2019t roll out a new Nanodegree program this week, but we DID introduce an awesome new feature: In-Clasroom Chat!\n\nAnd that brings us to \u2026. drumroll \u2026\n\nWe\u2019ll take this brand-new one from the fine folks at Cheddar TV, who just interviewed our own David Silver, the Program Lead for our Self-Driving Car Engineer Nanodegree program:\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-february-1-2018-16d862ec4ed5",
        "title": "This Week in AI, February 1, 2018 \u2013 Udacity Inc \u2013",
        "text": "Here\u2019s a really great list of best practices for improving your deep learning models. Of particular interest is the bit on learning rate optimization and stochastic gradient descent restarts. Both of these methods are generally applicable and are likely to improve models you\u2019re working on right now. Also interesting, the list includes examples using the package, a high-level framework developed by Fast.ai on top of PyTorch.\n\nAli Rahimi wrote a great article comparing the current state of deep learning with the understanding of optics when Galileo built his telescope 400 years ago. Back then, scientists had general ideas of how light bent through glass, but didn\u2019t understand the principles well enough to make true optical devices. Over time as we learned more about optics, we were able to develop mental models that allow us to construct complex stacks of lenses.\n\nWe don\u2019t have these mental models for deep learning yet, and for the most part, experts don\u2019t understand why deep learning works so well. As more research is done in this field, we should start seeing better abstractions and language for describing what each part of a deep learning models is doing.\n\nYou\u2019ve trained your network but how do you let other people actually use it? A great first option is to build a REST API with a simple package like Flask (one of my favorite Python packages). This way your model is available for training and making predictions using URLs and common HTTP methods. Learn how to serve your model with this great tutorial using Keras and Flask.\n\nOpenAI has released a new set of unsolved problems in deep learning. These problems span several domains such as using reinforcement learning to learn the classic Snake game, and training an autoencoder to generate new data for augmenting datasets. This looks like a great set of problems for deep learning beginners\u2014and experienced practitioners\u2014to tackle.\n\nHere\u2019s a really cool project by Jeff Zito where video footage was generated by a deep learning model based on music from Lord Over. The videos can be somewhat disturbing, but I love seeing people making art with deep learning. Zito\u2019s model is based on a deep learning model used to generate realistic videos from audio alone. It\u2019s truly impressive (and somewhat worrying) how well the mouth movements match the audio.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/udacity-code-roadshow-lessons-learned-in-january-ed7e2514e230",
        "title": "Udacity Code Roadshow: Lessons Learned in January \u2013 Udacity Inc \u2013",
        "text": "In September 2017, Udacity joined forces with Google\u2019s Zukunftswerkstatt to offer free Intro to Programming workshops across Germany. I spent a week traveling from Berlin to Munich and Hamburg to experience these workshops directly. Here\u2019s what I learned while on the road.\n\nGoogle Germany\u2019s Zukunftswerkstatt directly mirrors Google UK\u2019s Digital Garage: It\u2019s an on-site education center, where experts volunteer to teach local learners valuable digital skills to help them succeed in their careers.\n\nUdacity is excited to be among these local experts. We created a workshop for complete beginners that offers everything future coders need to get up to speed \u2014 with no prior programming skills required. Over the course of 90 minutes, participants learn about the underlying structure of the web \u2014 HTML.\n\nAfter a successful pilot phase that included 10 sessions, 4 cities, and over 300 participants, we have now committed to hosting three local workshops each month: one in Berlin, one in Hamburg and one in Munich. We\u2019re absolutely thrilled about the continuously great turnout we\u2019ve seen. Above all, it\u2019s a testament to lifelong learning. Across the country, people of all ages and backgrounds are excited to learn.\n\nTo get participants in \u201cthe developer\u2019s mindset,\u201d Session Lead (and Udacity\u2019s local engineer Hern\u00e1n) kicked off the workshop with a simple question: \u201cDo you think computers are smart?\u201d When participants reluctantly nodded, Hern\u00e1n disagreed, \u201cActually computers are very stupid.\u201d To prove his point, Hern\u00e1n proposed a game of Peanut Butter & Jelly (PB&J). \u201cI\u2019ll be the computer making the sandwich, and you\u2019ll be the code telling me how to do it,\u201d he explained. \u201cLet\u2019s start by giving me instructions.\u201d\n\n\u201cPut the bread on the plate,\u201d one participant shouted.When Hern\u00e1n put the entire bag of toast on the plate, the next participant offered a correction.\n\n\u2014 \u201cOpen the bag!\u201d\n\n\u2014 \u201c\u2026the left end of the bag!\u201d\n\n\u2014 \u201cTake out the bread!\u201d\n\n\u2014 \u201c\u2026but just one slice of bread!\u201d\n\n\u2014 \u201cPut it on the plate!\u201d\n\n\u2014 \u201c\u2026horizontally, please!\u201d\n\n\u2014 \u201cOpen the peanut butter jar!\u201d\n\n\u2014 \u201cTake the peanut butter!\u201d\n\n\u2014 \u201c\u2026not with your fingers, with the knife!\u201d\n\n\u2026and so it went on until finally, we had created something that looked something like a PB&J sandwich. And we learned a valuable lesson in the process: A computer will only do exactly what you tell it to do \u2014 no more and no less.\n\nChristina and her daughter Violetta joined our workshop in Munich. While most participants came on their own, they joined forces and wrote their first lines of code together. \u201cThere was a great learning atmosphere in the room,\u201d said daughter Violetta, a student in Munich. Her mother Christina, an experienced Finance Manager, added, \u201cThe workshop was the perfect way to get introduced to to programming.\u201d\n\nJoshua, 20, joined our workshop in Hamburg. This year, the recent high school grad started a traineeship to become an IT Specialist in System Integration in Hamburg. While his apprenticeship is technical, he had never programmed before.\n\nWe\u2019re happy that Joshua, Christina, Violetta and all the other participants decided to take their first step with Udacity, and we can\u2019t wait to see where their learning journeys take them next. Thank you!\n\nNote: This article is part of a series that will highlight monthly lessons learned at Udacity\u2019s in-person coding workshops in Germany."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-january-27-a02af3399665",
        "title": "Flying Car News, January 27 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Applications open for Udacity\u2019s Flying Car Nanodegree program, autonomous air tankers fight wildfires, a new Collision Avoidance startup, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nUdacity announced the opening of applications for the Flying Car Nanodegree program. The 6-month program consists of two terms covering aerial robotics and intelligent flight systems and teaches the skills required to earn a job in the cutting edge flying car and autonomous flight industries!\n\nDrone American and Thrush Aircraft have worked together to create the first autonomous air tanker to assist in fighting wildfires.\n\nResearchers at KOC University and the University of Cambridge published a paper which details an energy neutral internet of drones that allows drones to autonomously support each other and coordinate.\n\nDrone Delivery Canada will start testing its Raven X1400 cargo delivery drone which can carry 25 pound payloads up to 60 km in Q1 of 2018.\n\nIris Automation announced $8 million series A financing to develop its collision avoidance technology for the autonomous flying robotics industry.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-january-26-edition-58a9b904492d",
        "title": "This Week at Udacity, January 26 edition \u2013 Udacity Inc \u2013",
        "text": "My gosh, the question might be better phrased as: What DIDN\u2019T happen this week???\n\nWe started things off with a big announcement about a new scholarship opportunity. As you may be aware, we\u2019re fortunate to be part of a partnership that includes Google and Bertelsmann, and this partnership has already provided thousands and thousands of scholarships to deserving lifelong learners across the globe. On Monday, we were thrilled to add 15,000 more scholarships to the tally:\n\nBertelsmann is a media, services and education company that operates in about 50 countries around the world. The company has 116,000 employees and generated revenues of \u20ac17.0 billion in the 2016 financial year. Their CEO had this to say about this new scholarship initiative:\n\nBig news for a Monday, right? Well, we didn\u2019t stop there! That same day, we announced our newest Nanodegree Foundations Program: Learn Unreal VR!\n\nUnreal Enginer 4 (UE4) is used by more AAA game studios than any other engine, and we built the curriculum for this program in collaboration with Epic Games, the creators of Unreal Engine!\n\nIf you\u2019re keeping track, you\u2019ll note that at this point in the chronology, we\u2019re still on Monday!\n\nAnd on Tuesday, we had ANOTHER big announcement! This was something we\u2019ve been excitedly anticipating for months, and we weren\u2019t alone\u2014over 7,000 of you joined our notifications list to be first to get the news.\n\nAnd what WAS the news? We opened applications for our Flying Car Nanodegree program!\n\nApparently it wasn\u2019t just us, and you, that was excited; the press went a little crazy too!\n\nOn Wednesday, front-end web development enthusiasts gathered around their Facebook feeds as Richard Kalehoff, curriculum lead for our Front-End Web Developer Nanodegree program, led a LIVE info session about the program, and what students can expect to learn. If you missed it, no worries, you can watch it right now!\n\nAnd on Thursday, we were excited to receive a very nice nod from the folks over at The App Store!\n\nAnd THAT \u2026 brings us to the very best thing about Fridays!\n\nThis one\u2019s a lot more fun if I don\u2019t try to explain it first \u2026\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-january-25-2018-72b453966bbc",
        "title": "This Week in AI, January 25, 2018 \u2013 Udacity Inc \u2013",
        "text": "Google recently launched AutoML, a cloud service simplifying machine learning models such that any business can take advantage of recent advancements.\n\nThis is a great step forward in bringing AI models to every business and organization. But I think there will be an increasing demand for machine learning models that run natively on our hardware rather than being shipped off to the cloud. This will be great for internal data analysis and tooling, but less important for new products built around AI.\n\nUber has released a suite of papers detailing the use of neuroevolution for training deep neural networks on reinforcement learning tasks. Neuroevolution uses genetic algorithms to train networks, seeing better results than common models like deep Q-learning and A3C.\n\nThe AI team at Microsoft combined attention and GANs (a model appropriately called AttnGAN) to generate images from a string of words. There has been a lot of effort getting recurrent networks working with GANs, so it\u2019s nice to see some progress here. Check out the paper too!\n\nOne of my favorite things about TensorFlow is being able to visualize your models and parameters in TensorBoard. PyTorch has been missing this functionality, but no longer! Now there\u2019s a TensorBoard extension for viewing your PyTorch models.\n\nYou can find a live demo here and the code itself on GitHub.\n\nJanuary 19th was the one year anniversary of PyTorch going public. In that time it\u2019s grown to be one of the most popular deep learning frameworks. The team has made a lot of progress in a very short amount of time, really pushing the performance and utility of the framework. I\u2019m looking forward to what they accomplish in 2018.\n\nI\u2019ve realized recently that text generated with RNNs hits the sweet spot of the uncanny valley. The text is similar enough to actual language to seem real, but it\u2019s off just enough to be odd and funny. What\u2019s your favorite act?\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-january-20-2f2cf46829dd",
        "title": "Flying Car News, January 20 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: A drone saves swimmers\u2019 lives, AirSpaceX reveals their flying car, Boeing debuts a cargo drone, a world record for drones in a light show is set, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nA Little Ripper Drone piloted by a lifeguard saved two swimmers\u2019 lives off a beach in Australia, by dropping an inflatable rescue pod.\n\nAirSpaceX revealed their autonomous eVtol flying car called the MOBi-ONE, which will be able to fly up to 250 mph with a 60-mile range at the North American International Auto show in Detroit. AirSpaceX plans to have 2500 Mobi-One\u2019s operating in over 50 US cities by 2026.\n\nBoeing unveiled a new prototype cargo aerial prototype drone which is capable of carrying up to 500 pounds; it will be used as a platform to test autonomous eVTOL technology.\n\nDuring Intel\u2019s keynote at CES, one hundred Intel Shooting Star Mini Drones performed a light show that broke the world record for most drones in an indoor light show controlled by a single pilot.\n\nAt CES Bell Helicopter showed off a prototype for a four-person flying car cockpit, which included a VR flying taxi experience being developed in partnership with Uber Elevate.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-january-19-edition-946e93a5f90a",
        "title": "This Week at Udacity, January 19 edition \u2013 Udacity Inc \u2013",
        "text": "This week has provided us with so many wonderful opportunities to share the voices, stories, and successes of our students!\n\nJust this morning, it was our honor and pleasure to share how Sandra, a graduate of our Digital Marketing Nanodegree program, was able to launch her dream career, and reach the culmination of a journey that began in an elementary school classroom!\n\nEarlier this week, we were thrilled to share with you a remarkable story from Ari Michelle Mboya. She\u2019s a young woman who recently graduated from Yale, and is now living back in her native Kenya. She took an amazing leap into the unknown, and rather than following any sort of proscribed career path, opted to enter the remarkable world of VR! (spoiler alert: it was a great decision!)\n\nAnd here\u2019s a wonderful story we\u2019re sharing for the first time. It\u2019s another #StudentSuccess story, and it\u2019s about another Nandegree program graduate. But in this case, the story comes even a little closer to home, because it\u2019s one of our employees! Congratulations to our own Nancy Lee, who just graduated from the new Design Sprint Foundations Nanodegree program!\n\nLOVE that she\u2019s already thinking about her next program \u2026 Here\u2019s to #LifelongLearning!\n\nAnd THAT \u2026 brings us to the big finale!\n\nAre we above sharing puppy pics? No. No, we\u2019re not.\n\nTo ALL our students, you\u2019re ALL awesome!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer, Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-january-18th-2017-c116eca49ab2",
        "title": "This week in AI, January 18th 2017 \u2013 Udacity Inc \u2013",
        "text": "This week, we discovered a great analysis in response to a claim that artificial intelligence can infer sexual orientation from facial images. The authors found that AI algorithms pick up social and cultural signals like makeup, facial hair, and face tans \u2014 not facial structure, as is claimed in the study.\n\nIn controlled studies, humans can\u2019t tell sexual orientation from images alone. In social situations, we use cues like hair style, clothing, and behavior to judge sexual orientation. Similarly, an AI algorithm trained on images containing these cues will learn the same (sometimes stereotyped) judgements.\n\nThis is another powerful example of biased data leading to biased models. The whole article is worth a read.\n\nThis week, the team at OpenAI released a new method for training larger models on single GPUs, called gradient checkpointing. They found that \u201cfor feed-forward models we were able to fit more than 10x larger models onto our GPU, at only a 20% increase in computation time.\u201d This is great news for normal people like you and me who don\u2019t have access to clusters of GPUs.\n\nSo far, researchers and engineers have had to build distributed systems of GPUs to train the largest models efficiently. However, distributed GPUs are difficult to configure and maintain, and they take up a lot of time better used for innovation. Not to mention, individual contributors typically can\u2019t afford them. Being able to fit larger models on single GPUs opens up the range of possible models the community can explore.\n\nHere\u2019s some great work on automating front end development. The author trained a deep learning network to take a design mockup image and return the appropriate HTML tags to generate the corresponding layout.\n\nWhile this may at first glance seem a little bit like AI is going to make front-end developers obsolete, this is actually just replacing the busy work of turning a mockup into HTML which allows front-end developers to spend more time on the creative aspects of web design.\n\nFrom Booz Allen Hamilton, a new competition on Kaggle focusing on automating cell nucleus detection.\n\nSeems like a great problem to tackle with deep learning!"
    },
    {
        "url": "https://medium.com/udacity/udacity-goes-to-the-north-american-international-auto-show-in-detroit-20f4b3cdf27d",
        "title": "Udacity goes to the North American International Auto Show in Detroit",
        "text": "I am excited to be visiting Detroit next week for the North American International Auto Show. Please come say hello if you\u2019re attending, or send me an email at david.silver@udacity.com.\n\nWednesday, January 17, 12:30pm: I\u2019ll be at Automobili-D, speaking on a panel about the autonomous driving industry. Come watch! If you\u2019re a Udacity student, we\u2019ll take you to lunch afterward.\n\nThursday, January 18, 6pm: RSVP for our Career Workshop and Meetup! We\u2019ll teach you how to present yourself to recruiters in the autonomous vehicle industry, and you\u2019ll practice pitching yourself to other attendees. Also, free food!\n\nSaturday, January 20, 10:30am: I\u2019ll be speaking at the Future Automotive Career Exposition at NAIAS. Introduce yourself to me, then introduce yourself to the many recruiters who will be hiring autonomous vehicle engineers!\n\nSee you in Detroit!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-january-13-cd9117162ac",
        "title": "Flying Car News, January 13 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: A Volocopter Flies at Intel CES Keynote, the arrival of \u201cbat drones,\u201d circular drone runways, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nGerman flying car company Volocopter flew their autonomous air taxi for the first time in the United States on stage during Intel\u2019s keynote at the Consumer Electronics Show (CES) in Las Vegas.\n\nThe US government is hosting a competition to create flying robots that move like living animals to improve the maneuverability and stealth characteristics of a new generation of drones.\n\nAt CES, commercial drone operations software company Kittyhawk announced a new automated flight system for its enterprise mobile application.\n\nA Dutch engineer named Henk Hesselink is working with Valkenburg airport in the Netherlands to create a circular-shaped runway for a future autonomous drone innovation hub.\n\nUber recently hired a battery expert named Celina Mikolajczak from Tesla to help develop its Uber Elevate Flying Car project.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-january-12-edition-9a97b49b7c6f",
        "title": "This Week at Udacity, January 12 edition \u2013 Udacity Inc \u2013",
        "text": "Welcome to the first This Week at Udacity of 2018! Already, SO much going on, and it\u2019s all about YOU, and YOUR accomplishments this year. That\u2019s what the whole \u201cNew Year, New Skills\u201d campaign is all about. It\u2019s your chance to explore 8 different Nanodegree programs for free\u2014so go WAY outside of your wheelhouse if you want! Robotics? Got it. VR? Got it. Deep Learning? Got it!\n\nYou can read about it all right here:\n\nSo, that was the 1st of January.\n\nAfter that, the news just kept on coming. Cutting-edge new curriculum in our Machine Learning Engineer Nandegree program? You bet! (Spoiler Alert: It includes a section on Sebastian Thrun\u2019s cancer detection work, and a Quadcopter project!)\n\nNew partnership with Baidu, announced at CES? Yep, that happened too!\n\nDavid Silver, the head of our Self-Driving Car Engineer Nanodegree program, was so excited about the partnership news, he even penned his own post about it, right here on Medium!\n\nAnd speaking of right here on Medium, have you been following our new Flying Car News series? If you had ANY doubts about whether Flying Cars were really coming, this series will open your eyes to some amazing things that are already happening. Check out the latest!\n\nAnd speaking of amazing things already happening, how about THIS new series!\n\nWe\u2019d be remiss if we didn\u2019t mention one thing that happened this week that we were particularly excited about\u2014the opportunity to quote Snoop Dog in an aspirational article about learning to code!\n\nWhich brings us to your favorite section and mine, the \u2026\n\nTechnically, it\u2019s been two weeks since we last published, since we took the first week off. So really, you\u2019ll have to excuse us if we add a few tweets here! And why wouldn\u2019t we, when the news about the #GrowWithGoogle scholarships just went out, and there are all these great tweets about it!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer, Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-ai-january-11th-2018-b988558065fd",
        "title": "This Week in AI, January 11th 2018 \u2013 Udacity Inc \u2013",
        "text": "Generative Adversarial Networks (GANs) were recently highlighted in the New York Times.\n\nThis type of architecture has made amazing progress in generating realistic but completely synthetic data such as images. Work like this is a huge step towards artificial general intelligence.\n\nWhat makes humans exceptional is our ability to imagine, to generate completely synthetic data. We work through math in our head, visualize the design of websites and machinery, predict how customers will use our products, and consider how our decisions will effect the people around us.\n\nArtificial general intelligence will need this internal representation and the ability to generate new possibilities. This is exactly what GANs have done, at least one of our best attempts so far. The network learns an internal representation from the images given to it, and can then produce new images from that representation, in effect an imagination. There is still a lot of work to be done and GANs might not be the final answer. But, we\u2019re getting closer to machines that understand the world.\n\nA new version of TensorFlow was released with some interesting improvements.\n\nFirst up is eager execution which allows you to immediately get the results of operations as you\u2019re writing the code. TensorFlow has a reputation for being difficult to develop due to the way you build the graph and run data through it. If you\u2019ve used PyTorch before, this type of execution will be familiar. Adding eager execution is a good move for TensorFlow, and will reduce development time with the framework.\n\nSecondly, now there are pre-built binaries supporting CUDA 9 and AVX which means we should start seeing better runtime performance for some networks on GPUs and CPUs.\n\nStay tuned for new updates as we continue to review all that\u2019s new in the world of AI! And if you\u2019re interested in mastering these transformational skills, and building a rewarding career in this amazing space, consider one of our Nanodegree programs:"
    },
    {
        "url": "https://medium.com/udacity/udacity-and-baidus-new-course-introduction-to-apollo-4eb244313e8c",
        "title": "Udacity and Baidu\u2019s New Course: Introduction to Apollo",
        "text": "Big news from CES! Udacity is going to produce a one-month free course on developing self-driving car software with Baidu Apollo! Sebastian Thrun, Udacity\u2019s founder (and the father of the self-driving car), announced this together with Baidu COO Qi Lu at CES today.\n\nBaidu has open-sourced their self-driving car software stack, Apollo, with the goal of creating the \u201cAndroid of the autonomous driving industry\u201d.\n\nUdacity\u2019s upcoming \u201cIntro to Apollo\u201d course will focus on the top two layers: Cloud Service and Apollo Open Software Stack.\n\nApollo is an incredibly exciting platform in the autonomous vehicle industry. We are thrilled to work with the Apollo team to teach students and engineers around the world how to build self-driving car software quickly using the Apollo stack.\n\nI am especially delighted that this will be a free course, open to anyone with the desire to enter this amazing field. There is a huge demand for knowledge about how self-driving cars work, and this course will help educate the world on this topic. Our Self-Driving Car Engineer Nanodegree Program is an intense nine-month journey to becoming a self-driving car engineer, and it offers an amazing learning experience, but it is for advanced engineers. And while our Intro to Self-Driving Cars Nanodegree program is an excellent point-of-entry for aspiring learners newer to the field, it offers an equally immersive experience. This course offers adds something new and important to the range of learning options.\n\nThis is a special opportunity for us to collaborate with Baidu, one of the leading companies in China. China is a leader in the autonomous vehicle industry. And Chinese students currently make up 5% of enrollment in Udacity\u2019s Self-Driving Car Engineer Nanodegree Program, and 20% of enrollments in all Udacity programs. A major focus for our Self-Driving Car Program in 2018 is to reach even more students in China.\n\nThe course will be developed jointly by Baidu\u2019s Apollo team, the Udacity Self-Driving Car team in Mountain View, and the Udacity China team. The course will be in English, but this is a new experiment for us in developing course material in one of our offices outside of the US. I\u2019m excited.\n\nDid I mention I\u2019m excited about this course? Because I\u2019m excited!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-january-6-b59712b590ca",
        "title": "Flying Car News, January 6 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: A DeLorean flying car in 2018, autonomous quadrotor swarms, drone blood delivery, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nDelorean Aerospace announced that its flying car should fly by the end of 2018. A \u2153-size proof of concept of the personal commuter aircraft has already been tested. The final version should reach top speeds of up to 240 mph with a 120-mile range.\n\nResearchers at the University of Pennsylvania are testing autonomous quadrotor swarms by using visual inertial odometry to estimate their location and orientation in space.\n\nRichard\u2019s Architecture + Design has designed a futuristic net-zero tower with numerous docking platforms for flying cars throughout the structure. It is exciting to see designers tackling the challenge of providing the infrastructure needed to support the future of urban air transport.\n\nDrone delivery company Matternet has submitted an application to approve a pilot program to test drone blood delivery from Stanford Blood Center to Stanford Hospital in Palo Alto. Silicon Valley could be the first place in the United States to allow the use of drones to deliver blood!\n\nThe Laurel Marine Survey Team and Flying Cam team successfully tested the use of their unmanned autonomous helicopter by using sonar to discover a ship sunk over 70 years ago in WWII.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/these-pioneering-graduates-inspire-us-to-learn-more-in-the-new-year-15f41d651b31",
        "title": "These Pioneering Graduates Inspire Us To Learn More In The New Year",
        "text": "In his post, Andr\u00e1s expressed gratitude for the enjoyment this challenge provided, and thanked the instructors, mentors and colleagues that combined to make his experience such a positive one.\n\nIf you\u2019re surprised to see a graduate from an online learning program expressing such positive feelings about his community, don\u2019t be! Human connection is a big part of the Udacity learning experience, and our students regularly cite community as one of the most valuable aspects of their time with us.\n\nFor a wonderful footnote to Andr\u00e1s\u2019 story, scroll down and take a look at the first two people to comment on Andr\u00e1s\u2019 post\u2014David Silver and Frank Fuqiang Xu! Their congratulatory comments reinforce the strength of the connections our students make with one another, and with us!\n\nIf you\u2019ve been curious about how an online program might fit into your schedule, you might find this post from Jelena Koci\u0107 to be quite instructive. She\u2019s a mother, a full-time software engineer, and a PhD student. She\u2019s also a Nanodegree program graduate! She describes her experience as being an \u201cexciting journey of sleepless nights, and working through the weekend.\u201d\n\nJelena, like so many of us, has a lot going on. Fortunately, our platform is built to be flexible. While you need to meet deadlines, and keep pace with the curriculum and the work of your peers, you can do so in ways that align with your outside commitments, and not risk missing anything.\n\nAn engaged community of students and instructors is a hallmark of the Nanodegree program experience, and the existence of this community can make all the difference when it comes to delivering something that goes beyond straightforward online learning."
    },
    {
        "url": "https://medium.com/udacity/unexpected-time-struggles-6592c96fdc35",
        "title": "WHEN \u201cTIME\u201d HAPPENS: Unexpected Struggles of a Marketer",
        "text": "After 12 years of working in marketing and advertising, the most unexpected situation in my life happened to me.\n\nAs a working mom with a little kid, living away from my family, with my husband running a start-up, I couldn\u2019t believe it. Extra time? Is this for real?\n\nBut work authorization procedures take time and sometimes there\u2019s not much you can do to speed up the bureaucracy. At some point, you have to sit down and wait. Whether you like it or not.\n\nNow, you have to know one thing about me. I\u2019ve held at least one job at a time since I was 13 and suddenly I felt lost. What do you do in this kind of situation? You get some sleep, spend extra time with your kid, read a few books. You finally frame a few family pictures and organize a quick trip. Then what?\n\nI\u2019ve decided to take this opportunity to reevaluate my career status. I got my marketing degree over a decade ago and since then I\u2019ve been trying to pick up knowledge on the go, squeezing chapters of articles between meetings, attending conferences while answering my client\u2019s emails, checking trends, trying to keep my head above the water. Marketing is a fast-paced industry where recently everything changed with social media, smart phones, SEO, and it feels that technology is always two steps ahead of you.\n\nA few brainstorms later I figured out that I crave knowledge. Education. Online, where I could study at my own pace in an organized, well thought-out, supportive environment. I tried couple of courses and I dropped all of them. Themes were out of date, programs were not student-friendly, projects too theoretical, not applicable to the real world.\n\nThen a friend suggested Udacity Digital Marketing Nanodegree program and I immediately knew that was it. 3 months of practical courses, lectures on current topics, Facebook and Adwords campaigns, chapters on SEO, practicing with MailChimp, HootSuite, MOZ, HubSpot.\n\nI was sure that the Digital Marketing Nanodegree program was going to be beneficial and a piece of cake at the same time, but I was wrong.\n\nThe program is fantastic and I enjoyed every minute of it. But life happened and it turned out I didn\u2019t have as much time as I\u2019d anticipated. Kids break their arms, friends need you and opportunities show up. I was struggling to find enough time to study. And if it weren\u2019t for my mentor, I would have never completed it. She answered all my questions in the middle of the night, solved my technical glitches and supported me when my energy levels were down. The program is a real deal and it takes effort. But it\u2019s practical, doable, well-explained, beneficial and highly supported by the Udacity team. Best career decision of 2017.\n\nSo here I am. Almost out of my extra time, catching the last course deadline. Now that I know what to do with it, I hope for some extra time in 2018 too."
    },
    {
        "url": "https://medium.com/udacity/how-udacity-students-build-path-planners-for-highway-driving-5fa9a34d4e23",
        "title": "How Udacity Students Build Path Planners for Highway Driving",
        "text": "Many students describe the Path Planning Project as the most challenging project in the entire Udacity Self-Driving Car Engineer Nanodegree program. This is understandable. Path planning is hard! But it\u2019s not too hard, and I\u2019m going to tell you a bit about the project\u2014and about path planning in general\u2014in this post.\n\nThere are three core components to path planning: 1) Predicting what other vehicles on the road will do next, 2) Deciding on a maneuver to execute, in response to our own goals, and to our predictions about other vehicles, and 3) Building a trajectory to execute the maneuver we decide on.\n\nThis is a project that provides students a lot of freedom in how to implement their solution. Here are five approaches from our amazing students!\n\nI love Mithi\u2019s series of posts on the Path Planning Project. Her first post covers the project outline and her solution design process. The second post covers her data structures and pipeline. The third and final post dives into the mechanics and math required to actually produce a path. This is a great series of posts for anybody thinking about building a path planner.\n\nIn contrast to Mithi\u2019s articles, which take you through her process of building a path planner, Mohan\u2019s writeup does a great job of describing the final result. In particular, I was interested to read about the voting system he used for deciding on lane changes.\n\nInstead of quoting Mohan, I\u2019ll share the flowchart he built:\n\nThis installment of Andrew\u2019s long-running \u201cdiary\u201d covers the Path Planning Project at a high level, and details how it fits into the third term of the Nanodegree program. Like his fellow classmates, Andrew also found this to be a challenging project.\n\nShyam\u2019s post contains a particularly concise 6-point walkthrough of trajectory generation, which is both fundamental to building a path planner, and surprisingly challenging.\n\nAlena touches on several interesting points with her post. She focuses on cost functions, which she identifies as the most important part of the project. The post describes her finite state machine and the associated cost functions in detail, and describes how the car decides when to shift lanes. She also touches on how she merged the two branches of her path planner \u2014 one for the Nanodegree project, and one for the Bosch Challenge \u2014 to create a more generalized planner.\n\nSeeing our students working through these challenges, experiencing their solutions, and learning about their processes fills me with so much excitement about the future of this field\u2014these students represent the next generation of self-driving car engineers, and based on the work they\u2019re already doing, I am certain they\u2019re going to be making incredible contributions. I am especially moved by their generosity in taking the time to share in such detail the work they\u2019re engaged in, and it\u2019s a real pleasure to share their articles with you.\n\nReady to start working on self-driving cars yourself? Apply for our Udacity Self-Driving Car Engineer Nanodegree program today!"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-december-30-8ebef0634003",
        "title": "Flying Car News, December 30 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Will blimps disrupt the drone inspection industry? Did a UK startup just unveil a new passenger drone? Will the FAA pave the way for delivery drones in the U.S.? Discover the answers to these questions, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nMothership Aeronautics is creating an autonomous solar-powered long distance blimp which they hope will disrupt the drone inspection industry.\n\nUK company Autonomous flight announced passenger drone Y6S, which can carry two passengers up to 70 mph.\n\nThe FAA released a report with recommendations on the best way to identify flying drones, effectively paving the way for delivery drones in the U.S.\n\nLazzarini Design has created a concept retro flying car called the Hover Coupe modeled after luxury cars of the 1920s.\n\nBoeing unveiled the MQ-25 Stingray aerial tanker which will be able to carry 15000 pounds of fuel and autonomously refuel fighters after taking off from an aircraft carrier.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/your-most-read-stories-of-2017-8c2f280bdfeb",
        "title": "Your Most-Read Stories of 2017 \u2013 Udacity Inc \u2013",
        "text": "We read blogs for many reasons\u2014to get information, and to get inspired; for pleasure, and for research; to learn more about a person, and to learn more about a company.\n\nJudging by the Top 10 Most-Read Stories published on Udacity\u2019s Medium publication this year, you read this blog because you want details about what we teach! Fully 50% of the top posts focused on curriculum. For your reference, here are those 5 posts, presented chronologically in the order they were first published:\n\nYou also enjoyed Student Success Stories, written by the lifelong learners who actually lived the stories\u2014these two wonderful tales made the Top 10 as well:\n\nAlso popular were informational posts that provided actionable advice, like these two Top 10 posts:\n\nIf you\u2019re counting, you\u2019ll note we\u2019re up to nine posts now. We\u2019ll close out our 2017 summary by sharing our #1 Most-Read Post of 2017, and in doing so, we\u2019ll congratulate our very own Brad Crispin, the post\u2019s author. Great work Brad! Your wonderful post\u2014which is simultaneously heartwarming, inspiring, motivating, and informative\u2014captured the hearts and eyes of our readers this year, and is officially our most-read post of 2017:\n\nThank you to every single one of you who took the time to come and read something from Udacity this year, we appreciate it so much! We hope to inspire and inform with everything we publish, and looking back on these results now, it\u2019s deeply gratifying to feel as if we were able to offer something of value to you.\n\nThank you as well to all the wonderful writers who\u2019ve contributed to this publication\u2014your words have moved people, and lives have been changed.\n\nWriters, please keep the wonderful words coming, and readers, please keep coming back to read. There are stories afoot!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-december-23-8a9264b32df2",
        "title": "Flying Car News, December 23 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: A new \u201chomebuilt\u201d flying car, autonomous drones that help farmers, flying insect-scale robots, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nSamson motors is creating a flying car with three wheels that will be classified as a \u201chomebuilt vehicle\u201d because 51% of the vehicle must be built by the owner.\n\nAmerican Robotics recently unveiled their fully autonomous drone system for farming. The self-charging, self-managing drone system requires no manual intervention to run its operations.\n\nNicholas Roy, professor at MIT, founder of Google X Project wing, and an instructor for the Udacity Flying Car Nanodegree Program discusses the differences between the Flying Car Nanodegree Program and the Self Driving Car Nanodegree Program in an insightful new blog post.\n\nFlying insect bots the size of a penny require the use of \u201cneuromorphic chips\u201d (which are modeled after how neurons fire in the brain) in order to pack the computation required on such a small form factor.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/the-convolutional-neural-networks-lesson-3c6df66f421b",
        "title": "The \u201cConvolutional Neural Networks\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "The 8th lesson of the Udacity Self-Driving Car Engineer Nanodegree program is \u201cConvolutional Neural Networks.\u201d This is where students learn to apply deep learning to camera images!\n\nConvolutional neural networks (CNNs) are a special category of deep neural networks that are specifically designed to work with images. CNNs have multiple layers, with each layer connected to the next by \u201cconvolutions.\u201d\n\nIn practice, what this means is that we slide a patch-like \u201cfilter\u201d over the input layer, and the filter applies weights to each artificial neuron in the input layer. The filter connects to a single artificial neuron in the output layer, thereby connecting each neuron in the output layer to a small set of neurons from the input layer.\n\nTo make this more concrete, consider this photograph of a dog:\n\nWhen we run this photograph through a CNN, we\u2019ll slide a filter over the image:\n\nThis filter will, broadly speaking, identify basic \u201cfeatures.\u201d It might identify one frame as a curve, and another as a hole:\n\nThe next layer in the CNN would pass a different filter over a stack of these basic features, and identify more sophisticated features, like a nose:\n\nThe final layer of the CNN is responsible for classifying these increasingly sophisticated features as a dog.\n\nThis is of course simplified for the sake of explanation, but hopefully it helps to make the process clear.\n\nOne of the more vexing aspects of deep learning is that the actual \u201cfeatures\u201d that a network identifies are not necessarily anything humans would think of as a \u201ccurve\u201d or a \u201cnose.\u201d The network learns whatever it needs to learn in order to identify the dog most effectively, but that may not be anything humans can really describe well. Nonetheless, this description gets at the broad scope of how a CNN works.\n\nOnce students learn about CNNs generally, it\u2019s time to practice building and training them with TensorFlow. As Udacity founder Sebastian Thrun says, \u201cYou don\u2019t lose weight by watching other people exercise.\u201d You have to write the code yourself!\n\nThe back half of the lesson covers some deep learning topics applicable to CNNs, like dropout and regularization.\n\nThe lesson ends with a lab in which students build and train LeNet, the famous network by Yann LeCun, to identify characters. This is a classic exercise for learning convolutional neural networks, and great way to learn the fundamentals.\n\nReady to start learning how to build self-driving cars yourself? Great! If you have some experience already, you can apply to our Self-Driving Car Engineer Nanodegree program here, and if you\u2019re just getting started, then we encourage you to enroll in our Intro to Self-Driving Cars Nanodegree program here!\n\nThanks to my former colleague, Dhruv Parthasarathy, who built out this intuitive explanation in even greater detail as part of this lesson!\n\nWe\u2019re also grateful to Vincent Vanhoucke, Principal Scientist at Google Brain, who teaches the free Udacity Deep Learning course, from which we drew for this lesson."
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-18-december-2017-7e3b7fd4a8a9",
        "title": "This Week in Machine Learning, 18 December 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: an AI-generated Harry Potter chapter, a smartphone-based lightsaber, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nBanking giant Capital One commits a $3 million endowment to the University of Maryland to cultivate talent in machine learning, data analysis, and cybersecurity.\n\nSt. Louis-based startup Prattle applies natural language processing to earning announcements and bank policy statements to enhance market predictions.\n\nScientists from MIT\u2019s Media Lab use machine learning to train computers to comprehend the emotional arcs present in movies like Pixar\u2019s Up.\n\nDigital marketing agency iProspect reports 55% of marketers say machine learning helps them make better decisions; 56% say machine learning is a top 2018 priority.\n\nDevelopers train an agent on the Harry Potter series, which goes on to generate the first three pages of \u201cHarry Potter and the Portrait of What Looked Like a Large Pile of Ash.\u201d\n\nUsing deep learning, a Redditor makes a smartphone app called InstaSaber that turns live footage of a rolled-up piece of paper into a lightsaber."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-december-16-7e488e6d506f",
        "title": "Flying Car News, December 16 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Mercedes Benz successfully tests delivery drones, Charles Lindbergh\u2019s grandson announces a flying car startup, autonomous drones make headway against deadly diseases, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nMercedes Benz used drones to successfully conduct over 100 deliveries of everyday items like ground coffee and cellphones in Zurich.\n\nAustralian startup Aulada announced its prototype for a Flying Race Car, called \u201cAirspeeder,\u201d which is inspired by classic 1960\u2019s Formula V race cars.\n\nStudio Drift partnered with BMW to create a drone swarm art display in Miami. The flying sculpture, entitled \u201cFranchise Freedom,\u201d is meant to emulate the natural flying behavior of birds.\n\nAutonomous drones are helping defeat diseases like Zika, dengue, and malaria by delivering millions of sterile male mosquitoes to difficult-to-reach areas.\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-december-15-edition-ccd4b47da31d",
        "title": "This Week at Udacity, December 15 edition \u2013 Udacity Inc \u2013",
        "text": "Because we write this post on Fridays, our \u201cweek\u201d technically begins on Saturday, and that\u2019s really important to know THIS week, because we got to share a great story last Saturday, about a really amazing Udacity student\u2014you can read her story here:\n\nAnd that\u2019s not the ONLY Saturday news we\u2019d like to share\u2014did you know we\u2019ve started a new series right here on Medium, that publishes on Saturdays? It\u2019s true! It\u2019s our new Flying Car News series! It\u2019s curated by Tucker Dunn, the Program Lead for our Flying Car Nanodegree program, and every week, he shares some of the most compelling stories to emerge from the world of Flying Cars. You can find the most recent post in the series here:\n\nWant some more news? You got it! Here\u2019s the BIG story from the week, Early Bird Intersect 2018 tickets are now available!\n\nAnd in other news, did you get to see Kelly Howard, from our Intro to Programming Nanodegree Program, on Facebook Live? She was taking all sorts of questions about learning to code, and it was awesome! If you missed it, no worries! You can watch the whole thing right here:\n\nAnd since we\u2019re now into Social Media country, that must mean it\u2019s time for \u2026\n\nJust had to share this one. Because we can\u2019t resist a crazy GIF:\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/how-self-driving-cars-work-f77c49dca47e",
        "title": "How Self-Driving Cars Work \u2013 Udacity Inc \u2013",
        "text": "Earlier this fall I spoke about how self-driving cars work at TEDxWilmington\u2019s Transportation Salon, which was a lot of fun.\n\nThe frame for my talk was a collection of projects students have done as part of the Udacity Self-Driving Car Engineer Nanodegree Program.\n\nSo, how do self-driving cars work?\n\nComputer vision is how we use cameras to see the road. Humans demonstrate the power of vision by handling a car with basically just two eyes and a brain. For a self-driving car, we can use camera images to find lane lines, or track other vehicles on the road.\n\nSensor fusion is how we integrate data from other sensors, like radar and lasers\u2014together with camera data\u2014to build a comprehensive understanding of the vehicle\u2019s environment. As good as cameras are, there are certain measurements \u2014 like distance or velocity \u2014 at which other sensors excel, and other sensors can work better in adverse weather, too. By combining all of our sensor data, we get a richer understanding of the world.\n\nLocalization is how we figure out where we are in the world, which is the next step after we understand what the world looks like. We all have cellphones with GPS, so it might seem like we know where we are all the time already. But in fact, GPS is only accurate to within about 1\u20132 meters. Think about how big 1\u20132 meters is! If a car were wrong by 1\u20132 meters, it could be off on the sidewalk hitting things. So we have much more sophisticated mathematical algorithms that help the vehicle localize itself to within 1\u20132 centimeters.\n\nPath planning is the next step, once we know what the world looks like, and where in it we are. In the path planning phase, we chart a trajectory through the world to get where we want to go. First, we predict what the other vehicles around us will do. Then we decide which maneuver we want to take in response to those vehicles. Finally, we build a trajectory, or path, to execute that maneuver safely and comfortably.\n\nControl is the final step in the pipeline. Once we have the trajectory from our path planning block, the vehicle needs to turn the steering wheel and hit the throttle or the brake, in order to follow that trajectory. If you\u2019ve ever tried to execute a hard turn at a high speed, you know this can get tricky! Sometimes you have an idea of the path you want the car to follow, but actually getting the car to follow that path requires effort. Race car drivers are phenomenal at this, and computers are getting pretty good at it, too!\n\nThe video at the beginning of this post covers similar territory, and I hope between that, and what I\u2019ve written here, you have a better sense of how Self-Driving Cars work.\n\nReady to start learning how to do it yourself? Apply for our Self-Driving Car Engineer Nanodegree program, or enroll in our Intro to Self-Driving Cars Nanodegree program, depending on your experience level, and let\u2019s get started!"
    },
    {
        "url": "https://medium.com/udacity/your-resume-is-still-important-very-important-9819b330912f",
        "title": "Your Resume Is Still Important. Very Important. \u2013 Udacity Inc \u2013",
        "text": "When it comes to landing your dream job, the fundamental things still apply!\n\nMuch has changed when it comes to recruiting. One of more provocative writers on the recruiting landscape is Matt Charney, and a quick look at some of his recent post titles on Recruiting Daily signals the scope of what recruiters are thinking about in this day and age:\n\nHire Power: What Google\u2019s New Applicant Tracking System Means for HR Technology.\n\nThat Would Be Great: Sentiment Analysis for HR and Recruiting.\n\nOver at Fistful of Talent, a collective of similarly provocative voices, you\u2019ll find equally wide-ranging topics being addressed:\n\nThe *Real* Way You Make Your Employer Brand Come To Life On Social Media\n\nYou Already Have Ai In Your Company \u2014 Time To Energize It!\n\nHow Much Career Development Do You Owe Your Employees?\n\nClearly, recruiting and hiring has advanced into a whole new era! And yet, here is the first sentence from an article published in Entrepreneur just yesterday:\n\nThe more things change, they more they stay the same, right? The truth is, your resume IS still very important. That\u2019s why, in our Career Resource Center, we offer you so much support when it comes to making your resume shine!\n\nFor example, are you familiar with Jobscan?\n\nYou can learn more about their service here.\n\nUdacity also offers a full guide on how to optimize your resume, called Resume Revamp.\n\nAdditionally, we curate articles for you that deliver actionable insights on how to improve your resume, like this one:\n\n45 Quick Changes That Help Your Resume Get Noticed\n\nThese are just some of the resources you\u2019ll find in our Career Resource Center. Other offerings include:\n\nWhen it comes to landing your dream job, you\u2019ll do well to remember those memorable lyrics from Casablanca, as sung by Sam (played by Dooley Wilson) in Casablanca:\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-11-december-2017-6e1963619ae1",
        "title": "This Week in Machine Learning, 11 December 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: searching for extraterrestrial life, writing black metal music, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nNASA announces a major discovery will be unveiled on Thursday, December 14th, noting machine learning expertise from Google played a major role in the project.\n\nGoogle brings its machine learning expertise to its Sheets spreadsheet tool, focusing especially on analysis of natural language within structured datasets.\n\nZack Zukowski and CJ Carr use artificial intelligence to learn from existing pieces of music and generate an entire new song, releasing a musician-free black metal album.\n\nRaytheon BBN Technologies applies machine learning techniques to uncovering the root cultural and societal factors that cause violent conflicts.\n\nThe Sundance Film Festival adds new experimental works of art featuring artificial intelligence and virtual reality to its 2018 lineup.\n\nSouth Australia dedicates $7.1 million to machine learning research at the University of Adelaide, and the UK launches an initiative to give computing power to AI start-ups."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-december-9-b51e1849c5fd",
        "title": "Flying Car News, December 9 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Amazon patents drones that can self-destruct as a safety strategy, Udacity hosts a flying car panel, the Vahana flying car will get a test before the year is out, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nAmazon patents a drone that self-destructs in emergencies by using a \u201cfragmentation controller\u201d which slowly dismantles the drone by dropping pieces to the ground as it engages in a controlled crash landing:\n\nThe instructors of the Udacity Flying Car Nanodegree Program recently discussed the state of the Flying Car industry in a compelling panel:\n\nAirbus will test its Vahana flying car in Pendleton, Oregon by the end of 2017:\n\nNasa conducts the first successful test flight of a new-generation, fully-autonomous space shuttle:\n\nIf you\u2019re interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, explore Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-december-8-edition-956378c267df",
        "title": "This Week at Udacity, December 8 edition \u2013 Udacity Inc \u2013",
        "text": "Just when you think things are starting to mellow out around here, everything goes crazy again! What a week for Udacity, and for our students, partners, and community!\n\nYou may have seen this news this morning; how exciting is this? (hint: it\u2019s REALLY exciting!)\n\nPost author Leah Wiedenmann summed this up so beautifully:\n\nUdacity had the pleasure of making news all over the world this week. Did you see this article?\n\nI loved what Udacity COO Clarissa Chen had to say in her post about this historic launch:\n\nAnd speaking of launches, yours truly had the honor of announcing our newest Nanodegree program earlier this week:\n\nA Design Sprint is an extraordinarily effective way to harness creative energy, ensure the best ideas get put forward, and accelerate the processes by which great ideas become great products. (We run them at Udacity all the time!) In the new Design Sprint Foundations Nanodegree program, you can master this revolutionary 4-day methodology, and what you learn can be used by anyone, to advance any idea, or solve any problem (it\u2019s not just for designers!):\n\nA successful Design Sprint is essentially \u201cdesign thinking\u201d in action \u2014 it is a strategic method to leverage creativity in the service of building quality.\n\nAnd now, your favorite segment of this series and mine, the \u2026\n\nI\u2019d say this is a pretty self-explanatory expression of the lifelong learning ethos at its finest!\n\nAnd that \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/the-deep-neural-networks-lesson-c7a58a46c80",
        "title": "The \u201cDeep Neural Networks\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "I am continuing on my quest to write a post detailing every one of the 67 projects that currently comprise our Self-Driving Car Engineer Nanodegree program curriculum, and today, we look at the \u201cDeep Neural Networks\u201d lesson!\n\nStudents actually start learning about deep neural networks prior to this lesson, but this is the lesson where students begin to implement deep neural networks in TensorFlow, Google\u2019s deep learning framework.\n\nIn the previous lesson, \u201cIntroduction to TensorFlow,\u201d students learned to use TensorFlow to build linear models, like linear or logistic regression. In the \u201cDeep Neural Networks\u201d lesson, students learn new techniques in TensorFlow, to build up these models into neural networks.\n\nSome of the most important foundational blocks of neural networks are demonstrated in TensorFlow.\n\nStudents also learn some practical skills, like how to save and restore models in TensorFlow.\n\nFuture lessons take these basic skills and help students apply them to important problems for autonomous vehicles, like how to recognize traffic signs."
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-4-december-2017-ad830a88d9a5",
        "title": "This Week in Machine Learning, 4 December 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: improving radiology, machine learning at the top of security trends, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nNvidia partners with firms like Nuance and GE Healthcare to apply artificial intelligence and machine learning to radiological scans to speed up diagnosis.\n\nCybersecurity firm McAfee projects that adversarial machine learning will be among the greatest trends in online security in 2018.\n\nAdobe previews a new \u2018Select Subject\u2019 feature coming to future versions of Photoshop that will intelligently detect and select objects or people from images.\n\nExecutives at Google urge the world to adopt fair and responsible development of artificial intelligence, especially with an eye toward gender bias and user privacy.\n\nGoogle\u2019s recently-released Pixel 2 smartphone uses principles learned from analyzing millions of images to improve new images taken with the device.\n\nAmazon\u2019s web services division launches a new program to help partners connect with firms and employees who have experience working on machine learning problems on AWS."
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-27-november-2017-abe8bc4dfba4",
        "title": "This Week in Machine Learning, 27 November 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: improving solar supply chains, LiDAR systems, holographic reconstructions, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nVirgin Airlines partners with DataRobot to develop predictive models for when passengers will most appreciate cashing in frequent flyer rewards.\n\nA new report from advisory firm DNV GL projects that artificial intelligence and machine learning will be specifically impactful in developing new solar supply chains.\n\nResearchers at ProPublica apply machine learning to congressional data to launch a new Policy Priorities feature outlining each congressperson\u2019s legislative priorities.\n\nUCLA researchers use deep learning to rebuild holograms to improve optical microscopy with applications ranging from healthcare to scientific research.\n\nA new paper published via arXiv by Apple describes a method to use machine learning to improve the output of LiDAR arrays used in self-driving cars.\n\nGoogle partners with Pluralsight and Udacity to upskill workers in India, aiming to reach 130,000 developers within the next year."
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-20-november-2017-af486fdb9289",
        "title": "This Week in Machine Learning, 20 November 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: facial recognition, collision detection, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nScientists at UC-San Diego develop the Fastron algorithm, a machine learning-powered algorithm for collision detection in robotics.\n\nApple publishes new details in its Machine Learning Journal on the deep neural network system its devices use for facial recognition.\n\nGoogle previews TensorFlow Lite, a machine learning framework capable of running on mobile devices, bypassing the cloud entirely.\n\nA new study from University College London reveals that machine learning could improve the predictive power of clinical healthcare trials by detecting hidden effects.\n\nMicrosoft releases a beta version of Visual Studio Tools for AI, a plugin for their IDE that connects to frameworks like their own Cognitive Toolkit and Google\u2019s TensorFlow.\n\nIBM and Algorithmia both tackle adoption issues in artificial intelligence with new tools aiming to make it easier for researchers to get to results quicker."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-december-2-6553a93f39fe",
        "title": "Flying Car News, December 2 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: Airbus pursues autonomous pilotless airplanes, a hybrid octocopter is set to fly in Las Vegas, a British flying car company is accepting preorders, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nAirbus is hoping autonomous technology will help cut costs for carriers by reducing the amount of pilots needed to operate commercial aircraft, with the ultimate goal of replacing pilots entirely.\n\nThe SureFly octocopter is set to make its first manned flight in January in Las Vegas.\n\nBritish flying car NeoXcraft is accepting preorders now. Get yours by 2020!\n\nSan Diego Zoo Global partners with Northrop Grumman to deploy autonomous drones for Polar Bear Conservation.\n\nIf you\u2019re interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-december-1-edition-c6fbf8d947c",
        "title": "This Week at Udacity, December 1 edition \u2013 Udacity Inc \u2013",
        "text": "After last week\u2019s holiday break, we\u2019re back with two weeks of Udacity news, and what a two weeks it\u2019s been!\n\nPossibly the most exciting thing that happened during the whole two-week period actually took place last night, when we hosted \u201cCrossing the Finish Line: A Graduation Celebration.\u201d This was a a special event celebrating the pioneering accomplishments of the first graduates of our Self-Driving Car Engineer Nanodegree program.\n\nAs thrilling as this event was, it wasn\u2019t the only exciting news from the week. Our Robotics Software Engineer Nanodegree program team had a pretty big announcement to make:\n\nThe week before was of course Thanksgiving here in the US, and all of us at Udacity were certainly feeling very thankful! We shared our gratitude here \u2026\n\n\u2026 and had a bit of fun with a Thanksgiving acrostic here:\n\nBest of all, we got to take a look back at some wonderful Student Success stories:\n\nWhich two weeks\u2019 worth of options to choose from, it\u2019s going to be quite a challenge to pick our \u2026\n\nActually, not so difficult at all. Nothing better than 50,000 new Udacity learners!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/the-introduction-to-tensorflow-lesson-7600eae32110",
        "title": "The \u201cIntroduction to TensorFlow\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "TensorFlow is Google\u2019s library for deep learning, and one of the most popular tools for building and training deep neural networks. In the previous lesson, MiniFlow, students build their own miniature versions of a deep learning library. But for real deep learning work, an industry-standard library like TensorFlow is essential.\n\nThis lesson combines videos from Vincent Vanhoucke\u2019s free Udacity Deep Learning course with new material we have added to support installing and working with TensorFlow.\n\nStudents learn the differences between regression and classification problems. Then they to build a logistic classifier in TensorFlow. Finally, students use fundamental techniques like activation functions, one-hot encoding, and cross-entropy loss to train feedforward networks.\n\nMost of these topics are already familiar to students from the previous \u201cIntroduction to Neural Networks\u201d and \u201cMiniFlow\u201d lessons, but implementing them in TensorFlow is a whole new animal. This lesson provides lots of quizzes and solutions demonstrating how to do that.\n\nTowards the end of the lesson, students walk through a quick tutorial on using GPU-enabled AWS EC2 instances to train deep neural networks. Thank you to our friends at AWS Educate for providing free credits to Udacity students to use for training neural networks!\n\nDeep learning has been around for a long time, but it has only really taken off in the last five years because of the ability to use GPUs to dramatically accelerate the training of neural networks. Students who have their own high-performance GPUs are able to experience this acceleration locally. But many students do not own their own GPUs, and AWS EC2 instances are a cloud tool for achieving the same results from anywhere.\n\nThe lesson closes with a lab in which students use TensorFlow to perform the classic deep learning exercise of classifying characters: \u2018A\u2019, \u2018B\u2019, \u2018C\u2019 and so on."
    },
    {
        "url": "https://medium.com/udacity/flying-car-news-november-25-85ea79cfb220",
        "title": "Flying Car News, November 25 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Flying Car News: A new Uber and Nasa collaboration, flying police motorcycles in Abu Dhabi, the future of life-saving drones, and more!\n\nFlying cars will be a significant part of the future of transportation. Recent advancements in drone technology, electric VTOL aircraft, and autonomous systems have paved the way for an aerial transportation revolution. We created the Udacity Flying Car News Series, to ensure you stay up-to-date on all the latest Flying Car and Autonomous Aircraft stories!\n\nNasa calls for market study on Urban Air Mobility (UAM) to create a safe and efficient system for air passenger and cargo transportation within an urban area.\n\nUber\u2019s flying car project \u201cElevate\u201d partners with Nasa to test aerial taxis in Los Angeles, Dallas Fort-Worth, and Dubai by 2020.\n\nTechcrunch provides a snapshot of the current flying car ecosystem and analyzes the future of transportation.\n\nPolice in Abu Dhabi may soon incorporate flying motorcycles into their fleet of police vehicles.\n\nRecent advances in the autonomous drone technology are proving that drones can deliver potentially life-saving support to communities in need. Will federal regulators take notice?\n\nIf you are interested in joining the pioneering generation of engineers who will build the smart transportation systems of the future, discover Udacity\u2019s Flying Car Nanodegree Program today!\n\nAnd stay tuned for more Flying Car News!"
    },
    {
        "url": "https://medium.com/udacity/a-thanksgiving-acrostic-poem-for-udacity-students-11c732e0af0c",
        "title": "A Thanksgiving Acrostic Poem for Udacity Students! \u2013 Udacity Inc \u2013",
        "text": "The reason we are here. Without you, there is no Udacity!\n\nHeroes. The pioneering lifelong learners we look up to, and are uplifted by.\n\nNimble, and dynamic. Moving, pivoting, and adapting to changing demands and circumstances, and always fleet of mind.\n\nKnowledgeable. Mastering the latest skills, at the cutting edge of learning.\n\nSkilled, and equipped with the most valuable and valued competencies.\n\nGrowth-minded. Committed to lifelong learning, and the development of your talents and skills.\n\nInspiring, setting a remarkable example for all to see, and to be motivated by.\n\nValuable, in demand, and bringing with you the promise of a better future.\n\nInnovative. Constantly pushing the limits of creativity and technology to uncover new solutions, new ways forward, new ways to create, build, and solve.\n\nNurturing, embracing membership in a global community of lifelong learners who both teach and learn in equal measure.\n\nGlobal, and together comprising a worldwide community of lifelong learners.\n\nYou are all this, and more. You are the reason we are here, and we are thankful for you. Happy Thanksgiving!"
    },
    {
        "url": "https://medium.com/udacity/the-miniflow-lesson-929200f72e27",
        "title": "The \u201cMiniFlow\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "Editor\u2019s note: David Silver (Program Lead for Udacity\u2019s Self-Driving Car Engineer Nanodegree program), continues his mission to write a new post for each of the 67 lessons currently in the program. We check in with him today as he introduces us to Lesson 5!\n\nThe 5th lesson of the Udacity Self-Driving Car Engineer Nanodegree Program is \u201cMiniFlow.\u201d Over the course of this lesson, students build their own neural network library, which we call MiniFlow.\n\nThe lesson starts with a fairly basic, feedforward neural network, with just a few layers. Students learn to build the connections between the artificial neurons and implement forward propagation to move calculations through the network.\n\nThe real mind-bend comes in the \u201cLinear Transform\u201d concept, where we go from working with individual neurons to working with layers of neurons. Working with layers allows us to dramatically accelerate the calculations of the networks, because we can use matrix operations and their associated optimizations to represent the layers. Sometimes this is called vectorization, and it\u2019s a key to why deep learning has become so successful.\n\nOnce students implement layers in MiniFlow, they learn about a particular activation function: the sigmoid function. Activation functions define the extent to which each neuron is \u201con\u201d or \u201coff\u201d. Sophisticated activation functions, like the sigmoid function, don\u2019t have to be all the way \u201con\u201d or \u201coff\u201d. They can hold a value somewhere along the activation function, between 0 and 1.\n\nThe next step is to train the network to better classify our data. For example, if we want the network to recognize handwriting, we need to adjust the weight associated with each neuron in order to achieve the correct classification. Students implement an optimization technique called gradient descent to determine how to adjust the weights of the network.\n\nFinally, students implement backpropagation to relay those weight adjustments backwards through the networks, from finish to start. If we do this thousands of times, hopefully we\u2019ll wind up with a trained, accurate network.\n\nAnd once students have finished this lesson, they have their own Python library they can use to build as many neural networks as they want!\n\nIf all of that sounds interesting to you, maybe you should apply to join the Udacity Self-Driving Car Engineer Nanodegree Program and learn to become a Self-Driving Car Engineer!"
    },
    {
        "url": "https://medium.com/udacity/training-self-driving-car-engineers-in-india-deb55b3e66cb",
        "title": "Training Self-Driving Car Engineers in India \u2013 Udacity Inc \u2013",
        "text": "Udacity and Infosys just announced a partnership to train hundreds of Infosys\u2019 top software engineers in autonomous vehicle development.\n\nThis program will be part of Udacity Connect, which is Udacity\u2019s in-person, blended learning program. Infosys engineers from around the world will participate in Udacity\u2019s online Self-Driving Car Engineer Nanodegree program, and combine one term of online studies with two terms of being physically located together at the Infosys Mysore training facility, where the program will be facilitated by an in-person Udacity session lead.\n\nTwo aspects of this partnership are particularly exciting for me. One is simply working with a top technology company like Infosys. When we started building the Nanodegree program, our objective was to \u201cbecome the industry standard for training self-driving car engineers.\u201d This partnership moves us significantly closer to that objective. We are grateful and excited for the opportunity, and thrilled for the participating engineers.\n\nThe other exciting aspect of this partnership is that it will happen in India. The Infosys engineers will fly in from all over the world, but there is something special about conducting the program in Mysore.\n\nFor many years autonomous vehicle development has happened in just a few places: Detroit, Pittsburgh, southern Germany. Recently, we\u2019ve seen autonomous vehicle development expand to Silicon Valley, Japan, Israel, various parts of Europe, Singapore, and beyond. Training autonomous vehicle engineers in India expands the opportunities for students worldwide.\n\n7% of students in the Udacity Self-Driving Car Engineer Nanodegree program are from India. The Infosys partnership is an important next step in building a robust pipeline of job opportunities for our students on the subcontinent."
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-november-17-edition-79ad954a61b5",
        "title": "This Week at Udacity, November 17 edition \u2013 Udacity Inc \u2013",
        "text": "Another week, another exciting launch! What went live this week? Here\u2019s a hint: If you REALLY want to differentiate yourself as an elite Digital Marketer, and you REALLY want to get skilled in one of the most important specializations in the field, what do you want to learn?\n\nThings felt a little extra exciting at Udacity this week, thanks to some wonderful press coverage we were humbled to receive. We really appreciated the profile of Sebastian Thrun and Udacity that the Financial Times published this week, and we loved the quote from Sebastian that concludes the piece:\n\nThere was also a really excellent article published by language industry intelligence company Slator, all about how we localize our content for international learners:\n\nAs to our own publishing efforts, we were elated to share a fantastic student success story on our main blog today:\n\nAnd it is in this spirit of lifelong learning that we come to \u2026\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-30-october-2017-dd790153f722",
        "title": "This Week in Machine Learning, 30 October 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories, including the Higgs boson, Alzheimer\u2019s predictions, smart replies, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nScientists from CalTech and USC leverage machine learning and both quantum and classical annealing to optimize the identification of Higgs particles.\n\nLinkedIn debuts a smart reply feature that attempts to anticipate the user\u2019s next response in chat conversations and provide it as an easily accessible button.\n\nA survey of 500 Chief Information Officers conducted by ServiceNow reveals that managers expect a sharp increase in demand for workers with machine learning skills in 2018.\n\nThe Alzheimer\u2019s Disease Neuroimaging Initiative applies machine learning techniques to brain scans to predict the risk of developing Alzheimer\u2019s and recommend treatments.\n\nQBE Group\u2019s venture capital division invests $50 million in machine learning companies, highlighted by its investment in RiskGenius, which targets product development.\n\nIndia\u2019s Software Enterprises Association partners with the International Institute of Information Technology Hyderabad on a memorandum to promote AI jobs."
    },
    {
        "url": "https://medium.com/udacity/dominik-nuss-at-mercedes-benz-881772a5a109",
        "title": "Dominik Nuss at Mercedes-Benz \u2013 Udacity Inc \u2013",
        "text": "One of the delights of teaching at Udacity is the opportunity to work with world-class experts who are excited about sharing their knowledge with our students.\n\nWe have the great fortune of working with Mercedes-Benz Research and Development North America (MBRDNA) to build the Self-Driving Car Engineer Nanodegree Program. In particular, we get to work with Dominik Nuss, principal engineer on their sensor fusion team.\n\nIn these two videos, Dominik explains how unscented Kalman filters fuse together data from multiple sensors across time:\n\nThese are just a small part of a much larger unscented Kalman filter lesson that Dominik teaches. This is an advanced, complex topic I haven\u2019t seen covered nearly as well anywhere else.\n\nMBRDNA has just published a terrific profile of Dominik, along with a nifty video of him operating one of the Mercedes-Benz autonomous vehicles.\n\nRead the whole thing and learn what it\u2019s like to work on one of the top teams in the industry. Then, enroll in our program (if you haven\u2019t already!), and start building your OWN future in this amazing field!"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-13-november-2017-d476a914963d",
        "title": "This Week in Machine Learning, 13 November 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: diagnosing ovarian cancer, detecting counterfeit goods, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nStartup Entrupy leverages machine learning and a smartphone-powered microscope to allow at-home checks for counterfeit purses, watches, and other goods.\n\nNew app WhatThefont uses machine learning and computer vision to identify fonts observed by a smartphone\u2019s camera (hint: this font is Georgia).\n\nScientists at the Dana-Farber Cancer Institute train a neural network to identify cases of ovarian cancer from serum samples with 91% accuracy.\n\nScientists use deep learning to analyze the images generated by the MINERvA neutrino experiments to identify interesting particle interactions.\n\nMIT-based startup Pienso raises $2.1 million in funding to develop ways for non-programmers to train and use machine learning models.\n\nLet\u2019s Enhance uses machine learning to convert low-resolution images into high-resolution, filling in the data lost when compressing images with significant accuracy."
    },
    {
        "url": "https://medium.com/udacity/the-5-things-you-need-to-do-to-get-selected-for-the-2nd-phase-of-your-google-udacity-scholarship-649f22376030",
        "title": "5 things you should do to get selected for the 2nd phase of your Google-Udacity Scholarship",
        "text": "From the pen of a former scholar of the previous scholarship program: A guide to help you get into the top 10% of scholars who will earn the additional 6-month Nanodegree scholarship.\n\nFirst of all, congratulations for getting selected for the scholarship challenge. You surely did a good job with your application! You can be proud of yourself! Many people got rejected, so if you\u2019re in, feel yourself privileged!\n\nNo matter if you were selected for the Front-End Web Developer, the Mobile Web Specialist, the Android Basics, or the Android Developer track, this article will help you get into the next phase, where the real magic happens. \n\nSo, let\u2019s see what you need to do to get in!\n\nWhen the scholarship starts off, you may feel confused or overwhelmed. You may even think the whole scholarship experience is nothing but chaos, especially when you join your scholarship #Slack channel and see the tremendous number of posts flooding in. Here are a few reactions you may experience:\n\nWell, let me tell you I had a similar feeling 9 months ago when our Android Basics Nanodegree scholarship started. I won\u2019t say that your worries and fears are not valid, but you definitely have to overcome them. And remember this: It\u2019s pretty likely that all of your fellow scholarship students have the same feelings.\n\nYou had your reason to apply. You wanted to learn something new. You should not forget this. Generally, if you want something really bad, you don\u2019t even need a scholarship, right? You can keep listing all your cons and problems, but they will not get you closer to your goal.\n\nSo, just stop it. Start watching the videos and get your quizzes and projects (if there are any) done. This whole seemingly chaotic situation will calm down soon.\n\nIf you are wondering why this first phase is necessary, let the words of Ana\u00efs Bourg (Community Manager Europe Udacity) make it clear:\n\nYou get it, right? You don\u2019t marry someone you met 1 hour ago. You want to spend some time together first!\n\nThere is so much more you can get from Udacity than a simple video course and a credential. The Udacity community is something that you definitely want to be part of (There are a thousand reasons why this is true; I wont go into details now, just trust me on this!). And Udacity takes it seriously to build it even further. That\u2019s why the contribution to this mission is the second most valued aspect in the selection process.\n\nBut let\u2019s get more specific and see what the two aspects are, listed according their importance:\n\nThis makes a lot of sense. But how will recipients actually be selected? Well, in the case of course completion and the forum, Udacity has all the data they need:\n\nBut how about Slack? You\u2019ll have mentors, moderators and community managers, whose one job is to help and engage students. But Udacity also monitors the participants, and I think they prepare a list of the ones who are putting time into helping others. So the Big Brother is watching! \u2014 Haha! :)\n\nOnce again: I understand all your worries and problems, but hey, you know exactly what you need to do now! I know it\u2019s hard, I know it takes time, but it is absolutely worth it:\n\nNow go and do your best! Quality over quantity. Try to be helpful rather than a spammer. Complete all tasks in the classroom. You\u2019re going to love the second phase!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-november-10-edition-e0b59e856d14",
        "title": "This Week at Udacity, November 10 edition \u2013 Udacity Inc \u2013",
        "text": "Just when you thought things couldn\u2019t get more exciting, up jumps the Deep Learning Nanodegree Foundation program with new layers of amazing content!\n\nAnd if that weren\u2019t enough, the Udacity Deep Learning Team is opening up the classroom for a free preview!\n\nAmong the many innovative applications of deep learning you\u2019ll get to experience in this free classroom preview is something called \u201cStyle Transfer\u201d:\n\nAlong with providing detailed instructions on how to build this project, we encouraged visitors to do the following:\n\nDeep Learning wasn\u2019t the only launch this week. We were also super excited to introduce the next free courses in our ongoing collaboration with Facebook!\n\nExciting? You bet! But you know what was even more exciting? The hundreds\u2014literally hundreds\u2014of new Student Success stories we posted on our site this week!\n\nSo yes, it\u2019s true. We\u2019ve already shared some Tweets above. But still, that doesn\u2019t mean we can\u2019t still revel in our favorite feature, the \u2026\n\nThat title should actually be plural, because I\u2019m going to share 3 tweets! First, one of the most exciting things we ever get to witness: Self-Driving Car Engineer Nanodegree program students testing their code on an actual self-driving car\u2014ours!\n\nNext up, just a totally classic example of a Lifelong Learner in action. No sooner does this individual complete a Nanodegree program, than they\u2019re ready to start another one!\n\nAnd finally, we\u2019ll return to the topic of deep learning with a tweet from our founder, Sebastian Thrun!\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/the-introduction-to-neural-networks-lesson-f23f3111d164",
        "title": "The \u201cIntroduction to Neural Networks\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "Editor\u2019s note: On November 1st of this year, David Silver (Program Lead for Udacity\u2019s Self-Driving Car Engineer Nanodegree program) made a pledge to write a new post for each of the 67 lessons currently in the program. We check in with him today as he introduces us to Lesson 4!\n\nThe 4th lesson of the Udacity Self-Driving Car Engineer Nanodegree Program introduces students to neural networks, a powerful machine learning tool.\n\nThis is a fast lesson that covers the basic mechanics of machine learning and how neural networks operate. We save a lot of the details for later lessons.\n\nMy colleague Luis Serrano starts with a quick overview of how regression and gradient descent work. These are foundational machine learning concepts that almost any machine learning tool builds from.\n\nLuis is great at this stuff. I love Mt. Errorest.\n\nMoving on from these lessons, Luis goes deeper into the distinction between linear and logistic regression and then explores how these concepts can reveal the principles behind a basic neural network.\n\nSee the slash between the red and green colors there? If you ever meet Luis in person, ask him to sing you the forward-slash-backward-slash alphabet song. It\u2019s amazing.\n\nFrom here we introduce perceptrons, which historically were the precursor to the \u201cartificial neurons\u201d that make up a neural network.\n\nAs we string together lots of these perceptrons, or \u201cartificial neurons\u201d, my colleague Mat Leonard shows that we can take advantage of a process called backpropagation, that helps train the network to perform a task.\n\nAnd that\u2019s basically what a neural network is: a machine learning tool built from layers of artificial neurons, which takes an input and produces an output, trained via backpropagation.\n\nThis lesson has 23 concepts (pages), so there\u2019s a lot more to it than the 3 videos I posted here. If some of this looks confusing, don\u2019t worry! There\u2019s a lot more detail in the lesson, as well as lots of quizzes to help make sure you get it.\n\nIf you find neural networks interesting in their own right, perhaps you should sign up for Udacity\u2019s Deep Learning Nanodegree Foundation Program. And if you find them interesting for how they can help us build a self-driving car, then of course you should apply to join the Udacity Self-Driving Car Nanodegree Program!"
    },
    {
        "url": "https://medium.com/udacity/this-week-in-machine-learning-6-november-2017-3db9fdf1efa6",
        "title": "This Week in Machine Learning, 6 November 2017 \u2013 Udacity Inc \u2013",
        "text": "This week\u2019s top Machine Learning stories: dirty data, predicting and preventing suicide, and more!\n\nMachine Learning is one of the most exciting fields in the world. Every week we discover something new, something amazing, something revolutionary. That\u2019s why we created This Week in Machine Learning! Each week we publish a curated list of Machine Learning stories as a resource to help you keep pace with all these exciting developments. New posts will be published here first, and previous posts are archived on the Udacity blog.\n\nWhether you\u2019re currently enrolled in our Machine Learning Nanodegree program, already working in the field, or just pursuing a burgeoning interest in the subject, there will always be something here to inspire you!\n\nResearchers from Carnegie Mellon, Harvard, and more apply machine learning to fMRI scans to find the neural underpinnings of suicidal thoughts and behaviors.\n\nThe Linux Foundation announces a new open-source machine learning initiative titled Acumos, funded by donations from AT&T and Tech Mahindra.\n\nGoogle launches Firebase Predictions, a suite of machine learning-powered tools to allow web designers to predict user behaviors such as churn or spending habits.\n\nScientists at Nvidia use generative adversarial networks to generate realistic-looking fake photographs based on a given description.\n\nAI firm Vicarious develops a machine learning model it dubs a Recursive Cortical Network which it predicts will soon be able to defeat CAPTCHAs.\n\nA survey of 16,700 machine learning engineers on the popular Google-owned competition site Kaggle finds the biggest barrier to work in the field is dealing with dirty data."
    },
    {
        "url": "https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4",
        "title": "Shannon Entropy, Information Gain, and Picking Balls from Buckets",
        "text": "This blog post is a more detailed version of this video:\n\nEntropy, so far, had been a concept in physics. Namely, it is the (log of the) number of microstates or microscopic configurations. In colloquial terms, if the particles inside a system have many possible positions to move around, then the system has high entropy, and if they have to stay rigid, then the system has low entropy.\n\nFor example, water in its three states, solid, liquid, and gas, has different entropies. The molecules in ice have to stay in a lattice, as it is a rigid system, so ice has low entropy. The molecules in water have more positions to move around, so water in liquid state has medium entropy. The molecules inside water vapor can pretty much go anywhere they want, so water vapor has high entropy.\n\nBut what does this have to do with information theory? Well, the answer for this is by studying the relationships between knowledge and probability.\n\nTo introduce the notion of entropy in probability, we\u2019ll use an example throughout this whole article. Let\u2019s say we have 3 buckets with 4 balls each. The balls have the following colors:\n\nAnd we\u2019ll judge these three options by how much information we have on the color of a ball drawn at random. In this case, we have the following:\n\nSo it makes sense to say that Bucket 1 gives us the most amount of \u201cknowledge\u201d about what ball we\u2019ll draw (because we know for sure it\u2019s red), that Bucket 2 gives us some knowledge, and that Bucket 3 will give us the least amount of knowledge. Well, Entropy is in some way, the opposite of knowledge. So we\u2019ll say that Bucket 1 has the least amount of entropy, Bucket 2 has medium entropy, and Bucket 3 has the greatest amount of entropy.\n\nBut we want a formula for entropy, so in order to find that formula, we\u2019ll use probability.\n\nSo now the question is, how do we cook up a formula which gives us a low number for a bucket with 4 red balls, a high number for a bucket with 2 red and 2 blue balls, and a medium number for a bucket with 3 red and 1 blue balls? Well, as a first attempt, let\u2019s remember the definition of entropy: If molecules have many possible rearrangements, then the system has high entropy, and if they have very few rearrangements, then the system has low entropy. So a first attempt would be to count the number of rearrangements of these balls. In this case, we have 1 possible rearrangement for Bucket 1, 4 for Bucket 2, and 6 for Bucket 3, this number given by the binomial coefficient.\n\nThis number of arrangements won\u2019t be part of the formula for entropy, but it gives us an idea, that if there are many arrangements, then entropy is large, and if there are very few arrangements, then entropy is low. In the next section, we\u2019ll cook up a formula for entropy. The idea is, to consider the probability of drawing the balls in a certain way, from each bucket.\n\nSo, in order to cook up a formula, we\u2019ll consider the following game. The spoiler is the following: The probability of winning this game, will help us get the formula for entropy.\n\nIn this game, we\u2019re given, again, the three buckets to choose. The rules go as follows:\n\nThis may sound complicated, but it\u2019s actually very simple. Let\u2019s say for example that we\u2019ve picked Bucket 2, which has 3 red balls, and 1 blue ball. We\u2019re shown the balls in the bucket in some order, so let\u2019s say, they\u2019re shown to us in that precise order, red, red, red, blue. Now, let\u2019s try to draw the balls to get that sequence, red, red, red, blue. What\u2019s the probability of this happening? Well\u2026\n\nAs these are independent events, then the probability of the 4 of them to happen, is (3/4)*(3/4)*(3/4)*(1/4) = 27/256, or 0.105. This is not very likely. In the figures below, we can see the probabilities of winning if we pick each of the three buckets.\n\nFor exposition, the following three figures show the probabilities of winning with each of the buckets. For Bucket 1, the probability is 1, for Bucket 2, the probability is 0.105, and for Bucket 3, the probability is 0.0625.\n\nOr, as summarized in the following table:\n\nOk, now we have some measure that gives us different values for the three Buckets. The probability of winning at this game, gives us:\n\nIn order to build the entropy formula, we want the opposite, some measure that gives us a low number for Bucket 1, a medium number for Bucket 2, and a high number for Bucket 3. No problem, this is where logarithms will come to save our life.\n\nThe following is a very simple trick, yet used very widely, particularly in Machine Learning. See, products are never very good. Here we have a product of 4 numbers, which is not bad, but imagine if we had a million data points. How would the product of a million small probabilities (between 0 and 1) would look? It would be a ridiculously tiny number. In general we want to avoid products as much as we can. What\u2019s better than a product? Well, a sum! And how do we turn products into sums? Exactly, using the logarithm function, since the following identity will be very helpful:\n\nSo, what do we do? Well, we have a product of four things, we take the logarithm, and that becomes the sum of four things. In the case of Bucket 2 (3 red balls, 1 blue ball), we have the following:\n\nAnd taking the logarithm (in this case, we\u2019ll take the logarithm, and multiply by -1, to make things positive), we get:\n\nNow, as a final step, we take the average, in order to normalize. And that\u2019s it, that\u2019s the entropy! For Bucket 2, it\u2019s 0.811:\n\nIf we calculate the entropy for Bucket 1 (4 red balls), we get:\n\nAnd for Bucket 3 (2 red balls, 2 blue balls), we get:\n\nSo we have our formula for entropy, the negative logarithm of the probability of winning at our game. Notice that this is low for Bucket 1, high for Bucket 3, and medium for Bucket 2. In summary, we have the following:\n\nFor the formula lovers out there, the general formula is as follows. If our bucket has m red balls, and n blue balls, the formula is as follows:\n\nSo far we\u2019ve been dealing with two classes, red and blue. In order to relate Entropy with Information Theory, we need to look at entropy with several classes. Let\u2019s switch to letters, to make this more clear. We have the following three buckets, with 8 letters each. Bucket 1 has the letters AAAAAAAA, Bucket 2 has the letters AAAABBCD, and Bucket 3 has the letters AABBCCDD. While it\u2019s straightforward to see that Bucket 1 has the least amount of entropy, the difference between Bucket 2 and Bucket 3 is not obvious. We\u2019ll see below that Bucket 3 has the highest entropy of the three, while Bucket 2 has medium\n\nThe formula for entropy generalizes very easily to more classes. This is the general formula:\n\nWhere there are n classes, and p_i is the probability an object from the i-th class appearing. For our three buckets, we have the following:\n\nIn this case, since Bucket 1 has only one class (the letter A), and the probability of it appearing is 1, then the entropy is:\n\nFor Bucket 2, since we have 4 classes (the letters A, B, C, and D), and the probability of A appearing is 4/8, for B it\u2019s 2/8, for C it\u2019s 1/8, and for D it\u2019s 1/8, then the entropy is:\n\nAnd finally for Bucket 3, since we have 4 classes (the letters A, B, C, and D), and the probability of each appearing is 1/4, then the entropy is:\n\nOk, so we\u2019ve calculated the entropy for our three buckets.\n\nBut something much more interesting is happening, which is where information theory finally comes into play.\n\nHere\u2019s another way to see entropy. Let\u2019s say we want to draw a random letter from one of the buckets. On average, how many questions do we need to ask to find out what letter it is?\n\nFirst, let\u2019s get the easy case out of the way. If the bucket is Bucket 1, we know for sure that the letter is an A. So right there, we know that for Bucket 1, we need to ask 0 questions on average, to guess what letter we got. For the sake of redundancy, let\u2019s put it in a formula:\n\nNow, for buckets 2 and 3, naively, one would think that 4 questions is enough to find out any letter. Namely, the following four questions would be enough:\n\nSo, first off, the fourth question is redundant, since if the answer to all the previous ones is \u201cno\u201d, then we know for sure that the letter is a D. So three questions is enough. Now, can we do better than that? Well, our questions don\u2019t need to be independent. We can tailor our question 2 based on the answer to question 1, as follows:\n\nAnd that will actually do it, because based on the two answers, we get the following:\n\nThis tree of questions can be seen in the following image:\n\nNow, for Bucket 3, each letter appears with probability 1/4, since there are 8 letters, and 2 of each. Thus, the average number of questions to find out the letter drawn out of Bucket 2 is precisely 2, as the next formula states:\n\nNow, let\u2019s look at Bucket 1. Of course, if we use the same question tree as we used for Bucket 2, we can see that the average number of questions is 2. But we can do a bit better. Actually, let\u2019s use the first attempt. First asking if the letter is A, then B, then C. That\u2019s the following tree:\n\nIn this case, we have the following:\n\nNow the trick is the following. A appears much more often than C and D, so on average, we may be doing much better. How much better? Well, recall that Bucket 2 has the letters AAAABBCD, so A appears 1/2 the time, B appears 1/4 of the time, and C and D appear each 1/8 of the time. So the average number of questions is:\n\nSo, in terms of average number of questions asked to find out a letter drawn out of each of the buckets, we have the following:\n\nWell, that\u2019s exactly the entropy! Here\u2019s the connection between Entropy and Information Theory. If we want to find out a letter drawn out of a bucket, the average number of questions we must ask to find out (if we ask our questions in the smartest possible way), is precisely the entropy of the set.\n\nOf course, one huge question arises: How did we know that the way we asked the questions was the best possible? This is not obvious, and needs some thinking.\n\nSuggestions? Corrections? Please e-mail me at luis.serrano@udacity.com.\n\nAnd if you like what you saw, please feel free to check our Nanodegree Programs at Udacity!"
    },
    {
        "url": "https://medium.com/udacity/this-week-at-udacity-november-3-edition-b6300c908bc5",
        "title": "This Week at Udacity, November 3 edition \u2013 Udacity Inc \u2013",
        "text": "Gosh, what DIDN\u2019T happen this week? And how to organize all the great things afoot?\n\nWell, if we\u2019re looking for an organizing principle, we can start with LinkedIn. SO incredible to see all the expressions of excitement from new scholarship recipients!\n\nDo your good deed for the day, spend a bit of time on LinkedIn, and go congratulate some amazing Lifelong Learners, like these rock stars!\n\nAnd speaking of LinkedIn, Udacity was humbled and excited to receive a wonderful bit of recognition this week:\n\nA few other items we\u2019d love to share with you. First, David Silver, the indefatigable program lead for the Self-Driving Car Engineer Nanodegree program, will be publishing a new Medium post for each of the 67 projects in this program, and the first three are now live! To read David\u2019s posts, just visit the Self-Driving Car category on our Medium publication, which you can find here.\n\nWe\u2019d also love to share with you a seriously inspiring #StudentSuccess post we published this morning:\n\nAnd with that, we come to \u2026\n\nSimply had to share this one \u2026 you know you have an inspired and inspiring Design Team at your company, when THIS is the Halloween costume they come up with:\n\nAnd THAT \u2026 is This Week at Udacity!\n\nThis post was written by Christopher Watkins, Senior Writer and Chief Words Officer, Udacity"
    },
    {
        "url": "https://medium.com/udacity/finding-lane-lines-project-b737aa2de055",
        "title": "The \u201cFinding Lane Lines\u201d Project \u2013 Udacity Inc \u2013",
        "text": "The second lesson of the Udacity Self-Driving Car Nanodegree program is actually a lesson followed by a project. In \u201cFinding Lane Lines\u201d, my colleague Ryan Keenan and I teach students how to use computer vision to extract lane lines from a video of a car driving down the road.\n\nStudents are able to use this approach to find lane lines within the first week of the Nanodegree program! This isn\u2019t the only way to find lane lines, and with modern machine learning algorithms it\u2019s no longer the absolute best way to find lane lines. But it\u2019s pretty effective, and it\u2019s amazing how quickly you can get going with this approach.\n\nHere\u2019s a photo of Interstate 280, taken from Carla, Udacity\u2019s own self-driving car:\n\nThe first thing we\u2019re going to do is convert the image to grayscale, which will make it easier to work with, since we\u2019ll only have one color channel:\n\nNext, we\u2019ll perform \u201cCanny edge detection\u201d to identify edges in the image. An edge is place where the color or intensity of the image changes sharply:\n\nNow that we have the edges of the image identified, we can use a technique called a \u201cHough transform\u201d to find lines in the image that might be the lane lines we are looking for:\n\nAll of these tools have various parameters we can tune: how sharp should the edges be, how long should the lines be, what should the slope of the line be. If we tune the parameters just right, we can get a lock on our lane lines:\n\nApply these lane lines to the original image, and you get something like this \u201cFinding Lane Lines\u201d project, submitted by our student Jeremy Shannon:\n\nPretty awesome for the first week!"
    },
    {
        "url": "https://medium.com/udacity/the-welcome-lesson-a7bc6ad78755",
        "title": "The \u201cWelcome\u201d Lesson \u2013 Udacity Inc \u2013",
        "text": "\u201cWelcome\u201d is the first of 20 lessons in Term 1 of the Udacity Self-Driving Car Engineer Nanodegree program.\n\nThis is an overview lesson in which we introduce:\n\nWe also cover the history of self-driving cars, the logistics of how Udacity and this Nanodegree program work, and the projects that students will build throughout the program.\n\nI\u2019ll let Sebastian share that last bit:\n\nNext up, the \u201cFinding Lane Lines\u201d project!"
    },
    {
        "url": "https://medium.com/udacity/blogging-the-udacity-self-driving-car-engineer-nanodegree-program-dc04a19c8677",
        "title": "Blogging the Udacity Self-Driving Car Engineer Nanodegree Program",
        "text": "For the last year and a quarter, I\u2019ve been working with a team at Udacity to build the Self-Driving Car Engineer Nanodegree program. This is a nine-month program that prepares software engineers for jobs working on autonomous vehicles.\n\nOver the coming weeks and months, I\u2019m going to produce a new post about each of the lessons in the Nanodegree program, to help you explore what you can learn. As of right now, there are 67 lessons, so I anticipate this process will take me several months to complete. But I\u2019m excited to spend time reviewing and sharing what we\u2019ve built!\n\nDuring our program we cover: computer vision, deep learning, sensor fusion, localization, path planning, control, advanced electives, and finally system integration. In the final part of the program, students even get to put their own code on Carla, Udacity\u2019s actual self-driving car.\n\nI\u2019ll start today with a quick post about our 1st lesson, which is entitled: \u201cWelcome\u201d."
    }
]