[
    {
        "url": "https://towardsdatascience.com/my-take-on-data-scientist-interview-questions-part-1-6df22252b2e8?source=user_profile---------1----------------",
        "title": "My take on Data Scientist Interview Questions [ Part 1 ]",
        "text": "One of my friend have compiled a list of questions for people who are getting into Data Science. And I wanted to answer them, please note I don\u2019t know the origin of these questions if anyone knows where this questions are from please comment down below.\n\nAlso, I\u2019ll try to provide a correct answer for every questions. However, I am always open to learning and growing, so if you know a more optimal solution please comment down below."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/nips-2016-direct-feedback-alignment-provides-learning-in-deep-neural-networks-with-interactive-32d59045e8e?source=user_profile---------2----------------",
        "title": "[ NIPS 2016 ] Direct Feedback Alignment Provides Learning in Deep Neural Networks with Interactive\u2026",
        "text": "Direct Feed Back Alignment is actually very easy. Remember that the symbol e stands for derivative of the cost function. (In other words derivative respect to most outer layer.) Now we are going to directly use that derivative to update the weights rather than back propagating all the way through. If done in python it would look something like below.\n\nRed Box \u2192 Derivative respect to Softmax activation function. If you do not remember why the equation works out like above, please read my blog post here.\n\nNow lets talk about In-Direct Feed Back Alignment, I\u2019ll be honest this method looked weird to me at first. Quite brilliant that authors have thought of this idea. The strange thing about this method is the order of updating weights. For the first layer we are going to use direct feed back alignment to update the weights and for the second layer we are going to use the derivative from the first layer to update the weights. Again done in python it would look something like below.\n\nRed Box \u2192 First Time ever to update the weight for the first layer BEFORE updating second layer."
    },
    {
        "url": "https://towardsdatascience.com/back-to-basics-deriving-back-propagation-on-simple-rnn-lstm-feat-aidan-gomez-c7f286ba973d?source=user_profile---------3----------------",
        "title": "[ Back to Basics ] Deriving Back Propagation on simple RNN/LSTM (feat. Aidan Gomez)",
        "text": "There are two things to note here\u2026.\n\n1. Green Line \u2192 Please remember the derivative of Tanh() can be rewritten as such. If you do not remember why, please scroll up.\n\n2. I did not perform derivative respect to i(2), and f(2). The reason is because those two terms have very similar derivative structure with a(2). I\u2019ll try to explain why in details below.\n\nIf we observe how state(t) is calculated we can see that the terms a(t), i(t), f(t) and state(t-1) are involved. So when we take the derivative respect to the variable a(t), we can know that it would be very similar to taking derivative respect to i(t). However, there is one term that we need to take a more deeper look into and that is o(t). Since, the term gets used after we calculate state(t) the derivative is also different.\n\nWe can clearly see that there are some difference between the derivative equation when compared to a(2).\n\nWith those ideas in-mind we can see that deriving back-propagation at time stamp 2 is not that hard, since it is the most outer layer of our LSTM."
    },
    {
        "url": "https://towardsdatascience.com/generating-pixelated-images-from-segmentation-masks-using-conditional-adversarial-networks-with-6479c304ea5f?source=user_profile---------4----------------",
        "title": "Generating Pixelated Images from Segmentation Masks using Conditional Adversarial Networks with\u2026",
        "text": "Red Line \u2192 How each layer is composed of it is made up of Convolution Batch Normalization and finally Relu()\n\nSo from above image we can already see that each of the layer for this network is composed of three operations, and when implemented in Tensorflow it would look something like below.\n\nThe reason why there is a if condition for batch normalization is due to the fact that the first layer for generator does not have a batch normalization layer."
    },
    {
        "url": "https://towardsdatascience.com/cvpr-2014-paper-summary-the-secrets-of-salient-object-segmentation-9c777babdc5?source=user_profile---------5----------------",
        "title": "[ CVPR 2014 / Paper Summary ] The Secrets of Salient Object Segmentation",
        "text": "This section of the topic is huge, mainly because it is one of the core contribution of this paper. And I have to say, I don\u2019t know in details of all of the statistical analysis they did, however, once I research about them. I will surely make another blog post.\n\nPsycho physical experiments on the PASCALS data-set\n\nHere the authors have performed some experiments to gather ground truth data for fixation Prediction on PASCAL 2010 data set.\n\nEvaluating dataset consistency\n\nTo compare the level of agreement among different labelers (from previous experiment) the authors have done some extensive analysis to know the Inter-subject consistency. (For both salient object segmentation as well as fixation prediction). And one interesting fact the authors found was\u2026.. (shown below)\n\nBenchmarking\n\nHere the authors have compared many state of the art algorithms that performed salient object segmentation and found out that when the algorithm was not trained on FT dataset their performances decreased significantly.\n\nDataset design bias\n\nThe authors really went all out in this section, they performed many statistical analysis such as comparing Local color contrast, Global color contrast, Local gPB boundary strength, and Object size. And they have summed the founding into one paragraph\n\nBasically, in FT data set there is a strong contrast between the object that we want to segment and the back ground image of that object. That makes it easier for the model to learn how to segment an object, but fails to generalize well.\n\nFixations and F-measure\n\nHere the author discuss the effect of center bias problem, and the methods of many state of the art algorithms to counteract the center bias problems. For example, in AWS and SIG they benchmark their algorithm performance in s-AUC which cancels out the center bias problem."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec?source=user_profile---------6----------------",
        "title": "Wide Residual Networks with Interactive Code \u2013 Jae Duk Seo \u2013",
        "text": "Red Box \u2192 Network Layer we are going to implement.\n\nEach layer is mostly identical to traditional residual network, however again as discussed above the number of feature map have been increased. Now lets take a look at the full network architecture that we are going to use. Also, please note that batch normalization as well as ReLu() activation is not shown in the image above.\n\nAbove is the full network architecture that we are going to implement, we can observe two variables which are N and k. Here k is how much we want the feature map to increase per each layer and N is number of convolution block in each of the layer. So for out network I am going to set N as 1, and K as 8, so our network is only going to have 8 layers but a lot of feature maps per each layers. Now lets take a look at the OOP form of the network.\n\nAs seen above, the network itself is not that deep, however we can observe that there are a lot of feature maps per each layer."
    },
    {
        "url": "https://towardsdatascience.com/solving-internal-co-variate-shift-in-deep-learning-with-linked-neurons-with-interactive-code-61859388af76?source=user_profile---------7----------------",
        "title": "Solving internal co-variate shift in deep learning with linked Neurons with Interactive Code [\u2026",
        "text": "The main contribution of this paper is linked neuron which implies that at least one of the derivative of the gradient is none zero and this will take care of the dying neuron problem. This was very interesting proposal. Also the implementation of this \u2018linked neurons\u2019 was very simple as well.\n\nSo basically, we concatenate the output of each activation functions and pass on to the next layer, simple! Now lets see this in action.\n\nWhen we give this layer a tensor of shape [?,28,28,32] the output is [?,28,28,64] since it is concatenated in the channel dimension."
    },
    {
        "url": "https://towardsdatascience.com/computer-vision-feature-extraction-101-on-medical-images-part-3-difference-of-gaussian-and-b3cbe5c37415?source=user_profile---------8----------------",
        "title": "Computer Vision Feature Extraction 101 on Medical Images \u2014 Part 3: Difference of Gaussian, and\u2026",
        "text": "This is another post of me trying to remember what I learned in Computer Vision. And since it is Final Exam season I don\u2019t really want to do something crazy, hence DoG and LoG filters.\n\nClick here if you wish to see part 1, or click here if you wish to see part 2.\n\nAlso, here is the list of publicly available data that we are going to use. \n\n1. Breast Cancer Cell from UCSB Bio-Segmentation Benchmark data set\n\n2. Cellular 2D from UCSB Bio-Segmentation Benchmark data set\n\n3. DRIVE: Digital Retinal Images for Vessel Extraction\n\n4. Ultrasound Nerve Segmentation from kaggle Data set\n\n5. Brain MRI from pixabay\n\n6. Brain MRI from pixabay\n\n7. Natural Image from pixabay\n\nPlease note that this post is for my future self to look back and review the materials."
    },
    {
        "url": "https://towardsdatascience.com/paper-summary-google-deepmind-automated-analysis-of-retinal-imaging-using-machine-learning-17e61b2adc70?source=user_profile---------9----------------",
        "title": "[ Paper Summary ] Google DeepMind \u2014 Automated analysis of Retinal Imaging using machine learning\u2026",
        "text": "I found another great, paper from Deep Mind Health, and I wanted to take a deeper look into the paper while summarizing each part into one or two sentences. This was also covered by the media in the title of \u201cGoogle DeepMind is funding NHS research at Moorfields Eye Hospital\u201d.\n\nPlease note that this post is for my future self to look back and review the material."
    },
    {
        "url": "https://towardsdatascience.com/my-take-on-25-questions-to-test-a-data-scientist-on-image-processing-with-interactive-code-part-2-77eacfd96cf9?source=user_profile---------10----------------",
        "title": "My take on 25 Questions to test a Data Scientist on Image Processing with Interactive Code- Part 2",
        "text": "So I found this amazing blogger Faizan Shaikh and he have some amazing stuffs on his blog! So please check him out, also he is the creator of \u201c25 Questions to test a Data Scientist on Image Processing\u201d. So I\u2019ll try to challenge myself to solve them and this is part 2! And please note that my solution would be not optimized.\n\nAlso,for every question I\u2019ll screen shot the right answer (the answer that the original author have posted). However, I am always open to learning and growing, so if you know a more optimal solution please comment down below.\n\nAlso, here are the two images that I used to do some demonstration.\n\n1. Brain MRI from pixabay\n\n2. Natural Image from pixabay\n\nIf you wish to see part 1, please click here."
    },
    {
        "url": "https://towardsdatascience.com/my-take-on-25-questions-to-test-a-data-scientist-on-image-processing-with-interactive-code-part-1-a6196f535008?source=user_profile---------11----------------",
        "title": "My take on 25 Questions to test a Data Scientist on Image Processing with Interactive Code- Part 1",
        "text": "So I found this amazing blogger Faizan Shaikh and he have some amazing stuffs on his blog! So please check him out, also he is the creator of \u201c25 Questions to test a Data Scientist on Image Processing\u201d. So I\u2019ll try to challenge myself to solve them. And please note that my solution would be not optimized.\n\nAlso,for every question I\u2019ll screen shot the right answer (the answer that the original author have posted). However, I am always open to learning and growing, so if you know a more optimal solution please comment down below.\n\nAlso, here are the two images that I used to do some demonstration.\n\n1. Brain MRI from pixabay\n\n2. Natural Image from pixabay"
    },
    {
        "url": "https://towardsdatascience.com/computer-vision-feature-extraction-101-on-medical-images-part-2-identity-translation-scaling-90d160bcd41e?source=user_profile---------12----------------",
        "title": "Computer Vision Feature Extraction 101 on Medical Images \u2014 Part 2: Identity, Translation, Scaling\u2026",
        "text": "So today, I wanted to continue on my review of fundamentals of computer vision (I guess this post could be more of image processing). And for today I wanted to review on image transformations. (or matrix)\n\nAlso, here is the list of publicly available data that we are going to use. \n\n1. Breast Cancer Cell from UCSB Bio-Segmentation Benchmark data set\n\n2. Cellular 2D from UCSB Bio-Segmentation Benchmark data set\n\n3. DRIVE: Digital Retinal Images for Vessel Extraction\n\n4. Ultrasound Nerve Segmentation from kaggle Data set\n\n5. Brain MRI from pixabay\n\n6. Brain MRI from pixabay\n\n7. Natural Image from pixabay\n\nPlease note that this post is for my future self to look back and review the materials."
    },
    {
        "url": "https://towardsdatascience.com/paper-summary-adverse-events-in-british-hospitals-preliminary-retrospective-record-review-4fcb1f2451bc?source=user_profile---------13----------------",
        "title": "[ Paper Summary ] Adverse events in British hospitals: preliminary retrospective record review",
        "text": "I found this paper \u201c Adverse events in British hospitals: preliminary retrospective record review\u201d from Google Deep Mind\u2019s Health home page, and I wanted to take a deeper in-depth look at it and summarize it into one or two sentences.\n\nPlease note that this post is for my future self to look back and review the materials."
    },
    {
        "url": "https://towardsdatascience.com/my-journey-to-reinforcement-learning-part-1-5-57f334189655?source=user_profile---------14----------------",
        "title": "My Journey to Reinforcement Learning \u2014 Part 1.5: Simple Binary Image Transformation with Q-Learning",
        "text": "Black Numbers / Lines \u2192 Dividing the images into 10 little states\n\nFirst things first, lets make the states, since our original image have dimension of 10 * 100, lets divide the image into small squares (10*10) so we would have ten of them.\n\nSo our table for Q-Learning would look something like above. It would be an one-dimensional array with the index of the array being states and the values inside the array would be the threshold values. What this means is that we are going to have a threshold filter that only lets certain pixel intensity through and others will get filtered out.\n\nAbove we can see the hand crafted ground truth table, we can see that the index of number zero aligns where the image have black blocks. But we want to learn these threshold values, rather than hand crafting it. So lets first initialize our Q-Table like something below, with all ones."
    },
    {
        "url": "https://towardsdatascience.com/computer-vision-feature-extraction-101-on-medical-images-part-1-edge-detection-sharpening-42ab8ef0a7cd?source=user_profile---------15----------------",
        "title": "Computer Vision Feature Extraction 101 on Medical Images \u2014 Part 1: Edge Detection / Sharpening /\u2026",
        "text": "So today, I just wanted to review some of the core concepts in computer vision, and I wish to focus on the application rather than theory. If you are new to computer vision I strongly recommend watching this video series that I linked below to get the theory. (The video series is long, but it is really good.)\n\nAlso, here is the list of publicly available data that we are going to use. \n\n1. Breast Cancer Cell from UCSB Bio-Segmentation Benchmark data set\n\n2. Cellular 2D from UCSB Bio-Segmentation Benchmark data set\n\n3. DRIVE: Digital Retinal Images for Vessel Extraction\n\n4. Ultrasound Nerve Segmentation from kaggle Data set\n\n5. Brain MRI from pixabay\n\n6. Brain MRI from pixabay\n\n7. Natural Image from pixabay\n\nPlease note, this post is for me to review some of the fundamental concepts in computer vision."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/my-take-on-facebook-ai-interview-questions-with-interactive-code-part-1-75320713d79f?source=user_profile---------16----------------",
        "title": "My Take on Facebook AI Interview Questions with Interactive Code \u2014 Part 1",
        "text": "If a PM says that they want to double the number of ads in Newsfeed, how would you figure out if this is a good idea or not?\n\nI think this is another good use case for A/B Testing, the one problem with this approach is the that fact we are making a decision after doubling the number of ads in the Newsfeed. Because we are going to compare the reaction of users before/after the change in number of ads. Another good method I could think of would be making a survey for the users and asking their opinion on what do they think about doubling the number of ads in the Newsfeed, if most of them gives a positive reaction it may be a good sign.\n\nI was actually able to find the exact question by one simple google search, it seems like A/B Testing is a good way. Please click here to see the answers."
    },
    {
        "url": "https://towardsdatascience.com/google-deepmind-deep-learning-for-medical-image-segmentation-with-interactive-code-4634b6fd6a3a?source=user_profile---------17----------------",
        "title": "[ Google DeepMind ] \u2014 Deep Learning for Medical Image Segmentation with Interactive Code",
        "text": "Matthew Lai is a research engineer at Deep Mind, and he is also the creator of \u201cGiraffe, Using Deep Reinforcement Learning to Play Chess\u201d. But his Master Msc Project was on MRI images, which is \u201cDeep Learning for Medical Image Segmentation\u201d, so I wanted to take an in-depth look at his project.\n\nAnd since, this is not a traditional conference paper, rather a Master Project, I will approach this bit differently. I will do a Paper Summary (Making notes on the stuffs that I didn\u2019t know) and Implementation.\n\nPlease note, that in the original paper Matthew have used ADNI Alzheimer\u2019s MRI dataset, unfortunately I don\u2019t have access to that data so I am going to use \u201cDRIVE: Digital Retinal Images for Vessel Extraction\u201d data set. Also please note due to using a different data set, as well as hardware limitations there are few difference of network architecture from the original paper, however I tried to keep the general structure similar."
    },
    {
        "url": "https://towardsdatascience.com/my-journey-to-reinforcement-learning-part-1-q-learning-with-table-35540020bcf9?source=user_profile---------18----------------",
        "title": "My Journey to Reinforcement Learning \u2014 Part 1: Q-Learning with Table",
        "text": "Red Box \u2192 Updating what to do in the current state St\n\nBlue Box \u2192 Original value of what to do in the current state St\n\nFor now, lets only concentrate on those two things. For me I like to learn with concrete examples, so lets use OpenAI Gym\u2019s \u201cFrozenLake-v0\u201d as an example. (Please note, I won\u2019t go into explaining what this is and what Open AI is.)\n\nSo like above, we have 4*4 rectangle, and on each state (or coordinate) we can either die, by falling into a hole or win by going into the goal, or just walk by taking another step in the frozen lake, now lets actually take a look at the table of available state and actions.\n\nRed Number \u2192 Each of the State \n\nBlue Number \u2192 Each of action we can do in each state\n\nNow we can see that the Q-learning table we made have 16 column and 4 rows. Now lets review what our environment was.\n\nRed Number \u2192 Each state represented correlated in the Q Learning table\n\nNow, I am not 100% sure if the numbers would increase horizontally, or vertically (meaning the numbers for the first row can be 1 5 9 13). And I think this depends on the implementation, but we still can get the general idea. At each state we can do four actions, (what the Blue Number represented in the above graph) And those actions are Up, Down, Left, Right (Again, not sure if this is the exact order, it can be right, left, down, up etc\u2026). But we definitely can get the general direction of whats going on. So now lets go back to the Q-Learning Equation.\n\nFrom here we can estimate that the equation above will be updating a certain value in each row (which is the state). To choose what action to take."
    },
    {
        "url": "https://towardsdatascience.com/my-take-on-google-ai-interview-question-with-interactive-code-part-1-db2e33a26f10?source=user_profile---------19----------------",
        "title": "My take on Google AI Interview Question with Interactive Code \u2014 Part 1",
        "text": "Tossing a coin ten times resulted in 8 heads and 2 tails. How would you analyze whether a coin is fair? What is the p-value?\n\nSo the probability of getting head is 80 percent, and tails is 20 percent. Well for this question I think taking the expected value and comparing that to what we got could be an answer. (However, I am not good at stats or math, so if any statistician or mathematician know the answer please comment down below.)\n\nSo, the equation for expected values is E[x] = n * p(x), and if we plug in the numbers we can see that the expected value for getting a head is \n\nE[x] = 10 * 0.5 = 5, so when we toss the coin 10 times we can expect to see 5 times that are heads. (Same for tails as well). But we only saw 2 tails, so I guess we can say this coin is bias towards Head. For the p value, I actually forgot how to do that.\n\nSo the equation for expected value as well as the calculation was right, and for the p value I followed the step by step tutorial on this WikiHow page, and with significance level for 0.05, I got the p value of between 0.05 and 0.1. ( Let me know if I am wrong.)"
    },
    {
        "url": "https://towardsdatascience.com/my-journey-to-reinforcement-learning-part-0-introduction-1e3aec1ee5bf?source=user_profile---------20----------------",
        "title": "My Journey to Reinforcement Learning \u2014 Part 0: Introduction",
        "text": "When we google reinforcement learning, we can see images like above, over and over again. So rather than seeing an agent or environment, lets actually think about this as a process where a baby is learning how to walk.\n\n\u201c The \u201cproblem statement\u201d of the example is to walk, where the child is an agent trying to manipulate the environment (which is the surface on which it walks) by taking actions (viz walking) and he/she tries to go from one state (viz each step he/she takes) to another. The child gets a reward (let\u2019s say chocolate) when he/she accomplishes a sub module of the task (viz taking couple of steps) and will not receive any chocolate (a.k.a negative reward) when he/she is not able to walk. This is a simplified description of a reinforcement learning problem.\u201d \u2014 Faizan Shaikh\n\nThe author actually give a long explanation of how these algorithms differ, if you wish to view them please click here. But in a short one/two sentence.\n\nSupervised vs RL : Both map the relation between input and output, but in RL there is an reward function to measure the action that the agent took additionally a cost function to measure if we met the final goal. (e.g Winning a chess game \u2192 Winning the game is important, but there are multiple ways to win a chess game)\n\nUnsupervised vs RL : Unsupervised learning is (mostly) finding patterns in underlying data and clustering them."
    },
    {
        "url": "https://towardsdatascience.com/paper-summary-deep-mind-health-co-designing-a-patient-and-public-involvement-and-engagement-75f811cb08a5?source=user_profile---------21----------------",
        "title": "[ Paper Summary ] \u2014 Deep Mind Health: Co-designing a patient and public involvement and engagement\u2026",
        "text": "As a son of a doctor and as a person who gets sick from time to time. I really enjoyed reading this paper, and learned a lot.\n\nIf you wish to see the list of all of my writing please view my website here.\n\nMeanwhile follow me on my twitter here, and visit my website, or my Youtube channel for more content. I also did segmentation of Medical Images, check them out here."
    },
    {
        "url": "https://towardsdatascience.com/my-take-on-uber-ai-interview-question-with-interactive-code-part-1-40d6d795a566?source=user_profile---------22----------------",
        "title": "My take on Uber AI Interview Question with Interactive Code \u2014 Part 1",
        "text": "So I found this amazing blogger Vimarsh Karbhari and he have some amazing stuffs on his blog! So please check him out, also he is the creator of Acing AI. And today, I\u2019ll try to answer his Uber AI Interview question from this blog. And please note that my solution would be not optimized.\n\nAlso, I am not going to answer question in numeric order. And for every question I\u2019ll try to find the right answer and link them. However, I am always open to learning and growing, so if you know a more optimal solution please comment down below."
    },
    {
        "url": "https://towardsdatascience.com/my-take-on-microsoft-ai-interview-questions-with-interactive-code-part-1-c271388af633?source=user_profile---------23----------------",
        "title": "My Take on Microsoft AI Interview Questions with Interactive Code \u2014 Part 1",
        "text": "So I found this amazing blogger Vimarsh Karbhari and he have some amazing stuffs on his blog! So please check him out, also he is the creator of Acing AI. And today, I\u2019ll try to answer his Microsoft AI Interview question from this blog. And please note that my solution would be not optimized, and I am always open to learning and growing, so if you know a more optimal solution please comment down below.\n\nAlso, I am not going to answer question in numeric order."
    },
    {
        "url": "https://towardsdatascience.com/encrypting-different-medical-images-using-deep-neural-network-with-interactive-code-b47656dcd1e?source=user_profile---------24----------------",
        "title": "Encrypting Different Medical Images using Deep Neural Network with Interactive Code",
        "text": "So yesterday I covered \u201cHiding Images in Plain Sight: Deep Steganography\u201d now lets take that network and apply to a health care setting. We are going to encrypt variety of Medical Images using this Network.\n\nPlease note, we are only going to use publicly available medical images, and below are the list of data set we are going to use.\n\n1. UCSB Bio-Segmentation Benchmark dataset \n\n2. DRIVE: Digital Retinal Images for Vessel Extraction \n\n3. Ultrasound Nerve Segmentation from Kaggle\n\n4. Phantom FDA from Cancer Imaging Archive\n\n5. Cutaneous Melanoma (CPTAC-CM) from Cancer Imaging Archive\n\nAlso, all of the cover images are from this data set \u201cA benchmark for semantic image segmentation\u201d."
    },
    {
        "url": "https://towardsdatascience.com/nips-2017-google-hiding-images-in-plain-sight-deep-steganography-with-interactive-code-e5efecae11ed?source=user_profile---------25----------------",
        "title": "[NIPS 2017/Google] - Hiding Images in Plain Sight: Deep Steganography with Interactive Code [\u2026",
        "text": "However, thankfully the paper did described what kind of cost function the network used as well as what kind of optimizer it used. We are going to use Adam and L2 Loss Function, Square difference.\n\nAbove is the full error function, we are going to take a square difference between the carrier image and secret image. And for scecrte image error function we are going to have a beta term (we are going to set this as 1, so we can ignore it) in front of the square difference that enables how much error we have to put into back propagation. However, one other thing to note is the gradient flow of this model.\n\nAs seen above, the error rate for secret image is propagated all the way back, however for carrier image error rate it is only applied to hiding network and prep network."
    },
    {
        "url": "https://towardsdatascience.com/medical-image-segmentation-part-2-semantic-segmentation-of-pathological-lung-tissue-with-24482942d65a?source=user_profile---------26----------------",
        "title": "Medical Image Segmentation [Part 2] \u2014 Semantic Segmentation of Pathological Lung Tissue with\u2026",
        "text": "Right Image \u2192 Original Image\n\nMiddle Image \u2192 Ground Truth Binary Mask\n\nRight Image \u2192 Ground Truth Mask Overlay on top of Original Image\n\nThere are couple of differences from the original paper and those differences are\u2026..\n\n1. Data Set: I am going to use the segmentation data from Kaggle \u201cUltrasound Nerve Segmentation\u201d\n\n2. Normalization Layer / Batch size: The original paper used Instance Normalization Layer, however as seen below I will use batch normalization. Also, the original paper used a batch size of 1, I will use a batch size of 2.\n\n3. Different number of Feature Map: The original paper reported to use 32 feature maps for each layer, due to hardware limitations I will only use 3 feature maps. ( So in the concatenation operation we would have 1 + 3 * 10 = 31 feature maps)"
    },
    {
        "url": "https://towardsdatascience.com/paper-summary-google-deep-mind-towards-an-integration-of-deep-learning-and-neuroscience-240b7624c57f?source=user_profile---------27----------------",
        "title": "[ Paper Summary ] Google Deep Mind \u2014 Towards an integration of deep learning and neuroscience \u2014\u2026",
        "text": "This part is quite long, but in essence\u2026.\n\n1. Different part of the brain do different thing (e.g Thalamus part of the brain may act as an information routing gate while areas like basal ganglia help making discrete decisions) hence development of different structure of machine learning model are critical (LSTM, RNN, CNN etc\u2026) for efficiency.\n\n2. However, human brain are very special since, even if the world gives us limited amount of labeled data we are able to learn the differences and correctly differentiate from one another. None of existing unsupervised learning algorithms can do what we humans do. (As of today)\n\n3. Hence, it is very important to find the right sequence of cost functions that an unsupervised model can be trained on to provide the right behavior."
    },
    {
        "url": "https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6?source=user_profile---------28----------------",
        "title": "Medical Image Segmentation [Part 1] \u2014 UNet: Convolutional Networks with Interactive Code",
        "text": "The experiment set up for this network is very simple, we are going to use the publicly available data set from Kaggle Challenge Ultrasound Nerve Segmentation. And we are going to see if our model is able to segment certain portion from the image. However, please note that there are three difference from the original paper.\n\nHowever, I used a Mean Square Loss function, with ReLu() activation.\n\n3. Used different Optimizer \u2192 As seen below, the original paper used stochastic gradient descent optimizer, I just used an Adam Optimizer."
    },
    {
        "url": "https://towardsdatascience.com/experimental-model-implementing-tree-style-deep-neural-network-for-cifar-10-classification-1896cff85cce?source=user_profile---------29----------------",
        "title": "[ Experimental Model ] Implementing Tree Style Deep Neural Network for CIFAR 10 Classification [\u2026",
        "text": "So today, I wanted to make an experimental model, and this network architecture came to my thought yesterday evening. An architecture that resembles the shape of a tree, but if you know of any well-known academic paper that supports this innovation or network architecture, please comment below so that I may provide a proper reference.\n\nPlease note that this is an experimental model, hence performance is not my goal.\n\nAgain, as always lets compare .how a manual back propagation method compares with a traditional automatic differentiation model. If you are not aware of automatic differentiation, please click here."
    },
    {
        "url": "https://towardsdatascience.com/denosing-lung-ct-scans-using-neural-networks-with-interactive-code-part-4-convolutional-resnet-74335714a4ae?source=user_profile---------30----------------",
        "title": "Denosing Lung CT Scans using Neural Networks with Interactive Code \u2014 Part 4, Convolutional ResNet\u2026",
        "text": "I won\u2019t go into details with this, since this architecture is already so famous on its own. But as a high level overview, we are going to have two convolution operation for each layer, and add up the input to the output.\n\nHowever, one difference is that we are going to add a third convolution operation to create a bottle neck layer. Let me explain below."
    },
    {
        "url": "https://towardsdatascience.com/paper-summary-big-data-analytics-in-healthcare-promise-and-potential-ee3fba1488ea?source=user_profile---------31----------------",
        "title": "[Paper Summary] Big data analytics in healthcare: promise and potential",
        "text": "Examples of General Advantage:\n\na) Detecting Diseases earlier, and they can be more easily treated\n\nb) Predict the length of stay for different patient\n\nc) Save money from not doing wasteful research (Mckinsey estimates $300 Billion Dollars)\n\nc) Public Health: in an event of crises deal with the event more effectively and efficiently\n\nd) Evidence-based medicine: using past results from different sources (eg. EMR, or operation data) predict future outcomes.\n\ne) Genomic analytics: Analyze Gene data or do Gene Sequencing more efficiently\n\nf) Pre-adjudication fraud analysis: Analyze operation data to see if fraud exist\n\nh) Patient profile analytics: perform patient specific analytics to see what is the best procedure for that specific patient."
    },
    {
        "url": "https://towardsdatascience.com/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642?source=user_profile---------32----------------",
        "title": "Understanding Batch Normalization with Examples in Numpy and Tensorflow with Interactive Code",
        "text": "Red Box \u2192 Equation for Standardization\n\nBlue Line \u2192 Parameters that are going to be learned\n\nNow we have covered both normalization and standardization we can see that the equation for batch normalization is exactly the same process for standardization. The only difference is the gamma and beta term, underlined in blue. We can think of these terms exactly like weights, we are going to calculate the error from the ground truth data and using back propagation learn these parameters.\n\nBut there is one thing I wish to note! If we set the gamma (thank you Luoyang Fang for correcting me) as 1 and beta as 0 the whole process is just standardization. And for Tensorflow\u2019s implementation we are going to abuse this property."
    },
    {
        "url": "https://towardsdatascience.com/implementing-neural-network-used-for-self-driving-cars-from-nvidia-with-interactive-code-manual-aa6780bc70f4?source=user_profile---------33----------------",
        "title": "Implementing Neural Network used for Self Driving Cars from NVIDIA with Interactive code [Manual\u2026",
        "text": "So recently I came across this Quora question, \u201cHow many layers do neural networks used for self-driving cars have?\u201d, and soon I found out, (by answer from Prasoon Goyal ) that the model used by NVIDA from 2016 is not that complicated.\n\nDon\u2019t believe me? See the Network Architecture Below. Also, here is the link to the original paper, \u201cEnd to End Learning for Self-Driving Cars\u201d.\n\nFinally please note two things. \n\n1. This model was used in 2016, the current one would be much more sophisticated.\n\n2. Lets used Dilated Back propagation on this model as well, to see what kind of result we can achieve."
    },
    {
        "url": "https://towardsdatascience.com/paper-break-down-ten-quick-tips-for-machine-learning-in-computational-biology-3b224f6fed7e?source=user_profile---------34----------------",
        "title": "[ Paper Break Down ] Ten Quick Tips for Machine Learning in Computational Biology",
        "text": "Tip 5: Take care of the imbalanced data problem\n\nHere the author advise to make sure your data set is properly balanced. And if that is not the case the author also gives us a very simple rule that can counter act that difference. Which is the 50% Average rule.\n\nFor example, if you have 90% negative examples, and 10% positive examples in your data.\n\nBy using the 50% average rule as shown above, you can get a good ratio of how much data to put into your model."
    },
    {
        "url": "https://towardsdatascience.com/nips-2017-tensorflow-gated-recurrent-convolution-neural-network-for-ocr-part-1-with-47bb2a8a7ab3?source=user_profile---------35----------------",
        "title": "[NIPS 2017/Part 1] Gated Recurrent Convolution NN for OCR with Interactive Code [ Manual Back Prop\u2026",
        "text": "So this is the first part of implementing Gated Recurrent Convolutional Neural Network. And I will cover one by one, so for today lets implement a simple Recurrent Convolutional Neural Network as a warm up, and perform classification on MNIST data set.\n\nFinally, as usual lets compare how manual Dilated Back Propagation performs when compared to auto differentiation."
    },
    {
        "url": "https://towardsdatascience.com/iclr-2016-implementing-context-module-in-tensorflow-with-interactive-code-manual-back-prop-with-a2c84b3ae444?source=user_profile---------36----------------",
        "title": "ICLR 2016 \u2014 Implementing Context Module in Tensorflow with Interactive Code [Manual Back Prop with\u2026",
        "text": "Since I covered Dilated Convolution operation in the previous post it only make sense if I made a network out of it. So I think it is best for me to implement the Context Module Presented in this paper \u201cMulti-Scale Context Aggregation by Dilated Convolutions\u201d. Which was presented in International Conference on Learning Representations 2016.\n\nThere are two things I wish to point out\u2026\n\n1. The authors of the original paper initialized the weights using their own methods, for this post I am just going to initialize from normal distribution. \n\n2. For fun, lets train the network with Dilated Back Propagation as well."
    },
    {
        "url": "https://towardsdatascience.com/understanding-2d-dilated-convolution-operation-with-examples-in-numpy-and-tensorflow-with-d376b3972b25?source=user_profile---------37----------------",
        "title": "Understanding 2D Dilated Convolution Operation with Examples in Numpy and Tensorflow with\u2026",
        "text": "Red Box \u2192 Original Matrix \n\nBlue Box \u2192 The kernel we are going to use\n\nSo we are just going to perform multiple convolution operation to the Red Boxed Matrix using the Blue Boxed Kernel. However, there are three things to note.\n\n3. As seen above, ALL OF Tensorflow operation will use the original (3*3) kernel while changing the Dilation Factor, while for Numpy we will GENERATE specific kernel for each Dilation rates."
    },
    {
        "url": "https://towardsdatascience.com/depth-breath-first-search-matrix-traversal-in-python-with-interactive-code-back-to-basics-31f1eca46f55?source=user_profile---------38----------------",
        "title": "Depth / Breath First Search Matrix Traversal in Python with Interactive Code [ Back to Basics ]",
        "text": "Search algorithms are the perfect place to start when you want to know more about algorithms as well as artificial intelligence. So lets start with the basics Breath first search and Depth-first search to traversal a matrix.\n\nPlease take note the code is not optimized in any other method. It is brute force implementation. So be caution."
    },
    {
        "url": "https://towardsdatascience.com/converting-dna-sequence-to-protein-sequence-using-deep-neural-network-with-interactive-code-manual-16d41e1304a7?source=user_profile---------39----------------",
        "title": "Converting DNA Sequence to Protein Sequence using Deep Neural Network with Interactive Code [Manual\u2026",
        "text": "So today, I will continue my journey to Bio-informatics with Machine Learning. And I will try to perform the most basic task in Bio-informatics, which is converting DNA sequence to Protein. Also, this is over complicating the task, we can just build a dictionary to map the values, as done by Vijini Mallawaarachchi in this post.\n\nAlso, please take note that we are going to preprocess the DNA / Protein sequence to vectors, if you are not aware of how to do that, please see this post.\n\nFinally, I am going to perform Dilated Back Propagation to train our network."
    },
    {
        "url": "https://towardsdatascience.com/dna-protein-representation-for-machine-learning-task-with-interactive-code-6aa065b69227?source=user_profile---------40----------------",
        "title": "DNA / Protein Representation for Machine Learning Task with interactive code",
        "text": "So in today\u2019s post I am not going to perform any Machine Learning task rather it is preprocessing step for DNA and protein data.\n\nPlease note, I took portion of the code from this blog post and this blog post. So if you want to know more about bioinformatic or one hot encoding, check those blog posts out."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/analysis-of-binary-feature-mapping-rules-for-promoter-recognition-in-imbalanced-dna-sequence-c4b557fb3105?source=user_profile---------41----------------",
        "title": "Analysis of Binary Feature Mapping Rules for Promoter Recognition in Imbalanced DNA Sequence\u2026",
        "text": "Paper breakdown is series of post, where I read one paper and just write some notes down. For today, I will go though: \u201cAnalysis of Binary Feature Mapping Rules for Promoter Recognition in Imbalanced DNA Sequence Datasets using Support Vector Machine\u201d\n\n***These are notes to myself ***"
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/archive-post-how-to-install-open-ai-gym-on-windows-1f5208c16179?source=user_profile---------42----------------",
        "title": "[Archive Post] How to install open AI gym on windows.",
        "text": "Thank you all. Here I try to summarize the method of installing the complete OpenAI Gym on Windows without using WSL, for future reference.\n\nThe following procedure has been tested on both Windows 7 and Windows 10.\n\nNote: If you are using a non-English version of Windows and get , see this solution: pypa/pip#4251 (comment)."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/archived-training-results-out-performing-tensorflows-default-auto-differentiation-optimizers-28c5a75e9fc0?source=user_profile---------43----------------",
        "title": "[Archived Training Results] Out-Performing Tensorflow\u2019s Default Auto Differentiation Optimizers",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://towardsdatascience.com/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e?source=user_profile---------44----------------",
        "title": "Outperforming Tensorflow\u2019s Default Auto Differentiation Optimizers, with Interactive Code [Manual\u2026",
        "text": "So I was thinking about this idea for a long time, is there a different (even better) way to train a neural network? Frameworks such as Tensroflow, Keras, pyTorch are amazing and very easy to use. Thanks to not only their ability to perform auto differentiation for us, but they provide us with wide selection of optimizers. But that does not mean that we have to only rely on their Auto Differentiation.\n\nSo lets do something different, I\u2019ll try to outperform Tensorflows Auto Differentiation presented in their default implementation, in total there are 10 optimizers. And the two techniques that we are going to use to outperform auto differentiation are\u2026\n\na. Google Brain\u2019s Gradient Noise\n\nb. Dilated Back Propagation with ADAM optimizer for each layer"
    },
    {
        "url": "https://towardsdatascience.com/denosing-lung-ct-scans-using-neural-networks-with-interactive-code-part-3-convolutional-residual-6dbb36b28be?source=user_profile---------45----------------",
        "title": "Denosing CT Scans using NN with Interactive Code \u2014 Part 3, Convolutional Residual Neural Networks\u2026",
        "text": "So since I will be using a lot of image data, I will move on to Tensorflow to harness the power of GPU however, no worries, we will implement all of our back propagation. (Also compare the final results with auto differentiation). Now due to midterms I wasn\u2019t able to do much, so I thought of simple Convolutional Residual Neural Networks.\n\nFinally, for fun let\u2019s use different types of back propagation to compare what gives us the best results. The different types of back propagation that we are going to use are\u2026.\n\nNOTE: All of the DICOM images are from Cancer Image Archive Net, if you are planning to use the data please check with their Data Use-age policy. Specifically I will use DICOM images from Phantom FDA Data Set."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/do-deep-nets-really-need-weight-decay-and-dropout-paper-break-down-acf54e19eb48?source=user_profile---------46----------------",
        "title": "Do deep nets really need weight decay and dropout? \u2014 Paper Break Down",
        "text": "Paper Break Down is series where I read papers, and just write down what I have learned. Aka. My online note book, in hopes to help future me.\n\n2. Using the standard CIFAR data set, and resizing them as well as convert them to float 0\u20131.\n\n3. Two kind of augmentation, one is light (Used by Goodfellow as well) and the other one is heavy.\n\n4. Two network, one is All-CNN (surprised this network actually performs well) and the other is Wide Residual Network. (Also added Batch Norm)\n\n6. Very interesting case \u2014 Wide Res Net \u2014 better performance with drop out. However All-CNN 100 is not the case.\n\n7. The conclusion, is drop out layers or weight decay might not be needed since we can just use data augmentation."
    },
    {
        "url": "https://hackernoon.com/only-numpy-recommending-optimal-treatment-for-depression-using-dilated-update-gate-rnn-google-c327353f2d99?source=user_profile---------47----------------",
        "title": "Only Numpy: Recommending Optimal Treatment for Depression using Dilated Update Gate RNN (Google\u2026",
        "text": "University of Florida\u2019s Bio-statistic is a great place to find health related data. One of them being a study about depression conducted by National Institutes of Health. To quote from the website directly \u201c109 clinically depressed patients were separated into three groups, and each group was given one of two active drugs (Imipramine or Lithium) or no drug at all. For each patient, the data set contains the treatment used, the outcome of the treatment, and several other interesting characteristics\u2026..\u201d\n\nThere are five column for this data set, and for description for each column please see below.\n\nUsing this data, we can build a classifier that predicts whether certain treatment will prevent Depression from reoccurring or not. And using this model we can recommend the optimal treatment that has the highest probability of preventing Depression from reoccurring.\n\nFinally, for fun let\u2019s use different types of back propagation to compare what gives us the best results. The different types of back propagation that we are going to use are\u2026.\n\nIf you are not aware of the difference between each of them please read the blog post that I have linked to.\n\nNOTE: All of the CSV data are from University of Florida Bio-statistics, if you are planning to use the data set please check with their Data Use-age policy. Specifically I will use CSV data from \u2018Learn By doing Depression\u2019 Data set."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-medical-denosing-lung-ct-scans-using-neural-networks-with-interactive-code-part-2-6def73cabba5?source=user_profile---------48----------------",
        "title": "Only Numpy Medical: Denosing Lung CT Scans using Neural Networks with Interactive Code \u2014 Part 2\u2026",
        "text": "So today, I will continue on the image denoising series, and fortunately I found this paper \u201cLow-dose CT denoising with convolutional neural network. In Biomedical Imagin\u201d by Hu Chen. So lets take a dive into their implementation and see what results we get. Finally, for fun let\u2019s use different type of back propagation to compare what gives us the best results. The different types of back propagation that we are going to use are\u2026.\n\nIf you are not aware of the difference between each of them please read the blog post that I have linked to.\n\nNOTE: All of the DICOM images are from Cancer Image Archive Net, if you are planning to use the data please check with their Data Use-age policy. Specifically I will use DICOM images from Phantom FDA Data Set."
    },
    {
        "url": "https://hackernoon.com/only-numpy-dilated-back-propagation-and-google-brains-gradient-noise-with-interactive-code-3a527fc8003c?source=user_profile---------49----------------",
        "title": "Only Numpy: Dilated Back Propagation and Google Brain\u2019s Gradient Noise with Interactive Code",
        "text": "So yesterday I found this paper \u201cDilated Recurrent Neural Networks\u201d from NIPS 2017 and implemented here . But then something hit me, Res Net and High Way net are built in a way that allows direction connection between the input data X and the transformed data X`.\n\nWhy can\u2019t we do the exact same for back propagation as well? Connect the gradient from previous layers to deeper layers\u2026..\n\nI mean, if you are not using frameworks to perform auto differentiation, why don\u2019t we connect the gradients from latest layer to more deeper layer, and just see how that goes? In this post, we\u2019ll do exactly that, also lets go one step further and compare with a model that applies Google Brain\u2019s Gradient Noise.\n\nSince I got the inspiration after reading the Dilated RNN, I\u2019ll just call this Dilated Back Propagation, however if anyone knows other papers where they performed back propagation in this fashion, please let me know in the comment section. Also, I will assume you already have read my Blog post about Implementing Dilated RNN, if not please click here."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-nips-2017-implementing-dilated-recurrent-neural-networks-with-interactive-code-e83abe8c9b27?source=user_profile---------50----------------",
        "title": "Only Numpy: NIPS 2017 - Implementing Dilated Recurrent Neural Networks with Interactive Code.",
        "text": "Now the equation is bit complicated to understand in the mathematical equation form. So the authors of the paper have provided us with some graphics.\n\nSo as seen above, it is typical RNN but with multiple layers as well as skipped connections here and there."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-medical-denosing-lung-ct-scans-using-auto-encoders-with-interactive-code-part-1-a6c3f9400246?source=user_profile---------51----------------",
        "title": "Only Numpy Medical: Denosing Lung CT Scans using Neural Networks with Interactive Code \u2014 Part 1\u2026",
        "text": "My passion lies in Artificial Intelligent, and I want my legacy to be in the field of Health Care, using AI. So in hopes to make my dream come true as well as to practice OOP approach of implementing neural networks I will start the first part of long series of Denosing Lung CT Scans. I am going to start this series off with implementing the vanilla Auto Encoder, with Adam Optimizer.\n\nNOTE: All of the DICOM images are from Cancer Image Archive Net, if you are planning to use the data please check with their Data Use-age policy. Specifically I will use DICOM images from Phantom FDA Data Set."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-highway-network-oop-approach-with-mini-batch-with-interactive-code-b5c2de2df842?source=user_profile---------52----------------",
        "title": "Only Numpy: Implementing Highway Network, OOP approach with Mini Batch with Interactive Code",
        "text": "Red Box \u2192 Affine Transform + Non Linear Activation, we can think of this as \u2018normal\u2019 layer in standard Fully Connected Network\n\nBlue Box \u2192 Transform Gate, which we can also think of as Affine Transform + None Linear Activation (but with different activation function)\n\nGreen Box \u2192 Where we will add on our modification from the original paper. In the paper, we should directly pass on the input, however to match dimensionality I am going to add an affine transform as well as non linear activation function here as well. (Also, please note I will call them \u2018A\u2019 as a shorted form of \u2018Added\u2019.)"
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-decoupled-convolutional-lstm-to-classify-puppy-gifs-and-baby-gifs-with-interactive-4d3f4ab9d725?source=user_profile---------53----------------",
        "title": "Only Numpy: Decoupled Convolutional LSTM to classify Puppy GIFs and Baby GIFs with Interactive\u2026",
        "text": "Before reading on, please note that this is experimental model, I just wanted to challenge myself to build this model. So there are some high possibilities that there are some errors in the back propagation process. I will come back to this post to confirm this matter. Also, all of the GIF from this post are from GIPHY.\n\nLSTM is hard to train and even harder to implement without using frameworks. And the reason, in my opinion, is the sheer number of equation we need to solve to get the gradient for each weight in different time stamps. While performing back propagation on GRU, I realized how many equations we need just to get the gradient respect to one weight in time stamp 1.\n\nActually, the number of equation we need grows exponentially respect to the number of recurrent connection for each layer. So in LSTM\u2019s case, the number of equation needed grows by\u2026..\n\nAlso plus alpha if we are getting the cost for different time stamp layer as well, not just the most outer layer. Please have a look at my blog post on performing feed forward and back propagation operation on lstm here.\n\nHowever there is one approach to decrease the number of equation we need, and that is using the decoupled neural network architecture. Using this approach we can break the chain rule, kind of\u2026..\n\nSo with that in mind, let me explain what I wanted to do. Also if you are not familiar with LSTM please check out Colah\u2019s Blog."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/week-end-check-up-archive-574a92de509e?source=user_profile---------54----------------",
        "title": "Week End Check Up Archive \u2013 Jae Duk Seo \u2013",
        "text": "To make sure I am posting correct materials, I will dedicate this post as an archive to store all of the manual back propagation. As a double check up on all of the post I made. This is for quality assurance if any error found, please email me at \u2018jae.duk.seo@gmail.com\u2019."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-simple-resnet-for-mnist-classification-with-interactive-code-d58c77064304?source=user_profile---------55----------------",
        "title": "Only Numpy: Implementing Simple ResNet ( Deep Networks with Stochastic Depth) for MNIST\u2026",
        "text": "So I was reading this article \u201cStochastic Depth Networks will Become the New Normal\u201d and there I saw the paper \u201cDeep Networks with Stochastic Depth\u201d. Upon reading that paper I saw the diagram below.\n\nAnd right away I was inspired to build my own Res Net. However, since batch normalization is bit complicated to implement for back propagation I will not count them in for today\u2019s implementation. But I promise, I will implement them soon!"
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-mini-vgg-vgg-7-and-softmax-layer-with-interactive-code-8994719bcca8?source=user_profile---------56----------------",
        "title": "Only Numpy: Implementing Mini VGG (VGG 7) and SoftMax Layer with Interactive Code",
        "text": "I wanted to practice my Back Propagation skills on Convolutional Neural Network. And I wanted to implement my own VGG net (from original paper \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d) for sometime now, so today I decided to combine those two needs.\n\nIf you are not aware of back propagation process on convolution neural network, please view my tutorial on back propagation on convolution neural networks, here or here."
    },
    {
        "url": "https://towardsdatascience.com/manual-back-prop-with-tensorflow-decoupled-recurrent-neural-network-modified-nn-from-google-f9c085fe8fae?source=user_profile---------57----------------",
        "title": "Manual Back Prop with TensorFlow: Decoupled Recurrent Neural Network, modified NN from Google\u2026",
        "text": "I love Tensorflow and it\u2019s ability to perform auto differentiation, however that does not mean we cannot perform manual back propagation even in Tensorflow. Also for me, building an Neural Network is a form of art, and I want to master every single part of it. So today, I will implement Decoupled RNN for simple classification task, in TensorFlow using manual back propagation. And compare the performance with auto differentiated model.\n\nDecoupled NN was originally introduced in this paper \u201cDecoupled Neural Interfaces using Synthetic Gradients\u201d please read. Also I did Numpy version of implementation on Decoupled RNN here.\n\nFinally, please note for this post, I will be more focused on how Tensorflow implementation is different from Numpy\u2019s. And explain the reasons why I like Tensorflow\u2019s implementation."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-and-comparing-gradient-descent-optimization-algorithms-google-brains-8870b133102b?source=user_profile---------58----------------",
        "title": "Only Numpy: Implementing and Comparing Gradient Descent Optimization Algorithms + Google Brain\u2019s\u2026",
        "text": "Above image is trained result from running the code on Google Colab (Greatest invention of man kind.). I was mostly amazed by two things. The Red Star \u2192 Where Adadelta\u2019s cost have started going crazy and went to point of no return. \n\nBrown Star \u2192 Where Adam Noise optimization method actually started to show signs of convergence. It is truly amazing to see how this is even possible.\n\nAlso, please note the reason why you can\u2019t see Noise Training results (j) is because Noise Training and Gaussian Additive Noise almost have identical cost values, so one is overlay-ed by another.\n\nAbove you can see how the cost values for two optimization methods are very close to one another."
    },
    {
        "url": "https://medium.com/swlh/only-numpy-decoupled-recurrent-neural-network-modified-nn-from-google-brain-implementation-with-7f328e7899e6?source=user_profile---------59----------------",
        "title": "Only Numpy: Decoupled Recurrent Neural Network, modified NN from Google Brain, Implementation with\u2026",
        "text": "Pink Box \u2192 Every RNN have notion of Time Stamp, in this case, since there is A LOT going on with each time stamp. I decided to call them Time Box LOL.\n\nRed Box \u2192 Order of execution. Please take note that we don\u2019t have to fully wait on forward feed process to finish before updating the weights, as seen in box 2,4,5 and 7.\n\nOrange Star \u2192 True Gradient for each Time Stamp, we need this value to update our Oracle (Green Diamonds, that you saw in the first image) at each time stamp. Also, the math equation to get this value is very long, so I will show them as a code implementation in the next section."
    },
    {
        "url": "https://medium.com/swlh/only-numpy-noise-training-training-a-neural-network-without-back-propagation-with-interactive-ad775f04cad6?source=user_profile---------60----------------",
        "title": "Only Numpy: Noise Training - Training a Neural Network without Back Propagation with Interactive\u2026",
        "text": "So I was thinking, in Korea we have this word called \uc774\uc5f4\uce58\uc5f4. It means fight fire with fire or force with force. My parents would tell me this during the Summer/Winter time, when the weather gets too hot/cold. The would tell me to eat or drink Hot Soup/Ice Cream to make the Heat/Cold go away. Thinking back, the logic doesn\u2019t make any sense, but keep this idea in mind, while reading the next part.\n\nOne challenge for Neural Network is knowing the ground truth representation of the given data in the hidden layers. Simply put we don\u2019t have the ground truth values for hidden layers, so naturally we don\u2019t know how the data is supposed to be represented in those hidden layers.\n\nBut we need hidden layers for the network to perform complex tasks. Directly quoting from the paper published in 1986 \u201cLearning internal representations by error propagation\u201d by Dr. Hinton, Dr. Rumelhart and Dr. Williams.\n\nVery good example is the classical XOR problem.\n\nAnd this is my understanding of NN as well. The model is trying to learn or recognize patterns in the given data. Once certain pattern is learned from the training data. We can take advantage of this pattern to classify images or patient health status etc\u2026..\n\nHowever the data could contain noises that makes it harder for the model to learn proper weights that recognizes this pattern.\n\nFrom here, I got myself thinking, can we cancel out noise in the data with noise?\n\nLike how cosine wave and sine wave cancel each other, and like \uc774\uc5f4\uce58\uc5f4, can we fight noise with noise? I wanted to test this idea.\n\nWarning! \n\nI am not Good at Math, and this method does not have a solid proof on why this could be somewhat working. If any mathematician knows exactly why this happens (and possibly the theory behind this), please comment down below."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-gan-general-adversarial-networks-and-adam-optimizer-using-numpy-with-2a7e4e032021?source=user_profile---------61----------------",
        "title": "Only Numpy: Implementing GAN (General Adversarial Networks) and Adam Optimizer using Numpy with\u2026",
        "text": "One more thing to note is Red (L2A) and Blue (L2A) . Red (L2A) is the final output of our Discriminator Network with Real Image as input. And Blue (L2A) is the final output of our Discriminator Network with Fake Image as input.\n\nAgain, I won\u2019t go into too much details, but please note the Red Boxed Region called Data. For the Discriminator Network in GAN, that Data either can be Real Image or Fake Image Generated by the Generator Network. Our images are (1,784) vector of MNIST data set.\n\nThe way we implement this is by getting the real image, and fake data before putting them both into the network.\n\nLine 128 \u2014 Getting the Real Image Data \n\nLine 147 \u2014 Getting the Fake Image Data (Generated By Generator Network)\n\nAlso, please take note of the Blue Box Region, that is our cost function. Lets compare the cost function from the original paper, shown below.\n\nThe difference is the fact that we are putting a (-) negative sign in front of the first term log(L2A).\n\nAs seen above, in TensorFlow implementation we flip the signs if we want to Maximize some value, since TF auto differentiation only can Minimize.\n\nI thought about this and I decided to implement in a similar way. Cuz I wanted to Maximize the chance of our discriminator guessing right for real image while Minimize the chance of our discriminator guessing wrong for fake images, and I wanted the sum of those values to balance out. However, I am not 100 % sure of this part as of yet, and will revisit this matter soon."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-convolutional-update-gate-rnn-modifying-google-brains-update-gate-rnn-capacity-and-4a3e932eccf8?source=user_profile---------62----------------",
        "title": "Only Numpy: Convolutional Update Gate RNN, modifying Google Brain\u2019s Update Gate RNN (Capacity and\u2026",
        "text": "There is alot going on in above image, so let me explain from very right.\n\nLight Green Box \u2192 Zero Padding the Hidden State to Preserve Dimension (Very important to notice this since, we need to preserve the Dimensions!)\n\nX \u2192 Input Image of Dimension (8*8)\n\nWxg, Wxc \u2192 Convolution Kernel that is going to be applied to Input Image, Dimension (5*5)\n\ng(t),c(t),h(t) \u2192 Output of each Gate, all have dimension of (4*4)\n\nWrecc,Wrecg \u2192 Convolution Kernel that is going to be applied to Previous Hidden State Dimension (3*3)\n\nOrange Box \u2192 Forward Feed of CURNN and I assumed to have 2 Time Stamps\n\nPurple Box \u2192 For Both of the time stamp the input is the exact SAME IMAGE! (So my idea was the network might learn better by showing the same image once more, LOL don\u2019t know if this might be true.)\n\nBelow is the code implementation."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-google-brains-rnn-intersection-rnn-capacity-and-trainability-in-7dd7902b65a5?source=user_profile---------63----------------",
        "title": "Only Numpy: Implementing Google Brain\u2019s +RNN \u2014 INTERSECTION RNN (Capacity and Trainability in\u2026",
        "text": "So one thing to note here, I am not going to take the derivative respect to weights, rather I am going to take derivative respect to YY, HH, GY and GH.\n\nWhy? Well please take a look at Black Box, we are performing back propagation respect to the input to the activation function. After that we can either\n\nmultiply h2, if we want to perform back propagation respect the Wrecyy, Wrechh, Wrecgy, or Wrecgh, or\n\nmultiply x3, if we want to perform back propagation respect the Wxyy, Wxhh, Wxgy, or Wxgh.\n\nBelow is the code for back propagation implemented for time stamp 3."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981?source=user_profile---------64----------------",
        "title": "Only Numpy: Understanding Back Propagation for Transpose Convolution in Multi Layer CNN with\u2026",
        "text": "Funny Story Of Where I Got the Answer.\n\nYesterday, I was invited to a dinner for a gathering. The reason was one of very knowledgeable master student finished her defense successfully, So we were celebrating. However, for the past two days I wasn\u2019t able to fully understand the whole back propagation process of CNN. \n\nAs soon as I tried to perform back propagation after the most outer layer of Convolution Layer I hit a wall.\n\nBut at that dinner, it finally hit me.\n\nLooking at the corns on my plate, I realize that all this time, I was trying to understand the back propagation process in CNN as deconvolution. This was my original thinking.\n\nLet Red Box be 2*2 Output Image\n\nLet Green Box be 3*3 kernel\n\nLet Blue Box be 4*4 Input Image\n\n\u201cSince we get a 2*2 Output image after performing Convolution on 4 * 4 image, then, while performing back propagation we need to do perform some operation on 2*2 Output image to get some image that have 4*4 Dimension.\u201d\n\nBut the corns (LOL) made me realize that our goal isn\u2019t to restore the original image. Rather we are trying to get the error rate respect to the every weight in the network. And in the case of multi layer CNN, we need to back propagate that error. So haha, that\u2019s where I got my solution, and let me \u2018try\u2019 to explain what I mean by a concrete example and code."
    },
    {
        "url": "https://medium.com/swlh/only-numpy-why-i-do-manual-back-propagation-implementing-multi-channel-layer-convolution-neural-7d83242fcc24?source=user_profile---------65----------------",
        "title": "Only Numpy: (Why I do Manual Back Propagation) Implementing Multi Channel/Layer Convolution Neural\u2026",
        "text": "So, I made a post about understanding back propagation on Max Pooling Layer as well as Transpose Convolution. The next step would be to use those knowledge to make a Multi Channel/Layer CNN, so\u2026.lets do that! Also, just FYI, I am using momentum optimizer.\n\nBefore reading this post, I recommend reading this Quora question, \u201cWhy is Geoffrey Hinton suspicious of backpropagation and wants AI to start over?\u201d or this blog post \u201cWhy we should be Deeply Suspicious of BackPropagation\u201d. Both are very interesting.\n\nAlso, please note that it would be better if you already understand well about back propagating via transpose convolution and max pooling layer, since I won\u2019t go into detail in this post."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/only-numpy-understanding-back-propagation-for-max-pooling-layer-in-multi-layer-cnn-with-example-f7be891ee4b4?source=user_profile---------66----------------",
        "title": "Only Numpy: Understanding Back Propagation for Max Pooling Layer in Multi Layer CNN with Example\u2026",
        "text": "Okay, so there is a lot going here, let me explain one by one.\n\nPurple Star \u2192 Convolution Operation with the Kernel Rotated by 180 degrees (Other words transposed), we need to do this for proper update of gradient.\n\nRed Box \u2192 Mathematical Form of finding the Coordinates of highest signal on L1 \n\nBlue Box \u2192 Matrix Form of actual Coordination of where the highest values were in variable L1. (This was the reason why I told you guys to please take note of the Blue Circled Numbers in the Forward Feed Process)\n\nHowever, one question arises, please look at the Orange star, how can we perform element wise multiplication between Matrix that have Dimension of (2*2) and (4*4)? I will answer that in a moment for now, lets take a look at the actual implementation of the code."
    },
    {
        "url": "https://becominghuman.ai/only-numpy-implementing-and-comparing-google-brains-update-gate-capacity-and-trainability-in-940f0ad80649?source=user_profile---------67----------------",
        "title": "Only Numpy: Implementing and Comparing Google Brain\u2019s Update Gate (Capacity and Trainability in\u2026",
        "text": "So I was browsing around Google Brain\u2019s \u2018Google AI Residency\u2019 publication section and found this wonderful paper \u2018Capacity and Trainability in Recurrent Neural Networks\u2019. Also, from that paper, I was able to find this amazing paper, \u2018A Simple Way to Initialize Recurrent Networks of Rectified Linear Units\u2019. Both are very amazing papers, and I highly encourage you guys to read both. Now before we begin we are going to implement three different type of RNN.\n\n1 \u2192 Vanilla RNN\n\n2 \u2192 Initialize RNN (Which have the benefit of having same structure as Vanilla RNN)\n\n3 \u2192 Update Gate RNN (Which was a novel implementation from Google Brain)\n\nAlso very important point, I was playing around with activation function, so please don\u2019t expect this symbol \u03c3() means logistic sigmoid function.\n\nI could be using logistic_sigmoid() or tanh() vice versa. And play around for yourself to see what gives the best results, and comment down below!\n\nVery simple training data, basically want to add all of the given numbers, nothing too crazy. But we have quite a lot of weights.\n\nwx_i \u2192 Initialize RNN weight, since we set our weight to have dimension of (1,1) this would be the identity matrix.\n\nw_rec_i \u2192 Initialize RNN Recurrent weight\n\nFinally, below arethe learning rates, RNN and IRNN share same learning rates."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af?source=user_profile---------68----------------",
        "title": "Only Numpy: Implementing and Comparing Combination of Google Brain\u2019s Decoupled Neural Interfaces\u2026",
        "text": "So I was thinking, Google Brain published this paper \u201c Decoupled Neural Interfaces using Synthetic Gradients\u201d that enables training of each layer simultaneously. The Network Architecture is constructed in a way that each layer does not depend on next layers gradient, when performing back propagation. (Sort of).\n\nAnd they also published this paper \u201cAdding Gradient Noise Improves Learning for Very Deep Networks\u201d. I wrote a blog post few days ago, about adding Gaussian Noise to Back Propagation to make learning faster, now lets combine those two ideas together."
    },
    {
        "url": "https://becominghuman.ai/only-numpy-implementing-convolutional-neural-network-using-numpy-deriving-forward-feed-and-back-458a5250d6e4?source=user_profile---------69----------------",
        "title": "Only Numpy: Implementing Convolutional Neural Network using Numpy ( Deriving Forward Feed and Back\u2026",
        "text": "Lets keep things very simple, we have four (3*3) images. (LOL well too small to call them images but, it\u2019ll do the job). And as you can see in the Ground truth Label Data (Y), if the image have more 1, the resulted output increases. The max is set to 1.1 since we are using logistic sigmoid function as final output.\n\nSo as seen above, we have a very simple network structure.\n\nX \u2192 3*3 Image\n\nK \u2192 Convolution Operation (Right is Matrix Form, Left is Vectorization form) \n\nGreen Start \u2192 Resulted Image (Right Matrix Form, Left is Vectorization form)\n\nIf above image is confusing for you please see the image below.\n\nBasically, the 3*3 pixel convolution operation can be thought of multiplying certain pixels located in different images with given weight."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-implementing-different-combination-of-l1-norm-l2-norm-l1-regularization-and-14b01a9773b?source=user_profile---------70----------------",
        "title": "Only Numpy: Implementing Different combination of L1 /L2 norm/regularization to Deep Neural Network\u2026",
        "text": "As seen above, derivative of absolute function have three different cases, when X > 1, X < 1 and X = 0.\n\nOption 1 \u2192 When X > 1, derivative = 1\n\nOption 2 \u2192 When X = 0, derivative = undefined\n\nOption 3 \u2192 When X < 1, derivative = -1\n\nSince we can\u2019t just let the gradient to be \u2018undefined\u2019 I BREAK THIS RULE.\n\nAbove, is the function that I will use to calculate the derivative of value X. And as seen above, I don\u2019t have the second option, we merged that into first option."
    },
    {
        "url": "https://towardsdatascience.com/only-numpy-deriving-forward-feed-on-multi-dimensional-recurrent-neural-networks-spatial-lstm-by-35d111906258?source=user_profile---------71----------------",
        "title": "Only Numpy: Deriving Forward Feed on Multi-Dimensional Recurrent Neural Networks (Spatial LSTM) by\u2026",
        "text": "So above image shows how we can take the idea of 1D LSTM, to 2D LSTM. To apply them on images. One very important thing to take note from above photo are the Cell State and hidden States. Yellow Box \u2192 1D LSTM\n\nGreen Box \u2192 Transposed 1D LSTM \n\n(Think about it as being one column in a matrix)\n\nPink Box \u2192 2D LSTM\n\nAs seen above, for 1D LSTM, we initialize C(0) and h(0) before we start to train the network. There are multiple of methods to initialize these values, for example in the paper \u201c Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\u201d the authors initialize the first values via something called MLP \u2014 I can only assume that it is Multi Layer Perceptrons. Image from original Paper Show, Attend and Tell: Neural Image Caption Generation with Visual Attention But in 2D LSTM, we have to initialize whole lot more of cell and hidden state values.\n\nAs seen above, not only we need to initialize from C(0,1) to C(0,j) but also C(1,0) to C(i,0). Same goes for all hidden states. Now we can do something interesting, since we know the structure of 1D LSTM and 2D LSTM, let\u2019s imagine 3D LSTM.\n\nQuite a beauty isn\u2019t she? :D \n\nAgain, the orange boxes are the location of the first Cell and Hidden States. The applications for this network is not only bounding to video data but much more. Now we know the general structure, lets go back to the paper \u201c Generative Image Modeling Using Spatial LSTMs\u201d"
    },
    {
        "url": "https://becominghuman.ai/only-numpy-implementing-adding-gradient-noise-improves-learning-for-very-deep-networks-with-adf23067f9f1?source=user_profile---------72----------------",
        "title": "Only Numpy: Implementing \u201cADDING GRADIENT NOISE IMPROVES LEARNING FOR VERY DEEP NETWORKS\u201d from\u2026",
        "text": "So the main contribution of that paper is rather using normal gradient descent, we are going to add a Gaussian Noise to every gradient with \n\nMean Value of 0 and certain Standard Deviation Value. How and where do we calculate this STD? It is shown below.\n\nSo the \u03b7 value is selected from 3 set of numbers, \u03b3 = 0.55 and finally variable t stands for each training time step."
    },
    {
        "url": "https://becominghuman.ai/only-numpy-deriving-partial-forward-feed-lstm-on-show-attend-and-tell-neural-image-caption-4e44aa2b966d?source=user_profile---------73----------------",
        "title": "Only Numpy: Deriving partial Forward Feed (LSTM) on Show, Attend and Tell: Neural Image Caption\u2026",
        "text": "I have numbered each steps to be performed in the 2 Time Stamp LSTM network.\n\nOperation 1 \u2192 Image is given to the CNN and feature vector a are produced\n\nOperation 2 \u2192 Calculate the positive weight when time is 1 [Bahdanau]\n\nOperation 3 \u2192 Calculate the context vector Z(1) [Soft Attention]\n\nOperation 4 \u2192 Calculate the E(0) using the Embedding Matrix\n\nOperation 5 \u2192 Perform the Standard Forward Feed operation on LSTM\n\nOperation 6 \u2192 Calculate the positive weight when time is 2 [Bahdanau]\n\nOperation 7 \u2192 Calculate the context vector Z(2) [Soft Attention]\n\nOperation 8 \u2192 Calculate the E(1) using the Embedding Matrix\n\nOperation 9 \u2192 Perform the Standard Forward Feed operation on LSTM\n\nNow the two question that I have to answer is what is positive weight and context vector. How can we calculate them?"
    },
    {
        "url": "https://medium.com/swlh/only-numpy-why-we-need-activation-function-non-linearity-in-deep-neural-network-with-529e928820bc?source=user_profile---------74----------------",
        "title": "Only Numpy: Why we need Activation Function (Non-Linearity), in Deep Neural Network \u2014 With\u2026",
        "text": "So for today, I don\u2019t want to do something to over complicated, rather a simpl proof with code. Lets get right into it, so why do we need activation function?\n\nThat\u2019s it we need activation function because of the above reason. If you want to see in detail why read the blog post."
    },
    {
        "url": "https://medium.com/swlh/only-numpy-deriving-forward-feed-and-back-propagation-in-gated-recurrent-neural-networks-gru-8b6810f91bad?source=user_profile---------75----------------",
        "title": "Only Numpy: Deriving Forward feed and Back Propagation in Gated Recurrent Neural Networks (GRU) \u2014\u2026",
        "text": "Now the left screen is all of the equation that you need, and I the blue boxed symbol is called \u2018Candidate Activation\u2019. (Will denote them as CA for short) Also for now ignore the red boxed, however this becomes very important when performing back propagation.\n\nR(t) \u2192 Reset Gate at Time Stamp t\n\nCA(t) \u2192 Candidate Activation Function at Time Stamp t\n\nZ(t) \u2192 Update Gate at Time Stamp t\n\nS(t) \u2192 State at Time Stamp t\n\nAs usual, I will use the L2 cost function, which is the very bottom equation shown in the left of the screen."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/only-numpy-deriving-forward-feed-and-back-propagation-in-long-short-term-memory-lstm-part-1-4ee82c14a652?source=user_profile---------76----------------",
        "title": "Only Numpy: Deriving Forward feed and Back Propagation in Long Short Term Memory (LSTM) part 1",
        "text": "So I am back from my Winter Break trip to Korea. (South). I actually wanted to do this before I went on my vacation, but here it goes anyways. Also, I am going to divide this tutorial into two parts, since the back propagation gets quite long. And I am going to use mathmatical symbols from\n\nToday we are going to perform forward feed operation and back propagation for LSTM \u2014 Long Short Term Memory \u2014 network, so lets see the network architecture first."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/my-story-on-finishing-aws-educate-cloud-career-pathway-amazon-web-service-educate-4233c9a08c0a?source=user_profile---------77----------------",
        "title": "My Story on Finishing AWS Educate Cloud Career pathway \u2014 Amazon Web Service Educate",
        "text": "So today, I received an email regarding my completion of AWS Educate Career Pathway.\n\nAnd of course I blurred my Code and how much I have received LOL. But this post is not about my email, rather my story of AWS Educate and which career pathway I took.\n\nFirst, I choose the Database Administrator Career Path way, because I knew little bit of SQL statements and the position sounds cool, \u201cDatabase Administrator\u201d ;). Now I won\u2019t give you guys every little details on what kind of questions there are on the exams, but I think I can share what kind of modules there are.\n\nAs seen above, there are in total of 7 modules (including the final assessment and final project). All of the modules are include tutorials on VERY practical knowledge as well as quiz to test your knowledge skills on that topic.\n\nFor example, in the Databases section, you learn the basics for pretty much every existing database systems out there. For me, I loved the SQL section, because I already knew little bit about SQL.\n\nThe most interesting part of AWS Educate is the final project section, where you are given one project to work on. For me, I choose to document everything in a word doc format and submit.\n\nAnd I believe I used the PostGreSQL GUI to implement whole project.\n\nWell that\u2019s about it! Overall it was very fun experience, where I had a chance to review the materials that I learn in my third year undergraduate Database class (A year ago!)."
    },
    {
        "url": "https://medium.com/swlh/only-numpy-deriving-forward-feed-and-back-propagation-in-synthetic-gradient-decoupled-neural-ca4c99666bbf?source=user_profile---------78----------------",
        "title": "Only Numpy: Deriving Forward feed and Back Propagation in Synthetic Gradient (Decoupled Neural\u2026",
        "text": "Above is iamtrask\u2019s implementation of synthetic gradient (again link here) as seen there is two part for each layer. And we will look at each operation separately. I\u2019ll describe what they are doing and start with layer 1.\n\nForward and Synthetic Update: Performs regular forward feed operation, and update current weight using the sythentic gradient\n\nUpdate Synthetic Weights: Using the true gradient update the synthetic gradient\n\nSo, there are many things going on here. Firstly, the blue numbers in the square box, describes the dimensionality of the resulted equation. Second\u2026.\n\nBasically in the C1 Step we are performing regular forward feed operation to get the output of each layer. For example Layer1 = log(dot_product(x,w1)), and right after the forward feed operation, we update the weight W1 by using the W1SG (the synthetic gradient).\n\nTwo very interesting to note from above image are first, the amazing fact how similar the process is when compared to regular gradient update. Second, the Return Statement written at the bottom. Don\u2019t worry I will explain both.\n\nSo below is somewhat traditional method of performing gradient update.\n\nThere are three main components to get the derivative of cost function respect to certain weight, first using the chain rule, we need to get the derivative of the cost respect to output of a certain layer, derivative of output of certain layer respect to input of the same layer, and derivative of input of same layer respect to the weight. Now compare it with our forward feed process, it looks some what very similar! (This was obvious but I still though it was kinda cool)\n\nNow the second part, the Return statement, if you read the original tutorial by iamtrask you will get this part. Basically, we declared each layer as a class and we want to use the output of next layer to update the weights for our current layer so we return some numbers. ( I won\u2019t go into the math here, but if you see that L1WSG * W1_Transpose, this actually makes so much sense, very similar to traditional gradient update.)\n\nNow lets see the operations for the rest of the layers!\n\nAgain, just to recap\u2026\n\nThat\u2019s it for forward feed operation and back propagation, however THAT\u2019S NOT ALL! We now will observe the true power of Decoupled Neural Interfaces why is it so useful and where that power comes from."
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-with-activation-deriving-back-propagation-through-time-4110964a9316?source=user_profile---------79----------------",
        "title": "Only Numpy: Vanilla Recurrent Neural Network with Activation Deriving Back propagation Through Time\u2026",
        "text": "So today we are going to do the same thing but add one additional component which is activation function. For now lets keep it simple and use logistic function. (Note we will use the notation log(), and when implemented in python it could look like something below.)\n\nAnyways here is the starting point, the training data (x) and ground truth data (y) and what we wish to do, count how many ones are there in a given line of data.\n\nBut here is the difference, the relationship between current state and the next state is defined below.\n\n(E) is the equation defining the relationship between current state K and previous state k-1. Now let\u2019s perform forward feed process, that is defined at (F). But wait, State 3 does not have a log() function? WHY?\n\nLogistic Function outputs a number between 0 and 1, this means if we have more than one 1, the neural network cannot predict the correct number of ones!"
    },
    {
        "url": "https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-back-propagation-practice-math-956fbea32704?source=user_profile---------80----------------",
        "title": "Only Numpy: Vanilla Recurrent Neural Network Deriving Back propagation Through Time Practice \u2014 part\u2026",
        "text": "As seen above at (a) the training data is X and the test data is Y (Ground truth). (b) We are only going to have two weights, Wx (Where we are going to multiple with the input x) and Wrec (Where we are going to multiple with the previous states)\n\nIt is very important to understand ( c ) since it is our network architecture that is the unrolled version of our network architecture. However it clearly show that State 0 (Denoted as S0) have some relationship with State 1(Denoted as S1). THAT RELATIONSHIP IS SHOWN BELOW!\n\nUnder (E) we can see one equation, that clears up the relation between State.\n\nThat one line of math is the relationship between State 0 and State 1. But what about the numbers below each state? Very simple, those are inputs at each state, so at state 1 the input x is a vector [0,0,1].T.\n\nThey you might ask, what about State 0? Great question they are all ZEROS!"
    }
]