[
    {
        "url": "https://medium.com/@ATavgen/time-series-modelling-a9bf4f467687?source=user_profile---------1----------------",
        "title": "Time series modelling \u2013 AlexTavgen \u2013",
        "text": "This is short article about understanding time series and main characteristics behind that.\n\nWe have time-series data with daily and weekly regularity. We want to \ufb01nd the way how to model this data in an optimal way.\n\nOne of the important characteristics of time series is stationarity.\n\nIn mathematics and statistics, a stationary process (a.k.a. a strict(ly) stationary process or strong(ly) stationary process) is a stochastic process whose joint probability distribution does not change when shifted in time.\n\nConsequently, parameters such as mean and variance, if they are present, also do not change over time. Since stationarity is an assumption underlying many statistical procedures used in time series analysis, non-stationary data is often transformed to become stationary.\n\nThe most common cause of violation of stationarity are trends in mean, which can be due either to the presence of a unit root or of a deterministic trend. In the former case of a unit root, stochastic shocks have permanent effects and the process is not mean-reverting. In the latter case of a deterministic trend, the process is called a trend stationary process, and stochastic shocks have only transitory effects which are mean-reverting (i.e., the mean returns to its long-term average, which changes deterministic over time according to the trend).\n\nWhite noise is a stochastic stationary process which can be described using two parameters: mean and dispersion(variance). In discrete time, white noise is a discrete signal whose samples are regarded as a sequence of serially uncorrelated random variables with zero mean and finite variance.\n\nIf we make projection onto axis y we can see normal distribution. White noise is a gaussian process in time.\n\nIt means that we can model stationary stochastic process using just two parameters which means significant reducing of dimensions of the data.\n\nIn probability theory, the normal (or Gaussian) distribution is a very common continuous probability distribution. Normal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known. The normal distribution is useful because of the central limit theorem. In its most general form, under some conditions (which include finite variance), it states that averages of samples of observations of random variables independently drawn from independent distributions converge in distribution to the normal, that is, become normally distributed when the number of observations is sufficiently large. Physical quantities that are expected to be the sum of many independent processes (such as measurement errors) often have distributions that are nearly normal. Moreover, many results and methods (such as propagation of uncertainty and least squares parameter fitting) can be derived analytically in explicit form when the relevant variables are normally distributed.\n\nAssume that our data has some trend. Spikes around it is due to a lot of random factors, that affects our data. For example amount of served requests is described using this approach very well. Garbage collection, cache misses, paging by OS, a lot of things affects particular time of served response. Lets take half an hour slice from our data, from 2017\u201308\u201327 12:00 till 12:30. We can see that this data has a trend, and some oscillations"
    },
    {
        "url": "https://medium.com/@ATavgen/cryptoassets-and-investments-deep-learning-approach-97f3d649afc1?source=user_profile---------2----------------",
        "title": "Cryptoassets and Investments: Deep Learning Approach",
        "text": "This is the second part of the article about investment strategies applied to the market of crypto assets.\n\nWith the breakthrough of Deep Neural Networks and Reinforcement Learning we can deeply explore many entrenched problems at the financial markets which haven\u2019t been reachable till now.\n\nThe investors\u2019 interest in topic is growing rapidly and here are some intriguing opinions about using Deep Learning on financial markets:\n\nThere are existing a lot of Deep Learning approaches to the financial market trading. However many of them try to predict price movements or trends (Heaton et al., 2016; Niaki and Hoseinzade, 2013; Freitas et al., 2009). With history prices of all assets as its input, a neural network can output a predicted vector of asset prices for the next period.The performance of these price-prediction-based algorithms however highly depend on the degree of prediction accuracy, but it turns out that future market prices are too difficult to predict. High predictability is either false or not scalable and talking about markets with high volatility we can say that using Deep Learning for predicting market prices is not a good idea at all. Furthermore, price predictions are not market actions \u2014 converting them into actions which will maximize the profits requires additional layer of logic and that is where Reinforcement Learning can help us out.\n\n\u201cNobody has a crystal ball for seeing the future.\u201d\n\nAccording to KDnuggets \u201cReinforcement Learning is concerned with the problem of finding suitable actions to take in a given situation in order to maximize a reward.\u201d\n\nIn other words, we cannot predict future market prices but we can teach an agent to take the actions which maximize reward.\n\nDeep Reinforcement Learning is lately drawing much attention due to its remarkable achievements in playing video games and board games. DeepMind built an AI which could play Atari games from the 70s or beat a human being in Go. Even games with incomplete or imperfect information such as Poker or DOTA2 are feasible for such kind of algorithms.\n\nSo it looks like financial markets are good candidates for Reinforcement Learning approach. Some attempts were made for traditional financial institutions such as Agent Inspired Trading, Reinforcement Learning for Trading, Reinforcement Learning For Automated Trading.\n\nJPMorgan announced they will soon be using a first-of-its-kind robot to execute trades with its global equities after European trial of the bank\u2019s new artificial intelligence (AI) program showed it was much more efficient than traditional methods of buying and selling.\n\nLet\u2019s take closer look to the idea of the Reinforcement Learning and how it can help the investors to maximize their profits.\n\nYou can think of the agent as a human trader who opens the GUI of an exchange and makes trading decision based on the current state of the exchange and his or her account.\n\nWe can see exchange as an environment for our agent. Important thing to note is that there are many other agents, both human and algorithmic market players, trading on the same exchange.\n\nWe can see State as an aggregation of all exchange events within time range, let\u2019s say 30 minutes.\n\nWhen we observe a new state it will be the response of the market environment, which includes the response of the other agents. Thus, from the perspective of our agent, these agents are also part of the environment. They\u2019re not something we can control. However, by putting other agents together into some big complex environment we lose the ability to explicitly model them.\n\nReinforcement Learning problem can be formulated as a Markov Decision Process (MDP). We have an agent acting in an environment. Each time step t the agent receives as the input the current state s, takes an action a , and receives a reward r+1 and the next state s(t+1). The agent chooses the action based on some policy. It is our goal to find a policy that maximizes the cumulative reward over some finite or infinite time horizon.\n\nIt is easy to teach our Agent to make decisions at the one stock market but this is not a good idea. \u201cDon\u2019t put all your eggs in one basket\u201d.\n\nThus the Agent is the software program/portfolio manager performing trading Actions in the Environment and it is impossible for the Agent to get total information of the state of such a large and complex environment as crypto assets market. Nonetheless all relevant information is believed in the philosophy of technical traders to be reflected in the prices of the assets which are publicly available to the Agent. According to this point of view, an environmental state can be roughly represented by the prices of all orders throughout the market\u2019s history up to the moment where the State is at.\n\nHistoric price data which looks like a tensor (some sort of matrix) is fed into Neural Network to generate the output of the portfolio vector . Every tensor is time series market data.\n\nRecalculating market State every step of the time we can see these steps as a time-series data, and RNN-LSTM Neural Networks topologies can be used.\n\nHowever this could be a good solution, another possibility can be used as well.\n\nIf we have our market state data as tensors then we can use Convolution Networks same way as we use them for image recognition.\n\nInstead of image we have a matrix of market prices.\n\nLaunchpad used some derived market values (Moving Averages, Volatility Levels and Changes and so on) for their approach.\n\nLet\u2019s call that structure(Neural Network Model) Evaluator which evaluates market state and gives some output, portfolio weights. It is called policy \u2014 map of actions or portfolio weights. Ultimate goal of Reinforcement Learning is to learn a policy which helps to take the wisest action in any given state.\n\nJPMorgan announced of usage Q-Learning in their approach, same was used by DeepMind for the models playing Atari games.\n\nBut policy networks take easier approach \u2014 just input the state and out comes an action. Then you simply find out which actions worked well and increase their probability. This may sound exceedingly stupid but this approach cracked AlphaGo!\n\nWe used Reinforcement Learning framework specially designed for the task to manage portfolios proposed by Z. Jiang, D. Xu, J. Liang, A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem16 Jul 2017.\n\nWe used Convolution Neural Network Evaluator, which showed better results comparing with simple RNN, or LSTM models.\n\nSame dataset from Poloniex exchange were taken as in the first part of the article.\n\nAgent was trained on the historical prices of the 11 most-volumed non-cash assets which were preselected for the portfolio.\n\nAnd we still impose two hypotheses which were described in the first part of the article:\n\nOne reason for selecting top-volumed cryptocurrencies (simply called coins below) is that bigger volume implies better market liquidity of an asset. In turn it means the market condition is closer to Hypothesis 1. Higher volumes also suggest that the investment can have less influence on the market, establishing an environment closer to the Hypothesis 2.\n\nWe do not take in account transaction costs for the sake of simplicity, but we add them later as well. Time-step is set to 30 minutes, so every 30 minutes we make a new evaluation.\n\nWe can see portfolio weights as crypto assets ranking on specific exchange. Different metrics are used to measure the performance of a particular portfolio selection strategy. The most direct measurement of how successful is a portfolio management over a timespan is the accumulative portfolio value (APV). APVs here are measured in the unit of their initial values, or equivalently p0 = 1 and thus pt = pt/p0\n\nAll data is gathered with 30 min granularity as a pairs to BTC (ETH/BTC, LTC/BTC, USDT/BTC) . All rebalancing decisions are made every 30 minutes and transactions costs are set to zero which is considered as ideal conditions. But if we can prove by math, some portfolio outperforms market in ideal conditions then it is possible to find optimal rebalancing periods until transactions fee are lower than cumulative returns. Cumulative return means return from one BTC invested in ideal conditions.\n\nBack test is started from 2017\u201310\u201319 20:00:00 to 2018\u201301\u201301 00:00:00\n\nCRP \u2014 Constant rebalanced portfolio = use fixed weights all the time. Uniform weights are commonly used as a benchmark.\n\nOLMAR \u2014 On-Line Portfolio Selection with Moving Average Reversion Shortly this approach finds best momentum (MAR) strategies among all possibilities by applying powerful online learning techniques. 2012 academic publication https://icml.cc/2012/papers/168.pdf.\n\nWe can see that nnagent significantly outperforms other strategies. But let\u2019s take a closer look.\n\nWe can see that NNAGENT has an overall better drawdown profile. Same results were achieved in different RL experiments which show that RL agent acts better on drawdowns.\n\nSame is with the Sharpe Ratio which is higher than with other strategies.\n\nWe can see that even CRP used for benchmark has more positive periods and less negative than NNAGENT, the actions of NNAGENT have more effective impact on overall performance as well.\n\nWe continue experiments using different hyperparameters of Neural Networks and different stock exchanges.\n\nReinforcement Learning can be applied to algorithmic trading producing a strategy that is both unique and outperforms common baseline techniques.\n\nIn the nearest future we want to introduce a new service based on our researches which will help investors make right decisions on different crypto exchanges."
    },
    {
        "url": "https://medium.com/@ATavgen/cryptoassets-and-investments-online-portfolio-selection-ad01e4b67f40?source=user_profile---------3----------------",
        "title": "Cryptoassets and Investments: Online Portfolio Selection",
        "text": "Portfolio selection, aiming to optimize the allocation of wealth across a set of assets, is a fundamental research problem in computational finance and a practical engineering task in financial engineering.\n\nThere are two major schools for investigating this problem, that is, the\n\nMean Variance Theory [Markowitz 1952; Markowitz 1959; Markowitz et al. 2000] mainly from the finance community\n\nThe Mean Variance Theory, widely known in asset management industry, focuses on a single-period (batch) portfolio selection to trade off a portfolio\u2019s expected return (mean) and risk (variance), which typically determines the optimal portfolios subject to the investor\u2019s risk-return profile.\n\nOn the other hand, Capital Growth Theory focuses on multiple-period or sequential portfolio selection, aiming to maximize the portfolio\u2019s expected growth rate, or expected log return. While both theories solve the task of portfolio selection, the latter is fitted to the \u201conline\u201d scenario, which naturally consists of multiple periods.\n\nBut let\u2019s take a closer look at it.\n\nBuilding and running a Markowitz portfolio optimization model is an essential part of the portfolio construction process for most traditional assets managers (i.e. other central banks, pension funds, sovereign wealth funds, etc.) also.\n\nIt is impossible for the human being to choose best return vs lower risk from 50 000 different crypto assets at the market, while using a program based on that algorithms it can be feasible for everyone.\n\nBut as I said Markowitz theory is suitable for a single period portfolio selection. Investor chooses once and surveys how the portfolio acts.\n\nOnline portfolio selection is a fundamental problem in computational finance, which has been extensively studied across several research communities, including finance, statistics, artificial intelligence, machine learning, and data mining, etc.\n\nActually this problem is quite related to game theory and optimisational problems. Game theory is the study of human conflict and cooperation within a competitive situation. In some respects, game theory is the science of strategy, or at least the optimal decision-making of independent and competing actors in a strategic setting. The key pioneers of game theory were mathematicians John von Neumann and John Nash, as well as economist Oskar Morgenstern.\n\nAt financial markets, or cryptomarkets and assets, investor must make decisions under condition of uncertanty.\n\nMove by Nature is an interesting concept which means a decision or move in an extensive form game made by a player who has no strategic interests in the outcome. The effect is to add a player, \u2018Nature\u2019, whose practical role is to act as a random number generator. For instance, if a game of Poker requires a dealer to choose which cards a player is dealt, the dealer plays the role of the Nature player.\n\nWe may argue, every investor on the financial market has his own strategic interests. But at financial markets we assume a lot of different actors, everybody with their own agenda and strategy form some kind of stochastic process with constantly changing parameters.\n\nBecause of those processes we can say nobody can predict market. Actually there is an interesting bias related to our psychology.\n\nNow, look at the pattern in the charts in Figure A, which shows the stock prices of three major manufacturers over a 10-month interval ending in October 2005. Consider the charts and decide on an answer before reading the next paragraph: based on the given pattern, which one of the three stocks do you expect to increase in value over the subsequent year?\n\nDid you pick the third chart? It looks as if it is headed up at the end. Well, you\u2019re wrong. In fact, if you picked the first or second chart, you\u2019re also, equally, wrong. Not one of the stocks is upward bound, and none is trending down. Actually, the charts don\u2019t even represent stock prices. They were randomly generated: data gibberish, one might say. But the implanted belief that they belong to a specific company (in this case, in the manufacturing sector) can generate all kinds of speculation. Even with real charts, unless you had specific knowledge about a company or industry, it would be difficult to predict the future direction of a stock based on 10 months of past performance.\n\nThe tendency to create a story out of noise is sometimes dubbed the narrative fallacy. Even if you were suspicious of the question \u2014 or read ahead too quickly \u2014 when we asked top MBA students \u2014 some of them applying for jobs in finance \u2014 the same question, they expressed a good deal of certainty about the direction in which such \u201cstocks\u201d were headed. Some said up, some said down. When the charts were supplemented with \u201cnews clips\u201d randomly generated and placed in random order along the length of the chart, students claimed a still greater certainty about their predictions \u2014 showing, perhaps, the power of telling oneself a good story about data (Krumme [to appear]). (Consider, also, the loose causal quips thrown around by financial journalists: \u201cthe Dow dropped 100 points on fear of rising unemployment.\u201d)\n\nIf human beings are adept at spotting patterns, we\u2019re masters at making up stories about statistics. This is less problematic when we know where data comes from and what it means; it can be disastrous when we\u2019re faced with a lot of evidence from different sources and high-stakes outcomes. Beautiful Data\n\nSo how can we make right decisions under uncertainty conditions with our narrative fallacy and confirmation bias?\n\nTwo natures of cryptocurrencies differentiate them from traditional financial assets, making their market the best test-ground for algorithmic portfolio management experiments. These natures are decentralization and openness and the former implies the latter. Without a central regulating party, anyone can participate in cryptocurrency trading with low entrance requirements. One direct consequence is abundance of small-volume currencies. Affecting the prices of these penny-markets will require smaller amount of investment, compared to traditional markets. This will eventually allow trading machines to learn and take advantage of the impacts by their own market actions. Openness also means the markets are more accessible. Most cryptocurrency exchanges have application programming interface for obtaining market data and carrying out trading actions, and most exchanges are open 24/7 without restricting frequency of tradings. These non-stop markets are ideal for machines to learn in the real world in shorter time-frames.\n\nWe can compare how different approaches act on different markets conditions.\n\nThe following two hypothesis are imposed:\n\nIn the real-world trading environment, if the trading volume at the market is high enough, these two assumptions are near to reality.\n\nOne reason for selecting top-volumed cryptocurrencies (simply called coins below) is that bigger volume implies better market liquidity of an asset. In turn it means the market condition is closer to Hypothesis 1. Higher volumes also suggest that the investment can have less influence on the market, establishing an environment closer to the Hypothesis 2.\n\nIn the experiments, the 11 most-volumed non-cash assets are preselected for the portfolio.\n\nAnd BTC serves as a cash, or all top volumed currencies are computed as a BTC pairs.\n\nNB! All data is gathered with 30 min granularity as a pairs to BTC (ETH/BTC, LTC/BTC, USDT/BTC) . All rebalancing decicions are made every 30 minutes and transactions costs are set to zero which is considered as ideal conditions. But if we can prove by math, some portfolio outperforms market in ideal conditions, then it is possible to find optimal rebalancing periods until transactions fee are lower than cummulative returns. Cummulative return means return from one BTC invested in ideal conditions.\n\nLet\u2019s first analyse period from 01.05.2017 to 01.07.2017\n\nIf we take as a comparison BTC/USD movements we can see growth from avg 1400 USD to 2533 USD, we can see some decreasing waves, but still we had bullish market within this time range.\n\nLet\u2019s see if we try to optimise portfolios fully in crypto using BTC as a cash (asset with a high liquidity) and USDT cryptoasset as related to the USD.\n\nWe use in our simulation different algorithmic approaches listed above.\n\nOn the graph we can see CRP(blue) and M0(dark blue) are moving with the market which sounds logical because we do not rebalance portfolios but recalculate cummulative profit with each step.\n\nWe can notice rebalancing every 30 minutes to the BEST acts like a magnifier of the overall market, which is logical behaviour because crypto assets are very correlated with each other.\n\nWe can see that PAMR performance was not good at all.\n\nBut OLMAR and ANTICOR showed the best results, outperformed market 4\u20135 times.\n\nBut these were results from the time-range of bull\u2019s market with a low volatility.\n\nLet\u2019s take a more interesting period from 01.12.2017 to 31.12.2017\n\nIt was mostly bullish market against fiat currency, with some drops as well.\n\nCould we have good performance of portfolios staying fully on cryptomarkets.\n\nWe can see again that CRP and M0 are following the rhytm of the market(top 11 against BTC) as ANTICOR. PAMR is not performing well again. OLMAR performs well, but within some range BEST outperforms it which is also logical when on rapidly growing market you can always find asset which moves faster and constantly doing that you will always get best performance as well.\n\nLet\u2019s take period from 01.01.2018\u201308.02.2018, where we can see this picture\n\nIt was a bear market for crypto vs. fiat. But for cryptomarkets mostly it was a turbulence period. Yellow is LTC/BTC.\n\nAnd our portfolios are:\n\nOLMAR which showed good performance on the bullish market earlier, is much worse than a constant portfolio CRP, M0 (again this is not related to USD, but correlation with BTC) and WMAMR as well. Benchmark portfolios (CRP, M0) and ANTICOR showed very close results but BEST strategy has the best performance again.\n\nThis results show very clearly that \u201cno free lunch theorem (https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization)\" applies here as well. There is no \u201cshort-cut\u201d method which is applicable for the all use cases. But bringing in our domain knowledge we can choose best methods for every market condition of course with some uncertainty as well.\n\nOLMAR is good for the stable periods of the markets. Does BEST works always better in times of high market turbulence? We will see later.\n\nIn the next article we will talk about application of the Deep Learning technics related to the problems of portfolio optimisation for achieving best financial results."
    },
    {
        "url": "https://medium.com/@ATavgen/how-we-made-music-using-neural-networks-449a62b8a332?source=user_profile---------4----------------",
        "title": "How we made music using Neural Networks \u2013 AlexTavgen \u2013",
        "text": "Essentially, Magenta is a MIDI interface for working with TensorFlow, which is a widely used open-source framework for machine intelligence. Magenta creates virtual MIDI ports for call-response (or input-output) interactions. It is possible to create many parallel virtual MIDI port pairs. Each such pair can be connected to a TensorFlow model, which is a Recurrent Neural Network that has been trained on a set of MIDI files.\n\nIt was while I was thinking about how to implement our project and performing some tests using the Python MIDI library that I stumbled upon the Magenta project, which was launched in 2016 by the Google Brain team. Its aim was to find out whether machine learning could be used to create compelling art (images, music, texts, etc.). Today it functions both as a research project and as a community for like-minded researchers, developers, and artists. The models and tools used by the team are regularly released to the public in open source form together with demos, tutorials, and technical papers.\n\nMusic is also structured along various dimensions such as rhythm, intervals, dynamics, etc. It could be said that music constitutes well-structured time series data, which we can use as input for our RNNs. The MIDI format is highly suitable for this, because a MIDI signal is essentially a numeric set of code arranged in time.\n\nOn the other hand, there is the syntactic dimension, which is quite manageable for machines. The \u201cmagic\u201d behind Recurrent Neural Networks (RNN) is related to the fact that an RNN can hold states and also take into account previous states. Roughly speaking, we can feed a model many different strings of text and then ask it to predict the next character in a string depending on what the previous characters were. For example, there is a very high probability that the string \u2018I lov\u2019 is followed by an \u2018e\u2019, but the next character in the string \u2018I love \u2018 is not as obvious. It could be \u2018y\u2019 (\u2018you\u2019), \u2018h\u2019 (\u2018him/her\u2019), \u2019t\u2019 (\u2018them\u2019), and so on.\n\nGenerally speaking, Recurrent Neural Networks produce good results when handling time series data with an underlying structure. Take natural languages, for example. The structure of a natural language has a number of dimensions. On the one hand, there\u2019s the semantic dimension, which is quite difficult for machines to grasp. A famous example here is the Chinese room argument , which demonstrates that a program cannot give a computer a \u201cmind\u201d. However, this argument is less persuasive when it comes to multimodal learning , which is a large topic in and of itself.\n\nThe Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy (deep learning expert and Tesla\u2019s Director of Artificial Intelligence) serves as an excellent introduction to the technology behind this project.\n\nWe had less than two months for implementing this project, which was not much considering that we live in different cities and could only perform our experiments at weekends, but we received a lot of invaluable support from Playtech in our research.\n\nLast year, I proposed a collaboration to a friend of mine, Aleksandr Zedeljov ( http://faershtein.com/ ), who is a composer, musician, and musical director at the Russian Theatre of Estonia. We decided to implement it with the musical project MODULSHTEIN (Aleksandr Zedeljov, Aleksej Seminihhin, Marten Altrov) and to present the results of our work during a live performance at the badge pick-up party at Topconf 2017 in Tallinn.\n\nMy name is Aleksandr Tavgen and I work as a Software Architect in Playtech. I have always loved playing. When I was younger, I mostly played with LEGOs, but these days, my toys are slightly more complex. For example, recently I have been playing around with Recurrent Neural Network models.\n\nThe interaction process looks as follows.\n\nDue to the fact that RNNs do not work well with multidimensional data, MIDI signals should first be mapped onto an artificial alphabet, where every musical element corresponds to a unique character or hash code. During the interaction process, a MIDI signal goes through the Magenta MIDI interface and is converted into the NoteSequence format, which is a protocol buffers format for exchanging data with a TensorFlow model. A TensorFlow model is a RNN that receives an input sequence and produces a response using this sequence as a seed.\n\nAt first, I intended to train TensorFlow models from scratch, but I ran into some problems. To begin with, it was difficult to obtain large sets of data from specific styles of music. It is possible to download some training data (for example, from http://colinraffel.com/projects/lmd/), but it makes little sense to train your own models on the same data set that the Magenta team uses. So I decided to take one of Magenta\u2019s pre-trained models (a LSTM RNN with two hidden layers of 128 elements) and continue its training process. I downloaded a lot of music with break beats in the MIDI format, ranging from Prodigy\u2019s Out of Space and Goldie\u2019s Inner City Life to Moby and Massive Attack. Magenta\u2019s GitHub contains conversion tools that can help you prepare your own training set from a collection of MIDI files.\n\nThe second problem arose when I was trying to start the training process on the AWS Cloud. I started the process on a p2.8xlarge instance, but kept having non-obvious hang-ups that were related to native calls. Unfortunately, I had no time for investigating that problem.\n\nOnly the last two bars were taken into account during every training instance, so we only spent a few nights training the models at different settings. The gradient descent was not especially fast and I cannot say whether the trend was towards continued descent or whether it all amounted to oscillation around local minima, but it was acceptable for my purposes.\n\nThe last checkpoint from the training process was converted into a bundle file using Magenta\u2019s tools. Our configuration consisted of two pairs of virtual MIDI ports with a separate model for each. The first model was to listen to the rhythm provided by one of the live musicians and then provide a rhythm in response. The second model was to listen to its output and generate its own response, and so on. It is also possible to build a set-up, where two or more models are listening to each other and creating music together. We did perform one such test as well, letting our models play with each other while we took a lunch break. The result was vaguely trance-like and tinged with Afro-beats, bizarre but not unpleasant.\n\nThe next step was to figure out how to bind the models together with live musicians during an improvisation session. Aleksandr Zedeljov proposed that we use Ableton Live as a universal glue. It is a musical sequencer and digital audio workstation that was designed to be used for live performances as well as for music production. The MaxSP plugin has previously been used to bind Ableton Live with Magenta, but this solution did not work for us, because MaxSP always crashed and took Ableton with it. So we ended up discarding MaxSP and binding them straight together. Later, we also had some problems with synching Ableton and Magenta via midi_clock.\n\nOur first attempts at improvisation looked like this:\n\nAleksandr Zedeljov played a rhythm example on the drum pad (Ableton Push 2), the model received the MIDI signals through Magenta, and then produced a response.\n\nWe went through many \u201ctry, test, modify, repeat\u201d cycles. It was quite entertaining, especially when the results were unusual. The main complexity arose from the fact that the models gave different responses every time, so every test amounted to pure improvisation. During the process, we noticed that longer input from live musicians seemed to result in more sensible responses from the models. It felt like the models gained courage as they kept working. I decided to check whether it was merely our belief, or whether there were actual differences in the performance of the RNNs. In the beginning, the models produced responses with log-likelihood -70, but after a certain amount of time, the log-likelihood value fell to -150, -400, and even -700, which was distinguishable by ear. It seems to be somehow related to the internal state of the RNN, which seems to converge to values that start to generate increasingly better responses within a certain amount of time.\n\nWe decided to film our first real improvisation session with live musicians in Playtech\u2019s Tallinn office. It was pretty cool, because the office was empty that late in the evening and we were up on the 10th floor, with a view of planes landing at the airport.\n\nMagenta\u2019s browser interface enabled us to monitor what was going on within the models in real time, making it possible for us to change the parameters of the models on the fly (see the orange \u201cbricks\u201d running on the screen).\n\nWe achieved much better results during our Topconf performance due to the additional time we had for tuning the whole system. However, due to the lack of time and data for training melodic models, only the rhythm section was provided by two RNNs.\n\nMIDI signals can also be used for controlling digital video workstations, so it would be interesting to also use models that produce video responses in order to supplement the music with an improvised video stream. There are a lot of possible approaches to chaining various models and combining them with music and video devices, experimenting with various harmonic models, implementing call-response loops during any intermediate step, and so on.\n\nGreat thanks to the team: Aleksandr Zedeljov, Martin Altrov, Aleksei Semenihhin, Nikolay Alhazov, and Playtech and personally Marianne V\u00f5ime, Ergo J\u00f5epere."
    }
]