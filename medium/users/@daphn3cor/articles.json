[
    {
        "url": "https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050?source=user_profile---------1----------------",
        "title": "An intuitive guide to Convolutional Neural Networks",
        "text": "In this article, we will explore Convolutional Neural Networks (CNNs) and, on a high level, go through how they are inspired by the structure of the brain. If you want to read more about the brain specifically, there are more resources at the end of the article to help you further.\n\nWe are constantly analysing the world around us. Without conscious effort, we make predictions about everything we see, and act upon them. When we see something, we label every object based on what we have learned in the past. To illustrate this, look at this picture for a moment.\n\nYou probably thought something like \u201cthat\u2019s a happy little boy standing on a chair\u201d. Or maybe you thought he looks like he is screaming, about to attack this cake in front of him.\n\nThis is what we subconciously do all day. We see, label, make predictions, and recognize patterns. But how do we do that? How is it that we can interpret everything what we see?\n\nIt took nature over 500 million years to create a system to do this. The collaboration between the eyes and the brain, called the primary visual pathway, is the reason we can make sense of the world around us.\n\nWhile vision starts in the eyes, the actual interpretation of what we see happens in the brain, in the primary visual cortex.\n\nWhen you see an object, the light receptors in your eyes send signals via the optic nerve to the primary visual cortex, where the input is being processed. The primary visual cortex makes sense of what the eye sees.\n\nAll of this seems very natural to us. We barely even think about how special it is that we are able to recognise all the objects and people we see in our lives. The deeply complex hierarchical structure of neurons and connections in the brain play a major role in this process of remembering and labelling objects.\n\nThink about how we learned what, for example, an umbrella is. Or a duck, lamp, candle, or book. In the beginning, our parents or family told us the name of the objects in our direct environment. We learned by examples that were given to us. Slowly but surely we started to recognise certain things more and more often in our environment. They became so common that the next time we saw them, we would instantly know what the name of this object was. They became part of our model on the world.\n\nSimilar to how a child learns to recognise objects, we need to show an algorithm millions of pictures before it is be able to generalize the input and make predictions for images it has never seen before.\n\nComputers \u2018see\u2019 in a different way than we do. Their world consists of only numbers. Every image can be represented as 2-dimensional arrays of numbers, known as pixels.\n\nBut the fact that they perceive images in a different way, doesn\u2019t mean we can\u2019t train them to recognize patterns, like we do. We just have to think of what an image is in a different way.\n\nTo teach an algorithm how to recognise objects in images, we use a specific type of Artificial Neural Network: a Convolutional Neural Network (CNN). Their name stems from one of the most important operations in the network: convolution.\n\nConvolutional Neural Networks are inspired by the brain. Research in the 1950s and 1960s by D.H Hubel and T.N Wiesel on the brain of mammals suggested a new model for how mammals perceive the world visually. They showed that cat and monkey visual cortexes include neurons that exclusively respond to neurons in their direct environment.\n\nIn their paper, they described two basic types of visual neuron cells in the brain that each act in a different way: simple cells (S cells) and complex cells (C cells).\n\nThe simple cells activate, for example, when they identify basic shapes as lines in a fixed area and a specific angle. The complex cells have larger receptive fields and their output is not sensitive to the specific position in the field.\n\nThe complex cells continue to respond to a certain stimulus, even though its absolute position on the retina changes. Complex refers to more flexible, in this case.\n\nIn vision, a receptive field of a single sensory neuron is the specific region of the retina in which something will affect the firing of that neuron (that is, will active the neuron). Every sensory neuron cell has similar receptive fields, and their fields are overlying.\n\nFurther, the concept of hierarchy plays a significant role in the brain. Information is stored in sequences of patterns, in sequential order. The neocortex, which is the outermost layer of the brain, stores information hierarchically. It is stored in cortical columns, or uniformly organised groupings of neurons in the neocortex.\n\nIn 1980, a researcher called Fukushima proposed a hierarchical neural network model. He called it the neocognitron. This model was inspired by the concepts of the Simple and Complex cells. The neocognitron was able to recognise patterns by learning about the shapes of objects.\n\nLater, in 1998, Convolutional Neural Networks were introduced in a paper by Bengio, Le Cun, Bottou and Haffner. Their first Convolutional Neural Network was called LeNet-5 and was able to classify digits from hand-written numbers.\n\nFor the entire history on Convolutional Neural Nets, you can go here.\n\nIn the remainder of this article, I will take you through the architecture of a CNN and show you the Python implementation as well.\n\nConvolutional Neural Networks have a different architecture than regular Neural Networks. Regular Neural Networks transform an input by putting it through a series of hidden layers. Every layer is made up of a set of neurons, where each layer is fully connected to all neurons in the layer before. Finally, there is a last fully-connected layer \u2014 the output layer \u2014 that represent the predictions.\n\nConvolutional Neural Networks are a bit different. First of all, the layers are organised in 3 dimensions: width, height and depth. Further, the neurons in one layer do not connect to all the neurons in the next layer but only to a small region of it. Lastly, the final output will be reduced to a single vector of probability scores, organized along the depth dimension.\n\nIn this part, the network will perform a series of convolutions and pooling operations during which the features are detected. If you had a picture of a zebra, this is the part where the network would recognise its stripes, two ears, and four legs.\n\nHere, the fully connected layers will serve as a classifier on top of these extracted features. They will assign a probability for the object on the image being what the algorithm predicts it is.\n\nConvolution is one of the main building blocks of a CNN. The term convolution refers to the mathematical combination of two functions to produce a third function. It merges two sets of information.\n\nIn the case of a CNN, the convolution is performed on the input data with the use of a filter or kernel (these terms are used interchangeably) to then produce a feature map.\n\nWe execute a convolution by sliding the filter over the input. At every location, a matrix multiplication is performed and sums the result onto the feature map.\n\nIn the animation below, you can see the convolution operation. You can see the filter (the green square) is sliding over our input (the blue square) and the sum of the convolution goes into the feature map (the red square).\n\nThe area of our filter is also called the receptive field, named after the neuron cells! The size of this filter is 3x3.\n\nFor the sake of explaining, I have shown you the operation in 2D, but in reality convolutions are performed in 3D. Each image is namely represented as a 3D matrix with a dimension for width, height, and depth. Depth is a dimension because of the colours channels used in an image (RGB).\n\nWe perfom numerous convolutions on our input, where each operation uses a different filter. This results in different feature maps. In the end, we take all of these feature maps and put them together as the final output of the convolution layer.\n\nJust like any other Neural Network, we use an activation function to make our output non-linear. In the case of a Convolutional Neural Network, the output of the convolution will be passed through the activation function. This could be the ReLU activation function.\n\nStride is the size of the step the convolution filter moves each time. A stride size is usually 1, meaning the filter slides pixel by pixel. By increasing the stride size, your filter is sliding over the input with a larger interval and thus has less overlap between the cells.\n\nThe animation below shows stride size 1 in action.\n\nBecause the size of the feature map is always smaller than the input, we have to do something to prevent our feature map from shrinking. This is where we use padding.\n\nA layer of zero-value pixels is added to surround the input with zeros, so that our feature map will not shrink. In addition to keeping the spatial size constant after performing convolution, padding also improves performance and makes sure the kernel and stride size will fit in the input.\n\nAfter a convolution layer, it is common to add a pooling layer in between CNN layers. The function of pooling is to continuously reduce the dimensionality to reduce the number of parameters and computation in the network. This shortens the training time and controls overfitting.\n\nThe most frequent type of pooling is max pooling, which takes the maximum value in each window. These window sizes need to be specified beforehand. This decreases the feature map size while at the same time keeping the significant information.\n\nThus when using a CNN, the four important hyperparameters we have to decide on are:\n\nA nice way of visualizing a convolution layer is shown below. Try to look at it for a bit and really understand what is happening.\n\nAfter the convolution and pooling layers, our classification part consists of a few fully connected layers. However, these fully connected layers can only accept 1 Dimensional data. To convert our 3D data to 1D, we use the function in Python. This essentially arranges our 3D volume into a 1D vector.\n\nThe last layers of a Convolutional NN are fully connected layers. Neurons in a fully connected layer have full connections to all the activations in the previous layer. This part is in principle the same as a regular Neural Network.\n\nTraining a CNN works in the same way as a regular neural network, using backpropagration or gradient descent. However, here this is a bit more mathematically complex because of the convolution operations.\n\nIf you would like to read more about how regular neural nets work, you can read my previous article.\n\nIn summary, CNNs are especially useful for image classification and recognition. They have two main parts: a feature extraction part and a classification part.\n\nThe main special technique in CNNs is convolution, where a filter slides over the input and merges the input value + the filter value on the feature map. In the end, our goal is to feed new images to our CNN so it can give a probability for the object it thinks it sees or describe an image with text.\n\nYou can find the entire code here."
    },
    {
        "url": "https://medium.freecodecamp.org/building-a-3-layer-neural-network-from-scratch-99239c4af5d3?source=user_profile---------2----------------",
        "title": "How to build a three-layer neural network from scratch",
        "text": "How to build a three-layer neural network from scratch\n\nIn this post, I will go through the steps required for building a three layer neural network. I\u2019ll go through a problem and explain you the process along with the most important concepts along the way.\n\nA farmer in Italy was having a problem with his labelling machine: it mixed up the labels of three wine cultivars. Now he has 178 bottles left, and nobody knows which cultivar made them! To help this poor man, we will build a classifier that recognizes the wine based on 13 attributes of the wine.\n\nThe fact that our data is labeled (with one of the three cultivar\u2019s labels) makes this a Supervised learning problem. Essentially, what we want to do is use our input data (the 178 unclassified wine bottles), put it through our neural network, and then get the right label for each wine cultivar as the output.\n\nWe will train our algorithm to get better and better at predicting (y-hat) which bottle belongs to which label.\n\nNow it is time to start building the neural network!\n\nBuilding a neural network is almost like building a very complicated function, or putting together a very difficult recipe. In the beginning, the ingredients or steps you will have to take can seem overwhelming. But if you break everything down and do it step by step, you will be fine.\n\nImport all necessary libraries (NumPy, skicit-learn, pandas) and the dataset, and define x and y.\n\nBefore we can use our weights, we have to initialize them. Because we don\u2019t have values to use for the weights yet, we use random values between 0 and 1.\n\nIn Python, the function generates \u201crandom numbers.\u201d However, random numbers are not truly random. The numbers generated are pseudorandom, meaning the numbers are generated by a complicated formula that makes it look random. In order to generate numbers, the formula takes the previous value generated as its input. If there is no previous value generated, it often takes the time as a first value.\n\nThat is why we seed the generator \u2014 to make sure that we always get the same random numbers. We provide a fixed value that the number generator can start with, which is zero in this case.\n\nThere are roughly two parts of training a neural network. First, you are propagating forward through the NN. That is, you are \u201cmaking steps\u201d forward and comparing those results with the real values to get the difference between your output and what it should be. You basically see how the NN is doing and find the errors.\n\nAfter we have initialized the weights with a pseudo-random number, we take a linear step forward. We calculate this by taking our input A0 times the dot product of the random initialized weights plus a bias. We started with a bias of 0. This is represented as:\n\nNow we take our z1 (our linear step) and pass it through our first activation function. Activation functions are very important in neural networks. Essentially, they convert an input signal to an output signal \u2014 this is why they are also known as Transfer functions. They introduce non-linear properties to our functions by converting the linear input to a non-linear output, making it possible to represent more complex functions.\n\nThere are different kinds of activation functions (explained in depth in this article). For this model, we chose to use the tanh activation function for our two hidden layers \u2014 A1 and A2 \u2014 which gives us an output value between 0 and -1.\n\nSince this is a multi-class classification problem (we have 3 output labels), we will use the softmax function for the output layer \u2014 A3 \u2014 because this will compute the probabilities for the classes by spitting out a value between 0 and 1.\n\nBy passing z1 through the activation function, we have created our first hidden layer \u2014 A1 \u2014 which can be used as input for the computation of the next linear step, z2.\n\nIn Python, this process looks like this:\n\nIn the end, all our values are stored in the cache.\n\nAfter we forward propagate through our NN, we backward propagate our error gradient to update our weight parameters. We know our error, and want to minimize it as much as possible.\n\nWe do this by taking the derivative of the error function, with respect to the weights (W) of our NN, using gradient descent.\n\nLets visualize this process with an analogy.\n\nImagine you went out for a walk in the mountains during the afternoon. But now its an hour later and you are a bit hungry, so it\u2019s time to go home. The only problem is that it is dark and there are many trees, so you can\u2019t see either your home or where you are. Oh, and you forgot your phone at home.\n\nBut then you remember your house is in a valley, the lowest point in the whole area. So if you just walk down the mountain step by step until you don\u2019t feel any slope, in theory you should arrive at your home.\n\nSo there you go, step by step carefully going down. Now think of the mountain as the loss function, and you are the algorithm, trying to find your home (i.e. the lowest point). Every time you take a step downwards, we update your location coordinates (the algorithm updates the parameters).\n\nThe loss function is represented by the mountain. To get to a low loss, the algorithm follows the slope \u2014 that is the derivative \u2014 of the loss function.\n\nWhen we walk down the mountain, we are updating our location coordinates. The algorithm updates the parameters of the neural network. By getting closer to the minimum point, we are approaching our goal of minimizing our error.\n\nIn reality, gradient descent looks more like this:\n\nWe always start with calculating the slope of the loss function with respect to z, the slope of the linear step we take.\n\nNotation is as follows: dv is the derivative of the loss function, with respect to a variable v.\n\nNext we calculate the slope of the loss function with respect to our weights and biases. Because this is a 3 layer NN, we will iterate this process for z3,2,1 + W3,2,1 and b3,2,1. Propagating backwards from the output to the input layer.\n\nThis is how this process looks in Python:\n\nIn order to reach the optimal weights and biases that will give us the desired output (the three wine cultivars), we will have to train our neural network.\n\nI think this is very intuitive. For almost anything in life, you have to train and practice many times before you are good at it. Likewise, a neural network will have to undergo many epochs or iterations to give us an accurate prediction.\n\nWhen you are learning anything, lets say you are reading a book, you have a certain pace. This pace should not be too slow, as reading the book will take ages. But it should not be too fast, either, since you might miss a very valuable lesson in the book.\n\nIn the same way, you have to specify a \u201clearning rate\u201d for the model. The learning rate is the multiplier to update the parameters. It determines how rapidly they can change. If the learning rate is low, training will take longer. However, if the learning rate is too high, we might miss a minimum. The learning rate is expressed as:\n\nWe chose a learning rate of 0.07 after some experimenting.\n\nFinally, there is our graph. You can plot your accuracy and/or loss to get a nice graph of your prediction accuracy. After 4,500 epochs, our algorithm has an accuracy of 99.4382022472 %.\n\nWe start by feeding data into the neural network and perform several matrix operations on this input data, layer by layer. For each of our three layers, we take the dot product of the input by the weights and add a bias. Next, we pass this output through an activation function of choice.\n\nThe output of this activation function is then used as an input for the following layer to follow the same procedure. This process is iterated three times since we have three layers. Our final output is y-hat, which is the prediction on which wine belongs to which cultivar. This is the end of the forward propagation process.\n\nWe then calculate the difference between our prediction (y-hat) and the expected output (y) and use this error value during backpropagation.\n\nDuring backpropagation, we take our error \u2014 the difference between our prediction y-hat and y \u2014 and we mathematically push it back through the NN in the other direction. We are learning from our mistakes.\n\nBy taking the derivative of the functions we used during the first process, we try to discover what value we should give the weights in order to achieve the best possible prediction. Essentially we want to know what the relationship is between the value of our weight and the error that we get out as the result.\n\nAnd after many epochs or iterations, the NN has learned to give us more accurate predictions by adapting its parameters to our dataset.\n\nThis post was inspired by the week 1 challenge from the Bletchley Machine Learning Bootcamp that started on the 7th of February. In the coming nine weeks, I\u2019m one of 50 students who will go through the fundamentals of Machine Learning. Every week we discuss a different topic and have to submit a challenge, which requires you to really understand the materials.\n\nIf you have any questions or suggestions or, let me know!\n\nOr if you want to check out the whole code, you can find it here on Kaggle."
    }
]