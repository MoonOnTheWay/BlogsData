[
    {
        "url": "https://medium.com/deep-learning-turkey/deep-learning-lab-episode-3-fer2013-c38f2e052280?source=---------0",
        "title": "[Deep Learning Lab] Episode-3: fer2013 \u2013 Deep Learning Turkey \u2013",
        "text": "First and foremost: Importing the libraries\n\nOnce you have created a new folder, which is called \u201cEmotion Recognition\u201d in your Google Drive, you need to upload \u201cfer2013.csv\u201d Excel file to this folder. After then, we will define file paths through the virtual machine with the following code snippet.\n\nWe will feed the convolutional neural network with the images as batch, which contains 64 images for each, in 100 epochs and eventually, the network model will output the possibilities of 7 different emotions (num_classes) can belong to the faces on the images sized with 48x48.\n\nLet\u2019s read our data with the help of \u201cpandas\u201d from the Excel file we just uploaded to Google Drive.\n\nLet\u2019s see what it looks like.\n\nAs you realized at first glance, the images in the Excel file are stored with the corresponding pixel values on each row and preprocessing on the data is required -a little bit-. (Source for preprocessing)\n\nWe are now ready to split our model into training, validation and test sets -well, I am sure that-.\n\nWhat about the architecture of the model will be?\n\nWe are now ready to compile our model. The categorical crossentropy function has been picked out as a loss function because we have more than 2 labels and already prepared the labels in the categorical matrix structure -I confess, again, copied it from the previous episodes-.\n\nLet\u2019s add some more features to our model.\n\nFirstly, we help the loss function to get rid of the \u201cplateaus\u201d by reducing the learning rate parameter of the optimization function with a certain value (factor) if there is no improvement on the value of the loss function for the validation set after a certain epoch (patience).\n\nWe record everything done during the training into the \u201clogs\u201d folder as log to be able to better interpret the results of our model and to visually analyze the changes in the loss function and the accuracy during the training.\n\nFor more information on TensorBoard: GO\n\nEven if we could prevent that the loss function goes to the plateaus, the value of the loss function of validation set could get stuck in a certain range while the training set\u2019s does not (in other words, while the model continues to learn something). As long as we continue to train the model after this point, the only thing the model could do is to memorize (over-fit) the training data -I could say there is no chance of getting rid of the local minima for the loss function without a miracle-. This is something that we will not want at all.\n\nWe stop the training of the model if there is no change in the value of the loss function on the validation set for a certain epoch (patience).\n\nFinally, we save our model during training as long as it gets a better result than the previous epoch. Thus, we will have the best possible model at the end of the training.\n\nWe can start training our model. GO GO GO!!!"
    },
    {
        "url": "https://medium.com/deep-learning-turkey/behavioral-cloning-udacity-self-driving-car-project-generator-bottleneck-problem-in-using-gpu-182ee407dbc5?source=---------1",
        "title": "Behavioral Cloning (Udacity Self Driving Car Project) \u2014 Generator Bottleneck Problem in using GPU",
        "text": "Behavioral Cloning (Udacity Self Driving Car Project) \u2014 Generator Bottleneck Problem in using GPU This is a Udacity Self-Driving Car Nanodegree Project and all sources are belongs to Udacity. In this test I used my MacPro 15\" with 2.9GHz CPU and Sonnet Breakaway Box with Geforce 1060 6GB GPU. 1. What you expect for this paper How to use simulator data for training car autonomously like a real world. How to train a CNN Model with and without a generator. How to use data augmentation. How affect generator in training phase using GPU. Bottleneck Problem. Setup of environment for the project please download this link CarND Term1 Starter Kit. (I didn\u2019t use this Kit that explained below.) I use Conda (https://www.continuum.io/downloads) with Keras 2.1.4 and Tensorlow-gpu 1.5.0. I upload my \u2018environment.yaml\u2019 with simulator and data in below link. if you want to use my environment just run this code after downloading. Link for the environment.yaml, simulator and data: https://drive.google.com/drive/folders/1_a8tmhlsrWfp_vyi6uN_js6RqupJ8zFl?usp=sharing Before coding. I want to explain a bit of project. Data file which include images and driving_log.csv file that path of the images. Each frame has 3 images which comes from left camera, centre camera and right camera. So, when reading driving_log.csv file each row has \u2018center, left, right, steering, throttle, brake, speed\u2019 columns. In this project we use camera images (center, left, right) as input and steering as target. At first import needed packages for the project.\n\nI use two function to load images, first one is read csv file and load by line by line. Return \u2018lines[:1]\u2019 because first line is header. Second one is load the images for using lines path. Steering (angle) is for centre image. So, if image is right image angle is a bit small value (-0.2), and right add a bit (+0.2).\n\nFirst, I load the paths (not images) . And then split paths into two parts. One is for train and the other is for validation. You may asked, why not use test data? We don\u2019t need to test images because it is a regression problem not classification.\n\nAs you see data is not a normal distribution or gaussian. If we load this data to network, -0.2, 0, +0.2 degrees overweighted the other steering angles. I think we have two options. First one is when I load the data to network I cut overweighted degrees (as mention above) make it all degrees have normal or gaussian distribution. It seems a good option, however when thinking machine learning intuition it is not a good option, why? Because we lost some of the data and load to network very low data might makes it overfitted. Second option is generate a new, augmented data. It is like a opposite of the first option. Instead of cut the overweighted steering angles, this time we augmented the data that the other steering angles have more that and get nearly gaussian distribution. So I choose this option. How to augment data, I have some options: -Load left and right images (Like did it above), Also I have more options that like scale, zoom or crop images. However this are change the shape of the image that I don\u2019t need on this regression project. Although Keras have data function for augmentation process (https://keras.io/preprocessing/image/), I create my data augmentation function.\n\nAt this point we examine problem in two different manner, first one include generator the other not. Generators lets low memory usage. For more discussion for it is usage check this link: https://stackoverflow.com/questions/1756096/understanding-generators-in-python Randomly take center, right or left image and each image again randomly augmented it brighten or flipped.\n\nIt looks gaussian. Nice because it makes car more straight drive. We can improve it but I think it is enough for training. First, crop unneeded part of the image (Because, at the top of all the images are sky-mountain-forest and the hood of the car at the bottom), Resize image to a small one like a Le-Net architecture, Use 5 convolution layers with batch normalization and activation ELU, 1 Flatten layer and 3 dense layer with activation ELU and using dropout to not overfit the network, Optimizer Adam with learning rate 1e-5 instead of default 1e-3. This is the model that we are going to use;\n\nTotal parameter is more than 2 million. But it is not a big number if you use GPU. We train model in same model with/without generator. Model train is a bit different when using generator. (https://keras.io/models/sequential/) In training phase I setup \u2018steps_per_epoch= len(train_samples)\u2019 that means 6500 images used in this train. if you want to train more; like make it double which are nearly 13000 images, just multiply \u20182*len(train_samples)\u2019. Don\u2019t forget that without generator more than 14000 training images. Because it takes more time to train with generator, I entered only \u20181\u2019 to \u2018epochs\u2019 (epochs =1). Oh my God! It is more than what I predicted. Just one epoch takes more than 12 minutes with nearly 6500 images (In my first try it takes 34 minutes!!!).\n\nAs to it is a regression problem accuracy is trivial, aim is minimize the loss. The result of full training after preprocessing and data augmentation; The result of full training no preprocessing (except cropping and normalization in model). It is like a drunk car and at the end exit from the route : In this paper we take a simulator and data which is prepared for Udacity Self-Driving Car Nanodegree and train it in CNN architecture as a regression problem. We train the model with/without generator. Compare to with generator, without generator have double images and epoch/sec is 20sec. which is 720sec. in with generator. It means without generator is nearly 72 times faster than with generator. (Sometimes it goes up 200 times!!!). The problem is also about \u2018time efficiency\u2019 versus \u2018memory or space efficiency\u2019 problem. If have enough memory to allocate and want to effective usage of GPU selection without generator is understandable. However, training a huge data not possible to allocate all in memory makes to use generator. So in this data and model that using generator with GPU, bottleneck problem occurred. Of course it depends on data size, batches, model, generator function and computer CPUs-GPUs. It is just a example illustration of course it is more complex than that. As you see on above videos, data preprocessing is so important. It is a good example for ML experts saying, \u2018Garbage In Garbage Out\u2019. Because of the not enough data we make a data augmentation, which is coded by us. However we know that Keras has a data augmentation function. If you like this post please click \u2018Clap\u2019 below to support."
    },
    {
        "url": "https://medium.com/deep-learning-turkey/a-brief-guide-to-intel-movidius-neural-compute-stick-with-raspberry-pi-3-f60bf7683d40?source=---------2",
        "title": "A Brief Guide to Intel Movidius Neural Compute Stick with Raspberry Pi 3",
        "text": "Today, low-power consumption is indispensable for autonomous/unmanned vehicles and IoT (Internet of Things) devices. In order to develop deep learning inference application at the edge, we can use Intel\u2019s both energy efficient and low cost Movidius USB stick!\n\nMovidius Neural Compute Stick (NCS) is produced by Intel and it can be run without any need of Intenet. This software development kit enables rapid prototyping, validation, and deployment of deep neural networks. Profiling, tuning, and compiling a DNN on a development computer with the tools are provided in the Intel Movidius Neural Compute SDK. The Movidius NCS\u2019 compute capability comes from Myriad 2 VPU (Vision Processing Unit.\n\nRunning Deep Learning models efficiently on low capacity graph processors is very painful. Movidius allows us to optimize the operation of large models such as GoogLeNet (thanks to Yann LeCun) with multi-use support. It is an easy-to-use kit that allows you to design and implement applications such as classification and object recognition as physical products.\n\nWe can simply think of Movidius NCS as a GPU running on USB (Graphics Processing Unit). However, training of the model is not performed on this unit, the trained model works optimally on the unit and is intended to be used in physical environments for testing purposes.\n\nIt is so simple to run a image classification demo. Now we can use NC App Zoo repo for classifying an image. We need to take graph file to activate application of Movidius NCS. It has compiled GoogLeNet model for ready to run. This application needs some files.\n\ncommand is used for creating the files that Movidius needs as graph file. Graph file is a demo of image-classifier.\n\nI\u2018d like to thank Intel T\u00fcrkiye and Mustafa Aldemir for kindly and immediate donate a Movidius Neural Compute Stick to support my Deep Learning Research."
    },
    {
        "url": "https://medium.com/deep-learning-turkey/machine-learning-in-cyber-security-3c7d8620ba72?source=---------3",
        "title": "Machine Learning in Cyber Security \u2013 Deep Learning Turkey \u2013",
        "text": "In recent years, attackers have been developing more sophisticated ways to attack systems. Thus, recognizing these attacks is getting more complicated in time. Most of the time, network administrators were not capable of recognizing these attacks effectively or response quickly.\n\n experiences via interdependent metrics. Globally pontificate innovative expertise via competitive manufactured products. Rapidiously restore.\n\nTherefore, there is a lot of software has been developed to support the human race in order to be able to manage and protect their systems effectively. Initially, these software has been developed to handle some operations like mathematical calculations which seem very complex for the human being. And then we need more. Next step was extending the ability of software using artificial intelligence and machine learning techniques. As technology advances, a huge amount of data is being produced to be processed every day and every hour. Finally, the concept of \u201cBig Data\u201d was born and people began to need a more intelligent system for processing and getting make sense of these data. For this purpose, there are a lot of algorithms have been developed until today. These algorithms are used for many research area such as; image processing, speech recognition, biomedical area, and of course cyber security domain. \n\n \n\n Besides all of these, basically, the main purpose of Machine Learning techniques is providing decision mechanism to software as people do. Cybersecurity domain is one of the most important research area worked on. The Centre for Strategic and International Studies in 2014 estimated annual costs to the global economy caused by cyber crimes was between $375 billion and $575 billion. Although sources differ, the average cost of a data breach incident to large companies is over $3 million. Researchers have developed some intelligent systems for cyber security domain with the purpose of reducing this cost."
    },
    {
        "url": "https://medium.com/deep-learning-turkey/deep-learning-lab-episode-2-cifar-10-631aea84f11e?source=---------4",
        "title": "[Deep Learning Lab] Episode-2: CIFAR-10 \u2013 Deep Learning Turkey \u2013",
        "text": "The very first move: Importing the libraries\n\nWe need to assign a file path on Google Drive to save the model that we trained on Google Colaboratory. The first thing to do is to create a new folder named \u201ccifar10\u201d on Google Drive and then, let\u2019s run the following code snippet on Google Colab.\n\nWe will feed the convolutional neural network with the images as batches -each batch contains 64 images- in 100 epochs and eventually, the network model will output the possibilities of 10 different categories (num_classes) can belong to the image.\n\nThanks to Keras, we can load the dataset easily.\n\nWe also need to convert the labels in the dataset into categorical matrix structure from 1-dim numpy array structure.\n\nOnce bitten twice shy, we will not forget it for this time. We need to normalize the images in the dataset.\n\nWe are now absolutely sure that it is enough for preprocessing -for now, LUL-. It is the time to create our model. For this episode in the series, I would prefer to use the most common neural network model architecture in the literature: [CONV] \u2014 [MAXP] -..- [CONV] \u2014 [MAXP] \u2014 [Dense]\n\nThe summary of this model could be seen below:\n\nI would prefer the Stochastic Gradient Descent algorithm to optimize the weights on the backpropagation. Set the momentum parameter as 0.9, and just leave the others as default. I, again, strongly recommend you to read an article, this one, in order to get more information about SGD algorithm.\n\nWe are now ready to compile our model. The categorical crossentropy function has been picked out as a loss function because we have more than 2 labels and already prepared the labels in the categorical matrix structure -I confess, copied it from the first episode-.\n\nWe\u2019ve done a lot and we have only one step to begin training our model. At this time, I would like to make a different move. I will split the training dataset (50.000 images) into training (40.000 images) and validation (10.000 images) datasets to measure the validation accuracy of our model in such a better way. Thus, our neural network model will continue the training by evaluating the images that never been seen during the training after each epoch.\n\nWell, so far so good. We have started to learn. I think we did, didn\u2019t we?"
    },
    {
        "url": "https://medium.com/deep-learning-turkey/deep-learning-lab-episode-1-fashion-mnist-c7af60029836?source=---------5",
        "title": "[Deep Learning Lab] Episode-1: Fashion-MNIST \u2013 Deep Learning Turkey \u2013",
        "text": "This is the first episode of \u201cDeep Learning Lab\u201d story series which contains my individual works for deep learning with different cases.\n\nThe dataset for the first episode that I would like to work on is MNIST dataset -not surprisingly-. However, it is not MNIST handwritten digit database as first come to your mind, but MNIST-like fashion product database. Actually, Fashion-MNIST -wow!-.\n\nFashion-MNIST dataset has been developed by the Zalando Research Team as clothes product database and as an alternative to the original MNIST handwritten digits database. Besides to have the same physical characteristics as the ancestor (the original one), there are 60.000 images for training a model and 10.000 images for evaluating the performance of the model. The most significant reason for picking this dataset is that the vast majority of searches about deep learning on Google may introduce you to the original MNIST, but you are now probably meeting Fashion-MNIST for the first time -don\u2019t you?-."
    },
    {
        "url": "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d?source=---------6",
        "title": "Google Colab Free GPU Tutorial \u2013 Deep Learning Turkey \u2013",
        "text": "Now you can develop deep learning applications with Google Colaboratory -on the free Tesla K80 GPU- using Keras, Tensorflow and PyTorch.\n\nHello! I will show you how to use Google Colab, Google\u2019s free cloud service for AI developers. With Colab, you can develop deep learning applications on the GPU for free.\n\nI am happy to announce that this blog post was selected as KDnuggets Silver Blog for February 2018! Read this on KDnuggets.\n\nGoogle Colab is a free cloud service and now it supports free GPU!\n\nThe most important feature that distinguishes Colab from other free cloud services is; Colab provides GPU and is totally free.\n\nDetailed information about the service can be found on the faq page.\n\nSince Colab is working on your own Google Drive, we first need to specify the folder we\u2019ll work. I created a folder named \u201capp\u201d on my Google Drive. Of course, you can use a different name or choose the default Colab Notebooks folder instead of app folder.\n\nCreate a new notebook via Right click > More > Colaboratory\n\nRename notebook by means of clicking the file name.\n\nIt is so simple to alter default hardware (CPU to GPU or vice versa); just follow Edit > Notebook settings or Runtime>Change runtime type and select GPU as Hardware accelerator.\n\nNow we can start using Google Colab.\n\nI will run some Basic Data Types codes from Python Numpy Tutorial.\n\nIt works as expected :) If you do not know Python which is the most popular programming language for AI, I would recommend this simple and clean tutorial.\n\nRun these codes first in order to install the necessary libraries and perform authorization.\n\nWhen you run the code above, you should see a result like this:\n\nClick the link, copy verification code and paste it to text box.\n\nAfter completion of the authorization process,\n\nupload mnist_cnn.py file to app folder which is located on your Google Drive.\n\nrun the code below to train a simple convnet on the MNIST dataset."
    }
]