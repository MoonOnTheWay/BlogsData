[
    {
        "url": "https://medium.com/@aiii/pytorch-e64c248ab428?source=user_profile---------1----------------",
        "title": "Pytorch \u2013 Neil Zhang \u2013",
        "text": "This criterion combines and in one single class."
    },
    {
        "url": "https://medium.com/@aiii/understanding-data-science-c16823309463?source=user_profile---------2----------------",
        "title": "Understanding Data Science \u2013 Neil Zhang \u2013",
        "text": "Often one can find some links between data, which we can say they are associated, but it\u2019s not easy to conclude decisively that one causes another.\n\nIf the treatment and control groups are similar apart from the treatment, then differences from the outcomes in the two groups can be ascribed to the treatment.\n\nIf the treatment and control groups have systematic differences other than the treatment, then it might be difficult to identify causality. Such differences are often present in observational studies.\n\nWhen these underlying differences that you can\u2019t see lead researchers astray, they are called confounding factors. (e.g. researchers found coffee is linked to lung caner, but coffee drinkers tend to smoke a lot, and smoking is actually the causation of lung cancer)\n\nThe solution is to use randomized controlled experiments! But randomization must be done carefully! Randomization != Haphazard\n\nAreas (not the height, width) should be proportional to the values they represent in a graph, because your eyes pick up area.\n\nHistograms graphs are following this principle when vertical axis is in percentage (instead of counts). The height of a histogram measures the percent of data in the bin relative to the amount of space (width) in the bin. This is a measure of crowdedness, also known as density. Unit of height is percent per unit on the horizontal axis. The more crowded the bar, the taller it is."
    },
    {
        "url": "https://medium.com/@aiii/spark-49a72769bbd5?source=user_profile---------3----------------",
        "title": "Spark \u2013 Neil Zhang \u2013",
        "text": "Tips and Tricks with Spark and PySpark"
    },
    {
        "url": "https://medium.com/@aiii/tensorflow-tips-7806eb7960e6?source=user_profile---------4----------------",
        "title": "Tensorflow Tips \u2013 Neil Zhang \u2013",
        "text": "If you run a CNN model (e.g. VGG16) with tensorflow backend on Nvidia GPU, and see following errors, most likely tensorflow has problems with allocating memory in GPU.\n\nReference: mostly follow fkenghagho\u2019s comment \n\nCrash: Could not create cuDNN handle when convnets are used #6698"
    },
    {
        "url": "https://medium.com/@aiii/numpy-ef82c0ed78b?source=user_profile---------5----------------",
        "title": "Python NumPy \u2013 Neil Zhang \u2013",
        "text": "Broadcasting is a set of rules that allow binary operations on arrays of different sizes.\n\nWhen operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n\nIf these conditions are not met, a exception is thrown, indicating that the arrays have incompatible shapes. The size of the resulting array is the maximum size along each dimension of the input arrays.\n\nArrays do not need to have the same number of dimensions. For example, if you have a array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n\nBroadcasting provides a convenient way of taking the outer product (or any other outer operation) of two arrays. The following example shows an outer addition operation of two 1-d arrays:\n\nHere the index operator inserts a new axis into , making it a two-dimensional array. Combining the array with , which has shape , yields a array.\n\nBroadcasting is a powerful tool for writing short and usually intuitive code that does its computations very efficiently in C. However, there are cases when broadcasting uses unnecessarily large amounts of memory for a particular algorithm. In these cases, it is better to write the algorithm\u2019s outer loop in Python. This may also produce more readable code, as algorithms that use broadcasting tend to become more difficult to interpret as the number of dimensions in the broadcast increases.\n\nWell, is just a convenience function to create an , it is not a class itself. You can also create an array using , but it is not the recommended way. From the docstring of :\n\nMost of the meat of the implementation is in C code, here in multiarray, but you can start looking at the ndarray interfaces here:"
    },
    {
        "url": "https://medium.com/@aiii/python-pandas-f115b0870268?source=user_profile---------6----------------",
        "title": "Python Pandas \u2013 Neil Zhang \u2013",
        "text": "For pandas objects (Series, DataFrame), the indexing operator [] only accepts:\n\n1. colname or list of colnames to select column(s)\n\n2. slicing or Boolean array to select row(s), i.e. it only refers to one dimension of the dataframe.\n\nFor df[[colname(s)]], the interior brackets are for list, and the outside brackets are indexing operator, i.e. you must use double brackets if you select two or more columns. With one column name, single pair of brackets returns a Series, while double brackets return a dataframe."
    },
    {
        "url": "https://medium.com/@aiii/install-keras-tensorflow-gpu-1-6-on-windows-10-3-12-2018-4afdedcc196f?source=user_profile---------7----------------",
        "title": "Install Python 3.6 \u2013 Neil Zhang \u2013",
        "text": "This procedure mostly follow Keras-TensorFlow-GPU-Windows-Installation with some tweaks to make it work with latest tensorflow version 1.6 and CUDA toolkit 9.0.\n\nThe second command may cause error\n\nIn this case run following commands in sequence:\n\nNeed register in Nvidia Developer Program before you can download.\n\nN.B. CUDA 9.1 won\u2019t work with tensorflow version 1.6.0 and below.\n\nPut your unzipped folder in C drive as follows:\n\nAdd the following path in your Environment. Subjected to changes in your installation path.\n\nClose all the prompts. Open a new Anaconda Prompt to type the following command(s)\n\nYou shall see that the new Environment PATH is there.\n\nOpen Anaconda Prompt to type the following command(s)\n\nOpen Anaconda Prompt to type the following command(s)\n\nOpen Anaconda Prompt to type the following command(s)\n\nIf the system outputs the following, then you are ready to begin writing TensorFlow programs:\n\nThe default backend of keras is theano, let\u2019s change it to tensorflow\n\nTo change the backend permanently, you need change the config in\n\nFirst find out on window\n\nOnce find the , open and change \u201cbackend\u201d to \u201ctensorflow\u201d as below\n\nSometimes, this won\u2019t work even after you modified the keras.json file, that\u2019s because there\u2019s an environment variable KERAS_BACKEND which is automatically set to \u2018theano\u2019 at startup.\n\nTo fix this, find a file called \u2018keras_activate.bat\u2019, it\u2019s under\n\nJust delete the file: keras_activate.bat and re-open a new Anaconda prompt window.\n\nIt should work now.\n\nIf you see\n\nThen you are not running on GPU.\n\nMake sure you have installed tensorflow-gpu instead of tensorflow.\n\nMake sure you don\u2019t have extra copy of tensorflow installed outside of environment \u2018tensorflow\u2019 (as setup above)\n\nRun following command with and without environment to verify:\n\nIt seems that tensorflow 1.6.0 doesn\u2019t work with cuda 9.1, I have to install cuda 9.0 instead."
    },
    {
        "url": "https://medium.com/@aiii/use-pre-training-cnn-for-state-farm-kaggle-competition-38865ff20379?source=user_profile---------8----------------",
        "title": "Use Pre-Trained CNN for State Farm Kaggle Competition",
        "text": "With a small size of train data and enough training time, you can always fit the train data to 100% accuracy.\n\nApply VGG16 model with default finetune from fast.ai on Kaggle State Farm Distracted Driver Detection competition data, we use following parameters:\n\nAt around epochs 180, you can see line accuracy = 1 go through a red dot, meaning achieve exact 100% accuracy for training data.\n\nHowever, it\u2019 clear that we have overfit, validation accuracy is just 0.5.\n\nTo estimate the time cost with a full data set training and VGG16 model (except the last layer is replaced, and only dense layers are trainable), I apply following parameters:\n\nIt takes about 10 minutes to train the neural network for one epoch!\n\nSo if I am to check 10 learning rates, 10 weight decays, 3 dropout rates, 3 momentum (or learning rate decay), 3 batch sizes, 2 optimizers, it will take about (Assuming no grid searching here)\n\n(10 + 10 + 3 + 3 + 3 + 2)*10 = 310 minutes ~ 5 hours for just one epoch.\n\nGenerally, we would like to run with each parameter for longer time, e..g 10 epochs, that means 50 hours training time! And 10 epochs probably is not long enough!\n\nThat\u2019s too long for me to search the optimal parameters. I need use less data in shorter time to find some meaningful ballpark of the parameters.\n\nAlso, there are 79726 images in test, it takes about 30 minutes to generate predictions for them.\n\nAnyway, here\u2019s the accuracy vs. epochs plot for this run. One can tell the validation accuracy is better than train accuracy, this might indicate underfitting because we applied dropout.\n\nSubmitting this model to Kaggle, I got a score of 1.55869, ranking around 675 on Kaggle\u2019s private leaderboard.\n\nAlthough one can try some ideas to improve the validation error (e.g. reduce regularization), it\u2019s better to follow a systematic process to attack the problem.\n\nSince we are only training dense layers here, we probably should remove the convolution layers to speed up the training.\n\nTo save time in training and fine-tuning the hyper-parameters, I tried to use pre-trained VGG16 model here.\n\nHere\u2019s the plot of training/validation error vs. epochs. You can see the Accuracy is very low (0.1109) and flat through 200 epochs.\n\nOne can tell that the activations for all input images are way below zero. No wonder the cost value never gets down! The weights are all stuck there.\n\nNow the training is painless\n\nThe dropout layer is really crucial, without it, even if I used more neurons and/or more layers, I won\u2019t be able to achieve such a high accuracy. Guess dropout gives some weights the chance to escape the saturation and dramatically changes the loss.\n\nApply the model on test images and our clipping trick, we get a score of 1.04089 on private leaderboard, ranking around 550.\n\nRemember, this is achieved without any hyper-parameters tuning.\n\nLet\u2019s see how does batch normalization help on the image recognition.\n\nI trained the model until train and validation accuracies approach each other (vs. letting train accuracy fall below validation accuracy as above, which may indicate the model is still undeffit).\n\nThe train and validation accuracy both are about 0.998 at the 50th epoch. I expected the test scored to be better, however, it\u2019s not, I got a private score of 1.09856 and a public score of 1.32542. Worse than without normalize the inputs.\n\nAdding one more batch normalization layer to the dense layer:\n\nWe got overfit after 10 epochs, train accuracy achieves 100% at 9th epoch.\n\nNow this is much better:\n\nprivate score = 0.90923\n\nTo get a better score, try use ensemble model of following models:\n\n1. One hidden layer with dropout without any batch normalization at epochs: 20, 40, 100\n\n2. One hidden layer with dropout with inputs batch normalized at epochs 50\n\n3. One hidden layer with dropout with inputs and hidden layer both batch normalized at epochs 10\n\nThere are total 5 models used in ensemble, the average probabilities on test data are submitted.\n\nRanking around 380! Much better improvement!\n\nApply pesudo labeling model, we mixed 79726 test images with 17943 train images and got:\n\nLooks like it can improve the accuracy. It\u2019s usually suggested that in each batch, there\u2019s 1/3 of pseudo images. So let\u2019s make some augmented images.\n\nI applied following transformations to the train images and generate 6 sets of new images:\n\nTrain with original data, I got a score on Kaggle:\n\nNow train together with pseudo images, I got score on Kaggle:\n\nApplying Ensemble on above models will surely have better scores.\n\nSurprisingly, when apply ensemble I didn\u2019t get an improvement from the ensembles from simpler models. That says it\u2019s best to ensemble from very different models. \n\nPrivate Score = 0.64553"
    },
    {
        "url": "https://medium.com/@aiii/machine-learning-design-process-e5601e18086?source=user_profile---------9----------------",
        "title": "Machine Learning Design Process \u2013 Neil Zhang \u2013",
        "text": "In practice, one can usually do much better with a correct application of a commonplace algorithm than by sloppily applying an obscure algorithm.\n\nWhat is important is to determine which performance metric to improve ahead of time, then concentrate on improving this metric. Without clearly de\ufb01ned goals, it can be di\ufb03cult to tell whether changes to a machine learning system make progress or not.\n\nThese goals and error metrics should be driven by the problem that the application is intended to solve.\n\nEstablish a working end-to-end pipeline as soon as possible including the estimation of the appropriate performance metrics. Don\u2019t do premature optimizing on the algorithm.\n\nDiagnose which components are performing worse than expected and whether poor performance is due to over\ufb01tting, under\ufb01tting, or a defect in the data or software.\n\nIt is often much better to gather more data than to improve the machine learning model.\n\nThe end goal is good performance on the test set.\n\nIt tries to explain the difference between some baseline (much poorer) performance and current performance. How much did your algorithm components really help in the performance?"
    },
    {
        "url": "https://medium.com/@aiii/vim-tricks-31beb2c27fa4?source=user_profile---------10----------------",
        "title": "VIM Tricks \u2013 Neil Zhang \u2013",
        "text": "They\u2019re tabs. By default, VIM shows all control characers other than EOL as where is the character of the alphabet corresponding to the character being shown (tab = char #9, = 9th char in alphabet). To stop showing them, use , but that will turn off EOL display as well.\n\nIf you want to see end-of-line chars but not tabs, you can use for that. Use for details, but roughly:\n\nThat says, when showing tabs, show a space for the first virtual space it occupies and a space for the subsequent ones; when showing EOLs, use a . (Since tabs can span multiple virtual columns, you get to use two different chars, one for the first column, and one for the others.)"
    },
    {
        "url": "https://medium.com/@aiii/how-to-tune-hyper-parameters-in-deep-learning-a0fa4bc1d782?source=user_profile---------12----------------",
        "title": "How to Tune Hyper-Parameters in Deep Learning \u2013 Neil Zhang \u2013",
        "text": "The goal should be to develop a workflow that enables you to quickly do a pretty good job on the optimization, while leaving you the flexibility to try more detailed optimizations, if that\u2019s important.\n\nEach heuristic is not just a (potential) explanation, it\u2019s also a challenge to investigate and understand in more detail.\n\nWhen using neural networks to attack a new problem the first challenge is to get any non-trivial learning, i.e., for the network to achieve results better than chance. This can be surprisingly difficult, especially when confronting a new class of problem."
    },
    {
        "url": "https://medium.com/@aiii/optimization-d8a9272a26fb?source=user_profile---------13----------------",
        "title": "Optimization: Intuitive Explanation of Lagrangian Transformation",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@aiii/the-list-of-list-machine-learning-resources-82eb9a884e8?source=user_profile---------14----------------",
        "title": "The List of List: Machine Learning and Deep Learning Resources",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@aiii/machine-learning-diagnostics-b2256d78d51e?source=user_profile---------15----------------",
        "title": "Machine Learning Diagnostics \u2013 Neil Zhang \u2013",
        "text": "You can increase the classification threshold (normally 0.5) to increase precision (but will decrease recall), assuming Y=1 is the rare case.\n\nYou can plot a graph of precision vs. recall by changing threshold in classification."
    },
    {
        "url": "https://medium.com/@aiii/overfitting-8646424067dc?source=user_profile---------16----------------",
        "title": "Overfitting \u2013 Neil Zhang \u2013",
        "text": "The model fits the data more than warranted. The model is fitting the noise instead of data, which is harmful when it tries to generalize to unseen data."
    },
    {
        "url": "https://medium.com/@aiii/tips-and-tricks-for-machine-learning-2e11b9d53ed0?source=user_profile---------17----------------",
        "title": "Tips and Tricks for Machine Learning \u2013 Neil Zhang \u2013",
        "text": "We need to be cautious when submitting our results to Kaggle. The model that we\u2019ve built is likely to be over confident in its predictions, and as a result the probabilities it\u2019s going to return will be very close to 1 or 0. This is great when our predictions are correct, as the logarithm of 1 is of course zero. However, when we have misclassified with that level of confidence, we are taking the logarithm of 0. This is of course undefined, and we would expect this to throw an error. Fortunately, the wizards over at Kaggle made sure to avoid returning an error for such confident predictions by returning the logarithm of some arbitrarily small non-zero amount. But the logarithm of an arbitrarily small non-zero epsilon is a very large value, and therefore this over-confidence is going to throw off our score. A smarter choice is to compensate for this over confidence by clipping our results, i.e. to a range of 0.02 to 0.98(The loss function is calculated based on both P_dog and 1-P_dog, so we need to take care of both ends of the range, not just the lower end 0). While this means we won\u2019t be getting zero values for our absolutely correct predictions, we will avoid generating large values in response to a confident incorrect prediction, and this results in a better score.\n\nReference: fast.ai lesson 2 note"
    },
    {
        "url": "https://medium.com/@aiii/useful-python-tricks-and-tips-704b1b5e93ef?source=user_profile---------19----------------",
        "title": "Python Tricks and Tips \u2013 Neil Zhang \u2013",
        "text": ""
    },
    {
        "url": "https://becominghuman.ai/how-did-i-get-into-top-50-of-kaggle-competition-dogs-vs-e750979ff105?source=user_profile---------20----------------",
        "title": "How did I get into top 50% of Kaggle Competition (Dogs vs.",
        "text": "I started take the fast.ai course ( Practical Deep Learning For Coders, Part 1) around May, 2017. In lesson 1, students are required or strongly suggested to modify the course code to get into the top 50% ranking of the Dogs v Cats Redux competition. I am not sure about other people, but it turned out to be pretty hard for me at the very beginning.\n\nWhen I started, the competition has ended already, there are total 1314 rankings in the public leaderboard, with the 50% ranking (657th) having a score of 0.12203. So I need to have a score of less than 0.12203 to get into top 50%.\n\nGiven that the course code is utilizing a pre-trained Vgg16 model, there seems not much room to improve from a beginner\u2019s point of view. Through various googling and reading, here are the experiments I have tried:\n\nCheck the effects of batch size. I varied batch_size as [8, 16, 32, 50,64, 90, 128]. The following graph plots the loss of training data (red-circle), validation data (blue square) and test data (green triangle) respectively vs. batch size. By checking the validation loss, I think batch_size = 90 is an optimal parameter. Note, test data loss is shown for comparison only, they should not be used to select batch_size.\n\nStill, at this run with batch_size = 90, I got a test score of 0.15558, which is larger than the 50% score at Kaggle.\n\nAlso, when batch_size ~200, I started to get out of memory error.\n\nI then fixed batch_size at 90, and check the effects of epochs. The epochs are [1.0, 2.0, 4.0]. The following graph plots the loss of training data (red-circle), validation data (blue square) and test data (green triangle) respectively vs. epochs.\n\nIt looks like epochs=2 will be the best choice, although the validation loss between epochs=1 and epochs=2 are close, and also consider the compute efficiency (Each epoch train will run about 10 minutes on AWS EC2 p2.xlarge instance), I used epochs =1 in the end.\n\nStill, I am far from 50% at Kaggle.\n\nThis time, I tried to train on raw and transformed images in order. That is, I first trained a base line model with batch_size = 64, and epochs =1 using the raw images. Without restarting the training, I trained it again on a transformed data set. Here is a code snippet I used, where model vgg has been trained once on the raw images. Note the shear transformation applied to the raw images.\n\nContinue with such process, I applied rotation, vertical flip (later realized this is not a good transformation for my images and switched to horizontal flip), shift (both width and height) one by one on previously trained model.\n\nThe horizontal labels from left to right are:\n\nNone of the model gave me a better test score than 0.15. I need keep searching.\n\nFrustrated, days later, I reset batch_size = 90, epochs=1, and ran the training on raw images again, wala, I got a test score of 0.13399, which is the biggest improvement I have ever seen so far, it\u2019s still not beating the 50%, which is around 0.12, but very encouraging.\n\nI then changed epochs = 5, and trained the model again by applying multiple transformations at one time.\n\nHere are the trains for each epoch:\n\nI got a test score of 0.14027, no better than the simple batch_size = 90 run.\n\nI still have big belief on augmented data. This time, I first applied each image transformations on the raw images and saved the augmented images into their separate directories.\n\nI thus have 5 extra train sets: flip, shear, shift, zoom, rotate. I then trained one model for each data set separately. Following graph shows the results for them plus the base case. All with batch_size = 90 and epochs = 1.\n\nThe good news is with sheared and zoomed images, I can lower the test score to below 0.12: 0.11434 and 0.11701 respectively. So I got into top 50% of Kaggle leader board now!\n\nThis is not the end though, I can now use the predictions from my previous models and create an ensemble model by averaging all the predictions from Trial 3, Trial 4 and Trial 5.\n\nThis ensemble model gives me a test score of 0.10128, which is the best score I got so far and the best of all my trials.\n\nSince I have all the transformed images from trial 5, it\u2019s not hard to put them together with the raw images, and create a much bigger train data set. I have total 138000 images (raw + flip + shift + rotate + shear + zoom). I ran through with batch_size = 90, epochs = 1 on these training samples, I got :\n\nNot impressive, Did I overfitting the model? Maybe, given that only 1 layer of the network is trainable. Here comes the last trial.\n\nI tried to make the second to last layer also trainable so to increase the adjustable parameters in the network.\n\nRan through with raw data, I got:\n\nLastly, I ran this against the total 138000 images (raw + flip + shift + rotate + shear + zoom). Still, not impressive results:\n\nStill overfitting? Maybe. This may need further investigation.\n\nIt\u2019s hard though, it takes more than 1 hour to finish 1 epoch.\n\nThis concludes my struggles to beat the top 50% Kaggle score. The ensemble method easily beat every single training method. Keras provides a good mechanism to augment the images through various transformations, which prove to be very helpful to generate different models from the raw data.\n\nI can now continue to Jeremy Howard\u2019s lesson 2 for further enlightenment.\n\nThe following graph shows the train and validation data error against learning rate up to 10. Batch_size = 64, epoch = 1, the shuffle = True.\n\nYou can tell the errors start with larger value, and drop down when lr = 0.0005, then they constantly get bigger when learning rate is increasing. Validation error is minimum when lr = 0.0005.\n\nMaybe I should turn off shuffle? (Probably, so I have less variable when compare the effects. )\n\nMaybe I should keep the same set of random weight initialization as well?\n\nUpdate (11/22/2017): There might be underfitting according to the class, so if we remove dropout, we can probably increase the accuracy of train a lot.\n\nThe following graph shows the train and validation data error against epochs up to 20. Batch_size = 64, learning rate = 0.001. Shuffle = True. Initialization of weights is random."
    },
    {
        "url": "https://medium.com/@aiii/a-summary-from-how-to-improve-deep-learning-performance-f57def976d41?source=user_profile---------21----------------",
        "title": "A Summary from: How To Improve Deep Learning Performance",
        "text": "A summary from reading the post by Jason Brownlee post on machinelearningmastery.com. Here\u2019s the original link:\n\nhttps://machinelearningmastery.com/improve-deep-learning-performance/\n\nThe gains often get smaller the further down the list. For example, a new framing of your problem or more data is often going to give you more payoff than tuning the parameters of your best performing algorithm. Not always, but in general.\n\nIn fact, you can often get good performance from combining the predictions from multiple \u201cgood enough\u201d models rather than from multiple highly tuned (and fragile) models."
    }
]