[
    {
        "url": "https://medium.com/@leeprovoost/overriding-file-name-of-an-s3-object-using-pre-signed-url-and-aws-sdk-go-4256f30e7809?source=user_profile---------1----------------",
        "title": "Overriding file name of an S3 object using pre-signed URL and aws-sdk-go",
        "text": "I\u2019ve been trying to get uploading and downloading of S3 objects working using pre-signed URLs. Once you get the basics sorted around IAM permissions, bucket policies, etc., one final hurdle is downloading the S3 object with a custom name.\n\nOur problem is that we generate and assign a unique ID to the S3 object during file upload and use that ID as the key for the object name. So for instance the user uploads a PDF document named hello-kitty.pdf. We store the original file name in the database, but our actual S3 object key will be something like 12345678987654321.\n\nWhen you then provide a pre-signed URL to the user for downloading, then the problem is that the user will get a file named 12345678987654321, not hello-kitty.pdf.\n\nWhen you look at the official AWS documentation for the aws-sdk-go library, then you\u2019ll get something like this (slightly modified):\n\nThe key to override the filename is to use the Content-Disposition header. MDN has the following example:\n\nI struggled getting the Content-Disposition header added to the pre-signed URL because it turns out that in the API it\u2019s called Response Content-Disposition header. When you add the following line to your request, then it\u2019s all magically working:"
    },
    {
        "url": "https://medium.com/@leeprovoost/run-two-instances-of-atom-with-separate-config-272868700635?source=user_profile---------2----------------",
        "title": "Running two instances of Atom with separate config \u2013 Lee Provoost \u2013",
        "text": "I started with some React Native development and a big PIA is Facebook\u2019s nuclide package pretty much taking over your whole Atom setup.\n\nYou can\u2019t seem to launch multiple instances of Atom with its own config, so here\u2019s how I solved it:\n\nFirst, download Atom Beta. I use the mainline Atom for my daily work and from now on Atom Beta for my React Native development.\n\nThen add an alias to your profile (in my case ~/.zshrc):\n\nReload your profile (e.g. source ~/.zshrc) and from now on you can start this version of Atom with its own config and packages by just running:"
    },
    {
        "url": "https://medium.com/@leeprovoost/implementing-a-ping-check-when-using-redigo-and-connection-pooling-26466dc9bb5e?source=user_profile---------3----------------",
        "title": "Implementing a Ping check when using Redigo and connection pooling",
        "text": "I\u2019m implementing distributed sessions with a Redis cluster as its backend. The Go library I\u2019m using is Gary Burd\u2019s Redigo package that includes a connection pooling capability that can be used like this:\n\nThis is mentioned in the excellent package documentation but I couldn\u2019t immediately find how to implement a Ping function. When my application starts up, I tend to use (or implement myself) a Ping function that just checks whether the database (e.g. PostgreSQL) or backend APIs are actually reachable.\n\nThere isn\u2019t a built-in Ping function available here but it\u2019s straightforward to implement it because Redis does know the PING command (which returns a PONG response).\n\nJust add the following lines after:\n\nYou can catch the actual response rather than using the underscore to ignore it. The value of the response will be the string PONG, but if we can\u2019t talk to the Redis server, we\u2019ll get an error back anyway so we can safely discard the PONG message here."
    },
    {
        "url": "https://medium.com/@leeprovoost/go-methods-with-different-type-signatures-da754b573776?source=user_profile---------4----------------",
        "title": "Go methods with different type signatures\u2026 \u2013 Lee Provoost \u2013",
        "text": "\u2026 are not possible apparently.\n\nWhere the first method calls the second with a default limit as a convenience method.\n\nGo doesn\u2019t support that, see language spec:"
    },
    {
        "url": "https://medium.com/@leeprovoost/go-plus-auto-completion-only-returns-panic-6d4591569dbc?source=user_profile---------5----------------",
        "title": "go-plus auto-completion only returns PANIC \u2013 Lee Provoost \u2013",
        "text": "Just bumped into this interesting problem with Atom 1.11 and Go 1.7 when I try auto-completion:\n\nThis solution from the go-plus creator solved it:\n\nFor anyone coming across this in the future, if you\u2019re seeing as the only autocomplete suggestion, do the following:"
    },
    {
        "url": "https://medium.com/@leeprovoost/dealing-with-go-template-errors-at-runtime-1b429e8b854a?source=user_profile---------6----------------",
        "title": "Dealing with Go Template errors at runtime \u2013 Lee Provoost \u2013",
        "text": "One way of catching Go template errors is the following:\n\nYou execute your template named \u201cmyTemplate\u201d and if there is an error, an err object is returned that you can deal with.\n\nIn my case, I print an error message in my log files as well as return an HTTP 500 (Internal Server Error) and display an error page to the user.\n\nThe only problem with this is that the template engine starts rendering the template straight away and starts sending data to the client. So if somewhere midway, you encounter an error during rendering, you essentially send half of a rendered page, as well as an error page all in one page. It\u2019s ugly and confusing.\n\nIt took me quite some googling to stumble on a StackOverflow discussion where they are suggesting to render your template into a buffer and only when you\u2019re finished, you push the buffer to the response writer. Or, if you encounter an error, you discard the buffer and send a proper error page back. One improvement over this is to initialise a buffer pool where you can just reuse the buffers rather than creating new buffers every single time.\n\nSo we first need to initialise the buffer pool:\n\nThen we\u2019ll change our handler code into this:"
    },
    {
        "url": "https://medium.com/@leeprovoost/gos-json-unmarshal-errors-are-not-what-you-might-think-they-are-f98cacaa0c11?source=user_profile---------7----------------",
        "title": "Go\u2019s json.Unmarshal errors are not what you might think they are",
        "text": "When you\u2019re parsing JSON files in Go, you would probably do something like this:\n\nYou read your file containing your JSON document (jsonFile), then try to unmarshal it into your struct (MyStruct). I was in the assumption that json.Unmarshal would return an error in the following two cases:\n\nTurns out that this is a wrong assumption. json.Unmarshal only returns an error for the first case. Not the second.\n\nYou actually need to do an explicit check whether your struct is an empty struct, which you can do with reflection:\n\nNote 1: This Stack Overflow discussion was very helpful: http://stackoverflow.com/questions/28447297/how-to-check-for-an-empty-struct"
    },
    {
        "url": "https://medium.com/@leeprovoost/codeship-and-github-machine-users-with-2fa-8b980bc55d9e?source=user_profile---------8----------------",
        "title": "Codeship and Github machine users with 2FA \u2013 Lee Provoost \u2013",
        "text": "In my last article, I talked about how you can build Go apps with Codeship when you use vendoring with godep.\n\nOne thing I didn\u2019t touch on is the situation where you import your own custom (go gettable) package that lives in a private Github repository. The Codeship documentation explains how you need to remove your Codeship SSH key from Github and create a Codeship machine user.\n\nA good security best practice for Github accounts is to use SSH and enable 2 Factor Authentication. However, during the godep restore on Codeship, the build process times out on the following:\n\nThis means that the go get command is trying to access your repo using the https url, but your Github project will only accept SSH connections. This can be easily solved by adding one line to your Setup Commands on Codeship. Just before you install godep, add the following git global config line:"
    },
    {
        "url": "https://medium.com/@leeprovoost/using-godeps-vendoring-with-codeship-c79ab89439b5?source=user_profile---------9----------------",
        "title": "Using Godeps vendoring with Codeship \u2013 Lee Provoost \u2013",
        "text": "Yesterday, I switched from using Go 1.4 to Go 1.6 to build our binaries on Codeship. I also started using the new vendoring approach and settled on Godeps as our vendoring tool.\n\nWhilst the support for Go and custom Go versions on Codeship is great, it\u2019s sadly not that well documented.\n\nThe first thing you need to do is to change the version of Go. This Codeship page explains how you need to add the right commands to your Setup Commands section, but that doesn\u2019t help you with getting Godeps working.\n\nAfter bit of experimenting, I came up with the a solution. After switching to the Go 1.6 version in your Setup Commands section, you also need to install Godeps and restore and install those packages:"
    },
    {
        "url": "https://medium.com/@leeprovoost/validating-whether-a-struct-satisfies-an-interface-in-go-eea6ea5d209a?source=user_profile---------10----------------",
        "title": "Validating whether a struct satisfies an interface in Go",
        "text": "A good use case for interfaces in Go (golang) is when you want to create a mock database implementation for testing purposes.\n\nIf you are using the database/sql package then you\u2019ll have something like this:\n\nWe wrap the database connection in a struct (DB) and store that in our environment struct (env) that holds useful information about our application that we can pass around (e.g. pass to our HTTP handlers).\n\nWhen we\u2019re testing our code, we want to remove the dependency on the Postgres database (unless you\u2019re writing integration tests). We provide an alternative implementation of the database interaction code, like this:\n\nWhat we\u2019ve done now is created a new database struct (TestDB), but we don\u2019t need to worry about an actual database connection here so we can leave it empty. We then recreate functions with the same type signature as our original ones, but the implementation will be different. You could for instance just manually create a list of events and return that, as we\u2019re doing here.\n\nSo, how do you get your code to use this during testing? The key here is to create an interface and slightly tweak your environment struct:\n\nWe create an interface called DataStorer and use the same type signature as we\u2019ve used in the two previous examples with DB and TestDB. Go will figure out that the DB and TestDB implement the interface automatically. No need to explicitly define the relationship as you would do in Java. The important bit now is the change the type of the db variable in your environment struct from the DB struct to the DataStorer interface.\n\nThat means that we can now assign both a DB and a TestDB type to our environment struct.\n\nI quite like the assurance that my DB and TestDB structs are satisfying the DataStorer interface. Most likely your code will throw some errors if they don\u2019t, but just to be sure, I always add a little test like this:\n\nThis tries to assign an empty DB and TestDB struct to a variable (actually _ so we can discard it) with a DataStorer type. If DB or TestDB don\u2019t satisfy the interface, then you\u2019d get errors here."
    },
    {
        "url": "https://medium.com/@leeprovoost/aws-iam-and-s3-policies-marked-as-changed-by-terraform-50669585816d?source=user_profile---------11----------------",
        "title": "AWS IAM and S3 Policies marked as changed by Terraform",
        "text": "I\u2019ve bumped a couple of times into the situation where my IAM and S3 Bucket Policies were being marked as changed during the Terraform Plan phase whilst I hadn\u2019t changed anything.\n\nI decided to dig a bit deeper into the issue and found a Terraform pull request where this was being discussed. Notably the following:\n\nNote that this does not only apply to S3 bucket policies but also to IAM policies.\n\nThe second situation is quite common, take this example:\n\nWhen Terraform runs a refresh and compares it with the AWS state, then Terraform gets a normalised resource back. AWS tells us that there is only one element, Terraform\u2019s state has an array with one element. If you change the above code to reflect this, then you\u2019ll get rid of the message:\n\nI just discovered another case where policies are being marked as changed and that\u2019s when you\u2019re setting up an S3 bucket policy for your Elastic Load Balancing log files. The AWS documentation on the matter tells you to create a Principal with the Elastic Load Balancer Region ID:\n\nAfter normalising this Principal from an array with one element to just one element, it still got marked as changed.\n\nAfter some searching, I saw an example where someone was using the full ARN for the Principal.\n\nThat did the trick.\n\nThe Terraform team is working on trying to normalise the arrays automatically during the plan/refresh phase, but till then you can follow the above recommendations to get rid of those pesky messages."
    },
    {
        "url": "https://medium.com/@leeprovoost/using-terraform-to-create-a-credstash-table-and-permissions-912b9a5a4084?source=user_profile---------12----------------",
        "title": "Using Terraform to create a Credstash table and permissions",
        "text": "Credstash provides an easy way to securely store and retrieve credentials in your AWS environment.\n\nAfter setting up the right permissions to allow your EC2 instances to access your DynamoDB table, Credstash will set up your DynamoDB tables using the following command:\n\nI prefer to have my Terraform scripts provision the right table and permissions, so I\u2019ll take you step by step through the way I\u2019ve set it up.\n\nFirst, we need to create the DynamoDB table:\n\nThis is pretty much a translation of the setup function in the credstash.py source file. Credstash assumes that your DynamoDB table is named credential-store, but you can give it any name you want, as long as you then call the credstash command with the -t flag:\n\nThe arn output value will be used to create our policies.\n\nNow you need to set up an IAM Instance Profile that you can assign to your EC2 instance. That Instance Profile will have an IAM role, which will have one or more policies attached. Let\u2019s first set up the Instance Profile and Role:\n\nThe kms_key_guid can be retrieved from the Encryption Keys page (under IAM). It\u2019s the last part of the key\u2019s ARN:\n\nNext are the policies. There is a reader and a writer policy. You\u2019d typically only need a reader policy on your EC2 instances."
    },
    {
        "url": "https://medium.com/@leeprovoost/get-lastinsertedid-when-using-postgres-and-golang-database-sql-package-ca55ea23c2d5?source=user_profile---------13----------------",
        "title": "Get LastInsertedId when using Postgres and Golang database/sql package",
        "text": "When you want to insert a row in a Postgres database using the Go database/sql package, then you\u2019ll be doing something like this:\n\nWhat if you are interested in finding out what the auto-incremented database ID is for this INSERT? The Result type has a function called LastInsertedId() but when you try to run that with Postgres it will tell you that is not supported.\n\nIf only I had read the documentation properly, then I\u2019d know that the pq package documentation states this:\n\nSo if we take our initial example and change that according to the pq documentation, then we\u2019ll get this:"
    },
    {
        "url": "https://medium.com/@leeprovoost/securely-connecting-to-an-aws-rds-postgres-database-1356152a9830?source=user_profile---------14----------------",
        "title": "Securely connecting to an AWS RDS Postgres database",
        "text": "It took me a little bit of investigation on how to securely connect to an AWS RDS Postgres database from my Mac.\n\nGet your RDS Postgres instance up and running, make sure you have the Internet Gateway Route added to your Route Table, otherwise you won\u2019t be able to connect to it.\n\nInstall psql on your Mac, I use homebrew:\n\nDownload the AWS RDS pem file from the Amazon website and store it somewhere on your local machine. I\u2019ve renamed it to awsrds.pem and stored it in the following location:\n\nWhen you follow the AWS documentation then the examples show you to use command line flags:\n\nWhen you then try to add:\n\nIt will give you the following error:\n\nThat\u2019s because the sslmode option is only possible when you start the psql connection using a connection string:"
    },
    {
        "url": "https://medium.com/@leeprovoost/suppressing-accept-incoming-network-connections-warnings-on-osx-7665b33927ca?source=user_profile---------15----------------",
        "title": "Suppressing Accept Incoming Network Connections warnings on OSX",
        "text": "I recently started using fresh (https://github.com/pilu/fresh) to monitor my Go files during development. It monitors your source files and rebuilds your application and restarts your server when changes are detected.\n\nLovely tool, but on OSX I kept receiving a warning: \u201cDo you want the application xxx to accept incoming network connections?\u201d. EVERY. SINGLE. TIME.\n\nSome people tell you to sign the app to avoid this. Unfortunately, that doesn\u2019t work.\n\nThing is that fresh constantly rebuilds your app. Generating a new, unknown, unsigned, and untrusted application. So OSX continues complaining about it.\n\nI very coincidentally stumbled on a golang-nuts Google Groups discussion where they point out that you need to explicitly serve your server from localhost.\n\nThey got this solution from a live coding session with Brad and Andrew on Youtube.\n\nThe way I do it is to have a command line flag (but you can use an environment variable as well) that tells the app what environment it runs in (e.g. DEV, PRD) and then you check that in your main() code:"
    },
    {
        "url": "https://medium.com/@leeprovoost/the-following-paths-are-ignored-by-one-of-your-gitignore-files-19de007c4e42?source=user_profile---------16----------------",
        "title": "The following paths are ignored by one of your .gitignore files\u2026",
        "text": "I\u2019m currently building a Go (golang) web app and when I started to manually add some Bootstrap files, I received the following error:\n\nThat surprised me, I didn\u2019t add bootstrap to my .gitignore file. In addition, it started to exclude some other files and folders, seemingly randomly.\n\nTurns out that the default Github Go .gitignore file has the following couple of lines:\n\nThis means that the bootstrap-3.3.5 matches the pattern (*.5). To resolve, remove the offending lines and you\u2019re good to go (no pun intended)."
    }
]