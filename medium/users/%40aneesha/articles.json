[
    {
        "url": "https://towardsdatascience.com/topic-modeling-for-everybody-with-google-colab-2f5cdc99a647?source=user_profile---------1----------------",
        "title": "Topic Modeling for Everybody with Google Colab \u2013",
        "text": "Welcome to 2018! You can now find topics in text without installing any libraries or writing a line of python code. All made possible by Google Colab, a customized collaborative Jupyter Notebook that can be hosted on Google Drive. The fantastic Scikit-Learn library that includes two topic modeling algorithms is installed by default on Google Colab, making it really easy to start finding topics in text.\n\nThe aim of this blog post and the accompanying Google Colab Notebook was to made topic modeling accessible to a broader audience. Topic modeling algorithms such as Non Negative Matrix Factorization (NMF) and Latent Dirichlet Allocation (LDA) find the main topics or themes in a document collection. The document collection could be either short documents such as tweets or free text survey responses or longer documents such as blog posts or news articles. The NMF and LDA algorithms have two features that a beneficial to text clustering and not present in other algorithms like k-means. Both algorithms take a document collection as input and return the main words in a topic and the documents that belong to a topic \u2014 a feature that makes the output interpretable. NMF and LDA also support overlap between topics (i.e. documents can belong to multiple topics). I\u2019d particularly like to see researchers and qualitative content analysts start to use topic modeling algorithms and now they can, thanks to a simple Google Colab Notebook that can process data from a Google Sheet. Just follow these simple steps:\n\nThe release of a Google Colab Notebook that is able to perform topic modeling on textual data from a Google Sheet, has removed all the technical roadblocks to get started with topic modeling. The NMF and LDA topic modeling algorithms can be applied to a range of personal and business document collections. Some examples to get you started include free text survey responses, customer support call logs, blog posts and comments, tweets matching a hashtag, your personal tweets or Facebook posts, github commits, job advertisements and technical articles. If you think of a new way to apply topic modeling with the Google Colab Notebook, please post your example in the comments section."
    },
    {
        "url": "https://itnext.io/learning-maths-for-machine-learning-and-deep-learning-part-2-ebbbc918724?source=user_profile---------2----------------",
        "title": "Learning Maths for Machine Learning and Deep Learning (Part 2)",
        "text": "I could not believe the response I got for my previous blog post learning maths for Machine Learning and Deep Learning. There are definitely lots of people like me, who are interested in learning math in greater depth. I\u2019ve returned in 2018 with an updated list because I\u2019ve been totally blown away by resources I\u2019ve recently discovered.\n\nClick here to share this article on LinkedIn \u00bb\n\n3Blue1Brown has created an amazing youtube video series entitled \u201cThe Essence of Linear Algebra\u201d. The series of videos are highly visual and 3Blue1Brown explains linear algebra concepts from a geometric perspective. I must admit that 3Blue1Brown offers explanations and intuitions on linear algebra that I\u2019d wish were taught in all books and lectures. I certainly found myself wishing that I\u2019d had this resource way back when I was a first year engineering student. The custom animations are programmed in Python by 3Blue1Brown.\n\n\u201cThe Essence of Calculus\u201d is another gem from 3Blue1Brown. Also a youtube video series with custom animations, the series will make you feel like you discovered Calculus.\n\nTerence Parr and Jeremy Howard (yes thats the same Jeremy Howard from fast.ai fame) explain Matrix Calculus from first principles. If you have programmed a neural network and implemented back propagation, this resource is the next step in completely understanding the underpinning mathematics.\n\nStill a work in progress book but chapters for Analytical Geometry, Linear Algebra and Vector Calculus look intuitive and comprehensive.\n\nThat\u2019s all for the moment. Please share any useful resources you find in the comments. All the best in your Math travels\u2026."
    },
    {
        "url": "https://becominghuman.ai/enriching-word-vectors-with-lexicon-knowledge-and-semantic-relations-an-efficient-retrofitting-bcb5f1208a3e?source=user_profile---------3----------------",
        "title": "Enriching Word Vectors with Lexicon Knowledge and Semantic Relations: An Efficient Retrofitting\u2026",
        "text": "Word2Vec and Glove are two popular algorithms that produce word vectors or word embeddings. Both algorithms work in an unsupervised manner to determine vector representations of words (i.e., they map words to a latent dimensions). Glove is trained using corpus word-word co-occurrence statistics. The Word2Vec skip-gram algorithm uses a log-linear classifier and a continuous projection layer to predict words within a context window. Word vectors have been useful in a multitude of tasks such as sentiment analysis, clustering and classification and have by far replaced manually crafted semantic lexicons. I still however believe that valuable semantic information is captured in semantic lexicons (e.g., Paraphrase database, Framenet and Wordnet) and have wondered if there was a way to both learn word vectors in an unsupervised manner yet incorporate the knowledge captured in semantic lexicons as well. This blog post illustrates the use of an amazing retrofitting algorithm (Faruqui et al., 2015) that is able to apply semantic relations from any lexicon to pre-built word vectors.\n\nWhile a few techniques have been published that are able to add lexicon knowledge to word vectors, most of these techniques add an objective while the word vector algorithm is being trained. The retrofitting algorithm (Faruqui et al., 2015) on the other hand is able to apply must-link semantic relations on any pre-built word vector (Glove, Word2Vec, and even your own trained word vectors). The retrofitting algorithm is also extremely fast!!! A direct quote from the paper: \u201cabout 5 seconds for a graph of 100,000 words and vector length 300\u201d. Even more amazingly the implementation of the algorithm code is open source, implemented in Python and contains lexicons you can immediately use. In this blog post I\u2019ll describe the algorithm and then take you step by step through applying the algorithm to a pre-built word vector. Fig 1 compares a Glove word vector retrofitted with knowledge from the Paraphrase database, with the output from the original word vector for the word \u201cEmpathy\u201d .\n\nThe algorithm takes a matrix of word vectors and a graph of semantic relationships from the lexicon as input. The algorithm then learns a new matrix with a dual objective of trying to keep neighbouring words from the original matrix close together and at the same time placing similar words from the semantic lexicon in the same neighbourhood. The most impressive aspect of the paper is the manner in which the objective is trained \u2014 rather than use SGD, a highly optimised belief propagation algorithm is used.\n\nInstructions for running the algorithm are in the Github repo readme. The code is command line driven and you need to supply the word vector file (in txt format), the lexicon file, the number of iterations for the algorithm to run (10 is sufficient) and the output file. In the example below I have used the glove.6B.50d.txt word vector and the Paraphrase database. The code repo also includes Framenet and Wordnet. The word vectors must be in txt format. You are also not restricted to using an existing lexicon. If you have lists of words or rules for words that are similar (i.e., must-link rules or constraints), simply add these to the required format (space separated word lists on each line) and run the retrofitting algorithm.\n\nThe Gensim library is used to load and compare the original and retrofitted word vectors. Gensim is only able to load vectors in Word2vec format but provides helper scripts to convert from Glove to Word2vec.\n\nNext import gensim, numpy, matplotlib and TSNE. We also set up the Jupyter notebook for interactive matplotlib.\n\nThe display_closestwords_tsnescatterplot() method was introduced in a previous blog post. The method takes a Word2vec model and only displays a plot of the words that are closest to a given word.\n\nNow we can load the original word vectors and the retrofitted vectors as separate gensim models and use the display_closestwords_tsnescatterplot() method to evaluate how the neighbourhood of words around the specified word has changed.\n\nIn Figure 2 it is easy to see the improvement the retrofitting technique has made to the words neighbouring \u201cHappy\u201d. Words like \u201cpleased\u201d, \u201cdelighted\u201d and \u201cglad\u201d are now included that were not present in the original word vectors. Retrofitting is particularly promising especially when used with word vectors that are smaller in dimensionality (e.g., the glove word vectors used only had 50 latent dimensions) or created from a small corpus.\n\nThe full source code is also available as a Jupyter Notebook:\n\nThe retrofitting algorithm is currently only able to support must-link constraints (i.e., it is able to pull similar words together). There may however be cases when you need to add cannot link constraints (i.e., words that must not be places together or words that repel each other). Mrk\u0161i\u0107 et al (2016) has proposed an extension that adds repulsion rules. The source code for the Mrk\u0161i\u0107 algorithm is also available and will be covered in a future blog post."
    },
    {
        "url": "https://medium.com/@aneesha/using-tsne-to-plot-a-subset-of-similar-words-from-word2vec-bb8eeaea6229?source=user_profile---------4----------------",
        "title": "Using TSNE to Plot a Subset of Similar Words from Word2Vec",
        "text": "I needed to display a spatial map (i.e., scatterplot) with similar words from Word2Vec. I could only find code that would display the all the words or an indexed subset using either TSNE or PCA. I\u2019m sharing the Python code I wrote as a Gist. The code uses the fantastic gensim library as it provides easy access to the raw word vectors and a great api to perform similarity queries. The code performs the following tasks:\n\nFigure 1 shows the words most similar to \u201cMadonna\u201d. No surprise that \u201cLady_Gaga\u201d shows up. As gensim can load Glove pre-trained vectors, the code can easily be adapted to support Glove as well. I\u2019ll be using the code in a follow up blog post on adding lexicon knowledge to an embedding. Have Fun!"
    },
    {
        "url": "https://medium.com/@aneesha/es6-syntax-prep-for-react-part-1-fc1be7d18da3?source=user_profile---------5----------------",
        "title": "ES6 Syntax Prep for React (Part 1) \u2013 Aneesha Bakharia \u2013",
        "text": "I dived straight into React and slowly discovered that if I\u2019d learnt a little some of the new ES6 syntax, that my progress would have been greatly accelerated. I\u2019m writing this blog to cover the ES6 syntax magic I found I had to go read up on, while learning React. I must admit that I\u2019ve learnt to love ES6 syntactical magic and found the language improvement to be a big time saver. I\u2019ve included code snippets on Code Pen so you can play with the code without needing to install Babel or Webpack. This blog posts includes covers the new variable declaration types (let and const), template literals, object and array de-structuring, the spread operator and fat arrow functions.\n\nYou know can declare constants separately from variables. The const keyword is used to declare constant, the advantage being that if you accidentally try to change a constants value, you\u2019ll receive an \u201cUncaught TypeError: Assignment to constant variable\u201d error. By convention constants such as an API key are named with uppercase characters (e.g., APIKEY). Block scoped variable declaration is achieved with the let keyword.\n\nI totally love template literals. Its always been tedious to concatenate strings together or embed variables within strings in Javascript. Template libraries such as Handlebars used to be required. With ES6 you just place a string within backticks and can embed a variable using ${variable_name}. It gets even cooler, any javscript within ${} gets evaluated!\n\nDe-structuring provides an easy way assign multiple values from an array or object to variables in a single line of code. De-structuring also simplifies access syntax as once object properties have been de-structured, you can simply just refer to them by there new name without needing to use object syntax.\n\nThe Spread Operator aka the magic three dots \u2026 My initial response to the spread operator was rather unkind. After I used it for the first time, I actually felt like I could not code without it. There are really so many uses for the spread operator and I\u2019ve tried to illustrate each with examples. Whenever you see the spread operator refer to it as \u201ctake everything\u201d \u2014 this has helped while reading code. So \u2026array1 means take everything from array1 and [\u2026array1, 1, 2, 5] then means take everything in array1 and add 1, 2, and 5 as elements and return a new array.\n\nThe spread operator can also be used to pass multiple values to a function, a feature that had sadly been missing from Javascript. You can also use it grab multiple object properties and place them in a variable (i.e. use them with object de-structuring).\n\nFat arrow functions (=>) just provide a quick way to define functions without using the function keyword. Its much easier than ever before to write single line functions.\n\nI\u2019m sure you\u2019ll find many practical ways to use what I covered in Part 1 within your React adventures. Map, Filter and Reduce will be covered in Part 2 with an emphasis on using these methods to render React components. Part 3 will cover currying which is core to understanding how a Redux store gets connected to a container component."
    },
    {
        "url": "https://towardsdatascience.com/learning-maths-for-machine-learning-and-deep-learning-5509c097ee83?source=user_profile---------6----------------",
        "title": "Learning Maths for Machine Learning and Deep Learning",
        "text": "While I did learn a lot of maths while doing my engineering degree, I forgot most of it by the time I wanted to get into Machine Learning. After I graduated I never really had a need for any of the maths. I did a lot of web programming which relied on logic and I can honestly say that with each system with the word \u2018Management\u2019 in the title I lost a third of my math knowledge! I\u2019ve programmed extensions for Learning Management Systems, Content Management Systems and Customer Relationship Management Systems \u2014 I\u2019ll leave you to figure out how much math apptitude I had after working with these systems. At the moment I\u2019ve got good data science skills and can use a variety of ML and DL algorithms. I\u2019ve successfully completed a number of MOOCs (e.g., Deep Learning Foundations from Udacity and Andrew Ng\u2019s new Coursera courses). I can use Scikit Learn, TensorFlow and Kera\u2019s. \u2026. but I have rough ideas for creating new variants of algorithms. At the moment I really want to create a new kind of interactive topic modeling algorithm. I\u2019ve felt stuck due to my lack of maths knowledge. In my travels trying to re-learn some basic maths, I\u2019ve come across a couple of books that have been written by people with the art of explanation. These books have made a tremendous difference as they are able to convey complex concepts in a very simple manner. I am writing this blog post to share these great resources especially for programmers. The books cover Calculus and Linear Algebra. I\u2019ve not found an equivalent Probability and Statistics book yet \u2014 If you know of one please leave a comment or tweet Aneesha Bakharia.\n\nLearn calculus from a book written in 1914! The pdf for the book is freely available. This book is simply amazing. The English is a bit old style but the explanations are timeless. Thompson makes calculus super easy. Optimization of a cost function is core to ML and DL and this book will help you understand the basics of minimization. Those update rules in gradients decent won\u2019t seem like magic anymore. Just read the prologue \u2014 its set the tone for the rest of the book\u2026\n\nMost Linear Algebra books start easy but then concepts like image, basis, dimension, orthogonalization, eigenvectors are introduced in a completely abstract way. Most Linear Algebra books fail to even introduce real world applications and its hard to see where or why you would use the math. Matrix multiplication is a good example of something I learnt but never truely understood (i.e., why is was not performed element by element). Coding the Matrix is different! You actually get to build your own linear algebra library while improving your Python programming skills! The book is full of practical computer science applications (e.g. fix the perspective of a whiteboard photograph)."
    },
    {
        "url": "https://medium.com/@aneesha/beyond-bag-of-words-using-pytextrank-to-find-phrases-and-summarize-text-f736fa3773c5?source=user_profile---------7----------------",
        "title": "Beyond bag of words: Using PyTextRank to find Phrases and Summarize text",
        "text": "There are numerous weaknesses with the bag of words model, especially when applied to natural language processing tasks, that graph ranking algorithms such as TextRank are able to address. TextRank is able to incorporate word sequence information. Bag of words simply refers to a matrix in which the rows are documents and the columns are words. The values matching a document with a word in the matrix, could be a count of word occurrences within the document or use tf-idf. The bag of words matrix is then provided to a machine learning algorithm. Using word counts or tf-idf, we are only able to identify key single word terms in a document. In this blog post, I will describe the TextRank algorithm which is able to identify multi-word phrases and summarize text. The PyTextRank library will also be introduced.\n\nThe TextRank algorithm was introduced in 2004 by Rada Mihalcea and Paul Tarau. TextRank is a graph ranking algorithm \u2014 this simply means that nodes in a graph can be scored using information from the global graph. A well-known graph ranking algorithm is Google\u2019s PageRank. In the context of text, words are nodes/vertices and the cooccurrence of words together forms a link/relationship between the words (i.e., an edge). Mihalcea and Tarau introduce a vertex ranking algorithm that takes into consideration edge weights. TextRank can be used for keyword extraction and text summarization.\n\nA brief outline of the keyword extraction process using TextRank:\n\nA brief outline of the sentence extraction process using TextRank:\n\nPyTextRank is a great library, but if you want to delve a little deeper into TextRank and learn to program it, I recommend starting with a simpler implementation. NLP for Hackers has a blog post on TextRank which only uses Numpy and NLTK \u2014 the graph ranking is implemented in pure Numpy.\n\nIts great to have an understanding of how TextRank works. We don\u2019t however need to implement the algorithm especially if you are using Python. PyTextRank is an amazing robust Python library that uses spaCy, datasketch and NetworkX. PyTextRank is even used by O\u2019Reilly Media in production.\n\nPyTextRank includes a Jupyter Notebook that provides step by step instructions for loading a json file that contains the text and displaying the output of the TextRank algorithm.\n\nThis is the example paragraph used by most multi-word expression finding algorithms:\n\nIn Example 2, TextRank is run over the opening paragraph of this blog post. TextRank does a good job on the keywords but misses \u201cbag of words\u201d because only nouns and adjectives are used. The top 2 sentences are the first 2 sentences of the paragraph which I think provide a good summary.\n\nIn a future blog post I will show how TextRank can be used to summarize the output of a topic model. Till then have fun with algorithms\u2026."
    },
    {
        "url": "https://towardsdatascience.com/improving-the-interpretation-of-topic-models-87fd2ee3847d?source=user_profile---------8----------------",
        "title": "Improving the Interpretation of Topic Models \u2013",
        "text": "In my last blog post, I used the Non Negative Matrix Factorization (NMF) and Latent Dirichlet Allocation (LDA) algorithms implemented in the amazing Scikit Learn machine learning Python library, to find topics in a document collection. The output of the derived topics involved assigning a numeric label to the topic and printing out the top words in a topic. It is common practice to simply just print the top words for each topic \u2014 a lot of the topic model browsers, visualisations and examples on the open web do this! Just displaying the top words in a topic however, may not help a user to understand what each topic is about or determine the context in which the words are used. Only displaying the top topic words fails to take advantage of all of the data being returned by both of the algorithms. In this blog post I\u2019ll explain the matrices that both NMF and LDA return, include the code to print out the top documents in a topic and discuss ideas I have to improve the interpretation of derived topics especially when lengthy documents are included in the dataset.\n\nBoth NMF and LDA take a bag of words matrix (no documents * no words) as input. In the bag of words matrix, documents are represented as rows and words are represented as columns. Both algorithms also require the number of topics (k) that must be derived as a parameter. The output produced by the topic modelling algorithms is then 2 matrices: a document to topics matrix (no documents * k topics) and a topics to words matrix (k topics * no words). Most topic model output only uses the topics to words matrix and displays the words with the highest weights in a topic. A better understanding of the topic can be gained by displaying the top documents in a topic as well which is relatively simple to do with Scikit Learn.\n\nLets start by writing a new display_topics() method, which takes both the words to topics matrix (H) and the topics to documents matrix (W) as arguments. The method also needs to take the document collection (documents) and number of top documents (no_top_documents) to display in additional to the words (feature_names) and number of top words (no_top_words) to display as arguments. The display_topics method prints out a numerical index as the topic name, prints the top words in the topic and then prints the top documents in the topic. The top words and top documents have the highest weights in the returned matrices. The argsort() method is used to sort the row or column of the matrix and returns the indexes for the cells that have the highest weights in order.\n\nWe need to obtain the word to topics matrix (H) and the topics to documents matrix (W) from both the NMF and LDA algorithms. The word to topics matrix (H) can be obtained from the component_ attribute of the model after .fit() is called. Getting the topics to document matrix, is a little tricky but after reading the Scikit Learn api documents for each algorithm it will all make sense. Calling the transform() method on the algorithm model will return the topic to document matrix (W). The complete code that obtains the H and W matrices from NMF and LDA and then calls the display_topics() method is included below:\n\nA tiny and I mean really tiny dataset is used to illustrate the printing of the top words and documents in a topic. The tiny tiny dataset has 2 topics which are about user interfaces and graphs/trees. There are 9 really short sentences that make up the dataset. The code below uses NMF and LDA to find 2 topics, print 4 top words and 4 top documents in a topic:\n\nThe topics derived from NMF and LDA are displayed below. Both NMF and LDA do a good job of finding what we know are the topics.\n\nNMF Topics\n\nTopic 0:\n\ntrees graph minors survey\n\n- Graph minors IV: Widths of trees and quasi-ordering\n\n- The intersection graph of paths in trees\n\n- The generation of random, binary, unordered trees\n\n- Graph minors: A survey\n\nTopic 1:\n\nuser time response interface\n\nA survey of user opinion of computer system response time\n\nRelation of user-perceived response time to error measurement\n\nThe EPS user interface management system\n\nHuman machine interface for Lab ABC computer applications\n\nLDA Topics:\n\nTopic 0:\n\nuser response time computer\n\n- A survey of user opinion of computer system response time\n\n- Relation of user-perceived response time to error measurement\n\n- The EPS user interface management system\n\n- Human machine interface for Lab ABC computer applications\n\nTopic 1:\n\ntrees graph human minors\n\n- Graph minors IV: Widths of trees and quasi-ordering\n\n- Graph minors: A survey\n\n- The intersection graph of paths in trees\n\n- Human machine interface for Lab ABC computer applications\n\nDisplaying full documents when printing out the topic is not going to be practical when the size of the documents are large. The technique is only directly useful for short documents (e.g., tweets) or single paragraph documents. A solution would be to only display the snippets within the document that includes any of the top words. In a future blog post, I\u2019ll post some Python code that implements this idea and provides a keywords-in-context view of a derived topic. Combining this idea with a visualization tool like LDAVis will make a really useful Topic Model Browser that will help users interpret and explore derived topics."
    },
    {
        "url": "https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730?source=user_profile---------9----------------",
        "title": "Topic Modeling with Scikit Learn \u2013 ML Review \u2013",
        "text": "Latent Dirichlet Allocation (LDA) is a algorithms used to discover the topics that are present in a corpus. A few open source libraries exist, but if you are using Python then the main contender is Gensim. Gensim is an awesome library and scales really well to large text corpuses. Gensim, however does not include Non-negative Matrix Factorization (NMF), which can also be used to find topics in text. The mathematical basis underpinning NMF is quite different from LDA. I have found it interesting to compare the results of both of the algorithms and have found that NMF sometimes produces more meaningful topics for smaller datasets. NMF has been included in Scikit Learn for quite a while but LDA has only recently (late 2015) been included. The great thing about using Scikit Learn is that it brings API consistency which makes it almost trivial to perform Topic Modeling using both LDA and NMF. Scikit Learn also includes seeding options for NMF which greatly helps with algorithm convergence and offers both online and batch variants of LDA.\n\nI won\u2019t go into any lengthy mathematical detail \u2014 there are many blogs posts and academic journal articles that do. While LDA and NMF have differing mathematical underpinning, both algorithms are able to return the documents that belong to a topic in a corpus and the words that belong to a topic. LDA is based on probabilistic graphical modeling while NMF relies on linear algebra. Both algorithms take as input a bag of words matrix (i.e., each document represented as a row, with each columns containing the count of words in the corpus). The aim of each algorithm is then to produce 2 smaller matrices; a document to topic matrix and a word to topic matrix that when multiplied together reproduce the bag of words matrix with the lowest error.\n\nHow many topics? Well that is the question! Both NMF and LDA are not able to automatically determine the number of topics and this must be specified.\n\nI searched far and wide for an exciting dataset and finally selected the 20 Newsgoups dataset. I\u2019m just being sarcastic \u2014 I selected a dataset that is both easy to interpret and load in Scikit Learn. The dataset is easy to interpret because the 20 Newsgroups are known and the generated topics can be compared to the known topics being discussed. Headers, footers and quotes are excluded from the dataset.\n\nThe creation of the bag of words matrix is very easy in Scikit Learn \u2014 all the heavy lifting is done by the feature extraction functionality provided for text datasets. A tf-idf transformer is applied to the bag of words matrix that NMF must process with the TfidfVectorizer. LDA on the other hand, being a probabilistic graphical model (i.e. dealing with probabilities) only requires raw counts, so a CountVectorizer is used. Stop words are removed and the number of terms included in the bag of words matrix is restricted to the top 1000.\n\nAs mentioned previously the algorithms are not able to automatically determine the number of topics and this value must be set when running the algorithm. Comprehensive documentation on available parameters is available for both NMF and LDA. Initialising the W and H matrices in NMF with \u2018nndsvd\u2019 rather than random initialisation improves the time it takes for NMF to converge. LDA can also be set to run in either batch or online mode.\n\nThe structure of the resulting matrices returned by both NMF and LDA is the same and the Scikit Learn interface to access the returned matrices is also the same. This is great and allows for a common Python method that is able to display the top words in a topic. Topics are not labeled by the algorithm \u2014 a numeric index is assigned.\n\nThe derived topics from NMF and LDA are displayed below. From the NMF derived topics, Topic 0 and 8 don\u2019t seem to be about anything in particular but the other topics can be interpreted based upon there top words. LDA for the 20 Newsgroups dataset produces 2 topics with noisy data (i.e., Topic 4 and 7) and also some topics that are hard to interpret (i.e., Topic 3 and Topic 9). I\u2019d say the NMF was able to find more meaningful topics in the 20 Newsgroups dataset.\n\nNMF Topics:\n\nTopic 0: people don think like know time right good did say\n\nTopic 1: windows file use dos files window using program problem card\n\nTopic 2: god jesus bible christ faith believe christian christians church sin\n\nTopic 3: drive scsi drives hard disk ide controller floppy cd mac\n\nTopic 4: game team year games season players play hockey win player\n\nTopic 5: key chip encryption clipper keys government escrow public use algorithm\n\nTopic 6: thanks does know mail advance hi anybody info looking help\n\nTopic 7: car new 00 sale price 10 offer condition shipping 20\n\nTopic 8: just like don thought ll got oh tell mean fine\n\nTopic 9: edu soon cs university com email internet article ftp send\n\nLDA Topics:\n\nTopic 0: government people mr law gun state president states public use\n\nTopic 1: drive card disk bit scsi use mac memory thanks pc\n\nTopic 2: said people armenian armenians turkish did saw went came women\n\nTopic 3: year good just time game car team years like think\n\nTopic 4: 10 00 15 25 12 11 20 14 17 16\n\nTopic 5: windows window program version file dos use files available display\n\nTopic 6: edu file space com information mail data send available program\n\nTopic 7: ax max b8f g9v a86 pl 145 1d9 0t 34u\n\nTopic 8: god people jesus believe does say think israel christian true\n\nTopic 9: don know like just think ve want does use good\n\nIn my next blog post, I\u2019ll discuss topic interpretation and show how top documents within a theme can also be displayed.\n\nIt\u2019s amazing how much can be achieved with just 36 lines of Python code and some Scikit Learn magic. The full code listing is provided below:"
    },
    {
        "url": "https://medium.com/@aneesha/power-rail-blocking-with-an-arduino-aaca87bc98ca?source=user_profile---------10----------------",
        "title": "Power Rail Blocking with an Arduino \u2013 Aneesha Bakharia \u2013",
        "text": "You can save battery power! Instead of providing continuous power to your sensors, use an Arduino (or any microcontroller) to only provide power when you take a reading from a sensor. It is really quite a simple technique known as Power Rail Blocking. Power Rail Blocking involves providing power to a sensor (or other device) via a digital pin. The digital pin is set to HIGH when a sensor reading is taken and then set to LOW for the rest of the time.\n\nA simulation of Rail Power Blocking was made using the amazing and wonderful 123D Circuits: https://123d.circuits.io/circuits/1717500-power-rail-blocking-with-an-arduino/ I can\u2019t praise 123D Circuits enough! 123D Circuits even allows you to enter Arduino programming code.\n\nIn the example below, an Arduino is providing a fixed 5V to power a light sensor. The light sensor is made with a wheatstone bridge and a comparator. 2.7k Resistors, a photoresister (LDR) and a 741 Op Amp are used.\n\nThe Arduino is programmed to read the input from the comparator and if a HIGH input is received (i.e. the photoresister is illuminated) then turn the LED attached to PIN 12 on.\n\nRunning the example as a simulation is 123D Circuits, provides a slider to change the brightness of the photoresister. Two voltmeters are attached \u2014 one shows the voltage across the wheatstone bridge and the other the output of the comparator. When no light is received by the photoresistor, the voltage across the wheatstone bridge is 2.42V and the output of the comparator is 0V.\n\nWhen the photoresistor is illuminated (i.e. fully bright), the voltage across the wheatstone bridge goes negative, the comparator outputs 5V (HIGH) and the LED is turned on.\n\nIn the example above, we are however always providing the wheatstone bridge with 5V. In order to save power, we can use a digital pin to power the wheatstone bridge and only turn on the pin while we take a reading from the comparator. In the Arduino code below, pin 7 is used as the pbrail. In the loop routine , pbrail is turned on for 10ms, the comparator input is read, the LED is either turned on or off depending on the photoresistor illumination and then there is a 1 second delay before the loop is repeated.\n\nRunning a simulation with the pbrail used to power the wheatstone bridge works as planned, though it is hard to see accurate voltages. \u2026. but you can see them if you want using an oscilloscope, also included in 123D Circuits.\n\nThis is my first blog post on electronics! I plan to do many more. Next up maybe Tri-Stating with a Microcontroller. I hope you have enjoyed this post."
    },
    {
        "url": "https://medium.com/@aneesha/recursive-feature-elimination-with-scikit-learn-3a2cbdf23fb7?source=user_profile---------11----------------",
        "title": "Recursive Feature Elimination with Scikit Learn \u2013 Aneesha Bakharia \u2013",
        "text": "Datasets used to train classification and regression algorithms are high dimensional in nature \u2014 this means that they contain many features or attributes. In textual datasets each feature is a word and as you can imagine the vocabulary used in the dataset can be very large. Not all features however, contribute to the prediction variable. Removing features of low importance can improve accuracy, and reduce both model complexity and overfitting. Training time can also be reduced for very large datasets. In this blog post performing Recursive Feature Elimination (RFE) with Scikit Learn will be covered.\n\nRecursive Feature Elimination (RFE) as its title suggests recursively removes features, builds a model using the remaining attributes and calculates model accuracy. RFE is able to work out the combination of attributes that contribute to the prediction on the target variable (or class). Scikit Learn does most of the heavy lifting just import RFE from sklearn.feature_selection and pass any classifier model to the RFE() method with the number of features to select. Using familiar Scikit Learn syntax, the .fit() method must then be called.\n\nIn the example code below the iris dataset is used to illustrate the use of RFE. The iris dataset has 4 features (or attributes namely \u2018sepal length (cm)\u2019, \u2018sepal width (cm)\u2019, \u2018petal length (cm)\u2019 & \u2018petal width (cm)\u2019). ref.support_ returns an array with boolean values to indicate whether an attribute was selected using RFE e.g. for the iris dataset this array is [False True True True]. ref.ranking_ returns an array with positive integer values to indicate the attribute ranking with a lower score indicating a higher ranking e.g. the array for the iris dataset is [2 1 1 1] which means that sepal width, petal length and petal width all rank higher than sepal length.\n\nRFE is really that simple with Scikit Learn however it may take a while to run if the dataset has many attributes. In a future blog posts, feature ranking with information gain and performing RFE with cross-validation will be covered. Stay tuned\u2026.."
    },
    {
        "url": "https://medium.com/@aneesha/could-graphql-bring-better-query-capability-to-xapi-and-learning-record-stores-3c27deb6bc7a?source=user_profile---------12----------------",
        "title": "Could GraphQL bring better query capability to xAPI and Learning Record Stores?",
        "text": "So you believe the xAPI hype and insert a heap of statements into an Learning Record Store (LRS). The next sensible thing to do is to query the LRS. Unfortunately the LRS only provides an endpoint for retrieving full statements. You can\u2019t run queries that return aggregate results. Yep not even simple counts of xAPI verbs and object use. Whole statements that match get returned. \u2026 and queries are written as example statements. The idea is that you must retrieve via paged datasets the xAPI statements (over a 24 hour period) and then perform your analytics magic somewhere else. I\u2019ve recently been using GraphQL and have a few thoughts on how it may provide a better alternative to the current way statements in a LRS are queried.\n\nI understand the reason for the simplicity of retrieval syntax in the xAPI spec. The LRS could be implemented in any suitable backend (eg Postgres, HBase, MongoDB, ElasticSearch, etc) and query syntax over JSON document structures might differ. MongoDB query syntax is quite different from SQL. I also understand that with huge amounts of data in the LRS, you probably would want to either create a data warehouse (with data cubes) or cache the results of your custom analytics. However, I also think that more flexibility is needed in allowing statements to be retrieved. Key examples include retrieving related statements (such as all the threads in a discussion, responses to a quiz question, etc), flexible query operators (i.e., is, not, lt, lte, gt, gte, contains, icontains, startswith, endswith, iendswith, like, ilike), return selected JSON fields (the full statement may not be required) and yes basic aggregate counts. The major design features of GraphQL are described here: https://code.facebook.com/posts/1691455094417024/graphql-a-data-query-language/\n\nSure the xAPI spec can be extended to include basic reporting. Then the current vendors and open source solutions can also be extended each individually. This would take time and money \u2014 both for the development of the spec and by the vendors. An easier option would be to adopt GraphQL. I think GraphQL has most of what is needed to move forward. GraphQL was developed by Facebook as a way to allow developers to control how data is returned \u2014 very useful in service oriented architectures. A number of implementations for Postgres and MongoDB are also starting to become available.\n\nNodal provides a great GraphQL Playground that illustrates some of the functionality I described above (even though they only have a partial implementation). There are examples that illustrate that only the specified fields are returned, query operator usage (such as is, not, lt, lte, gt, gte, contains, icontains, startswith, endswith, iendswith, like, ilike) and the ability to return structured/related statements (eg the Query to retrieve all Users their Threads, and Posts in Threads).\n\nGraphQL also has stricter typing. xAPI extensions at the moment don\u2019t have enforced typing. If xAPI moved to JSON-LD, it would be a step forward in determining data types in an automated manner for analytics. The JSON-LD typing to describe statements extensions may then easily map to the stricter typing required by GraphQL.\n\nWhat about simple aggregate counts? Well in the design of the custom schema for xAPI GraphQL, summary fields could be added and code written in the resolve methods to perform the custom queries.\n\nAnyway its just an idea I had for awhile which was reinforced when I saw the Nodal GraphQL Playground. I encourage you to have a play in the Nodal GraphQL Playground and provide feedback."
    },
    {
        "url": "https://medium.com/@aneesha/timeseries-forecasting-with-the-forecast-r-package-and-shiny-6fa04c64196?source=user_profile---------13----------------",
        "title": "Timeseries Forecasting with the forecast R package and Shiny",
        "text": "I\u2019m more of a Python person \u2014 I love Python\u2019s syntax, the tons of Machine Learning libraries in Python and Django (for web dev). \u2026but I swap to R when necessity calls, and necessity usually takes the form of a useful library for which there is no Python alternative. Sometimes its just a waste of time to port to another language and easier just to learn to load data and use the library. This pretty much sums up my relationship with R.\n\nI\u2019ve mainly used Machine Learning algorithms (i.e., classification and clustering) and not done much with Timeseries Forecasting. I did once investigate what was possible with Exponential Smoothing (ETS), ARIMA models and Timeseries decomposition. I looked for a good implementation of these algorithms and found the wonderful Forecast R package written by Rob J Hyndman. Around the same time I heard about Shiny and thought I\u2019d see if I could learn to use both at the same time. In under an hour I had a simple prototype UI that allowed a dataset to be selected, enter the months to forecast ahead and produced 3 graphs which included the timeseries decomposition, ARIMA forecast and ETS forecast. I put the code up on Github as ShinyTimeseriesForecasting in 2013 and never thought much about it again. This week (Feb 1, 2016) I came across an article about using Timeseries Forecasting on IoT datasets on Data Science Central. It occurred to me that Timeseries Forecasting would be useful to identify trends and forecast into the future for IoT data. This prompted me to resurrect the ShinyTimeseriesForecasting app and deploy it to shinyapps.io \u2014 you can have a play here: https://aneesha.shinyapps.io/ShinyTimeseriesForecasting/\n\nOnce a data is loaded as a timeseries object, the decompose method returns the trend, seasonal, random and observed components for the dataset which can easily be plotted using plot().\n\nThe power of the Forecast package can be illustrated by what it is able to do in 2 lines of code. auto.arima() finds the best ARIMA model and forecast method uses the model to forecast out to the specified time period.\n\nThe Forecast package also includes ETS models which once fitted can also be forecast out to a specified time period and plotted."
    },
    {
        "url": "https://medium.com/@aneesha/visualising-top-features-in-linear-svm-with-scikit-learn-and-matplotlib-3454ab18a14d?source=user_profile---------14----------------",
        "title": "Visualising Top Features in Linear SVM with Scikit Learn and Matplotlib",
        "text": "A classifier need not be a black-box! I know we are often dealing with very high dimensional data but particularly with a linear Support Vector Machine, it is possible to take a peek at the top features. This blog post is not about using feature selection or ranking using information gain metrics \u2014 I\u2019ll cover that in a follow-up blog post. In this post I am going to cover how to visualise the top feature coefficients after an SVM model has been created in Scikit Learn. I have found the technique to be very useful especially when dealing with binary text classification.\n\nI\u2019ll start by sharing a good tip for working with Scikit Learn. Don\u2019t just stick with the known public API \u2014 you need to explore the _methods and attributes_. After applying a CountVectorizer you can for example get a vocabulary count using .vocabulary_.\n\nOnce a linear SVM is fit to data (e.g., svm.fit(features, labels)), the coefficients can be accessed with svm.coef_. Recall that a linear SVM creates a hyperplane that uses support vectors to maximise the distance between the two classes. The weights obtained from svm.coef_ represent the vector coordinates which are orthogonal to the hyperplane and their direction indicates the predicted class. The absolute size of the coefficients in relation to each other can then be used to determine feature importance for the data separation task.\n\nI\u2019ll share a method that takes the fitted linear SVM model, feature names (obtained with .get_feature_names()) and the number of top features to use as parameters and produces a bar chart using Matplotlib.\n\nAs you can see below, the plot provides useful insight into what features (words) are being used by the model to make the positive and negative classifications from a sentiment dataset. Some features seem reasonable while others such as \u201817\u2019 and \u2018bit\u2019 are not. In any case visualising the top feature coefficients makes the mystery behind what the linear SVM classifier has learnt more transparent.\n\nI\u2019ll conclude with a link to a good paper on SVM feature selection. In the paper the square of the coefficients are used as a ranking metric for deciding the relevance of a particular feature. In a future blog post I\u2019ll cover feature ranking and selection using Information Gain."
    },
    {
        "url": "https://medium.com/@aneesha/thoughts-on-a-gui-for-scikit-learn-and-tensorflow-d41caa812e3e?source=user_profile---------15----------------",
        "title": "Thoughts on a GUI for Scikit Learn and TensorFlow \u2013 Aneesha Bakharia \u2013",
        "text": "I\u2019ve been thinking for a while about building a GUI for Scikit Learn and given that I am currently taking the Google Deep Learning course on Udacity, I thought I would extend my original idea to TensorFlow. This post covers my reason for building the tool, some of the requirements and my design ideas for bringing the project to life.\n\nScikit Learn is a great library. I use it lots in all my data science projects \u2014 it has clustering, classification (inc Affinity Propagation) and dimension reduction (inc Non-negative Matrix Factorisation and tsne) algorithms as well as experiment setup (e.g., splitting a dataset into a train and test set), cross validation and parameter tuning (e.g., gridsearch) functionality. Scikit Learn is well maintained and actively developed. I wrote Scikit Learn code from scratch for my first few projects. As I got more experienced I created a few abstractions but ultimately started to copy and paste code. At this point I noticed a workflow that was really dependant upon the choices I was making. These choices were either the type of algorithm or related to the experiment (evaluation) setup. I realised that a GUI that could facilitate these choices would reduce setup and coding time.\n\nI\u2019ll be frank \u2014 I don\u2019t like visual tools that hide code or stop me from interacting with code. I like the idea of the GUI generating either an IPython Notebook or just Python code once you have made all your experiment setup choices. The GUI could even be an IPython widget that generates cells in the IPython Notebook that can be edited.\n\nI also don\u2019t like visual tools that employ a flowchart metaphor. There is a lot of dragging and dropping. Also tools such as Orange already exist. I don\u2019t like the step by step wizard interfaces either.\n\n\u2026but there are also things that I do want. I want to make Data Science using Scikit Learn easier for both experienced users as well as users that never want to touch Python code.\n\nI have a few rough ideas for the GUI and I\u2019m about to start prototyping. I\u2019m still very much figuring out how everything will work. The GUI metaphor will be a tree-based outline editor. As choices are made the tree expands, change choices and the child tree objects get modified. Each node of the tree will be easily translatable to python code for Scikit Learn.\n\nI have a defined workflow of choices for supervised machine learning, which will be the first prototype I build. The choices include selecting the algorithms, selecting parameters for the algorithms, running cross-validation (perhaps viewing scores, confusion matrices and plotting learning curves), performing feature selection and feature engineering and persisting the best model.\n\nI\u2019ll post a follow-up post soon that will include a link to the prototype. If you have any feature requests or suggestions please include in the comments below."
    },
    {
        "url": "https://medium.com/@aneesha/svm-parameter-tuning-in-scikit-learn-using-gridsearchcv-2413c02125a0?source=user_profile---------16----------------",
        "title": "SVM Parameter Tuning in Scikit Learn using GridSearchCV",
        "text": "Recently I\u2019ve seen a number of examples of a Support Vector Machine algorithm being used without parameter tuning, where a Naive Bayes algorithm was shown to achieve better results. While I don\u2019t doubt that a simpler model produced by Naive Bayes might be better at generalising to held-out data, I\u2019ve only ever been able to achieve good results with an SVM by first performing parameter tuning. There is really no excuse not to perform parameter tuning especially in Scikit Learn because GridSearchCV takes care of all the hard work \u2014 it just needs some patience to let it do the magic.\n\nBefore trying any form of parameter tuning I first suggest getting an understanding of the available parameters and their role in altering the decision boundary (in classification examples). There are two parameters for an RBF kernel SVM namely C and gamma. There is a great SVM interactive demo in javascript (made by Andrej Karpathy) that lets you add data points; adjust the C and gamma params; and visualise the impact on the decision boundary. I suggest using an interactive tool to get a feel of the available parameters.\n\nYou don\u2019t need to use GridSearchCV and can write all the required code manually. Without GridSearchCV you would need to loop over the parameters and then run all the combinations of parameters. If you were then after a cross-validated result, you would also need to add the code to find the best average CV results across all the combinations of parameters. Rather than doing all this coding I suggest you just use GridSearchCV.\n\nUsing GridSearchCV is easy. You just need to import GridSearchCV from sklearn.grid_search, setup a parameter grid (using multiples of 10\u2019s is a good place to start) and then pass the algorithm, parameter grid and number of cross validations to the GridSearchCV method. An example method that returns the best parameters for C and gamma is shown below:\n\nThe parameter grid can also include the kernel eg Linear or RBF as illustrated in the Scikit Learn documentation.\n\nOne last thing \u2014 please always remember to include the parameters you selected in your publications, blog posts, etc \u2026.. It just makes for reproducible research!"
    },
    {
        "url": "https://medium.com/@aneesha/using-affinity-propagation-to-find-the-number-of-clusters-in-a-dataset-52f5dd3b0760?source=user_profile---------17----------------",
        "title": "Using Affinity Propagation to Find the Number of Clusters in a Dataset",
        "text": "Clustering and dimension reduction algorithms help you to explore a dataset. Clustering and dimension reduction are unsupervised learning algorithms i.e., they don\u2019t need labelled data to build a model. k-means is a popular clustering algorithm \u2014 you specify the the number of clusters (k) and it then finds the best cluster for each data instance. Choosing a good initial value for the number of clusters (k) can be problematic as k can be anything between 1 and the number of data instances. Finding the number of clusters is an active research field and techniques do exist (such as the Silhouette coefficient) but have varying success as the dimensionality of the data increases. I\u2019m not going to go into any of these other techniques to find k in this blog post. Instead I\u2019m going to focus on a fairly recent (2007) algorithm called Affinity Propagation which is able to cluster data and find the number of clusters simultaneously. The best thing is that Affinity Propagation is already included in a popular machine learning library for Python \u2014 Scikit Learn!\n\nThe Affinity Propagation algorithm was published in 2007 by Brendan Frey and Delbert Dueck in Science. The algorithm exchanges messages between pairs of data points until a set of exemplars emerges, with each exemplar corresponding to a cluster. The Affinity Propagation algorithm takes as input a real number s(k,k) for each data point k \u2014 referred to as a \u201cpreference\u201d. Data points with large values for s(k,k) are more likely to be exemplars. The number of clusters is influenced by the preference values and the message-passing procedure.\n\nScikit Learn includes the Affinity Propagation algorithm and has demo code. I\u2019ll include sample code and a plot of dummy data with the exemplars linked to data points within the cluster. Note that a preference value can be specified (in this case it is set to -50) but if it is not specified as an argument, it will be set to the medium of the input similarities.\n\nIn conclusion, I\u2019ve found Affinity Propagation to be a useful clustering algorithm that provides a viable alternative to k-means. I\u2019ve used Affinity Propagation both as a standalone clustering algorithm and as a way to determine a good starting point for selecting the number of clusters (which can then be used in conjunction with other dimension reduction and clustering algorithms)."
    },
    {
        "url": "https://medium.com/@aneesha/quick-social-media-sentiment-analysis-with-vader-da44951e4116?source=user_profile---------18----------------",
        "title": "Quick Social Media Sentiment Analysis with VADER \u2013 Aneesha Bakharia \u2013",
        "text": "I recently came across a very useful open source python library that performs sentiment analysis out of the box. The library is called VADER (Valence Aware Dictionary and sEntiment Reasoner) and the source code is available on Github. With VADER you can be up and running performing sentiment classification very quickly even if you don\u2019t have positive and negative text examples to train a classifier or want to write custom code to search for words in a sentiment lexicon. VADER is also computationally efficient when compared to other Machine Learning and Deep Learning approaches.\n\nVADER is a lexicon and rule-based sentiment analysis library that I have found to work well, even on short textual statements. VADER performs well on text originating in social media and is described fully in a paper entitled \u201cVADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.\u201d published at ICWSM-14. VADER is able to include sentiment from emoticons (e.g, :-)), sentiment-related acronyms (e.g, LOL) and slang (e.g, meh).\n\nVADER is a python library and can be installed using pip:\n\nOnce VADER is imported, the sentiment for a list of sentences can be found using the vaderSentiment() method:\n\nThe vaderSentiment() method returns the values to represent the amount of negative, positive, and neutral sentiment and also works out the compound sentiment value as a signed value to indicate overall sentiment polarity. The output for the code snippet above:"
    }
]