[
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-siemens-autotuning-cnc-30x-faster-with-deep-reinforcement-learning-616a12b9533?source=user_profile---------1----------------",
        "title": "Bonsai & Siemens: Autotuning CNC 30x Faster with Deep Reinforcement Learning",
        "text": "Artificial intelligence is transforming industries from manufacturing to energy and supply-chain, enabling subject matter experts within these fields to tackle their most challenging \u2014 and costly \u2014 business problems.\n\nAs highlighted in the announcement we made this morning, we partnered with the Siemens Digital Factory Motion Control team to work on one of these problems: combining Siemens subject matter expertise with deep reinforcement learning to calibrate a real CNC machine faster than an expert human operator.\n\nLeveraging Bonsai\u2019s Platform, including our unique Machine Teaching technology, we did just that.\n\nA Siemens subject matter expert \u2014 an engineer with no background in AI \u2014 built an AI model that autotuned a real-life CNC machine more than 30x faster than the best operators. The machine was calibrated with expert-level precision, with one axis calibrating in just 13 seconds.\n\nThis achievement marks one of the first real-world industrial applications of deep reinforcement learning since DeepMind\u2019s notable HVAC results in 2016.\n\nIf you happen to be at the O\u2019Reilly AI Conference in New York make sure to come by my talk at 11am est; Deep reinforcement learning\u2019s killer app: Intelligent control in real world systems.\n\nInterested in learning more about the business impact of this accomplishment? Read the case study. You can also learn how to build deep reinforcement learning into your own real-world systems by visiting bons.ai."
    },
    {
        "url": "https://medium.com/@BonsaiAI/introducing-the-bonsai-simulink-beta-2638e9411456?source=user_profile---------2----------------",
        "title": "Introducing the Bonsai Simulink Beta \u2013 Bonsai \u2013",
        "text": "Bonsai was built on the core belief that the best way for machines to learn is to teach them.\n\nJust like we teach humans to solve problems, so can we teach machines using the expertise we already have. We can break down complex problems into simpler concepts, and let them practice solving those concepts one-by-one until a larger problem is solved.\n\nBonsai combines this Machine Teaching approach with cutting-edge deep reinforcement learning algorithms to optimize the operational efficiency of real-world systems.\n\nBut there\u2019s one more essential element: simulations.\n\nSimulations are key to building applied deep reinforcement learning models. These digital replicas of real-world environments allow enterprises to test and validate processes in simulation before trying them out on real, and expensive, systems.\n\nThere are many simulators on the market today, being used across a range of industries to assist subject matter experts in modeling the best processes and systems for their business problems.One simulator in particular, Matlab/Simulink, is extremely well-suited for modeling industrial control systems, and machine tuning processes, that can be very well optimized with deep reinforcement learning. But until now, applying cutting-edge AI to existing Simulink models has not been possible for the subject matter experts most familiar with the simulations themselves.\n\nToday we\u2019re excited to announce a new Simulink connector for the Bonsai Platform and the launch of the Bonsai Simulink Beta program. These tools apply deep reinforcement learning to existing Simulink models and enhance the performance of your real-world systems.\n\nAnyone enrolled in the Bonsai Simulink Beta program can leverage the Bonsai Platform to build deep reinforcement learning directly into their existing Simulink models. This program offers participants:\n\nApply now to the Bonsai Simulink Beta program, and start optimizing your Simulink model with deep reinforcement learning:"
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-ai-using-simulink-for-deep-reinforcement-learning-8dfd6f6af997?source=user_profile---------3----------------",
        "title": "Bonsai AI: Using Simulink for Deep Reinforcement Learning",
        "text": "This is the second post in our Simulation and Deep Reinforcement Learning (DRL) series. In our first post, we covered the benefits of simulations as training environments for DRL. Now, we\u2019ll focus on how to to make simulations + DRL work.\n\nIn the example below, we will train a Bonsai BRAIN using a Simulink model. The goal is to teach the BRAIN (an AI model built in the Bonsai Platform) how to tune a wind turbine and maximize the energy output of it by keeping it turned into the wind at an optimal angle.\n\nSimulink provides a great training environment for DRL as it allows 3rd parties like Bonsai to integrate and control simulation models from the outside. This ability is one of the basic requirements for simulation platforms to be feasible for Deep Reinforcement Learning using Bonsai AI. More requirements can be found here.\n\nThis Simulink Wind Turbine model is provided by The MathWorks. For this scenario, it represents a simple control problem that can be solved by applying reinforcement learning.\n\nFirst, we need to identify a control point within the model so Bonsai can take over inputs and outputs. We\u2019re doing this by inserting a Bonsai block into the model, replacing the existing control block.\n\nOnce training has completed, you can use the trained Bonsai BRAIN to get predictions.\n\n\u200dDuring training, users may need to modify reward functions to optimize learning time and results. A great resource on writing reward functions can be found here: Bonsai Training Video.\n\nSimulators are a crucial tool for reinforcement learning. Enterprises can use simulation models that reflect real-world business processes or physical realities and optimize them with Bonsai\u2019s reinforcement learning technology. Typically, there are no changes needed to the simulation model. If you\u2019ve missed our first post on how simulations can be used for training, please find it on our blog.\n\nBonsai can help you apply deep reinforcement learning technology and build intelligent control into your own industrial systems using Simulink as the training environment. If you are using Simulink and you want to try out Bonsai AI, join our beta program and get started here."
    },
    {
        "url": "https://medium.com/@BonsaiAI/simulators-the-key-training-environment-for-applied-deep-reinforcement-learning-698f7124388c?source=user_profile---------4----------------",
        "title": "Simulators: The Key Training Environment for Applied Deep Reinforcement Learning",
        "text": "Deep reinforcement learning (DRL) is one of the most exciting fields in AI right now. It\u2019s still early days, but there are obvious and underserved markets to which this technology can be applied today: enterprises that want to automate or optimize the efficiency of industrial systems and processes (including manufacturing, energy, HVAC, robotics, and supply chain systems).\n\nBut there is a key element for building applied DRL: simulation environments. In this blog, we\u2019ll tell you what simulators can do, why you need them, and how you can use the Bonsai Platform + simulators to solve real business problems.\n\nLet\u2019s start with defining the term simulation as it\u2019s quite an abstract concept. Simulations can range from flight simulators to simulations of electrical and mechanical components or models of entire cities.\n\n\u201cSimulation is the imitation of the operation of a real-world process or system over time.\u201d\n\nEssentially, there is some kind of system that has a number of inputs, applies some mathematical functions to these inputs, and delivers back an output in the form of data that can be visual (like a robotics simulator) or just pure data (like the energy simulator, EnergyPlus).\n\nSimulations have been used by computer scientists for quite some time, going back to the late 1950s. During the last 20 years, increased computing power and vast amounts of data have allowed simulations to dramatically increase in fidelity and value. Many leading industrial simulations match physical realities or business processes almost identically.\n\nA huge influence has been the evolution of the digital gaming industry. Gamers wanted a more immersive experience, requiring high fidelity graphics and more realistic behaviors of items within the virtual worlds. Gaming middleware companies developed and delivered powerful 3D and 2D physics engines over the past 30 years.\n\nBy utilizing some of these software products and a variety of mathematical libraries, enterprises are able to simulate complex systems with a large number of components that allow subject matter experts (SME) to test and evaluate systems prior to building them in the real world. Use cases include digital twins, robotics, tuning small and large industrial machines, electrical and physical systems of many kinds, and optimizing business processes like supply chains.\n\nWhile there exist a large number of custom and very specialized simulations based on a single model, there are also a number of simulator platforms which are able to run and simulate a basically infinite number of models. Examples are MATLAB Simulink (engineering and manufacturing), ANSYS (engineering), AnyLogic (supply chain), Gazebo (robotics), TRNSYS (energy), and many others.\n\n\u201cAn area of machine learning concerned with how software agents ought to take actions in an environment to maximize a cumulative reward\u201d.\n\nIn other words, RL trains an agent to learn a policy for how to act by trying a large number of actions in a given environment, optimizing for a defined reward function.\n\nDeep reinforcement learning (DRL) follows the same method, using a deep neural network to represent the policy.\n\nReinforcement learning requires a very high volume of \u201ctrial and error\u201d episodes \u2014 or interactions with an environment \u2014 to learn a good policy. Therefore simulators are required to achieve results in a cost-effective and timely way.\n\nJust imagine trying to teach a robot to walk by watching a real, physical robot try and fall 100,000 times before it could successfully and consistently walk. Or training an AI to play the boardgame GO by actually playing a human competitor for hundreds of thousands of games. Simulators allow these episodes to happen in a digital world, training an AI to reach its full potential while saving time and money.\n\nSome simulations model environments in which an agent can take continuous actions that impact the state of the environment; other simulations model settings where a discrete input creates a different output. Both of these types of simulations can be used for reinforcement learning.\n\nBonsai is an artificial intelligence platform that allows enterprises to program control into industrial systems, and the only commercially available product for programming control of industrial systems using deep reinforcement learning.\n\nUsing the Bonsai Platform, enterprises can build a BRAIN (an AI model), connect the simulator of their choice, and train the BRAIN in that environment to learn a desired behavior.\n\nTo learn more about building a simulation and applying DRL to your enterprise, head to our Getting Started page."
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-redmonk-what-is-deep-reinforcement-learning-32d21d29b151?source=user_profile---------5----------------",
        "title": "Bonsai + Redmonk: What is Deep Reinforcement Learning?",
        "text": "Deep reinforcement learning has generated tons of buzz for its ability to beat games like AlphaGo and Poker. But the technology has advanced to the point of being able to solve real business problems across industries like manufacturing, supply chain and energy optimization.\n\nWatch Bonsai\u2019s Kence Anderson and Redmonk co-founder and analyst, Stephen O\u2019Grady, give a brief overview of deep reinforcement learning, simulations and how enterprises can apply deep reinforcement learning to automate and optimize their own real-world business problems. Kence also demonstrates how the Bonsai Platform uses deep reinforcement learning to optimize the energy of a wind farm."
    },
    {
        "url": "https://medium.com/@BonsaiAI/deep-reinforcement-learning-models-tips-tricks-for-writing-reward-functions-a84fe525e8e0?source=user_profile---------6----------------",
        "title": "Deep Reinforcement Learning Models: Tips & Tricks for Writing Reward Functions",
        "text": "In this post, I\u2019m going to cover tricks and best practices for how to write the most effective reward functions for reinforcement learning models. If you\u2019re unfamiliar with deep reinforcement learning, you can learn more about it here before jumping into the post below.\n\nCrafting reward functions for reinforcement learning models is not easy. It\u2019s not easy for the same reason that crafting incentive plans for employees is not easy. We get things affectionately known as the cobra effect.\n\nHistorically, the government tried to incentivize people to assist them in ridding the area of cobras. If citizens brought in a venomous snake they had killed, the government would give you some money. Naturally, people started breeding venomous snakes.\n\nThe same thing happens in the real world. People always game the system.\n\nKeep this in mind when writing reward functions: You get what you incentivize, not what you intend.\n\nThe following examples highlight this well. The goal was to teach a robotic arm to grasp blocks and stack them on top of each other. (We ultimately succeeded; you can see how we did it here).\n\nBut we started with first simply trying to teach the robotic arm to move the blocks. In an early attempt, the reward function was to move the block as far away as possible from the arm. The engineer writing this reward was thinking \u201cThe arm will pick it up, go to full extension, and set the block down, thus moving the block as far as possible.\u201d\n\nExcept the arm is in a physics environment. It\u2019s familiar with the world. So the first thing it learns to do is smack it really, really hard to get it really, really far away:\n\nThen it learns that it can get it even further away by picking it up and throwing it. So it learns to chuck it and get it really, really far away.\n\nAs you\u2019re crafting your reward functions, which is major part of the task as you\u2019re building out reinforcement learning models, be sure to understand what your reward function is doing. And be sure that it\u2019s doing what you intended before you start a 8 hr long training run.\n\nHaving tooling, even tooling you build yourself, that lets you check if your model is doing what you wanted before you start training will save you inordinate amounts of time. At Bonsai, we\u2019ve crafted internal tools that let you drag a block through space and watch the reward function change as it gets dragged through space in a simulated environment so you can gauge if you\u2019re on the right track or not.\n\nReward shaping is a big deal. If you have sparse rewards, you don\u2019t get rewarded very often:\n\nIf your robotic arm is only going to get rewarded when it stacks the blocks successfully, then all the time it\u2019s off exploring far away it will never get any feedback. This takes a much logner time.\n\nYou want to instead shape rewards that get gradual feedback and let it know it\u2019s getting better and getting closer. It helps it learn a lot faster:\n\nA key to making this work is being able to decompose the reward functions in reasonable ways.\n\nWhen structuring the reward itself, how you structure them numerically makes a huge difference. If you structure positive rewards, the system will wanting to accumulate as much as possible. This can lead to interesting behavior.\n\nIf, for instance, your simulation allows the robotic arm to stack a block, yank it away, stack again and continue getting rewards\u2026then it will do that forever because its entire purpose is to get the highest reward possible.\n\nBe careful with positive rewards. You need to make sure you don\u2019t have a lot of reward near the terminals unless it\u2019s a massive step function from where you were really close to it.\n\nNegative rewards are different. Negative rewards incentivize you to get done as quickly as possible because you\u2019re constantly losing points when you play this game. That\u2019s an Important distinction as you build these out.\n\nWhen you\u2019re shaping your functions you need to understand the area that you\u2019re playing in. Here you have a region of 2D space where the goal is to get the agent to bottom left corner red square, but hitting a blue square means you crash. You don\u2019t want your reward function to look like this:\n\nYou want it to look like this:\n\nYou\u2019re going to go slower but you won\u2019t crash as much.\n\nShaping rewards makes a huge difference. Time spent here vs tinkering in simulation saves a lot of time.\n\nSometimes as you shape the reward functions, you need to think in terms of time as well as in terms of space.\n\nThis goes back to the importance of decomposing problems into smaller tasks. In the case of the robotic arm, we wanted it to pick up the block, then orient it, then stack it. Those are three distinct activities.\n\nWe know that it doesn\u2019t make sense for the arm to waste time trying to grasp the block while it\u2019s still too far away to reach it. So you can craft the reward functions and activation functions so that you don\u2019t spend a lot of time in areas where you can\u2019t hope to reasonably achieve your goal.\n\nIt\u2019s fine to have rewards functions that combine a few things when they\u2019re relatively simple. As these problems get larger and more complex, which happens pretty easily with real-world systems, you want to start thinking about using techniques like concept networks instead of just constantly making more and more complex reward functions.\n\nWant to learn more about deep reinforcement learning, reward functions and concept networks? Check out the following resources:"
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-tensorflow-the-value-of-an-abstraction-layer-for-building-industrial-ai-858f73077e7b?source=user_profile---------7----------------",
        "title": "Bonsai + TensorFlow: The Value of an Abstraction Layer for Building Industrial AI",
        "text": "TensorFlow is unquestionably a powerful tool for training AI models and a crucial part of the emerging AI ecosystem. While there\u2019s a steep learning curve for developers without extensive math backgrounds, TensorFlow is a great resource for data scientists who are capable of programming at the low-level to set up the neural network for AI models.\n\nBut setting up a neural network is only the beginning.\n\nHow you structure your network will impact its ability to learn certain tasks.\n\nThe network\u2019s layers and hyperparameters will also impact its ability to learn. If you make a mistake at this point, you might not even realize it, but you will definitely feel the pain later on.\n\nThere\u2019s a lot to manage when you\u2019re programming AI models \u2014 a veritable spaghetti bowl of messy code. TensorFlow will spit out plenty of code, but it won\u2019t really help you organize, manage and maintain it.\n\nIf you\u2019re dealing with complex problem spaces like robotic assembly lines, commercial HVAC systems or wind turbine farms, you\u2019re going to need a solution that\u2019s built to handle Industrial AI.\n\nBonsai tackles this problem. The Bonsai Platform is an abstraction layer that sits on top of TensorFlow and automatically takes care of the low-level chores that will come back to haunt you if they\u2019re not handled properly from the beginning.\n\nLet\u2019s say you\u2019re operating a 100-turbine wind farm and your goal is optimizing its energy output across a wide variety of continuously changing weather conditions. Each of those 100 turbines has six variable settings, such as blade pitch and head yaw, which gives you 600 \u201cknobs\u201d to adjust for producing optimal power at any given moment.\n\nIf you were using TensorFlow alone, the problem would become unmanageable very quickly. With Bonsai, however, you are able to input your control actions, weather conditions and objectives using Inkling, our specialized programming language for Machine Teaching. Bonsai automatically creates a teaching plan based on your inputs and then our AI engine generates a tuned neural network wrapped in a GPU-optimized Docker container that runs in the cloud and connects via API or Python SDK.\n\nTensorFlow is at the bottom of that stack, largely invisible to users. That means you don\u2019t need teams of highly specialized data scientists manually training your AI models. By streamlining and automating the process, it radically reduces the time and energy required to get the most value from your AI investments.\n\nBonsai makes it simple for analysts and operators to generate optimal neural networks and create usable Industrial AI, ready to tackle real-world problems in complex physical environments.\n\nTo learn more about best use cases for Bonsai + TensorFlow\u2019s Machine Teaching approach, download our whitepaper, \u201cAI for Industrial Applications\u201d. You can also get started building deep reinforcement learning models for your own control systems with the Bonsai Platform."
    },
    {
        "url": "https://medium.com/@BonsaiAI/concept-networks-combining-subject-matter-expertise-machine-learning-to-build-industrial-ai-85dc4fa15f92?source=user_profile---------8----------------",
        "title": "Concept Networks: Combining Subject Matter Expertise & Machine Learning to Build Industrial AI",
        "text": "Most of the chatter around AI focuses on problems such as data analysis (data mining, customer segmentation), prediction (churn prediction, fraud detection, product recommendation) and perception (facial recognition, language translation, identifying birds).\n\nTypically, those kinds of AI problems are finite, constrained and relatively low in risk. Nobody dies if you recommend the wrong book to a customer, misidentify a warbler or mistranslate a word from Greek into French.\n\nBut there\u2019s an untapped group of large and complex physical systems in which modern machine learning technologies can be highly effective; areas such as autonomous transportation, manufacturing processes, supply chain logistics and advanced robotics. Applying AI to these types of systems, which we refer to as Industrial AI, essentially means using machine learning to automate the control of a physical system (ie: manufacturing line) or optimize the decisions and actions of an enterprise system (ie: supply chain).\n\nWhile applying machine learning to these systems present huge business opportunities, they pose their own special kinds of challenges:\n\nThese types of challenges highlight the importance of understanding your business problem before developing an AI strategy, both to understand potential risks and to be able to most effectively break down the problem into smaller, more manageable pieces.\n\nConcept networks allow subject matter experts to break down a large, complex problem into smaller sub-concepts. An AI model can learn to solve each sub-concept before combining all of the trained sub-concepts to solve the end goal. The subject matter expert is able to break down a complicated problem and teach an AI model how to solve it just as a human would, piece by piece.\n\nTackling large problem spaces with concept networks leads to a number of benefits for enterprises:\n\nLet\u2019s look at an example of how subject matter experts would use concept networks to control an industrial-scale HVAC system in an office building. The expert wants to train an AI model to control the building\u2019s environment, providing maximum comfort for workers while keeping energy costs minimal\n\nIn the old days, you would have set the temperature controls on the building\u2019s HVAC system, walked away and hoped for the best. But with concept networks, you can train an AI model to optimize for multiple smaller concepts at once, all of which contribute to solving a larger problem. A subject matter expert might determine that a model needs to learn about concepts like inside temperature, outside temperature, humidity, sunshine, cloud cover, time of day, day of the week, season of the year, how many people are in the building and where they are located in order to make the best decisions on how to set the temperature of the room.\n\nThose concepts can be seen as nodes in a network; changing the condition of a node will send ripples across the network. By first learning how to optimize for each individual concept, the system can then learn how each decision affects the rest of the environment (ie: turning on the air conditioner to lower the temperatures inside a building will also shorten the life of the air conditioner, raise electricity costs and require more frequent changes of air filters throughout the HVAC system) and ultimately learn how to leverage all concepts to most effectively heat the room.\n\nConcept networks are just one feature of the Bonsai Platform \u2014 along with Gears and Machine Teaching \u2014 that brings deep reinforcement learning closer to the enterprise.\n\nTo better understand how concept networks result in intelligent control of industrial systems, check out how we taught a robotic arm to stack and grasp blocks using 5 low-level concepts. You can also head over to our Getting Started page to learn how you can incorporate concept networks and reinforcement learning in your own organization."
    },
    {
        "url": "https://medium.com/@BonsaiAI/why-reinforcement-learning-might-be-the-best-ai-technique-for-complex-industrial-systems-fde8b0ebd5fb?source=user_profile---------9----------------",
        "title": "Why Reinforcement Learning Might Be the Best AI Technique for Complex Industrial Systems",
        "text": "One of the first things to know about machine learning is that you will be working with one of three types of algorithms: supervised learning, unsupervised learning and reinforcement learning. Here\u2019s a quick summary of the three types:\n\nLet\u2019s first take a quick step back and look at situations in which supervised or unsupervised learning would be useful in developing an AI strategy: You would probably use some form of supervised learning (e.g., linear regression, random forest, support vector machines) to solve problems such as customer segmentation, churn prediction, likelihood to purchase or fraud detection.\n\nAnd you would probably use some form of unsupervised learning (e.g., clustering, k-means, neural networks) when you\u2019re working on problems like facial recognition, language translation or speech analysis.\n\nIn those kinds of situations, you already have a pretty good idea of the data you have, what\u2019s going on and how to solve the problem. You\u2019re using machine learning to find interesting patterns in that data to get to a better solution, accelerate the process and get to your solution faster. You have a ton of data and you want a machine to find interesting patterns \u2014 and tell you what choices to make based on what it discovers.\n\nAnother popular type of AI, reinforcement learning is a form of supervised learning, but only given partial information. RL is an increasingly popular technique for organizations that deal regularly with large complex problem spaces. Because RL models learn by a continuous process of receiving rewards and punishments on every action taken, it is able to train systems to respond to unforeseen environments. Industrial systems, including supply chain management and industrial robotics, are good examples of large problems well spaces perfectly suited to be solved with reinforcement learning.\n\nWith reinforcement learning, domain experts and organizations typically know what they want a system to do \u2014 but they want to automate or optimize a specific process.\n\nIn the case of supply chain management, it would be extremely difficult, if not impossible, to write a program that could effectively manage every possible combination of circumstances occurring in everyday scenarios. The trucks could break down, the food could spoil, bad weather could force road closures \u2014 the list of potential hazards is virtually infinite.\n\nHere\u2019s something else to consider in the supply chain example: The problem space is highly dynamic; it\u2019s constantly changing. Every decision made by your system has an impact on the world and team around it.\n\nAs a result, your system must be highly adaptive. Again, this is where reinforcement learning techniques are especially useful since they don\u2019t require lots of pre-existing knowledge or data to provide useful solutions.\n\nDeep reinforcement learning is at the cutting-edge right now, with many of the world\u2019s best researchers working on improving the core algorithms. But it\u2019s finally reached a point that it can be applied to real-world industrial systems. Organizations should implement reinforcement learning in their AI strategies when:\n\nTo see reinforcement learning in action, head over to our blog to see a robotic arm learn to intelligently grasp and stack blocks in simulation.\n\nYou can also download our free whitepaper, \u201cAI for Industrial Applications\u201d to learn more about how reinforcement learning can solve real-world enterprise problems."
    },
    {
        "url": "https://medium.com/@BonsaiAI/deep-reinforcement-learning-from-toys-to-enteprise-147d990ea381?source=user_profile---------10----------------",
        "title": "Deep Reinforcement Learning: From Toys to Enteprise",
        "text": "Reinforcement learning is an increasingly popular machine learning technique that is particularly well suited for addressing problems within dynamic and adaptive environments. When paired with simulations, reinforcement learning is a powerful tool for training AI models that can help increase automation or optimize operational efficiency of sophisticated systems such as robotics, manufacturing, and supply chain logistics.\n\nHowever, moving from the games commonly used to demonstrate these techniques into real-world applications isn\u2019t always straightforward. Structuring solutions to move beyond purely data-driven training introduces all sorts of new complexity, requiring you to consider things like how to use simulations to target your learning objectives, what kinds of simulations are applicable, how to deal with long-running simulations, how to incorporate ongoing training refinement once deployed, how to account for scaling and performance, and ultimately how to bridge from simulation to the real world.\n\nI was recently able to talk about how to effectively leverage reinforcement learning in real-world use cases at the O\u2019Reilly AI conference in San Francisco. You can see my talk in full below, or keep reading to learn more about deep reinforcement learning and the problems it can solve.\n\nLet\u2019s first understand what we mean when we talk about deep reinforcement learning. Deep reinforcement learning (DRL) is different from supervised learning in that you have an agent interacting with environment. Once it interacts with the environment, it gets an assessment of a reward function for its interaction with that environment and that then drives subsequent behaviors.\n\nThe challenge with DRL is different because you don\u2019t know what the correct answer is. With supervised learning, it\u2019s learning because you\u2019re telling it the right answer. But RL models learn by exploration. The system has to explore the environment, and understand what moves it can make in order to achieve the outlined reward objective. You don\u2019t tell the system, \u201cat this point in time, the right move to make is X.\u201d Instead, you ask the system, \u201cDid you achieve the overall end objective that I set out for the agent to accomplish?\u201d\n\nIt\u2019s very natural to think of games when you think of deep reinforcement learning. Games are, by construction, environments where the players have to interact with the game.\n\nYou\u2019ve probably seen reinforcement learning models playing games like Lunar Lander. Training a DRL model to play Lunar Lander is actually part of the getting-started tutorial in the Bonsai Platform. Games are a great way to get a feel for reinforcement learning technology and understand how it works.\n\nEnterprises, however, face different problems when trying to apply this technology to real-world systems. That\u2019s what I want to talk about today, how we make the leap from games to the environment of the enterprise.\n\nIf we\u2019re going to talk about \u201cIndustrial AI\u201d, we should define what we mean by that term. Industrial AI techniques help enterprise companies, both commercial and industrial build control and greater optimization into their physical operations or systems. There are a number of use cases where industrial AI techniques are applicable \u2014 but if you look at the chart below you\u2019ll see a few things that are different from the pure database scenarios that you run into with supervised learning.\n\nFor example, you have a lot of devices. Frequently the environment you\u2019re working in is not a device, it\u2019s a whole set of devices that need to interact.\n\nAnother thing to highlight is that these use cases typically require reinforcement learning technology and simulations or digital twins.\n\nThe AI Use Case spectrum seen above the broad spectrum of problems to which AI technology is being applied today. But when we talk about industrial AI, we focus on the business problems on the left side of the chart. These problems tend towards optimization and automation of control systems, and away from the pure data analytics and prediction problems further to the right. Industrial AI use cases are rarely scenarios in which you go in with a large, curated, and labeled dataset. Instead, you\u2019ll have physical equipment that you actually want to control or for which you want to optimize behavior.\n\nThrough this lens, you start to see a progression of how AI is being applied to these systems, and what that means for the business. It progresses from monitoring to maintenance, then to optimization and ultimately automation of those systems. This is a sequence regularly followed as enterprise engagements build more sophisticated AI into their industrial systems, and net greater return from its capabilities.\n\nThrough this lens, you start to see a progression of how AI is being applied to these systems, and what that means for the business. It progresses from monitoring to maintenance, then to optimization and ultimately automation of those systems. This is a sequence regularly followed as enterprise engagements build more sophisticated AI into their industrial systems, and net greater return from its capabilities.\n\nBut building AI into systems requires unique techniques and technologies as industrial AI applications are fundamentally different in a lot of ways:\n\nIf you want to watch streaming video and the recommendation is not to your liking, that\u2019s not the end of the world. But if the AI system monitoring your airplane maintenance system to gauge when to replace engines gives you a false positive, you\u2019ve cost yourself $200,000. The predictions of these systems are high stakes.\n\nOn top of that, you don\u2019t want systems to get into states where things break. That\u2019s equally expensive and equally damaging. You can\u2019t simply deploy live AI models straight to the realsystem. First, you need to set up and connect a simulation or digital twin to build reinforcement learning models that are capable of solving real-world problems.\n\nI\u2019ll talk more about the landscape of simulators, and why they\u2019re so important for enterprises building AI into industrial systems, in subsequent posts. Until then, you can view my O\u2019Reilly AI talk below or download our whitepaper, \u201cAI for Industrial Applications.\u201d"
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-6-questions-to-ask-before-implementing-your-enterprise-ai-strategy-a5b9f7eebd00?source=user_profile---------11----------------",
        "title": "Industrial AI: 6 Questions to Ask Before Implementing Your Enterprise AI Strategy",
        "text": "Bonsai was founded in 2014 to reduce complexity and lower barriers that often make it difficult for software developers to program AI models.\n\nOver time, we\u2019ve learned that the most immediate value of AI becomes clear when it\u2019s applied in specific use cases within specific industry verticals. Speaking with business leaders and executives, we continue to see an underserved market with a genuine need for more accessible machine learning technologies: enterprises with industrial control systems.\n\nThese enterprises work in a range of industries, including robotics, manufacturing, supply chain, energy and HVAC. All want to leverage AI technology to enhance operations of these systems, but the kinds of tools these execs want \u2014 tools that allow enterprises to scale their existing domain expertise, while optimizing their best people\u2019s work with machine learning \u2014 simply don\u2019t exist.\n\nThat\u2019s why the Bonsai Platform has been built to make industrial AI techniques more accessible to a team of subject matter experts, data scientists and developers within an organization. The machine learning tools and technologies best suited for industrial AI \u2014 including deep reinforcement learning, simulations, and machine teaching \u2014 allow enterprises to combine human knowledge and cutting-edge AI to program intelligent control into real-world systems.\n\nFive or six years ago, applying AI to industrial applications would have been premature. But the technology has progressed to the point where it can be used to solve more than just toy problems. With the right tools and algorithms, industrial AI applications can now accomplish critical tasks at scale in large organizations.\n\nDo you have an industrial AI application?\n\nThe AI use case spectrum is vast. Here are some ways to tell if industrial AI techniques are the right approach to solving your organization\u2019s business problems:\n\nWe believe that industrial AI techniques will become the standard for dynamic production environments, complex autonomous systems and other scenarios in which continuous control and optimization are paramount.\n\nTo learn more about getting started with Industrial AI, and to learn more about the best-fit use cases, download our free whitepaper, \u201cArtificial Intelligence for Industrial Applications\u201d."
    },
    {
        "url": "https://medium.com/@BonsaiAI/reinforcement-learning-bonsai-platform-video-training-pt-3-e5e8084a9b1a?source=user_profile---------12----------------",
        "title": "Reinforcement Learning: Bonsai Platform Video Training, Pt. 3",
        "text": "We\u2019ve put together a series of Training Videos to teach customers about reinforcement learning and The Bonsai Platform. Check out Video 1 to get started with an introduction to types of machine learning.\n\nToday we have completed the release of our Bonsai training videos, a series of five videos to help new customers quickly get up to speed on the Bonsai platform, the Inkling programming language, and reinforcement learning. If you don\u2019t yet have access to the Platform but are looking to learn more, this series will allow you to learn what you\u2019ll need to know before you get started using the platform.\n\nThis third video is named Advanced Platform Techniques and has Victor Shnayder, Product Manager at Bonsai, outline some of the more complex features of The Bonsai Platform in order to train your BRAINs more efficiently. The video assumes that you\u2019ve already watched the previous video, Introduction to The Bonsai Platform.\n\nIn this video you will learn advanced usage of concepts and lessons, such as when to use multiple lessons or concepts to improve the training time when developing deep reinforcement learning models. Next, the video covers implementing gears to plug in custom behaviors. Lastly, the experimenting and debugging section covers tips and tricks while working with simulators and BRAINs. Check out the full video below.\n\nThis is the final video to be recorded (for now!), if you subscribe to our Training Video playlist you\u2019ll be notified of updates to these videos and any future videos we release. Thanks for watching, and please send us feedback on this and the rest of our series if you have thoughts!"
    },
    {
        "url": "https://medium.com/@BonsaiAI/7-challenges-of-building-industrial-ai-applications-445ed321cad8?source=user_profile---------13----------------",
        "title": "7 Challenges of Building Industrial AI Applications",
        "text": "A big part of what makes Industrial AI different from consumer and other business applications of AI is the fact that the stakes are much higher.\n\nThe tools best suited for recommendation systems or data analytics won\u2019t suffice for the unique requirements of Industrial AI applications. Here are 7 reasons organizations must look to leverage domain expertise and novel technologies to program intelligent control into enterprise systems:\n\nWhile challenging, the right AI strategy can turn even minor improvements to the control or optimization of a system into massive returns.\n\nYou can learn more about how to get started building and industrial AI strategy, and the best-fit use cases, by downloading our free whitepaper, \u201cArtificial Intelligence for Industrial Applications\u201d.\n\nHead over to https://bons.ai/ or tweet us at @BonsaiAI to let us know how you want to leverage Industrial AI in your own organization."
    },
    {
        "url": "https://medium.com/@BonsaiAI/what-is-industrial-ai-7d8839a20df6?source=user_profile---------14----------------",
        "title": "What is Industrial AI? \u2013 Bonsai \u2013",
        "text": "It may be overhyped, but AI technology is solving real world business problems every day.\n\nThanks to massive datasets and advances in machine learning, AI technology can predict churn, recommend products and conduct speech and facial recognition with incredible accuracy.\n\nBut AI is also being used to automate and optimize dynamic systems including robotics, manufacturing, HVAC, energy and supply-chain. These types of use cases, which we refer to collectively as Industrial AI, pose unique challenges but offer some of the most immediate opportunities for significant business impact.\n\nTo understand what Industrial AI is, it\u2019s helpful to know what it is not. Here is how we define some of the AI buzzwords you may be familiar with:\n\nSo what is Industrial AI? We define it as:\n\nIndustrial AI includes, for example, applications relating to the manufacture of physical products, to supply chains and ware-houses where physical items are stored and moved, to the operation of building HVAC systems, and much more.\n\nYou can learn more about the best fit use cases for Industrial AI, its unique challenges, and how to get started programming intelligent control into your own applications by downloading our free whitepaper, \u201cArtificial Intelligence for Industrial Applications\u201d.\n\nHead over to bons.ai or tweet us at @BonsaiAI to let us know how you want to leverage Industrial AI in your own organization."
    },
    {
        "url": "https://medium.com/@BonsaiAI/reward-functions-writing-for-reinforcement-learning-video-85f1219a0bde?source=user_profile---------15----------------",
        "title": "Reward Functions: Writing for Reinforcement Learning (Video)",
        "text": "We\u2019ve put together a series of Training Videos to teach customers about reinforcement learning, reward functions, and The Bonsai Platform. Check out Video 1 to get started with an introduction to types of machine learning.\n\nIn August we started the release of our Bonsai training videos, a series of five videos to help new customers quickly get up to speed on the Bonsai platform, the Inkling programming language, and reinforcement learning. If you don\u2019t yet have access to the Platform but are looking to learn more, this series will allow you to learn what you\u2019ll need to know before you get started using the platform.\n\nThis fourth video is Writing Great Reward Functions where Ross Story, Data Scientist at Bonsai, explains the process of writing reward functions in reinforcement learning. The video assumes that you already have a general understanding of reinforcement learning from the first video in this series, Introduction to Types of Machine Learning.\n\nIn this video you will learn the basic topics of reward functions such as shaping, terminal conditions, and negative and positive rewards. Ross then gives a basic and complex example of a reward function, and then concludes with talking about some challenges and advanced topics like hidden state, sequential or conditional tasks, and pitfalls and how to avoid them. Check out the full video below.\n\nFor more information about how Bonsai uses reinforcement learning, you can watch the next video in the series or read our blog on Mark Hammond\u2019s Deep Reinforcement Learning presentation at GTC this year."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-control-systems-is-reinforcement-learning-the-answer-6380ab2eddeb?source=user_profile---------16----------------",
        "title": "Industrial Control Systems: Is Reinforcement Learning the Answer?",
        "text": "At Bonsai, we talk to a lot of Fortune 500 companies who want to explore using Reinforcement Learning to solve their industrial control problems. Often the thorniest part of the conversation is figuring out whether Reinforcement Learning is a good technique to solve their problem. This blog post is meant to shed some light on that subject.\n\nMuch of the buzz about Reinforcement Learning (RL) is created by solving so called \u201ctoy problems\u201d. These toy problems, like the ones on OpenAI Gym and OpenAI Universe, are good benchmarks as they provide a standard set of simplified problems to judge AI algorithms against. Enterprise customers, however, face a much more complex set of challenges when using reinforcement learning to control or optimize industrial applications.\n\nIndustrial control systems like a wind turbine or diesel engine may involve dozens or thousands of variables, require human intensive calibration or optimization, and generate reams of output data. You may be thinking: machine learning is used to solve complex problems all the time, why do I need Reinforcement Learning? True, some problems are best solved by supervised or unsupervised machine learning. On the other hand, Reinforcement Learning can help control and optimize some systems that other methods cannot. The following three comparisons are meant to share some insights we\u2019ve gained about how to tell a good industrial strength Reinforcement Learning problem when you see it.\n\nWhen you play chess, each move that you make completely changes the game for you and your opponent. There are far too many move combinations for there to be a \u201cright answer\u201d move at any stage of the game because each sequential move changes the whole game and there\u2019s no turning back. On the other hand, each question in a trivia game can be independently scored correct or incorrect.\n\nIf your system has many \u201cknobs to turn\u201d and turning any of those knobs changes the entire state of the environment, you might have a great application for Reinforcement Learning. On the other hand, if you have a data set where each row in the data can be graded correct or incorrect like a test or trivia game, then your problem is a better fit for supervised or unsupervised learning.\n\nWe\u2019ve recently come across the following applications of industrial control systems that are a good fit for RL:\n\nMusicians practice at rehearsals. They play musical passages over and over until they get it right. Mistakes are allowed and even encouraged in rehearsal to prepare the musicians for a high quality performance. Reinforcement Learning, like music rehearsal involves letting your AI learn by experience so you need to give the AI a lot of opportunities to practice and fail in order for it to learn.\n\nSome industrial systems allow an AI to practice getting things right and some systems require performance quality only. For example, you wouldn\u2019t want an AI to practice learning control on an expensive CNC machine.\n\nThis is where simulations become very valuable. In a simulated environment, the AI can repeat the try-fail \u2014 learn cycle many thousands of times safely and quickly. Safely because the AI is not failing in your live environment, and quickly because the simulation can show the AI failure conditions much more frequently than failure occurs in real life. If you have a simulation of your system or a live system that an AI can practice on (for example assembling a small and inexpensive polymer part repeatedly), then you might have a strong candidate for RL.\n\nReturning to our chess example: an AI might learn how to play chess well against one type of opponent that it\u2019s been training against, but teaching the AI how to play well against players who employ many different styles is another matter. Some algorithms are well suited for cookie cutter scenarios where the conditions will be identical over time. When conditions vary, it can become more difficult for those algorithms to optimize or control the system well. This is a job for Reinforcement Learning!\n\nNow let\u2019s return to the examples used in section #1 above to show the kinds of variations in industrial systems that are well solved with reinforcement learning:\n\nHopefully this post gives you a better idea about where Reinforcement Learning should be considered across different types of applications. If you think have a use case that could be solved with RL, we would love to hear from you at our getting started page. You can also find more details in our Use Case Qualification Worksheet."
    },
    {
        "url": "https://medium.com/@BonsaiAI/concept-network-reinforcement-learning-for-flexible-dexterous-manipulation-47bf459b19b9?source=user_profile---------17----------------",
        "title": "Concept Network Reinforcement Learning for Flexible Dexterous Manipulation",
        "text": "At Bonsai, we are building an AI platform to enable subject matter experts to teach an AI how to solve complex problems in optimization and control using deep reinforcement learning. Typically, effectively using deep reinforcement learning requires a great deal of expertise in defining suitable reward functions for your task. This becomes even more challenging when the task requires coordination or sequential planning of different skills and operations.\n\nA key feature of the Bonsai platform is the ability to decompose complex tasks using concept networks. Concepts are distinct aspects of a task that can be trained separately, and then combined using a selector concept. This approach drastically reduces the overall complexity, since the simpler problems can be trained with focused and easier-to-specify reward functions. The selector concept can be quickly learned using a simple reward function.\n\nToday, we\u2019ll tell you how we used this approach to solve a complex robotics task requiring dexterous manipulation: training a simulated robot arm to grasp an object and stack it on another one. A similar task was recently studied by DeepMind, getting excellent results [1]. We applied our decompositional approach, improving training efficiency and flexibility. Here is a video of the end result:\n\nA recent paper by DeepMind [1] described a similar grasping and stacking task, and solved it with two main contributions. First, by carefully crafting reward functions, they could teach an AI to learn how to correctly sequence the sub-tasks needed to solve the complete problem. Solving the problem with this approach required about 10 million interactions with the simulator. Secondly, they showed that if key subtasks were learned separately (each took on the order of 1 million interactions with the simulator), and traces from executing these subtasks were used to prime learning the full task, it was possible to learn the full task in about 1 million interactions with the simulator, thus achieving a 10x speed up over the baseline which did not use subtasks.\n\nOur approach has its precursors in the Options Framework by Sutton et al. [5]. More recently. T. D. Kulkarni et al. has shown how a similar approach using deep hierarchical reinforcement learning could be used to learn complex sequences [2]. The main difference from our approach is that the meta-controller is learned at the same time as the basic controllers (sub-tasks) and there are no constraints on when to use each basic controller.\n\nThe robotics task starts with a Kinova Jaco arm at a neutral position in a MuJoCo robotics simulator, and then moves the arm to a work area to grasp a four-sided geometric prism. Once the prism has been grasped, the arm moves the prism to an adjacent work area to stack the prism on top of a cube. The position and orientation of the prism and the cube can vary around the center point of their their respective working areas.\n\nWe decompose the task into five subconcepts \u2014 reach the object, orient the hand for grasping it, grasp it, move to the object for stacking it, and stack it on top of a block. We solve each separately, and learn a meta-controller \u2014 or selector \u2014 concept to combine them into a complete solution.\n\nThe hierarchical decomposition gives us several practical benefits:\n\nThe \u201creach for grasping\u201d (reach) and \u201cmove for stacking\u201d (move) concepts are simple motions for which we use a classical motion controller. The Bonsai platform allows us to integrate such controllers using Gears, an interoperability feature we announced in June of this year. The orient, grasp, and stack concepts are neural controllers trained with deep reinforcement learning, using the TRPO-GAE algorithm [3].\n\nEach concept is trained in order once its precursors in the concept graph have been trained. First the system trains orient, grasp, and stack independently. Once these concepts are trained the system trains the overall grasp and stack concept.\n\nAs shown in Figure 3, the selector learns to choose the action recommended by the sub-concept most applicable in the current state. This is a discrete reinforcement learning problem, that we solve with DQN, using progress toward overall task success as the reward (any discrete RL approach could be used). To make this effective, we don\u2019t choose a new sub-concept at each time step. Instead, the selector uses long-running concepts: each subconcept can have pre-conditions for when it can be selected, and a run-until condition to meet before switching to another task. This gives the designer an easy way to specify constraints like \u201cdon\u2019t try to grasp until you\u2019re close to the object\u201d, and \u201conce you start to move, continue that for at least 100 time steps\u201d.\n\nInkling is Bonsai\u2019s special purpose programming language used to codify the concepts the system should learn, how to teach them, and the training sources required (e.g. simulations). Collectively, we refer to these techniques as Machine Teaching. The Bonsai Platform can integrate these taught concepts to learn new skills. Read more about Inkling in the Bonsai Docs.\n\nFigure 4 shows the number of samples (environment transitions) required to learn each of the concepts. The grasp and stack (Selector) concept only took about 22K samples to converge \u2014 this is drastically faster than the number of samples required to learn the other tasks. Because the other concepts can be trained in parallel or could be already pre-trained, the overall time for solving the full problem using a composition of concepts is significantly reduced. In the ideal case, with pre-trained sub-concepts, this gives a 500x speedup over DeepMind\u2019s all-at-once solution, and a 45x speedup over their approach of using subtask traces to speed up training [1].\n\nAll tasks (including the full task) achieved 100% success on 500 test executions. Parameters for the algorithms and detailed equations for the reward functions are provided in our research paper.\n\nWe implemented the task reach and move using inverse kinematics classical controllers. These did not require training.\n\nReach moved the arm from its initial position (always the same) to a staging area for starting grasping. The staging area for grasping was defined as a fixed point centered above the grasping working area.\n\nMove repositioned the arm from the end position of the grasp task to the staging area for stacking. The staging area for stacking was defined as a fixed point centered above the stacking working area.\n\nThe orient concept was trained using TRPO-GAE on about 2 million samples using the following reward function:\n\nHere is the training graph and a video of orient training:\n\nThe grasp concept (called lift in our paper) was trained using TRPO-GAE and the endpoints of the orient concept task as starting arm configurations. We collected 100K sample starting points by executing the orient concept with different prism location and orientations. The grasp concept converged after about 5 million samples using the following reward function:\n\nHere is the training graph and a video of grasp training:\n\nThe stacking concept was trained with TRPO-GAE on about 2.5 million samples using the following reward function:\n\nHere is the training graph and a video of stack training:\n\nWe used DQN [4] to train the grasp and stack concept. Figure 1 shows a video for an exemplary run for the full task. Figure 11 shows the training graph \u2014 the selector learns very quickly (6K training steps, corresponding to about 22K interactions with the simulator) to sequence the different concepts in order to solve the problem.\n\nWe used the following reward function:\n\nThe problem we chose to tackle is quite difficult. Even after splitting it into simpler subproblems using Concept Networks, there remain design decisions that require careful consideration. Read our arXiv paper to learn more about\n\nIf working on a platform to support flexible, usable reinforcement learning and AI is interesting, join us! If you\u2019re interested in using our platform to solve your control or optimization tasks, check out our Getting Started page.\n\n[5] Sutton, R. et al. Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial Intelligence 112 , 1999: 181\u2013211."
    },
    {
        "url": "https://medium.com/@BonsaiAI/ai-explainability-machine-teaching-recomposability-e48f440632c0?source=user_profile---------18----------------",
        "title": "AI Explainability: Machine Teaching & Recomposability",
        "text": "One of the biggest challenges facing AI researchers today is an absence of explainability from their models. Neural networks can crunch data and churn out remarkable predictions, but humans are unable to understand the thought process that led to those conclusions.\n\nExplainability will become increasingly important as AI is deployed into more consumer facing products (as will the need to define what we hope to learn from explainable models). And there are a number of techniques being pursued to gain visibility into deep learning models (you can read about the Deep Explanations approach here, and the Model Induction approach here.)\n\nBut today I want to shed some light on Bonsai\u2019s approach to building intelligent systems, and how that approach results in more explainable AI models.\n\nIn my deep dives of both the Deep Explanations and the Model Induction approach, I touched on the importance of subject matter expertise and machine intelligence.\n\nWe know machine learning is very flexible, very powerful, and can learn dynamic representations.\n\nWe also know subject matter expertise enables us to give ontology to machines, and tell machines about which subjects matter to a specific problem we\u2019re trying to solve.\n\nIntegrating both together results in a new technique \u2014 Machine Teaching.\n\nMachine Teaching is used to build a conceptual hierarchy. It\u2019s a fuzzy hierarchy; it\u2019s not like old expert systems with very strict sets of rules. But it enables you to teach specific expertise that matters, and build that expertise into a conceptual model.\n\nLet\u2019s go back to the zebra example from the Model Induction experiment. Using Machine Teaching, you can teach the system that a zebra has four legs, and a head, and stripes, and a tail. (You don\u2019t need to tell the machine what those things are; machine learning techniques and data and simulations enable the machine to learn what a head is). Those ideas are built into a conceptual hierarchy to drive predictions from models that can be explained.\n\nMachine Teaching is particularly important when talking about deep reinforcement learning systems and not just traditional classification systems.\n\nIn a classic reinforcement learning system, you have an actor taking an action in an environment. The actor gets some assessment of reward for its behavior, and that reward is used to drive the learning loop.\n\nIt\u2019s important to note that, unlike circumstances with quite readily composable features (ie: a leg, a head, and a tail of a zebra image), RL systems must predict actions to be taken. And everything is fighting over the exact same action prediction.\n\nFor example, in the game Lunar Lander, you can teach the system lots of concepts in order to win the game, but each concept is still ultimately trying to fire the thrusters. They\u2019re all thinking the same thing (ie: Concept 1 thinks they should fire one way, Concept 2 thinks they should fire another way.) The ability to understand how to deal with those conflicting ideas becomes very important for RL systems.\n\nOne approach to this problem, which informs a lot of the work we do at Bonsai, is the subsumption architecture put forth by Rodney Brooks when he was building RL models for robotics in the mid 80\u2019s.\n\nIn this approach, the concepts you teach the machine are not features of the environment, but behaviors for the agent to take in an environment. You can decompose behaviors into sub-behaviors that correspond to a hierarchy of available actions to take.\n\nFor example, if you have sensory information coming in, you could have behaviors for \u2018explore world\u2019, \u2018wander around\u2019, and \u2018avoid objects\u2019. If you\u2019re activating the \u2018avoid objects\u2019 behavior, you\u2019re inherently also activating the other two behaviors, but it forms a hierarchy of needing to do certain things in order to do other things.\n\nThis approach helps us derive a way to decompose and recompose when we talk about behaviors.\n\nIn our platform, we have a new programming language called Inkling that lets you build a concept graph. You literally codify concept hierarchies.\n\nIn our system, these concepts can be features or actions. But as you build them, you\u2019re giving each concept its own training regime.\n\nTo understand concept graphs, think about teaching a 5 year old to play baseball. You, as the teacher, already know the skills that the 5 year old will have to learn in order to understand the game: catching, hitting, running bases.\n\nYou would never teach a 5 year old to master the skill of hitting a ball by taking them outside and throwing fastballs. But that\u2019s exactly what we do with modern machine learning systems; we take the absolute end result and throw lots and lots of examples at them.\n\nInstead, we start with a wiffle ball on a tee. Then the tee pops up the ball. Then underhand, etc. It\u2019s totally fake to start, but it\u2019s fake in a way that\u2019s designed to be instructive. And it genuinely works.\n\nThis increases rate of acquisition of skills dramatically; around 2 orders of magnitude faster. You can see what I mean in the Lunar Lander example below:\n\nThe goal of the game is to get the spacecraft to land on the pad. We used Bonsai\u2019s Platform to teach the game 3 concepts to win the game : stability, going to certain points in space, and landing at a graceful rate of descent\n\nTo be clear, you don\u2019t have to teach these concepts. You can use powerful reinforcement learning algorithms and it will learn how to solve this problem. But just using RL takes around 2,000 episodes. Using concepts, it beats the games in 50 episodes. It\u2019s not just a little better; it\u2019s a lot better.\n\nAnd on top of performance increases, now it\u2019s explainable.\n\nTo get explainability, it needs to learn how to select between behaviors that we want system to learn, and synthesize novel behaviors that are informed by those behaviors in pursuit of the objective. Let\u2019s see it in action:\n\nIn this first video, the craft is learning. In the upper left, you can see the three different concepts it\u2019s learning between and it\u2019s reason for using any one concept at a given time. In this training example, \u2018going to a certain point\u2019 is dominating because that the concept it\u2019s currently learning.\n\nIn this video, the system is already trained. It\u2019s trained first to go to a specific point at the top, then a specific point at the bottom, then land gracefully.\n\nIt learns all behaviors but then the systems learns how to select between them at any given time. And we can offer visual explanations for those selections.\n\nWhen you integrate these together and the system is fully trained, you get perfectly reasonable, human-like behavior. And because you can explain it, and you\u2019ve introduced concepts, you get generalizability in that system.\n\nThe system has not just learned how to keep the craft stable, go to a point, and land. It means that if I tweak the environment in ways that it\u2019s never seen before \u2014 if I add wind, for example, it will continue to expect human-like behavior and solve the problem.\n\nA normal neural network would no longer work with added wind. But since the system learned these generalized concepts, and it understands the subsumption hierarchy that getting to a point and stability takes precedence over landing, it will still exhibit intelligent behavior.\n\nConcepts \u2014 both feature or behavioral \u2014 give you benefits around training times and offer explainability in a way that lets you add increasingly complex capabilities and verify behaviors by testing and setting up new environments that might not have been seen in training.\n\nWe\u2019ve now explored three approaches to building more explainable AI systems:\n\nTaken together, we can start to build explainability and debug systems to build more sophisticated models.\n\nBonsai is building a general purpose deep reinforcement learning platform for control and optimization problems including robotics, HVAC, and supply chain. To learn more about our work, visit bons.ai. You can also view my Explainable AI talk in full at the link below:"
    },
    {
        "url": "https://medium.com/@BonsaiAI/explainable-artificial-intelligence-using-model-induction-f257c92f426e?source=user_profile---------19----------------",
        "title": "Explainable Artificial Intelligence: Using Model Induction",
        "text": "Researchers are exploring many paths to building more explainable artificial intelligences models. I recently wrote about one of those approaches, Deep Explanations.\n\nToday I want to dig into a second popular approach, Model Induction. Specifically I\u2019ll look at two techniques:\n\nThe goal of model induction is to look at the behavior of the resulting trained system and use that to infer the model that can be used to explain the behavior.\n\nLet\u2019s first look at LIME, which stands for Local Interpretable Model-Agnostic Explanations. We can tease apart what these words actually refer to:\n\nLOCAL \u2014 this refers to something that is true for the model but has locality. Continuity is important; you want locality within a specific area of the image. An example shows a labrador with a human body, playing a guitar that is both acoustic and electric guitar. It\u2019s a very hard image to classify if you treat it globally. It\u2019s a mash up on purpose.\n\nBy using a local approach, and carving up the image into sections, you\u2019re able to make explanations that make sense locally.\n\nINTERPRETABLE \u2014 This means that it has to be readable by a non-expert human and provide a qualitative understanding between the joint values of the inputs and the responses.\n\nMODEL AGNOSTIC \u2014 This means that we don\u2019t want to this to depend on the details of the model selected. A lot of the previous work is model dependent; this is model independent.\n\nUsing this method, instead of trying to generate textual label, we take an input and highlight what about the input made it an exemplar or not.\n\nDoing this globally is not realistic. So we look at local super pixel groups, which underscores an important facet of explainability within these systems \u2014 part of what we want to get out of building explainable system is not just the explanation itself; it\u2019s also a mental model that we can impart to people using the system so they can have a measure of trust for why something is being done in a particular way.\n\nThe LIME technique starts to get at this because the model can look at superpixel groups and tell you what it thought the group was indicative of, and composite all of those into an explanation.\n\nTo further understand this, let\u2019s look at the local explainability:\n\nYou take a sample, you take a weighted random sample around it, you remove the other pixels and you feed it again through the classifier to see if it keeps getting the same classification. You do this over and over again. But there\u2019s an additional constraint put on this, which is that it has to be interpretable by a human. The measure for this being the continuity. It needs to cluster; it\u2019s not ok to have 4 pixels here, 8 pixels there.\n\nYou can see examples from the labrador experiment. It takes a portion from the labrador face, but also takes a portion from pixels on the bottom which get an increased negative score because the groups are further away.\n\nThis process was done for both images and texts. They picked overall configurations based on maximizing the differences between features. When you get all the different classifications together, you want to pick all the different explanations you could have that maximize the number as wide as possible distinctions in the image; labrador vs guitar is a pretty wide distinction in a feature, and those are selected to be put together.\n\nAn interesting note \u2014 when these researchers brought in their test groups, they used data scientists and non-data scientists, and reported results separately to remove biases. (You can read the full paper here).\n\nAnchor LIME is an approach out of University of Washington that adds another facet to this work.\n\nUsing Anchor LIME, researchers are trying to create local explanations where they can tie if-then rules for more precise explanations.\n\nAgain looking at the picture of the labrador, the image is visually reasonable but hard to describe verbally. The researchers wanted to make it more reasonable to verbally describe what was happening.\n\nIn the example below, you see many features being taken into account with various weights in the LIME process. But in the ALIME process, these are distilled down into exemplar rules, or anchors, which are used to distinguish what it is that\u2019s actually driving the explanation for the given model.\n\nThe next example highlights a visual explanation. The system is very good; the derived anchor for the image of the zebra has latched onto the stripes along its body. Even substituting in different images, the model still consistently predicts that it\u2019s a zebra. So this is a reasonable anchor according to the model. But is it a good explanation?\n\nIt\u2019s fairly subjective. It mentions nothing about a horse\u2019s head, a tail, or four legs. It\u2019s only looking at the pattern of stripes. So it\u2019s very possible to fake out the model by showing a striped zebra pattern on a jacket, and it will still predict the image is a zebra.\n\nThis approach is certainly interesting and useful as an explanatory tool. It allows us to identify what the predictive failure models will be, and test them, so that we can refine and iterate models to eliminate those errors. But ultimately it would be more satisfying to have a model correlate more with our own personal understanding of what it means for something to be a zebra. (You can read the full paper here).\n\nAs explainable AI techniques evolve, it\u2019s useful to remember that often these explanatory tools are useful in a debugging context more so than the context of being the ultimate explanation that the system will provide.\n\nI will touch on a third approach to explainable artificial intelligence \u2014 machine teaching \u2014 in my next post. In the meantime, you can watch my full O\u2019Reilly AI talk on this topic at the link below or visit bons.ai to learn how we\u2019re thinking about explainability in industrial AI systems."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-this-week-in-machine-learning-ep-8-41f39c228996?source=user_profile---------20----------------",
        "title": "Industrial AI Podcast: This Week in Machine Learning, Ep. 8",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out this special bonus episode below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nWe\u2019ve got a special bonus episode of the TWIML Industrial AI podcast series this week! Sam Charrington talks with Bonsai CEO & co-founder, Mark Hammond, about how to combine human and machine intelligence to build more efficient and intelligent enterprise control systems.\n\nCheck out the full episode in the link below. Huge thanks to TWIMLAI for partnering with us on this Industrial AI podcast series! To learn more about how you can combine machine teaching and machine learning to build intelligent control systems in your own organization, head over to https://bons.ai/ to apply for the Early Access Program."
    },
    {
        "url": "https://medium.com/@BonsaiAI/reinforcement-learning-bonsai-platform-video-training-pt-5-528cfa2ab9ed?source=user_profile---------21----------------",
        "title": "Reinforcement Learning: Bonsai Platform Video Training Pt. 5",
        "text": "We\u2019ve put together a series of Training Videos to teach customers about reinforcement learning and The Bonsai Platform. Check out Video 1 to get started with an introduction to types of machine learning.\n\nToday we have uploaded the fifth video in a series of training videos to get new customers quickly up to speed on the Bonsai platform, the Inkling programming language, and reinforcement learning. You might be wondering, \u201cwhere are videos three and four?\u201d \u201cWhy isn\u2019t this one the third video in the series?\u201d The truth is, this training series all started from giving this presentation to an early access customer, deciding to turn it into a video, and then planning out a curriculum to set the stage for it. Videos three and four will follow this one.\n\nWe realized that other companies might not have such a strong grasp on machine learning as our initial customers did, so we set out to break up the on-site training into smaller, easily digestible videos for you to watch in your leisure. Today\u2019s video is Challenges and Strategies in Reinforcement Learning (RL) and is broken up into two parts; an overview of three main challenges in RL, and general strategies to make RL problems easier to solve.\n\nThe video assumes that you already have a general understanding of reinforcement learning, which you can get from watching the previous videos in this series. You\u2019ll learn about challenges with dynamic programming problems, reward functions, and scalability of learning. Turning to solutions, you\u2019ll then learn some strategies to overcome these challenges, such as shaping, curriculum learning, apprenticeship learning, and using building blocks. Check out the full video below.\n\nFor more information about how Bonsai uses reinforcement learning you can read our blog on Mark Hammond\u2019s Deep Reinforcement Learning presentation at GTC this year."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-this-week-in-machine-learning-ep-7-581749ebb9be?source=user_profile---------22----------------",
        "title": "Industrial AI Podcast: This Week in Machine Learning, Ep. 7",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out Episode 7 below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nThe final episode of TWIML AI\u2019s Industrial AI podcast series features Josh Bloom, VP Data and Analytics at GE Digital and co-founder of wise.io\n\nJosh builds applied AI solutions for one of the largest enterprises in the world. His conversation with Sam covers how to think about building AI for physical systems (and why it\u2019s so much more important to get it right), how to leverage simulations and digital twins to build solutions at scale, and the importance of combining machine learning with domain expertise.\n\nYou can listen to the full episode in the link to the AI podcast below. To learn more about how you can leverage reinforcement learning, simulations and domain expertise in your own organization, head over to https://bons.ai/ to apply for the Early Access Program."
    },
    {
        "url": "https://medium.com/@BonsaiAI/explainable-ai-3-deep-explanations-approaches-to-xai-1807e251e537?source=user_profile---------23----------------",
        "title": "Explainable AI: 3 Deep Explanations Approaches to XAI",
        "text": "In a recent post, I described the importance of thinking about what we hope to achieve from building more transparent neural nets and explainable AI models. But today I want to talk about one of three emerging methods that researchers are using to make headway in this space.\n\nLet\u2019s start with deep explanations, a method of building explainable AI where where we try to tease apart what is happening within the neural network itself. Within deep explanations, I\u2019d like to highlight three techniques:\n\nIn this first technique, SRI tried to learn semantic associations in video. The goal was to \u201ccount\u201d occurrences of items of interest in frames of a long video and generate a caption for that event. The eventual goal was to later be able to search video content.\n\nIn one example, they took a video sequence of a skateboarder. They identified frames of a skateboarder standing, jumping or falling. When composited into one event, they wanted the model to say \u201cThis is a skateboarder attempting a board trick\u201d.\n\nThey retrieved as much information as possible from the scenes using visual recognition, audio based recognition, and even OCR techniques for looking at closed captioning when available. This information was then fed into stacked convolutional layers in a network for classification and trained multiples times; they trained it to associate semantic attributes within specific hidden layers, and they trained it to associate hidden nodes with human-labeled ontologies. And they used this to generate examples of prominent but unlabeled nodes to see what they should be applying.\n\nAnother example used a video of a wedding. They wanted the model to look at the evidence supporting this event being a wedding: a bride, a groom, an exchange of rings.\n\nThis technique mixes learned subject matter expertise with a learned system. Classifying the picture as a ring being placed on a finger is not enough in this case; you also have to provide the ontology as the subject matter expert that these events imply something specific (ie, two people getting married). This has to be done as part of building the model itself.\n\nSRI completed this task successfully. They later used meta data derived from scenes to build a system for searching video for certain moments (ie: show me the vows). You can see the original paper detailing this work here.\n\nThe second technique, out of Berkeley, expanded on these efforts.\n\nTheir goal was to generate a caption about why an image was in a specific class. So they didn\u2019t want to just generate a textual caption, they also wanted the system to be discriminative and describe the reasons for thinking a scene shows something.\n\nOne example looks at an image of a bird with a long white neck and yellow beak. This system is not able to discriminate this bird from other birds until you bring in the detail that there is a red eye.\n\nThey did this by working with a model to classify images. They passed in categories and target sentences to train an LSTM model to generate descriptions. Then they rewarded it on its ability to discriminate between that particular classification and any other classification that could have been derived (as opposed to being rewarded based on relevance). It\u2019s interesting to note that again, subject matter expertise and ontology had to be passed in. The model then learned to generate the appropriate descriptions and repetitively generate more examples to compete with itself, discriminate and be rewarded accordingly.\n\nOne important thing to note is that, while it\u2019s discriminative in this way, these explanations for AI are just justifications. The technique does not peer into the innards of a neural net and say what the derived feature is actually representing. They trained the system to competitively discriminate between features that could be used to identify explain different types of animals in the scene. But there\u2019s no way to know if the underlying neural representation was not actually identifying a red eye, and was instead identifying a bird flying over water. You can identify correlation, but you can\u2019t look in and say for certain that you know what the model is doing. You can find the original paper here.\n\nThis last technique highlights work done out of MIT. They focused on extracting snippets of text that corresponded to scores.\n\nIn one example, they looked at reviews of beer to take textual review, identify ratings, and associate those with each other. This case showed a five star review for appearance of beer being associated with \u201cA pleasant ruby red amber color\u201d. Overall, this is objective. But they also wanted to highlight salient parts of questions that corresponded to categories in forms.\n\nThey did this with two pieces: an encoder and a generator.\n\nThe encoder builds mapping between the text and the specific scores. The generator is trained simultaneously and looks to pull out text. It takes words, assigns each a probability using traditional methods, and then selects phrases that are not just high probability correlation with the scores they see, but that also possess continuity. Effectively, they\u2019re looking to find strings of words that run together that are all associated with that score Continuity is seen not just with text, but also images, in this system.\n\nWith this mechanism, they were able to create brief, coherent explanations tying the scores back to the text. This is not a way of explaining what the neural network is actually doing, but it is a method for rationalizing the behavior and justifying its predictions. You can read the original paper here.\n\nYou can view my full talk on Explainable AI techniques in the video below. To learn how Bonsai is building explainability into reinforcement learning models, you can visit https://bons.ai/."
    },
    {
        "url": "https://medium.com/@BonsaiAI/what-do-we-want-from-explainable-ai-5ed12cb36c07?source=user_profile---------24----------------",
        "title": "What Do We Want From Explainable AI? \u2013 Bonsai \u2013",
        "text": "How can we explain why machine learning systems make the predictions that they do?\n\nBefore we can answer this question of explainable AI \u2014 one that Will Knightrecently described as \u201cThe Dark Secret at the Heart of AI\u201d \u2014 we need to take a long hard look at what exactly we mean by \u2018explaining\u2019 things.\n\nIf we look back at the expert systems of the 80\u2019s, we had what we would consider complete explainability: an inference engine leveraged a knowledge base to make assertions that it could explain using the chain of reasoning that led to the assertion.\n\nThese systems were completely built on subject matter expertise and while powerful, were somewhat inflexible. Expert systems were largely an artificial intelligence endeavor and not a machine learning endeavor.\n\nModern machine learning algorithms go to the opposite end of the spectrum, yielding systems capable of working purely from observations and creating their own representations of the world on which to base their predictions. But there is no ability to deliver explainable AI, or to present those representations in a meaningful way to a human who asks, \u201cwhy?\u201d\n\nOur current techniques are quite powerful, but do not engender a lot of confidence in the systems. We\u2019re left wondering, \u201chow do we verify behavior in novel situations?\u201d, \u201cHow do we iteratively debug and refine these systems?\u201d, \u201cHow do we prevent systemic, undesired biases that may be present in data but we want to filter out?\u201d\n\nIf you are building a system to approve loans, for example, and the machine learning system learns from the data that zip codes are a good predictor for credit, are you running afoul of non-discrimination rules? What if you can\u2019t even say what factors are ultimately used?\n\nThese are non-trivial, real-world concerns as we work to apply AI to our businesses. When my cofounder and I were first starting Bonsai, we spoke to a lot of large companies to learn about the problems they faced in using AI. One company, comprised of quite capable AI practitioners, had built a machine learning system to replace the hand-crafted system used to predict what item to next show its users. The new ML system, in measured tests, outperformed the existing system, but they ultimately decided not to adopt it. The reason was that despite the improved performance, they could not explain why it made suggestions, and consequently they were hard pressed to iteratively improve it. It presented a potential ceiling for what they could do, and so despite their successful work, it was not put into production.\n\nThese issues become even more pronounced as we look at systems making health recommendations, autonomously controlling vehicles, and providing operational decision support. Analysts don\u2019t want to simply be told that this is what will optimize their supply chain, they want an explanation why an AI made these suggestions.\n\nMany of us here are familiar with the constant refrain of \u201cwhy\u201d from children delving deeper and deeper into something. For most situations, when we ask why, we don\u2019t want an explanation in terms of the underlying particle physics\u2026 we want an answer at the appropriate level of abstraction. (Though here\u2019s a pretty amusing story showing what happens when a young child continuously asks \u201cWhy?\u201d of her chemistry professor father.)\n\nThis can be a challenge in the real world because we have to distinguish between introspection and justification, and we must frame things in terms of shared, mutually held concepts that build upon each other. This is why children keep asking why\u2026 they don\u2019t yet have all of those concepts.\n\nIf my son asks me why he must eat his vegetables and I say \u201cbecause it is a healthy food that helps you grow\u201d and he asks why again I can start to explain the nuances of nutrition or I can just say \u201cbecause I said so\u201d\u2026 one is introspection and one is justification.\n\nJustification is more common than one might imagine. For much of our own behavior, we cannot point to a rational chain of deduction for a particular outcome, but we can seek plausible justifications for it. This is so natural that we do it without even thinking about it. But it has large implications for the way we work toward programming explanations into our machine learning systems.\n\nDo we want the systems we build to be able to explain the features they\u2019ve learned and how they were applied? Do we want the system to justify why a prediction was reasonable? Do we want both? How can we work to achieve these objectives?\n\nThere is quite a bit of research being done to answer these questions, with techniques generally falling under 3 categories:\n\nIf you\u2019d like to learn more about these techniques, you can view a recent talk (link below) I gave at the O\u2019Reilly AI conference in San Francisco. I\u2019ll also be posting blogs describing each method in detail over the next few weeks.\n\nTo learn more about the work we do at Bonsai, you can visit https://bons.ai/."
    },
    {
        "url": "https://medium.com/@BonsaiAI/reinforcement-learning-bonsai-video-training-series-pt-2-a53d0a0ac922?source=user_profile---------25----------------",
        "title": "Reinforcement Learning: Bonsai Video Training Series, Pt. 2",
        "text": "We\u2019ve put together a series of Training Videos to teach customers about reinforcement learning and The Bonsai Platform. Check out Video 1 to get started with an introduction to types of machine learning.\n\nLast week we started the release of our Bonsai training videos, a series of five videos to help new customers quickly get up to speed on the Bonsai platform, the Inkling programming language, and reinforcement learning. If you don\u2019t yet have access to the Platform but are looking to learn more, this series will allow you to learn what you\u2019ll need to know before you get started using the platform.\n\nThis second video is Introduction to The Bonsai Platform. First, Keen Browne, Head of Product at Bonsai, outlines how to build, teach, and use a BRAIN on the Platform. Then, you\u2019ll learn about Inkling, Bonsai\u2019s special purpose programming language, from its creator Megan Adams. Megan speaks to why this new language was created:\n\nNext, you\u2019ll learn about each of the main components of Inkling while following a demo of a simulated Turtlebot maneuvering around an office. Lastly, Keen closes with an analogy, comparing Bonsai and Inkling to the good ol\u2019 days when databases and SQL were brand new too. Check out the full video below.\n\nFor detailed information about The Bonsai Platform and how it works you can take a look at the Bonsai Whitepaper on our Resources page."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-this-week-in-machine-learning-ep-6-cb37f1cf0067?source=user_profile---------26----------------",
        "title": "Industrial AI Podcast: This Week in Machine Learning, Ep. 6",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out Episode 6 below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nIn Part 6 of TWIML AI\u2019s Industrial AI podcast series, Sam Charrington sits down with research scientist, Calvin Seward, to discuss how he used deep learning to optimize warehouse operations at one of the largest e-commerce companies in Europe.\n\nAt Zalando, Calvin used machine learning to determine the optimal way for workers to move about a warehouse filling carts with goods to be shipped to customers. Calvin discusses these techniques in great detail, including how they progressed from data analytics to deep learning, and how they used simulations to generate the data with which they trained their neural networks. He also touches on how his team leveraged the cart picking solution to create new products, and how managers can start integrating machine learning technologies within enterprises.\n\n\u201cThere\u2019s a progression in companies. The first thing they do is use all the data they have sitting around to drive efficiency. They take existing processes and make it a little bit more efficient with data science and machine learning. And then you can go to the next thing where you create new processes that drive efficiency with data science.\u201d \u2014 Calvin Seward\n\nListen to the full conversation with Calvin in the link to the AI podcast below. To learn more about how you can build reinforcement learning models for warehouse and route optimization in your own organization, visit bons.ai."
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-training-introduction-to-types-of-machine-learning-a51a47259746?source=user_profile---------27----------------",
        "title": "Bonsai Training: Introduction to Types of Machine Learning",
        "text": "This week we start the release of our Bonsai training videos, a series of five videos to help new customers quickly get up to speed on the Bonsai platform, the Inkling programming language, and reinforcement learning. To improve accessibility, we\u2019ve decided to take our on-site training program and break it up into small bite-sized videos for our general audience to learn from. These videos will allow you to learn what you\u2019ll need to know before you get started using the platform.\n\nThis first video is titled Introduction to Types of Machine Learning and is broken up into two parts, an overview of three main types of machine learning, and then a quick 4-part quiz to make sure these basic concepts are firmly cemented. You\u2019ll learn to differentiate between the three types of learning, and specifically how to differentiate reinforcement learning from the more widely used supervised and unsupervised learning. This is important because reinforcement learning is the method currently used by The Bonsai Platform.\n\nCheck out the full video below and stay tuned for the next video in the series, Introduction to The Bonsai Platform.\n\nFor more information about how Bonsai uses reinforcement learning you can read our blog on Mark Hammond\u2019s Deep Reinforcement Learning presentation at GTC this year."
    },
    {
        "url": "https://medium.com/@BonsaiAI/explainable-ai-machine-teaching-58f8649ce62?source=user_profile---------28----------------",
        "title": "Explainable AI & Machine Teaching \u2013 Bonsai \u2013",
        "text": "At the O\u2019Reilly AI conference in New York this past June, I had a chance to speak on an important topic: the latest techniques and cutting-edge research currently underway to build Explainable AI.\n\nGreater interpretability is crucial to greater adoption of applied AI, yet today\u2019s most popular approaches to building AI models don\u2019t allow for this. Explainability of intelligent systems has run the gamut from traditional expert systems, which are totally explainable but inflexible and hard to use, to deep neural networks, which are effective but virtually impossible to see inside.\n\nIn this talk, I examine two approaches to building explainability into AI models \u2014 learning deep explanations and model induction \u2014 and discuss the effectiveness of each in explaining classification tasks.\n\nI also look at how a third category \u2014 learning more interpretable models with recomposability \u2014 uses building blocks to build explainability into control tasks. This last approach, along with Machine Teaching, is a cornerstone of the Bonsai Platform. I demonstrate exactly how this works within the Platform at the end of my talk by building an AI model to beat the game Lunar Lander.\n\nI invite you to watch the talk in its entirety below or view the slides here. To learn more about how Bonsai is building Explainable AI with Machine Teaching, visit our How It Works page or check out the Bonsai Early Access Program."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-69914ad708da?source=user_profile---------29----------------",
        "title": "Industrial AI Podcast \u2013 Bonsai \u2013",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out Episode 5 below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nIn part 5 of TWIML AI\u2019s Industrial AI series, Sam Charrington catches up with Professor Sergey Levine, a roboticist at UC Berkeley. Sergey\u2019s work focuses on how robotic learning techniques can be used to allow machines to autonomously acquire complex behavioral skills.\n\nSam and Sergey discuss deep reinforcement learning at length, including mastery v. generalized training, multi-task learning, transfer learning and how researchers are working towards using past experiences to accelerate future learning in robotics.\n\nListen to the full conversation with Sergey below. To learn more about how you can leverage reinforcement learning in your own industrial systems, visit bons.ai."
    },
    {
        "url": "https://medium.com/@BonsaiAI/why-i-joined-bonsai-b63e52772e32?source=user_profile---------30----------------",
        "title": "Why I joined Bonsai \u2013 Bonsai \u2013",
        "text": "After working for almost 20 years on software platforms and tools for companies like Microsoft, Intel and others, I\u2019ve just last week started at Bonsai in the product management team. Since taking the job, a lot of people have asked me how I chose Bonsai out of all the different artificial intelligence companies, so I decided to share my story here.\n\nDuring summer 2016, I participated in a three-day Artificial Intelligence workshop organized by the Aspen Institute\u2019s Socrates chapter. Led by the incredible Neil Jacobstein, from Singularity University, our group of around 30 participants from different backgrounds worked through a comprehensive set of curated materials and engaged in deep discussions on the subject at hand. This was not meant to be a technical deep dive but rather a starting point for developing a perspective of the impacts of Artificial Intelligence and automation on societies. At the last day of the gathering, we all were convinced that we\u2019ve entered a time that will come with dramatic changes touching every aspect of human society and everyday life.\n\nThis anticipated shift made me recognize that I want to be part of upcoming AI revolution and make it my career in the foreseeable future. It also turns out, AI is a substantial field presenting a large number of opportunities for a Product person like me. While it has been around since the 50s, we recently experienced a large improvement in its ability to deliver results that have never been achieved before, which led to a large number of start-ups and increased investments by established enterprises. This has also presented a significant amount of opportunities for somebody looking to get into this space.\n\nThroughout my career, I\u2019ve been passionate about building platforms that allow both individual programmers and enterprises to develop applications that can address a broad range of uses cases. Applying this to the AI world, I decided to follow that passion and look for artificial intelligence companies building AI platforms focused on enabling users to build smarter applications by adding the latest Deep Learning (DL) technologies into their offerings.\n\nWhen evaluating platforms in general, they have to meet a number of key guiding principles:\n\nWhen assessing the AI Platform landscape it basically came down to three different approaches that I could choose from. There are Cloud Providers which are established large scale companies that offer Machine Learning as a Service (MLaaS). Familiar household names include Google, Amazon, Microsoft, IBM and others. Secondly there are Start-Ups using a simple abstraction approach of trying to make using existing DL networks easier by creating some sort of a wrapper that hides complexity. And then there are those visionary companies that have decided it is worth the risk to take a fundamentally different approach to solving the problem.\n\nAfter doing a significant amount of research and playing around with some of the existing tools and technologies like TensorFlow, Keras etc., I eventually found Bonsai.\n\nFalling into the 3rd category from above, Bonsai uniquely provides a complete platform that allows companies and developers to build AI into their applications without requiring in-depth knowledge of the latest Deep Learning technologies. I found this approach to be extremely compelling compared to how the rest of the industry is addressing the problem. The large cloud providers are investing heavily in core AI frameworks and research but are less willing to implement substantially different ways to solve customer problems, while most of the startups are also only making incremental progress in delivering against the above stated principles.\n\nThings got really exciting when I started to learn more about the individuals who founded Bonsai. Mark Hammond, the CEO, has this ability to clearly articulate what problems the company is solving and how it is doing it. While this should be a given, it\u2019s a rare find in an extremely challenging space that requires sophisticated solutions. After more discussions with the leadership team, especially with the co-founder and Head of Product, Keen Browne, I was convinced to have found the right place for me. We immediately found common ground on how we saw the platform space, and how to build products focusing on solving customer problems, as well as how we should work across teams in an environment that is dynamic, fun and rewarding.\n\nI\u2019m super excited to have joined a company whose founders vision is centered around how to create a platform for enterprises and individual developers that can learn to solve a huge number of problems using concepts that everybody understands. Done right, we can enable our customers to stay out of the weeds of low-level machine learning libraries and instead focus solely on solving real business problems.\n\nTo read more about what we are up to at Bonsai, you can read more about our AI Platform here, or if you prefer you can jump straight into the docs.\n\nAlso, we\u2019re hiring \u2014 please come and check out our open positions."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-59172d666038?source=user_profile---------31----------------",
        "title": "Industrial AI Podcast \u2013 Bonsai \u2013",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out Episode 4 below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nIn episode 4 of TWiML AI\u2019s Industrial AI series, Sam Charrington sits down with Yodit Stanton, the founder and CEO of Opensensors.io. Yodit started Opensensors to create a real-time data exchange for IOT and currently focuses on using IOT data to optimize Smart Buildings. Sam and Yodit discuss deriving value from IOT data, applying AI technologies to IOT, and building models that combine real world data and domain expertise.\n\nYou can hear the entire conversation with Yodit below. If you\u2019d like to learn more about using reinforcement learning to solve enterprise control and optimization problems, head to bons.ai."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-68497a97f095?source=user_profile---------32----------------",
        "title": "Industrial AI Podcast \u2013 Bonsai \u2013",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7 part series on Industrial AI. Check out Episode 1 below and download our latest paper exploring the unique challenges and requirements of Industrial AI.\n\nIn Part 3 of TWIML\u2019s Industrial AI series, Sam Charrington digs into robotics and reinforcement learning with Berkeley PhD student, Chelsea Finn. This talk gets into some of the technical weeds of cutting-edge robotics technologies, including inverse reinforcement learning, meta learning and the benefits and challenges of training robots in simulations. Chelsea also talks about what it\u2019s like pursuing a PhD in machine learning and how to keep up with such a rapidly advancing field.\n\nCheck out the full conversation with Chelsea below. If you want to explore using reinforcement learning in your own organization, learn more at bons.ai."
    },
    {
        "url": "https://medium.com/@BonsaiAI/introducing-gears-80d07e8dc876?source=user_profile---------33----------------",
        "title": "Introducing Gears \u2013 Bonsai \u2013",
        "text": "A new way to blend existing models or classical controllers with state-of-the-art reinforcement learning.\n\nToday we announced a new feature, Gears, to help programmers leverage their existing AI models and code to solve reinforcement learning problems with the Bonsai Platform.\n\nUsing Gears, a Bonsai Platform programmer can replace any \u201cconcept\u201d in an Inkling program with existing Python code. In effect this means you can transform data flowing into our Bonsai Platform generated reinforcement learning algorithms. These transforms can include other machine learning models built with frameworks like Google\u2019s TensorFlow and even \u201cskills\u201d that incorporate classical control operations into a more complex AI model. At Bonsai, we\u2019re building Gears to:\n\nTo be clear there are still many restrictions on this feature. As such, Gears are currently only available to those that are part of the Bonsai Early Access Program. We will, of course, relax these restrictions over time.\n\nLet\u2019s explore how one could use a Gear in a Robotics application. For this application, we will teach a robot arm to pick and place blocks.\n\nOur first step is to break this problem down into four discrete skills which we can define in Inkling: reach, grasp, move, and stack. In this particular example we\u2019ve decided to code the more dextrous manipulations, grasp and stack, using concepts (and accompanying curriculums, not shown in the code sample below) so the AI Engine will generate and train a model to learn those skills. Move and reach are simpler skills and can be coded using a classical controller, so we define these as Gears. Lastly, these four concepts are blended together using the AI Engine\u2019s underlying selection and synthesis mechanisms.\n\nIn inkling we promise a Gear for reaching and moving the arm. We resolve that with some Python code using MoveIt!:\n\nAdditional capabilities we are working on enabling within gears include:\n\nTo learn more about Gears and the Bonsai Platform, sign up for an in-depth webinar and demo on July 13th with Bonsai co-founder and Head of Product, Keen Browne: https://bons.ai/gears-webinar-signup. For more information on how to join Bonsai\u2019s Early Access Program, visit: https://bons.ai/getting-started.\n\nThe Gears feature is available today for partners in the Early Access Program. If you have a control or optimization use case within your organization, learn more about the Early Access Program at https://bons.ai/getting-started."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-problems-f3d8babb2c73?source=user_profile---------34----------------",
        "title": "Industrial AI Problems \u2013 Bonsai \u2013",
        "text": "A recent Gartner report predicts half of enterprises will be using some measure of artificial intelligence next year. But most discussions of enterprise AI use cases focus on applications in the digital domain; use cases like getting people to click on ads, making recommendations, personalizing customer experience, predicting customer churn, and detecting fraud of various sorts.\n\nThese don\u2019t account for Industrial AI problems; systems in organizations that don\u2019t exist purely in digital form.\n\nThere is a huge opportunity for enterprises with Industrial AI problems \u2014 including robotics, manufacturing, supply chain, logistics, energy and utilities \u2014 to monitor, optimize or control the behavior of these operations and systems for improved efficiency and performance.\n\nTo shed some light on the unique challenges and requirements of building intelligence into industrial systems, we have partnered with Sam Charrington (@samcharrington) at CloudPulse Strategies to produce a special report on \u201cAI for Industrial Applications\u201d. You can download the report here.\n\nYou can also check out Sam\u2019s podcast, This Week in Machine Learning & AI, where we have sponsored a series of interviews covering Industrial AI from a number of different perspectives. The latest episode with renowned roboticist Pieter Abbeel can be found here."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-f714b0fd2739?source=user_profile---------35----------------",
        "title": "Industrial AI Podcast \u2013 Bonsai \u2013",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7-part series on Industrial AI. Check out Episode 2 below and stay tuned for an upcoming paper exploring the unique challenges and requirements of Industrial AI.\n\nIn Part 2 of TWIML\u2019s Industrial AI series, Sam Charrington talks to renowned roboticist, Pieter Abbeel. Pieter and Sam discuss the basics of reinforcement learning, the challenges of training robotics systems for commercial applications, and where this technology is headed.\n\nBe sure to listen to the full conversation with Pieter below. If you want to explore using reinforcement learning in your own organization, learn more at bons.ai or download our whitepaper."
    },
    {
        "url": "https://medium.com/@BonsaiAI/deep-reinforcement-learning-10ca020f6063?source=user_profile---------36----------------",
        "title": "Deep Reinforcement Learning \u2013 Bonsai \u2013",
        "text": "Last month, I had the chance to speak at at NVIDIA\u2019s 2017 GPU Technology Conference in San Jose. The conference brought together academics, startups and enterprises all leveraging the incredible recent advancements in GPU computing for machine learning. With such a GPU-centric audience, I focused my talk on the how to deal with the headache of latency, hazards, and pipeline stalls in the GPU era.\n\nIn the realm of deep reinforcement learning, stateful, interactive simulation based workloads push these problems to the extreme, necessitating a handoff to the simulator on every iteration \u2014 and that simulator may not even by running on the same machines as the deep reinforcement learning model!\n\nFor control and optimization problems using simulation based workloads, deep reinforcement learning models are highly relevant, and there are many nuances to optimizing usage of the GPU. Since you can\u2019t simply batch data to load into GPU memory for learning, new techniques are needed to keep the GPU humming and not stalled waiting for other parts of the system to catch up.\n\nFor example, in a typical interactive controller application, any control action that is given must be sent to the simulator or physical system to be carried out, the resulting new state must be returned and evaluated, and that data is then available to be used to update the learning system. Consequently, there are seemingly unavoidable transitions between the deep reinforcement learning model and the simulator, as well as latency for transmission and execution. In these cases, optimizing use of the GPUs becomes a non-trivial concern.\n\nIn this talk, I explore lessons we\u2019ve learned on how to avoid these performance degrading modern hazards. You\u2019ll learn some tricks and techniques \u2014 including approaches to pool multiple concurrent simulations for use with single networks \u2014 that you can employ in your own systems to increase performance with your deep reinforcement learning workloads. This talk will present data from Bonsai\u2019s platform (a mix of python + tensorflow, C++, and inkling), but the lessons learned and resulting tricks and techniques can be leveraged broadly.\n\nYou can watch the talk below or view the slides here. If your organization has a use case that can benefit from reinforcement learning, check out the Bonsai Early Access Program and start leveraging AI in your own industrial systems."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-podcast-79c4237ea08a?source=user_profile---------37----------------",
        "title": "Industrial AI Podcast \u2013 Bonsai \u2013",
        "text": "We\u2019ve partnered with the This Week in Machine Learning & AI podcast for a 7-part series on Industrial AI. Check out Episode 1 below and stay tuned for an upcoming paper exploring the unique challenges and requirements of Industrial AI.\n\nIn the first episode in the series, Sam Charrington sat down with Ilia Baranov, engineering manager at Clearpath Robotics. Ilia talks about the future of robotics in industrial settings, how to leverage existing subject matter expertise to train robots to work cooperatively with humans, and the challenges and approaches to achieving full autonomy.\n\nHear more from Ilia in the full episode below. If you\u2019ve got a use case like this, learn more at bons.ai or download our whitepaper."
    },
    {
        "url": "https://medium.com/@BonsaiAI/ai-models-webinar-using-machine-learning-to-solve-business-problems-7477aba61e0?source=user_profile---------38----------------",
        "title": "AI Models Webinar: Using Machine Learning to Solve Business Problems",
        "text": "Bonsai CEO, Mark Hammond, recently sat down with NVIDIA VP and GM, Jim McHugh to talk about the challenges and requirements for building programmable, adaptive and trusted AI models.\n\nWatch this on demand webinar to learn about the spectrum of AI use cases and how enterprises can combine cutting-edge machine learning technologies with deep domain expertise to solve real business problems.\n\nThe key topics covered in this webinar include:"
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-ai-platform-faa54df0a76b?source=user_profile---------39----------------",
        "title": "Bonsai AI Platform \u2013 Bonsai \u2013",
        "text": "When meeting with customers today there is inevitably a conversation about the applications and use cases that are best suited for the Bonsai Platform. And while coming at it from different angles, both parties are well aligned with the intent of the discussion: 1) Can we identify a specific hardware or software application that would drive increased business value from greater intelligence, 2) Is the Bonsai Platform well suited to enable you to program AI models to deliver on this objective?\n\nWith Bonsai initially optimized for a particular set of applications, specifically programming control and optimization into industrial systems including robotics, supply chain, manufacturing and HVAC, it is extremely important to be very targeted when identifying appropriate use cases for the platform. Our primary objective in any customer engagement is to help identify the \u2018best fit\u2019 use cases as quickly as possible. To help expedite this discovery process, we have devised three questions to qualify whether or not a specific application is a fit for Bonsai:\n\nBefore going any further in a customer engagement it is important to confirm that the application in question falls within Bonsai\u2019s current area of focus on the AI use case spectrum.\n\nWhile there are many possible use cases that would benefit from increased intelligence, Bonsai is optimized today for programming AI models that improve system control and enhance decision support. Building greater intelligence into these applications results in lower costs, and increased operational efficiency.\n\nThis one is a bit tricky. The Bonsai Platform currently uses deep reinforcement learning algorithms to train AI models. Deciphering whether or not an application can increase automation, or enhance operational efficiency through deep reinforcement learning requires a better understanding of a how the system interacts with its environment, and how that interaction changes the state of the environment. The more dynamic the interactions are between the controller (e.g. a robot) and its environment, the better suited reinforcement learning is relative to data-centric techniques.\n\nTo better understand how exactly a system interacts with its environment we usually walk through this sequence of questions below:\n\na. Does the system interact with a real world environment? In this question we are trying to gauge if a system\u2019s predictions, or actions in the case of a robot, impact state, or have material consequences to the environment it interacts with? If the answer is yes, this suggests that the system may be a good candidate for RL.\n\nb. Is the environment the system interacts with always presented consistently, or does it vary? In the case of a specific part, item, or package, is it in the same place and orientation all the time? If the environment varies frequently this implies that the system may be a good candidate for RL.\n\nc. Are the system\u2019s interactions with its environment predictable or unpredictable? For example, if a self-driving car is instructed to turn left at an intersection, and the same arrangement of cars is present at that intersection as has been previously observed, you cannot expect the behavior of the environment to be the same as before. If the interactions are unpredictable, this means that the system may be a good candidate for RL.\n\nd. Does system setup need to be re-tooled often to accommodate new runs/configurations? A real life example is the factory restructuring that takes place to accommodate a new vehicle model. If retooling occurs frequently then the system may be a good candidate for RL.\n\nWith the Bonsai Platform today, learning is greatly enhanced from interacting with a simulation of a real world environment. As a result, it is important to understand whether or not a system\u2019s operations and interactions with its environment can be simulated, or modeled. An example of this would be an HVAC system, which can be both modeled in advance, while also collecting real-time telemetry."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-use-cases-e1dbd6325e31?source=user_profile---------40----------------",
        "title": "Industrial AI Use Cases \u2013 Bonsai \u2013",
        "text": "This is the final installment of a six part series from our recently published whitepaper; A fundamentally different approach for building intelligent industrial systems. You can download the complete paper here.\n\nThe Bonsai Platform is best suited for programming AI models that can inject greater intelligence, in the form of control and optimization, into sophisticated industrial systems. Models produced with the Bonsai Platform help increase the automation and operational efficiency of these systems.\n\nThere are currently two Industrial AI use cases for the platform:\n\nIf you think you have an Industrial AI use case that could be a fit for the Bonsai Platform, visit https://bons.ai/getting-started to learn how to get started."
    },
    {
        "url": "https://medium.com/@BonsaiAI/machine-teaching-machine-learning-c0ed7c74be75?source=user_profile---------41----------------",
        "title": "Machine Teaching & Machine Learning \u2013 Bonsai \u2013",
        "text": "This is the fifth installment of a six part series from our recently published whitepaper; A fundamentally different approach for building intelligent industrial systems. You can download the complete paper here.\n\nBonsai brings together state of the art techniques in machine teaching and machine learning, providing developers, data scientists, and subject matter experts with the tools to teach the desired intelligence to a system, while automating the complex, low level mechanics of machine learning. With the Bonsai Platform, enterprises can more efficiently build application specific AI models that increase the automation and operational efficiency of sophisticated industrial systems.\n\nStarting with Inkling, Bonsai\u2019s special purpose programming language, developers codify the specific concepts they want a system to learn, how to teach them, and the training sources required (e.g. simulations, data). We refer to this technique as Machine Teaching. Each Inkling program developed with this approach is fed into the Bonsai AI Engine, where it is paired with state of the art machine learning libraries (e.g. Tensorflow) and techniques (e.g. reinforcement learning) to generate and train the most appropriate model. The resulting high-level model can then be connected into your hardware or software application through Bonsai provided libraries. Each model is available for ongoing debugging and refinement, and can be repurposed for use in other applications.\n\nAn AI learns from interacting with a simulation or analyzing recorded data. Using the Bonsai Platform, each AI model is created by following the three step sequence outlined below.\n\nFor more detailed technical information and demos of the Bonsai Platform visit our Docs page."
    },
    {
        "url": "https://medium.com/@BonsaiAI/how-machine-teaching-can-expand-reach-effectiveness-of-machine-learning-ebc2c9ce9f35?source=user_profile---------42----------------",
        "title": "How Machine Teaching Can Expand Reach, Effectiveness of Machine Learning",
        "text": "Enterprises of all sizes are evaluating artificial intelligence for a range of use cases beyond business-to-consumer and data-centric applications.\n\nIn particular, there is a growing need for AI models that can inject greater intelligence \u2014 in the form of control and optimization \u2014 into sophisticated industrial systems. These systems take many different forms, including robotics, vehicles, factories, supply chains, logistics, warehouse operations, HVAC systems, oil exploration and resource planning.\n\nTrying to program AI to improve control and enhance real-time decision support for multidimensional, industrial systems quickly outstrips the capabilities of generic solutions. At the core of the issue is the lack of talent or tools that can combine an organization\u2019s subject matter expertise with complex machine learning technologies to build application-specific AI models.\n\nSubject matter expertise, in the form of data, models and simulations, is critical to understanding the different variables, behaviors and constraints that drive the efficient operation of industrial systems. Paired with powerful machine learning libraries and techniques, like TensorFlow and reinforcement learning, specific domain expertise can significantly improve the efficiency and prediction accuracy of produced intelligence models, as well as the automation and operational efficiency of targeted systems.\n\n\u25cf Human intelligence provides critical subject matter expertise that understands the variables that yield the most efficient operation of specific systems.\n\n\u25cf Machine intelligence is critical for helping systems learn faster and make better predictions, but this by itself is a brute force approach that can be complex and inefficient, especially for industrial systems applications.\n\nThroughout the history of AI, we\u2019ve seen innovations at both extremes. Expert systems gained popularity in \u201970s and \u201980s \u2014 solely based on subject matter expertise. This approach worked for simple deductions, and had strong explainability. However, it struggled with more complex predictions, was very rigid and difficult to scale.\n\nWith machine learning today, the pendulum has swung to the other side, focusing exclusively on finding patterns within huge piles of data without relying on any subject matter expertise. What\u2019s still missing is an approach that can combine subject matter expertise, with the massive learning horsepower of machine intelligence, making the programming and management of AI models more accessible to developers and enterprises.\n\nFortunately for us, industry has tackled this problem before in other technology domains. Before databases were commonplace, it was very difficult to work with data in sophisticated ways. Databases solved this problem nicely, but they didn\u2019t do it by providing a massive toolkit to tweak and tune all the low-level database mechanics. Instead, databases shifted up the level of abstraction, allowing developers to focus on the problem they were trying to solve.\n\nAI suffers from a very similar problem today. The low-level machine learning libraries and algorithms are very difficult to work with. To make AI more accessible, the answer is not to expose these vast, complex toolkits to developers. Just like databases did for data, we need to shift the level of abstraction. This is where machine teaching comes in.\n\nMachine teaching provides the abstraction and tooling for developers, data scientists and subject matter experts to program domain-specific intelligence into a system. Using a special purpose programming language like the one we have built at Bonsai, developers codify the specific concepts they want a system to learn, how to teach them and the training sources required (for example, simulations or data).\n\nUsing Bonsai\u2019s AI Platform, programs developed with this approach can then be paired with state-of-the-art machine learning libraries such as TensorFlow and techniques such as reinforcement learning to more effectively generate and train the most appropriate high-level models for use in a specific hardware or software application.\n\nBy combining state-of-the-art techniques in machine teaching and machine learning, enterprises can more efficiently build application specific AI models that increase the automation and operational efficiency of sophisticated industrial systems."
    },
    {
        "url": "https://medium.com/@BonsaiAI/ai-development-platform-81c775c5c449?source=user_profile---------43----------------",
        "title": "AI development platform: \u2013 Bonsai \u2013",
        "text": "This is the third installment of a six part series from our recently published whitepaper: A fundamentally different approach for building intelligent industrial systems. You can download the complete paper here.\n\nBringing together expertise in neuroscience and developer platforms, Bonsai was founded in 2014 by Mark Hammond and Keen Browne with the vision of making intelligence a core component of every hardware and software application. Recognizing the shortage of data science talent capable of building sophisticated AI models, they created an AI development platform that abstracts away the complexity of libraries like TensorFlow, making the programming and management of AI models more accessible to developers and enterprises. Bonsai achieves this vision by applying a proven approach to a new problem, providing an abstraction layer above the low-level AI mechanics.\n\nBefore databases were commonplace, it was very difficult to work with data in sophisticated ways. Databases solved this problem nicely, but they didn\u2019t do it by providing a massive toolkit to tweak and tune all the low-level database mechanics. Instead, databases shifted up the level of abstraction, allowing developers to focus on the problem they were trying to solve.\n\nAI suffers from a very similar problem today. The low level machine learning libraries and algorithms are very difficult to work with. To make AI more accessible, the answer is not to expose these vast, complex toolkits to developers. Just like databases did for data, Bonsai has shifted up the level of abstraction. As shown in the graphic above, Bonsai provides a developer with a special purpose programming language to codify the concepts unique to their problem domain, a runtime that generates and manages all the low level mechanics for them, and the libraries to connect the resulting AI models into hardware and software applications.\n\nFor more information about the Bonsai AI Development Platform visit our Product page."
    },
    {
        "url": "https://medium.com/@BonsaiAI/programming-intelligence-into-industrial-systems-85e3a7accef4?source=user_profile---------44----------------",
        "title": "Programming Intelligence Into Industrial Systems \u2013 Bonsai \u2013",
        "text": "This is the second installment of a six part series from our recently published whitepaper; A fundamentally different approach for building intelligent industrial systems. You can download the complete paper here.\n\nProgramming AI to improve control and enhance real time decision support for multidimensional, industrial systems quickly outstrips the capabilities of generic AI solutions. At the core of the issue is the lack of talent and/or tools that can combine an organization\u2019s subject matter expertise with complex machine learning technologies to build application-specific AI models.\n\nSubject matter expertise, in the form of data, models, and simulations, is critical to understanding the different variables, behaviors, and constraints that drive the efficient operation of industrial systems. Paired with powerful machine learning libraries and techniques, like TensorFlow and reinforcement learning, specific domain expertise can significantly improve the prediction accuracy of produced intelligence models, as well as the automation and operational efficiency of targeted systems.\n\nUp until now there has not been a platform available for enterprises to efficiently fuse together subject matter expertise and AI without requiring an advanced degree in machine learning. Consequently, enterprises have been forced to compete for the rare talent that can work with low-level AI toolkits, limit use cases to those with established APIs, or be unnecessarily constrained by black box solutions.\n\nTo learn more about Bonsai\u2019s fundamentally different approach for programming AI, visit our How it works page."
    },
    {
        "url": "https://medium.com/@BonsaiAI/industrial-ai-d196d84b206?source=user_profile---------45----------------",
        "title": "Industrial AI \u2013 Bonsai \u2013",
        "text": "This is the first installment of a six part series from our recently published whitepaper; A fundamentally different approach for building intelligent industrial systems. You can download the complete paper here.\n\nEnterprises of all sizes are actively evaluating artificial intelligence (AI) for a range of use cases beyond business-to-consumer (B2C) and data-centric applications. Shown on the left side of the graphic below, there is a growing need for AI models that can inject greater intelligence, in the form of control and optimization, into sophisticated industrial systems. These systems take many different forms, including robotics, vehicles, factories, supply chains, logistics, warehouse operations, HVAC systems, oil exploration, and resource planning.\n\nRecognizing this trend, market analysts have begun forecasting the size of the opportunity for these intelligent industrial systems. IDC recently pegged the market for Cognitive & Artificial Intelligence Systems at $12.5B today, growing to $46.0B by 2020. David Schubmehl, Research Director, Cognitive Systems and Content Analytics at IDC, commenting on the opportunity for these AI-enabled systems, remarked:\n\nBreaking down the market opportunity further, he noted:\n\nIn a recent Economist article, The Growth of Industrial Robots, unit sales of industrial robots were cited to have increased by 15% in 2015, while revenues grew 9% to $11bn. In the article, ABI Research, a consultancy, forecasted industry sales to triple by 2025.\n\nMeanwhile, a recent Forbes article discussed the size of the Industrial AI opportunity outside of robotics.\n\nAcross the different applications highlighted above, the business objective is very often to increase automation or enhance operational efficiency. In programming intelligence into these systems, organizations require industrial-strength AI models that can hold up to the unique requirements of these dynamic, unconstrained problem spaces.\n\nTo learn how Bonsai enables enterprises to build more programmable, adaptive and trusted AI models, watch this video."
    },
    {
        "url": "https://medium.com/@BonsaiAI/cultivating-the-bonsai-ai-platform-6112592310f?source=user_profile---------46----------------",
        "title": "Cultivating the Bonsai AI Platform \u2013 Bonsai \u2013",
        "text": "With the strategic funding and Early Access Program announced today, I am excited to accelerate our product development and customer engagement efforts. Countless conversations with enterprises, ISVs and technology partners over the last 12+ months have simultaneously validated the fundamental product assumptions from our founding in 2014, and informed the investments we need to make in the future.\n\nThere is a rapidly growing demand from enterprises of all sizes for AI models that can inject greater intelligence, in the form of control and optimization, into dynamic industrial systems. These systems take many different forms, including robotics, vehicles, factories, supply chains, logistics, warehouse operations, HVAC systems, oil exploration, and resource planning. Programming sophisticated AI that can improve the automation and operational efficiency of industrial systems requires a platform that can account for a variety of factors:\n\nLet\u2019s consider an example of a pick-and-place robot on a work site. If we want to be confident in the behavior of this robot in an open, dynamic environment, we need a rigorous mechanism for training. Luckily, there is an entire field of study dedicated to helping data scientists, programmers and engineers define how to be structured and rigorous in their approach to training models. Machine Teaching is the counterpart to machine learning. While machine learning focuses on how to best get a computer to learn how to predict or control something, the focus of machine teaching is on how to best teach an ML algorithm.\n\nA combination of Machine Teaching and Machine Learning techniques are at the foundation of Bonsai\u2019s platform and comprise a fundamentally new way to tackle the needs of AI for programming optimization and control.\n\nAt the heart of Bonsai\u2019s approach to tackling complex control and optimization problems is a new special purpose programming language and runtime technology. Inkling, the new special purpose programming language, gives programmers a way to combine machine learning and machine teaching into one AI program. Bonsai\u2019s AI Engine \u2014 the runtime technology \u2014 generates, trains and hosts models that solve the challenge posed by the Inkling program and associated training sources.\n\nA programmer begins by defining a directed graph of concepts for how to solve the problem named the mental model. Concepts in this model are trained using simulations or datasets. Then, the model is deployed for use where it is further fine tuned and then hosted for prediction.\n\nAt Bonsai, our platform enables users to combine learning algorithms into one workflow or pipeline so the AI can make real time predictions or decisions. This pipeline is described by concept keywords and their relationships with one another. For example in the robot case:\n\nConcepts represent features of the environment the AI must perceive or skills that the AI must combine to accomplish a goal. These concepts can be models predefined by the programmer using toolkits like TensorFlow or the models can be selected and tuned automatically by Bonsai\u2019s AI Engine. In the above example, the robot must combine the skills of moving to a target, grasping and lifting, and picking and placing. The feeds and follows keywords specifically state that the AI should first learn how to MoveToTarget GraspAndLift and use those new skills as a basis for then learning PickAndPlace.\n\nEach concept is taught using a curriculum. Curriculums are further decomposed into lessons and each lesson uses all or some subset of real or synthetic data to train that portion of the AI.\n\nFor example the TeachMoveToTarget curriculum starts the arm off close to a target within a simulation. The AI masters ability to reach the target in that close-in configuration; the AI is then taught to move to target from further away. This initial simplification of the training environment shortcuts the amount of exploration the AI needs to move through in order to train. Each lesson in the curriculum optimizes some objective or reward. This objective or reward is calculated using the state of the simulation or physical environment.\n\nInitial lessons are in simulation while later lessons tweak the model in the real world. Robotics applications can be trained using many simulations like Gazebo, RobotStudio or RobotExpert. The simulator or programmed solution uses a Bonsai Library to receive control signals from the Bonsai AI Engine over a Websocket.\n\nThe AI Engine can run in the cloud or on-robot. Deployed models are automatically versioned so that use of each model has consistent behavior. The accompanying libraries and standardized Web APIs are designed to connect to a wide array of systems and applications.\n\nIf you think you have a control or optimization use case that would be a good fit for the Bonsai Platform, we want to hear from you. Our Getting Started page has all the information you need to learn about and apply for our Early Access Program."
    },
    {
        "url": "https://medium.com/@BonsaiAI/ai-use-cases-9d1b70e61396?source=user_profile---------47----------------",
        "title": "AI use cases \u2013 Bonsai \u2013",
        "text": "When out talking to prospective enterprise customers we often find that the AI use cases that get the most attention in the technology press (e.g. chat-bots) fail to resonate with enterprises looking to leverage AI to solve more complex business problems. But it is not too hard to see how we got to this point. In current form, the easiest way to demonstrate the merits of cutting edge machine learning algorithms is by training systems to compete in games, solving \u201ctoy problems.\u201d\n\nDerrick Harris (@derrickharris) describes the key issue that arises from this dynamic in his most recent ArchiTECHt.io blog:\n\nBeyond games as a proving ground, the earliest actual applied AI use cases favor applications where there is a mountain of available data to leverage as the primary training source which helps explain the attention paid to virtual assistants, image recognition, and sentiment analysis. The reason for this can also be easily rationalized: in building these intelligent systems, the easiest way to train them is with loads of data. In fact, this pocket of AI use cases are a natural extension of big data, leveraging gigantic datasets to train machines to make faster and more accurate predictions and recommendations than we would otherwise make on our own.\n\n\u200dBut data is not the answer for every AI problem. Applications toward the left side of the spectrum in the graphic shown above are characterized by dynamic and expanding problem spaces (e.g. your Roomba doesn\u2019t know your floor plan, the robot assisting in manufacturing of your car is retooled every model year, etc.). In these environments, more than raw data must be relied upon as the training sources if the goal is to build programmable, adaptive, and trusted intelligent systems.\n\nThere are at least two drivers of this reality. The first is money. The investment required to physically model and optimize the many different dimensions and variables within these complex settings quickly outruns the time, budget, and skill-set of many developers and enterprises. The second is knowledge. Enterprise systems and business processes are constructed, configured, and continually optimized in part based on input from an organization\u2019s most strategic asset: subject matter expertise. Despite what some would lead you to believe, this expertise doesn\u2019t all sit neatly in some database or model. It sits in the spreadsheets and brains of the business analysts, the field engineers, the civil and mechanical engineers, etc. Capturing and codifying this expertise to create more intelligent and autonomous systems is not a big data problem. As such, for AI to realize its true potential, enterprises are going to have to think differently about solving these type of problems relative to the data-centric training blueprint that dominates the AI use cases covered in the media today. More concretely, this means that beyond throwing massive data sets against greater compute power and expecting systems to learn faster and more effectively, we must also come up with better ways to teach them.\n\nIn trying to understand how the enterprise embrace of AI evolves from here I am reminded of a comment made by James Hamilton, VP & Distinguished Engineer at AWS, during a presentation in 2011 regarding data center innovation. His basic point was that most great data center tech shows up in mobile phones first. But Hamilton\u2019s insight likely fell short for those that couldn\u2019t envision how a consumer electronics device could influence the roadmap of something as mission critical as the enterprise data center.\n\nWith AI innovation, it feels like we are at a similar point where games are the proxy, and favorite research proving ground, for the innovations that will eventually bleed into enterprise applications. The enterprises that will lead, and benefit the most from AI adoption will be the ones that can extrapolate real world use cases from the techniques demonstrated first within games. As an industry we must do our part to not only innovate around the AI platforms that will help bridge the gap between toy problems and business problems, but also educate enterprises as to the different lenses through which they can frame the problem.\n\nFor enterprises sorting through AI tools and technologies currently, the good news is that there are already very active pockets of innovation around AI development platforms that foster the construction of intelligent systems without relying solely on massive data sets. The use of simulations and digital twins, leveraging subject matter expertise, and reinforcement learning are just a few examples of emerging tools and techniques that will complement data in the rapidly evolving toolbox of the AI-enabled enterprise. At Bonsai, we are actively working with enterprises to help them leverage our AI development platform to build more intelligent systems and business processes. If you are interested in learning more about how your business can work with the Bonsai Platform to achieve this objective, please contact us to learn more."
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsai-speaks-on-explainability-of-deep-learning-at-sf-meetup-bef4c8a4e14e?source=user_profile---------48----------------",
        "title": "Bonsai Speaks on Explainability of Deep Learning at SF Meetup",
        "text": "First of all, thank you to Mattermark for hosting us and to SF Bay Area\u2019s Machine Learning Meetup for inviting Bonsai to speak last week. They were a friendly bunch of folk and Sarah Catanzaro from Canvas Ventures was a force to be reckoned with in her talk about the pitfalls of machine intelligence startups. Keen Browne here at Bonsai spoke about the Recomposability and Explainability of Deep Learning Systems, and I could tell everyone was very engaged in both talks based on the fantastic questions from the audience.\n\nExplainability is about trust. It\u2019s important to know why our self-driving car decided to slam on the breaks, or maybe in the future why the IRS auto-audit bots decide it\u2019s your turn. Good or bad decision, it\u2019s important to have visibility into how they were made, so that we can bring the human expectation more in line with how the algorithm actually behaves. In an earlier blog on explainability, we touched on its importance in driving broader AI market adoption, and today we\u2019re going to explore this concept from a research perspective.\n\nDARPA defines the goal of Explainable Artificial Intelligence (or XAI as they call it) to \u201ccreate a suite of new or modified machine learning techniques that produce explainable models that, when combined with effective explanation techniques, enable end users to understand, appropriately trust, and effectively manage the emerging generation of Artificial Intelligence (AI) systems.\u201c That is quite the mouthful! To help us understand this concept, Keen unpacks what explainability is and takes a look at how some notable universities around the country are approaching this problem.\n\nFor those of you that don\u2019t have time to watch the video (the TL;DW if you will) I will go over the main topics Keen speaks about from the meetup with the relevant links from the presentation.\n\nThe first paper addressed is around learning semantic associations in video from a whitepaper, Multimedia Event Detection and Recounting, out of SRI International Sarnoff and others. This research was also used in a presentation about XAI (pictured below) by David Gunning at Georgia Tech. Their research was to pick out what they refer to as \u201cconcepts\u201d in the video via the audio, visuals, or even text found in the imaging or captions. The end result was rich metadata that helped you be able to search throughout the video based on seeing what the computer thought would be such as a \u201cgroom\u201d, a \u201cbride\u201d, \u201cthey are looking this way\u201d, \u201cthe crowd is looking that way\u201d, etc from a wedding video.\n\nThe second method, Generating Visual Explanations, is a paper out of UC Berkeley that talks about introspection versus justification. You might not have the introspection on what\u2019s going on in the algorithm based on its weights going in, but it would be possible to justify why the classifier did what it did in hindsight. This is with the aim of making accurate \u2014 and more importantly discriminative \u2014 sentences about the image subject based on the visual and text description.\n\nThe third, and one of our favorites, is LIME out of University of Washington from a paper aptly titled \u201cWhy Should I Trust You?\u201d.They did something pretty cool where instead of trying to apply a textual label, they would highlight in a picture or body of text what made it an exemplar. A perfectly natural dog playing an acoustic guitar was used for the paper and is shown below. This was done by examining \u201csuper-pixels\u201d (a contiguous patch of similar pixels), graying them out, and feeding the resulting image back through the classifier to see if the classification changed. The image below presents the super-pixels with highest positive weights as an explanation, graying out everything else.\n\nWhen working with text in the 20 newsgroups data set, instead of super-pixels, the researchers removed similar groups of words were removed to test if the classification changed. The task was to classify whether a post came from a Christian newsgroup or an Atheist newsgroup, two classes that are hard to distinguish because they share many words. Keen goes through the sample code in the video and you can follow along on github.\n\nThe fourth paper considered is research out of MIT\u2019s Computer Science and Artificial Intelligence Laboratory titled Rationalizing Neural Predictions. In this research, two neural networks, an encoder and a generator, are trained together. Similar to the research done with LIME, the goal was to predict what part of a paragraph, in this case beer reviews, corresponded with the rating it was given. The encoder\u2019s job was to classify the text and build a mapping based on the beer rating, which was then passed through the generator for prediction of the most probable continuous chunk of text that represented that rating.\n\nLastly, let\u2019s take a look at what Bonsai is doing to bring explainability to reinforcement learning. When you\u2019re building a model, instead of focusing on how you\u2019re going to build that model, what if instead you focus on how you\u2019re going to train it? In Bonsai\u2019s programming language, Inkling, you describe a curriculum for training a learning system to perform a task, broken down into concepts and lessons, and the backend handles building models and running them through your curriculum.\n\nBy decomposing behaviors into sub-behaviors and organize them into a hierarchy of concepts, you can now see which behavior is being chosen. Once you have this hierarchy that breaks down the task the system will perform, you can ask which of those concepts contributed to any given behavior the system generates. For instance, you can ask if the car turned right because it was executing its pedestrian avoidance concept, or because its traffic sign detection concept reported a no left turn sign. Explainability means expressing how a concept contributed to the result and how much it contributed.\n\nOur approach is focused on four things, amounting to our strategy for explainable reinforcement learning:\n\nIf you only learn one thing from this blog, it\u2019s that explainability in AI is important! And not only is it important, but it is possible. A human is able to explain what they are doing when approaching a problem, and your AI should too. So consider the different techniques out there, and if you are frustrated by the lack of explainability in your current approach, or are embarking on a quest where explainability is required, I would love to hear from you.\n\nThis is Katherine, Developer Advocate here at Bonsai, signing off. Next week I\u2019ll talk a little about what I do here at Bonsai, and what you can expect from me in the future. You can find me @KatMcCat or over on our forums until then."
    },
    {
        "url": "https://medium.com/@BonsaiAI/the-trunk-6382564d45c3?source=user_profile---------49----------------",
        "title": "The Trunk \u2013 Bonsai \u2013",
        "text": "We\u2019ve built a state-of-the-art, self-healing Artificial Intelligence cluster using the public cloud at AWS using cutting edge technology. We can\u2019t reveal our secret sauce (otherwise it wouldn\u2019t be secret anymore!) but read on to learn about how our Docker expert and Senior Software Engineer Jett Jones and the Bonsai Seattle team built a scalable, resilient AI Engine using some of today\u2019s most exciting configuration management, monitoring, and networking technologies.\n\nProvisioning resources in AWS is a tedious and error-prone task, due to the enormous number of possible options. To make this process repeatable there are several options, but the notion of a \u201ctainted\u201d machine drew us to HashiCorp\u2019s Terraform for machine-level provisioning over similar solutions such as Cloud Formation for launching instances and creating network configurations.\n\nThe recently released Docker Swarm manages post-provisioning creation of services and some of the IPC functionality that allows the services to work together, as well as ensuring that services are launched on the correct machines and providing process management features around starting, stopping, and failure recovery.\n\nOnce we\u2019ve built up the stack of machines and Docker Swarm initiates container launches, we use Consul for service naming and discovery, as well as a key-value store for configuration information and feature flags. This provides service naming through a DNS masquerade service on the conventional DNS port, and also offers an HTTP service for retrieval and storage of keys and values.\n\nRegistrator from GliderLabs (sponsored by WeaveWorks) is auditing Docker engine state on our hosts, so it reports each service back to the Docker Swarm process manager for tracking and identification. This provides the quickest route to service discovery, while maintaining the flexibility of on-demand port assignment.\n\nWith all of these microservices running around, we need to record their logs and monitor their status. The core of our logging and monitoring solution is the Elastic Stack, consisting of Elastic Search, Logstash, and Kibana (you may know it by its superseded common name, ELK Stack). This collects, sorts, collates, and displays the logs for our review. To monitor container status, we rely on Swarm-Kit\u2019s own builtin monitoring and health checks to restart any failed services. Finally, our home-built Watchman service monitors container utilization so we can pause idle containers.\n\nWe have a surprisingly diverse set of data to manage in our cluster, so we rely upon several databases to keep things sorted. PostgreSQL provides a fast relational data store, so we keep user data and configurations in a pgSQL container. For our training graph data, we find that a document store such as MongoDB is sufficiently robust and performant.\n\nTo store training result data as it\u2019s generated, we turn to InfluxDB, the industry leader in time-series data management. Finally, Redis rounds out our data-management stack, providing high speed data operations where they\u2019re needed most.\n\nAt the View level, a Flask server is wired to Gunicorn as a WSGI gateway and proxy to provide connection stability and recycling among other durability features. This produces the Web page for display to end-users, to allow user and BRAIN management, as well as monitoring of training sessions. Gunicorn, in turn, is plugged into the Elastic Load Balancer which forms a network bridge from the public cloud to our cluster.\n\nThe \u201csecret sauce\u201d is our training engine, which is a group of containers that manage the long-running socket connections to simulators and provide the BRAIN itself. In addition to driving the simulator state and action cycle, the training engine maintains optional viewports into neural network state and feeds data into the BRAIN details page for the Accuracy Graph. A description of the components of the AI Engine can be found at Under the Hood in the Bonsai documentation."
    },
    {
        "url": "https://medium.com/@BonsaiAI/inkling-e3032ad5510?source=user_profile---------50----------------",
        "title": "Inkling \u2013 Bonsai \u2013",
        "text": "We\u2019ve written a full language reference in our documentation, and that\u2019s the source of truth. If you\u2019re looking for a few quick pointers to get started, read on for a short introduction to Inkling. We\u2019ll take a close look at the Cartpole sample gym.\n\nWhen creating Inkling code, concepts have inputs and outputs. These are defined using the \u201cfollows\u201d, \u201cpredicts\u201d, and \u201cfeeds\u201d keywords.\n\nRead our documentation for more information about:\n\nThe Inkling language and compiler is quite robust, but there are some semantic pitfalls that users can run into. Here\u2019s a short list:\n\nEven though the Inkling compiler will consume all of your code and evaluate it a a block, it\u2019s helpful to\n\nWe love writing Inkling, and we hope you do to! The guidelines listed above will help you write the best, clearest, and most reliable code out there.\n\nCome visit us in the forums, or file a support request at support if you\u2019d like more information. Follow me at @bitbucketeer and Bonsai at @bonsaiai"
    },
    {
        "url": "https://medium.com/@BonsaiAI/bonsais-non-random-interpretation-of-the-state-of-ai-adoption-fdc37dcdb976?source=user_profile---------51----------------",
        "title": "Bonsai\u2019s Non-Random Interpretation Of The State of AI Adoption",
        "text": "In an attempt to gain a better understanding of the different types of intelligence models that developers are looking to build, we recently sent a brief survey to all of the registrants within our Private Beta Program. Closing in on 550 responses from the initial round of surveys we could not be more appreciative of the engagement and feedback we have received from our growing community. To those that participated, this information will be critical in helping shape the direction of our ongoing product investments. Thank you.\n\nGiven the current industry discussion trying to gauge the status and direction of AI adoption, we thought it would be useful to publish the survey results to help further inform the dialogue. While the questions asked were in some cases specific to the use of Bonsai, due to the horizontal applicability of the platform we think the the responses can also serve as a decent proxy for how people are looking to apply AI more broadly. However, as you read through the results below please keep in mind that the data was derived from a non-random sample as all survey respondents had already self-selected into the Bonsai Beta Program. With that in mind, let\u2019s take a look at the responses\u2026\n\nSelected by 60% of respondents, Prediction is most popular work use case\n\nWith six different use cases each flagging as relevant to 30% of the respondents, there is clearly a wide range of applications looking to benefit from increased intelligence. Notable in these results is what appears to be an emerging interest in use cases that fall outside of classic machine learning use cases of prediction, recommendation and natural language processing. As AI expands its reach, and new tools and technologies become available, we would expect to see continued expansion into these non-traditional use case including adaptive control and system/process optimization.\n\nAt 48%, Prediction also selected as most popular use case for personal projects with a number of others close behind\n\nFor personal projects and/or hobbyists, prediction, NLP, perception, and chatbots ranked as the top four use cases. The composition of these responses is not unexpected given these applications are built on data sets (e.g. text, images) that are more easily accessible to individuals. These applications have also received considerable attention across the AI community, as such there are a number of readily available APIs that can be leveraged to help expedite development.\n\nTensorFlow selected as most popular AI toolkit currently in use\n\nSelected by 42% of respondents, TensorFlow has clearly developed an early mindshare leadership position (at least within our community) for AI toolkits. In contrast, across the IaaS players offering machine learning services we have yet to see the emergence of a clear leader with AWS, Azure and Google all selected by 10\u201312% range. While still very early days in the uptake of these services it will be notable to monitor the adoption trajectory of cloud-based services versus the likes of Tensorflow.\n\nLacking time-series data as this is our first survey, what we can\u2019t decipher from this data is where on the adoption trajectory any of these respondents fall with any one of these tools. Are they happy with the tool they are using, and looking to build on top of them? Or are they displeased and looking for alternatives? Beyond TensorFlow, it is interesting to note the second most selected option was \u201cNone of the Above\u201d at 37%. It is encouraging to see people that are new to AI, and likely lacking machine learning expertise, exploring the different tools and technologies that are accessible to them in the market.\n\nVery early days for simulators but OpenAI Gym (12%) and Simulink (8%) selected as most popular in current use\n\nHowever, with 74% of respondents selecting, \u201cI have never used a simulator\u201d, it is clear that we are very early days in the use of simulations as an AI training source. This lack of use, and likely overall familiarity with simulations leads us to believe that most users haven\u2019t yet considered how a simulator could be combined with AI to solve their problem.\n\nDialing into only those respondents looking to address control or optimization use cases, and those that have never used a simulator approaches 100%. This is an extremely telling response as it relates to both the opportunity and challenge for developers building AI for optimization and control use cases. Control and optimization problems have very large and complex problems spaces that are extremely inefficient and expensive to model in the real world. In these situations simulations are the most viable and cost effective alternative, yet adoption to date as evidenced by this survey is extremely low. We as an industry clearly have our work cut out for us to better convey the benefits of simulation-based training, while also improving the developer experience by proactively integrating and perhaps even hosting select simulators within our platforms."
    },
    {
        "url": "https://medium.com/@BonsaiAI/explainability-c88dfa2e06e6?source=user_profile---------52----------------",
        "title": "Explainability \u2013 Bonsai \u2013",
        "text": "IDC recently released an update to their Cognitive/Artificial Intelligence Systems spending forecast. With this revision they now predict the market will grow from $8B in 2016 to a staggering $47B by 2020, a 55% CAGR over that period. According to the press release, nearly half of all of the revenue throughout the forecast will go to software, including cognitive applications and software platforms. Taking these numbers at face value, it is extremely interesting to think about product implications that will arise if we are to realize anything close to market growth of this magnitude.\n\nIn this context, I find the recent Wired article by Clive Thompson, Sure AI Is Powerful \u2014 But Can We Make It Accountable?, to raise some compelling questions that must be considered in any discussion around the growth of intelligent applications and systems. In the article Clive focuses on the question of how, amidst the increased use of AI-based systems across a wider and wider range of use cases, the industry will deal with the current lack of explainability inherent to most AI and machine learning algorithms. He writes:\n\nCentral to this discussion is the lack of explainability that exists in the current black box approach employed by most AI algorithms and techniques. As Thompson points out in the article, the stakes are raised when unexplainable system biases impact things like bank loan decisions or medical diagnosis. As AI becomes more prevalent in our personal and professional lives, it will inevitably be utilized in increasingly dynamic, mission critical, and non-routine scenarios where the stakes are only going to get higher.\n\nIn order for AI to be confidently deployed, and ideally thrive, in these environments, explainability will be paramount. DARPA refers to this concept as Explainable AI (XAI). Below is an excerpt from a recent presentation by the agency\u2019s David Gunning on the importance of XAI:\n\nExplainability matters for all consumers of AI that want to have confidence and trust in the decisions that are made by the system that they interact with on a daily basis. Explainability matters for the producers of AI, the developers and technologists, that are continually looking to debug, refine and repurpose their models to produce more adaptable, dynamic and intelligent applications and systems. If the Cognitive/AI Systems market is to have a chance at realizing the type of growth that IDC is projecting, then explainability must increasingly be considered as a table stakes requirement in all AI platforms or toolkits.\n\nAt Bonsai, with our focus on adaptive control and system optimization use cases, this is a problem we set out to address from very early on. Each high level model created within the Bonsai AI Engine allows you to see a causal inference chain detailing what contributed to a prediction, identify conceptual gaps and bugs, and constantly refine training. Now with the recent introduction of our Private Beta program we are actively working with developers and enterprises to help validate the platform for specific use cases, while informing future product direction. If you, or someone at your company, are interested in trying out the platform you can sign up here and we will onboard you as soon as we can."
    },
    {
        "url": "https://medium.com/@BonsaiAI/fundamentally-different-approach-to-intelligent-systems-16bcda4e99c4?source=user_profile---------53----------------",
        "title": "A fundamentally different approach to building intelligent systems",
        "text": "In September, I had a chance to speak at the O\u2019Reilly AI conference in New York. I spoke about the power of abstraction, and how we are harnessing that power at Bonsai to unlock AI for every developer.\n\nAbstraction, I would argue, is the single most powerful driving force propelling computing forward. Abstraction has taken integrated circuits from transistor transistor logic gates, to arithmetic logic units, to the processors that we leverage every day. In the realm of data, it has brought us from managing data structures and storage directly, to leveraging libraries of structures and algorithms, to databases and SQL. \n\n \n\n Increasing levels of abstraction let us do more in less time. It also lets us reuse and share work, better understand what\u2019s going on under the hood to debug and iterate more effectively, and even take advantage of improvements in the levels below without having to rebuild our work from scratch.\n\n \n\n Abstraction is what will finally unlock AI for developers.\n\nIn my talk, which you can watch below, I detail how Bonsai\u2019s platform empowers developers to work at a higher level and build smarter apps faster. I also show step-by-step how we trained an AI to play Breakout, and replicated Deepmind\u2019s work, in just 40 lines of code.\n\nWe\u2019re building the platform for artificial intelligence and this talk should give you a good sense of how it works. But ultimately, it\u2019s not about what we do \u2014 it\u2019s about what we enable you to do. You can apply for the private beta at bons.ai or come join the team to help build AI for everyone."
    },
    {
        "url": "https://medium.com/@BonsaiAI/reinforcement-training-basics-f878b2e3ed68?source=user_profile---------54----------------",
        "title": "Reinforcement Training Basics \u2013 Bonsai \u2013",
        "text": "To understand training times in reinforcement learning, it\u2019s helpful to consider both where we\u2019re starting and what we\u2019re going through. I spoke more with Ruofan and our Data Scientist, Ross Story, to find out what influences training times and find guidelines to keep them as manageable as possible. Our AI engine will do the work of picking the best algorithm and hyperparameters; your careful selection or engineering of your training environment can provide a simulator that best represents the problem you want to solve. Ross taught me about the fundamentals of reinforcement learning, so that I would have a clear view of the factors involved in finding or creating a quality simulator.\n\nAs with so many machine learning topics, it\u2019s helpful to consider an analogy to human learning, which is something that we\u2019ve all been exposed to. Just like baby humans, AI systems start with a blank slate \u2014 typically the AI engine has no foreknowledge of the environment it will be working in. All it knows is the state of the environment, the actions it has available to take, and some notion of reward. By iterating over the simulator or data set and observing the rewards and penalties associated with each action and state combination, the engine is able to identify correct combinations of state data and action. In reinforcement learning , the engine is capable of finding successful \u201cpaths\u201d, through a sequence of actions that lead to a desired result. This is not much different from a young child, who first understands that they have a hand, and then that they can move it, followed by the reward of successfully swatting at an object \u2014 a process that typically takes a full three months after birth.\n\nAn iteration is one frame from a simulator. To clearly define an iteration to the AI engine, we want to specify a quality schema, action space, and reward function. In simulators like the OpenAI Gym series, these define the inbound information, the array of available options, and the \u201creinforcement\u201d component of each iteration.\n\nThe schema describes the types of information that is provided to the AI engine that it can use to evaluate the simulator\u2019s current state. In some cases, such as arcade style simulators which use image data as the input, convention indicates a schema that is based on the pixels in the source image; with other sims, the schema will be a collection of scalars or booleans that represent notions that are important to reasoning about the problem; an example would be x_position in Mountaincar. The state space is the total of all possible combinations of states, so in MountainCar that is the entire range on the x axis that could be occupied by the car, or in the case of an image buffer, it\u2019s the size of all of the pixels in the frame. For best results, your schema will not include any extraneous data; otherwise, your state space will be unnecessarily large and longer training times can result. When building our own simulator, it\u2019s best to consider two factors:\n\nOur action space represents all of the different actions that can be performed by the AI engine. As much as possible, these actions should also have a deterministic effect on the state. The union of the state space and the action space is called the state transition space. While this state transition space isn\u2019t inherently important for building sims, it can become very large and unwieldy for a human to reason about its contents so it\u2019s worthwhile to keep this in mind.\n\nIn an arcade-style sim, the action space generally relates to the joystick or button inputs that a human player would have available. When building your own simulator, try to make the each action have a predictable effect on state. In the event that this is not possible, it\u2019s best to restrict the variability to only one action, and to normalize the distribution of possible outcomes. An study of this difficulty is FrozenLake, which adds a high degree of variability to some actions chosen by the AI engine.\n\nReinforcement learning gets its name from the use of a carrot and stick mechanism to teach the right behaviors and policies to the AI engine. To do this, we provide a score to the engine after each iteration. Think of this as a way to score the correctness of the AI engine\u2019s result. This is calculated by the reward function. A minimal interpretation of this is a boolean function that returns 1 in the event of a correct outcome and 0 in the result of an incorrect outcome; a higher-resolution interpretation is a reward function that represents the difference between the decision of the AI engine and the desired outcome.\n\nThe key to understanding this core pillar of reinforcement learning is the understanding that the reward function is not the desired outcome for the action, but rather a signal that represents an appraisal of the actual outcome of the action when compared to the desired outcome. It\u2019s also important to remember that you can use a different reward function with the same sim to train different AI engines, which provides reusability to your finely-tuned simulator.\n\nA careful simulator author can provide the AI engine with an advantage by clearly defining the simulator environment and reward function. By using the same simulator with multiple rewards, multiple concepts can be trained, resulting in a more robust system. At the same time, it\u2019s important to consider the schema, and how complicated the resulting action space and state transition space are.\n\nThere are some great options open source solutions to get started with simulator design. The SimPy package offers a really straightforward way to build your own. Take a look at the classic control environments in OpenAI Gym for other examples, or Gazebo for a more complex environment.\n\nWe\u2019re going to write a simple simulator to implement some of the concepts I\u2019ve discussed in the past few weeks! Follow me on Twitter at @bitbucketeer and Bonsai at @BonsaiAI on Twitter for more updates, or come visit our forums to join the community."
    },
    {
        "url": "https://medium.com/@BonsaiAI/enabling-the-next-economy-6665e03012fd?source=user_profile---------55----------------",
        "title": "Enabling the Next Economy \u2013 Bonsai \u2013",
        "text": "Last week, I had the opportunity to speak at the O\u2019Reilly Next:Economy Summit in San Francisco. I was on a panel of startups working to empower and augment the human workforce alongside the new technologies that will define our future.\n\n \n\n One of those new technologies, almost certainly the most important, is artificial intelligence. With the continued march of AI, it has become apparent that intelligence is going to become a core part of every software and hardware application. In practice, this means it is now viable to automate non-routine work that has previously resisted automation, enabling us to scale our expertise.\n\n \n\n I spoke about the disconnect between those who build teachable systems and those who have something to teach. On the one hand, we have data science and machine learning experts who excel at making sense of vast troves of data and uncovering the intelligence contained therein. On the other hand, we have subject matter and domain experts who already have intelligence we want to bring to bear. In-between, we have developers and engineers who codify and build the systems that power our businesses. \n\n \n\n The key for the next economy is to unlock AI for our developers and engineers. As it stands today, there are more than 21 million developers in the world but only 19,000 data science experts capable of building AI at the lowest level- that\u2019s three orders of magnitude more developers than data scientists worldwide. We must empower the developers that are already in our organizations to scale our expertise and automate our work.\n\n \n\n So how do we do that? By recognizing a simple fact \u2014 today\u2019s machine learning technologies are all about learning, which is a fancy way of saying they\u2019re about making better students. What we need instead is to look at the other side of that coin \u2014 to look at teaching and crafting the technologies and tools that allow us to codify how to teach learning systems the intelligence we actually want to apply. At Bonsai, we\u2019ve built a platform that enables exactly this. We shift the level of abstraction up so your teams can focus on building, teaching, and using intelligence models without getting mired in the low-level mechanics of machine learning.\n\n \n\n Using Bonsai, developers focus on the concepts they want to teach the AI model and how to teach them. The low level details are left to the platform, similar to how databases let us focus on using our data for the business problem we want to solve instead of managing the database itself. By working at a higher level, a problem that formerly required handwritten advanced deep learning network topologies can now be solved with just a couple dozen lines of code. \n\n \n\n Ultimately this gives you a host of benefits: increase the scope of what you were doing and achieve it in less time; understand what was going on so that you can debug and iterate more effectively; reuse and share work more effectively; take advantage of improvements in the levels below without having to rebuild all of our work. This enables us to harness the power of AI in our businesses, bringing our unique and collective intelligence to bear as we build the next economy.\n\n \n\n I\u2019ve posted slides from my talk below. You can also learn more about Bonsai and apply for the private beta at bons.ai!"
    },
    {
        "url": "https://medium.com/@BonsaiAI/hyperparameters-6a9fe7e2311a?source=user_profile---------56----------------",
        "title": "Hyperparameters \u2013 Bonsai \u2013",
        "text": "One of the most important but least approachable facets of the study of artificial intelligence is the notion of hyperparameters, the parameters used to train specific algorithms. These crucial aspects of system setup govern the training speed and accuracy of your network, so getting them right is critical to finding best results. Traditionally, a machine learning expert would be required to work out several sophisticated equations to determine the best parameters around the training model; with some models, there can be a dozen or more hyperparameters that must be computed or discovered through repeated experiments. Experts with years of experience can sometimes guess at the values before starting the learning process. As an example, for DQN this can include exploration decay, learning rate, and gamma.\n\n \n\n At Bonsai, we\u2019re abstracting this process by building a hyper-learner to identify and detect the optimum configuration to attack the given task. I sat with Ruofan Kong to get some of the details about how this is done.\n\nThe first hyperparameters to select are the correct learning algorithm and configuration of the neural network to apply to the task. The component responsible for this is the Architect, which will examine your compiled Inkling code to infer the correct number of input and output neurons, and design the rest of the layers accordingly. We\u2019re continually implementing more algorithms that the Architect can employ on new problems. Today\u2019s most popular learning models are Stochastic Gradient Descent and Adam, but there\u2019s constant research pushing forward the state of the art.\n\nEach optimizer has hyperparameters of their own. The Instructor sets the parameters around the learning optimization scheme, and like the Architect, it will be collecting new information every time it makes a decision. This keeps the process abstracted away, so you can concentrate on more interesting things.\n\nJust in case you did want to know what\u2019s behind the curtain\u2026\n\nTo abstract this, our hyper-learner studies the problem before assigning hyperparameters by taking a fingerprint of a sample of the data available, using random predictions. During this time, we collect statistics about the different states that are reported, as well as our results based on the reward function. Based on these specifics, we can get a pretty good guess at the type of learning parameters that will give the best results. We do this by keeping a tally of the problems we\u2019ve solved, and how those were best resolved. Naturally, the AI engine will have the hive mind to support it, which is the database of all of the solution statistics that have passed through the public API. Using this platform, we can democratize machine learning and artificial intelligence for developers around the world.\n\nWe\u2019ll talk to the AI team about training times, and why they\u2019re so hard to predict, as well as what our research is finding in this area."
    },
    {
        "url": "https://medium.com/@BonsaiAI/the-root-of-bonsai-b624a4ceec?source=user_profile---------57----------------",
        "title": "The root of Bonsai \u2013 Bonsai \u2013",
        "text": "In the early days of forming the company, our founders Mark and Keen had a unified vision: make the implementation of artificial intelligence accessible to every developer. Current state of the art tools for machine learning and artificial intelligence are extremely complicated and difficult to understand. Eventually, they identified the core question: \u201cWhat exactly is it that developers want to do?\u201d The answer was that they wanted to teach a computer, and the only way to do that is to create tools for teaching a computer. The first thing they would need a high-level programming language to express the core concepts of teaching, an academic discipline known as pedagogy.\n\nI interviewed our language specification and compiler expert, Megan Adams, and got an in depth view of the process of creating a new language to harness the power of AI. With two decades of experience in language and compiler design at HP Labs, Amaret, and others, she\u2019s an unequivocal expert on the subject.\n\nWe\u2019ll dive into the BRAIN and how it tunes hyperparameters with our Control Systems expert Ruofan Kong! Read more about template metaprogramming at the Gentle Introduction to TMP, or learn more about Boost.Spirit at Dr. Dobb\u2019s."
    },
    {
        "url": "https://medium.com/@BonsaiAI/welcome-to-bonsai-f57119b0df91?source=user_profile---------58----------------",
        "title": "Welcome to Bonsai \u2013 Bonsai \u2013",
        "text": "As the newest member of Bonsai\u2019s Berkeley staff, I\u2019ve entered into this new and uncharted territory of developer tooling for artificial intelligence, and I\u2019m absolutely fascinated with what I (and the computers!) could learn. Coming to this from a developer tools background, I\u2019m eager to use the Bonsai platform to craft my own artificial intelligence models (we call them BRAINs, short for Basic Recurrent Artificially Intelligent Network) and add the wonder of AI to my own projects. Come along and we\u2019ll explore this brave new world of notional training using concepts, lessons, and curricula to break down the barriers to entry into machine learning! But first, Python. As a scientific and mathematical modeling language, we looked at Python as a natural choice for the first implementation of our tooling. The initial implementation of our simulator integration library is built with it (more languages coming soon), as well as our CLI and tools. The popularity of Python provides an easily comprehensible starting point and ensures there will be ample resources to draw upon in the greater community of developers. Fun fact: the entire Bons.ai service stack, both front and back end, are built on Python.\n\nBefore I got started with Inkling and the Bonsai CLI, I had to get my Python, pip, and virtualenv into shape. The general idea is that virtualenv allows me to isolate a specific Python environment (in our case the Python that I use with Bonsai) from the Python I use for everything else. To do this, it will be represented by a group of files that are created in the context it\u2019s called from containing only the packages I\u2019ve called for this virtual environment. Pip, in turn, will obtain and maintain your packages in this virtual environment. Full documentation can be found at the PyPA website, but here\u2019s some pro tips to make sure your virtual environment stays in good condition:\n\nArtificial intelligence and machine learning are complex and difficult to get started with, even for seasoned developers. The only way we\u2019ll realize our vision of AI for Everyone will be to break down these barriers to entry that prevent the world\u2019s developers from using and deploying modern artificially intelligent systems. We\u2019ve already seen this approach earlier in the history of computer science with the development of compiled and interpreted languages. To see how Bonsai leveraged the DQN algorithm against the Breakout Simulator problem published by University of Toronto in just a few dozen lines of code, check out our three-part blog post on the topic: Concepts and Schemas,Curricula and Lessons, and The BRAIN Server. The current state of AI and ML is similar to the earliest days of computing, when the only method of representing logic to a computer was through the use of assembly code or machine language. Over time, some enterprising developers wrote a compiled language to express this complexity in a (somewhat) human-readable fashion. While learning this new \u201cC\u201d language was a large commitment, it took the world by storm because it abstracted the details into a modular, interchangeable system. By now, C is one of the most widely used languages in the world, with assembly code relegated to #8. When taken together with its descendants C++ and C#, the C family is in the #1 spot. We can catalyze the same transformation in the AI space, and make AI approachable to many more developers, by creating the tooling and paradigms that will unlock the power of AI for everyone.\n\nIn the upcoming weeks, I\u2019ll be reporting on the people and ideas that drive our design, implementation, and architecture as we bring artificial intelligence and machine learning to the masses with Inkling as our language and compiler, trained BRAIN models, and approachable concepts using a modular approach. Next week, I\u2019ll chat with Megan Adams, our Senior Engineer writing the Inkling language specification and compiler, to get more details. She\u2019ll give us an insider\u2019s view of the challenges and motivations around building a special purpose language for AI."
    }
]