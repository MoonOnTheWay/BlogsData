[
    {
        "url": "https://towardsdatascience.com/why-we-need-a-better-learning-algorithm-than-backpropagation-in-deep-learning-2faa0e81f6b?source=user_profile---------1----------------",
        "title": "Why we need a better learning algorithm than Backpropagation in Deep Learning",
        "text": "We all agree on one thing that Back propagation is a revolutionary learning algorithm. For sure, it has helped us in the training of almost all neural network architectures. With the help of GPUs, backpropagation has reduced months of training time to hours/days of training time. It has allowed an efficient training of neural networks.\n\nI think of two reasons because of which it has gotten this widespread adoption, (1) we didn\u2019t have anything better than backpropagation, & (2) it worked. Backpropagation is based on the chain rule of differentiation.\n\nProblem lies in the implementation of the Backpropagation algorithm itself. To calculate gradients of the current layer we need gradients of the next layer, so current layer is locked and we can\u2019t calculate gradients until and unless we have gradients for the next layer. If we have 1000s of layers in our network, our 1st layer has to wait till eternity to get it\u2019s weights updated. First few layers in the neural networks are miserable ones and don\u2019t get updated properly. Sometimes, in case of the Sigmoid activation function, when we propagate back, gradient vanishes or explodes.\n\nWhen we take decisions, we take decisions based on our current observation and our previous learning. Current neural networks or deep learning algorithms are not designed the way we take decisions. Our experience defines our decisions. For example, when we walk we use vision, audio and sensory inputs to take decisions. We use learning from one task to learn other tasks.\n\nDeepMind\u2019s synthetic gradients shows a workaround, but it is not a solution. In my opinion, we have to think from scratch and design a new learning algorithm which can learn efficiently and can help our network learn in real time.\n\nDisclaimer: This is my personal opinion and it is solely based on my studies and research. I invite you all to share your thoughts on this.\n\nI am a Co-Founder of MateLabs, where we have built Mateverse, a ML Platform which enables everyone to easily build and train Machine Learning Models, without writing a single line of code."
    },
    {
        "url": "https://codeburst.io/what-is-regularization-in-machine-learning-aed5a1c36590?source=user_profile---------2----------------",
        "title": "What is Regularization in Machine Learning? \u2013",
        "text": "Regularization in Machine Learning is an important concept and it solves the overfitting problem. It is very important to understand regularization to train a good model. Sometimes one resource is not enough to get you a good understanding of a concept. I have learnt regularization from different sources and I feel learning from different sources is very important. An easy and simple explanation is what everyone needs. I am listing 2 Quora answers and 5 articles, I hope, these will help.\n\nI am a Co-Founder of MateLabs, where we have built Mateverse, a ML Platform which enables everyone to easily build and train Machine Learning Models, without writing a single line of code."
    },
    {
        "url": "https://towardsdatascience.com/important-resources-if-you-are-working-with-neural-style-transfer-or-deep-photo-style-transfer-719593b3dbf1?source=user_profile---------3----------------",
        "title": "Important resources if you are working with Neural Style Transfer or Deep Photo Style Transfer",
        "text": "Important resources if you are working with Neural Style Transfer or Deep Photo Style Transfer\n\nNeural style transfer and deep photo style transfer are interesting fields of deep learning. Their popularity has grown to an another level. Apps like Prisma and Deepart.io accelerated the popularity. If you are working with neural style transfer or deep photo style transfer these are some very important resources(papers, implementations and tutorials) to help you out.\n\nI am a Co-Founder of MateLabs, where we have built Mateverse, a ML Platform which enables everyone to easily build and train Machine Learning Models, without writing a single line of code."
    },
    {
        "url": "https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5?source=user_profile---------4----------------",
        "title": "Essential Cheat Sheets for Machine Learning and Deep Learning Engineers",
        "text": "Learning machine learning and deep learning is difficult for newbies. As well as deep learning libraries are difficult to understand. I am creating a repository on Github(cheatsheets-ai) with cheat sheets which I collected from different sources. Do visit it and contribute cheat sheets if you have any. Thanks."
    }
]