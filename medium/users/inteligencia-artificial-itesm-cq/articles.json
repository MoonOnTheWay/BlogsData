[
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/academic-coffee-deep-q-learning-cca10d0ebdc?source=---------0",
        "title": "AcademIc Coffee: Deep Q-Learning \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "Reinforcement learning is an area in machine learning which is focused mainly on training an agent in a given environment in order to get the maximum reward based on the action it can take at the moment.\n\nQ-Learning refers to a technique for reinforcement learning in which we hypothesize a function for an agent which knows nothing about the environment except for the current state and possible actions it can take. This function is called the Q function which is a reference for the \u2018Quality\u2019 of the decision made, the traditional Q-function value can be obtained with help of the bellman equation and its explained more in depth in the post in the link below.\n\nThis function helps out agent to make the decision which maximizes our reward on the long term, since we take into consideration the future decisions made.\n\nIn Deep Q-Learning we make all these assumptions, except that we train a model in order to predict for the value of the Q-function which helps us make the best decision.\n\nThis technique has been used to maximize rewards in different environments such as basic games or stock market simulations.\n\nMore details can be found in the following post:"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/deep-learing-to-teach-and-aihow-to-play-videogames-c76f234f5acd?source=---------1",
        "title": "Deep Learing to \u201cteach\u201d and AIhow to play videogames",
        "text": "One team of the University of Oxford to create a better performance of a AI in Atari videogames. They have inspired with the demostration of combine Q-learning with deep learning to play Atari games maked in the work of Mnih et al (2013).\n\nThey approach instead of making a better score to train the AI, they choose to \u201cteach\u201d the AI to imitate an expert gamer using Convolution layers in its architecture using the framework Theano. Because the trainng never use the score as an optimizing metrica and the AI is imitating a gamer, they named the method as Deep Apprenticeship Learning.\n\nIn order to process the data, this team preprocessed the frames to go from 128 color images to grayscale, resized the frames from 210 x 160 to 83 x 83, removing the background and finally normalizing it.\n\nThe results of the experiments are measured with the scores and, even the AI of D.A.L. method never knows its score, it performs better that Sarsa, the other AI."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/detection-emotions-in-text-2f165fa285d7?source=---------2",
        "title": "Detection emotions in text \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "It\u2019s common to hear about detection of emotions in pictures of people faces, but other area that can be usefull to now the emotions of people with only analysing what they write in places like comments in Facebook or Twiter. This open a new possibility to automatize the analisys of the emotions and impact of the users about a product, a service or even the opinion of the goverment.\n\nUnderstanding the user is so important to many sectors, even in economics it can be a main factor to predict the success in the market or the risk that a company could face in a future.\n\nIn this case, using the method of the Mechanical Turk for its low cost and scalability, it tries to classify short informal english messages in fice classes: happy, angry, sad, excited and fear.\n\nThe plan is to identify \u201chow much\u201d of a emotion that messages could be interpreted. They use a private dataset of more than 780,000 messages that 60% used in trainig, 20% in validation and 20% for testing; in a experiment of a three layer ANN with 125, 25, 5 nodes.\n\nThe funny part of the results, its to see that the more accurated predictions are in negative emotions, except in fear that is the worst one."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/deep-photo-style-transfer-e63e0551db80?source=---------3",
        "title": "Deep Photo Style Transfer \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "In 2016 researchers published the paper Image Style Transfer Using Convolutional Neural Networks in which they presented a technique that enables a Neural Network to transfer a style from an artwork onto a photograph. This technique became popular and it is now available in apps like Prisma or Facebook filters.\n\nIn 2017 researchers from Adobe and Cornell University published a new paper called Deep Photo Style Transfer in which they take the methods from the original style transfer paper and improve it in order to achieve photo realistic style transfer."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/big-data-in-medicine-c5f5f79284b4?source=---------4",
        "title": "Big Data in Medicine \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "Big data has been the new tendency in many areas of study, including medicine. The three major steps of actually using all of the data provided by patients are:\n\nAn example of data interpretation is Google\u2019s \u201cflu trends\u201d which can track a flue epidemic with real time data. A few years back it was not possible to track epidemics since the information was not provided continuously and by the time it could be interpreted it was over.\n\nAs we can see in the image below big data and all of its components are increasing significantly in order for big data to be relevant. 3 of the main aspects of big data, which can be seen in the image below, are:"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/academic-coffee-using-ai-to-find-the-graves-of-mexicos-missing-people-46a0063e01d?source=---------5",
        "title": "Academic coffee: Using AI to find the graves of Mexico\u2019s missing people",
        "text": "This is based on Quartz\u2019s article \u201cMachine learning is being used to uncover the mass graves of Mexico\u2019s missing\u201d. If you want to know more click on the link.\n\nMexico is a country were at least 30,000 people have disappeared since 2006. Sadly the search for most of these missing persons often has to start underground.\n\nUntil recently the large size of Mexico\u2019s territory made it really hard to think where to start looking for someone. A team of multi-country researchers, data scientists, and statisticians is using machine learning to predict which counties in Mexico are most likely to have hidden graves. A team which is composed of three groups: the Programa de Derechos Humanos at the Ibero-American University, Data C\u00edvica and the Human Rights Data Analysis Group (HRDAG).\n\nEach one helps with some specific piece of analysis and together help to form the bigger picture. They have created a database with details of every report of graves found. They have been able to create a profile of sociodemographic data for every one of the 2547 counties in Mexico.\n\n\u201cPatrick Ball, HRDAG\u2019s Director of Research and the statistician behind the code, explained that the Random Forest classifier was able to predict with 100% accuracy which counties that would go on to have mass graves found in them in 2014 by using the model against data from 2013.\u201d It could also predict which counties did not have a hidden graves on them!\n\nCounties with hidden graves are likely to have a lower average income than other counties, be more rural than urban, have higher numbers of indigenous residents. Also, many of the counties have been found to have strong connections to drugs and high homicide rates. The counties with found graves tend to have highways and they also evidence a pattern of being close to borders. The team at Data C\u00edvica reports that three out of every ten disappearances happen in the states of Tamaulipas or Guerrero.\n\n\u201cThough the team has been able to use data from 2013 to predict accurate results for 2014, they haven\u2019t yet been able to do the same for 2017. Before this can be done, N\u00fa\u00f1ez\u2019s team has to update their database with media mentions from 2016, a task that is forthcoming and time-consuming.\u201d"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/atari-playing-ai-cde6752de412?source=---------6",
        "title": "Atari Playing AI \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "Using Reinforcement Learning (Learning to take better actions in order to have a cumulative reward), scientifics of DeepMind Technologies developed a deep learning model for learning control policies directly from high-dimensional sensory input applied to learning and playing different gamees form the Atari 2600. The model uses a convolutional neural network, trained with a variant of Q-learning (It works by learning an action-value function that ultimately gives the expected utility of taking a given action in a given state and following the optimal policy thereafter https://en.wikipedia.org/wiki/Q-learning), whose input is raw pixels and the output is a value function estimating future rewards.\n\nA convolutional network was used as the inputs are the frames of the Atari 2600 (210x160 RGB at 60Hz). The problem with this is that it is a lot of data and it is hard to process it a real time, the solution was to preprocess it by converting it to gray-scale and down-sampling it to a 110x84 image. Then, the picture was cut to a 84x84 area which contains the playing area.\n\nThe first hidden layer convolves 16 8x8 filters with stride 4 and applies a rectifier nonlinearity. The second hidden layer convolves 32 4x4 filters with stride 2 with another rectifier. The final hidden layer is fully-connected and consists of 256 rectifier units. The output layer is a fully-connected linear layer with a single output for each valid action (between 4 and 18). This network is referred as a Deep Q-Network (DQN).\n\nThere is one special characteristic about the learning process of this architecture, there is a technique known as experience replay which stores the agent\u2019s experiences at each time-step pooled over many episodes into a replay memory. This allows the AI to distinguish some actions that worked in the past and in which conditions, and to update the weights. Also, as a matter of fact, learning directly from consecutive samples is inefficient due to the strong correlations between samples, randomizing them break these correlations and reduces the variance of the updates.\n\nThis was tested with 7 different games: Beam Rider, Breakout, Enduro, Pong, Q*bert, Sequest, and Space Invaders. The AI outperformed all previous approaches on six of the games, and surpassed a human expert on three of them."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/bird-sounds-classification-and-visualization-95a9585431a?source=---------7",
        "title": "Bird Sounds: Classification and Visualization \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "As a part of the Google\u2019s \u201cA.I. Experiments\u201d (https://aiexperiments.withgoogle.com/) this project was developed in conjuction with the Cornell Lab of Ornithology. The main purpose of this was to create an AI for classifying and visualizating the sounds made by different species of birds and group them by similarities.\n\nFor doing this, Deep Learning techniques were used, but, first the sounds needed to be fragmented into \u201celemental\u201d divisions, such as when analyzing voice. Then, it was needed to create fingertips from this \u201celemental\u201d bird sound/particle for classifying new sounds and grouped them by similarities. For this last part, a machine learning technique known as t-distributed stochastic neighbor embedding, or t-SNE (https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), this models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points, this is particularly useful comparing the different elemental footprints that can create different bird sounds.\n\nAfter this, the AI now can identify the variations in these sounds and to determine if it is another kind of bird or the same, also it can name the bird by only hearing the sound it emits.\n\nThe ultimate goal of the project is to introduce microphones in forests and jungles in order to get more information, classify the noises automatically and to monitor the different species."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/do-you-know-about-sscait-4d8259a9dbf3?source=---------8",
        "title": "Do you know about SSCAIT? \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "When someone mentions StarCraft, its almost granted that 90% of the people hearing imagines a korean guy that has played for 47 hours nonstop, no sleep, no food, and most likely no bathroom. I will not deny that koreans are the epitome of StarCraft players, but ever since 2011, there are other contenders to pick the top seat at StarCraft competitive play.\n\nStudent StarCraft AI Tournament is a yearly event that allows artificial intelligence savvies to show of their skills. In this competition, each participant can upload an AI capable of playing StarCraft autonomously. Note that the participants must be students. For 6 years, AI have brutally slaughtered each other, seeking for the title of ultimate champion.\n\nThere is little information about the first tournament back in 2011. All we know is that Roman Danielis, from the Comenius University, Bratislava, took the scepter for one long year. However, the success of the event allowed a second edition in 2012. In that year, Matej Istenik, University of Zilina, Slovakia ruled them all.\n\n2012 was also the first year where non-students were allowed to participante, where Wang Zhe et al. from Japan, won. From there, one edition has been celebrated annually, with winners from east Europe and Asia dominating.\n\nNow, you may be wondering, how this guys do it? The answer is quite simple (or not). The official portal of the SSCAIT has complete documentation on how to use the necessary APIs and libraries to program your own StarCraft Bot. Technically speaking, bots are programmed using BWMirror.\n\nBWMirror API is a Java wrapper for C++ BWAPI. It wraps all the classes, constants and enums inside Java objects, while providing the exact same interface as the original C++ BWAPI. This is achieved by heavily utilizing JNI.\n\nOne of the winners of the 2014 edition, Martin Rooijackers, has shared with the world via Rock, Paper, Shotgun how his bot, LetaBot, works. Detailing the entire functionality of LetaBot would be insane; the important thing is that this bots use most of the machine learning and AI techniques as a whole to cover up different problems. Robot vision is used to process the known map information, behavior trees are used to generate a hierarchy of decision making, and machine learning can be used to fine-tune the behaviors.\n\nIts remarkably what this students can do. Videogames are complex, stochastic, continuous AI problems that require every single piece of knowledge to work. Would you prove yourself participating?"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/ri-xian-explores-the-use-of-dbn-for-image-reconstruction-and-defect-detection-47dcb1676567?source=---------9",
        "title": "Deep Belief Neworks for Defect Detection \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "This post explores the use of DBN for image reconstruction and defect detection.\n\nRBM is based on Boltzmann machine. BM is powerful on unsupervised learning, but slow training and impossible to calculate the distribution accurately, and it\u2019s hard to get samples that follow the distribution required by BM. RBM is used to solve those problems.\n\nIn RBM, neurons are random, which only have active and inactive states, like BM, RBM also have hidden layers and visible layers. The difference is RBM has no connections inside the layers.\n\nDBN is constructed by multiple layer RBM, every low level RBM output as the input of higher level RBM. Comparing with traditional BP, DBN can get suitable initial weight of nets by pre-training, which can conquer the localized optimization problem of BP caused by initialization.\n\nThis complete training is achieved in two steps:\n\n* Unsupervised training on each RBM layer, making sure as many as possible features are preserved from lower to higher layers. \n\n* Fine adjust the DBN weight by BP, after getting forward and backward weights.\n\nDBN defects detection analysis:\n\n* Solar cell surface have simple pattern, the defect-free area have uniform pattern as same background and detection location, while the defected image only have difference on grey scale. \n\n* DBN can combine processing image and extracting features, which is fast for production lines.\n\n* DBN can be combined with traditional detection nets\n\nImages are normalized to 64 x 64 and 100 images are used for training while 20 for testing. The defects present include: fractures, scratches, missing corners.\n\nThe network is then trained with the previously explained process yielding a total training time of 2597s. After training image reconstruction can be done using the 20 images. The test set takes 3.01s, averaging 0.151s per frame. In practice, this method still has shortcomings such as, using high resolution images which directly impacts training time.\n\nIf you want to know more about DBN\u2019s check http://videolectures.net/mlss09uk_hinton_dbn/"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/emotional-ann-9fd0b3662d4b",
        "title": "EMotional ANN \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "Give emotions to a system like the artifitial neuron networks is one approach in ordder to create a better model of a biological brain. The emotions are a set of biological and biochemical reactions, the ones more associated to the emotions are the hormones. They can, in sort way, modulate the decisions of the neurons and other glandes and change the output. With this, a EMANN is a model that propouse is rethink the ANN in order to make it work with a new signal that can modulate the weights, the sumatory or the activation function of the neurons in order to improve the evolution of a network."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/myo-emg-big-data-66cf3a4eaf9c",
        "title": "MYO EMG big data \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "MYO is an armband that is used to detect electric pulses from your arm which can later be used to detect a certain movement. These electric pulses are detected by 8 different sensors in the armband which go around your arm. Before MYO only released a version of the armband which detected predefined movements but later released an SDK version which let coders be able to receive the raw data gathered from the electric pulses. One of the many difficulties is to program personalized movements with the electric pulses. The reason for this is that exactly the same movement can give extremely different data as seen in the image below:\n\nThis depends on muscle complexity, BMI, arm length, injuries, among other things. For this it necessary, in order to do machine learning, that a large data set is made with a variety of people in order for the machine learning algorithm to detect the exact movement of the user, or at least make a very good assumption of what it is. Big data algorithms are needed in order to have arm movement detection programs which can easily be used for anyone with a wide variety of characteristics. This becomes much more simple if the detection is being programmed for a person or a specific group of people since the training data wont be much different from the testing data."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/the-challenge-of-machine-learning-in-videogames-184b078194a6",
        "title": "The Challenge of Machine Learning in videogames \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "A thought that often crawls the mind of someone interested in videogame development is why the hell machine learning is not yet a standard in the godamn industry?\n\nArtificial inteligence is often critized when the enemy stands, slowly dying, while you machiavellously snipe him from a distance so long your crosshair doesn\u2019t even recognize him as an enemy. Most of the time, AI implementations of enemies are full of exploits that the player can take advantage of.\n\nIt may seem only natural that the solution to such problem is machine learning. Just imagine, after exploting the distance glitch described above on a few enemies, you attempt it once again without much though. Suddenly, you notice that the enemy acts differently. After trying it against a few other enemies, you can swear that enemies seem to have learnt how to hide from your cheese tactic. You find yourself even more surprised when one of them actually seems to be searching for you while hiding closer and closer.\n\nUnfortunately, things aren\u2019t that simple. There are several problems when trying to add learning into videogame AI. Kenneth O. Stanley, Bobby D. Bryant, and Risto Miikkulainen explain why in their article Evolving Neural Network Agents in the NERO Video Game.\n\nFirst, there is the problem that comes with stochastic behaviour. With machine lerning, the AI needs to experiment sometimes new actions it can take to discover if what it normally does is, in fact, the best action it can make. The problem here: the AI actually needs to try new actions. This means that the AI could try to do some movements so random at random times that it may seem even more retard than a normal exploitable AI. Just picture the enemy AI stunt you with a flash granade, but instead of shooting you dead, he just decides to make a 360\u00b0 turn and throw a granade to where his fellows are taking cover.\n\nA solution to the stochastic behaviour is to train the AI before the actual release of the game. The problem with this solution is that the AI will not learn anything new at release and any new exploit found will remain there forever. Pre-training nullifies flexibility.\n\nReal Time learning comes as a the most viable solution. The computer learning as the player plays would effectively solve any given exploit eventually. There are two problems here, however. First, machine learning is very expensive and Real Time Learning could have serious impact on the performance of the game, and nobody wants to play a slideshow of a game. Second, common machine learning techniques as back-propagation in Neural Networks learn really slow, for the entirety of the player\u2019s playtime with a game, the AI could never show any type of learning.\n\nThis problems take us to the two crucial elements of machine learning in videogames: it must not impact performance, and it should learn really fast.\n\nTechniques to achieve this milestones are still very experimental, and are not yet fully usable in mainstream game genres. However, the discoveries made so far are encouraging. Refering back to Stanley, Bryant and Miikkulainen\u2019s work, we can learn about how they used NeuroEvolution of Augmenting topologies (NEAT) to create a game where you must train some robots for military tactics.\n\nNEAT is a strategy to create Networks that can mutate. They start as simple neural networks (with no hidden layers) and mutate (adding new perceptrons for new potential features). If such a mutation proves no relevance the added neurone is deleted, if not, it can keep evolving. The learning can occur inbetween epochs (read play sessions) which minimizes the impact on performance. This solution also works fast because of the mutability (adding a whole new feature can impact far more than plain weight adjustment).\n\nAgain, NEAT is not perfect and cannot be applied to mainstream action first person shooters, but the ideas behind it encourage us to believe that one day we will see that utopic AI enemy overpowering us.\n\nFor more information about NEAT and it\u2019s application, follow the next link: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.728.5120&rep=rep1&type=pdf#page=182"
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/academic-coffee-netflixs-new-ai-173c832d2209",
        "title": "Academic coffee: Netflix\u2019s new AI \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "This is based on Quartz\u2019s article \u201cNetflix\u2019s new AI tweaks each scene individually to make video look good even on slow internet\u201d. If you want to know more click on the link.\n\nNetflix has been working on a new AI to prevent tedious pauses while watching a movie or serie. This AI, analyzes each one of the shots in order to compress it without affecting the quality of the video. Meaning that it reduces the amount of data requires to load the shot.\n\nThis new AI is focused mostly to users living in countries with emerging economies which watch content in their mobile devices.\n\nThis new technology is called Dynamic Optimizer and it is the result from the collaboration of Netflix with the University of Southern California and the University of Nantes. Hundreds of thousands of shots and hundreds of viewers were used to train the algorithm to detect the quality of an image.\n\nThis allows for a better compression of a video. Normally they are uniformly compressed, but this algorithm would be able to detect which shots can be compressed while keeping a really similar quality."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/academic-coffe-redes-neuronales-artisticas-d09f621c9714",
        "title": "AcademIc Coffe: Redes Neuronales Artisticas \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/google-detectando-im%C3%A1genes-en-videos-16597df87d78",
        "title": "Google: Detectando im\u00e1genes en videos \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/deepdriving-creando-al-carro-aut%C3%B3nomo-823de762a4c8",
        "title": "DeepDriving: Creando al carro aut\u00f3nomo \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/generaci%C3%B3n-de-dataset-para-problema-de-visi%C3%B3n-computarizada-a90c77a0dc9a",
        "title": "Generaci\u00f3n de dataset para problema de visi\u00f3n computarizada",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/reconocedor-de-letras-de-la-lengua-de-senas-mexicana-f97899d612fd",
        "title": "Reconocedor de Letras de la Lengua de Senas Mexicana",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/procesamiento-de-imagenes-95c7e5637403",
        "title": "Procesamiento de Imagenes \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/m%C3%A9todo-de-montecarlo-d11b0ff7af33",
        "title": "M\u00e9todo de Montecarlo \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/inteligencia-artificial-itesm-cq/vision-artificial-2a3ff155fb7f",
        "title": "Vision Artificial \u2013 Inteligencia Artificial ITESM CQ \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    }
]