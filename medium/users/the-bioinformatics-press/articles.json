[
    {
        "url": "https://medium.com/the-bioinformatics-press/virtual-reality-and-healthcare-6787d2eadb9f?source=---------0",
        "title": "Virtual Reality and Healthcare \u2013 The Bioinformatics Press \u2013",
        "text": "So \u2014 I started working with a startup near my university, and I am pretty excited. Serendipitously, I uploaded my resume on a website and got a response from them pretty quick. No need for the those career fairs!\n\nThings are in full-swing, and it feels good to be working with a company on a real project that should have some fruitful outcomes. Though I\u2019m part time, I definitely feel apart of their team.\n\nThat said, I am taking a deep-dive into another field that I have no idea about. Virtual reality, and putting cognitive data science and machine learning in the mix.\n\nThese two field are burgeoning individually, and when you think of the implications of both combined \u2014 the possibilities, yet again, seem limitless. That\u2019s the beauty of technology, that with each new tool that emerges, there are that many more combinations (or permutations? or both?) that can allow for interesting methods for solving problems.\n\nI want to highlight some early learnings as I research more of these areas\n\nBefore this gig, I didn\u2019t read much about virtual and augmented reality. I found the idea scary. I mean, we humans don\u2019t even really know how to live our lives in the real-world, why should we go to an artificial one? It seemed like running away.\n\nThere is more to it than that, and I realized that I was very biased. There is a growing amount of research in the healthcare field that activities within augmented or virtual worlds can improve therapy outcomes when compared to traditional methods.\n\nIt\u2019s all about improving the human condition, and making sure that the patients do not feel as if they are sickly and have to wait in a dreary hospital to get better. There are methods to move beyond the physical setting and environment. The virtual world allows for researchers and physicians to put their patients in a controlled environment to monitor activity and progress.\n\nDon\u2019t get me wrong. There are definitely downsides to the technology. One of which is motion sickness \u2014 something I attest to after a 10 second roller-coaster ride in a virtual world. Jokes aside, it is imperative to make technology that improves and does not hinder. This is one of the many kinks that need to be worked out.\n\nAs stated before, more control is given to the creators of this virtual world. More control through sensors. And sensors mean data. Lots and lots of it.\n\nThere are so many sensors that can be added on top of the body. Motion, speech, pressure, temperature \u2014 whatever you want to be measured can probably measured with a good degree of accuracy.\n\nNow on top of this, you can add the interaction details from the virtual environment. With all of this information, it can easily become cognitive overload for one person or team to process. However, with techniques from academia and some industry leaders, there are methods to dissect truly clear pieces of information from all of these signals.\n\nUsing accelerometer data, you could figure out the heartbeat of a patient. Using gyroscope data, you could figure out respiration. With the EEG, you could attempt to figure out mood, stress levels, etc. This is just scratching the surface, but that\u2019s where our team is at today.\n\nThese data will feed into different algorithms and models to assess and predict future states of the patient."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/gpu-accelerated-sequence-matching-bb0c8b7fe6d1?source=---------1",
        "title": "GPU Accelerated Sequence Matching \u2013 The Bioinformatics Press \u2013",
        "text": "In this article I will be introducing you to the Needleman Wunsch algorithm and its implementation on a CUDA powered NVIDIA GPU.\n\nNeedleman Wunsch algorithm is used to match sequences in a pairwise manner. Also this algorithm is used as a subroutine in searching for a DNA sequence in a large database. This is a dynamic programming approach where a scoring scheme is used.\n\nAs you can see in the image match scores 1, mismatch scores -1 and a gap scores -1. Matches are equal nucleotides overlapping and mismatches are different nucleotides overlapping at the same position. Gap is introduced when one sequence skips a match of a mismatch state by just leaving a gap. The final motive of the dynamic programming approach is to obtain the alignment with the highest aggregate score. In this article I will assume that you know what is dynamic programming and how to execute a CUDA code. You can refer to this article if you need to know more.\n\nMoving either Right or Down will introduce a Gap. Moving diagonally will either create a Match (If the row and column has same letter) or a Mismatch. Therefore, the score of a particular cell is the sum of the parent cell\u2019s score and the score of the movement (Match, Mismatch or Gap).\n\nAs you can see, first row and first column becomes inevitable Gaps. Therefore, the score keeps decrementing by one. For clarity of the dynamic step consider the bottom right corner cell. The maximum possible value for that cell is 0, obtained by traversing diagonally. This type of dynamic programming calculations can be GPU optimized by running calculations concurrently for rightward diagonals as depicted in the image below.\n\nIn this case, we can calculate cells with same number concurrently. Altogether, we just have to run the algorithms X+Y times where X and Y are the lengths of the two sequences. This can be further improved by tiling the matrix and computing with shared memory. Let\u2019s keep that for future. If this was to be done in normal manner we would need X * Y number of calculations. For a sequences of length 1000bp its a gain of nearly 500 times. Lets see the CUDA code for this computation. Before that a small not on backtracking.\n\nWe must build the alignment by backtracking parents of each cell. There could be several parents as well. Having parents for each of the cell will drastically reduce the performance of the calculation and reduce performance gain of CUDA computation. Therefore what I have done is simply traversed from the bottom right corner to initial cell. For this a simple Depth First Search (DFS) can be done with path replication. This allows building the complete set of paths. To make it easy for you I have included all the support headers I have implemented and complete code. The complete repository with few other algorithms can be found in this link, i hope you won\u2019t mind giving me a star ;-) link."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/healthcare-workflows-8fe21c7c4dde?source=---------2",
        "title": "Healthcare Workflows \u2013 The Bioinformatics Press \u2013",
        "text": "The art of bundling services is one of those business models that companies have been using for a while now. Every time you sign up for one of the major service providers, they always have something else they want to tack on to the list.\n\nJust moved in and got some internet? Check out the great deals on phone services! TV services! We will do your laundry too!\n\nIt is one of those marketing techniques to squeeze just a littttle more money out of the consumer. Nowadays, the healthcare field is beginning to use this approach, but to make money in a different way \u2014 by saving money through creating more efficient clinical workflows.\n\nIt\u2019s still bundling, but with a twist. The healthcare industry, as we know it, is one of those slow moving entities. Little changes can cause great waves. With the help of research, industry leaders, and consumer expectations, innovative ways to reduce the many frictions in healthcare, like bundling, will need to become a reality soon.\n\nA couple of studies below illustrate how time series and workflow analysis can improve the way healthcare works.\n\nThe more complex systems get, the easier the researcher can be overwhelmed by the sheer amount of layers upon layers of connections and behaviors that seem to exist. Carefully analyzing such systems can lead to large rewards.\n\nWorkflow analysis is one way to cut through all of the noise. There are several approaches to this type of problem: analyzing the players, the processes they take, and the effect of those processes. From all of this knowledge, one can start to develop a framework of what works, what doesn\u2019t, and to possibly run experiments confirmed what was witnessed.\n\nIn the clinical setting, the researches in this article took a data-driven approach to develop a model to learn potential healthcare bundles. Their model\u2019s output is visualized with this cool graphic below.\n\nThe researchers took an unsupervised approach to analyze over 16,000 patient diagnoses and the respective sequence of events that was taken for each patient (i.e. workflow patterns). From this, they developed 4 clusters which you can read more about in the article. After, they had healthcare professionals to validate these \u2018bundles\u2019 as plausible implementation strategies.\n\nThe only caveat is that these actual bundles were not deemed generalizable. In other words, this healthcare bundles may not work at a hospital near you. This area needs to be furthered studied. I find this approach an intriguing way to apply data science and learning algorithms to the health industry.\n\nFurther, if these hospitals and specialties are equipped with the best technology to eliminate the friction of poor communication and other inefficiencies, effective collaboration will surely emerge from the chaos.\n\nTime series studies are always interesting because they tell a story through time \u2014 how we typically think about life and events. The researchers from this article showed the impact of adding the electronic health record into the clinical workflow.\n\nJust to back up a bit \u2014 a healthy amount of research demonstrates that healthcare providers negatively see electronic records and health information technology implementations. These patterns are explained by a plethora of reasons: poor project management, lack of training, lack of expertise, no real return on investment, etc.\n\nThese are probably all valid, but sometimes the data is all that needs to be said. This study found that:\n\nYou can kind of visually see that from the graphic above. The line between the talking/rounding and patient activity is thicker, indicating more time is spent with the patient. Not a huge improvement, but there is significance to the change. Technology did make a positive impact \u2014 of course, met with some consequences (i.e. more time walking, using the computer, etc.)."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/only-numpy-understanding-back-propagation-for-max-pooling-layer-in-multi-layer-cnn-with-example-f7be891ee4b4?source=---------3",
        "title": "Only Numpy: Understanding Back Propagation for Max Pooling Layer in Multi Layer CNN with Example\u2026",
        "text": "Okay, so there is a lot going here, let me explain one by one.\n\nPurple Star \u2192 Convolution Operation with the Kernel Rotated by 180 degrees (Other words transposed), we need to do this for proper update of gradient.\n\nRed Box \u2192 Mathematical Form of finding the Coordinates of highest signal on L1 \n\nBlue Box \u2192 Matrix Form of actual Coordination of where the highest values were in variable L1. (This was the reason why I told you guys to please take note of the Blue Circled Numbers in the Forward Feed Process)\n\nHowever, one question arises, please look at the Orange star, how can we perform element wise multiplication between Matrix that have Dimension of (2*2) and (4*4)? I will answer that in a moment for now, lets take a look at the actual implementation of the code."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/pipeline-frameworks-for-genomic-data-af390b163ed?source=---------4",
        "title": "Pipeline Frameworks for Genomic Data \u2013 The Bioinformatics Press \u2013",
        "text": "Yesterday I was returning home from university via the expressway and the oil refinery at Sapugaskanda caught my eye. The refinery towers operate while sending huge flames into the sky with smoke. The sight of the oil refinery reminded me of pipelines which are used in many manufacturing and transportation industries to transform and transport materials which will provide outputs at the end. One common example is an oil pipeline which is used for long-distance transportation, while refining the oil within intermediate units to give various petroleum products.\n\nSimilarly, genomic data can be passed through special software pipelines to refine and analyze the data as required, while resulting in desired visualizations and interpretations.\n\nWith the advancement in sequencing technologies such as Next Generation Sequencing (NGS), huge amounts of genomic data are being generated at a fast rate. NGS techniques include steps such as sequence alignment and genomic annotation that consist of plethora of parameters and are compute-intensive. With the abundance of data and problems faced while carrying out genomic analyses, have led to the creation of several efficient tools for faster processing and analysis. Pipeline models is one such solution that scientists have used for various analyses. In this article, I will be introducing you to pipeline tools and how they have evolved over time to result in cloud-based pipeline frameworks at present, along with future trends.\n\nMultiple analyzing tools can be connected together to analyze genomic data in a step-wise manner. This is where pipelines come to work. Pipelines are created to process data in steps consisting of different tools where the output produced by one step is passed as input to the next step.\n\nPipelines are created using special code snippets known as pipeline scripts which consist of various instructions for processing and tracking information in all the steps. Scripts written in Unix shell or other scripting languages such as Perl and Python, can be seen in most of the basic forms of pipelines. These scripts can be customized according to the application and incorporate the desired analysis tools.\n\nAs the pipeline grow with more steps, managing these scripts becomes hard. Dependencies in various steps need to be met precisely and updating these dependencies manually can in erroneous outputs. Furthermore, if a pipeline fails in the middle of execution, it can be hard to resume from where it stopped. It can be inconvenient and error prone to run every step of the pipeline manually for numerous samples with multiple conditions in different projects.\n\nIn order to automate the process of creating and arranging scripts to form pipelines, pipeline frameworks were created. This reduced the burden upon scientists to manually setup pipelines and run them individually for different projects with terabytes of data. Pipeline frameworks introduced new features such as reproducible scripts, version controlling and reporting facilities.\n\nClass-based frameworks consist of existing code libraries which provide different functionality. These frameworks provide abstract classes to implement pipelines. Genome Analysis Toolkit is a class-based pipeline framework developed by BROAD Institute, USA.\n\nThese workbenches consist of tools in the form of preconfigured modules where scientists can arrange them to create pipelines and analyze data. Generally these framewokrs provide a graphical user interface with modules as drag-and-drop components. Some of the most popular server-base workbenches are Taverna and Galaxy.\n\nAdvancements in cloud computing have paved the way for attractive and scalable options for big data analytics. Various cloud-based platforms for pipeline management are available at present which utilizes the scalability of cloud computing to offer high performance, rapid pipeline generation, execution and an enhanced user experience. They also provide APIs to automate analysis of large batches of data without using a web interface to feed the data to the tool.\n\nSome of the commercial available cloud-based platform solutions include DNAnexus, Illumina\u2019s BaseSpace and SevenBridges.\n\nMany companies are working towards distributing popular gene data anaylyzing tools among different frameworks in order to standardize them. Furthermore, containerization of pipeline tools using software containerization platforms such as Docker, can enable pipeline frameworks to operate with various dependencies.\n\nFuture developements of pipeline frameworks can impact immensely upon analysis of genomic data, medicinal data and drug testing, while improving the quality of outputs. This can result in better human life and help heal the world."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/digital-healthcare-b866376235ce?source=---------5",
        "title": "Digital Healthcare \u2013 The Bioinformatics Press \u2013",
        "text": "For the next two years, I will be attending school in the Texas Medical Center (TMC). Driving through that area makes me feel the energy and vibrancy of healthcare innovation. Everywhere you look there are students, professors, doctors, and patients. In some form or fashion, these people are connected to the overall healthcare network at the TMC.\n\nIt is a hub of sorts, and in recent years, the TMC began to invest in the future of health through creating an accelerator. There were some startups from the last cohort that caught my attention. I\u2019ll brush over a couple of general themes that I am seeing when watching and reading about these companies.\n\nHealthcare is one of those unique fields where there are so many specialties interacting with each other. Naturally, the interplay between hierarchies, sub-specialties, data scientists and patients start to develop a large system and emergent behavior starts to occur.\n\nOne of the interesting behaviors that will be disrupted and is under research is the clinical workflow and how entities communicate with one another.\n\nImproving communication is at the core of many of these digital health startups.\n\nWhether it be ConsultLink\u2019s aim to improve care coordination between the many professionals, Medifies goal to help providers send mobile notifications to the family, friends, and caregivers of their patient, or The Right Place\u2019s objective to improve the outpatient experience, the key idea is to reduce or eliminate the friction when communicating about the current or future status about the patient.\n\nBy doing so, more time will be spent on the actual face-to-face encounter with the patient instead of the technology that can be sometimes be seen as a burden on health providers.\n\nAs written here and here (and I\u2019ll probably keep writing about it until it becomes bane), the patient will become flooded with health-related information. As that trend becomes more mainstream, the need for accessing, mining and sharing that data will become evermore pressing. There needs to be meaning behind the data.\n\nIn due time, the personal health record will become a culmination of medically-related history, genetics, risk factors, and, potentially, a glimpse of what a patient\u2019s health future may hold.\n\nThat burden of information will definitely fall in the laps of the physicians. The doctors will need to use this large amount of data and information, combine it with their knowledge, and make an accurate diagnosis or recommendation. This is where some startups are focusing their efforts.\n\nSemantic MD helps healthcare providers design and develop image analysis algorithms that integrate with their products. No coding required.\n\nThere are many more that are solving different problems in this multi-faceted industry. It is very exciting to see these machine learning companies add real value to healthcare."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/health-information-exchange-b9e9e271ea31?source=---------6",
        "title": "Health Information Exchange \u2013 The Bioinformatics Press \u2013",
        "text": "Lightning is one of those amazing wonders that embody impermanence with the might of nature. If you witness the flash of light that starts and ends in a split-second, it is often difficult to recollect the remarkable shape and brightness of the phenomena moments after.\n\nThunder is also just as cool. We all semi-know the equation that lets you calculate the distance between you and lightning by counting the seconds it takes to witness the lapse between the speed of sound and speed of light.\n\nEach molecule down the path of the energy transfer within the flash of lightning plays a distinct role in transmitting energy or \u2018information\u2019 to one another. Without one molecule, the lightning would take another form. Without one molecule, then the chain is broken and the energy transferred elsewhere.\n\nSometimes, this is how I view information transfer between two or multiple parties. Particularly in the healthcare industry.\n\nEach molecule or link, whether this be a hospital, network of hospitals, or one physician inputting EHR data, is a part of a larger chain. Each link holds a specific set of information and knowledge that needs to be transferred coherently in order to maintain overall strength and integrity of the system. If one connection is broken, the data may be fragmented, loose, or become an apparition of what was once there.\n\nThere are many people working on this problem, as it is not a new one. When considering the complexity of information exchange in the medical field, some ideas come to mind:\n\nThe network theory and theories alike say something like this:\n\nIf we take this statement from theoretical physician Markus Schirmer and relate it to the healthcare industry, we can start to imagine an extremely complex network that can be modeled by the interactions of different entities. These players can be the patients, doctors, data scientists, nurses, etc.\n\nOnce that messy picture comes to fruition, many related problems can come into purview. One of which has become a topic of discussion and will continue to be \u2014 patient information exchange.\n\nOn a national and government level, The Office of the National Coordinator for Health IT is coming up with the Trusted Exchange Framework. According to the draft created in January 2018:\n\nNote: The public has until February 18th, 2018 to comment on this framework!\n\nWith an incipient expanded network, emergent behavior will appear, and data scientists will be equipped with yet another tool to analyze how these different players may interact with one another. Eventually, patients will reap the benefits of improved care through this information exchange.\n\nThere are other related organizations that are all looking at this concept of interoperability from a different lens. Some of these include the Centers for Medicare and Medicaid Services, US Department of Health & Human Services, and the National eHealth Collaborative.\n\nAs the healthcare industry takes in more and more structured and unstructured data, these new systems and standards will be very important moving forward. As health professionals, it is imperative to understand how your unique role can influence the health information exchange of a patient.\n\nInformation is key to creating wisdom, so it is obvious that a good foundation is necessary.\n\nThis insight makes intuitive sense, but sometimes it\u2019s when research finds out the obvious things is when people and industries may start to act. When I read this, I hear that health professionals need to be more mindful in their patient interactions. I hear that technology may demand other skill sets as it becomes more integrated into the medical field.\n\nIn other words, there needs to be more care in understanding in what seemingly simple decisions we may be imposing on the patient. As health data scientists, we need to deeply understand our tools that are deployed and educate those who may be inundated with the information becomes available.\n\nMedical records are among the most important pieces of information that someone can own \u2014 these documents are years of descriptions about our health and well-being. Letting the power rest in the patient\u2019s hands and educating them about their privacy will be one key for establishing trust when exchanging information."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/global-companies-in-bioinformatics-35534789bd69?source=---------7",
        "title": "Global Companies in Bioinformatics \u2013 The Bioinformatics Press \u2013",
        "text": "Bioinformatics has become an emerging area in the field of science, and its introduction to the global industry has made a turning point in many areas such as healthcare, gene technology and medicine. Various applications of bioinformatics in fields like biotechnology, pharmaceuticals, medicine, etc. can be seen at present.\n\nIt is important to understand the nature of the current bioinformatics industry, its key players, as well as the various job opportunities available in the job market within the focus. Certain companies operating within the bioinformatics industry provide various software packages to analyze and interpret biological data whereas some provide instrumentation and supplies for various biological analysis and researches.\n\nThis article will help you get an idea about 5 leading companies currently operating in the bioinformatics industry.\n\nDNAnexus provides a cloud-based platform for analysis and management of large volumes of DNA sequence data. It is a company based in Mountain View, California, USA. The platform addresses various challenges pertaining to security, scalability, and collaboration, for organizations focusing on genomic-based approaches.\n\nFurther details can be found at https://www.dnanexus.com/\n\nSeven Bridges Genomics provides end-to-end bioinformatics solutions including access to datasets, analytic workflows, algorithms, cloud-computing infrastructure, and scientific support. Offices are located in USA, UK, Serbia and Turkey.\n\nJob opportunities at Seven Bridges Genomics include Bioinformatics Analyst and R&D Engineer.\n\nFurther details can be found at https://www.sevenbridges.com/\n\nIllumina is a company that develops integrated systems for the analysis of genetic variations and biological functions. It provides a line of products and services that serve sequencing, genotyping, gene expression and proteomics. Its headquarters are located in San Diego, California, USA and commercial offices are located in Australia, China, Japan, Canada, Brazil, UK, Singapore and Netherlands.\n\nIllumina manufactures various DNA Sequencers including MiniSeq, MiSeq, NextSeq HiSeq and NovaSeq. Furthermore, Illumina offers BaseSpace Sequencing Hub, which is a cloud-enabled environment for sequencing data management and analysis.\n\nFurther details can be found at https://www.illumina.com/\n\nGenedata is a company which provides software solutions and consulting solutions that support large-scale, experimental processes within pharmaceutical, biotechnology, and agricultural industries, as well as academia worldwide. It is headquartered in Basel, Switzerland.\n\nSome of the products include:\n\nJob opportunities at Genedata include, IT Support Engineer, Software Developer, Field Application Scientist and Data Scientist.\n\nFurther details can be found at https://www.genedata.com/\n\nGenomatrix is a company that provides technologies to analyze and interpret genomic data. Also it provides hardware and software based solutions for microarray experiments and NGS (Next-Generation Sequencing) data analyses. The company is headquartered in Munich, Germany.\n\nFurther details can be found at https://www.genomatix.de/index.html"
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/the-near-future-of-precision-medicine-ef39dbe4401c?source=---------8",
        "title": "The (Near) Future of Precision Medicine \u2013 The Bioinformatics Press \u2013",
        "text": "It\u2019s the holiday season \u2014 which means that gift giving is in full swing, and we all know giving is one of those exchanges that can go really wrong or really right.\n\nThere are a couple of ways it can go right. You graciously ask the receiver what they want, and you get it for them. Simple, but not really thoughtful or exciting.\n\nThe other, more interesting one, is the path you take that is characterized by a higher risk/reward ratio. If you\u2019re smart, you\u2019re always scheming throughout the year (that is, if you care enough) to see what the wants and needs of this special person are. This will definitely reduce your risk of giving a bad gift. BUT. There is always a but, you can also get the gift totally wrong. You got a pink shirt instead of a blue one. You thought you got the right book, but, nope you didn\u2019t.\n\nMuch like a personalized gift, personalized medicine is a place where high risk/reward can occur. As a society, we are transitioning from giving the \u2018go-to gift-card\u2019 to an upgraded \u2018diamond necklace\u2019. Or, in other words, giving a patient a well-known drug that might work versus a new clinically tested drug built for a specific mutation fueled molecular pathway that drove the patient\u2019s disease.\n\nIf the treatment goes well, hot damn, you did a great job taking advantage of the newest technology and potentially gave a patient more years to their life. If the treatment does not go well, well then you probably were better off giving the former drug. With time and ongoing innovation, personalized medicine will improve to provide better medical solutions on the individual level.\n\nJust to back up a little. Let\u2019s define precision medicine. According to the National Institutes of Health,\n\nSounds like a lot of data and interacting variables! Now let\u2019s dig into what the near-future for precision medicine will be like.\n\nPrecision medicine will be evolving quickly as new technologies become widely adopted. Clinicians, patients and Information Technology personnel will need to prepare and to stay informed.\n\n\u201cThe changes are happening so quickly,\u201d said India Hook-Barnard, Associate Director of Precision Medicine at University of California San Francisco. \u201cI think the world is going to be a very different place in five years.\u201d\n\nAt the NorthShore University HealthSystem, physicians are working closely with genetic data interwoven within their EHR system to enhance the clinical work flow system at the hospital.\n\nFor example, patients may be given a genetic test before an appointment that evaluates and identifies any genes that may pose a problem with certain drugs. This data and information will be at the fingertips of the physicians, which may empower the physician to choose a more informed and personalized approach for the patient.\n\nThroughout the world, physicians will be apt to make data-driven decisions in a real-time fashion. This new approach to providing care will be interesting to watch as more technology will be in our doctor\u2019s tool-belts. As technology adoption comes closer to reality, the ways physicians and patients used to interact will also change.\n\nThe patient will be the end-user or consumer of this technology, which makes it very, very important to understand what works and what does not. In the years to come, there will be a lot of research that will go into what data is scientifically valuable and positively life-changing and what data is junk.\n\nNo doubt, the health consumer will be more empowered with their incoming data. That being said, a new type of conversation may pop up between physicians and their patients. The patients will need help interpreting their genetic results, understanding what data is actionable and not, and making sense of clinical decisions.\n\nAs bioinformaticians, it is imperative to keep in mind the patient\u2019s needs, wants, what emotions they may feel when they see their data, and the overall presentation. The patient\u2019s input and the way they interact with technology is important to understand.\n\nThe data scientist and bioinformatician has the power to put the plethora of patient data in the palms of the physician. With this responsibility, many features will become paramount.\n\nOn top of that, much like the patient-physician relationship, there will be a increasing need to develop working physician-IT relationships since the doctors will be the end user.\n\nMoreover, bioinformaticians will need to keep up with cutting edge technologies that their job can use. According to Bryce Olson, Global Marketing Director, Health and Life Sciences, Intel Corporation:\n\nPretty soon, hospital data scientists will need to effectively leverage new genetic tools while keeping in mind that more does not necessarily mean better.\n\nThe physician, patient and bioinformatician will soon be intermingled and deeply connected in this new era of precision medicine. As with many other technologies, it is a tool. As providers and receivers of healthcare, it is important to understand the power and limitations of the tools at our disposal."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/become-a-writer-with-us-edc6dc5f0c78?source=---------9",
        "title": "Become a Writer with Us \u2013 The Bioinformatics Press \u2013",
        "text": "The Bioinformatics Press is an ongoing project to educate and inspire the public about the innovations in the fields of gene technology, medicine and healthcare particularly with computer science. We are eager to read and publish any work that may fall within the following categories related to bioinformatics.\n\nJoin us in spreading the word about the field of bioinformatics as we document the successes and challenges ahead.\n\nPlease email your work (final drafts or links to the published medium articles are preferred) to thebioinformaticspress@gmail.com and we will make sure to get back to you within 24 hours."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/bioinformatics-what-why-how-4328f8b1a200",
        "title": "Bioinformatics \u2014 What? Why? How? \u2013 The Bioinformatics Press \u2013",
        "text": "Bioinformatics has become a buzzword in today\u2019s world of Science. About one or two decades ago, people saw biology and computer science as two entirely different fields. One would learn about living beings and their functions whereas the other would learn about computers and underlying theories. However, at present, there seems to be a mere separation between the two fields and this new field, bioinformatics, has emerged as a combination of both Computer Science and Biology.\n\nVarious biological analyses result in exponential amounts of biological data and it becomes very hard to analyze them using manual means. This is where Computer Science comes to the rescue. Various computational techniques are used to analyze hunks of biological data more accurately and efficiently by means of automated processes. Hence, bioinformatics can be considered as a field of data science for solving problems in biology and medicine.\n\nBioinformatics has become an inter-disciplinary science and if you are a biologist, you will find that having knowledge in bioinformatics can benefit you immensely with your experiments and research.\n\nToday\u2019s job industry is full of vacancies for people with skills in bioinformatics. Major pharmaceutical, biotech and software companies are seeking to hire professionals with experience in bioinformatics where they will be working with huge amounts of biological and health care information. You can check out Indeed.com for several job opportunities in the field of bioinformatics.\n\nA major application of bioinformatics can be found in the fields of precision medicine and preventive medicine. Precision medicine consists of health care techniques customized for individual patients, including treatments and practices. Rather than treating or curing diseases, precision medicine focuses of developing measures to prevent diseases. Some of the diseases being focused are influenza, cancer, heart disease and diabetes.\n\nResearches are being carried out to identify genetic alterations in patients allowing scientists to come up with better treatments and even possible measures of prevention. Certain types of cancer, being caused by such genetic alterations can be identified beforehand and can be treated before the conditions get worse. You can read more about the role of bioinformatics in cancer treatment at National Cancer Institute.\n\nBefore getting deep in to the subject, as the starting steps, you will have to learn a little bit about biology; genetics and genomics to be specific. This will include studying about genes, DNA, RNA, protein structures, various synthesis processes etc.\n\nNext, you will have to study about biological sequences (for example, sequences found in DNA, RNA and proteins) and techniques to discover and analyze various patterns and informative sites in them. You will come across various algorithms used by different techniques. Also, you will get the chance to use various machine learning and data mining techniques such as hidden Markov models, neural networks and clustering.\n\nSince you will be dealing with large amounts of data, it is crucial to have a good understanding in statistics as you have to analyze data according to specific requirements.\n\nOf course you will need good programming skills. R, Python, and Bash are the most commonly used programming languages in biological data analyses. Deciding which one to start with depends on your goals. You can use other languages such as C/C++ and Java as well.\n\nAfter having the basic understanding about the fundamental concepts, you can explore other areas such structural bioinformatics, systems biology and biological networks."
    },
    {
        "url": "https://medium.com/the-bioinformatics-press/the-empowered-health-consumer-445674ab1f2f",
        "title": "The Empowered Health Consumer \u2013 The Bioinformatics Press \u2013",
        "text": "Technology and healthcare are two behemoths that will continue to cross paths. Technology is nimble. It continually has advancements in big data, AI, and machine learning. Healthcare is not so nimble. Large health organizations are starting to tap into the teeming tech innovations, but there are many forms of resistance (budget, infrastructure, buy-in, etc.). However, with a consumer and industry push towards prevention instead of treatment, investors and CEOs are feeling the two world colliding with great inertia.\n\nNew technologies are changing the healthcare landscape, and they are just scratching the surface.\n\nWhile this all sounds good \u2014 the consumer is always worth mentioning. The consumers are us. Every human being.\n\nEveryone is part of the expanding healthcare ecosystem. We all have a body, and most of us want to take care of them. Though the idea of using data mixed with the right information to push certain healthy behaviors is not new, it is one of those fields that is changing with time."
    }
]