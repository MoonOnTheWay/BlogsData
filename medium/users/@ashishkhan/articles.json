[
    {
        "url": "https://medium.com/@ashishkhan/convolutional-neural-network-with-the-simpsons-c1d5eda395bc?source=user_profile---------1----------------",
        "title": "Convolutional neural network with The Simpsons \u2013 Ashish \u2013",
        "text": "Convolutional Neural Network(CNN) is a type of neural network especially useful for image classification tasks. I applied CNN on thousands of Simpsons images training the classifier to recognise 10 characters from the TV show with an accuracy of more than 90 percent.\n\nYou can download the images from Kaggle. The dataset contains images for more than 20 Simpson characters. I picked the ones with a minimum of 1000 sample images and chose 10 characters to train my model.\n\nAll chosen characters have thousand sample images. And I split them into 800 for the training set and 200 for the test set.\n\nThe training_set and test_set folders each have 10 folders(1 per character), consisting 800 and 200 images respectively.\n\nAnd similarly for the test_set\n\nKeras is a very good python package for neural networks. To use Keras, you need tensorflow\n\nFollow the instruction on the Tensorflow website to install depending on your OS. I installed the gpu version for faster computation.\n\nIn machine learning, a convolutional neural network is a class of deep, feed-forward artificial neural networks that has successfully been applied to analyzing visual imagery. CNNs use a variation of multilayer perceptrons designed to require minimal preprocessing. Convolutional networks were inspired by biological processes in which the connectivity pattern between neurons is inspired by the organization of the animal visual cortex.\n\nCNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns the filters that in traditional algorithms were hand-engineered. This independence from prior knowledge and human effort in feature design is a major advantage. They have applications in image and video recognition, recommender systems and natural language processing\n\nI resized all my images to 128x128. You can choose a size that\u2019s greater or lower depending upon the computational power of your system.\n\nA CNN consists of an input and an output layer, as well as multiple hidden layers. I constructed 4 hidden layers for my neural network.\n\nConvolutional layers apply a convolution operation to the input, passing the result to the next layer. The convolution emulates the response of an individual neuron to visual stimuli. Each convolutional neuron processes data only for its receptive field.\n\nMax pooling uses the maximum value from each of a cluster of neurons at the prior layer, greatly reducing the size of the image after feature extraction.\n\nWe have placed our training and test images in the folders mentioned above. We now have to tell python where to find them.\n\nThis starts the training process. It took me close to 10 minutes for running 100 epochs to return an accuracy of more than 90 percent.\n\nThe kaggle dataset also has an independent folder, predict, containing close to 500 images of the 10 characters.\n\nIf you are happy with the predicted results, you can save the trained model with the below code\n\nYou can download my trained weights here."
    },
    {
        "url": "https://medium.com/@ashishkhan/unsupervised-machine-learning-simulator-download-902c2c306452?source=user_profile---------2----------------",
        "title": "Unsupervised Machine Learning Simulator \u2014 Download \u2013 Ashish \u2013",
        "text": "An easy-to-use windows application to simulate the two major Clustering algorithms for unsupervised machine learning, KMeans and Hierarchical Clustering. I\u2019ll keep updating versions to make the application more intelligent and usable with different kinds of datasets.\n\nThe Simulator is a standalone app that does not require python or any other associated dependencies to be installed in your system.\n\nOnce you have the two files ready inside the input folder, run the clustering_simulator application\n\nThis will generate three files \u2014 dendogram.jpg, output.csv and output.txt. Output.csv will have your predicted values and output.txt will give information about the algorithm used, number of clusters and elements per cluster details.\n\nThe dendogram.jpg file will help you verify if the number of clusters chosen by the application is reasonable. You can always change the cluster number in the program settings file and run the application again.\n\nWith every dataset being unique in its own way, your algorithm might require custom configurations and this application may not give you the best results.\n\nAnd in such cases mail your requirements to khan.mlblog@gmail.com"
    },
    {
        "url": "https://medium.com/@ashishkhan/supervised-machine-learning-simulator-download-8fa856072252?source=user_profile---------3----------------",
        "title": "Supervised Machine Learning Simulator \u2014 Download \u2013 Ashish \u2013",
        "text": "An easy-to-use windows application to simulate major Machine Learning algorithms. Right now, it supports very basic algorithms at their default settings and I\u2019ll keep updating versions to make it more intelligent and usable with different kinds of datasets.\n\nThe Simulator is a standalone app that does not require python or any other associated dependencies to be installed in your system.\n\nOnce you have the two files ready inside the simulator folder, run the simulator application\n\nThis will generate two files \u2014 output.csv and output.txt. Output.csv will have your predicted values and output.txt will give information about the algorithm used, the accuracy and other details.\n\nRight now output.txt gives information only about the algorithm used. More insights will be included in upcoming updates.\n\nWith every dataset being unique in its own way, your algorithm might require custom configurations and this application may not give you the best results.\n\nAnd in such cases mail your requirements to khan.mlblog@gmail.com"
    },
    {
        "url": "https://medium.com/@ashishkhan/crofters-the-good-the-bad-and-the-ugly-3ebe1b36e8e6?source=user_profile---------4----------------",
        "title": "Crofters: The Good, the Bad and the Ugly \u2013 Ashish \u2013",
        "text": "This blog discusses my experience as a young startup founder, the challenges faced, the high points and of course, the fall. We started with three co-founders with the goal of growing fresh greens and veggies inside living rooms. After a turbulent journey of close to two years, we had to shut the company down.\n\nCrofters\u2019s flagship ecosystem, is an intergrated aquagardening system which helps you grow fresh food farmed in the convenience of your very living room.\n\nWe built the product for people who are keen to furnish their living room with an aquarium and a mini-garden in less than a shoe-rack\u2019s space, gardening hobbyists living in a crowded metro with no balconies or backyards. And with the Ecosystem being a controlled system, growing plants like strawberries in a 40 degree Chennai weather was no longer a dream.\n\nI did not quit my job with a plan. Losing everything is sometimes the best way to reinvent yourself. I helped my friend with his newly found Start-up and at around the same time I was looking at similar Start-ups in the US picking up pace and wanted to build one for myself at home.\n\nWith close friends from college and school, who later formed the core of the company, we built the below prototype. People around us appreciated and loved the system we built, and that\u2019s when we decided to make a company out of it.\n\nThe plan was not just about being a single product company but also to provide an e-commerce platform for gardening and fish-keeping accessories.\n\nWith Kolathur, the hub of ornamental fish trade in the country being within reach for partnerships, we managed to sell our products online much cheaper than our competitors.\n\nThe momentum was very high and it carried us forward with the first order coming even before we made a stable, marketable product. Within days after delivering the first order, we installed our systems at Teach for India led school and also at workplaces.\n\nThings were going so well. We were awarded the Best Business Startup award by IIM Ahmedabad, Innovators of the month award by Tissot and were featured in media like the Hindu.\n\nAn opportunity came from a MIT based company in the USA for a partnership deal and it still remains as one of the high points in my career. Not because of the deal itself but for the way we as a team worked together to achieve the goal.\n\nWe were challenged with a very short duration to ship the product and manufacturing the product was the easier task when compared to figuring out packaging, export licenses, shipping agents etc.\n\nWe then got incubated by NIT Trichy\u2019s CEDI. Things were beginning to look good before it took a U turn.\n\nMost of our team were of interns. We couldn\u2019t afford to keep them for long and they left for \u201creal\u201d jobs. Each departure left a dent in the team and to see the office reduce to 3\u20134 people from 10\u201315 in a matter of few months was confidence-sapping. We also lost one of our co-founders midway. With just 2 of us making decisions, differences in opinions seemed more like ego clashes. I would\u2019ve loved a third perspective at that point.\n\nAll of us were first time entrepreneurs and the tag \u2018engineers\u2019 described us better. Maybe if we had prior experience we would have concentrated more on the business side of the things and less on making things \u2018cool\u2019.\n\nBut when I look back at the whole journey I have nothing but positive experiences and Crofters has been the best phase of my life so far. There were a lot of amateur mistakes that if I were to start all over again I might do those things differently.\n\nIt has been a great learning curve and I\u2019ll carry everything forward into my next phase in life. Cheers!"
    },
    {
        "url": "https://medium.com/@ashishkhan/buddy-my-whatsapp-personal-assistant-with-python-6ec7160edbf5?source=user_profile---------5----------------",
        "title": "Buddy: My WhatsApp Personal Assistant with Python \u2013 Ashish \u2013",
        "text": "This is a different kind of chat bot built with Selenium. Selenium is a tool for automating web browsers. Selenium is capable of doing anything that you would be able to do on a browser.\n\nSo this script simulates what you\u2019d normally do to message your friend on WhatsApp.\n\nNow let\u2019s get started with the code\n\nMake sure to have python3, selenium and beautifulsoup installed and import the following dependencies. Any missing libraries can be installed with pip install.\n\nAll major browsers are supported in Selenium. I used Chrome for the chat bot.\n\nFor some reason navigating to \u201chttps://web.whatsapp.com/\" did not work. So I converted the url with Google URL Shortener.\n\nI added a delay of 25 seconds to allow WhatsApp to load completely.\n\nDefine your friend or the group name, matching the characters exactly. The below code scrolls through the chat list to find the tab matching your target and clicks on it.\n\nThe below is a series of conditions to check, if the selected tab is an user or a group, if the last message was sent by the Bot or by a friend.\n\nOnce properly located, the script stores the last sent message. This code runs every 5 seconds and looks for any new message with the threading function.\n\nThe rest of the code should be placed inside this function.\n\nPrint out the stored details to verify if everything works.\n\nWhen the conditions are satisfied, the code looks for the word \u201cBuddy\u201d in the stored text (the Bot only responds to texts with the word \u201cBuddy\u201d). This is to ignore other text messages that are not intended for the Bot.\n\nThe message is iterated through the csv file and a corresponding reply is returned.\n\nThe message is either in the csv file or absent. A simple if-else statement to return the corresponding reply.\n\nSelenium is then used to locate the \u201center\u201d button and the reply is sent on WhatsApp\n\nInstead of looking up for replies from the csv file, the bot can be integrated with the Facebook and Twitter API (refer previous blog) to send the retrieved data from social media to WhatsApp.\n\nA message: \u201cBuddy, Give me the latest news from BBC facebook page\u201d should reply you with the latest status from the FB page."
    },
    {
        "url": "https://medium.com/@ashishkhan/extract-facebook-and-twitter-data-from-any-page-71198fa65349?source=user_profile---------6----------------",
        "title": "Extract Facebook and Twitter data from any page \u2013 Ashish \u2013",
        "text": "You may need data from social media like Facebook and Twitter for a variety of reasons. I for one use it for statistical analysis \u2014 to get the reactions on posts from a certain page and make it into a spreadsheet for easy analysis.\n\nTo be able to extract publicly available data using a python code, you need to register as a developer and then get your app\u2019s access tokens.\n\nThe provided APIs are no longer public APIs and it requires user authentication via access tokens\n\nSince the user access token expires within an hour, we use the app ID and app secret generated above from our dummy application solely made for scraping, both of which never expire.\n\nNow we can access public Facebook and Twitter data without limit. Let\u2019s do our analysis on the Manchester United Facebook and Twitter page, which is popular enough to yield good data.\n\nChange num_statuses in parameters to the number of statuses you want to extract from the page\n\nWhen scraping large amounts of data from public APIs, there\u2019s a high probability that you\u2019ll hit an HTTP Error 500 (Internal Error) at some point. There is no way to avoid that on our end.\n\nInstead, we\u2019ll use a helper function to catch the error and try again after a few seconds, which usually works. This helper function also consolidates the data retrieval code, so it kills two birds with one stone.\n\nThe status is now a Python dictionary, so for top-level items, we can simply call the key.\n\nAdditionally, some items may not always exist, so we must check for existence first\n\nAnalyzing data on Posts can be used to quantify the growth and success of your own page, or that of your competitors. Or, like you\u2019ll see in the next blog, to build a WhatsApp bot\n\nThe data is easy to get and is very useful."
    },
    {
        "url": "https://medium.com/@ashishkhan/face-detection-with-darknet-yolo-1b3d5d15e824?source=user_profile---------7----------------",
        "title": "Face detection with Darknet Yolo \u2013 Ashish \u2013",
        "text": "You only look once (YOLO) is a state-of-the-art, real-time object detection system. It comes with a few pre-trained classifiers but I decided to train with my own data to know how well it\u2019s made, the potential of Image Recognition in general and its application in real-life situations.\n\nIf you are a fan of HBO\u2019s Silicon Valley TV series, you might be aware of the famous Not Hotdog app that J\u00ecng-Y\u00e1ng built. This is similar, very basic, and detects if an image has me or not.\n\nTo get started, we need to install Darknet with two dependencies \u2014 OpenCV and CUDA for faster computation. The following were on an Ubuntu 16.04 machine with Nvidia GTX 1060.\n\nTo verify your installation, run darknet with\n\nIf you get the above output, you\u2019re good to go to the next step!\n\nCompiling with your GPU is many times faster than your CPU. To install CUDA, you\u2019ll need a compatible Nvidia gpu. For installation, download CUDA (make sure it is version 8) and follow the instructions on the website.\n\nTo enable CUDA, change the first line of the Makefile in the base directory to GPU = 1 and \u2018make\u2019 in the terminal\n\nTo support multiple formats of media install OpenCV. Check instructions here\n\nSimilar to CUDA, change the Makefile to read OPENCV=1 to enable OpenCV and then \u2018make\u2019 in the terminal to build the darknet application.\n\nCreate file yolo-obj.cfg with the same content as in yolo-voc.2.0.cfg (or copy yolo-voc.2.0.cfg to yolo-obj.cfg) and:\n\nCreate file obj.names in the directory darknet\\data\\, with objects names \u2014 each in new line\n\nCreate file obj.data in the directory darknet\\data\\, containing (where classes = number of objects):\n\nPut image-files (.jpg) of your objects in the directory darknet\\obj\\\n\nCreate .txt-file for each .jpg-image-file \u2014 in the same directory and with the same name, but with .txt-extension, and put to file: object number and object coordinates on this image, for each object in new line: <object-class> <x> <y> <width> <height>\n\nUse the BBox-Label-Tool to get the face coordinates from your images.\n\nFor example for img1.jpg you should create img1.txt containing:\n\nCreate file train.txt in directory darknet\\data\\, with filenames of your images, each filename in new line, with path relative to ./darknet, for example containing:\n\nDownload pre-trained weights for the convolutional layers (76 MB): here and put in the main directory.\n\nStart training by using the command line: ./darknet detector train data/obj.data yolo-obj.cfg darknet19_448.conv.23\n\nAfter training is complete \u2014 get result yolo-obj_xxxxx.weights from darknet\\backup\\\n\nAfter each 1000 iterations you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just copy yolo-obj_2000.weights from darknet\\backup\\ to main directory and start training using: ./darknet detector train data/obj.data yolo-obj.cfg yolo-obj_2000.weights\n\nDuring training, you will see varying indicators of error,\n\nWhen you see that average loss 0.xxxxxx avg no longer decreases at many iterations then you should stop training.\n\nTest your trained weights using the command\n\nAfter over 40000 iterations I found my results to be fairly accurate. By default, YOLO only displays objects detected with a confidence of .25 or higher. You can change this by passing the -thresh <val> flag to the yolo command.\n\nI dont know if an application exists based on darknet yolo. Building one will make it complete and useful for real-life applications. Something that can iterate through multiple images and save the results for easy insights should be the next step. If you have built one already, let me know.\n\nBut doing this small exercise made me appreciate the power of Image Recognition. If you\u2019re a mechanical engineer like myself, you can instantly build a tool for manufacturing companies to study the material flaws in industrial radiography. Or a sign language translator for the hearing-impaired people. The possibilities are endless."
    },
    {
        "url": "https://medium.com/@ashishkhan/analysis-of-water-situation-in-chennai-web-scraping-4047bf3af4bf?source=user_profile---------8----------------",
        "title": "Analysis of water situation in Chennai \u2014 Web Scraping",
        "text": "This post is inspired from a recent forward on social media about rain and water situation in Chennai. This also triggered the curiosity of data monks (a secret group) in Report Bee with questions like?\u2026\n\nWe needed data to answer these questions. Luckily we had a good starting point for our data adventure with the website of Chennai Metro Water providing water levels of Chennai\u2019s reservoirs (Lakes) for each day for the last 14 years.\n\nA Python script (full code) helped retrieve the total volume of major reservoirs in Chennai. Once we had the data in the desired CSV format, it was play time \ud83d\ude42\n\nWe plotted various graphs to visualize the data and learn from it . The first graph, the total water levels from 2004 until today.\n\nFrom the above graph, from 2004 up until 2012, the water levels have been fairly consistent across the year and these were years of water sufficiency. From 2013 onwards, there is a drastic fall in water levels across the 5 chief reservoirs which supply water to Chennai. This shortage of water did not stop even in 2015- December, the year infamous for Chennai floods.\n\nWhat we are seeing increasingly is a Monsoon that is holding itself back a little and then packs a punch too wet to handle in the months of Nov-Dec.\n\nThe truth is that when it rains so much in so little time, all water goes down the drain, literally. We need new ways to trap the monsoon efficiently.\n\nThen, we visualized the 2004 to 2017 in an overlapping graph.\n\nThis visualization makes it is easy to compare the water levels across the years. In recent years, we run out of water faster and failed Monsoon threatens the city of drought. Validates the humour in the title of this post.\n\nTo understand this better, we calculated time taken for the water level to come to 3600 Mcft from 10000 Mcft in a given year. Assuming that this level of water is a situation of concern. Listing the calculation for some of the years.\n\nIn 2030, at full capacity in the 5 chief reservoirs, we\u2019ll completely run of water in 9 months even if we get good rains. Chennai will face severe water scarcity in coming years.\n\nDo we need more desalination plants? Do we need to build more reservoirs? Take a look at the table below.\n\nThree were built in British era and other 2 much before! Are our catchment areas (reservoir locations) enough, do we need more?\n\nMonsoons are India\u2019s lifeline. We used to be an agrarian economy dependent on rainfall for our survival in the global market. Today, years later, though the balance has shifted in favour of services more than manufacturing or agriculture, we are still dependent on these life-giving winds from the Indian Ocean. Even if not for agriculture in Chennai, it is to feed our rivers and put that glass of water on our dinner tables!"
    }
]