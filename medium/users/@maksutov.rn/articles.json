[
    {
        "url": "https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-3a-optimizers-overview-ed1631127fb7?source=user_profile---------1----------------",
        "title": "Deep study of a not very deep neural network. Part 3a: Optimizers overview",
        "text": "In the previous part we have seen, how different activation functions perform with RMSProp optimizer. Now we will test various optimizers with the same set of activation functions, to see which combination works best.\n\nThe list of optimizers we will be comparing consists of:\n\nThese optimizers are also implemented in Keras, and can be used out-of-the box. Each optimizer has a few parameters with default values set according to the original papers. We will use these defaults, except for RMSProp, where as in the previous part, the learning rate will be set to 0.001 instead of 0.01. When I was preparing the experiment I found that the value of 0.001 for RMSProp makes the training results more comparable to the results of other optimizers.\n\nAs this is a not introductory tutorial, I assume that the reader already knows what is an optimizer, and how it works. There are lots of good sources on optimizers for those who would like to get a basic understanding, like this and this. Just to recap, optimizer is an algorithm, which purpose is to minimize the objective function. In plain words, it calculates, how to change the weights of your neural network, so that the error becomes lower on each iteration.\n\nAs with activation functions, over the last decades many optimizers have been developed, and it is not so easy to a beginner to pick the right one. Hundreds of research papers present, discuss and compare various optimizers, and often the results of comparing them are contradictory. You may see that in one paper the experiment shows that certain optimizer is better than others, and in another paper in a different experiment that optimizer has performed worse. It is a common case in Deep Learning, that there\u2019s no \u2018silver bullet\u2019, and the choice of an optimizer may be determined by the nature of the data, the architecture of a neural network, the formulation of the problem, and many other factors. Besides that, almost every optimizer has a number of parameters, which may have a significant effect on the quality of training. It is often hard to find the explanation of these parameters, and most of other tutorials almost always use the default values, except for the learning rate.\n\nIn this series we will be comparing optimizers when applied to image classification problem with a fully-connected neural network. But before that, I would like to demonstrate the differences of each optimizer, and, more importantly, demonstrate how changing certain parameters of an optimizer affect the training process.\n\nFor this we will run another experiment, this time even much more simple one.\n\nConsider a linear function y = a*x + b. We will train a neural network consisting of just one layer with one neuron and linear activation, and its aim will be to find the values a and b. Yes, it is a plain old linear regression, and there\u2019s no point doing it using neural networks. But this example will allow us to visualize the training process, and see, how the optimizer comes to the target values.\n\nAs you may remember, each neuron has weight and bias values. So the output of this neuron with linear activation will be weight * input + bias, which looks in the same way as our target function. Therefore the optimal weight and bias found for this neuron will represent the a and b values of our function.\n\nThe neuron weight will be initialized with the value 0 and the bias with the value 0. Optimizers will be minimizing Mean Squared Error, which for this starting point is equal to 0.065929635, and the number of epochs will be set to 100.\n\nThe notebook with the code for this experiment is available on my github, so you may experiment with other target functions.\n\nI have randomly chosen a and b to be equal to 0.1 and 0.3 respectively, and now let\u2019s have a look, whether optimizers have managed to find these values, how changing optimizer parameters affect the training process, and how did each optimizer was coming to the solution.\n\nIn Keras, SGD, besides learning rate, has a number of parameters: momentum and nesterov. Momentum determines how much the previous gradients will affect the current one. It accelerates SGD by navigating along the relevant direction and softens the oscillations in irrelevant directions. Nesterov parameter tells, whether to use Nesterov variant of SGD, which prevents the optimizer from missing the minima if the momentum is too high.\n\nThis is how the learning process progresses with various values for momentum with nesterov = False:\n\nYou can see that for very low momentum the oscillations are nearly absent, and the weights changes very slowly. The models with momentum >= 0.9 were unable to get close to the minima (which is known to us). When the momentum is too high, the oscillations are large, and we can see that with momentum 0.99 the optimizer first missed the minima, then started converging. The best momentum value has been 0.95, resulting in relatively stable training and the lowest error.\n\nNow compare that to the case when nesterov parameter is set to True:\n\nThe training has become much more stable, and despite the fact that again the optimizer with 0.99 momentum has initially missed the minima, it has still resulted in the lowest MSE after 100 epochs. In both cases optimizers with the default momentum value of 0.0 were not able to come close to the minima by the end of the training. Therefore we can say that the usage of the right momentum value accelerates training, and nesterov makes it more stable. However, it is not always true that setting nesterov to true or setting higher momentum would be able to produce better results. Look at this graph:\n\nIt looks like someone gave a pencil to a 2-year-old child. Momentum values that are too high, as well as too low result in very bad performance. Also, for momentum = 0.95 the optimizer without nesterov slightly outperforms the one with the same momentum with nesterov:\n\nFrom this experiment it is evident that momentum or nesterov alone will not be able to produce lower error. Instead, you should use nesterov and try several momentum values in order to find the one that gives the best results.\n\nAdaGrad is a variation of SGD, but with learning rate that is adjusted separately for each parameter on each step according to the size of the gradients for this parameter. When gradient change is small, AdaGrad decreases the learning rate less, so that it moves towards the optimum faster. When the gradient is large, the learning rate is decreased more, resulting in smaller steps, so that the optimizer does not jump over the optimum.\n\nAdaGrad does not have any tunable parameters, except for the initial learning rate and learning rate decay, so here I will show you only the training process with several decay rates:\n\nThe training goes very stable, and as we see, the best decay rate was 0.0. Actually, in AdaGrad setting decay rate doesn\u2019t make much sense, because the learning rate will be adjusted properly anyway.\n\nThis optimizer combines the ideas from momentum-based SGD (the usage of the exponential moving average of the past gradients) and AdaGrad (adapting the learning rate).\n\nIt has the same parameters, like learning rate and decay, but also uses RHO parameter, which is similar to momentum in SGD. Let\u2019s test different RHO values with 0.0 decay and 0.01 learning rate:\n\nThe training is very stable for all RHO values, and almost all of the models have been able to get very close to the minima, except for RHO = 0.0. Notable ones are with RHO > 0.99. For 0.9999 the first step was in a very wrong direction, but contrary to what we have seen with SGD\u2019s momentums above 0.99, the final result has been fantastic:\n\nAnother extension of AdaGrad optimizer, which instead of accumulating all past gradients, uses only last N of them. The parameters of this optimizer are similar to the ones of RMSProp. This is how it performs with different RHO values:\n\nNote that for RHO values below 0.9999 \u2018the higher the better\u2019 rule does not work. Also the training has been very slow, despite choosing very large initial learning rate, so keep in mind that with this optimizer you may need more iterations than with other ones.\n\nStands for adaptive moment estimation, an optimizer that is similar to AdaDelta and RMSProp, but in addition to what these two do, it keeps an exponentially decaying average of past gradients. Beta_1 and beta_2 parameters are the decay rates, which by default are equal to 0.9 and 0.999 respectively. The image below confirms that these values are not the only best ones for our specific case, and the other good combinations are {0.95, 0.999}, {0.9, 0.9999} and {0.95, 0.9999}:\n\nThe closer beta_1 to 0.9, the less the optimizer accounts the previous gradients, and the \u2018jumps\u2019 to the sides are weaker. And with higher beta_2 the optimzers\u2019s velocity towards the minima. However, when these two values are too high, the optimizer misses the minima because of high velocity gained on the previous steps. It is interesting that all optimizers except for the last two have perfectly found the a = 0.1 and b = 0.3 values.\n\nAdam also has another variant \u2014 AMSGrad (in Keras, it is controlled by setting amsgrad = True for Adam optimizer), which uses the maximum of past squared gradients in order to allow the rarely-occurring minibatches with large and informative gradients to have greater influence on the overall direction, otherwise diminished by exponential averaging in plain Adam.\n\nThis is how the training process graph looks for AMSGrad:\n\nQuite similar to Adam: again the 0.99 value for beta_1 resulted in jumping over the minima, and the rest have managed to find the desired values. The visual difference between regular Adam and AMSGrad is that in the latter the optimizer\u2019s path is more stable.\n\nThis optimizer takes the idea of Adam one step further, and for the current gradient takes the maximum of beta_2 x past gradients and the current gradient. This results in a smaller and smoother movement towards the minima:\n\nNote that the default value for beta_2 (0.999) was not the best in our case: lower beta_2 values (0.95\u20130.99) demonstrate better performance.\n\nThe last optimizer we are exploring is again the development of the previously discussed ones. Nadam (Nesterov-accelerated Adaptive Moment Estimation), as you may understand from its name, combines combines Adam and Nesterov-accelerated SGD, so it is both stable and reaches the minima very closely:\n\nThe best two optimizers here used beta_1 equal to 0.95 and 0.99 and beta_2 = 0.99. While the authors suggest different values, this example shows that it is always worth trying various combinations, to see what works best for each specific case.\n\nIt is interesting that only Adam (and its AMSGrad variation) and RMSProp optimizers were able to perfectly find the a and b values. That doesn\u2019t mean that more sophisticated optimizers are worse. It always depends on the task, the configuration of the network, the data and many other factors.\n\nAnd of course, there are more optimizers out there used in training neural networks. There is a whole area in mathematics devoted specifically to the search of more advanced and sophisticated optimization methods and algorithms. I hope this brief overview gave you an intuition of what your options are, and what are the differences in terms of the training process. You may find the source code and the final rankings of the optimizers in my notebook on github.\n\nIn the next part we will come back to our simple neural network, and test these optimizers with various parameters, to see which is best.\n\nI\u2019m always happy to meet new people and share ideas, so if you liked the article, cosider adding me on LinkedIn."
    },
    {
        "url": "https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-2-activation-functions-fd9bd8d406fc?source=user_profile---------2----------------",
        "title": "Deep study of a not very deep neural network. Part 2: Activation functions",
        "text": "This is the second part of the series, and this time we will explore activation functions. I assume that you already know, what is an activation function, and what role it plays in a neural network.\n\nIn our experiment we will be comparing the activation functions included in Keras, specifically:\n\nAs in the previous part, here we will stick to RMSProp optimizer. In the later parts of the series we will also evaluate, how various activation functions work with different optimizers, but for now let\u2019s get the first view on the activations. As for the data, we will be training our networks on dataset-wise normalized data (because it performs equally well compared to sample-wise one) and on sample-wise standardized data (you know why, if you have read the previous part).\n\nBelow is a brief and not very scientific description of each activation function, just to provide you with an intuitive understanding of each.\n\nLinear activation (also called Identity) function is one of the simplest possible activation functions. It linearly translates input into output. It is almost never used in training neural networks nowadays both in hidden and in final layers. Its range and domain are equal to [-Inf; +Inf].\n\nSigmoid activation function translates the input ranged in [-Inf; +Inf] to the range in (0; 1), and looks like an S-shaped curve. It is generally the first choice when developing simple neural networks for learning purposes, but as of today it is generally being avoided because of its lower quality compared to other activation functions.\n\nSuffers from the Vanishing gradient problem, when \u201cin some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value\u201d.\n\nThis function is piece-wise linear approximation of the sigmoid function. It is equal to 0 on the range [-Inf; -2.5), then linearly increases from 0 to 1 on the range [-2.5; +2.5] and stays equal to 1 on the range (+2.5; +Inf] (Source). Computing Hard Sigmoid is considered to be faster than computing regular Sigmoid, because you won\u2019t have to calculate the exponent, and it provides reasonable results on classification tasks. But exactly because it\u2019s an approximation, it shouldn\u2019t be used for regression tasks, as the error will be much higher than that for regular sigmoid.\n\nTanH looks much like Sigmoid\u2019s S-shaped curve (in fact, it\u2019s just a scaled sigmoid), but its range is (-1; +1). It has been quite popular before the advent of more sophisticated activation functions. Briefly, the benefits of using TanH instead of Sigmoid are (Source):\n\nHowever, similar to Sigmoid, TanH is also susceptible to the Vanishing gradient problem.\n\nWorks as a continuous approximation of the sign function, and its graph looks very similar to TanH. However, TanH grows exponentially, whereas SoftSign \u2014 polynomially. The range of SoftSign is also (-1; +1).\n\nA very simple yet powerful activation function, which outputs the input, if the input is positive, and 0 otherwise. It is claimed that it currently is the most popular activation function for training neural networks, and yield better results than Sigmoid and TanH. This type of activation function is not susceptible to the Vanishing gradient problem, but it may suffer from the \u201cDying ReLU problem\u201d. As stated in Wikipedia: \u201cReLU neurons can sometimes be pushed into states in which they become inactive for essentially all inputs. In this state, no gradients flow backward through the neuron, and so the neuron becomes stuck in a perpetually inactive state and \u201cdies.\u201d In some cases, large numbers of neurons in a network can become stuck in dead states, effectively decreasing the model capacity. This problem typically arises when the learning rate is set too high.\u201d Here\u2019s a very good description of this issue: https://www.quora.com/What-is-the-dying-ReLU-problem-in-neural-networks.\n\nThis activation function has parameter alpha, which controls the steepness of the line for x < 0 and is set to 0.0. Setting this parameter to any value < 1.0 transforms this activation into Leaky ReLU and setting it to 1.0 makes this function work as Linear activation. What happens, when alpha is > 1.0 will be interesting to investigate.\n\nA variation of the ReLU function, which allows a small \u2018leakage\u2019 of alpha of the gradient for the inputs < 0, which helps to overcome the Dying ReLU problem. By default in Keras alpha is set to 0.3\n\nAnother variant of ReLU activation, where the output is 0 for x < theta, and equals to x if x >= theta. In Keras the default value for theta is set to 1.0, whereas in the original paper the value of 0.7 is said to provide the best results for their particular experiment.\n\nLess widely-used modification of ReLU, which is said to lead to higher classification results than traditional ReLU. It follows the same rule for x>= 0 as ReLU, and increases exponentially for x < 0. ELU tries to make the mean activations closer to zero which speeds up training.\n\nIt has just one parameter alpha, which controls the scale of the negative part, and by default is set to 1.0.\n\nThe last rectifier we will be evaluating in our experiment. It extends ELU with parameter lambda, responsible for scaling both positive and negative parts. Alpha and lambda are hardcoded in this function are are roughly equal to 1.67 and 1.05 respectively, as proposed in the paper by Klambauer et al. They also say that this activation should be used together with \u201clecun_normal\u201d initializer and AlphaDropout, but for the sake of comparability with other activations in this part we will use default initializer and regular Dropout. We will check the proposed initializer and dropout for SELU later in the series.\n\nSoftPlus function\u2019s graph looks like smoothened ReLU. I couldn\u2019t find the exact reasons for why SoftPlus should be preferred over any other activation function, and this is supported by the statement from Deep Sparse Rectifier Neural Networks paper by Glorot, Bordes and Bengio: \u201cDespite the hard threshold at 0, networks trained with the rectifier activation function can find local minima of greater or equal quality than those obtained with its smooth counterpart, the softplus.\u201d\n\nJust for your convenience here are all activation functions combined in two graphs:\n\nWhen comparing the activation functions we will consider the same indicators as in the previous experiment. After we have trained our network with RMSProp optimizer with each of the activation function 5 times, here\u2019s what we get for the normalized dataset (sorted by Overall Max Achieved Validation Accuracy):\n\nThere are clear underperformers here: Linear activation, Thresholded ReLU with default theta value and Leaky ReLU with very large alpha. Linear activation wasn\u2019t able to pass the 93% accuracy level in all four measures. Thresholded ReLU has the lowest accuracy value at the final epoch, and one of the lowest maximum achieved accuracy, which means that there is overfitting. Widely used ReLU demonstrated average results. The clear winners here are ELU and SELU activations.\n\nAnd this is the same table for the sample-wise standardized data:\n\nHere the rankings are basically the same with some minor movements in the middle of the table. However, in general the performance of the networks trained with standardized data are slightly worse. The only exception is for Thresholded ReLU, where the results have improved significantly.\n\nNow let\u2019s compare the two data transformation ways more closely:\n\nOn average with normalized data you will be able to achieve slightly better results. There are a few activations, which (if for whatever reason you decide to use them) perform better on standardized data. However, there is one interesting thing to note here: for significant amount of the activations the maximum accuracy value is achieved earlier with standardized data, than with normalized data. So if for your particular experiment you can sacrifice some accuracy in order to reach the maximum results faster, standardized data is the way to go.\n\nNow let\u2019s investigate closer the details of training the network with each activation function, so you can clearly see the difference in their training behaviour. (Beware, lots of graphs!)\n\nLinear activation has shown the worst results. As we can see from the image below, the training has been very unstable, especially for the standardized data. The vertical lines showing the moment, when the maximum validation accuracy in each experiment has been achieved, are spread across the entire x-axis. This means that after a certain point, the optimizer cannot find a better local minima, jumping back and forth. This can be solved by reducing the learning rate (which we will explore later in the series), but it is also the problem of the linearity of the model, which cannot model too complex dependencies.\n\nSigmoid activation is resulting in a much more stable model, than with Linear one, and achieved maximum validation accuracy values are closer to the end of the training, but the validation accuracy value is average.\n\nVery similar to the plain Sigmoid, it has lower final average value and lower maximum average, but the maximum achieved validation accuracy is exactly the same as for Sigmoid. So for this particular setting, we can say that Hard Sigmoid performs worse than Sigmoid. The maximum values on the normalized data are closer to the end of the training, which tells us that if we adjust the learning rate, it may achieve better results.\n\nDespite having roughly the same Maximum achieved validation accuracy as for Sigmoid, TanH is a bit less stable. The majority of the local minima have been reached closer to the middle of the training, and the optimizer wasn\u2019t able to improve the results further. The model with this activation function may also benefit from decreasing the learning rate. It is also interesting to note that despite TanH is perceived as more advanced than Sigmoid, and is used nowadays much more often, the latter may still be more applicable in certain network set-ups and tasks.\n\nOn normalized data all lines follow the average very closely. But the results of the training are also somewhat average. With standardized data SoftSign is much less stable despite demonstrating slightly higher final accuracy.\n\nThis is the first time we see overfitting in our experiment. As we can see, the models reach their peak performance between the 10th and the 40th epochs, and then start slowly decreasing. Maximum achieved validation accuracy is identical to that of Sigmoid for normalized data, and lower for standardized. So without further fine-tuning Sigmoid beats ReLU here.\n\nLeaky ReLU has shown worse performance than its traditional variant \u2014 ReLU. Both the maximum validation accuracy and the accuracy at the last epoch are lower than those of ReLU. Which means that even with overfitting, ReLU is more preferable for our case.\n\nReducing the \u2018leakage\u2019 parameter alpha helped the model to significantly improve the results both on normalized and standardized data.\n\nSetting alpha to a relatively large value resulted in one of the worst performances in out experiment. The training was highly unstable, and the accuracy was very low. So don\u2019t do that.\n\nThis is a very interesting case. The models trained with Thresholded ReLU with normalized data have quickly reached the maximum values, and then started to decrease. So it\u2019s a clear overfitting, and also very bad overall performance. Whereas on the standardized data, despite still underperforming when compared to other activations, there was no overfitting at all. We see that the theta value proposed in the original paper does not work well for normalized data. And this is probably the best demonstration of how different may the models perform with the two data transformation approaches.\n\nThis theta value has resulted in even worse performance. Which means that you should use the default values built into the deep learning frameworks with caution, and always check if changing them leads to better results.\n\nSignificant improvement both in terms of accuracy and overfitting, but still overall lower than average performance. This example demonstrates that tuning the model parameters according to the data you feed in is incredibly important.\n\nQuite stable and one of the best in terms of maximum achieved validation accuracy value. The maxima have been reached in the middle of the training, so it can get to the best results faster, and potentially with some fine-tuning of the learning rate these results can be further improved. This activation performed high both on standardized and normalized data.\n\nAlso very good performance, at least on the normalized data.\n\nELU with alpha = 1.5 was among the leaders across all activation functions on the standardized data. It performed almost as high as SELU. The maxima values on the normalized data are very close to the end of the training, so probably, if further trained, it could have achieved even better results.\n\nSecond-best activation function, quite stable and demonstrates higher performance. Slightly unstable on standardized data. Later we will check, if it is possible to improve the results by reducing the learning rate and tuning the dropout in order to stabilize the training and achieve higher accuracy.\n\nThis function was the third in terms of the maximum achieved validation accuracy (after SELU and ELU) on the normalized data, but with a large gap separating it from the leaders. On standardized data there was overfitting and lower than average performance.\n\nIf we compare SoftPlus with the results of ReLU, we can see that the statement about the \u201cgreater or equal quality\u201d of ReLU compared to SoftPlus has not been confirmed for our particular setting. It supports the widely accepted idea that benchmarking neural networks\u2019 components is difficult and leads to contradicting results in different network set-ups.\n\nThe example with SoftPlus beating ReLU contrary to what the fathers of Deep Learning have said in their paper mean that the rankings of the activation functions that we received in this experiment and the results are only applicable to the specific configuration of the neural network we are considering, and in general do not tell you that one activation function is better than another. But at least for the 3-layered fully-connected network with RMSProp optimizer on the image classification task we can say that by using Exponential Linear Unit activation or its Scaled variation you will be able to achieve better results, than with other activations.\n\nTo sum up, the main learning points from this experiment is that for similar task and neural network set up you should:\n\nYou can find the code for the experiments and for visualizing the results on my github. In the next part we will expand our experiment and test other optimizers in the same way to see, how they perform in combination with the same set of activation functions.\n\nI\u2019m always happy to meet new people and share ideas, so if you liked the article, cosider adding me on LinkedIn."
    },
    {
        "url": "https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-1-whats-in-our-data-7971356037a3?source=user_profile---------3----------------",
        "title": "Deep study of a not very deep neural network. Part 1: What\u2019s in our data",
        "text": "People who begin their journey in Deep Learning are often confused by the problem of selecting the right configuration and hyperparameters for their neural networks. Various courses, tutorials and textbooks just briefly describe the available options and don\u2019t provide guidance on their applicability and performance. In most tutorials, it is stated that some function, optimizer, or initializer is just preferred over others, without explaining why, or under what conditions. Certain parameters, like the number of units, or epochs, are sometimes given without any justification. Students are told to \u2018play around\u2019 with them on their spare time to see if it can improve the results. Various authors refer to the process of finding the best configuration for a neural network as an art, and say that the ability to pick the right values comes with experience. I don\u2019t believe it\u2019s always true. Some common knowledge should be made easily available to the people who are making their first steps in this field, without the need to go through hundreds of research papers.\n\nSo I\u2019m starting a series of articles, where I describe the results of an experiment I\u2019ve been conducting for the last couple of months. Namely I have evaluated almost every tunable bit of a very simple neural network to see how the changes affect the resulting accuracy.\n\nSpecifically, in this series we will see:\n\nIn this series I will focus solely on a fully-connected neural network designed to classify handwritten digits from the famous MNIST dataset. The reasons for using MNIST are simple: it is well-balanced, so we can be sure that the test results are adequate; it is not too large, so we can train the models with various parameters combinations in a reasonable time, and it is built into all the major Deep Learning frameworks.\n\nFully-connected neural network architecture is probably the simplest one out there, and it is often the first one that is presented in books and courses on Deep Learning. Despite being simple, even this architecture has so many parameters and options to play with, that often people just leave everything at their default values, hoping that these values will result in acceptable performance.\n\nOf course there are much more appropriate ways to deal with MNIST, like using Convolutional Neural Networks. But here our task is not to beat the state-of-the-art model\u2019s score. Instead, we are focussing on the role of each parameter of our network in the resulting accuracy.\n\nThis is not an introductory tutorial, and the readers are expected to have at least basic understanding of neural networks, how they work, how to build and to train them. For building the network I will use Keras with TensorFlow backend.\n\nThe baseline code for our experiment will be taken from the Keras library\u2019s examples. We will be slightly modifying it over the course of this series to allow us to see how changes in its parts affect the accuracy on the test set.\n\nThe configurations will be evaluated based on the validation accuracy values, because it is the most objective metric in our case. Loss score does not provide much information, and accuracy on the training set is not representative because of the possible overfitting.\n\nEach configuration will be tested 5 times (i.e. 5 neural networks will be trained from scratch for each configuration) in order to reduce the influence of the inevitable randomness, and the resulting accuracy of training these configurations will then be averaged. This will help to ensure that we see more representative results.\n\nOur neural network will initially consist of two fully-connected layers with 64 units each, and one output layer with 10 units and softmax activation.\n\nThe first part of this series will discuss various techniques used to transform the data before feeding it into a neural network.\n\nMNIST dataset contains 60 000 training and 10 000 test images, each image is 28x28 pixels. Each pixel has a value between 0 and 255, where 0 represents completely black color, and 255 is white. In data science the data is usually scaled into small real numbers. The reason for this is to make the model to converge faster, and find a better minima.\n\nHere\u2019s how Geoffrey Hinton formulates this problem: \u201cwhen the error surface is a quadratic bowl\u201d \u2026 \u201cgoing downhill reduces the error, but the direction of steepest descent does not point at the minimum unless the ellipse is a circle. \u201c And here\u2019s how he visualizes this problem:\n\nThere are two approaches to transform the data before feeding it to a neural network, and make the error surface more even.\n\nOne is to transform the data so that all vector components are fit into the [0; 1] range. This is called normalization. Here we take the minimum values found across each component of our input vector, subtract them from the respective components, and then divide by the maximum values for each component.\n\nAnother approach is to make the data to have 0 mean and unit variance (equal to 1). It is achieved by computing the mean and standard deviation of each component, then subtracting the mean from each value of the component and dividing it by standard deviation of respective components. Sometimes this is also referred to as normalization, but here for the sake of clarity we will call it standardization.\n\nWhen dealing with MNIST we work with 28x28 images, and in order to be able to feed it into a fully-connected network, we first need to flatten them, i.e. transform each image into a 28x28 = 768-dimensional vector. In MNIST all components of this vector represent pixels, which can have values only from the 0 to 255 range.\n\nTherefore it may be natural to assume that each image should have at least one completely black and completely white pixels, and just work with global minimum and maximum, or mean and standard deviation values across the entire dataset. In reality each sample from the dataset may have its own statistics, so if you transform them using the global values, the dataset as a whole would have the desired statistics, but each individual sample would become shifted and scaled. To illustrate this let\u2019s look at the first 4 MNIST samples:\n\nIt is almost certain that each of these images have at least one completely black pixel (i.e. zero-valued). But it may not be the case for the value 255, representing the white color. Look at these samples:\n\nSurprisingly, these samples have no completely white pixels, therefore if you normalize them using the global min and max values, the value range of each of these images would become scaled in a different way, than for the samples, whose min and max values are equal to the global ones. It is not a big issue for our black and white images, human eye would not even notice such a change. But in other cases, like with colored images this may completely transform the image, therefore it is always a better approach to normalize each sample independently.\n\nThe same thing is with standardization. Intuitively we may understand that the distribution of various pixel values is different for each image, and standardizing them using the global mean and standard deviation values may incorrectly transform the samples and in the end lead to poorer performance of the model. We will check this assumption soon.\n\nNow let\u2019s look at the the plot of the normalized data distribution (it is nearly the same for dataset-wise and sample-wise normalization, so I\u2019ll present just the one for the first):\n\nThis histogram shows the counts of each discrete value in our data. From the histogram on the left we see that a large portion of the data are zeros. In fact, zero values constitute about 20% of all data points in our normalized data, i.e. 20% of pixels in our MNIST image data are black-colored. If we plot the data distribution without zeros, the next large group is ones, representing completely white pixels.\n\nThe statistics for the normalized data:\n\nThe histogram for dataset-wise standardized data is identical with the exception that the horizontal axis now has the range from -0.424 to 2.822.\n\nThe form of the data did not change, but it has been shifted and scaled. Now let\u2019s look at the statistics for dataset-wise standardized data:\n\nThe dataset is now standardazied as a whole (that weird numbed in the Mean for Dataset is essentially zero), but each sample has different means and variances. Also note that identity of the data distribution shape is confirmed by the same global skewness and kurtosis as for the normalized data.\n\nNow let\u2019s standardize each individual sample. This is the plot of the sample-wise standardized data:\n\nA significant difference. Now each sample is standardized, but the dataset as a whole is also standardized: the mean is so tiny, that we can count it as zero, and the variance is very close to 1.\n\nNow let\u2019s check, if these transformations really make the difference. We will train our simple neural networks using all four transformed datasets.\n\nThe example code initially uses RMSProp optimizer and ReLU activation, so we will be using these in our first experiment. We will compare the results of training the same configuration of a neural network on each of the four data transformation types: Normalized dataset- and sample-wise, and Standardized dataset- and sample-wise.\n\nThey will be compared by the following measures:\n\nNote: for calculating the averaged maximum accuracy in this and further experiments instead of finding the maxima for each of the 5 experiments for a particular configuration and then dividing them by five, I am averaging the whole process of training, i.e. for step N I take accuracy observed in each of the five experiments at step N and then average them. This way I calculate the averaged training progress and take it\u2019s maximum accuracy. I believe, this approach betters represents the typical training results you would get with a particular configuration.\n\nIt is clear that on our network configuration normalized data demonstrates better results, than the standardized one. From these results it is not possible to tell, whether dataset-wise normalization is better than the sample-wise one, but it may be only because of the specifics of our dataset. Most probably with other datasets you will be getting higher results with sample-wise normalization.\n\nAs for standardization, we have confirmed that it was wrong to use the global values to standardize our training data. However, the fact that sample-wise standardization resulted in lower accuracy in our experiment doesn\u2019t mean that this is always the case. In the later parts we will see that in some particular neural network configurations sample-wise standardization may lead to much higher results than with normalized data.\n\nBelow are the plots showing the accuracy change over the course of training on four types of data:\n\nThe dotted lines represent individual experiments and the black lines is the averaged accuracy across these experiments. Here are all four averages compared:\n\nAgain, networks trained on normalized data follow each other very closely, and sample-wise standardized training goes just slightly worse, but not as bad as for the dataset-wise standardization. Also, note that for the standardized data the training is a bit less stable, i.e. it has larger changes of accuracy, both up and down as the training progresses. Partially this can be solved by adapting the learning rate, and we will try it in one of the next parts.\n\nThe learning points from the first part:\n\nThe code for the experiment is available on my github. In the next part we will investigate activation functions, which are the bits of a neural network that transform your prepared input data into outputs. Stay tuned!\n\nI\u2019m always happy to meet new people and share ideas, so if you liked the article, cosider adding me on LinkedIn."
    },
    {
        "url": "https://medium.com/@maksutov.rn/thinking-of-predicting-stock-market-prices-im-here-to-help-with-my-indicators-library-for-python-60e9d5ba1509?source=user_profile---------4----------------",
        "title": "Thinking of predicting Stock Market Prices? I\u2019m here to help with my Indicators Library for Python",
        "text": "One of my colleagues once said, that the first thing that comes to mind for most people who realize that Artificial Neural Networks can be trained to predict some things, is \u201cHey! Let\u2019s predict stock market prices and get rich!\u201d He said this after I told him I\u2019ve signed up for the Udacity\u2019s Deep Learning Foundations course, and am planning to develop a model that does exactly that: tries to predict the stock prices.\n\nI\u2019ve spend several months developing the model, testing various network configurations, spent tons of money on AWS instances, and haven\u2019t moved further than 60\u201370% accuracy on just predicting directions for the next day, let alone the actual movement value. It has been a great experience, although I realized that with the computing resources available to me this task is practically impossible to solve.\n\nI will do a big post on this experience one day (and there are plenty of similar ones already, like this series by Alex Honchar), but today I want to share with you a by-product of this exercise: a Python library, which implements the most common stock market indicators.\n\nIn the vast majority of articles and tutorials on using Deep Learning for stock market prediction, only the OHLC values are used (which stand for Open, High, Low, Close), sometimes Volume is also taken into account. But the trading industry has quite a long history, and over this history, a wide range of derivative indicators have been developed, which are heavily used by traders and analysts.\n\nMy suggestion was that such indicators may greatly improve the accuracy of predictions by providing additional hints and patterns for the neural network. As it turned out, they actually were helpful, and in my case the accuracy increase was about 10% compared to just the OHLCV data.\n\nI didn\u2019t have time so far to open-source my entire project, make it human-readable and remove experimental and redundant code, but I can share the library, which implements 22 most common stock market indicators. Surprisingly, I couldn\u2019t find anything similar at the time I was working on my project, so I had to implement them by myself.\n\nHere\u2019s the list of the implemented indicators:\n\nIt is small, simple to use, and relatively fast. There is some space for improvement, like you may wish to re-write the functions so that they return not the copy of the original DataFrame with a few new columns added, but only the required columns, or there may be some places where the calculations can be simplified using Pandas\u2019 and NumPy\u2019s tricks, but I\u2019ll leave it up to those who will be using this library as a starting point.\n\nThe code is on GitHub, feel free to use, fork and develop it further."
    },
    {
        "url": "https://medium.com/@maksutov.rn/rebus-inside-out-my-first-android-game-published-b24b5df85b3c?source=user_profile---------5----------------",
        "title": "Rebus inside out \u2014 my first Android game published \u2013 Rinat Maksutov \u2013",
        "text": "For the last couple of months my blog has been abandoned. This happens when someone becomes so excited about his idea, that he forgets about everything, and devotes all the spare time he has to developing this idea. Which exactly what has happened to me.\n\nI love puzzles. This is the only type of games I play on my mobile phone. Last year I came across a very good puzzle game, which took away a couple of weeks of my life: REBUS \u2014 Absurd Logic Game. And recently I thought, what if I inverse the idea, and instead of finding out the word encoded in a picture, try encode that word using the set of given pictures.\n\nDeveloping a quick prototype took about a week, and when I showed it to my wife, she found it playable. So I decided to move on and develop a complete game.\n\nThere is a picture, representing some word. You have to guess this word, and then construct it, using other pictures given below. Of course, most of times you need only certain parts of these words, so you have to remove some letters from the front or the back of these words. Like this:\n\nFor each correctly composed word you get some coins. Initially, the number of coins equals to the number of letter the target word has. Each time you remove a letter, while composing the target word, the number of coins is decreased by 1. The aim is to find out the word while removing as fewer letters as possible.\n\nThe puzzles are composed in such way that there is always one best solution (which gives you at least one coin after solving it), and there are other not-so-bad solutions (which give less or even no coins).\n\nCoins can be used to get various types of hints, like revealing the target word, or the word options, or they can be used to unlock new puzzles. Initially, only 10 out of 250+ puzzles are available, and each time you solve one, a new one is unlocked.\n\nThe player can purchase additional coins using in-app purchases, and Google provides a very easy way of integrating such a feature into your app.\n\nAndroid. Just because I\u2019ve already had some experience developing Android apps and recently completed a few Android Development courses, I decided to make it the primary platform. The iOS version will follow, if the Android gets even slightly successful, meaning that it gets at least 1000 downloads by the end of 2017.\n\nProbably, this was the most time-consuming part. Constructing puzzles manually would take weeks and would have been error-prone. So I decided to automate this task.\n\nI downloaded a file containing 1000 most popular English nouns. This dictionary was fed into a Python script, which I developed.\n\nOn the first iteration the script creates all possible splits of each word; each split containing word parts with at least 2 letters, like this: \u201cmassage\u201d = [[\u201cma\u201d, \u201css\u201d, \u201cage\u201d], [\u201cmas\u201d, \u201csa\u201d, \u201cge\u201d], [\u201cmass\u201d, \u201cage\u201d], [\u201cmassa\u201d, \u201cge\u201d], [\u201cmas\u201d, \u201csage\u201d], [\u201cmassa\u201d, \u201cge\u201d]].\n\nOne the second iteration the script looks at each word, and for each split it finds the full words, from which each word part of the given word can be obtained by removing letters either from the front or the back. For each word part there can be many full words, from which it can be obtained, so the script keeps track of how many letters have to be removed from the full word to get the required part \u2014 the cost of that word.\n\nThen it sums up the costs for each combination of full words that construct the target word, and drops those, whose costs are equal or higher than the number of letters in the target word. The combination of words, which has the lowest cost becomes the best possible solution. Limiting the cost of the best solution to the target [word length \u2014 1] ensures that the player receives at least one coin for successfully solving the puzzle using the best solution.\n\nAfter running the script on the entire dictionary, something like 400 questions have been generated. These questions then have been manually checked. Many puzzles had similar word options, because, for example, if there are many target words containing the part \u201cid\u201d, and the shortest word option in your dictionary, which contains this part is \u201cidea\u201d, of course the script will suggest this word for almost all of such puzzles. So these had to be manually substituted to a different word options. Often, this led to increasing the cost of the best solution, but gave a greater variety of word options.\n\nThe resulting set of puzzles has been saved into an XML file, and imported into the Android project. The app would then parse this file, and use it to display the puzzles.\n\nTricky part. Android runs on a vast range of devices, each with different screen size and resolution. There are literally thousands of possible combinations of these, and it is impractical to try to create images that suit the majority of them. So the solution was to use vector icons in SVG format. Android Studio can import this format, so that there is only one resource for all screen sizes and densities. Also, this greatly reduces the size of the app, because often, vector images take less space than raster ones.\n\nI still had to create different variations of the main puzzle screen, where the lower part of the screen that contains the buttons has been rearranged for better utilization of the available space on larger screens. However, this was just one such place in the app, and all the rest of layouts are completely identical for small, medium and large screens.\n\nSurprisingly, this was the easiest part. There is a singleton, which keeps track of the score, provides the puzzle data, decides, whether the player has solved it or not, and saves the progress to a small internal database. The rest is quite straightforward, so I won\u2019t describe it in too much details.\n\nThe game is now available on Google Play, and it is free. Now I\u2019m trying to figure out how to cheaply promote it so that I get the desired 1000 downloads by the end of this year. Social media has been utilized, but this did not result in too many installs. I\u2019ve sent review requests to a few dozens of Android gaming websites, and still waiting for responses. I even tried to run an AdWords campaign, which brought me about 50 installs for the $15 spent. Still, 1000 installs is quite far away. Probably, a larger promotion budget would have given me the required numbers, but unfortunately I don\u2019t have a spare penny at the moment to spend it on promotion.\n\nAll in all, this was a good exercise, which gave me the opportunity to get some experience in all stages of an app development, starting from the concept, to prototype, to the complete app, and to promotion. It would be nice to do the same for the iOS version, especially, if the app also brings some money."
    },
    {
        "url": "https://medium.com/@maksutov.rn/concept-of-the-week-net-salary-calculator-for-those-thinking-of-relocation-63c998c7c566?source=user_profile---------6----------------",
        "title": "Concept of the Week: Net salary calculator for those thinking of relocation",
        "text": "Last winter, after about 3 years of working for my current employer, I decided that it\u2019s time to, as they say, \u201ctake a new challenge\u201d. And because sometimes I\u2019m a bit lazy, and sometimes a bit na\u00efve, I thought that it would be nice to transfer to the Berlin office of my employer\u2019s subsidiary, so that technically I would still work for the same company. This would be easy and fun, I thought, and applied there to a position strangely called a \u201cCreative Technologist\u201d. Which, as it turned out after a couple of interviews, is sort of \u201ca web and mobile developer with some idea-generation skills\u201d.\n\nIn order to demonstrate my (somewhat average, to be honest) skills in both web development and idea generation, I decided that it would be nice to set up a small web app and launch it live. So I did it. First of all, I thought, the app should be very simple. Two screens/pages max. Why? Because this is how much I can do with best quality within 3 days before the interview, having the current full-time job. Second, the topic of the app should be practical, but not too common.\n\nBefore applying to the Berlin office, there were many other places I was considering: UK, Canada, the Netherlands, Sweden, Italy and even New Zealand. And in order the see, how much money I will need per month for my particular situation, I was using numbeo.com. For estimating the salary I was using glassdoor.com, which, considering the vast number of employees my current employer had around the world, was quite accurate. However, when looking at these numbers, one has to keep in mind, that these are gross salaries, and you still have to deduct the personal income tax. Which, depending on the country, may vary in wide range of rates. The problem was to quickly find these rates and, using sometimes quite a complex rules, estimate the net salary.\n\nA quick googling gave me no one-stop solution. I had to use separate, sometimes outdated services to find the right rates and rules. \u201cAha\u201d, I thought, \u201cthis may be a good exercise\u201d. I wasn\u2019t aiming to cover lots of countries of course, because that would take weeks or event months of work. But implementing it for a few countries, which have flat or not-so-complex tax rate formulas, would be a good demo of the entire concept. So I started working on it.\n\nUsing the app is straightforward:\n\nOn the main page you pick the country you\u2019re interested in. Let it be Canada, for example:\n\nSelect some additional details (if the rates depend on particular circumstances), like province in Canada:\n\nEnter the gross monthly amount and get the net amount on-the fly:\n\nThere are a few notable points about this web app:\n\nUnfortunately for me, this plan didn\u2019t work. Most probably, because I\u2019m not a professional developer, and apart from a few toy projects on GitHub, I\u2019ve got nothing to demonstrate \u2014 most of my career I spent developing business and technical requirements and solution architectures. However, I find that the concept that I developed for this endeavor might be quite useful, and some of you may want to take it further and turn into a fully-featured product.\n\nYes, there are some competitors on the internet, but like I said earlier, some of them are outdated, some are dedicated to a particular country, and some are just not user-friendly.\n\nYou may find the demo of the app at http://netsalary-in.herokuapp.com/ and the source code on my GitHub. Feel free to fork it, and if you manage to make something good out of it, let me know."
    },
    {
        "url": "https://medium.com/@maksutov.rn/how-to-promote-an-android-app-that-no-one-actually-needs-part-1-begging-for-reviews-f681e7abaa4b?source=user_profile---------7----------------",
        "title": "How to promote an Android app that no one actually needs \u2014 Part 1: Begging for reviews",
        "text": "You reached this moment when you generate a signed APK, upload it to the Play Store, fill all that description and screenshot stuff, and hit \u2018Publish\u2019. And then comes that thrilling feeling\u2026 How many people will have downloaded it?\n\nJust to get rid of that disappointing zero in the dashboard stats you download it via the Play Store to your own Android device. The next day, there is 1.\n\nYou turn on to Twitter in the hope that someone from your tiny followers pool will find the app worth the downloading hassle, or at least do some retweets, like this:\n\nOh, what\u2019s that? There\u2019s 2 now! You and some other guy! However, now you see another disappointing number, 1/2, which means that this guy has uninstalled it right after first interaction with your app. Too bad. You wait another week or so, but nothing really happens. Your download stats look something like this:\n\nThis was my situation after I uploaded my very first app to Google Play Store (here\u2019s the link, by the way). The app was developed while going through one of the Android Development courses on Udemy, just to refresh my Android skills, and I wasn\u2019t planning to monetize it in any way. However, just to make the numbers look better, I decided that my app needs some promotion. In a month I want to get, let\u2019s just randomly say, 1000 active users. Is it feasible if you don\u2019t plan to spend a penny on promotion? Let\u2019s see!\n\nBy the way, in a few days after you submit you app to the store, you will be contacted by several companies offering you to promote your app and get some positive reviews using their services. If you have some spare money to spend on these, you may want to try them.\n\nFirst thing, asking Google: \u201chow to promote an android app for free\u201d. Besides the ads of the services, which offer you to \u201creach millions of mobile users\u201d, there will be hundreds of pages written by random people with \u201cXX creative ways to promote your app for free\u201d.\n\nDespite being pessimistic about the specialized services, in terms that they will all probably ask you for money upfront, let\u2019s test what came out on the ads first. I got five of them: Appnext, AppBrain, StartApp, AppLift and Tappx.\n\nSo, what do we have here?\n\nSigned up, added an app. Now on to creating a campaign\u2026 and they ask me how much I\u2019d like to spend per day. I do not want to spend anything, so skipping this option.\n\nSinging up, then trying to add my app\u2026 Wait, what\u2019s that? They have already listed it in their database! Cool! No need to add it manually. Now going to dashboard and creating a campaign\u2026 And again, asking me for money.\n\nTheir landing page says that if I deposit $50, I will get another $50 credit. So just skipping them too.\n\nSigned up\u2026 And they told me to wait until they contact me. Disappointing. (Edit: there have been 7 days since I signed up, and still nothing from them. Wonderful service!)\n\nEasy signup and adding of the app. There is an option to promote the app for free using cross-promotion, which means that you have to display a banner promoting some other apps, and the banner of your app will be displayed in exchange. It may be the way for someone who does not object to display banners, but I do not want to do this (ok, I\u2019m missing an opportunity here, but I personally find displaying banners in such a small app quite unfair towards my users).\n\nAlright, specialized services are not an option for me. So moving on to the zillions of creative ways.\n\nBasically, if you compile what these guys are telling you, it comes down to the following things:\n\nSo, to sum up, the feasible thing to do would be to submit my app to as many app review resources, as I can, and wait for the results.\n\nI have found several lists of the websites, where you can submit your app for review. Many of them are free, some require paying for reviewing, some specialize on particular platforms, and some are just abandoned. Therefore I took a 5-day pause and manually complied a list of exactly 100 sites (out of around 300), where you can submit your app. The full list is available on this page. It\u2019s funny that this magic number was just a coincidence, I didn\u2019t plan to make it to look round.\n\nFrom this list we are selecting only those which accept Android apps, and, because we are poor, those which offer a free review. All of them say that they do not guarantee that the app will be reviewed, because they receive millions of free review requests per day, but we\u2019ll try.\n\nSo, we start going through the list and begging for reviews. In total, I\u2019ve submitted the app to 25 app reviewing resources, providing them with the basic info, such as app name, the link to Play Store, app description, etc. Some may feel uncomfortable asking random people to do some unpaid job, but hey, this is what they offered to do themselves.\n\nAfter I\u2019ve completed this job, I found that there are other sites, where you can showcase your app, which fall into several categories:\n\nSo while I\u2019m waiting for the first reviews to appear (if there will be any), I decided to spend some time submitting my app to these:\n\nIn total, if I exclude the time required for finding these resources, it took me about a day to submit my app to all the websites. I guess, it\u2019s not too much for an app, which you are not planning to monetize. In the next post, which will come in a month, we will analyze the outcome of our experiment, and see, if these efforts have brought us any significant results. Stay tuned!"
    },
    {
        "url": "https://towardsdatascience.com/concept-of-the-week-let-artificial-intelligence-tell-you-how-good-is-your-look-7dedd324d1d8?source=user_profile---------8----------------",
        "title": "Concept of the Week: Let Artificial Intelligence tell you how good is your look",
        "text": "This is a series of articles presenting the ideas (some may be stupid) of apps and products I come up with. Sometimes I will provide the basic source code, and sometimes there will be just description and simple mockups. In any case, you are free to implement these ideas into a complete product, but don\u2019t forget to tell me that you did :).\n\nI am terrible at picking the right clothes. Every time I do shopping on my own, I end up buying idiotic-looking stuff and never wear them again. Or wear them only when I need to pop into the local groceries to make it look like \u201cI just quickly took on the first thing I found in my closet\u201d. There are of course hordes of salespeople who are trying to help me, but, as the help is rarely useful, I guess, they are just trying to sell me whatever is more expensive and less popular.\n\nThis is why I always try to have my wife to buy clothing for me. And even though we sometimes argue about whether this shirt is OK to take on when I\u2019m going to a meeting, almost 99% of time she\u2019s right \u2014 that patchy shirt will make me look like I\u2019m a geeky student among the million-dollar-making Wall Street lions in gray suits and light blue shirts with shiny red ties.\n\nMany of the people out there don\u2019t have such a person nearby like my wife. So for such style-blind single people, here\u2019s the idea I\u2019m giving away. A mobile app with a neural network in the back-end, that will tell you if your new look is good or bad. There may be just 2 categories (OK / not OK), or a 5- or 10-star rating, or anything else you think the audience will accept.\n\nThe basic flow is that you:\n\nI don\u2019t know, whether this girl actually looks awesome, because, as I was saying, I\u2019m bad at this.\n\nProbably, this is what would have happened if I were to take the picture of the kind of person like me:\n\nThen goes all that usual share-on-instagram-and-get-million-likes stuff, if the user gets the 5. And, probably nothing will be shared, if she scored lower, because no one likes sharing bad pictures on Instagram.\n\nThe app itself is straightforward. The screen for signing in with your Instagram account, the camera screen and the results screen. Can be implemented on both iOS and Android in a day.\n\nThe back-end would require setting up a simple API server, which would pass the data to the \u2018brain\u2019. The \u2018brain\u2019 could be a TensorFlow Serving or whatever you are familiar with.\n\nI do believe that something similar is already there. The idea is simple, and there is nothing in it that has not been done before.\n\nThere are a couple of obstacles, though.\n\nOne thing that might be a problem here is obtaining the training set. If you decide to implement it, you would need thousands or even tens of thousands of examples for the initial training of the neural network. The size of the training data set highly depends on the scale you would use to grade the image. If there are only good/bad categories, then you need less. If you think users would want something more granular, like 5- or 10-grades rating, then the number of training examples should be increased accordingly.\n\nAnd of course there should be some sort of feedback on how well the model classified the image. One way to do it would be for the model to look after a certain time on the likes-to-users ratio for each picture taken, i.e. how many likes the shared photo got out of total followers number. For example, if the user has 100 followers, and only 1 liked the 4-starred photo, then the algorithm was wrong, and it should have been 1-starred. There are some obvious disadvantages in this approach, but it may be a good starting point.\n\nThe second problem is, to teach the neural network one would need to rate pictures yourself initially. That means this should be a developer with an exceptional taste, feeling of style and knowledge of the latest fashions. Not that I\u2019ve ever met such a unique species of human. It would probably be right to find a designer to cooperate with. Which would still be difficult, because she or he would need to have a galactic-sized level of patience, considering the number of pictures he or she has to rate.\n\nAnd there is the last problem with this app for a person like me. While shopping, whenever I\u2019m in a difficult situation I don\u2019t usually think, \u201cOh, is there an app for this?\u201d So every time I\u2019m in a shopping centre, I should be able to somehow be reminded that I have this app on my phone. That means I will need another app, which will do exactly that \u2014 and this may be the concept of the next week."
    },
    {
        "url": "https://medium.com/@maksutov.rn/sci-hub-is-blocked-in-russia-founder-says-shes-been-bullied-by-scientists-b482aa76037?source=user_profile---------9----------------",
        "title": "Sci-Hub is blocked in Russia; Founder says she\u2019s been bullied by scientists",
        "text": "Just yesterday I was excited to tell you about CyberLeninka, a large open database of scientific papers, which was backed by a local investor. Today I am sorry to state that Sci-Hub, a very popular archive of illegally downloaded scientific papers, has been banned in Russia.\n\nProject founder, Aleksandra Elbakyan, says that she has been bullied by some Russian scientists for the work that she has been doing. One of them even named a recently discovered insect after Alexandra: Idiogramma elbakyanae. She perceived this as another way of harassing her, though one might see this as honor to get her name cemented forever in science. \u201cTo consider this as insulting, means to completely miss the actual meaning of this act\u201d, says Andrey Khalaim, the author of the paper.\n\nRussian users now see this long message from Aleksandra:\n\nThe situation here is not that straightforward, I think. On the one hand, of course, Sci-Hub was illegal in terms that it provided copyrighted materials for free. It is never OK to steal something, and we\u2019ve been through it with music, movies and software back in early 2000's.\n\nOn the other hand, as some commentators say, science in Russia is funded by the government, so it is public money, and therefore access to scientific advancements should also be public. Secondly, as far as I know, not so many universities in Russia are funded enough to afford all the necessary official subscriptions. Therefore many Russian scientists have been using Sci-Hub as the only way to keep up with the international advancements, and it is now unclear, what they will do without it. One can overcome the blocks of course, but the tools that allow you to do that are going to be illegal in Russia in the nearest future. Many Russian researchers hope that Aleskandra will change her mind and will open the access for the Russian users again.\n\nLastly, the most notable part here is that out of 200 000 daily downloads on Sci-Hub, the majority of them were from the USA, Europe and China. Maybe that\u2019s why, oddly enough, one of the most expensive scientific journals \u2014 Nature \u2014 has even included her name in the list of \u201cTen people who mattered this year\u201d."
    },
    {
        "url": "https://medium.com/@maksutov.rn/russian-open-database-of-scientific-papers-get-500k-investment-4f169dbc0f4?source=user_profile---------10----------------",
        "title": "Russian open database of scientific papers get $500k investment",
        "text": "Good news this week! The Russian open database of scientific texts has just received a $500k investment for a 25% stake.\n\nBeing a local equivalent to Google Scholar, CyberLeninka offers access to more than a million articles in more than a thousand peer-reviewed journals. Of course, the majority of them are in Russian, but I guess, they do have a plan of somehow internationalizing it, because this round of funding has only been the first one. As the source says, they are actively working with international investors and probably prepare for launching on the international market.\n\nCyberLeninka uses the name of the largest Russian \u2018brick-and-mortar\u2019 library named after Vladimir Lenin (people just call it Leninka). It was established in 2012 by Dmitry Semyachkin, Evgeniy Kislyak and Mikhail Sergeyev. On average, it has 3 million monthly visitors, with an annual figure of 22 million.\n\nAs the founders say, they don\u2019t plan to introduce paid access, the content will remain free for all. This is because the license of the journals, which are indexed by CyberLeninka, allows free distribution. Instead, they are working on commercial services for publishers, scientists and the government.\n\nSo Russia\u2019s contribution to the global science community is going to grow substantially in the nearest future, and that\u2019s not because President Putin said that Russia will do it, but thanks to people like Dmitry, Evgeniy and Mikhail."
    },
    {
        "url": "https://becominghuman.ai/what-putin-actually-said-about-ai-tl-dr-nothing-meaningful-5531fb768caf?source=user_profile---------11----------------",
        "title": "What Putin actually said about AI. TL;DR: Nothing meaningful.",
        "text": "President Putin\u2019s meeting with students, otherwise quite boring, caused a global tech media fever. And that\u2019s just because some schoolboy from Ulan-Ude, the capital of Buryatiya region, mentioned the term \u2018Artificial Intelligence\u2019 while telling the President about his personal side-project (source, word-by-word translation):\n\nThe scary NBICS word here stands for \u201cNano-, Bio-, Info-, Cognitive- and Socio-\u201c, and is just an official Russian term for saying \u201call that trendy tech stuff\u201d.\n\nThe President\u2019s answer was short. So short, in fact, that one just can\u2019t say that the President has put much thought or meaning into it.\n\nMoreover, this was just a tiny bit of the 30+ minutes conversation, which actually wasn\u2019t about AI at all. It was about all modern technologies, and was developing like:\n\nSo the question is why the global media had put so much stress on the AI part. And moreover, why they started the usual AI-will-cause-WW3 stuff. Putin said that Russia is ready to share their technology. Not that they will open-source it on GitHub, apparently, but I guess by publishing the research papers just the same way other guys from the US, Canada and China do. If this thing had been said by, say, the Prime Minister of Iceland, no one would have ever noticed. But this came from the mouth of the Russian President, and everyone now thinks that he is planning to develop a Russian Skynet. Or at least a single Terminator.\n\nAnd my advice for Elon Musk (who am I to give him advice, but nevertheless): please come to visit Putin and make him join your OpenAI on the governmental level. I think, given your opinion on how strong computer science in Russia is, this will benefit both parties."
    }
]