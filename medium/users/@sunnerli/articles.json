[
    {
        "url": "https://medium.com/@sunnerli/pursue-to-experience-the-touching-in-jay-chous-world-5689143371e8?source=user_profile---------1----------------",
        "title": "Pursue to Experience the Touching in Jay-Chou's World",
        "text": "In the end of March 2017, there\u2019s a classical model purposed which called Cycle-Consistent Adversarial Networks (CycleGAN)[2]. This project got thousands of stars on GitHub pages in the short time. The most creative idea is that it can reach unpaired training image. For example, you cannot find two horse and zebra doing the same action in the same environment and background. However, we can reach horse-zebra transformation by CycleGAN. This model can also achieve some others tasks, including image to photo and summer to winter which is shown in Figure 3.\n\nThe training path of CycleGAN is shown in Figure 4. In our application scenario, we can split the image as two image space: real-image space (real space) and waiting-for-you space (wait space). In the whole structure, there\u2019re four components: wait-to-real generator, real discriminator, real-to-wait generator and wait discriminator. The corresponding generator will transfer the input image to the target image domain.\n\nThere\u2019re two paths in this topology. In the first path, the waiting image will be transferred by wait-to-real generator firstly. Then the real discriminator will judge if the transfer result is at real image domain or not. Next, this image will be transferred back into waiting space by real-to-wait generator, and the result is called reconstructed image. At last, we can compute the lasso loss (l1 loss) between original image and reconstructed image.\n\nThe other path in this topology is the reversed direction which opposed to the first path. The real image will be transferred by real-to-wait generator, then judge if it\u2019s at wait image domain or not by wait discriminator. Next, the generated image will be transferred back by wait-to-real generator, and compare the l1 loss at the end.\n\nThere\u2019s another key issue. To make the generated image keep the original color tone, the author also included the identity mapping loss. The idea of identity mapping loss is that the image will keep the same structure and intensity by generator whose target image space is as the same as the input\u2019s. The idea of identity mapping loss is shown in Figure 5. By adding this l1 loss, the generator can ensure the identity mapping between the same image domain."
    },
    {
        "url": "https://medium.com/@sunnerli/the-story-about-wgan-784be5acd84c?source=user_profile---------2----------------",
        "title": "The story about WGAN \u2013 Sunner Li \u2013",
        "text": "However, Martin et al. claimed[1] that the optimal discriminator is the main problem, and it leads the instable in usual GAN. The Figure 5 shows the loss function of usual GAN. We can just put the optimal discriminator into the loss function, and see what\u2019s the result under this situation. To be notice, the JS-divergence is another metric which measures the distance between the both distributions and the average distribution.\n\nSo we can get the new message: unlike shrinking the KL-divergence in VAE case, the GAN reduces the JS-divergence respectively. As the result, if we keep training the discriminator, the value of loss will become 0, and the JS-divergence will keep in .\n\nHowever, this great result is based on the assumption: If the distribution is continuous, then we can get the gradient respectively. Is this assumption built anywhere?\n\nIn the general case, the both distributions have full dimension toward the union space which means the data may spread averagely in the data space. Take Figure 7 as example, if the generative data and real data are both gaussian-like distributions, then reducing the JS-divergence is to reduce the distance between these two gaussian. If the two distributions are close, then the generator can generate the data which are just like getting from real data distribution.\n\nHowever, the fact is that the data don\u2019t distribute correctly in the union space. Simplify to say, the two distributions may not have intersection. There\u2019s one guessing which was written in paper:\n\nThe paper splits as two cases to discuss. The first one is: the two distributions are perfectly-aligned. Take the Figure 8 as example, we assume that the vertical axis is called . In the example, the set distributes in the plane which is over than the . However, the set is laid on . By Urysohn\u2019s smooth lemma, we definitely can find the optimal discriminator that can distinguish the two distributions.\n\nIn fact, the probability that the two distributions are perfectly-aligned is small. As the result, the author discussed about another case: If the two distributions have sub-manifold which has transversallity toward each other, then the dimension of this perturbation is much lower than the dimension of the both data distributions. Moreover, we still can find the optimal discriminator!\n\nThe Figure 9 illustrates this case. For example, if the distribution of real data is just like the yellow plane, and the generative distribution is just like the green plane. The orange region is overlapping if we project our sight to the white background. Actually, they didn\u2019t overlap in this area. The only region of the transversallity is a single line!\n\nGeneral to say, the function of the generator is to project the random vector to the image feature space. However, the dimension of manifold isn\u2019t change. Take the Figure 10 for example, we assume the dimension of noise vector is 2, and the dimension of feature space is 3. By generator, the noise distribution can be projected to the position of orange line. However, although the data point are located in 3-dimensional space, the dimension of orange line (manifold) still remains 2.\n\nBy this simple example, the fact I want to show is: even though the generator can project the data point to the high dimensional space, the dimension of actual manifold isn\u2019t change. As the result, it doesn\u2019t increase the probability that the two distributions can have large transversallity."
    },
    {
        "url": "https://medium.com/@sunnerli/simple-introduction-about-hourglass-like-model-11ee7c30138?source=user_profile---------3----------------",
        "title": "Simple Introduction about Hourglass-like Model \u2013 Sunner Li \u2013",
        "text": "How to deal with this problem? The first straight forward sight is: bring each pixel into network and predict one by one! However, it\u2019s not a practical method. Since the category of the pixel isn\u2019t just determined by the intensity. The relation between the neighbor may be the influence toward the result. Another idea is: why can we just revise the original CNN structure? As the result, FCN was born.\n\nObject segmentation is another kinds of popular problem. Unlike the object recognition, we should recognize the object into pixel-level. In the previous object recognition task, we can just use bounding box to post the region of interesting. The point we care is just the location of the object, and we don\u2019t really care about the edge (or shape) of the object. However, we should consider pixel-by-pixel to check if it\u2019s belong to object or not. Rather than object recognition, object segmentation is a more hard problem.\n\nThe original name of FCN is fully convolutional network[1]. For original structure, the last layer of CNN may be a softmax layer to predict the probability of the category. However, there\u2019s only one result can be produced. As the result, Long et al. try to treated the model with another concept: the fully connected layer in usual structure can be regard as a convolution layer whose kernel size is the size of whole feature map! Is there possible to predict the category of each pixel just by convolution?\n\nThe answer is yes. In FCN, the image will be processed through the network. The \u201ccourse\u201d feature response map will be produced at the end. This feature response map some how represents the category of original image in pixel level. However, the size is shrink to 1/32 times. To reconstruct as original image size, the first idea is bi-linear interpolation. However, it\u2019s not suitable to adapt in the realistic situation.\n\nAnother idea is , and it\u2019s more reasonable to learn how to deal with this problem case by case. In the upsampling process of FCN, the course feature map will be operated by a learnable up-sampling layer. Next, the element-wise addition will be adopt to the feature map. By the previous feature map, the result can realize more location and detail information which are destroyed by max pooling layer.\n\nThe author purposed the three kinds of result: FCN-32s, FCN-16s and FCN-8s. The meaning of the back number is the times of shrinking. For example, the result of FCN-32s is 1/32 than the original image. On the contrary, the result of FCN-8s gets through two learnable up-sampling layers and element-wise additions.\n\nIn the author\u2019s experiment, we can see that the performance of FCN-8s is the most brilliant. As you can see, the detail margin of human and bicycle is more clear than the two other result. Moreover, as the author mentioned, the performance of FCN-4s and FCN-2s aren\u2019t well than the FCN-8s. Thus it\u2019s not certain that the more fusion will lead to more high accuracy."
    },
    {
        "url": "https://medium.com/@sunnerli/an-interesting-idea-toward-cnn-residual-4bb54040b9a?source=user_profile---------4----------------",
        "title": "An Interesting Idea toward CNN \u2014 Residual \u2013 Sunner Li \u2013",
        "text": "The whole name of ResNet is \u201cresidual network\u201d. During the years experiment, Kaiming He [1] observed a phenomenon: In theory, the deeper the network it is, the more accurate the result is shown. However, when he added more layers into traditional CNN model, the training error and testing error were both increasing! The result can be shown in the following statistic.\n\nHe gave a guessing about this result: It might not be the over-fitting. On the contrary, it\u2019s the disadvantage of the deep network. Once you add the more layers, they cannot learn very well through the whole parameters. He also gave the name to this result: degradation problem. After this experiment, the residual network was created.\n\nA fundamental question is: what is residual? In machine learning concept, we want to learn the hypotheses such that is similar to the target function . The is just like the identity mapping from the feature domain to the target domain, and it can be shown at the left side of the above image.\n\nHowever, the residual is different. In residual network, the model wants to learn the hypothesis such that is similar to the difference between the target function and the input . On the other word, we want to find the hypothesis which follows the format: . The is just like the difference between the feature domain to the target domain."
    },
    {
        "url": "https://medium.com/@sunnerli/visual-attention-in-deep-learning-77653f611855?source=user_profile---------5----------------",
        "title": "Visual Attention in Deep Learning \u2013 Sunner Li \u2013",
        "text": "In the computation of convolution layer, the kernel filter will use sliding window mechanism that work on the whole feature map. Respective field and shared weights are the two advantages of the CNN. However, the slow speed of sliding window is the major disadvantage.\n\nThe Deepmind company tried to describe the action about how the human see toward the front object. Take the following picture for example. what is the process that you know there\u2019s a dog in the picture?\n\nIn the original CNN program, the kernel will try to realize from the top-right corner, and slide to the most right position. If the kernel sees the dog in the middle of the image, it will keeps sliding the field to the most right as usual. However, did you realize the dog by such these process?\n\nI think the answer is not. For the usual person, after he realizes the head of the dog, he might try to watch the body part or the tail part rather than seeing right white floor. On the other words, the human will try to determine where to see in the next period instead of watching the other parts.\n\nDeepMind gives this hobby a creative name: attention. They tried to stimulate the human that the people will pay attention to the object which they\u2019re focus on. As the result, recurrent attention model (RAM) had been launched[1]."
    },
    {
        "url": "https://medium.com/@sunnerli/predict-the-type-in-pokemen-go-world-450be8c05529?source=user_profile---------6----------------",
        "title": "Predict The Type in Pokemon GO World! \u2013 Sunner Li \u2013",
        "text": "I use sklearn random forest object to complete the work. However, there\u2019s a critical problem. The tag of each row can just accept one class. For example, Pikachu has only one type \u2014 electronic. However, Bulbasaur has two types: grass and poison. How to deal with this situation?\n\nI split as the two rows. In this strategy, each pokemon has only 1 class, but there\u2019re more data that will be generated. The format of the data can be shown below. As the result, one type of pokemon might occupy two rows if it has two different type of classes.\n\nTo reformat the data table, function of pandas is useful! The parameter accept the list which will not be reshape. On the contrary, the whole other attribute will be reformat. The usage is shown below.\n\nOn the other hand, the problem doesn\u2019t happen in the DNN structure. Since the output can accept for multiple types. For this tricky method, the common soft-max estimation isn\u2019t adopted in this approach. I use sigmoid function to approximate the multiple one-hot vector output."
    },
    {
        "url": "https://medium.com/@sunnerli/normalize-before-training-872858e332a1?source=user_profile---------7----------------",
        "title": "Normalize before Training \u2013 Sunner Li \u2013",
        "text": "In the previous article, I normalize the training data manually. However, after I check some kernels on Kaggle, some interesting method can be learned. This article records the methods.\n\nNow we want to predict if the country has nuclear weapon. The above table is the data CSV file whose name is . Each row represents one country. The first attribute is the number of soldiers in the particular country, and the second one is the total number of population. The last attribute represent if the country has nuclear weapon. represents it has.\n\nThe first function that I think is very useful is . This function can split the whole x and y into training data and testing data. The shape of x is while the shape of y is .\n\nThe second idea that is worth to learn is . This class can scale the column into the range between . The advantage of is that it can make the variance be more obvious.\n\nThe left side is a simple example. The different of 0.5 is relatively smaller than the mean (seven hundred thousand). However, the different will be obvious after works.\n\nThe is a common class that I can see on the Kaggle kernel. On the other hand, is another class that can help us arrange the data. it can makes the mean of each column become 0, and the variance of each column become 1.\n\nHowever, both scalier have their own disadvantage. will control the value to be in the range of . If the testing data is out of range, it might get the incorrect predicted result. just normalize the column value. On the contrary, some result will be negative after the work. Some architecture (ex. ReLU) might be sensitive toward this property.\n\nThe last part is train and test the model! I use random forest to make the prediction. Even though the result is not good enough.\n\nFor the conclusion, we can use to get the corresponding sets of data. and can help us normalize the feature, and use these data to do the further work!"
    },
    {
        "url": "https://medium.com/@sunnerli/dnn-regression-in-tensorflow-16cc22cdd577?source=user_profile---------8----------------",
        "title": "DNN Regression in Tensorflow \u2013 Sunner Li \u2013",
        "text": "It\u2019s popular to apply DNN (Deep neural network) in classification task. The famous MNIST dataset is one case. We can reshape the 784-dimensions input into 1-rank vector. Can we use DNN to solve regression problem?\n\nThe answer is yes. Remember we can just need to do like the classification work! The above code load the sine data which contain some noise. The result can be illustrated as the following:\n\nNow we try to use regression model to fit these data distribution. First, we just use a simple DNN which just has one full-connected layer. The number of neuron is one, and you can regard it as a simple perceptron model.\n\nHowever, the result is not pretty good. In our approach, we just multiply the input vector with weight tensor, and add with a bias tensor. You can regard as a linear model. Just like the following format:\n\nAnd the corresponding result is shown below:\n\nThe red line is the model we get. How to make it better? In the machine learning territory, it\u2019s obvious that the linear model cannot solve the linear inseparable problem. One of the powerful technique we can use is to project the data to the high-dimension vector space! For example, we can project the whole data to the 3-dimension vector space. The following graph shows the project result:"
    },
    {
        "url": "https://medium.com/@sunnerli/relu-in-dnn-9bc1d78db2fb?source=user_profile---------9----------------",
        "title": "ReLU in DNN? \u2013 Sunner Li \u2013",
        "text": "In the usual situation, we can see that the ReLU activation function has been wildly used in CNN. However, can we adopt ReLU in the usual DNN?\n\nThe above code is a simple example. First, we create the training data. The number of data is 4 whose number of feature is 2 in each row. The target is 1-dimension whose rank is 2. We want to use DNN to solve the regression problem.\n\nNext, we create the DNN by the tensorlayer package. In the origin, we use linear activation function to train the model.\n\nIn our observation, it\u2019s not proper to train the model directly. As we can see, the first row has the relative small feature while the last row has the large value. On the other hand, the value of target is close to 1000.\n\nAfter I set these data, The Lin\u2019s concept (Professor Hsuan-Tien Lin) appears. In the concept of the regularization, the model has the property of transforming invarience. For example: is equal to the model . The scaling will not influence the data distribution. What\u2019s more, it can reduce the number of possible hypothesis of the model. As the result, we normalize the data before training. The above quote shows the value after normalization.\n\nIn the last part, we train the model whose epoch is 5000. In each epoch, the batch size is 1. And we show the output at final.\n\nThe above is the terminal result after running this code. We can see it is hard to converge. In the default case, the tensorlayer adopt linear activation. If we change to ReLU? Does the result get better?\n\nYes! We get the better performance. In the above quote, we can see the result is very similar to the target we show previously.\n\nHowever, this case will also occur sometimes. As we can see, the value of cost function remains zero without changing. What\u2019s going wrong?"
    },
    {
        "url": "https://medium.com/@sunnerli/get-start-with-pandas-822db89705c9?source=user_profile---------10----------------",
        "title": "Get start with Pandas! \u2013 Sunner Li \u2013",
        "text": "In 2016, I heard about the pandas package in the SITCON. At that time, I don\u2019t very clearly know what it is. In the previous task, I just use numpy to deal with the array data. In this summer, I have time to arrange the information. So the introduction will be mentioned in this article.\n\nIn this article, I will show how to use pandas to deal with the CSV files. The containing in this article are mostly referred from The SITCON slide. However, the fill NaN process will be skipped since I\u2019m not agree with the method that pandas provides.\n\nThe following one is a example CSV file whose name is . A class has 5 student. This table record the id of each student and their wieght of the backpack. In the last column, it shows the situation of each student if he passes the math test or not. means pass and means no pass.\n\nThe function is the key function that we will use frequently in this article. First, we can use this function to read the csv table. After reading, it will change the table as class which is defined in pandas. Next, we can split the x and y data and print them. y is the list of passing or not. x is the other data.\n\nThe above program use to change the containing of the into numpy object. The following program is another approach. We can use function to drop the columns we don\u2019t want to use. Next, use function to change it as numpy object. By this alternative method, we can get the same result!\n\nHow about to access the value in the particular position? The following program show this mechanism. It\u2019s more special that we create a object to help us change the index into attribute name.\n\nIn usual, we\u2019re adopt to use integer number to access the array directly. However, the pandas just allow attribute name string to become the column index. To simplify our approach, we use dict to change the integer into corresponding attribute string which can be accept in pandas."
    },
    {
        "url": "https://medium.com/@sunnerli/little-observation-about-multi-thread-multi-model-implementation-b4811654fb8f?source=user_profile---------11----------------",
        "title": "Little observation about Multi-thread & Multi-model Implementation",
        "text": "Last month, I encounter a lot of error while I use keras to produce the multiple CNN model in the individual thread. The question is obvious: Does the deep learning framework support multi-model?\n\nIf you\u2019re just interactive with the multiple model in order. The answer is yes. Look at the above program, the tensorflow really support in-order model without doubt.\n\nHow about use multi-thread? The answer is also Yes! The code is similar with the previous one. But how can the tensorflow deal with this situation?\n\nIf you run the above code, the correct result can be obtained. Before I think of this question, I think there is some conflict functions. But After I trace the source code, I realize that how the tensorflow control this phenomenon.\n\nThe key point is declaration. The following is the definition. I skip amount of comments which you can see the code more clearly. As you can see, there is only one thing need to be deal with. But what is the ? And what is the detail of ?"
    },
    {
        "url": "https://medium.com/@sunnerli/the-rough-implementation-of-tlu-threshold-logic-unit-476b2ba13026?source=user_profile---------12----------------",
        "title": "The rough implementation of TLU (Threshold Logic Unit)",
        "text": "Few days ago, my friend asked me some questions about TLU. In fact, there\u2019s few resource to introduce TLU before. I try to understand the contain and share what I know.\n\nThe left part of the above image shows the operation of the TLU. First, the weighted sum process will be done. Next, the \u03c6 function is step function, the math result is shown at the right part of the above image.\n\nNow, I use tensorflow to implement the TLU structure. First, I define which can load the training data and testing data.\n\nNext, I write the TLU structure as following:\n\nHowever, I cannot do anything since I didn\u2019t really realize the updating process. The following image illustrates the process to update the weight. On the contrary, I know a one truth.\n\nAs you can see, we should compute the gradient of the initial weight. In the first step, the derivative toward the activation function should be gotten. By the calculus, the derivative function of the step function is delta function (\u03b4 function).\n\nWait! Is there some strange things? In the fourth line of the pseudo-code, we should multiply the gradient value with the other parameter. But the gradient is 0 in the major period!! So we cannot update the gradient by the usual method since the updating value is almost 0.\n\nHow to solve this issue? The alternative function I use is sigmoid function. In order to perform the approximate the same result, the scaling process is performed. The following graph shows the result. In the left side, the graph show the origin distribution. On the other hand, the right side shows the result after revision.\n\nAfter this altering, The TLU implementation can be changed as following:\n\nAfter you run this code, the result can show the loss changing and the testing result. The following code is the keras version:\n\nFor the conclusion, it is a great method to use sigmoid function to \u201csimulate\u201d the step function. By this revision, the result can be perform well. In fact, you can use the geometry concept to update your weight since it\u2019s the original idea. This article just shows the other method to perform the TLU structure.\n\nIn fact, there\u2019s some issue I cannot under stand. First, the function can be divide as two part: and . However, I didn\u2019t know the result of . Maybe there\u2019s something I didn\u2019t remember.\n\nSecond, the NaN(Not a Number) error I got while I set scaling factor as 100. But I think it\u2019s not the problem that the factor is too much. The optimizer I use is Adam optimizer. In usual, the total revise level will reduce after I set the much few learning rate. However, the error still occurs after I reduce the learning rate.\n\nIf you have any opinion, welcome to tell me!"
    }
]