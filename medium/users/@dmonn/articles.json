[
    {
        "url": "https://blog.mentorcruise.com/jordi-scharloo-meet-the-mentors-65a3fdd31ec8?source=user_profile---------1----------------",
        "title": "Jordi Scharloo \u2014 Meet the Mentors \u2013",
        "text": "In this new series, we will take a look at our diverse and awesome mentor team here at MentorCruise. Building this platform wouldn\u2019t have been possible without the support of them. Today, we are going to talk to Jordi Scharloo.\n\nJordi is one of our mentor on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/JordiScharloo/.\n\nHey Jordi! Before we get started, why don\u2019t you tell us a little bit about yourself?\n\nNormally I would leave the talking about me to others, but from what I\u2019ve gathered I am a critical thinker with an above average interest in knowledge, skill and computer science.\n\nMy passion for the field started when I was very young. I was amazed by things like the walkman (and later MP3-player) that I had, and every time I could get my hands typing on a keyboard I took the chance! I got into (strategic) video games and started my affinity with computer science by making mods for them. Soon thereafter I got introduced to Linux and programming. I haven\u2019t looked back since!\n\nEvery year since then I have learned a lot of new things, and further mastered the skills I had picked up before. Yet, the world of IT never stops evolving and there will always be more to learn and master! Right now, 10 years later, I am a successful entrepreneur in the world of cyber security (and loving it!)\n\nOver the years, you have worked on several different exciting projects and have collected a lot of experience. How did you get started? How did you get your first job?\n\nAfter I found my passion for the field and had realised my very first few projects, I wanted to develop myself and my skillset more. I started taking on small projects in my area (for example data management and websites for local businesses) so I could learn better what it is to set up and finish technical products. After a few successes I started writing up some business ideas for myself to develop. For a couple of years I spent 50% of my available time on projects for others and 50% on projects that I was personally very passionate about.\n\nWhen I finished high school and wanted to pursue an education in computer science I decided to apply for a job at a medium-sized software house. Because I was able to give them a portfolio containing multiple developed projects, and was able to answer all their questions satisfactory they gave me the benefit of the doubt even though I had no degree yet. This was the formal beginning of my career. Later, I started my own company providing cybersecurity and software services.\n\nWhat was the favourite project that you\u2019ve worked on?\n\nOne of the first business ideas I\u2019d developed was a travel website. I would create a scaling website that would list all available rooms, bungalows and resorts from all major travel agencies in my country. I worked on that very happily for several years, and managed to get enough contacts in the sector to get a good catalog going. Unfortunately the site never took off as well as I\u2019d hoped because marketing-wise I couldn\u2019t beat the older names in the sector. Yet, this was definitely one of the most fun projects I have worked on, partly because it was totally mine!\n\nAfter that I worked on a bunch of projects, ranging from frameworks to mobile apps. But the project I\u2019m currently developing for RedSocks Security is definitely my new favorite. I like working with data \u2014 raw data. Right now I am creating software that can analyze file samples for malware (and categorize them) at high speeds, north of 1 terabyte per hour. The requirement for speed makes this project very fun and challenging to develop.\n\nWhat is the best advice you can give to someone who wants to follow your footsteps?\n\nJust go for it! Don\u2019t wait for school projects to come along or start by making something for somebody else. Figure out an idea that you would like to realise and just start working on it! You\u2019ll meet plenty of challenges along the way, which you will learn extremely much from. Watching hours of YouTube tutorials won\u2019t get you very far. You\u2019ll watch it and think you understand, until you have to make something yourself. If you currently have no inspiration try to draw from others. Maybe make your own version of Notepad? Or try to make an improved version of that one website you love so much? If you see some news about a cool new tech, just install and play with it! Also getting a mentor to help you along with your journey will surely help :)\n\nNow that you are a mentor \u2014 who would you like to mentor? What is your desired mentee like?\n\nAnybody that is passionate about technology and doesn\u2019t want to have their work done for them, but to be taught how to do it and improve it.\n\nAnything you would like to tell us?\n\nComputer science is a magical thing. If you learn the building blocks you will learn to master the environment, and bend it to your hand.\n\nJordi is one of our mentor on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/JordiScharloo/."
    },
    {
        "url": "https://blog.mentorcruise.com/pauline-narvas-meet-the-mentors-2cfa2afcc74a?source=user_profile---------2----------------",
        "title": "Pauline Narvas \u2014 Meet the Mentors \u2013",
        "text": "In this new series, we will take a look at our diverse and awesome mentor team here at MentorCruise. Building this platform wouldn\u2019t have been possible without the support of them. Today, we are going to talk to Pauline Narvas.\n\nHey Pauline! Before we get started \u2014 why don\u2019t you introduce yourself?\n\nHi all! I\u2019m Pauline, thanks for having me on MentorCruise \u2014 super excited to be here :-)\n\nI\u2019m currently a final year Biomedical Sciences with Employment Experience (yes, this is a part of my degree title) student at the University of Sheffield, currently only with a few months left until I graduate! I also am a self-taught developer, avid community builder, advocate for STEM, speaker and blogger. I\u2019m from a Filipino-Spanish origin but grew up in England!\n\nYou are currently studying \u2014 however, you already collected a lot of different experiences: You are a Web Dev, a public speaker, a blogger and more. How did you get started with all this?\n\nHa \u2014 this is a question I get asked a lot.\n\nAll of my hats \u2014 web dev, public speaker, blogger etc \u2014 actually all stemmed from when I was 8 years old, in front of my parents\u2019 computer, scratching my head over how to re-create a game I was playing because I was unhappy with its current features. So, being very curious of the tech that goes on that makes everything on the internet happen \u2014 I decided to try and make my own game \u2014 it was going to be a hybrid of Sims and Skyrim! I started off with trying to make a website because Runescape (the game I was playing at the time) was online, so I googled how to create a website and that is where my journey into the web-development world began.\n\nI have enjoyed coding on the side since and taught myself a lot about front-end web development which led me to starting a blog where I initially documented my game designs but then it shifted to a place where I\u2019d document all aspects of my life and what I was learning. My journey into building an online presence hasn\u2019t been easy \u2014 I\u2019m still going! I still have a lot to learn but it\u2019s become such a huge part of who I am today, it\u2019s led me to speaking gigs about my not-so-linear journey into tech and communicating online for impact \u2014 I\u2019m very thankful. :)\n\nYou are also very involved with Code First: Girls. Tell us a little bit about that.\n\nI could talk to you about Code First: Girls all day everyday!\n\nWhen I was teaching myself how to code and build websites, I was always alone. It can get lonely! When I was coding with a group of people, it was at school during my GCSE Computing class with a group of boys. And that\u2019s all I ever knew and sort of just\u2026 accepted.\n\nUntil my second year at University, where one day I received an email from the Department of Computer Science advertising an all-female coding course. Excited and shocked (more than I should have to be honest) that such a thing existed, I signed up and ended up getting a place on the course. The course was for complete beginners but at the time, I felt that I needed to refine my coding skills anyway \u2014 this would be the first time I\u2019d be learning front-end development in a class, and a class of women just like me.\n\nAfter my first class, I was inspired. More inspired than I have ever been in my life. I was eager to not only continue the course, but to be a part of what they were working towards \u2014 a more equal workforce in tech and entrepreneurship. So, after the course finished, I signed up to be an ambassador and instructor where I have, for two years now, helped teach 100+ female students how to code their first website from scratch. I also helped introduce the students to the wider tech community in the UK and across the world, giving them confidence to not be afraid of tech but embrace it as part of an exciting future. It was a commitment I very much looked forward to every single week and is something I am very proud of being a part of!\n\nYou can read all about STEM education and my work with Code First: Girls here.\n\nWhat was your greatest accomplishment in the last year?\n\nI think my greatest accomplishment would be getting up in front of people and delivering talks. I\u2019ve delivered talks at meetups, conferences and seminars, I gave my first talk in October last year on building inclusive communities.\n\nFor me, it was a lot more than just talking. It was me, standing in front of a crowd, being vulnerable, open and honest about some of the difficulties I faced in my journey and aiming to connect with at least one person who may have gone through a similar thing in the past or presently. I\u2019m very grateful for the opportunities to share my story in this way because I truly think it\u2019s the way to change the world!\n\nMy most recent talk, \u201cNevertheless, she persisted\u201d was my favourite one to deliver to date. At the end of the conference, two little girls (one aged 5, another 10) told me how I motivated them to go for it! \u201cIf Pauline can do it, I can too!\u201d It touched my heart.\n\nYou can watch all my previous talks here.\n\nYou are graduating this summer! What would you like to do after?\n\nI\u2019m currently very interested in the health tech space at the moment. Back in March, I helped organised a medical hackathon, #HackMed18, which inspired me to dig deeper in the digital health world. I realised that it fits quite nicely with my background in Biomedical Sciences, technical knowledge and general \u201clife goal\u201d to make a positive impact in the world.\n\nI\u2019m in the process of interviews and assessments at the moment from a range of digital health and tech companies, fingers crossed!\n\nWhat is your best advice to students out there, who still have some years to go?\n\nMy best advice would be to keep yourself open to different types of opportunities \u2014 don\u2019t be afraid of going beyond your degree even if it may seem different and disjointed at first. I truly believe that every single thing you take part in \u2014 whether that\u2019s a event, a part-time job, volunteering work \u2014 it all comes together to create a better you for both future career growth and personal development. I know that my 2 years folding clothes and selling shoes has contributed greatly to the person I am today \u2014 a speaker, a blogger, a developer, an advocate!\n\nThings you may like to explore:\n\nI wrote a blog post on the University of Sheffield Enterprise how you can maximise your university/school experience, you can read more here.\n\nNow that you are a mentor \u2014 who would you like to mentor? What is your desired mentee like?\n\nI\u2019m especially keen on mentoring students who are unsure about what is available out there for them \u2014 I know when I was at that stage, I wish someone would help guide me in my journey of discovery rather than tell me I can only be x or y because of a \u201cchosen\u201d route.\n\nAnything you would like to tell us?\n\nYou can find me bloggging at pawlean.com, re-writing my code endlessly at paulinenarvas.com, tweeting at @paulienuh and editing photos at instagram.com/paw.lean.\n\nPauline is one of our amazing mentors on MentorCruise. Visit her profile and get mentored by her today: https://mentorcruise.com/mentor/PaulineNarvas/"
    },
    {
        "url": "https://blog.mentorcruise.com/adrianus-warmenhoven-meet-the-mentors-1286a5175e74?source=user_profile---------3----------------",
        "title": "Adrianus Warmenhoven \u2014 Meet the Mentors \u2013",
        "text": "Hey Adrianus! Before we get started, why don\u2019t you tell us a little bit about yourself?\n\nThe most important things in my life are my son and my wife. I will never understand what I did to deserve them, but hey, I am counting my blessings.\n\nAt heart and in the core of my being, I am a hacker. That is neither good nor bad, it simply means I am curious about everything. And I want to understand everything. So that I then can control and/or play with everything. Literally, everything; technology, people, nature, life\u2026\n\nMy basic life philosophy is that one should try to be a good person first and foremost. Everything else follows from that. And that sometimes means letting go of actually being a good person; be nice, until it is time not to be nice.\n\nOver the years, you have worked on several different exciting projects and have collected a lot of experience. How did you get started? How did you get your first job?\n\nMy first job was kind of accidental; Sir Tim Berners Lee had literally (in the months before) invented the World Wide Web and we were playing with NCSA Mosaic at the university.\n\nI thought it would be a good idea to run a webserver and charge people about (in today\u2019s value) $50,- for 1 MB (yes, 1 Megabyte!!) of disk space, per month.\n\nSomeone at the university thought that it would be a good idea to have an office, so I got a room in a lab.\n\nSince they had to walk past a couple of biohazard placcards and some radiation gauges (the university had its own particle accelerator some 50 meters from my office), my customers always wanted to meet at their premises or at some coffee shop (the coffee drinking kind; I need to clarify that since it was in Amsterdam).\n\nThat company was later on sold to a large telco and so began the further adventures\u2026\n\nYou have worked on some impressive stuff in the past, including one of the first free ISPs in the Netherlands. Tell us about the project you are most proud of.\n\nTo be honest, the project I am most proud of has nothing to do with technology. It is the number of people that have transcended what everybody ever thought they could become.\n\nAnd the most striking example is Mr. Marijn Meijles (co-founder of http://fuga.com/ ). Marijn is a full paraplegic; he calls it \u2018being 100% spastic\u2019.\n\nWe met at a dinner that was hosted so I could get to know some other fellow and during the course of the meals to conduct a job interview with that other person (he got hired).\n\nMarijn was also present. And the most remarkable thing happened; he felt comfortable enough to correct me on some technical matters and we got into a technical discussion where I completely forgot that he was handicapped.\n\nI was so impressed with his technical knowledge that I wanted to hire him as well. I had to fight people close to him, I had to fight the large bank I was working for, I had to fight the nationwide employment agency. All of them told me \u201cYou can not hire him, he is 100% invalid\u201d.\n\nWhen I told them \u201cbut I am still going to hire him, he is the best coder I have ever met\u201d they told me I was crazy.\n\nWell, I am happy both he and I stuck to our guns. Marijn really became the best coder in my team, founded a family, has kids of his own and runs a company where 80 people work for him.\n\nI have lots of other stories about people, so tag me on MentorCruise if you want to hear them.\n\nBut people, those are the projects I am proudest of.\n\nWhat is the best advice you can give to someone wanting to follow your footsteps?\n\nJust do it. Go in guns blazing. But do so being prepared. Max out your skills, get yourself in a comfortable place, and then just go in. You get one chance this lifetime, no returns, no replay.\n\nWhy did you decide to join MentorCruise?\n\nI want Dominic Monn to be successful ; )\n\nBasically because it allows me to set a small bar so that I can focus on people that are really motivated.\n\nAlso, I had very good fortune to be mentored by someone in a very senior position; he taught me to take the anger out of myself and channel that energy to study and work very very hard.\n\nNow that you are a mentor \u2014 who would you like to mentor? What is your desired mentee like?\n\nAnyone that is motivated. I am not easy. Friendly, yes. Easy, no. So keep that in mind :)\n\nAnything you would like to tell us?\n\nLet\u2019s have some fun while we are at it!\n\nAdrianus is one of our mentors on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/AdrianusWarmenhoven/"
    },
    {
        "url": "https://blog.mentorcruise.com/sanyam-bhutani-meet-the-mentors-3ff8409d0f0e?source=user_profile---------4----------------",
        "title": "Sanyam Bhutani \u2014 Meet the Mentors \u2013",
        "text": "In this new series, we will take a look at our diverse and awesome mentor team here at MentorCruise. Building this platform wouldn\u2019t have been possible without the support of them. Today, we are going to talk to Sanyam Bhutani.\n\nSanyam is a new mentor on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/SanyamBhutani/.\n\nHey Sanyam! Before we get started, why don\u2019t you tell us a little bit about yourself?\n\nI\u2019m a Deep Learning and Computer Vision Nerd from India.\n\nI\u2019m an active blogger of Deep Learning and Self Driving Cars on Medium.\n\nProfessionally, I\u2019m a Fast AI International Fellow, an AI Geek Leader at the Nurture.ai Community, an Udacity Flying and Self Driving Car ND Student and Deep Learning Graduate.\n\nMy dream is to work on the next DeLorean (Back to the Future) and bring the wonders of Deep Learning to Agritech in my nation.\n\nOver the years, you have worked on several different exciting projects and have collected a lot of experience. How did you get started? How did you get your first job?\n\nI think I\u2019ve always been attracted to Coding since quite a young age. \n\nMy Hello World-breakthrough moment was writing a few nested \u2018for-loops\u2019 in High School to print patterns, in that moment I found my love for coding.\n\nI joined my First internship right after High School, where I got to work on a Project involving Data Visualisation and basic Data Analysis. Thanks to the amazing guidance I received, I found my love for playing around with data and later AI.\n\nOn my learning path, I\u2019ve worked on various Deep Learning and Computer Vision Projects (End to End), you can read more about them here: sanyambhutani.com. Currently I\u2019m working on a drone and autonomous system to be developed for Native Indian Farms.\n\n4. You are a co-founder at Init27. Can you tell us more about that?\n\ninit27 Labs is a way of giving back to the Community. \n\nWe\u2019re a group of Udacity graduates and Fast AI Fellows. We really want to help the community in their learning path and init27 is a medium to share our knowledge.\n\nThe dream was to keep it completely open source, hence It\u2019s a non-profit and open to all \u2018Lab\u2019: where we\u2019re putting out Tutorials for anyone who might want to get started on their Deep Learning journey or wants to try something new.\n\nRight now we\u2019re in early beta, but we plan do a complete launch this Fall.\n\nPS, for the Linux Nerds: The name comes from init & the birthday of me and my-counder (27th). Hence init27.\n\n5. You are a regular speaker at Tech conferences. How did you get started there?\n\nI\u2019ve always taken up Technical Speaking very seriously, I started by using my college\u2019s platform: by taking part in every technical event happening on campus.\n\nDuring my numerous internships, I tried getting involved in the On-Campus events and from the constant feedback and re-shaping I\u2019ve improved at my speaking skills (which for me was a challenge since I take pride in calling myself a Coder, you\u2019d understand if you watch Silicon valley \ud83d\ude0e)\n\nI delivered a few technical seminars in ONGC, at the IIT-Madras Campus which were really well received and appreciated.\n\nThe greatest achievement of my career was being invited to present at the Anaconda Conference \u201918, being the only Undergrad and Indian presenter on board.\n\n6. Why did you decide to become a mentor?\n\nI was very lucky to be guided by amazing practitioners during my internships, and during my Fast AI International Fellowship.\n\nQuite frankly, I wouldn\u2019t have learnt a lot without their guidance.\n\nI want to help anyone who wants to get started on their AI Learning path.\n\n7. Now that you are a mentor \u2014 who would you like to mentor? What is your desired mentee like?\n\nAnyone who is interested in building our Robotic overlords to help rule the world and take over humanity.\n\nHAIL HYDRA!\n\nI\u2019d like mentees that are fascinated by the \u2018AGI\u2019 dream as much as I personally am and are interested in building systems that\u2019d help us bring closer to the dream.\n\nNot a code jam winner, But definitely someone who is excited about AI and is willing to put in a few 5 to 9s for their passion.\n\n8. Anything you would like to tell us?\n\nI\u2019m very excited and honoured to be part of such an amazing board of Mentors. (Also, Hail HYDRA!)\n\nSanyam is a new mentor on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/SanyamBhutani/."
    },
    {
        "url": "https://blog.mentorcruise.com/sebastien-provencher-meet-the-mentors-64d824e9fe75?source=user_profile---------5----------------",
        "title": "Sebastien Provencher \u2014 Meet the Mentors \u2013",
        "text": "In this new series, we will take a look at our diverse and awesome mentor team here at MentorCruise. Building this platform wouldn\u2019t have been possible without the support of them. Today, we are going to talk to Sebastien Provencher.\n\nHey Sebastien! Before we get started, why don\u2019t you tell us a little bit about yourself!\n\nI\u2019m a serial startup entrepreneur with more than 15 years of experience in product management and business development. I have experience in adtech, media, local commerce, social media and artificial intelligence. I\u2019m a startup mentor and advisor. I joined Element AI (www.elementai.com), the biggest Canadian AI startup, as one of their early employees and now work in the product team.\n\nOver the years, you have worked on several different exciting projects and have collected a lot of experience. How did you get started? How did you get your first job?\n\nI think what really helped me in my career is that I learned to code as a teenager. That gave me enough technical chops and culture to really be able to succeed as a product manager. After getting an undergrad degree and a MBA in marketing, I was hired as an e-commerce product manager at the Canadian Yellow Pages. That was the first time I was exposed to product management and truly loved it from day 1!\n\nYou work at Element AI now. What do you do there?\n\nI joined two weeks after the official launch, as one of the first employees. I spent 15 months in a business development role, talking to hundreds of potential business customers. Since the beginning of January, I\u2019m now using that extensive market knowledge in Element AI\u2019s product team, helping ship our first products.\n\nYou founded a lot of companies in the past. What is the best advice you can give someone, going down the same path?\n\nBuilding startups is super hard! There\u2019s a lot of moving pieces and you need a lot of resilience. I think the best advice I would give is to join a growing startup for a few years and learn as much as you can about them. And once you feel it, you can start of launching your own company.\n\nYou are based in Montreal. Do you think it is more difficult to acquire customers and investors there than in the US / SF?\n\nFrom a funding POV, I think that was true ten years ago when I did my first startup. The Montreal (and Canadian) startup ecosystem is now much more mature and we can now attract investments more easily. For customer acquisition, it\u2019s not more difficult than the US/SF. In fact, the fact that Canada is multicultural is definitely helping us with customer acquisition in regions like EMEA and APAC.\n\nYou are already an experienced mentor. What is your desired mentee like?\n\nI like mentees that are mature enough to understand what they know & what they don\u2019t know. Also, this might sound basic, but I like mentees that listen and incorporate mentor advice in their thought process. Many startup entrepreneurs are cocky and believe they know better, making the same mistakes I did all over again (and against my advice). Not that I have all the answers, but there\u2019s no need to make basic mistakes given all the advice available out there. :)\n\nAnything you would like to tell us?\n\nCreating and launching my own startup was a very positive life-changing event for me. I wish I would have done it earlier in life. So, if you feel the calling (even if it\u2019s scary), do it!\n\nSebastien is a new mentor on MentorCruise. Visit his profile now and get mentored by him: https://mentorcruise.com/mentor/SebastienProvencher/."
    },
    {
        "url": "https://blog.mentorcruise.com/introducing-mentorcruise-d6864f90f4e7?source=user_profile---------6----------------",
        "title": "Introducing MentorCruise \u2013",
        "text": "Hello World! After several months of planning, developing and polishing the application, I am very excited to announce the launch of MentorCruise: the long-term mentorship platform for people in Tech.\n\nSign up as mentor or mentee on https://mentorcruise.com.\n\nMentorCruise turned into an idea when I graduated from Udacity about a year ago. Udacity students have access to a long-term mentor, which will guide them through the 6 to 9-month long journey of a Nanodegree. However, after you graduate, the mentor is gone.\n\nYoung people need mentoring. It helps them reach their goals and feel confident about their skills. It\u2019s also a good tool for networking and getting to know people. However, finding a mentor is hard. The people you adore might not have the time or will to mentor you. Most people do not have access to a mentor in their school or at their workplace, especially if their goal is to change careers.\n\nMentorCruise solves this problem by formally connecting mentor and mentee through a marketplace. From the beginning, it is clear if the mentor is ready for mentorships and which services they want to provide.\n\nToday, we are launching! As of now, our hand-picked mentors are ready to talk to you! Sign up and explore the mentor list to find your perfect mentor.\n\nThanks to everyone who has worked and is working on this platform, to all early-stage mentors and advisors. Let\u2019s do this!\n\nSign up as mentor or mentee on https://mentorcruise.com."
    },
    {
        "url": "https://blog.mentorcruise.com/the-mentorship-model-at-udacity-cb11a6b1e894?source=user_profile---------7----------------",
        "title": "The mentorship model at Udacity \u2013",
        "text": "It is now over a year ago that I got the confirmation message to join the \u201cSelf-Driving Car Engineer Nanodegree\u201d from Udacity. It is now about three months ago that I graduated \u2014 but I\u2019m still very active in the community: I mentor the next generation.\n\nWhen I first heard about Udacity, Nanodegrees were a bit different than they are now: Entirely self-paced packages of courses, with some cool projects in between. Awesome thing: These projects were reviewed by real humans! Even though they were already very high-quality courses, they had the same problem as every MOOC as well: A very short student life-cycle.\n\nI remember reading this article about \u201cHow Udacity scales\u201d when I did my first course with them. TL;DR: Udacity ran into a scaling issue \u2014 they had more than 2'000 paying students, but could only afford about 15 people to review projects. Since the projects were self-paced and open to anyone, the rate that students solved projects was changing a lot \u2014 but the number of reviewers stayed the same.\n\nThe solution: Graduates or people that did the project could apply for a freelance reviewer position and got paid on a \u201cper-review\u201d basis. When there were more project submissions, people got paid more. No need to hire more full-time people. It also helped to keep students connected to Udacity after they graduated.\n\nThe \u201cSelf-Driving Car Engineer\u201d Nanodegree was the first \u2014 or at least one of the first \u2014 to also feature mentors. This set Udacity apart from all other MOOCs; Students now had a single point of contact for advice, help and guidance throughout all of their Nanodegree experience \u2014 but where did the mentors come from?\n\nI was greeted by my mentor when I first logged in to the Udacity classroom. He was a nice and experienced Machine Learning Engineer, who told me that he mentors a lot of people. He didn\u2019t want to give me specific numbers \u2014 but it was likely 100+. This also meant that he didn\u2019t have a lot of time for me and so I didn\u2019t use the offer very much because of the long response times.\n\nThis was also the case for a lot of other students, so when I started the second term as part of the first cohort ever, we were asked to apply to become mentors ourselves for the new students. This meant that single mentors had to advise fewer students (I started with 30) and they also had hands-on experience for all the projects of the previous terms. Mentors could also use this to get part of their tuition back, which was relatively high for a MOOC.\n\nIt had also a nice side-effect: Grads like me stayed in the community. Even though I graduated and I got a new job because of it, and I don\u2019t feel the need to start another Nanodegree (even though the flying car one looks awesome), I\u2019m still looking over the numerous Slack channels and write with some of the Udacity staff from time to time.\n\nIt got pretty obvious to me that Udacity wants to change the student life-cycle of MOOCs. When I do a course at Udemy, I pay for the course, watch all the videos, do the project and then leave. That is the case for most MOOCs.\n\nAt Udacity however, I might do one of their Foundation Nanodegrees, before moving on to the Advanced one, then I could become a reviewer, classroom mentor or a moderator in the forums. In the past, I could also become a part of Udacity Blitz and start freelancing work for them \u2014 but this got discontinued lately. I might browse their career boards after that \u2014 and then maybe even start the next Nanodegree. This extension of the default student life-cycle is a win-win situation for Udacity, but also for the students and might be one of the reasons why Udacity is one of the most successful MOOCs out there."
    },
    {
        "url": "https://towardsdatascience.com/how-openmined-uses-your-idle-consoles-to-train-the-next-generation-of-ai-64a2207e2323?source=user_profile---------8----------------",
        "title": "How OpenMined uses your idle consoles to train the next generation of AI",
        "text": "By now, you should already have heard plenty about the open-source organization OpenMined. They are working on a way to democratize the access to personal data using Blockchain\u2014 and the Unity Game Engine.\n\nNever heard of OpenMined? No problem, there are plenty of articles out there. Just pick one.\n\nOpenMined uses the Unity Game Engine for PySyft, their encrypted Deep Learning Library. You might ask yourself now, why a Deep Learning Library uses a Game Engine. Let me explain.\n\nIf you are active in the Deep Learning space, you know that training an AI takes a large amount of processing power. In most cases, a good CUDA-compatible GPU can massively speed up the training progress. Even training a simple classifier can be a pain if you don\u2019t own the appropriate hardware.\n\nThis is a problem for OpenMined.\n\nOpenMined targets everyday users, not just Data Scientists or Deep Learning Engineers, who probably own a high-end GPU anyway. Think about your parents, your brothers and sisters, your non-tech friends: Do they own CUDA hardware?\n\nIf you have read some of the articles linked above, you know that the goal of OpenMined is that users train the shared network with their own data on their own devices\u2014 the personal data shouldn\u2019t leave the device. That\u2019s why it is important that the training is possible on devices that most people use.\n\nBy using the Unity Game Engine, the OpenMined team is able to cross-compile their code to almost every existing GPU on the planet. This means that the training can be run on a lot more devices \u2014 you probably own multiple of them:\n\nI said it in my last article, and I\u2019m saying it again: The OpenMined project has the vision and the tools to revolutionize the way we collect, protect and secure your personal data and use that for Artificial Intelligence. Obviously, revolutionizing the way we use our hardware for training was a part of this too.\n\nLarge parts of this were taken from the \u201cWhy Unity?\u201d Markdown file on the OpenMined GitHub. If you want to contribute, check out the website of OpenMined for more infos and join our Slack. I\u2019m going to say hello."
    },
    {
        "url": "https://towardsdatascience.com/reinforcement-learning-the-quirks-44b0e315fed2?source=user_profile---------9----------------",
        "title": "Reinforcement Learning: The quirks \u2013",
        "text": "I have been working on Reinforcement Learning for the past few months and all I can say about it: It is different. A writeup of the common quirks and frustrations of Reinforcement Learning I have experienced.\n\nI have been applying variations of the A3C and the GA3C algorithm on various OpenAI Gym environments as part of my internship. I did not have any extensive Reinforcement Learning experience before that, apart from some introduction courses, so this was very new to me.\n\nI quickly learned that Reinforcement Learning is very different from the default classification and regression tasks I had done previously \u2014 but it is very exciting! Let me tell you about problems I encountered during all of this.\n\nIn Deep Reinforcement Learning, training data usually gets collected \u201con the job\u201d, meaning that the agent starts with no prior knowledge of his environment and then starts collecting experiences while interacting with the simulation.\n\nThis means that it takes some time to collect the data in a memory buffer and then some more time to pass it into the algorithm and update the network weights. This can be optimized by using a asynchronous approach \u2014 such as the A3C algorithm mentioned above \u2014 which makes things a lot more complicated. This means that even some simple agents take hours to train \u2014 and more complex systems need multiple days or even weeks.\n\nWorking at NVIDIA AI brings some obvious benefits with it \u2014 sheer unlimited computational power.\n\nThe worse it was to realize, that most of Reinforcement Learning work is done on the CPU.\n\nUsing the GA3C algorithm, some power gets moved to the GPU, allowing bigger and more complex networks, but in my experience the limitations usually come from the CPU, which is very unusual in the rest of the Deep Learning space.\n\nThis one hurts the most. The \u201cExplorations vs. Exploitation\u201d seems to be a very common problem. Basically, there is a trade-off between exploring your environment and taking the best possible action. Let\u2019s look at this in the context of a maze.\n\nIf you explore too much, your bot will always try to find new ways to solve the maze better. Sounds good at first, but it also means that if your bot finds the perfect way to solve the maze \u2014it won\u2019t believe that it is the best and try another route the next time, possibly never finding the \u201cbest way\u201d again.\n\nIf you explore too little / you exploit too much, your bot might find a way to solve the maze and will just keep on going the same way. That might mean that it goes through every single corridor before getting to the core of the maze \u2014 but that is good enough for it and it will keep doing that forever.\n\nIn my experience, the second one happens way more. I read this brilliant article by Arthur Juliani about some exploration techniques and I can recommend it to anyone experimenting with RL."
    },
    {
        "url": "https://blog.mentorcruise.com/why-mentorships-matter-dc95522a3e9b?source=user_profile---------10----------------",
        "title": "Why mentorship matters \u2013",
        "text": "Mentorships are a great way for students and young people to keep track of their progress and have some support when it comes to reaching their goals. So why do so many people don\u2019t have a mentor?\n\nDid you know, that a third of young people don\u2019t have any kind of mentor figure while growing up and while starting a career? Due to this, they miss out on the personal growth and development that a long-term mentorship brings with it and can often feel forsaken while pursuing a career or even handling day-to-day situations.\n\nIt is proven that mentorships have positive effects on young people in a large variety of personal, academic and professional situations. In fact, people who had a mentoring relationship at a younger age are more likely to hold leadership positions and mentor others themselves when they are older.\n\nMentors can help students to tackle a large variety of situations and are therefore one of the most personalized ways of education that exist. So why do so many people don\u2019t have a mentor?\n\nYou might have been there before: You have an idol, a really successful person with the skillset you want to have as well. One day, you finally brace up and write them on Twitter: \u201cWill you be my mentor?\u201d. You anxiously wait for a response, but \u2014 nothing. You just got ignored.\n\nThis might have many reasons:\n\nIt is very unlikely that the person actively has negative feelings against you, so don\u2019t worry. Mentors are rare \u2014 most people might not know that they actually would be good mentor material.\n\nThere are a lot of ways to find a mentor, and if you were actively looking for one \u2014 you will have read most of them already.\n\nAll of these reasons have a good right to exist, but there is something else as well \u2014 and this is where the self-advertisement comes in. Sorry! Meet MentorCruise.\n\nThe goal of MentorCruise is to connect aspiring, young students with experienced and awesome industry professionals in the technology industry, who are willing to mentor people. We plan to offer mentorship opportunities in Engineering & Data, Design and Business. This can be free or for some small fee \u2014 it is your and the mentor\u2019s choice.\n\nMentorCruise is currently in development, but we would love to have you on board already. Visit our website and get notified about our launch and new updates, such as early access. You can also follow us on Twitter, we appreciate it!"
    },
    {
        "url": "https://becominghuman.ai/how-openmined-will-revolutionize-data-privacy-protection-and-collection-2a634da76d63?source=user_profile---------11----------------",
        "title": "How OpenMined will revolutionize data privacy, protection and collection",
        "text": "The OpenMined project has the vision and the tools to revolutionize the way we collect, protect and secure your personal data and use that for Artificial Intelligence.\n\nThe open source project \u201cOpenMined\u201d was called to life by Andrew Trask and has the goal to encrypt and decentralize artificial intelligence by using the blockchain.\n\nAsk yourself the question: Do you feel like you are in control of your personal data? If you think so, great! But it is probably not true.\n\nBy using services provided by companies such as Google, Apple, Microsoft and Amazon, you agree to share your personal data with them by blindly accepting their Terms of Service. Even most apps on your phone have a clause in the Terms of Service to be able to use your data.\n\nOpting out of that is often difficult and confusing since the companies don\u2019t want to lose your data. They need this data to create user profiles and advance the quality of their artificial intelligence. They own your data, even if they only want to use it for their neural network training.\n\nSo where am I going with this? There isn\u2019t really a way to stop these companies using your data as long as you use their services. But at least you could make some money out of it, right?\n\nOpenMined uses your data to train encrypted neural networks for companies, that otherwise wouldn\u2019t be able to get that kind and amount of data. The best part: Your data won\u2019t ever leave your device \u2014only the training results will. The company can train their neural networks, without having you lose control over your data. Depending on how much your data helps the training of the network, the more you\u2019ll get paid.\n\nWhile big tech company secured a nearly endless stream of private and personal data with their shady Terms of Service documents, smaller companies often face a lack of high-quality data.\n\nOn the other side, you probably don\u2019t want any company to own your data. That\u2019s why the training happens on your device. Only the training results get shared.\n\nThat way, the small companies can get their models trained and you don\u2019t have to worry about anyone selling your data to third parties.\n\nOpenMined is open source, which not only means that it is free, but it also means you can actively help to make the vision reality.\n\nContributors come from all over the world and work on Development, Research, but also on Design, Marketing and more. No matter what your skills are, you are welcome!\n\nSimply sign up for Slack by using this link and get involved. You should actually get a message as soon as you join us \u2014from me! I will help you to find a project that matches your skills and interests.\n\nDon\u2019t be shy! We are very beginner friendly.\n\nIf you want to learn more about OpenMined, look at these additional videos on the topic:\n\nI hope you enjoyed this brief overview of OpenMined. We hope you are as much excited about this as we are! If you want to get involved, it might be worth checking out our website and join Slack."
    },
    {
        "url": "https://towardsdatascience.com/pytorch-vs-tensorflow-1-month-summary-35d138590f9?source=user_profile---------12----------------",
        "title": "PyTorch vs. TensorFlow: 1 month summary \u2013",
        "text": "How PyTorch compares to TensorFlow after one month of working with PyTorch.\n\nI\u2019ve been a TensorFlow user for the better part of my Deep Learning work. However, when I joined NVIDIA, we decided to switch to PyTorch \u2014 just as a test. These are my experiences with it.\n\nThe installation is very easy and straightforward. PyTorch can be installed via PIP or can be built from source. PyTorch also offers Docker images which can be used as a base image for your own project.\n\nThere isn't a designated CPU and GPU version of PyTorch like there is with TensorFlow. While this makes installation easier, it generates more code if you want to support both, CPU and GPU usage.\n\nIt is to note that PyTorch does not offer an official window distribution yet. There are non-official ports to windows, but there is no support from PyTorch.\n\nPyTorch offers a very Pythonic API. This is very different from TensorFlow, where you are supposed to define all Tensors and the Graph and then run it in a session.\n\nIn my opinion, this leads to more, but much cleaner code. PyTorch Graphs have to be defined in a class which inherits from the PyTorch class. A function gets called when the Graph is run. With this \"convention over configuration\" approach the location of the graph is always known and variables aren't defined all over in the rest of the code.\n\nThis \"new\" approach needs some time to get used to, but I think it is very intuitive if you have worked with Python outside of Deep Learning before.\n\nBased on some reviews, PyTorch also shows a better performance on a lot of models compared to TensorFlow.\n\nDocumentation is complete for the most part. I never failed to find the definition of a function or module. Opposed to TensorFlow, where all functions have a single page, PyTorch only uses one page per module. This makes it a bit more difficult if you are coming from Google, looking for a function.\n\nObviously the community of PyTorch isn't as large as the one of TensorFlow. However, many people enjoy working with PyTorch in their free time, even though they use TensorFlow for work. I think this could change as soon as PyTorch gets out of Beta.\n\nAt the current moment, it is still a bit more difficult to find proficient people in PyTorch.\n\nThe community is large enough that questions in the official forums usually get a quick answer and so that a lot of example implementations of great neural networks got translated into PyTorch.\n\nEven though PyTorch offers a fair amount of tools, some very useful ones are missing. One of the most helpful tools that are missing is TensorFlow's TensorBoard. This makes vizualization a bit more difficult.\n\nThere are also some very common used helpers missing. This requires a bit more self-written code than TensorFlow.\n\nPyTorch is an awesome alternative to TensorFlow. Since PyTorch is still in Beta, I expect some more changes and improvements to the usability, docs and performance.\n\nPyTorch is very pythonic and feels comfortable to work with. It has a good community and documentation. It is also said to be a bit faster than TensorFlow.\n\nHowever, the community is still quite smaller as opposed to TensorFlow and some useful tools such as the TensorBoard are missing."
    },
    {
        "url": "https://medium.com/@dmonn/you-will-probably-never-own-a-self-driving-car-1b66804d9335?source=user_profile---------13----------------",
        "title": "You will probably never own a Self-Driving Car \u2013 Dominic Monn \u2013",
        "text": "On the current trend of autonomous vehicles and why you probably won\u2019t and shouldn\u2019t own one.\n\nSelf-Driving Cars aren\u2019t just a current craze of ambitious Silicon Valley startups, they are an invention which could transform the way we commute and travel. Even though fast and flexible startups and startup-like automakers just as Tesla Motors are leading in this space, big automakers don\u2019t sleep either and presented several concepts at the IAA in Frankfurt.\n\nSomething I always hear when talking to non-Tech people about Self-Driving Vehicles is: \u201cYou know, these cars will be so expensive that ordinary people won\u2019t be able to buy one for the next 20\u201330 years, just like with the first computers\u201d. When I hear this, I can usually assume that these people don\u2019t see the bigger picture.\n\nThese people have to understand that a Self-Driving Car won\u2019t be a proprietary object anymore. When thinking about Self-Driving Cars, don\u2019t think of the car in your garage. A Self-Driving Car won\u2019t be something you let sit in your garage and use it on 8am and 5pm to get to work and back. Instead, think of it as a cheap taxi for long distances.\n\nSelf-Driving Taxi services are sprouting up in the San Francisco Bay Area and the rest of California. Tesla Motors is planning on introducing the Fleet program \u2014 a function where the Tesla can be made available to autonomously act as a Self-Driving Taxi, picking up passengers and making the owner a little side money. Uber is experimenting actively with adding Self-Driving Taxis to their service and Oliver Cameron launched his Self-Driving Taxi Service \u201cVoyage\u201d with its 2 Fords quite a while ago.\n\nThese services also make the concept of garages and driveways completely obsolete. This means less rent for people in rented apartments and more usable space for people with their own houses.\n\nThe concept of owning a car will be obsolete soon. People will summon a Self-Driving Taxi with their phone in minutes or even seconds and will commute cheap and quick.\n\nWith the use of electronic vehicles, the Self-Driving Taxis will get even cheaper and will have the ability to drive themselves to a charger when needed. This makes the rides even cheaper and more convenient.\n\nSo if someone is telling you that they won\u2019t be able to afford a Self-Driving Car for a long time, ask them: \u201cIf you aren\u2019t able to pay a few dollars for your daily commute, how are you going to buy a whole car?\u201d."
    },
    {
        "url": "https://medium.com/@dmonn/how-does-an-a3c-work-4e02266d1a96?source=user_profile---------14----------------",
        "title": "How does an A3C work? \u2013 Dominic Monn \u2013",
        "text": "How to leverage your DQN-based reinforcement learning using multiple workers.\n\nReinforcement learning gained a lot of popularity after the historic victory of AlphaGo against the (human) Go champion and quite recently after OpenAI announced their StarCraft 2 testing environment in cooperation with Blizzard.\n\nMost of these recent achievements were made possible thanks to an architecture named \u201cDeep Q-Network\u201d. This architecture achieves superhuman performances on Atari games by collecting memories while trying out different scenarios and recording the given rewards and then using these memories to train a neural network.\n\nBut what comes after? The same company who is responsible for the DQN, DeepMind, introduced the A3C architecture more recently. It\u2019s supposed to be faster, simpler and more robust than the DQN and also able to achieve better results. But how?\n\nYou can figure out the biggest difference by looking at the name of this mysterious architecture: Asynchronous Advantage Actor-Critic. In DQN, a single agent (or so-called worker) interacts with a single environment, generating training data. The A3C launches several workers asynchronously (as much as your CPU can handle) and lets them all interact with their own instance of the environment. They also train their own copy of the network and share their results at the end of the simulation.\n\nSo why exactly is this better than a traditional DQN? There are multiple reasons for that. First, by asynchronously launching more workers, you are essentially going to collect as much more training data, which makes the collection of the data faster.\n\nSince every single worker instance also has their own environment, you are going to get more diverse data, which is known to make the network more robust and generates better results!\n\nIf you are interested in seeing an implementation of A3C, together with a much more in-depth explanation of the two remaining A\u2019s of A3C, I\u2019d strongly suggest taking a look at this Medium post by Arthur Juliani!\n\nNVIDIA introduced the next generation of A3C, the GA3C, which also makes use of the GPU, in a paper earlier this year. Instead of copying the whole network to every single worker, the network here stays global on the GPU.\n\nDue to the generated delay by copying data from the CPU to the GPU and back, this makes smaller networks about 6x faster. For larger networks, however, this method generates the same results about 45x faster, according to the paper.\n\nThanks for reading! Now you know what an A3C is! You also learned about its advantages against DQN and its next evolution: The GA3C. Follow me on Medium for more high-level explanations of your favorite nets and algorithms!"
    },
    {
        "url": "https://medium.com/@dmonn/udacity-self-driving-car-engineer-nanodegree-a-walkthrough-c0c1616dd71a?source=user_profile---------15----------------",
        "title": "Udacity Self-Driving Car Engineer Nanodegree: A walkthrough",
        "text": "About a year ago, the well-known online education provider Udacity announced their newest program: The Self-Driving Car Engineer Nanodegree. I had known Udacity for quite some while at that point. I had done a few free courses before and was actually thinking about starting one of their Nanodegrees. But when they announced the Self-Driving Car Engineer Nanodegree (or SDCND for short), I was immediately hooked.\n\nAt that point, I was in the fourth year of a 4-year apprenticeship in Software Engineering (to read more about the apprenticeship model in Switzerland click here) and was looking for a new challenge in the Machine Learning space. So I was giving it a shot.\n\nThe SDCND was a bit different from the previous Nanodegrees: People had to apply to grab one of the first 250 spots in the program, there were hiring partners such as Mercedes-Benz, Uber ATG, BMW and NVIDIA in place, it consisted of three fixed three-month long terms and there was a mentorship program. I applied for the first cohort and about a month after I got a mail. I was accepted into the second (November 2016) cohort! Now, almost a year after that, I\u2019m only days away from completing the program. Therefore, I want to share my experiences.\n\nTerm 1 consisted of five projects and various lessons centred around Deep Learning and Computer Vision. To be fully honest, this was the term I enjoyed the most since I wanted to learn as much as I could about Deep Learning.\n\nThe first project was an easy one: Using some basic Computer Vision techniques, we annotated lane lines in a video. I remember that I was excited submitting my very first project and I got an awesome review (from an actual human!). I was also excited about the community forming in their Slack channel. I actually made some friends there and had some really good conversations.\n\nThe second project was to build a Traffic Sign Classifier. In hindsight, this is a very basic and easy project. But as a beginner, to build this was a huge challenge. However, after some days I got it running and it actually got a great review.\n\nThe third project might be my all-time favourite project from the program. Using Udacity\u2019s own race track simulator, we built a behaviour cloning network. First, data had to be collected by driving around the track a few times (P.S: Use a controller for this one!). Then, a neural network had to be built to predict steering angles. The result was a \u201creal\u201d virtual autonomous car. I was so proud!\n\nThe fourth project was similar to the first one: Advanced Lane Finding. This time, we used some more advanced computer vision techniques to get better results (e.g. on roads with shadows and curves).\n\nThe fifth and final project was a tough one! Using computer vision and machine learning techniques, we built a vehicle tracking algorithm. It was not easy to train the machine learning algorithm to correctly classify cars. This was a lot of work, but with this one done, the first term was completed.\n\nTo my surprise, I had finished the term a lot quicker than expected. I actually could start the second term with the first cohort. This was exciting since I\u2019d be one of the first people to experience the content, but it was also scary, since there weren\u2019t as many people to help me. At this point, I also got the offer to mentor some students myself. I did not use my mentor very much, but I took the offer and started with 30 students. At the time of writing, I\u2019m mentoring over 80 students!\n\nThe second term was the least exciting one for me personally. I suppose people who love robotics will absolutely love this term, but I did not have any background in C++ and wanted to do more Deep Learning. I was hungry for more!\n\nThis term consisted of five projects as well. With help of Mercedes-Benz, we learned a lot about Extended and Unscented Kalman Filters, which we both had to implement for projects.\n\nThe third project was about Kidnapped Vehicles. Using a particle filter and a map, we had to localize an autonomous vehicle in an unknown environment. This one was very fun to do!\n\nThere wasn\u2019t much theory in this term (what a lot of my peer students did not like), so after a single theory block, the next project already started. The goal of this one was to build a PID controller (proportional\u2013integral\u2013derivative). We also used Udacity\u2019s simulator for this one.\n\nThe final project of the second term was to build a model predictive control. This was a really interesting project and gave a lot of insight into an autonomous vehicle. The goal of the project was to steer the car around a track with latency between the commands. Very exciting!\n\nAt this point, I was confident enough to go on Deep Learning interviews. My apprenticeship was coming to an end and I was looking for something new. I failed at some of the technical interviews which, even if it hurt my confidence a bit, taught me a lot. My advice for people looking for a job in a new industry: Go on interviews. It\u2019ll show you all your flaws and what to study next. In the end, I got an amazing internship at NVIDIA in Zurich.\n\nThe final term was another exciting one, even though it only has three (or four) projects.\n\nIn the path planning project, the goal is to build a path planner to drive on a high way without so-called \u201cincidents\u201d. Which means that the car shouldn\u2019t drive faster than the limit \u2014 and also not a lot slower \u2014 and of course it should not crash into other cars. This project was a lot of fun!\n\nIn the next part, students have the possibility to choose between to concentrations: Advanced Deep Learning and Functional Safety. Of course, I choose Advanced Deep Learning which was taught by the Deep Learning Institute of my future employer. In this concentration, students learn about Fully Convolutional Networks and will build a Semantic Segmentation algorithm to identify free areas on the road.\n\nThe capstone project, however, is the truly special thing about the SDCND. Students are required to build teams of 3 to 5 people and work on the last project together. The goal of this one is to implement some nodes in the Robot Operating System (ROS), test the solution in a simulator and then load it onto the Udacity Self-Driving Car \u201cClara\u201d! I had a look at the team spreadsheet and got into a team named \u201cWhiteDriver\u201d which consisted of four people already, which were mostly in my timezone. On the same evening, we planned the project.\n\nOur team leader implemented some things very fast and other people from the team did too. Unfortunately, my computer which I use for working on the nanodegree broke in this very week, so I was left with a weaker machine which could not run the simulator. Therefore, I implemented the computer vision algorithm to classify traffic lights. This did not need me to run the simulator or a virtual machine.\n\nAt the time of writing, we are finishing this project and are expecting to submit it somewhen next week. After that, our journey in the SDCND is over! I\u2019m thanking David Silver, Udacity and the whole SDCND team for putting this program together. I have learned a lot and it helped me to transition into a new career. I will never forget that.\n\nIf you want to enter the Self-Driving Car Engineer Nanodegree yourself, do so by clicking the link and applying to the program. The views expressed in this article are my own!"
    },
    {
        "url": "https://medium.com/@dmonn/how-to-use-nvidia-digits-for-image-classification-79600acbe0db?source=user_profile---------16----------------",
        "title": "How to use NVIDIA DIGITS for image classification \u2013 Dominic Monn \u2013",
        "text": "The NVIDIA DIGITS system is an interactive Deep Learning training system which allows you to manage datasets, neural networks and their training on a simple web frontend.\n\nIn this short tutorial, I want to go through a very basic image classification task: Classifying the MNIST dataset using Yann LeCuns \u2018LeNet\u2019 architecture.\n\nThis README on the DIGITS repository on GitHub walks you through the installation steps for Ubuntu. You need to install CUDA on your machine first (given that you have a NVIDIA GPU). After that, you can install DIGITS, which will per default run on port :80. You might want to change that.\n\nFirst, you need to import a dataset. In our case, this would be MNIST. The DIGITS ecosystem already offers an easy way to download the MNIST dataset as such:\n\nAfter that, you can click on the tab \u201cDatasets\u201d and create a new one for \u201cClassification\u201d. You can now configure your dataset and then let it process.\n\nAt the end of processing, DIGITS gives you a nice overview of your dataset. Next up, we want to create our classification network and then train it on our MNIST dataset.\n\nTo do this, we switch to the tab \u201cModels\u201d and create a new model for \u201cClassification\u201d as well. This should display all options for the classification networks, such as the choice of the dataset and the learning rate.\n\nTo make it easy for ourselves, we choose the default \u201cLeNet\u201d architecture here. However, one could easily customize these architectures or even upload their own networks for a very easy way to train them. DIGITS also offers a way to visualize network architectures, which can come in handy.\n\nAll that is left to do is to kick off the training process, observe it and wait. DIGITS automatically plots the current loss and accuracy of the model, which makes it very easy to quickly see any signs of over- or underfitting.\n\nAt the end of training, DIGITS offers the option to download the pre-trained network or save it in DIGITS itself for future testing. You can also upload single or multiple images to classify them. In our case, the network had an accuracy of 98.8%.\n\nIf you have followed the steps to create a dataset and use it for image classification, you have now successfully classified handwritten digits using the MNIST dataset and the LeNet network.\n\nDIGITS is, in my opinion, a very good way to showcase new architectures and to play around with Deep Learning models. It\u2019s very easy and straightforward to set up and use. So now that you know how DIGITS work, create your own networks or perform some segmentation or object detection tasks. Have fun!"
    },
    {
        "url": "https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2?source=user_profile---------17----------------",
        "title": "Denoising Autoencoders explained \u2013",
        "text": "Autoencoders are Neural Networks which are commonly used for feature selection and extraction. However, when there are more nodes in the hidden layer than there are inputs, the Network is risking to learn the so-called \u201cIdentity Function\u201d, also called \u201cNull Function\u201d, meaning that the output equals the input, marking the Autoencoder useless.\n\nDenoising Autoencoders solve this problem by corrupting the data on purpose by randomly turning some of the input values to zero. In general, the percentage of input nodes which are being set to zero is about 50%. Other sources suggest a lower count, such as 30%. It depends on the amount of data and input nodes you have."
    },
    {
        "url": "https://medium.com/@dmonn/what-are-variational-autoencoders-a-simple-explanation-ea7dccafb0e3?source=user_profile---------18----------------",
        "title": "What are Variational Autoencoders? A simple explanation",
        "text": "GANs are awesome! But as we have seen in my previous post, they still generate pretty random results. I gave my DCGAN a huge dataset of celebrity faces, which led it to generate new, but random faces \u2014 which is fun for a research project, but quite useless for anything in production. What if I want to generate a specific face \u2014 for example, one with black hair, green eyes and a blonde mustache? What if I want to generate specific digits or letters? I\u2019m not able to configure a GAN to take these parameters into account. This is where VAEs are coming into play.\n\nJust like regular Autoencoders, VAEs try to reconstruct output from input and consist of an encoder and a decoder, which are encoding and decoding the data. The encoder outputs a compressed representation of the output data. The decoder then learns to reconstruct the initial input data by taking this compressed representation as input data. This way, you can use the decoder as a generative model which is able to generate specific features \u2014 such as specific digits or letters.\n\nI have found a simple implementation example on the Keras blog. They build a sample VAE to generate handwritten digits based on the MNIST dataset. If you are interested in building a VAE yourself, definitely check it out!\n\nBut where exactly can we use this type of neural network? Because VAEs are much more flexible and customizable in their generation behavior than GANs, VAEs are suitable for art generation of any kind.\n\nCarl Doersch briefly talks about the possibility of generating 3D models of plants to cultivate video-game forests in his paper and the blog \u201cMachine Learning Insights\u201d created a small tool to generate pixel art of a video game character just recently.\n\nThink about it: With the ability to generate customizable art of any kind you can generate video game characters and 3D models of trees \u2014 but also logos, drawings, personalized music and so much more! The possibilities are endless.\n\nSo there you have it! VAEs are an incredible tool when it comes to art generation of any kind and are possibly a tool to transform the work of creatives in the future. A VAE could potentially become a graphic designer\u2019s best friend when it comes to inspiration and prototyping.\n\nThanks for reading my article! Let me know if I got anything wrong or if you want to discuss the topic a little bit further. I\u2019m always up for a constructive discussion!"
    },
    {
        "url": "https://medium.com/@dmonn/generating-faces-with-deep-convolutional-gans-c0dac44c8d49?source=user_profile---------19----------------",
        "title": "Generating Faces with Deep Convolutional GANs \u2013 Dominic Monn \u2013",
        "text": "As part of my Deep Learning Foundation Nanodegree at Udacity, I have learned how to generate new faces using Generative Adversarial Networks, or GANs for short.\n\nIf you have no idea what GANs are, maybe first read this handy article by Dev Nag where you learn about GANs in theory and also implement one in 50 lines of PyTorch code.\n\nIn the last few lectures of the Deep Learning Foundation Nanodegree program, students learn how to apply and implement GANs and in this project, the goal was to use that knowledge to implement a GAN to generate new faces. The idea was to implement a Deep Convolutional GAN and train the architecture on the MNIST dataset. As soon as the architecture was able to generate new handwritten digits, it was ready to generate new faces using the CelebA dataset.\n\nWhen choosing the architecture of my DCGAN, I first settled for a simplified version of the Network described in the paper \u201cUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\u201d which you can see above. Instead of using four convolutional layers, I only used two \u2014 and the results accordingly were blurry and inaccurate.\n\nSo I immediately got back to work and used the initial architecture described in the research paper with a total of four convolutional layers. The training time drastically increased, but the generated digits speak for themselves.\n\nThis obviously meant that my architecture was ready for training on the CelebA dataset. The training took approximately 15\u201320 minutes and even though the first few iterations looked like something demonic \u2014 the end result was fine.\n\nThe results became recognizable as faces in the middle of the training process and refine themselves only a little bit until the end. This is the result after a single epoch. To make the faces less blurry, the training would need to go on a little bit longer.\n\nIf you want to check out my code, visit the project on my GitHub. All the code is on there! See you next time!"
    }
]