[
    {
        "url": "https://medium.com/@joey_tallieu/simple-gevent-latency-benchmarks-d68d6885fbdc?source=user_profile---------1----------------",
        "title": "Simple Gevent Latency Benchmarks \u2013 J. Clayton Tallieu \u2013",
        "text": "While we were gathering metrics about the delays and interrupts, I took some time to see if I could figure out where Gevent breaks down. I really wanted to understand if there was a saturation point. I was also concerned about the scheduling. Greenlets \u201cwill be executed one by one, in an undefined order\u201d according to the documentation. UNDEFINED ORDER?! This speaks to the scheduling of greenlets, and, if it was random, could greenlets starve, were some greenlets favored? I needed to know. Of course, I could just read the code for the scheduling answer but that\u2019s no fun. I like graphs.\n\nI read on StackOverflow, that around 100,000 greenlets, performance start to decline. I was curious in a few metrics regarding latency. When X number of greenlets are ready to execute, what is the latency for the first greenlet to execute AND what is the latency of the middle quartile? What is the range?My script was simple. Spawn X greenlets to wait on an event from the main greenlet, record the time and set the event to start the gathering. As each greenlet executes, it records the start time in a list.\n\nWhen the greenlets were all done, I computed the delta for each start time and plotted the results on the box chart below using plotly.\n\nFindings There is a noticeable increase in latency at 100,000 greenlets. Also, of interest is how much deviation or spread there is once you hit 100,000. This mean, below 100,000 greenlets, you are guaranteed a consistent latency. Above 100,000, the latency range increases.\n\nBelow is a link to the interactive Plotly data. Here is the plotter function to graph my results.\n\nNext up was to determine if the scheduling algorithm was FIFO, LIFO, or Round Robin. Spawn a bunch of greenlets, count the number of times they execute, and show the results.\n\nFindings The scheduling is neither LIFO, FIFO, or round robin. Notice the difference in ops at 500 greenlets. If the scheduling algorithm was either of the above, I would have expected to never see a difference greater than 2 ops.\n\nWe are always looking for devOps people to join our staff at Eagle Eye Networks Inc.\n\nEagle Eye Networks is a security and business intelligence video management company. Eagle Eye Networks provides a cloud-based, on-demand security and business intelligence VMS built on top of an open video API platform.\n\n**View this article on our company blog."
    },
    {
        "url": "https://medium.com/@joey_tallieu/weve-gone-to-plaid-delivering-at-ludicrous-velocity-64eccde4adfa?source=user_profile---------2----------------",
        "title": "We\u2019ve Gone To Plaid: Delivering at Ludicrous-Velocity",
        "text": "We ARE a high-velocity application delivery company. That\u2019s only been true recently, and the transformation has been exciting. This post chronicles how we recently approached and resolved an issue with ludicrous speed.\n\nI won\u2019t dive into the gritty details of our setup in this article. My intent is to illustrate our tight instrument, analyze, adjust cycles to continually deliver for the customer at high-velocity. In regards to the Spaceballs reference, I think our DevOps director would argue we only approaching ridiculous speed. He\u2019s got big plans.\n\nMotion alerts and system notifications are critical aspects of any video surveillance system. At Eagle Eye Networks, our customers rely on alerts and notifications to be timely and correct. During an incident, seconds matter.\n\nEagle Eye Networks customers can tailor motion alerts for certain cameras and regions. Camera motion regions have independent motion settings, alert levels, and recipients. Aside from motion alerts, Eagle Eye Networks also provides system notifications to indicate camera statuses (online/offline). Motion alerts are designed to be delivered immediately, while notifications about a camera state changes have some built in heuristics to prevent spamming users for momentary online/offline status changes, which are typical for networked systems.\n\nPrior to our recent update, the alert and notification system involved three components \u2014 a single alert monitor, a collection of archivers, and a collection of gateways. Archivers continually push device events (ETags) onto the poll stream. Both internal or external services can monitor the poll stream for various device events. The archivers also send out a heartbeat event reporting the current state of a device every 30 seconds. The alert monitor listens on the poll stream for every device for state change and motion ETags. When the alert monitor determines the event is valid, a notification is sent to the gateway service, where, based on the account settings, an email is sent.\n\nRecently, we noticed that alerts were delayed. Over a short time, the delays were becoming significant \u2014 sometimes hours. We had to react fast.\n\nWe verified the poll stream was delivering ETags on time, our email server was not queueing, and our gateway was responding immediately to the alert monitor. All signs indicated the bottleneck was IN the alert monitor. Was it picking up events on time? How many events it is processing? Is it over worked?\n\nWe love Gevent, so naturally, we\u2019d leverage the technology as much as possible for I/O bound tasks. The alert monitor\u2019s main thread spawns a greenlet for each account, which in turn spawns a device state machine (DSM) greenlet for each device. The DSM greenlet attaches to the poll stream for the device and begins listening for ETags and reacting accordingly. By simple math, we figured we were approaching several hundred thousand greenlets running in the monitoring service. Was this too many greenlets for one process? Did we hit some magic greenlet limit?\n\nWithout going any further [being up against time], we thought we might see some improvement by horizontally scaling the alert monitor service. Distribute the work across multiple alert monitors to reduce our greenlets per instance. With a little help from Peter, our DevOps director (by the way, he\u2019s hiring), this was a quick and easy rollout. Like minutes, really. We copied the alert monitor deployment for each of our 9 data centers, configured the alert monitor to only service accounts in that data center, and Bob\u2019s your uncle \u2014 we scaled."
    },
    {
        "url": "https://medium.com/@joey_tallieu/scaling-django-gevent-with-ldap-connection-pooling-d2c5cbb60a40?source=user_profile---------3----------------",
        "title": "Scaling Django+Gevent with LDAP Connection Pooling \u2013 J. Clayton Tallieu \u2013",
        "text": "Within the Eagle Eye Networks cloud, we have a series of application microservices that we consider our middleware. Our middleware provides services for both internal systems and our public API. Because of the large volume of requests handled by the middleware, the Eagle Eye Networks Middleware Team designed the service for performance using Django+Gevent with an OpenLDAP backed persistence model.\n\nGevent\u2019s Pywsgi Server has been proven to handle nearly 5000 requests/sec according to the Mixpanel Benchmarks. In our production environment, for the Austin datacenter, we run 30 instances of the middleware services with the ability to scale horizontally. Our top goal was maximum concurrency.\n\nIn early 2016 Eagle Eye Networks achieved a critical growth milestone. With the additional load on our system, we did not observe the performance we expected. Our metrics were disastrous. We were frequently saddled with sluggish performance and request timeouts. We suspected slow queries as the cause and began analysis, looking for bad indexing or long running queries. Our LDAP logs indicated blazing fast queries but also revealed an unusually high number of open connection from our middleware. Our LDAP server was periodically reaching the open file descriptor limit.\n\nIncreasing the server\u2019s connection limit only bought us a little time. We knew, going forward, this would not be a viable scaling solution. We quickly exhausted the number of connections again. Another outage! After extensive research we determined there were two issues at play. The first was a connection leak (look for an upcoming post). The bigger problem was Django+Gevent\u2019s connection management.\n\nWhy were we seeing massive amounts of LDAP connections from the middleware? We began to dive into how connections are managed by the middleware. Gevent\u2019s WSGIServer hands off each incoming request to a new Django.wsgiHandler Greenlet. The Django framework requests a new database connection on the first query and reuses that connection for the life of the request. When the request completes, the connection is cleaned up and life goes on. This was really bad news. This meant, for each concurrent request, there was one open connection to LDAP.\n\nHow could we run without limiting concurrency on the WSGIServer? Better yet, how do we avoid limiting our concurrency by the number of connections supported by our LDAP Server?\n\nAlso, the latency for each request was killing us. The latency for opening an LDAP connection got exponentially worse as concurrency rose. It appears that within the system LDAP Client library, opening a new connection was synchronous and sequential.\n\nThe obvious solution was to implement some sort of connection pooling and simply hand off open connections to new requests as they arrive. This would reduce the latency, but would still limit our concurrency. Considering connections are held for the life of the request, we\u2019d only be able to serve as many requests as there were connections in the pool. Effectively we would be limiting concurrency by the number of connections in the pool. We needed to maximize the usage of our connections across all the active requests.\n\nTo understand where time was going for a request, we looked at a simple endpoint. The GET /user makes two LDAP queries to fulfill the request. Historically, the GET /user request would complete in 150ms. According to the LDAP logs, the corresponding queries take between 3\u20138ms each to complete, for a total of 12ms. For the entire time that the endpoint is holding onto that connection, it\u2019s only used 8% of the time. We were wasting 92% of a precious resource. We needed a connection pool that multiplexed the connection across all the concurrent requests to maximize our connections.\n\nExcited by the prospect increasing our capacity by 92%, we forked the Django LDAP library and added pooling per query. The pooling library was simple. We gave it options to limit the size of the pool, a timeout so that we could scale down the number of idle connections, and a minimum number of connections to always keep open. And of course, as standard practice, we outfitted it with metrics so that we could monitor the free pool size using Prometheus. The pool provided methods to acquire and release connections.\n\nWe integrated the pool into the django-ldap backend to acquire and release connections for each ldap (query) operation \u2014 NOT at the start and end of a request. To accomplish this, we extended the django-ldapdb backend base.py, which provides the LDAP Django DatabaseWrapper. The DatabaseWrapper implements methods to give a database cursor (connection) to the framework when needed. By extending the _cursor method to acquire a connection from the pool, and the close method to release the connection, we were able to integrate with the LDAP pool. To complete the task we modified the add_, delete_s, modify_s, rename_s, and search_s methods to acquire a connection from the pool and release it when the operation was complete.\n\nTo measure the performance, we ran some simple load tests against the server with pooling and without pooling enabled. The load simply ran a specific number of threads each making 10 GET /user requests. Clearly, the server with pooling didn\u2019t flinch as concurrency went beyond 30 compared to the non-pooling server. The benchmarks were generated running the server and load in docker containers on a laptop, so the actual times are not what we see in production. The important take away from the data was that pooling gave us consistent and acceptable performance as concurrency increased. Good enough to try in production.\n\nIn the Austin datacenter, we run 30 middleware docker instances across 3 hosts (s141, s142, s143). Each instance\u2019s pool is configured to use up to 40 LDAP connections. That\u2019s a total of 1200 connections allowed, or 400 per host. Below is a snapshot of our pooling performance. Each vertical in the graph represents a host system, which aggregates the metrics for all 10 instances.\n\nRow 1: Free Pool Space The number of free slots (40 max) for connections. When this is zero, new connections cannot be created on demand. Connections are closed and pool space is reclaimed when a connection has not been used in 5 minutes.\n\nRow 2: Acquired Connections per minute When any query in the middleware is made, a connection is acquired from the pool and released when the query is complete. The graphs below show the number of connections used per minute.\n\nRow 3: Connections Created per minute New connections created per minute. When all connections are in use, the pool manager will create new connections if there is free pool space. Otherwise, the consumer will block until a connection is released."
    },
    {
        "url": "https://medium.com/@joey_tallieu/does-your-saas-provider-use-the-cloud-or-build-the-cloud-26ae71664037?source=user_profile---------4----------------",
        "title": "Does your SaaS provider use the cloud or build the cloud?",
        "text": "I was introduced to my definition of cloud in early 2007. It was around the time Amazon released Amazon Elastic Cloud Compute or EC2 in 2006. A good friend and colleague dropped by and said, \u201cHey Joe, let me show you something.\u201d Whenever Vijay said this, you stopped everything and gave full attention, because he was about to crush your belief system or send you off doubting your own existence. He was in the limited public beta, and introduced me to EC2.\n\nAt that time, this was a real game changer for a developer with an entrepreneurial spirit. Before EC2, there was a slight barrier for someone to create a new service. You had to build hardware, host it somewhere, pay for enough bandwidth and maintain those things. It was a real investment to stand up a service on the internet. Most everything I did up to this point in my side-hustles were isolated experiments contained in my lab.\n\nThen EC2 came\u2026 Now we could have a fully networked server with beefy compute power on a whim. Wanted to try a thing? Go get a new EC2 instance and build it. Don\u2019t like it. Destroy it. You paid for as much as you used. This meant the initial cost barrier to try something was really really low. You were not heavily invested.\n\nThe capabilities provided by the cloud expanded and other players entered the cloud market. You had Rackspace, Microsoft Azure, Digital Ocean and other big players like Dell offering compute in the cloud to run your software. You had PaaS atop those providers, like AppFog and DotCloud (makers of Docker) giving away ready made LAMP stacks. And the value adds kept coming. MongoDB in the cloud, Stripe for secure credit card payments, and on and on.. It was trivial and virtually free to cobble together a web service around 2011. I know, because I did just that.\n\nIn 2011 over the 2-week Thanksgiving for a total of $44, I built an inventory managment system bridging Point of Sale and E-commerce systems on DotCloud for a monthly fee. But, I would not consider this a cloud service. It was a service built ON a cloud. I did not build a cloud.\n\nI know from experience, like myself, many companies have been able to capitalize on a small investment by building IN the cloud...stitching together other SaaS platforms. Some eventually turning them into a successful business or a useful service. As a consumer of these services, you are once removed from the underlying cloud supporting this service and are a bit exposed to the risks that your provider has accepted on your behalf.\n\nWhen Eagle Eye Networks reached out to me about working on their middleware API, I was intrigued not only because cloud video surveillance sounded sexy, but because it seemed like they were HEAVILY invested in their product. Doing a little research on Dean Drako made it clear that this was no ordinary Austin-type start-up. I didn\u2019t fully comprehend the difference, but my \u201cspidey sense\u201d was tingling, and I wanted to find out. I was in.\n\nIn my early days at Eagle Eye Networks, the way they did things was at odds with what I was used to. And I was naturally resistant and skeptical to some of the practices. I could not comprehend why a company in this age would not use AWS or Rackspace. Or use Amazon S3 for storage? It seemed unnecessarily costly to build it all yourself. Then it became very clear to me. They are BUILDING A CLOUD, not building IN A cloud. They were making that serious investment I mentioned earlier on behalf of it\u2019s customers who are serious about security. We are in the security business.\n\nThe important distinction between building a cloud and building on the cloud became evident twice since I started at Eagle Eye Networks. The first was the world-wide DDOS attack that brought down the internet in Oct 2016.\n\nWe didn\u2019t notice a thing. Except that, because we ourselves use cloud services, our development and business operations were halted. But the service we provide to our customers did not blink.\n\nThe second instance was just yesterday, when Cloudbleed became a new term.\n\nGuess what? We are the cloud. We do not use Cloudflare, so our customers are not impacted.\n\nWhen choosing to use a cloud service it\u2019s important to understand how these services are built to properly assess the risk. Making the decision to rely on the cloud can be scary.\n\nIs the service you are choosing, built in the cloud, or are they building the cloud? Eagle Eye Networks is building its own cloud and does not leverage other cloud services in its product. This is an important distinction to understand when selecting a cloud video surveillance company. From the decision to build the cloud to the architecture of the edge devices, it\u2019s all about cyber security at Eagle Eye Networks."
    },
    {
        "url": "https://medium.com/@joey_tallieu/case-studies-in-cloud-base-video-surveillance-677c850085c4?source=user_profile---------5----------------",
        "title": "Case Studies in Cloud Base Video Surveillance \u2013 J. Clayton Tallieu \u2013",
        "text": "Working as an engineer is often an isolated and lonely profession. Most of the day is working with diligent focus on a particular problem you are trying to solve. No matter the industry, the engineering team is often once removed from the actual customers of the product you are building.\n\nI work for Eagle Eye Networks, building a new vision for video surveillance. Eagle Eye Networks offers a cloud based video surveillance system designed for enterprise customers. The field seems colorful and exciting. We are managing video feeds for thousands of customers world wide. By large contrast, as engineers, we are a bit isolated from this live world of feeds we are managing.\n\nEveryone at Eagle Eye Networks is bound by a strict policy of not accessing customer feeds unless it\u2019s in response to resolving an issue on behalf of a customer. So for the most part, the only time we actually get to see what\u2019s happening in the outside world is when helping our support team troubleshoot an issue. Our world as engineers is watching and working with large volumes of ascii all day.. so much ascii.\n\nAs as engineer, it\u2019s a morale boost to see the end result of what we do and how we are impacting real world customers. To that end, I often visit our own www.eagleeyenetworks.com to get a glimpse of what we\u2019ve accomplished. I was thrilled the other day to see a new section on our site that showcased some of the installations as case studies and the motivation and problems our customers are solving with Eagle Eye Networks Cloud Surveillance System."
    }
]