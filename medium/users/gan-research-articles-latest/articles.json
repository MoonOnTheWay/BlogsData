[
    {
        "url": "https://medium.com/gan-research-articles-latest/dynamics-of-gans-m-i-t-undisputed-champion-of-research-for-the-past-156-years-3d5280a60a7f?source=---------0",
        "title": "Dynamics of GANs- M.I.T- undisputed champion of research for the past 156 years.",
        "text": "MIT is known for its elegance and style with which it approaches a problem and it is so clear in their latest paper titled \u201cTowards understanding the dynamics of Generative Adversarial Networks\u201d.\n\nI was waiting for a paper to come out describing the dynamics of GAN since it would give us a lot of information about how our Discriminators and Generators are performing. It is very clear now in the ML society that GANs suffer from training instability. Thus efforts had been taken to identify the common problems and out came mode collapse, vanishing gradients for generators etc.\n\nBut this paper fundamentally differs from all the other ones ( obviously its MIT ;), this one does not aim to solve the problem at hand but has made a very mathematically taxing effort towards first understanding the problem. This paper gives us hope through mathematical revelations but also poses the community with more bad news such as discriminator collapse.\n\n\u201cIf I had 8 hours to chop down a tree, I would spend 6 of those hours sharpening my axe.\u201d -Abraham Lincoln.\n\nIn this paper the researchers have made an attempt to understand what is happening when we are training our GAN and have also proposed some clear mathematical proofs as to why their claim holds true. In order to make in simpler the dynamics which this paper studies relates to how the optimization process converges a.k.a training finishes and GAN is good. In order to study this problem we need to try to transform our thinking to the world of functions and understand the practical problems in our training journey.\n\nI am still in awe of how MIT always achieves such incredible results. This paper shows the problem of training GANs through the conventional MIT technique of abstracting larger problems with simpler problem statements. This paper does this in the aspect of studying the dynamics of a system (GMM-GAN) which is kind of known and try to generalize the results and observations to neural network based approaches but sadly only linear ones.\n\nThis paper has a lot of building blocks and the proofs in the appendix is pure mathematical euphoria for people like me. I am going to only discuss about the main contribution of the paper, thus certain proofs which I say exist do exist in the optimization world.\n\nGMM-GAN is a variant of GAN which captures the learning of a mixture of two univariate Gaussians. In some of my previous posts I had discussed that since GANs are min max problem if we have an optimal discriminator or in other words one part of min is solved to the best then all we need to do is max the generator. But this paper poses the question \u201c But who said so? \u201c.\n\nThe paper defines the GANs dynamics of the above variant and introduces nuances in order to simulate commonly known problems such as mode collapse and vanishing gradients. For this purpose the researchers have assumed that both the true data distribution and the generator distribution are a mixture of two univariate gaussians and uniform mixing weights, thus creating a problem of multi-modal density estimation.\n\nThis leads us to setting up the problem in this manner. There are two generated distributions with varying means ( this translates to generator producing two different images a.k.a multi modal) and then the loss function of the discriminator is identified as finding the total variation distance between these generated distributions and the real distribution. We all know that in real time, sampling is done and thus the authors have made use of the maximum over all the events which happen in order to account for the worst scenario possible.\n\nThey go ahead and define that the loss function for such a problem is comparable to certain previous mathematical proofs and similar analysis can be carried out here too. In order to measure the difference between two generators we focus on the union of two disjoint intervals in the real domain. This translates in a simpler manner as follows, the cops are trying to identify two different suspects. Thus in order find them out we need to focus on two individual killings over time which are not similar so that we are confident that there are two killers around.\n\nThe main use of defining our loss function like this is that we know this kind of problem\u2019s solutions parametrically. Or in other words we know the best cop for this kind of job already. So with the above definition the cops measure indicator functions ( Idiosyncratic trails left by both these killers) as sets of features over two disjoint time intervals. When we define the problem statement like this and use alternating stochastic gradient descent to generator and discriminator we see all common problems of mode collapse, vanishing gradients and this proves this problem\u2019s analysis will give us insight into the dynamics of general GANs. This kind of dynamics is usually called first order dynamics since we use only the gradient and not the gradient of the gradient a.k.a acceleration during our updates.\n\nNow that we have identified the problem\u2019s representation power the researchers go forward to compare first whether an optimal discriminator actually helps us in this first order optimization problem. They have proven mathematically that if the means of the generator modes are bounded and are far apart from each other by some distance then the optimal discriminator dynamics converge with total variation distance in time which is given by a polynomial function of accuracy needed and how far apart the two means were. The proof basically shows that we need the two means to be far apart so that we have good gradient information.\n\nThe best part about this paper is this section which shows how the first order dynamics affect the width of the intervals in which the discriminator is defined.\n\nThe above graph shows us two lines. The solid line is difference between the generated and the actual data\u2019 probability density function. The dotted line running horizontally is the generator\u2019s probability density function. The shaded areas are the interval functions where the discriminator is defined.\n\nNow with the above graph in head it is seen clearly in (b) that the optimal discriminator in the above case would be one which classifies all positive differences from the data distribution as one class and all the negative examples as the other class. In the way the min max game is formulated the discriminator has always an incentive to place mass a.k.a on the positive difference over the negative ones.\n\nIf we start with two discriminators as in (a) then the first region of the discriminator is the negative difference region and this interval never increases in width because of its underlying dynamics always asking it to place mass in the positive difference side. Thus the opposite happens and this interval shrinks in its width and becomes a line. This is what the researchers define as discriminator collapse. They have also shown that this phenomenon exists even in unrolled GANs. This above phenomenon can be rephrased and understood that mode collapse happens whenever the PDF of the generator is very large than the discriminator\u2019s PDF.\n\nIn a more practical sense with neural networks this means that the discriminators get caught at local points which ask them to reduce their representational power through their updates. The researchers also attribute this collapse to first order dynamics unable to have the power to model the dynamics to reach the optimal discriminator and thus capture only part of that magic network\u2019s structure. In our cop theory it just means that the cops go on an undercover operation to the hood and slowly believe that the hood are the good people and the cops are bad.\n\nThis section is filled with mathematical proofs and my only aim here would be to give an understanding of the final result which this paper has come out with. They have shown using various lemmas and proofs that the optimal discriminator\u2019s intervals can be computed by reasoning out the structure between the current mean estimates and the true means. Once this is known we also have the power to compute bounds over its gradients and hence its update function.\n\nThe basic idea behind all this is that once we know that the initial means of the generator are far from the true means, the zero crossings ( these are places which indicate saddle points) cannot blow up infinitely. Once this holds then the zeros of the function can be captured using other methods.\n\nThe paper first says that in order to catch two different suspects we need to make sure that the cops are never misinformed with the picture of a good man to be the thief. ( This corresponds to discriminator being placed in the negative difference zone). If this happens then any cop would slowly lose his sense of judgement as he catches more and more good people and is slowly collapsed to an insignificant cop in the operation. The researchers also say that if initially these two suspects are very different from each other then by studying their methods (interval functions) we can figure out the time when they could make another attack and thereby in polynomial time catch the criminals. But the researchers have also made some assumptions about the type of the crime and people involved a.k.a the type of the function Lipschitz etc.\n\nThe researchers have made this function to follow three rules:\n\nThe above assumptions for functions studied are reasonable and thus give researchers an idea of how this training of GAN actually progresses with time. The problem of discriminator collapse is interesting since if there is a collapse happening in the cops also this leads us to identify regions where both of them collapse and why such situations arise. I also believe this paper is giving us an idea of how to approach the understanding of optimization dynamics and the same ideas can be extrapolated to understand supervised learning."
    },
    {
        "url": "https://medium.com/gan-research-articles-latest/geometric-gan-here-comes-the-hyperplane-split-d1c14cd4fd23?source=---------1",
        "title": "Geometric GAN \u2014 here comes the Hyperplane split \u2013 Generative Adversarial Networks- Latest Research articles and ideas \u2013",
        "text": "We all know that the generative adversarial networks operate on probability density functions and compute a distance in the probability space to compute a discrepancy metric to differentiate two samples from real and fake. We also know that since all density functions are plotted in space we can expect some sort of abstract geometry to be present when it comes to optimization of higher dimensional features. This paper aims at finding the underlying geometry in GAN training and also proposes an efficient method to identify a hyperplane to separate the data samples. They also go ahead to use a support vector machine for the binary classification task since SVMs are very efficient in classifying data distributions separated by lines or planes. They also show that the GAN converges to Nash equilibrium \u2014 the magic spot for GAN researchers.\n\nWhat does any researcher working on GAN know ? \u201c The training process is extremely fragile and lots of care has to be taken during the training to achieve Nash equilibrium\u201d. This training is mainly affected by two major problems, the first one being that with an optimal discriminator the generator gradient vanishes. This is like saying that the counterfeit producers stop improving their technique because the cops are just too good for them. There is no incentive for the generator to improve since it always loses and also faces singularity (mathematically infinity) at the denominator when the discriminator is too good.\n\nThis paper aims to improve upon the results of the paper McGAN which uses Mean and Covariance matching using the IPM minimization framework. Kindly refer the post on MMD GANs by me for more insight into these kind of GANs. The paper claims that there is a geometric generalization in McGAN which can be split into three individual regions. Once this geometry is known all we need to do is to inform the generator and discriminator to go in opposite directions towards and away from the hyperplane to achieve our goal of GANs.\n\nGoing back to the explanation of the cops, this paper resembles the fact that a cop does a two sample test by arresting two suspects and then uses the F.B.I a.k.a the SVM to identify how good or bad is this suspect in comparision to other suspects and places them in a small city a.k.a SVM\u2019s margin. This city has borders where the really good people live which are the samples which are classified as real by the discriminator. Now once this information is tuned to be very good, the generator tries to infiltrate this city so that the F.B.I is tricked into identifying the generated sample also to be good. The main point to note is that majority of the work is done by the F.B.I and all we have to care about is making the generator good enough to fool the F.B.I thus making the optimization easier.\n\nThe paper goes about introducing the McGAN which is very similar to the MMD GAN about which I have written a small review in this same publication. Then the author converts the primal formulation of the McGAN into another form using a very famous mathematical inequality known as Cauchy-Swartz Inequality in order to improve the geometric information which the cost function is hiding.\n\nThe beauty of mathematics is seen in the next section where once the formulation is done using the above inequality, the optimal weight parameter solving equation for the discriminator becomes the direction which specifies the direction of the separating hyperplane for the mean difference classifier. Thus once this is identified the next steps are to move parallel to this normal vector direction towards and away from the hyperplane thereby solving the optimization problem.\n\nThe other intuitive contribution is that this hidden geometry in GAN training can be realized in the variants of various GANs which have been out till day. When two linear classifiers are compared, the comparison actually means that we are comparing the directions of the individual samples normal vector. Thus the variant of the GANs , correspondingly differ in the manner in which this direction is defined and also by the scaling factors. We have created a pool of GAN which define discrepancies using various distances geometrically and thereby produce different results.\n\nWhen the minibatch sample size in practice is very much smaller when compared to the dimension of the feature space d, the problem is known as High Dimensional low-sample size problem (HDLSS). In the previous section, I had mentioned about mean difference classifiers. These classifiers selects the hyperplane which lies exactly halfway between good and bad distributions. Thus the normal vector of the hyperplane is just the difference of these two class means. The HDLSS problems also come equipped with piling of data in one particular direction which is not favorable.\n\nSupport Vector Machine is based on geometrical heuristics applied to an optimization problem to maximize the margin between two classes of different data. The variant of SVM known as Soft-Margin SVM aims at not only balancing two competing objectives but also penalizes the points which are on the wrong side. This post gives better details about SVM individually which helps in the understanding of this paper.\n\nThe basic idea is that SVMs achieve binary classification by using tuning parameters C and also allows for a small slack in samples being on the wrong side of the separating hyperplane. The SVM is defined as a region between the boundaries of these classes distribution and the goal is to increase the margin or this area between these two classes. The SVM\u2019s cost function is assigned with values of one when it is within the margin boundaries and zero when it lies outside, since the SVM only cares about the feature vectors within the margin boundaries. Now once this cost function is well defined the discriminator\u2019s goal is explicitly clear ,which is to move the data samples to the margin of these boundaries and thereby increase the area.\n\nNow the generator update would be to try to move fake features towards this separating hyperplane so that they can be classified as true feature vectors. Thus by using a linear classifier this can be achieved where the linear classifier gives us a measure of how close the fake samples are to the separating hyperplane and we minimize this distance.\n\nThe authors also claim that when a soft margin SVM\u2019s cost function is minimized using discriminator and generator functions with closed form expressions, the equilibrium falls to Nash equilibrium which is the sweet spot we need our GANs to be in order to produce data samples which are indistinguishable from the real dataset. They have also provided the readers with a hands-on example which helps us understand that when the above condition is satisfied the SVM\u2019s cost function turns out to be two which is indicative of the fact that the real and fake samples are not separable and lie on the separating hyperplane.\n\nThis paper explains us with the concept of geometry lying behind GAN training. The paper also helps us in identifying an optimal hyperplane which separates the two data distributions using Support Vector Machine. But for researchers getting inspired from this work, I would say the last section where they have shown the various scaling factors and divergences for f-GAN is a proof of work indicating how Geometry manifests itself in GAN training using divergences. This work opens research in changing the training regime of existing GANs from alternating gradient updates to controlling the balance at which the two networks are updated in order to reduce the training stability issues such as mode collapse and gradient vanishing.\n\nTheir appendix section about how this geometric GAN is superior to EBGAN explains the fact that in EBGAN the margin is defined on the discriminator output values. Whereas in the geometric GAN the margin is defined by using concrete geometric distance between feature vectors. This paper provides a promising approach to stable GAN training by exploiting the underlying geometric structure of the optimization manifold."
    },
    {
        "url": "https://medium.com/gan-research-articles-latest/mmd-gan-thanks-to-david-hilbert-6f3f7f00ddfe?source=---------2",
        "title": "MMD GAN- Thanks to David Hilbert \u2013 Generative Adversarial Networks- Latest Research articles and ideas \u2013",
        "text": "\u201cGenerative Moment matching networks\u201d- as fancy as the name sounds, the mathematical technique used in this paper is equally fancy and contributes to the research of many such as Deepmind where they stumbled upon the same objective function in the dual domain. This paper aims to make use of an well-known mathematical technique known as two sample testing to replace the discriminator. It also makes an attempt to achieve realistic results using the magic of autoencoders and IPMs.This paper has a lot of different blocks which come together so i apologize for the lengthy read but I promise its every bit worth it.\n\nThe paper has made use of a mathematical technique known as two-sample test to completely replace the discriminator and then use Integration probability metrics to compute the distance between the distributions. Now going back to our age old explanation, the single cop here has been replaced by a cop who takes two samples and finds out the suspect right. Now how would a person do it ? We would compute some metric in our head which is the probability that a particular person is good or is the suspect. Once we compute that we would go ahead and measure the discrepancy between these two distributions to get a measure of our confidence in our decision.\n\nThe same ideas translate magically into the mathematical world which is the main research area which has been studied in this paper and the researchers have also done a wonderful work in implementing statistical ideas through neural networks. It is amazing how different departments of mathematics, control theory and computer science confluence in deep learning where the ultimate machine is being developed.\n\nThe GAN framework can be viewed as a min-max game which is how the original author Ian Goodfellow imagined it to be. But game theory is not the only solution to this particular min-max game since distinguishing between two samples from two different data distributions has been studied extensively by statisticians. They map the probabilities density functions for these two samples and find the distance (most of the optimization for GANs are done over various distances as we have only the spatial domain in maths) between these 2 distributions. Now the selection of this metric as to which would accurately tell me the representation falls under Integration Probability Metrics (IPM). The very famous Wassertarian GAN is using the Wasserstein distance as the IPM and is continuous most of the places hence more reliable. IPM used here in this paper is kernel maximum mean discrepancy(MMD). The kernel technique has the advantage that if a characteristic kernel is applied then it would output zero only when both the distributions are the same. Therefore this replaces the discriminator and we need to only maximize the generator.\n\nNow with the above concept in mind the kernel is a magical function which helps us in estimating this vital MMD distance metric. for more details this paper helped me clearly understand phi-divergences and IPMs.\n\nNow going back to the cop concept the kernel is like a lie detector and helps us in investigating the two suspects who we have rounded up. As with all machines even this lie detector has sometimes errors. In order to accommodate for this error in measurement we need to use instrumentation techniques to calibrate it to perfection. The hypothesis test helps us in doing this by setting a threshold for samples rejected. But this test doesn\u2019t tell us whether we are far away from the actual measurement or not but just tells we are wrong or right. Thus we cannot totally rely on only this lie detector. The researchers have therefore used a learning setup for the kernels too. As the saying goes\n\n\u201cThe capacity to learn is a gift: the ability to learn is a skill; the willingness to learn is a choice\u201d -apparently not for neural networks, all the neural networks gotta do is learn learn learn.\n\nLearning this setup comes with its own problems one of them being that in order for the kernels to remain characteristic (generalized about which we know something) the kernel combination functions must be an injective function. There are other constraints of Lipschitz functions too but luckily most of our feedforward neural networks satisfy them. The maximum gradient conditions are satisfied by weight clipping (cutting the weight updates of discriminator beyond a threshold).\n\nI would like to take a moment for the brilliance of the researchers to have found connections between this statistical method and aligning it to deep neural networks. Injective functions are a class of functions which can be encoded and decoded successfully and there comes the magic of autoencoders which are very successful approximators of injective functions. So if the two sample test is good enough all we need to do is to train the generator to fool this test.\n\nNow in this particular MMD GAN the researchers have used an encoder which transforms the base data to a feature transformation and then the two sample test is done on this space. Thus the optimization in this paper involves finding a manifold which gives better outputs for the two sample test. I believe this idea would benefit from energy GANs where we try to model the energy of non-admissible values to be as far away from the real energy manifold as possible.\n\nNow I also said that the kernel is learnt but learning all possible combinations is apparently not even possible by machines \u201cyet\u201d. So to reduce the allowable functions, constraints are applied and a penalty is applied only when the constraints are violated.\n\nTo sum it all up the cops arrest two suspects and then use the lie detector a.k.a kernels to compute the distance between the probability density functions of these two suspects. In order to be really good a.k.a optimal the cops make use of lie detectors which can transform the suspect\u2019s statements into different quantities such as blood pressure etc of the suspect when the statement is uttered a.k.a encoding data. Then this information is decoded by the doctor a.k.a decoder and both the machine and the doctor work in unison to detect lies from suspect always. The generator being the hero in our case is just made sure he fools the lie detector and the doctor by crafting wonderful samples. The lie detectors are continuously learned as to which is the best for this particular person from a predefined set of machines a.k.a. characteristic kernels. The doctor here uses the IPM metric defined as maximum kernel mean discrepancy to measure the lies.\n\nThe paper also finds out that when the kernel used is a linear the objective is similar to Wasserstein GANs. This fact again reflects on the fact that all the IPMs are just varied definitions of finding out the same quantity and when manipulated like using a linear kernel we would stumble upon the same metrics. Thus the paper makes the claim that WGANs are first-order moment matching networks whereas their method since the kernel is an autoencoder and we do not specify the order of the moments which have to matched, MMD GAN is a an infinite order moment matching networks.\n\nNow the Energy based GANs (EBGANs) work done by Yann Le Cunn also uses an autoencoder for the loss but this MMD method differs in the fact that when EBGANs try to minimize and maximise the reconstructions errors of the data and generated samples, MMD GAN minimises the reconstruction errors of invertible functions of both data and generated samples. There are many other GANs similar to this method but this method clearly differs due to the adversarial training given to the kernel through an autoencoder thereby generates data directly from the generator\u2019s probability density function.\n\nThe paper contributes in two major sections, one being the usage of two sample testing to replace the discriminator in GANs and other other being the application of autoencoders as approximators of invertible functions and constantly learning the kernel due to this. Now apart from the various suggestions for future research given in the paper such as using Wasserstein distance for autoencoder loss instead of data and using adversarial training only for latent feature matching, I would like fellow enthusiast and researchers to make a note about the various IPMs in two sample testing and trying to adapt them to the structure of the GAN game. This is the magic skill which A.I researchers have and deserve all the credit for. If it were not for David Hilbert in identifying the Reproducing Kernel Hilbert Space (RKHS) which is at the core of this method, this work would have been impossible."
    },
    {
        "url": "https://medium.com/gan-research-articles-latest/dualing-gans-is-stochastic-gradient-descent-going-to-be-replaced-f240c01e9114?source=---------3",
        "title": "Dualing GANs- Is Stochastic Gradient Descent going to be replaced?",
        "text": "The power of Generative Networks has been upgraded with the advent of Generative Adversarial Networks introduced by Ian Goodfellow. The concept of GANs is so simple yet elegant in its own mathematical construct. I am sure people are familiar with the concept of GANs and if not please go through this link\n\nThis research paper titled Dualing GANs is the latest publication related to GANs from Google Deepmind and its absolutely fascinating for a Machine learning enthusiast like me.\n\nThis paper aims to solve the most famous problem related to GANs \u201cHow do we train the goddamn thing and Be Stable?\u201c. The most common issues include mode collapse, vanishing gradients and divergence. Since stability is such an issue the model suffers from sensitivity to hyperparameters. So coming back to the native explanation of Discriminators being police and Generators being the fake sample makers, this paper tells us an intuitive observation that the cops need to be trained to optimality first thereby making it easier for us to focus only on optimizing the Generator.\n\nMathematics and the work done by great individuals such as David Hilbert allow us to dualize parts of the objective function thus helping us achieve our above target without falling for the trap of alternating gradient update.\n\nThe main research finding of this paper would be this dualizing of the training and its application to linear and non-linear discriminators. But for me personally the paper is so impressive in the way it has been written with crystal clarity in the ideas and supporting hand-solved mathematical examples. So the question remains, Is this paper going to end stochastic gradient descent in neural networks ?\n\nEvery normed space has a \u201cdual\u201d space of (continuous/bounded) linear functionals, i.e. mappings which eat vectors (which might actually be functions) and spit out numbers. Thus by dualizing the objective function of the discriminator we change its objective function from min to max thereby achieving a max-max game which is easier for optimization. There is another advantage that there are usually lesser variables in the dual than the primal formulation.\n\nThe paper goes on to talk about the application of this idea to linear and non-linear discriminators and the appendix has supporting proof for their claim. I would like to keep the mathematical notation as less as possible in this review and try to explain the concepts in a more understable manner.\n\nSimilar to the way we solve control problems in the Laplace domain, this dual transform takes the discriminator to a dual space first and its new cost function is formulated in the dual domain and is observed that the final formulation is similar to MMD GANs. I have added more details about MMD GANs in another tab in this publication. The wonder of mathematical notations is that they always convey a intuitive observation which in this case is that the cost function tries to match the empirical data and generated sample\u2019s observation. I would like to stress on the word observation since our samples are stochastically observed from a wide sea of data samples.\n\nSince this cost function is formulated in the dual domain it is constrained. ( Dual domain has various constraints in the way it is defined) Thus we have to solve the stochastic optimization using a different solver like Interior point Filter line search algorithm-IPOPT. Control engineers have been using optimization schemes like Interior point and Active set solvers in model predictive control and this papers is a proof of how control theory concepts trickle down to deep learning-the ultimate control system.\n\nIn order to extrapolate the same concepts of linear discriminator into the more complex non-linear world, the researchers at Deepmind have approximated the the primal objective function of the cops a.k.a discriminator around a point into a model function. Once the model function is known the update of the parameters is just stepping in direction which maximizes the primal or dual objective. The power of of approximation obviously depends on the way the model functions are formulated- the architecture for the discriminator used.\n\nIn order to understand this entire concept in a more easier manner let\u2019s assume now we know how our cops are going to perform on some city and we model it as a function. Once that is done we see ways to make the function very easy to compute and understand it in both domains a.k.a linearization. After this step we ask the cops to go search in some street of the city and keep giving it information as to whether this street can be trusted to improve my final score and build a trust region which is specified by the number of streets in the region a.k.a step size. If this routine is tuned to optimality i can inform the counterfeit to stay as far away as possible from this region using its own cost function.\n\nNow the researchers have used two techniques for linearization, cost-function linearization and score-function linearization.\n\nMost engineers would have been taught that non-linear functions can be approximated used taylor\u2019s expansion and that is exactly what is done to the cost function at some local point. This method also gives us the additional perk of being able to compute the step size analytically. Voila this opens research in application of this method with different model functions and linearization techniques for optimization of non-linear functions used in other supervised learning models.\n\nThe score function linearization is taking the score at which this model based function is performing directly with step updates and optimizing it w.r.t to the weights of the discriminator to improve the primal or dual score. Based on the previous explanation the score function is directly seeing how the cops perform on streets and optimizing it on the go to build the trust region. Whereas the first method involved computing the streets to search in analytically by taylor series expansion of the primal cost function. Now we need to take care that when we formulate the score function it must reflect the actual cost function and this has been done with dual formulation in the appendix of the paper and this is the place where all the different parts of the paper come together in symphony.\n\nAs explained in the above sections, I believe the major takeaway for a researcher from this paper would be the application of duality to GAN training rather than going for improving the Integral Probabilistic Metrics (IPM) or the divergences like other papers. The innovation of the researchers is explicitly seen in the way the dual formulation has been achieved mathematically by introduction of auxiliary variables and usage of acceptance ratios for the trust region optimisation. This paper is going to start a whirlwind of research in supervised,unsupervised and reinforcement learning. So is research in GANs going to be like f1 racing where the technology finally trickles down to other machine learning models too ?"
    }
]