[
    {
        "url": "https://medium.com/zeg-ai/future-of-ai-how-long-before-ai-overtakes-humans-12ad88196a01?source=---------0",
        "title": "Future of AI : How long before AI overtakes Humans.",
        "text": "Last week has been interesting for AI; with two of the tech stalwarts locking horns over the way AI is expected to unfold in future. It all started when Mark Zuckerberg told the reporters that warnings against artificial intelligence are pretty irresponsible.\n\nand yes, Mark was probably referring to Elon Musk \u2014 who has been quite vocal about the potential dangers that AI poses to humanity. And, here\u2019s what Elon had to say to this:\n\nPretty interesting, huh ? Though we can\u2019t be sure who\u2019s among the two is right, but we can certainly try to estimate how far have we come in terms of development of AI ?\n\nIn the recent times, arti\ufb01cial Neural Networks have doubled in size roughly every 2.4 years (primarily driven by the availability of faster computers and larger data sets). The larger networks are vital because they\u2019re able to achieve higher accuracy on more complex tasks. However, unless new technologies allow faster improvement, the artificial neural networks would not have the same number of neurons as human brains until at-least 2050's.\n\nIn comparison, today\u2019s networks \u2014 which are considered quite large from computational point of view \u2014 are still smaller than the nervous system of relatively primitive vertebrate animals like frogs. Also, biological neurons represent more complicated functions than current arti\ufb01cial neurons, so biological neural networks may be even larger than what this graph depicts. Well, it seems that we still got some time to settle the debate, or maybe prepare for the Armageddon.\n\nPS. You can follow me on Twitter: @smilesikand"
    },
    {
        "url": "https://medium.com/zeg-ai/voxel-to-mesh-conversion-marching-cube-algorithm-43dbb0801359?source=---------1",
        "title": "Voxel to Mesh Conversion: Marching Cube Algorithm \u2013 Zeg.ai \u2013",
        "text": "The \u2018Marching Cubes\u2019 is a simple iterative algorithm for creating triangular surfaces for a 3D function (in our case the 3D function is defined point wise and is called voxels).\n\nIt works by \u201cMarching\u201d over the whole 3D region which has been divided into cubes. The vertices of the cube are the voxels. The algorithm then computes whether a triangular surface passes through this cube or not. For a high level intuition say if the corners of the cube(the voxels) are all 1. This would mean that the cube will lie entirely inside the surface. Similarly if the voxels are all 0s then it would mean the cube lies outside the surface. In both the cases there would be no triangular surface passing through the cube. The main aim of the algorithm is to calculate the triangular surface (its intersection points, normals) in the cases where some voxels are 1 others are 0 (inside a cube). As there are 8 voxels in a cube which can have value 0 or 1 we have 2\u2078 = 256 cube configurations.\n\nThe ingenuity of the algorithm is the way it handles the calculation of 256 configs by:\n\nConsider the 2D variant of the problem. We need to divide it into polygons. We divide the whole area into squares (in Marching cubes we divide the area into cubes).\n\nNote here the blue region is the desired shape, the input will be the voxelized representation. In 2D the voxels correspond to the red points.\n\nNow we can see the square configurations. For squares having all vertices red, no boundary should pass through it. Same is the case for cubes having all blue vertices. For the other cases , the marching cubes algorithm will hash how the boundary should pass through the squares.\n\nAs there are 4 vertices we have 16 cases.\n\nUsing the above we mark the intersection points.\n\nThe pink dots are the points of intersections of the boundaries with the edges as calculated by the algorithm. Finally given these a mesh rendering system can create a mesh representation as shown.\n\nAlthough the representation is decent, the mesh boundaries are still not quite accurate. The accuracy can be increased in 2 ways:\n\n1. Decrease the area of squares.\n\n2. Better interpolation strategy.\n\nDecreasing the area of the squares (increasing the number of squares) will lead to increased computational cost.\n\nInterpolation strategy: in the example above after determining the configuration of the cube we simply marked the midpoints of the edges as the intersection point. A better strategy (as given in the original algorithm) is to mark the points of intersection by a linear function (the true algorithm simply uses mass point average). The output obtained from this modification is:-\n\nThe following figure shows the nomenclature of edges and vertices.\n\nSay only vertex 3 (or voxel at vertex 3) is 1, then the triangular mesh through the cube will cut edge 3, 2, 11. Note the same surface should be obtained when only vertex 3 is 0 rest are 1. (this reduces the number of cube configurations from 256 to 128).\n\nThe authors of the algorithm encode the information (which vertices are within or outside the required volume) by flipping bits of an 8 bit cubeindex.\n\nWhere cubeindex |= 2^i means that ith bit of cubeindex is set to 1\n\nAnother Hash table is constructed that gives the edges to be cut (same type of encoding as that shown above. This time each bit of the number is 1 if the corresponding numbered edge is to be cut). The index of the hastable (input) is the cubeindex generated.\n\nSo In the example in which only 3 is inside the volume (voxel value is 1 rest have 0),\n\nif P1 and P2 are the vertices (coordinate position of vertices) of a cut edge and V1 and V2 are the scalar values at each vertex (in our case 0 or 1), the the intersection point P is given by\n\nThe intersection point (linear interpolation) is calculated by:\n\nUsing these points the mesh is can be obtained."
    },
    {
        "url": "https://medium.com/zeg-ai/variational-autoencoders-explained-faa433691760?source=---------2",
        "title": "Variational Autoencoders: Explained \u2013 Zeg.ai \u2013",
        "text": "Autoencoders are feed-forward neural networks that are used for creating latent representations of the input data. So, essentially, these neural networks are trained to reproduce its input at the output layer. A special variant of autoencoders, called Variational autoencoders (VAE\u2019s), doesn\u2019t only creates latent representations but also holds the capability to generate new images. One of the key use for VAE\u2019s is in dimensionality reduction.\n\nVAE, primarily consists of three parts: encoder, decoder and a loss function:\n\nThe encoder is a neural network that takes data, x, as input and outputs the latent representation, z. The decoder, on the other hand, is also a neural network that takes latent representation, z, as input and outputs the data space.\n\nA loss function is introduced which essentially is a sum of two losses \u2014 a generative loss, (which is a mean squared error that measures how well the output is generated from the given input. This error encourages the decoder to learn to reconstruct the input data accurately. If the decoder doesn\u2019t reconstruct the data well in its output, this term would show a huge loss) and a latent loss (regulariser, a KL divergence between the encoder\u2019s distribution and Gaussian distribution. It captures how closely the latent variables match the normal distribution or unit Gaussian)\n\nAs a property of VAE, the output from encoder is expected in Gaussian distribution with mean zero and variance one. This is done to ensure that similar features from the input data don\u2019t end up with completely different representations. Thus, any deviation from the Gaussian distribution, is captured by the KL divergence loss. Further, to optimize KL divergence, instead of encoder generating a vector of real values, it\u2019s made to generate a vector of means and a vector of standard deviations."
    },
    {
        "url": "https://medium.com/zeg-ai/deep-learning-comparison-of-available-frameworks-ab89610f8d2b?source=---------3",
        "title": "Deep learning: Comparison of Available Frameworks \u2013 Zeg.ai \u2013",
        "text": "One of the first things that you do as you get started with Deep Learning is select a tool. So, here\u2019s a comparison of most popular available tools:"
    }
]