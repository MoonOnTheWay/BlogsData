[
    {
        "url": "https://medium.com/@darrenyaoyao.huang/airbnb-owners-were-missionaries-7fa586966627?source=user_profile---------1----------------",
        "title": "Airbnb owners were missionaries \u2013 Yi Yao Huang \u2013",
        "text": "Airbnb is not the first company which operates hospitality service for people. When building Airbnb, the company has a strong opponent, Wimdu, which focuses on Europe market.\n\nChesky starts to think about buy this company to expand their Europe business. However, Wimdu had four hundred employees and Airbnb only had forty people at the time. Chesky asked lots of people for advices and Paul Graham told him:\n\nThis idea inspires me to think about what kind of business I want to build in my career. We should be missionary not mercenary.\n\nThe other thing I learn from this part is that Airbnb is not only a travel company but also a technology company.\n\nTo solve customers\u2019 problem, they apply lots of data science techniques to their product. For example, the engineers at Airbnb use the people\u2019s history booking information to match the traveler and hosts. They also use machine learning to do dynamic pricing tools.\n\nTheir experience tells me that in the modern society, we can use lots of technology to improve traditional industry and our own product. In this way, we can build more exciting product and provide better user experience for customers."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/why-we-need-normalization-in-deep-learning-from-batch-normalization-to-group-normalization-d06ea0e59c17?source=user_profile---------2----------------",
        "title": "Why we need Normalization in Deep Learning? From Batch Normalization to Group Normalization.",
        "text": "Recently, Dr. Kaiming He proposed a new normalization method, Group Normalization, which has aroused the widespread discussion in Deep Learning research community and also gives me a chance why we need Normalization in Deep Learning.\n\nThis blog will focus on what normalization does in neural network and what are Batch Normalization and Group Normalization.\n\nIf we have a task which is to predict the users\u2019 probability of loaning account with their income and age.\n\nFrom Figure 1, we can observe that the range of income is larger than the range of age. If we do not do some preprocessing methods on these data, the effect of income feature may influence more than the one of age.\n\nFor a cat classifier, we may face a problem with the diverse data distribution of different batches. Even though there is a function which can split the data point, it is hard for the model to distinguish the data correctly in one mini-batch. We call this phenomenon \u201cInternal Covariate Shift\u201d.\n\nOne of the problem in Deep Learning is how to stable gradients value.\n\nFor a very deep neural network, we will multiply several gradients. If any of them is too small or too large, the neural network will face a vanishing/exploding gradients problem. Normalization can stable each value to reduce the vanishing/exploding gradient problem.\n\nTo solve above problems, we usually use normalization and standardization techniques during data processing. Today topics, Batch Normalization and Group Normalization, are the same ideas used in neural networks.\n\nBatch Normalization is an algorithm which applies standardization on each mini-batch. We calculate the mean and the variance among each mini-batch and standardize our data. Then, we will learn two parameters (gamma and beta) to scale and shift our data point.\n\nBatch Normalization provides a really strong way to reduce Internal Covariant Shift problem and can also stable the value in neural networks to speed up our training process.\n\nIn test time, we do not have any mini-batch, so we can not get the mean and variance. The alternative way is that we can store weighted mean and variance during training time and use it in testing time.\n\nThe good thing from Batch Normalization is that it really solve the above problems and speed up the training time dramatically. However, the performance of Batch Normalization will be influenced by the batch size developers used. It is a serious problem for the task which can not use too many batch size such like, Object Detection and Video Classification.\n\nThe idea of Group Normalization is processing feature by group-wise normalization over channels. Classical features of SIFT, HOG and GIST are group-wise representations by design, so it is not necessary to think of deep neural network features as unstructured vectors.\n\nLet\u2019s us review how we compute the mean and standard deviation of data in a neural network.\n\nSi is the set of pixels in which the mean and std are computed, and m is the size of this set.\n\nIn Batch Norm, the set Si is defined as:\n\nwhere ic and kc denotes the sub-index of i along channel axis.\n\nIn Group Norm, the set Si is defined as:\n\nHere G is the number of groups, which is a pre-defined hyper-parameter. C/G is the number of channels per group. iN denotes the sub-index of i along batch axis.\n\nHere is visualization of these methods.\n\nGroup Normalization is independent computations along the batch axis and is applicable for sequential or generative models. It helps deep learning model work better at small mini-batch size."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/the-start-of-airbnb-the-hustle-b2c8b6102b63?source=user_profile---------3----------------",
        "title": "The Start of Airbnb: The Hustle \u2013 Yi Yao Huang \u2013",
        "text": "Two designers cofounder, Brain Chesky and Joe Gebbia, met an engineer, Nathan Blecharczyk. They start one of the most highly valued startups in the world.\n\nAt first, Chesky and Gebbia quit their jobs and tried to start their own business at San Francisco. Without income, they rent their airbed to earn some money and then they found some opportunities in this idea.\n\nBlecharczyk helped them to implement their website and they kept refined their idea at the first year. Even though they did not have too many customers first, they never gave up and just kept launching their new product.\n\nFortunately, they got into the Y combinator startup program. Going in, they had made a pact with one another that for three months they\u2019d give it their all. Finally, they got funding! The investments valued the company at $2.4 million.\n\nThe most impressive thing I learned from this part is that you don\u2019t have to be smart to run a startup, but you have to be persistent.\n\nThe first two cofounders do not have any coding or engineering background. They can still make their Minimum Viable Product to test their idea.\n\nTheir idea is simple but crazy. Not too many people believe their idea will come true. However, they truly have some customers.\n\nBy keeping refined their product and going to their users, they finally know what people want.\n\nThe story of Airbnb can give you a clear picture of how to start a startup and give you some hope that you can also do the same thing."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/text-summarization-on-longer-articles-1c93ef07b10c?source=user_profile---------4----------------",
        "title": "Text Summarization on Longer Articles \u2013 Yi Yao Huang \u2013",
        "text": "*This blog is my review of paper \u201cGenerating Wikipedia by Summarizing Long Sequences\u201d\n\nI am deeply concerned about the techniques of text summarization because my goal is to summarize a book. In the past, the biggest disadvantage of text summarization is that it is hard for a neural network to summarize long articles. In this paper, the authors propose an architecture which can summarize multiple articles.\n\nThere are two stages of the model. First, the model will use extractive methods to summarize some words for each article. Second, the model apply TRANSFORMER-DECODER to do abstractive summarization. The TRANSFORMER-DECODER model is the one used in the paper \u201cAttention is all you need\u201d. For the advanced version, the paper add memory-compressed attention on the architecture.\n\nThe concept is really easy. The thing can be challenged is how to do end-to-end learning without stage 1. The memory issue forces the model to use non-neural-network methods to do extractive methods. We can think more on it."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/umbocv%E5%AF%A6%E7%BF%92%E5%BF%83%E5%BE%97-%E8%AE%93%E6%88%91%E6%87%82%E7%9A%84%E4%BB%80%E9%BA%BC%E5%8F%AB%E5%AF%A6%E5%8B%99%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-fb5d2292b689?source=user_profile---------5----------------",
        "title": "[UmboCV\u5be6\u7fd2\u5fc3\u5f97] \u8b93\u6211\u61c2\u7684\u4ec0\u9ebc\u53eb\u5be6\u52d9\u6a5f\u5668\u5b78\u7fd2 \u2013 Yi Yao Huang \u2013",
        "text": "One clap, two clap, three clap, forty?\n\nBy clapping more or less, you can signal to us which stories really stand out."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/practical-deep-learning-strategy-160fa41a4a43?source=user_profile---------6----------------",
        "title": "Practical Deep Learning Strategy \u2013 Yi Yao Huang \u2013",
        "text": "I write this article to conclude my deep learning development experience of my internship at UmboCV. During my internship, I built a violence detection system on production. I hope that I can introduce my strategies on this cutting-edge research deep learning project.\n\nFor each project which has its own data, I will follow three states.\n\n1. Data Processing\n\n2. Model Development\n\n3. Transfer Learning\n\nAs the first state of a deep learning problem, it may be the most important one. There is a simple exploratory data analysis pipeline from the blog.\n\nFor Ingest Data, we have to collect data as more as possible. Then, we should think about what kind of input data should be for models. As the position of models, we can design how to label our data. This step is really important because if you choose the wrong way to label data, it will be really hard to train a good model.\n\nIf you know what kind of format is suitable for your models, you can start to build a good quality dataset. A good quality dataset will lead to a good model, so make sure to clean your dataset really carefully.\n\nThen, transform your data into the specific format for your models. For example, resize your image data as the input size of your models. This step will speed up your data loader.\n\nFinally, try to present your data and check that it is reasonable for a model to learn the meaning. Sometimes, researchers will assume deep learning model can learn anything and forget to check the final data. It is really dangerous for researchers to build a baseline method. In general, a machine is hard to beat a human. Make sure people can do the tasks.\n\nIf you already built a good dataset, you can start to read some papers and select a good model to implement. For your first model, you should choose a model in a simple architecture. Implement the model as fast as you can. To make sure you successfully train the model, there are some tips I usually take.\n\nFirst, select some small amount of data and try to overfit them. The capacity of your model must remember all the feature of your small dataset. If you can not train the dataset to 100%, there must be some bugs in your code. Second, data augmentation is really important. From my experience, data augmentation is as essential as model architecture. If your architecture is correct and there is no bug in your code, try to change your data augmentation strategy.\n\nAfter your finish your baseline model, you can survey more papers and compare the pros and cons of these methods. Choose the approach which is most suitable for your situation.\n\nAll of the models should train on the public dataset first. There are two reasons. First, on the public dataset, you will have a standard metric. Second, in most of the time, the public dataset includes much more data than your own data. Pretrained weights of deep learning models are the most critical elements.\n\nFor the strategies of transfer learning, you should follow the guide on CS231n. There are some advice I want to share. \n\n1. Don\u2019t think you make your model have a great fit on your dataset in one time. You should be patient and take care of the parameters in all layers.\n\n2. You should inference on your testing data for each fine-tuned model. With several iterations of the processing, you will understand more about the distribution of your dataset."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/visualize-the-meaning-of-text-e5b1f8bcd265?source=user_profile---------7----------------",
        "title": "Visualize the meaning of text \u2013 Yi Yao Huang \u2013",
        "text": "*This blog is my review of paper \u201cAttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\u201d\n\nOne of my goal is to transform knowledge into videos and I also survey lots of research about video and interaction between texts and videos. This paper really impresses me. It proposes a way to transform text into image. Here is their model architecture.\n\nThe key idea of this paper is that we can use attention models to synthesize fine-grained details at different sub-regions of the image by paying attentions to the relevant words in the natural language description. From the architecture, we can find that we will re-generate the image for each word feature. Then, we will use discriminator to boost the quality of the image.\n\nThe most amazing thing of this paper is not the method but the idea. People usually like to read images more than words. If this method works well in the future, I believe my goal of transforming knowledge into video will be realized soon."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/natural-language-to-sql-d4da0e179ae4?source=user_profile---------8----------------",
        "title": "Natural Language to SQL \u2013 Yi Yao Huang \u2013",
        "text": "Natural language has become a new interface between human and computer. In the recent trend of chatbot development, it is important to translate human language into the query language. The main challenge of this task is how to evaluate the output. We can not use BLEU score because the similarity of two sentences does not represent the query is a valid query. In this blog, I will introduce two papers about translating natural language into SQL.\n\nThis paper is from Allen Institute for Artificial Intelligence and is published in EMNLP 2017. The main contribution of this paper is that it proposes a Feedback-based Learning algorithm. The authors use a seq2seq model for generating SQL from natural language. The algorithm will modify the training dataset based on the users\u2019 feedback. In this way, researchers can make sure the model predict the correct form of SQL.\n\nThis paper uses a more automatic system to make sure the model can generate correct SQL query. The authors execute the generated SQL query against the database to obtain a reward and use this reward to do reinforcement learning for their Seq2SQL model.\n\nThese two papers propose smart ways to evaluate the SQL output. The first one tells us how to interact with users and the second one shows us how to get feedback from the SQL complier. I think that the paper \u201cSeq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning\u201d gives us a great method for generating SQL query from a single sentence. The next step for this research is how chatbot can use this method in dialogue which contains common communication and query request. The dataset is a big challenge here. The Feedback-Learning algorithm may be a solution for this."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/attention-on-text-and-vision-39f22e0eb360?source=user_profile---------9----------------",
        "title": "Attention on Text and Vision \u2013 Yi Yao Huang \u2013",
        "text": "*This blog is my review of paper \u201cAttention Is All You Need\u201d\n\nThis paper \u201cAttention Is All You Need\u201d attracts lots of attention in this year and I also heard the talk of the author in EMNLP 2017. The most impressive idea of this paper is that the authors propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrent and convolutions entirely.\n\nThis idea is a breakthrough of deep learning because in the past, we think the core of deep learning is convolutional network and recurrent network. Attention mechanism will help the model to focus on particular parts of input. However, this paper only use attention to do machine translation.\n\nIn my opinion, it is a evolution of deep learning model on text. Just like Capsule Network is the advance version of convolutional network.\n\nAttention is not only used in Natural Language Processing, but also in Computer Vision. In the paper \u201cShow, Attend and Tell: Neural Image Caption Generation with Visual Attention\u201d, researchers propose a visual attention mechanism to do image caption generation.\n\nAlso, in the paper \u201cACTION RECOGNITION USING VISUAL ATTENTION\u201d, authors propose a location attention map to help action recognition.\n\nMost of works generate attention weight from LSTM. It means it is hard to apply attention approach without time series data.\n\nThere are four types of attention:\n\n1. Additive attention\n\n2. Multiplicative attention\n\n3. Self-attention\n\n4. Key-value attention\n\nThis blog introduces this four types of attention clearly."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/practice-and-trends-of-deep-learning-566e136216c7?source=user_profile---------10----------------",
        "title": "Practice and Trends of Deep Learning \u2013 Yi Yao Huang \u2013",
        "text": "*This blog is my review of the NIPS 2017 talk \u201cDeep Learning: Practice and Trends\u201d\n\nAfter watching the talk \u201cDeep Learning: Practice and Trends\u201d, I feel very exciting and I organize the material with some my ideas into this blog.\n\nConvolutional Networks has been around for a long time. The idea first come from the paper \u201cGradient-based learning applied to document recognition.\u201d\n\nHowever, it does not attract too much attention until the appearance of AlexNet. Using deep learning technique in the paper \u201cImageNet Classification with Deep Convolutional Neural Networks\u201d brings a great success in computer vision.\n\nWith the power of deep learning, researchers try deeper neural network to improve the performance. However, the deeper layers come with the harder normalization problems. Residual connection solves this problems.\n\nNow, ResNet almost becomes the most popular and powerful backbone network for computer vision research. Based on ResNet, there are lots of more advance model for different tasks. For example, ResNeXt and DenseNet for image classification, UNet for Segmentation, and FasterRCNN, MaskRCNN for Object Detection.\n\nMoreover, there are two very interesting papers. \u201cDeformable Convolutional Networks\u201d introduces a new way to calculate convolutional features. \u201cA Closer Look at Spatiotemporal Convolutions for Action Recognition\u201d pushes convolutional network to video understanding.\n\nThere are two important ingredients: neural embeddings + recurrent language model\n\nFor neural embeddings, we have word2vec, Golve vector and fasttext.\n\nWith recurrent language model, we have seq2seq model to do machine translation, text summarization \u2026\n\nAlso, we have attention mechanism to improve seq2seq model. There are lots of advance model like pointer network, memory network and recurrent highway network."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/ai-to-serve-humanity-d915189ae2dc?source=user_profile---------11----------------",
        "title": "Apply AI to Serving Humanity \u2013 Yi Yao Huang \u2013",
        "text": "As an Electrical Engineering student, I keep asking myself \u201cWhat is my purpose?\u201d since I was a freshman in college. In my deep heart, I not only want to be a problem solver as an engineer but also I want to become a problem finder. Struggling from Electrical Engineering to Computer Science, Human-Computer Interaction to Artificial Intelligence, I keep exploring the possibilities in the world and investing myself. Finally, I found that what I want to do is to make knowledge more easily absorbed and it does not matter what kinds of techniques I use. In the MIT 2017 commencement speech of Tim Cook, he mentioned that an engineering student should find their purpose and he stated an idea of \u201cServe Humanity\u201d. Yes, it is what I want to do! Improve modern education system to serve humanity.\n\nIn today\u2019s AI era, it is a fierce competition between human and machine. The more intelligent computer can save more our time. Some people concerned about that machine will replace human in one day. AlphaGo beat the most smartest Go player, Neural Network can generate artworks and machines start to write articles and create music. AI seems to be able to do all the things that human can do. However, I have an opposite opinion. I believe the machine will enhance human ability rather than replace human. Creativity and emotion from human are the things which won\u2019t be learned by machine. Also, we should never overlook the potential of our brains. People can learn and do more things than they originally think. The only thing we have to do is making good use of our time and ability.\n\nWhat I am worried about is that human gives up their ability to learn and let machine exceed themselves. With the convenience of technology, we live more easily and can get entertainment everywhere through the Internet. People enjoy the amusement on the Internet but be influenced by the bias from social media. People get information more easily and people become more arrogant to believe they are right. Gradually, there are more and more conflicts among people. Too much information make people lose the ability to collaborate and lose the competition with AI. Tim Cook said \u201cI\u2019m not worried about artificial intelligence giving computers the ability to think like humans. I\u2019m more concerned about people thinking like computers without values or compassion, without concern for consequences.\u201d We have to improve ourselves by victories over ourselves and we have to be humble and keep learning.\n\nI know learning takes sacrifice, energy, and focus. It is hard but valuable. With knowledge, everyone can change his life and even change the world. It is what I want to do: Apply AI to education. Building a personal education system pave the way for people to learn new things more efficiently without fake news and wrong knowledge."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/my-dream-comes-true-soon-combining-information-extraction-and-text-summarization-75dd630099a5?source=user_profile---------12----------------",
        "title": "My Dream Comes True Soon? Combine Information Extraction and Text Summarization",
        "text": "*This blog is my review of paper \u201cChallenges in Data-to-Document Generation\u201d\n\nMy dream is to build an AI tutor which can transform knowledge into articles. I surveyed lots of text summarization works before. Most of the works cannot support longer output. Therefore, I start to do some research on relation extraction and I hope that I can combine these two methods in the future. When I read this work, I am very excited. It is the first work which is most close to my idea.\n\nThis paper proposes a more difficult data-to-text generation task. The authors introduce a new large-scale corpus consisting of textual descriptions of basketball games paired with extensive statistical tables.\n\nThe missions of the models are to understand the data and then generate some words containing the information of the data. I won\u2019t discuss the details of the models they used here. I will focus on the more exciting part that how they evaluate their result. In text summarization, researchers usually use BLEU score to evaluate the performance. However, BLEU has lots of disadvantages. In this work, they extract the information from generated words first and then compare the Content Selection (CS), Relation Generation (RG), and Content Ordering (CO). It is a brilliant idea to combine information extraction and text summarization. Also, the method will point out how much information the generated words contain.\n\nAfter reading this work, I immediately come up with a new way to do longer output text summarization. Take a long article for example. First, a machine will apply information extraction approaches on the article and list all the information in it. Then, use data-to-text generation models to generate articles. We can split the information into different parts and generate words for each part. In this way, models will not face problems about trying to condense too much knowledge in one time.\n\nI really like this work and I will keep following up the research on data-to-text generation models."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/natural-language-for-visual-reasoning-322c36949cd1?source=user_profile---------13----------------",
        "title": "Natural Language for Visual Reasoning \u2013 Yi Yao Huang \u2013",
        "text": "Today, I want to introduce a new visual reasoning language dataset which come from Cornell Tech.\n\nEach data from this dataset is a pair of a picture and a sentence. Researchers have to design a model to tell the sentence of each data is true for the image or not. This task is a little bit different from VQA task. From my opinion, it may be more simple for deep learning model, but it is also more important for visual reasoning.\n\nThis task need more structured representations of images and sentences. Even though deep learning works really well in the recent year, I think it is time to start to do research on basic set-theoretic reasoning and logical reasoning. This dataset provides a really good chance to explore these fields.\n\nThe paper also proposed a way to evaluate the bias in the dataset. The authors use image-only model and text-only model to predict the result. However, I could not understand why there is a text-only method from leader boarder which can achieve 83%. Does it mean that this dataset has serious bias issues?"
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/revolution-of-video-understanding-9abb91923a4c?source=user_profile---------14----------------",
        "title": "Revolution of Video Understanding \u2013 Yi Yao Huang \u2013",
        "text": "*This bog is my review of \u201cA Closer Look at Spatiotemporal Convolutions for Action Recognition\u201d and \u201cRethinking Spatiotemporal Feature Learning For Video Understanding\u201d.\n\nRecently, I am in charge of the development of Fight Detection system at UmboCV. It gives me a chance to explore the deep learning technique about video understanding. In the first half of this year, the Two-Stream model is still the-state-of-the-art method which combines the spatial stream (fed by RGB) and the temporal stream (fed by optical flow). However, there are two serious disadvantages of this method. First, generating optical flow is slow and optical flow is not raw feature from data. Second, the spatial stream fed only one RGB is not reasonable for understanding videos. Therefore, lots of people are looking forward to the C3D model.\n\nAfter the Kinetic dataset is released, researchers finally have enough data to train C3D model and avoid overfitting. This blog will mainly discuss two papers from Facebook and Google recently about the new C3D model architecture they proposed.\n\nIn the paper \u201cA Closer Look at Spatiotemporal Convolutions for Action Recognition\u201d, the authors state that 3D convolutional kernel is not the solution for video understanding. They propose R(2+1) kernel which operates a 2D convolutional kernel on frames first and then operates a 1D convolutional kernel for temporal features.\n\nI like this idea because I believe when human watch video, human will understand each frame first and then consider the time series of every frame. From their result, this model beat the performance from two stream model. It excites me because this method will give me a lot of benefits if I don\u2019t have to generate optical flow for the real-time production system.\n\nAnother paper \u201cRethinking Spatiotemporal Feature Learning For Video Understanding\u201d discuss similar research. The researchers from Google want to know if it is necessary to compute temporal features for all layers. They propose a model \u201cS3D\u201d which is similar with R(2+1), but they more focus on the experiments about only applying \u201cS3D\u201d to bottom layers and top layers.\n\nWe can observe that the top layers S3D has better performance. The result tells us that spatial features are still very important and maybe temporal features only work on high-level features.\n\nWe can tell that video understanding is a very popular research topic from the recent active actions of Facebook and Google. Even though it seems that the performance of action recognition task is still far away with image classification, I believe that approximately one or two years, there will be a classification video understanding model just like ResNet today."
    },
    {
        "url": "https://medium.com/@darrenyaoyao.huang/do-you-ever-consider-the-gender-bias-issue-in-machine-learning-f7847b3fe1aa?source=user_profile---------15----------------",
        "title": "Have you ever considered the gender bias issue in Machine Learning?",
        "text": "*This blog is my review of paper \u201cMen Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints\u201d in EMNLP 2017\n\nMachine learning shows powerful performance nowadays. However, the paper \u201cMen Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints\u201d points out that machine learning models may be influenced by bias in datasets. This reminds me the Ted talk: How I\u2019m fighting bias in algorithms which found that most of face recognition system can not detect faces of black people.\n\nI think the issue of bias in data is really important because most of machine learning systems, especially deep learning, highly depend on training data, but their labels may include stereotypes in human society. For example, most of cooks in cooking pictures are women. In imSitu visual semantic role labeling (vSRL) dataset, 67% of cooking images have woman in the agent role. The most interesting thing is that models may amplify the bias when testing. This paper introduce Reducing Bias Amplification, RBA, a debiasing technique for calibrating the predictions from a structured prediction model.\n\nThe method applies Corpus-level Constraints on the CRF score function on test instances and tries to use Lagrangian Relaxation to optimize the target function. It tests on visual semantic role labeling and multilabel classification tasks. The most wonderful thing is that this approach works as a meta-algorithm and developers do not need to implement a new inference algorithm."
    }
]