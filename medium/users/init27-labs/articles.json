[
    {
        "url": "https://medium.com/init27-labs/fine-tuning-feature-engineering-eb57b7d30ce8?source=---------0",
        "title": "Fine Tuning & Feature Engineering \u2013 init27 Labs \u2013",
        "text": "Post is divided into two topics.\n\nBelow are some general guidelines for fine-tuning implementation:\n\nFor Further Readings [There is a difference between using pre-trained weights and transfer learning.][1]"
    },
    {
        "url": "https://medium.com/init27-labs/readerbot-an-event-driven-chatbot-54e960eecc00?source=---------1",
        "title": "ReaderBot: An Event Driven ChatBot \u2013 init27 Labs \u2013",
        "text": "Below, is the code for ReaderBot: A EDP based chatbot that interacts with you and opens articles that you\u2019d like to read based on your responses.\n\nFeel free to check the GH repository. Below, is the explanation of the key functions.\n\nFor Example, consider a callback for Self Driving Cars.\n\nThis is a callback that the Bot is expected to execute when provided an input of \u201cSDCs\u201d\n\nWe have to populate a local dictionary for accepted messages for the pre-defined responses, such as the SDC callback shown above.\n\nHere, We\u2019re creating a local dictionary of accepted messages for standard responses.\n\nThis would open in a new tab, a post on Self Driving Cars."
    },
    {
        "url": "https://medium.com/init27-labs/understanding-q-learning-the-cliff-walking-problem-80198921abbc?source=---------2",
        "title": "Understanding Q-Learning, the Cliff Walking problem",
        "text": "In the Last post we\u2019ve introduced the Cliff Walking problem and left off with a scary algorithm that made no sense. This time we\u2019ll uncover the secrets of that gray box, and we will see that it isn\u2019t that scary at all.\n\nWe concluded that by maximizing the sum of future rewards we are also finding the quickest route to the goal, so our objective now is to actually find a way to do this!\n\nThe optimal Q-table has values that allow us to take the best action at every state, giving us the best path to victory!\n\nProblem Solved, Welcome Robot Overlords. (If only solving a simple problem creates an AGI)\n\nFor example, suppose we are one step away from the goal (square [2, 11]), if we choose to go down we\u2019ll receive a reward of 0 instead of -1.\n\nWe can use this information to update the value of this state-action pair in our table so that the next time we visit it we already know that going down gives us a reward of 0.\n\nNow we can propagate this information even further! Since we now know the path to the goal from square [2, 11], any action that takes us to square [2, 11] will also be good, so we update the Q-value of the square that lead us to [2, 11] to be closer to 0.\n\nNote that every time we reach the goal we increase our \u201cmap\u201d of how to reach the goal by one square, so after a sufficient number of iterations we\u2019ll have a complete map, that will show us how to get to the goal from every state.\n\nBefore we talk code, let\u2019s talk math: the main concept behind Q-learning, the Bellman equation.\n\nBelow is an math to English translation:\n\nBut we might think that receiving a reward right now is more valuable than receiving a reward on the future, and that\u2019s why we have \u03b3, a number between 0 and 1 (generally between 0.9 and 0.99) that get\u2019s multiplied to the future reward, making future rewards discounted.\n\nSo considering \u03b3 = 0.9 and applying this to some states of our grid world we have:\n\nWe can compare these values with those of the GIF above and see that they are the same!\n\nNow that we have an intuition on how Q-learning works, we can start thinking about implementing all of this, we\u2019re going to use the Q-learning pseudo-code from Sutton\u2019s book as our guide.\n\nBut there\u2019s a problem with this approach, image we are in a maze that has two rewards, one of +1 and other of +100 (and every time we find one of them the game ends), because we always take the action we believe is best we\u2019re going to get stuck with the first reward we find, always going back to that, so if we first find out the reward of +1 we\u2019re going to miss out on the bigger reward of +100.\n\nWe need to make sure we sufficiently explore our world (this is a surprisingly difficult task). Here is where \u03b5 in \u03b5-greedy comes in, it means that we should act greedily BUT take a random action \u03b5 percentage of the time, so with a infinite number of tries we should explore all states.\n\nThe action is chosen following this strategy at , with , meaning we explore 10% of the time. The implementation of the policy is done as follows:\n\nIn we simply call the step method to execute the action, the world returns to us the next state, the reward and if the game is over.\n\nWe have a long equation, let\u2019s think about it:\n\nIf we consider \u03b1 = 1:\n\nWhich is exactly the same as the Bellman equation we saw some paragraphs ago! So we already now that this is the line responsible for propagating the information about the value of the states.\n\nBut generally \u03b1 (mostly know as the learning rate) is much smaller than 1, its main purpose is to avoid big changes in only one update, so instead of flying directly into the target, we slowly move to it. In our tabular approach, setting \u03b1 = 1 doesn\u2019t cause any problems, but when dealing with neural networks (more depth on this in the next posts) things can easily get out of hand.\n\nLooking at the code, we see that in we defined the , this is the value we need to move closer to, but instead of directly jumping to this value in we calculate the , we will use this value in conjunction with the learning rate to slowly move to the target.\n\nNow we just need to update our state and we\u2019re done, this is . We repeat this process until we reach the end of the episode, dying into The Cliff or reaching the objective.\n\nNow we intuitively understand and know how to code Q-Learning (at least the tabular variation), be sure to check all the code used for this post available on my GitHub.\n\nCheckout the visualization of the Learning Process:\n\nNotice that all actions start with a value higher than it\u2019s final value, this is a trick for encouraging exploration.\n\nMore depth on this in the upcoming posts."
    },
    {
        "url": "https://medium.com/init27-labs/quadcopter-physics-explained-c305da3ec141?source=---------3",
        "title": "Quadcopter Physics Explained \u2013 init27 Labs \u2013",
        "text": "This articles discusses the physics behind Flights.\n\nThe Rotors act as wings. They generate thrust by rotating at Fast speeds, which pulls the air downwards and keeps the quad in the air.\n\nThe setups for Flying is simple:\n\nA,C spin Clockwise (From our point of view)\n\nPhysics says to be in stability the net forces acting on a body should be zero.\n\nSo if all the rotors were to spin in the same direction, it would result in a net Torque causing the complete Quad to rotate.\n\nThe attitude is defined with analogy from the Naval World.\n\nWe will use these terms to define the motions of our drone.\n\nTo Roll Rightwards (Our Right)\n\nThis creates a net forward force which causes the Drone\u2019s nose to Pitch Downward.\n\nTo Pitch Away from us\n\nWhy?\n\nTo keep the Net upward/downward force zero."
    },
    {
        "url": "https://medium.com/init27-labs/building-a-quadcopter-components-explained-diary-of-a-flying-car-engineer-2-7cb8231534c8?source=---------4",
        "title": "Building a Quadcopter-Components Explained: Diary of a Flying Car Engineer #2",
        "text": "Note: The two are mentioned are as a combined unit for simplicity However have some significant technical different tasks. Autopilot controls the motors and Flight Controller-Flight execution.\n\nNote: Pitch: The twist of the propellers-is the linear distance moved by the Propellers in one complete rotation."
    },
    {
        "url": "https://medium.com/init27-labs/quadcopter-as-the-flying-car-test-platform-diary-of-a-flying-car-engineer-1-75221c88e148?source=---------5",
        "title": "QuadCopter as The Flying Car Test Platform: Diary of a Flying Car Engineer #1",
        "text": "This article is aimed at explaining why applying our code to Quadcopters are a good Test Platform for flying Cars.\n\nAn everyday Boeing passenger plane, a F-22 Fighter jet classify as fixed wing aircrafts. These are highly efficient and are the choice for longer travel distances.\n\nThese have rotating propellers to act as wings and keep the aircraft flying. These are capable of VTOL (Vertical TakeOff and Landing) which makes them a better choice for landing in tight environments where we can\u2019t have long runways in place.\n\nI\u2019ll save some interesting Takeoffs for another post in the series.\n\nWe have taken the Crazyflie 2.0 as our flying car test platform, Udacity has generously offered us a discount on the Bundle. Also the kit will allow us to run our projects from the Flying Car Nanodegree, directly on the Nanodrone."
    },
    {
        "url": "https://medium.com/init27-labs/diary-of-a-flying-car-engineer-0-b7e369370686?source=---------6",
        "title": "Diary of a Flying Car Engineer #0 \u2013 init27 Labs \u2013",
        "text": "Remember when I said My dream has been working on Self Driving Cars? \n\nI Lied.\n\nI\u2019ve always dreamed about Flying Cars after watching Back to the Future movie. I\u2019ve grown up watching the series and have always fantasised about pushing a button and transforming my car into hover mode whenever I\u2019m stuck in traffic and I\u2019ve wasted endless hours thinking how I could fly from my apartment to university.\n\nOfcourse I\u2019m passionate about Self Driving Cars. But Flying Cars have always been a dream. If you don\u2019t feel the same. I refuse to believe you.\n\nSo when Udacity Came out with their Flying Car Nanodegree; I had to apply right away. I was already pursuing the Self Driving Car Nanodegree and I was convinced that this is the best way that I come closer to my dream."
    },
    {
        "url": "https://medium.com/init27-labs/my-impression-of-stanfords-tensorflow-course-assignment-1-ed368af28d73?source=---------7",
        "title": "My impression of Stanford\u2019s Tensorflow course: Assignment 1",
        "text": "The first assignment of this course covers 3 main problems. The first one is simply filling in missing chunks of code to solve simple tasks. The second one is implementation of a deep neural network model which gives 97%+ accuracy on the MNIST dataset. And the third one is to implement the CBOW model. You can find the assignment here.\n\na) Problem: Create two random 0-d tensors x and y of any distribution. Create a TensorFlow object that returns x + y if x > y, and x \u2014 y otherwise. Hint: look up tf.cond()\n\nb) Problem: Create two 0-d tensors x and y randomly selected from the range [-1, 1). Return x + y if x < y, x \u2014 y if x > y, 0 otherwise. Hint: Look up tf.case().\n\nc) Problem: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] and y as a tensor of zeros with the same shape as x. Return a boolean tensor that yields Trues if x equals y element-wise. Hint: Look up tf.equal().\n\nd) Problem: Create the tensor x of value [29.05088806, 27.61298943, 31.19073486, 29.35532951, 30.97266006, 26.67541885, 38.08450317, 20.74983215, 34.94445419, 34.45999146, 29.06485367, 36.01657104, 27.88236427, 20.56035233, 30.20379066, 29.51215172, 33.71149445, 28.59134293, 36.05556488, 28.66994858]. Get the indices of elements in x whose values are greater than 30. Hint: Use tf.where(). Then extract elements whose values are greater than 30. Hint: Use tf.gather().\n\ne) Problem: Create a diagonal 2-d tensor of size 6 x 6 with the diagonal values of 1, 2, \u2026, 6. Hint: Use tf.range() and tf.diag().\n\nf) Problem: Create a random 2-d tensor of size 10 x 10 from any distribution. Calculate its determinant. Hint: Look at tf.matrix_determinant().\n\ng) Problem: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9]. Return the unique elements in x. Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n\nh) Problem: Create two tensors x and y of shape 300 from any normal distribution, as long as they are from the same distribution. Use tf.cond() to return:\n\n\u2014 The mean squared error of (x \u2014 y) if the average of all elements in (x \u2014 y) is negative, or\n\n\u2014 The sum of absolute value of all elements in the tensor (x \u2014 y) otherwise.\n\nHint: see the Huber loss function in the lecture slides 3.\n\nThis task has 2 parts \u2014 improve the logistic regression model to achieve 97%+ accuracy on MNIST dataset or build a new logistic regression model on the nonMNIST dataset.\n\nI started tweaking the hyperparameters of this model with the example code. I also changed the activation functions and did some other slight improvements. Unfortunately, non of my attempts ended up having 97%+ result on the test data. If you manage to find the appropriate changes, I am happy to see them in the comment section.\n\nSo, I searched for the models which produce the best results and found this nice list which inspired me to try doing a simple 3-layer convolutional neural network.\n\nI will now explain the full implementation below. Bear in mind that it may seem a blackbox to you but you will get a better understanding of convolution neural networks in my next article.\n\nThis code below follows this Tensorflow example.\n\nnumpy and tensorflow should be fairly familiar, utils is used to load the MNIST dataset. In general, utils is used to collect the most common functions and operations used in python.\n\nIt consists of 2 convolutional layers, each of them followed by a max-pool layer and there is a dense layer in the end.\n\nConvolutional layer \u2014 produces feature maps after applying a filter window to the input (initially it is the image itself)\n\nPooling layer \u2014 used to reduce the size of the image representation during training.\n\nDense layer \u2014 this is the final layer in the model and it is a result of full connection between all neurons in the previous layer.\n\nYou can find the difference these layers here. Additionally, here is a brief explanation of CNN.\n\n#0. Our model function receives the input data (images) and labels as parameters. In addition we add mode which is used for Tensorflow Estimator which I will explain below.\n\nWe reshape data following the concept: [batch_size, image_width, image_height, num_channels]. Since the images are grayscale, the num_channels is 1. batch_size is set to -1 which means that this dimension should be dynamically computed based on the number of input values.\n\nWe use Tensorflow tf.layers.conv2d() function. Let me quickly explain what each parameter mean:\n\nWe use the Tensorflow tf.layers.max_pooling2d to perform the max pool layer which reduces the size of the conv1 matrix.\n\nSame as the first convolutional layer with the only difference in the number of filters \u2014 here is 64.\n\nThis is the final layer in the CNN.\n\nNow let\u2019s look at the optimizer:\n\nIt is used to update the weights in the direction that minimizes the loss function. The global_step is just for keeping track of the number of batches.\n\nIn case of evaluation mode, we just return how often does the labels match the predictions using tf.metric.accuracy.\n\nThe main purpose of the loss function and the optimizer is to adjust the weights of our network so that the error between our predicted values (logits) and the actual results (labels) is minimized and the prediction is as closer as possible to the truth.\n\nA high-level Tensorflow API which helps training, evaluating and testing your model. You can read more about it in the documentation. I will explain below how our model uses this Estimator:\n\nThis task is in 3 parts where the most crucial one is 3c which asks you to implement CBOW model by tweaking the provided code for the skip-gram. In this article, I will only show how to implement 3c. If you have difficulties doing 3a and 3b, comment at the bottom and we can chat about it.\n\nWe will be modifying the skip-gram code by changing the following functions:\n\nFor any enquiries regarding the modifications in the code, comment below or email me: simeon dot kostadinoff at gmail dot com."
    },
    {
        "url": "https://medium.com/init27-labs/intro-to-pandas-and-numpy-532a2d5293c8?source=---------8",
        "title": "Intro to Pandas and Numpy: Basic Tutorials Part 6 \u2013 init27 Labs \u2013",
        "text": "Pandas is one of the data centric python packages that makes importing and analyzing data much easier. Pandas is build on Numpy and matplot which makes data manipulation and visualization more convinient.\n\nBefore importing on your platform,we need to first install it.The installation guide to pandas can be found here->https://pandas.pydata.org/pandas-docs/stable/install.html.\n\nThe head command is used to return the first N rows in the data frame whereas tail is used to get the last N rows.\n\nDataframe is a 2-dimensional labeled data structure with columns of potentially different types.\n\nNumpy is that library for computing in python.It provides high performance multidimensional array object and tools for working with arrays."
    },
    {
        "url": "https://medium.com/init27-labs/linear-regression-in-2-minutes-using-pytorch-49d80a9e6528?source=---------9",
        "title": "Linear Regression in 2 Minutes (using PyTorch) \u2013 init27 Labs \u2013",
        "text": "This is Part 2 of the PyTorch Primer Series.\n\nLinear Regression is linear approach for modeling the relationship between inputs and the predictions\n\nWe find a \u2018Linear fit\u2019 to the data.\n\nFit: We are trying to predict a variable y, by fitting a curve (line here) to the data. The curve in linear regression follows a linear relationship between the scalar (x) and dependent variable.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://medium.com/init27-labs/pytorch-basics-in-4-minutes-c7814fa5f03d",
        "title": "PyTorch Basics in 4 Minutes \u2013 init27 Labs \u2013",
        "text": "This is Part 1 of the PyTorch Primer Series.\n\nIt\u2019s a Python based package for serving as a replacement of Numpy and to provide flexibility as a Deep Learning Development Platform.\n\nI encourage you to read Fast AI\u2019s blog post for the reason of the course\u2019s switch to PyTorch.\n\nTensors are similar to numpy\u2019s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n\nThis will create a X by Y dimensional Tensor that has been instantiated with random values.\n\nTo Create a 5x3 Tensor with values randomly selected from a Uniform Distribution between -1 and 1,\n\nTensors have a size attribute that can be called to check their size\n\nPyTorch supports various Tensor Functions with different syntax:\n\nInline functions are denoted by an underscore following their name. Note: These have faster execution time (With a higher memory complexity tradeoff)\n\nAll Numpy Indexing, Broadcasting and Reshaping functions are supported\n\nNote: PyTorch doesn\u2019t support a negative hop so [::-1] will result in an error\n\nNote: Be careful when working with different Tensor Types to avoid type errors\n\nConverting a torch Tensor to a numpy array and vice versa is a breeze.\n\nNote: The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n\nMoving the Tensors to GPU can be done as:\n\nCentral to all neural networks in PyTorch is the package. Let\u2019s first briefly visit this, and we will then go to training our first neural network.\n\nThe package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n\nLet us see this in more simple terms with some examples.\n\nis the central class of the package. It wraps a Tensor, and supports nearly all of operations defined on it. Once you finish your computation you can call and have all the gradients computed automatically.\n\nYou can access the raw tensor through the attribute, while the gradient w.r.t. this variable is accumulated into .\n\nAs explained by this Blog Post by Radek, My friend and Mentor from the Fast AI community\n\nFeel free to ask any questions below. \n\nAlso drop us a comment on the tutorials that you\u2019d love to read, I will try to have that up ASAP.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://medium.com/init27-labs/pytorch-primer-series-0-8f38fb09ad2f",
        "title": "PyTorch Primer Series #0 \u2013 init27 Labs \u2013",
        "text": "This is Part 0 of the Series.\n\nThe series will be in a beginner friendly form. All the links to the GitHub repositories will be provided in the posts. The Posts will be in the form on a theory minima appraoch-where only just the bare amount of theory needed to get you started is required, with in depth discussion of the code.\n\nIf you feel you need a quick refresh of Python, Checkout my Basic Tutorial Series.\n\nFeel Free to contribute and improve the code, I\u2019ll update my posts and Credit you for the contributions as well!\n\nThe topics that will be covered are (Links will be updated as the drafts become public):\n\nPlease drop a comment below if you\u2019d like to read more tutorials and I will try my best to have them up and ready ASAP!\n\nIf you want to chat, ping me in the comments or find me on twitter. I\u2019d love to hear from you!"
    },
    {
        "url": "https://medium.com/init27-labs/robotics-series-0-call-for-proposals-e594fd42b824",
        "title": "Robotics Series #0 Call for Proposals \u2013 init27 Labs \u2013",
        "text": "Part 0 of the ROS Series, spanning from the Ground Basics of ROS to working on real Projects, with End to End Code Walkthroughs.\n\nI\u2019m really excited to announce a Robotics Tutorial Series to be released very soon.\n\nWe really want to make this series to be as helpful as we can. We\u2019d love to hear what you\u2019d want to read about.\n\nThe Content decided thus far, based on all the requests is:\n\nWe\u2019re actively creating this Tutorial Series to be released on here very soon and would love to hear about your ideas, what you would love to read about.\n\nPlease Drop us a Comment below or Shoot me a tweet @bhutanisanyam1"
    },
    {
        "url": "https://medium.com/init27-labs/my-impression-of-stanfords-tensorflow-course-week-1-3-57dc73920915",
        "title": "My impression of Stanford\u2019s Tensorflow course: Week 1\u20133",
        "text": "In my previous post I gave a brief introduction to this new series of posts which aims to give an explanation of the most recent Stanford\u2019s Tensorflow course from January-February 2018. In this part I will uncover my impressions of the first 3 weeks of this course.\n\nThis week provides is the best explanation of Tensorflow I have ever seen. Often, when one gets motivated to learn about machine learning, he may quickly be discourage by the complication and ambiguity of the original Tensorflow documentation.\n\nI would recommend first go briefly through the lecture notes and then jump into the slides. The latter will give you this fluent start towards your understanding of TF.\n\nThis week dives into the power of Tensorflow. First the course covers TF operations like constants, summation, multiplication etc. and the second lecture of the week reveals how to implement Linear regression.\n\nThe 2nd lecture of this week covers a some examples.\n\nThe first one is an implementation of linear regression for predicting life expectancy from birth rate \u2014 the model is fairly simple and you can find it here. If you follow the steps in the lecture notes, you will be able to run it yourself. Drop a message in the comment section if you have any questions.\n\nThe second example cover logistic regression for MNIST dataset (contains 30k + examples of handwritten images).\n\nLinear and logistic regression sound familiar but they are completely different algorithms. Here is the difference:\n\nThis week is again divided into 2 lectures. The first one covers Eager execution (find below) and the second one is entirely about word2vec model and some advanced techniques which come with it.\n\nAs you are already familiar, building models in TF comes in 2 steps \u2014 forming the graph and executing it using tf.Session(). This (declarative) approach comes with many advantages but also some disadvantages. The main one is difficulty in debugging. This is where Eager execution come in. Recently, the TF team started working on it which offers an imperative execution of all operations. This means that you will be able to see the results of your model in runtime \u2014 isn\u2019t that awesome ^^.\n\nFor better understanding, I would this time recommend going thought the slides rather than the lecture notes. Both are useful but the slides (+ the notes under each slide) give wider perspective.\n\nThis lecture emphasizes on the implementation of word2vec model. It is used to give us a nice and powerful representation of words when we want to base our neural network on natural language.\n\nWord2vec can be used with 2 models \u2014 skip-gram and CBOW. Quoted from the lecture:\n\nThe lecture presents an explanation of the skip-gram model whereas the CBOW one is left for homework. I will give a solution to it in my next article.\n\nIf you want to have a better understanding of the word2vec model, I would recommend briefly going through Stanford\u2019s NLP course. Let me know if you have any questions so I can assist you.\n\nIn the next part, I will give solutions to Assignment 1 of this course. Hope you enjoy the series :)"
    },
    {
        "url": "https://medium.com/init27-labs/learning-to-understand-epsilon-f204636dbdc1",
        "title": "Learning to Understand Epsilon \u2013 init27 Labs \u2013",
        "text": "In a previous post I mentioned the use of epsilon in the SLR model. Here is a link to that post: Linear Regression part 2. Now I will attempt to explain in laymen\u2019s terms how to understand the use of this particular Greek letter within Statistics. Epsilon is referred to as an error term, but this can lead to a mindset which can be somewhat misinformed if not interpreted correctly. Here it is again below:\n\nUsing the label \u2018error term\u2019 for Epsilon is confusing in the sense that it sounds like you as a Statistician are using data to fulfill an interpretation created by the researcher. It begins to sound like if the data doesn\u2019t fit a particular design, then it\u2019s possible to consider that data as belonging to some sort of error equation, and ignoring it\u2019s presence from the dataset as a whole.\n\nTo remedy this issue, it is simpler to think of epsilon in its alternate form as a residual. Below is the formula for the residuals which is:\n\nThe first y represents an observation from the dataset, and the second y hat is the fitted value created from the simple linear regression model. The residual itself is a sample from epsilon. Using a previous example created by me in RStudio, (shown here at the bottom of the markdown), it\u2019s possible to draw a vertical line from each observation either up or down to the fitted line. The difference between these two creates the value for the residual as either positive (if the data point is above the line), or negative (if the data point is below the line).\n\nInterpreting epsilon as a \u2018residual\u2019 rather than an \u2018error\u2019 allows the Statistician to understand that the interpretations and inferences being done are only in relation to a particular model that previously had been chosen to be used on a given data set. Personally, I consider this to be a key viewpoint in allowing for a correct understanding of the statistical work being done.\n\nFor Data Scientists and Machine Learning Engineers, I believe that it would be incredibly fruitful to develop this insight further in their work doing modeling for various data. I think that as a researcher it is easier than not to develop bias towards one\u2019s own personal opinion. In a sense, even as a scientist you are prepared to bring more credibility than there inherently is towards one\u2019s own findings. Seeing that the term \u2018error\u2019 refers to a problem with the model and not the data makes it possible to see with clarity what the data is actually saying."
    },
    {
        "url": "https://medium.com/init27-labs/my-impression-of-stanfords-tensorflow-course-introduction-96b6054dc4ef",
        "title": "My impression of Stanford\u2019s Tensorflow course: Introduction",
        "text": "With the start of the second semester at Stanford University (January 2018), a new class was released \u2014 CS 20: Tensorflow for Deep Learning Research. Since during the day I fully focus on my at Speechify in SF, I am not able to attend any lectures or meet the professors. For that reason, I decided to do the course (+every assignment) remotely. Thankfully, Stanford is so welcome that they have publicly opened all the resources.\n\nI decided to document my journey in a series of blog posts. I am thrilled to share my impression of the course with you and, also, to further enhance my ML skills.\n\nMy plan is of writing follows the course structure which is ordered in a way that after 3 sets of 6 lectures, students need to submit an assignment. So I will do this:\n\nI will keep this introductory article short in order to focus on the course material from the next one. I will start with Overview of Tensorflow, Operations, Linear and Logistic Regression, Eager execution and Variable sharing and managing experiments.\n\nHope you enjoy the series. You can find Part 1 here."
    },
    {
        "url": "https://medium.com/init27-labs/reinforcement-learning-rl-for-the-intimates-eef924cd5ee4",
        "title": "Reinforcement Learning (RL for the intimates) \u2013 init27 Labs \u2013",
        "text": "If you\u2019re a geek of our league, I probably don\u2019t need to talk about the recent success of RL, but I will anyway.\n\nLet\u2019s start start with DQN?\n\nThe first algorithm to really hit the media, learning to play Atari games from scratch using only pixels of the screen as input!\n\nAnd you can consider that rather \u201cold\u201d, 2013 news.\n\nAll of this might seem a little bit magical and almost impossible, but it\u2019s not, for now just take my word that it is really simple. Sure, some fancy tricks and cool math are used here and there, but it all comes down to one simple thing:\n\nWow! Calm down! , I know. Hopefully by the end of this post everything will start to make sense. So let\u2019s start to get our hands dirty.\n\nI present you to the \u201cHello World\u201d of RL, the Grid World!\n\nThe rules are very simple:\n\nFirst step, represent our problem as something the computer can interact with, we can represent the grid as a 2D array:\n\nThe numbers in bold are the indexes. The choice of what the numbers represent doesn\u2019t really matter, you just need some way to differentiate the squares.\n\nNext we need to code the rules I just described above. We act in turns, we perform one action and the world gives us the consequence of that action. Generally speaking the world returns the next state, the reward and a flag signalizing if game is over.\n\nSo stepping into \u201cThe Cliff\u201d means death and we can represent that by giving the agent a negative reward, let\u2019s say -100, and signalizing the game is over. As I said, we\u2019re in a hurry, so every time step we\u2019ll receive a reward of -1 except if we reached the goal, then the reward will simply be zero and the world will signal the game is over.\n\nNow, remember what I said:\n\nWe\u2019re now ready to understand exactly what this means. Our agent receives a reward of -1 every time it makes a move, stepping into \u201cThe Cliff\u201d gives us a reward of -100, reaching the goal gives us a 0 reward and both actions end the game. So pause and think a little bit, what it means to maximize the sum of future rewards here? Since all of our rewards are negative we want to finish the game with a sum of rewards closest to zero as possible, and how we do that?? Finding the quickest route to the goal!!\n\nSo we defined our problem in a way that maximizing the sum of futures rewards (I have to say it a gazillion times, since it is indeed important) causes the agent to \u201csolve\u201d the world.\n\nSo by now you might be thinking\n\nI present to you the Q-learning algorithm! Your (possibly) first reinforcement learning algorithm.\n\nSpoiler Alert: \n\nWe\u2019ll get there in the Next Post, Stay Tuned."
    },
    {
        "url": "https://medium.com/init27-labs/tackling-adversarial-examples-introspective-cnn-b28c67176575",
        "title": "Tackling Adversarial Examples : Introspective CNN \u2013 init27 Labs \u2013",
        "text": "Convolutional Neural Networks(CNNs) are the workhorse of many Computer Vision tasks. Image Classification is the most common one. We have achieved state of the art results on this task over the period of years exceeding human level accuracy. But, there is a problem with CNNs. It is called the problem of adversarial examples.\n\nAdversarial examples are those which can fool the neural network to be of one class while being of other. WHOA! What does it even look like?\n\nHow can a CNN trained on millions of images can be so stupid to predict a clear-cut cat to be a toaster? Let\u2019s look at one more example from a paper which came a few weeks back.\n\nIt turns out that even the best of the classifiers can be fooled by making small changes in the pixel values of an input image and the classifier will predict it to be any class your choice. If you are intrigued and want to fool your own CNN classifier then go to this blog post.\n\nThis is a big problem.Suppose an e-commerce company uses a classifier like this to predict whether there is any product related to banned categories e.g guns, drugs, animals etc. One day someone decides to fool its classifier and tries to sell some of the banned categories. \ud83d\ude2e\n\nEver since I got to know about this I wanted to find solutions tackling this problem. Researchers are still doing work in this area e.g Capsule Networks by Hinton also tackle this issue. One more paper which I read last week also tries to solve this problem. However, solving this problem is not the primary objective of that paper it is just a by-product. The solution they proposed seemed to be very mystic to me and mystic is interesting. Instead of replacing the CNN like Hinton they used a different approach by making some modifications in the current CNN architecture. They named it Introspective Convolutional Neural Net.\n\nIntrospective CNN is nothing but a normal CNN endowed with generative capabilities. Generative capabilities mean that it can generate its own examples similar to the dataset. It employs a strategy called reclassification-by-synthesis. ICN tries to iteratively generate negative examples by a sampling process and improve its classification accuracy by adding those generated or pseudo negative examples in the original dataset.\n\nThe basic idea of ICN is similar to how we train and become expert in something. When we want to master a mathematical concept we try to solve its hard examples or questions. After some iterations, the generated examples get closer and closer to the class under consideration and the decision boundary tightens hence improving the robustness.\n\nIn supervised classification, a classifier is only focused on the decision boundary to separate the given samples and the classification on the unseen data may not be accurate because the training data is not sufficient to cover the entire data space.\n\nThe image above shows the contraction of decision boundary over training iterations for a simple 2-d classification of two classes red and blue. Initially, the boundary is a normal decision boundary. Then the model starts to generate pseudo-negative examples and these are added to the training set thus increasing the training size during training. These examples get closer and closer to the red class. Eventually after training on hard examples the decision boundary contracts and covers only the red class thus improving the model\u2019s robustness. The training stops when the model accuracy starts to go down as the generated negative samples come closer to the target class. In the end, adding pseudo-negatives might degrade the classification result since they become more and more similar to the positives. We repeat the same procedure for all the classes in our dataset.\n\nThis method decreases the error on benchmark datasets like MNIST, CIFAR10 and, SVHN. But I was more concerned with its performance on adversarial examples.\n\nThey use a method called fast gradient sign which can cause a maxout network to misclassify 89.4% of adversarial examples generated from the MNIST test set.\n\nSadly no! No matter how much accurate system we create in present time, even then adversarial examples can easily fool them.\n\nTackling these kinds of problem is not a destination but a journey where our system will get stronger and stronger so does the adversaries."
    },
    {
        "url": "https://medium.com/init27-labs/linear-regression-pt-3-8f449d4a8bbe",
        "title": "Linear Regression pt. 3 \u2013 init27 Labs \u2013",
        "text": "In this part of my series on Linear Regression, I think that it\u2019s a good opportunity to introduce the Linear Algebra that is used within Linear Regression. If you have been following my previous posts, you will have seen that the Simple Linear Regression (SLR) model can be represented as this:\n\nAn interpretation of this model would involve temporarily ignoring the error term epsilon, and seeing that there is an \u2018ideal regression line\u2019 that passes through a linearly associated set of data points on an X and Y scatterplot. The line is created with the betas that I mentioned in a previous lesson, and can be seen as the plane in the image below. Just to make sure that you have an accurate understanding of the concept, this is merely a hypothetical regression plane, and there could potentially be more accurate regression planes that exist for the data.\n\nFrom the image it is possible to see that for a given point x, there is an associated point y that exists vertically above it, and is different from the \u2018True Regression Plane.\u2019 The difference between the point y and the regression plane is the error term epsilon that is within the equation. It can be positive if it is above the plane, or negative if below the plane. So for a dataset with two columns of x and y data points, they can be interpreted this way for a total \u2019n\u2019 number of pairs.\n\nHowever, this can be a tedious way to write out such data points, and can be written in another way which is more convenient to work with. To avoid writing out an entire equation for each pair of data in a potentially larger set of data, it can be shortened using vector notation from Linear Algebra. This will especially save time and energy in Multiple Linear Regression (MLR) where there are multiple pairs of X\u2019s and betas (indicating multiple predictors). The shortened version can be seen in the following formula:\n\nFor those who have no experience with Linear Algebra in college, I will try to explain the more simple aspects which are at play here. Previously there were separate equations that represented the order of Y\u2019s from an imaginary data set. The set of Y\u2019s have been collected into what is known as a vector. The notation for vectors in Linear Algebra can be used with bold letters, a particular arrow pointing to the right (from physics), or a squiggly line below the variable (similar to the squiggly representing a typo in Microsoft Word).\n\nIf this is new to you, perhaps you would enjoy learning more in depth about matrix math through Khan Academy.\n\nUnderstanding the Linear Regression model in terms of vectors and matrices is vital for having a more intuitive understanding of its use within both Data Science and Machine Learning. A common package within Python that utilizes vectors and matrices for Linear Algebra is Numpy. In order to deal with large datasets, it\u2019s important to place data into arrays which can be thought of as vectors and matrices. This makes it possible to perform mathematical operations on them such as Linear Regression.\n\nHere is an example from scikit-learn.\n\nDo you enjoy learning about Statistics and it\u2019s applications in Data Science and Machine Learning? For future updates feel free to subscribe to my posts via the subscribe form in the right panel. Also, I appreciate any positive criticism that can be sent through the contact form in the menu bar."
    },
    {
        "url": "https://medium.com/init27-labs/linear-regression-pt-1-158359a7d0cb",
        "title": "Linear Regression (A Statistician\u2019s plots) pt. 1 \u2013 init27 Labs \u2013",
        "text": "For the Standard Normal Distribution, it can be said that there\u2019s a calculated 68.2% chance that the grain of sand was within a central part of the mound (assuming that the mound of sand had a Standard Normal Distribution, there are other types of distributions).\n\nHere is a refresher in case you haven\u2019t learned it before or have merely forgotten.\n\nNow combining the two, a regression line with the bell curve, we are able to understand this new idea:\n\nBasically, we now are able to see that the distribution of the data along a regression line follows a certain probability. With this new insight into how to analyze a seemingly random scatter plot, we can begin to understand the usefulness of linear regression and it\u2019s inclusion within the fields of Data Science and Machine Learning.\n\nUsing the above image as an example, if we are given a new piece of data that is outside of this sample, and it has an \u2018x\u2019 value of 30 (the independent variable), the \u2018y\u2019 value (dependent variable) can be predicted to lie within a certain prediction interval up to a specific percentage of certainty. Making things up, it can be thought to have a 90% of being within the range of [200, 300].\n\nAlthough I have not so much personal experience with Machine Learning and Linear Regression, I do know that from a Data Science perspective, the addition of the regression line itself makes it possible to clearly visualize apparent trends in data, and to see how they are progressing. It makes it possible to distinguish data which is useful for prediction, and data which either needs to be transformed or would be a poor source for predicting future events."
    },
    {
        "url": "https://medium.com/init27-labs/init27-labs-3b7a30e54be1",
        "title": "init27 Labs \u2013 init27 Labs \u2013",
        "text": "init27 is an initiative by Deep Learning and Computer Vision geeks.\n\nPersonally, I\u2019ve had some working experience via internships and and I\u2019ve worked on a few projects by myself. Check them out here. I\u2019ve also completed Udacity\u2019s Deep Learning Nanodegree, and just started with the Self Driving Car Nanodegree as well, completed the FastAIv2 as a part of the International Fellowship. I\u2019ve interned at IIT-Madras, ONGC, IIT-Roorkee. I\u2019ve worked as a Computer Vision Engineer on an Autonomous Underwater Vehicle\u2019s Software suite (AUV) and worked with Embedded Systems.\n\nHowever, as a beginner I had always struggled with learning about Deep Learning or Computer Vision. (TBH, I still consider myself to be a noob. But by beginner, I mean anyone who is standing at the starting line)\n\nHere\u2019s what my learning experiences were like:\n\nSo as init27 \u2018lab\u2019, We\u2019ve decided to start this initiative as a community to help anyone who finds Deep Learning/Computer Vision or even coding in general to be difficult to start with. We hope to do this by putting out resources to for beginners.\n\nNo questions is too silly, neither is any topic too basic.\n\nWell, just leave a comment below or shoot me a tweet @bhutanisanyam1.\n\nAnd We\u2019d be happy to help you with it!\n\nI personally also hope to do weekly or bi-weekly google hangouts to discuss and brainstorm ideas or do walkthroughs as time permits.\n\nWe consider ourselves fortunate enough to be able to pursue paid Courses, Nanodegrees and even be able to purchase the expensive books in some cases.\n\nHowever, since we\u2019re truly Open Source geeks. \n\nWe would love to help others find a way to get started in the field. This is not a monetized attempt neither do we expect profits out of the same. We wish to give back what we have learned, and guide the people that are struggling with applying knowledge or others who might just be getting started.\n\nBy no means are we the experts of the fields and by no means do we even hope to claim that, or call us experts. This is a way to guide others, by creating Tutorials, or curated lists or contributions to their projects too.\n\nWe would also love to share our knowledge by inviting contributors to our Garage Projects.\n\nIf you would like to join us to help the community, you\u2019re very welcome to join us. We\u2019d love to give you the complete credit of contributions that you make.\n\nHere is the little content that we\u2019ve put out:\n\nA lot more coming soon! Later, we\u2019ll be creating detailed walkthroughs of the Projects that we are working on to help you recreate them or maybe extend them to cases better than our abilities."
    },
    {
        "url": "https://medium.com/init27-labs/linear-regression-pt-2-dea063eb63a0",
        "title": "Linear Regression pt. 2 \u2013 init27 Labs \u2013",
        "text": "For this post I\u2019m going to try and explain what the equation of a line from Algebra appears like in Linear Regression. The following is the equation that I\u2019m referring to in part 1.\n\nNow I will introduce you to the Simple Linear Regression (SLR) model. SLR refers to a linear regression model involving just one X variable. If we were to extend it to several X\u2019s, then we would have Multiple Linear Regression (MLR).\n\nTo state it in formal terms I will use the following wording, \u2018For the simple linear regression model\n\nwhere epsilons are independent with mean 0 and variance sigma squared, we use the method of least squares and estimate the parameters to be beta hat 0 and beta hat 1.\u2019 (end of formal statement)\n\nThe difference now is that \u2018b\u2019 (from the equation of a line) has moved to the front and become beta 0, while \u2018mx\u2019 (from the same equation of a line) has moved behind it and become beta 1 multiplied with X indexed by \u2018i\u2019. The additional epsilon refers to an error term. The meaning of which I will discuss in the future.\n\nThe equation for the beta hats are as follows:\n\nNote: It would be helpful to think of these two betas as constant coefficients, and therefore have constant values within each sample size."
    },
    {
        "url": "https://medium.com/init27-labs/statistical-variables-pt-1-91fea94d0599",
        "title": "Statistical Variables pt. 1 \u2013 init27 Labs \u2013",
        "text": "Data Science has mushroomed greatly in the past few years. However, I am not sure if many people are aware of what it is. I myself admit that I don\u2019t quite know a solid answer. I\u2019m a 3rd-year student at a respectable university within my country, and my major is called, \u2018Statistical Data Science, B.S.\u2019. To be fair, I have only been at the university for one quarter thus far as a transfer student, and I\u2019m confident that in the future there will be a knowledgeable professor who is capable of explaining to me from an academic point of view of what data science truly is.\n\nUntil that time, I can make use of a clue within the title, the word data. What is data within the field of Statistics? \u2018Data are the actual pieces of information that you collect through your study. (source)\u2018\n\nOne of the beginning steps that we must take before utilizing various models to understand predictions is that we must understand the dataset that we are given. A data scientist has said before, \u2018Let the dataset change your mindset.\u2019 This process is known as Exploratory Data Analysis or EDA.\n\nI\u2019m going to try and explain to you the two types of data that exist within the field of Statistics. The two types of data are Categorical and Numerical.\n\nI feel that as someone who aspires to become a Statistician, the type which is easiest to understand is numerical data. Numerical data are data which can be broken up into numbers. After identifying data as numerical, it can be further broken down into either discrete or continuous.\n\n\u2018Discrete data can only take certain values (source).\u2019 In other words, there are 2 dogs, and not 2 and a half dogs. Or the pair of dice rolled together to come up with the values 2 and 4. I think that an easy way to identify them is that they are whole numbers, and don\u2019t connect to infinity.\n\nContinuous data, on the other hand, can take on any value within a specific range. If you imagine measurements such as height or weight, they can be narrowed down to fractions or decimals. Variables such as time can be thought of as continuous. I say that these values are in a way connected to infinity because within a given distance or even a span of time there could be infinite values. Here is a brief video that can explain.\n\nNow that we understand numerical data in terms of their discrete and continuous cases, let\u2019s move on to the next type of data called \u2018Categorical data.\u2019 After getting into a long discussion about infinity, maybe this type of data will prove to be more intuitive after all. Categorical data is in a sense data which aren\u2019t numbers. Or to say it more clearly, data that is descriptive using language. For example, tall, short, fast, slow, blue, green, United States of America, China, or India. If you see examples such as these in your dataset, it would be simple to instantly imagine that they\u2019re the categorical variables within your dataset.\n\nAnother way to initially see these two types of data is as either qualitative or quantitative data. Qualitative data are categorical, and quantitative data are numerical. Better than me explaining is these examples which have been borrowed from Jerry Linch\u2019s course:\n\nTo expand on this understanding of qualitative versus quantitative, here are more examples that expand on the previous:\n\nThere are now other types of categorical variables which I will now mention. For curiosity\u2019s sake, I read that there are three types of these variables, but I will only discuss how to identify certain variables which may seem numerical but are actually categorical.\n\nThe clue here is that if you see a group of data such as this in your dataset, and if you found the average, would it make any logical sense? Clearly, the answer is no. Averaging a set of zip codes most likely will no give you a clue about the data or have very much valuable meaning.\n\nAs a side note, you may be thinking that categorical variables aren\u2019t so useful since it wouldn\u2019t make sense to plug them into an equation and perform some sort of prediction modeling. This is actually not true, they are still quite useful for such a process. Wouldn\u2019t it make sense to say that gender is useful for predicting whether or not a group of people are likely to become the president of a country? (I\u2019m just implying that there are very few female presidents in the history of the world)\n\nI will explain how these categorical variables can be used. I actually had the pleasure of learning how to do this task in my Linear Regression course with Prof. Chen last Fall at U.C. Davis. However, I feel that this post has gone on for quite some length, and so I will continue this lesson in part 2."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-5-45ee269f98e7",
        "title": "Basic Tutorials Part 5 \u2013 init27 Labs \u2013",
        "text": "In this post we discuss the Python Programming basics.\n\nAn overview of why we want to use the langauge has been given in Part 0 of this series.\n\nThis post shall serve as an introductory-crash course to Python.\n\nHere is the accompanying Notebook, the code portions discussed here and in the Notebook will be with bits and pieces left for the reader to figure out. We expect a more active participation in learning. Do leave a comment below if you feel anything is missing or have any doubts.\n\nWe suggest you use Jupyter notebooks (Details were discussed in the early posts)\n\nNotice the indents. Python uses indentation instead of using braces to mark the bodies.\n\nTuples can be created by () braces\n\nLists are created by enclosing within [] braces\n\nLists can be roughly linked to deques in their functionality\n\nDictionaries store values in the form of Key Value Pairs\n\nList comprehensions are a neat trick to collapse several lines of codes into one"
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-4-f6ea21045564",
        "title": "Basic Tutorials Part 4 \u2013 init27 Labs \u2013",
        "text": "Welcome to this tutorial, Part 4 of the series on using Jupyter notebooks.\n\nAs a seasoned practitioner, you might want to demonstrate your code. Your insights and the techniques used.\n\nThe notebook is a web application that allows you to combine explanatory text, math equations, code, and visualizations all in one easily sharable document.\n\nNotebooks have quickly become an essential tool when working with data. You\u2019ll find them being used for data cleaning and exploration, visualization, machine learning, and analysis.\n\nThese support one of my favourite philosophies of Literate programming. To qoute Donald Knuth\n\nJupyter notebooks grew out of the IPython project started by Fernando Perez.\n\nIPython is an interactive shell, similar to the normal Python shell but with great features like syntax highlighting and one of my favourite-code completion (For the note, I\u2019m not lazy, I\u2019m a relaxed typer)\n\nThe central point is the notebook server. You connect to the server through your browser and the notebook works as a web app. The code is sent through the server to the kernel. The kernel runs the code and sends it back to the server, then any output is rendered back in the browser.\n\nThe notebooks are saved as .ipynb files, in a JSON format.\n\nJupyter isn\u2019t Python exclusive! The new name Jupyter comes from the combination of Julia, Python, and R. The basic working is the same for any given language. Just the kernel running everything in the background changes.\n\nNote: Since the Notebooks do not have to be on the same machine, we will use to render notebooks on our machine while using a cloud vendor\u2019s offering.\n\nWhen in the environment\n\nYou\u2019ll see a little box outlined in green. This is called a cell. Cells are where you write and run your code.\n\nJuputer also supports Markdown. In the toolbar, click \u201cCode\u201d to change it to Markdown and back. The little play button runs the cell, and the up and down arrows move cells up and down. Notice, the colour is now Blue.\n\nNow there is a lot of things in the toolbar, feel free to play around a bit and familiarize yourself. Here are a few:\n\nTo activate a cell, press enter when it is highlighted.\n\nNow, in my defence I\u2019m not lazy, the touchpad is just too far down on Macbook. So here are a few commands that I think are common:\n\nThese will often become intuitive and you will find the faster rather than searching for these commands via the GUI\n\nThese are few of the shorcuts that are worthy of a quick mention. There many more mentioned in our Git Repo\n\nTo get a list of all commands,\n\nMarkdown is the widely used format to create web documents. This post is written in Markdown. So it\u2019s worth to mention a few of the Syntaxes that are common.\n\nYou may want to leverage this when you create a notebook for showcasing your models/results.\n\nThis is a basic overview of the funtionalities offered by Jupyter notebooks, this is by no means an exhaustive list."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-3-8ca1bf9627b8",
        "title": "Basic Tutorials Part 3 \u2013 init27 Labs \u2013",
        "text": "Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in Part-1 of this series.\n\nPackage managers are used to install libraries and other software on your computer. Pip is the default package manager for Python libraries.\n\nConda is similar to pip except that the available packages are focused around data science while pip is for general use.\n\nHowever, conda is not Python specific like pip is, it can also install non-Python packages but it does include all the Python packages and supports pip.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nConda is the package of Anaconda. If you\u2019ve used virtual env, pip: it includes both of these functionalities along with a few extra.\n\nWe will use conda because we\u2019re geeks. Just kidding, conda will be required when you need to access a cloud instance since you won\u2019t have access to GUI. Plus, it\u2019s easier to type 1 command than click a few buttons (Okay, maybe I wasn\u2019t kidding about the geekiness).\n\nAnaconda navigator which serves as a GUI to the Conda package and includes it is supported on Linux, OS X and Windows.\n\nYou can download the Navigator from Here\n\nSelect your OS and follow the Steps. These are pretty basic and have been omitted. If you\u2019re stuck anywhere or need help, please ask us in the comments below.\n\nThe commands below are to serve as a syntax. We\u2019ve create a Github repository for you to use. Feel free to use the code from there\n\nGithub repository link (Link to be updated soon)\n\nTo use an environment:\n\nNotice that your prompt has a (envname) before it.\n\nTo get out of an environment:\n\nYour project has a certain set of required libraries in order to work. When sharing your project, you share your requirements file so that one can create an environment directly from these.\n\nThis creates a YAML file that contains the list of dependencies of the project.\n\nThis creates a new environment with the name as is \u2014 inside the YAML file.\n\nThis is by no means an exhaustive list of the commands. These are meant to serve for an introductory purposes.\n\nCheckout the Conda user guides if you want to learn more.\n\nHere is another interesting read Common Myths and Misconceptions"
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-2-97a6e04b35e8",
        "title": "Basic Tutorials Part 2 \u2013 init27 Labs \u2013",
        "text": "A version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others.\n\nThe most common way of using git is via the Command Line interface. We will demonstrate this because we are geeks! (Er, it\u2019s needed when you\u2019re working remotely)\n\nTo get help\n\nIf you get something like\n\nGit Works as shown: Unstage refers to making the file \u2018staged\u2019 from being untracked (In English, the file is added to our repository in the eyes of Git)\n\nUntracked: Changes are not tracked Unstaged: These aren\u2019t a part of Git\u2019s repository.\n\nReturns the status of the Repository\n\nThis adds the File FileName to the staged area\n\nAdds everything in our repository to git\n\nCommit: When you make changes in a repo, these need to be commited. By design, Git requires every commit to include a commit message describing the purpose of the commit. Typically, this takes the form of a single line, usually limited to around 72 characters, with an optional longer message if desired\n\nTo see a record of your commits\n\nWhen you have made changes in your repository, that have not been commited yet.\n\nThis shows the differences between the previous commit and the current one. (For all you Linux geeks, it runs the diff command in the background)\n\nWhen someone wants to submit changes to your repository, they submit a pull request. You review these changes and then \u2018Merge\u2019 the request into your repo.\n\nWell, generally speaking, your Repository will be available for anyone to view once you put it on GitHub. But Collaborators are people that have direct access to the repo. Consider them the administrators.\n\nDifferent collaborators work on the code simultaneously. To avoid hinderence, everyone works on a branch. A branch is the copy made of the code at point of time, which is used to work upon in a manner to keep other branches unaffected.\n\nMaster branch contains the main code for your Project\n\nA site designed to facilitate collaboration with Git repositories and it\u2019s free to use.\n\nSign up for a GitHub account Here.\n\nNow for all purposes of managing a local repository, I recommend you start with Github Desktop which provides a neat GUI to interact with GitHub and has a set of neat tutorials to get you started.\n\nThis is a fairly advanced topics to share amongst complete beginners and is skipped over for a later post in the series. (Or an update)\n\nThis Blog post might feel a little incomplete-that is because it\u2019s been created in a way to force you to explore the Software. Git is a software to be used and explored, hence that part is left out as an intensive excercise to the reader.\n\nThat being said, if you have any doubt: Do leave a comment below and we\u2019d be happy to help resolve it."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-1-3ba416f2ba65",
        "title": "Basic Tutorials Part 1 \u2013 init27 Labs \u2013",
        "text": "These terms are usually used to refer to a Black and white window where people (geeks) usually type in code and work with.\n\nBASH: Bourne Again Shell, is what runs your commands when you type them.\n\nTerminal: The windows is called Terminal, is where you type the commands.\n\nGiven these reasons, we chose to use Terminal for our work.\n\nKnow that this is by no means an exhaustive list and is meant to provide an introductory walkthrough.\n\nThere are many more things to be explored. Feel free to ask for more resources or doubts in the comments below.\n\nThe $ is the prompt. Which means that the terminal is ready and is waiting for your commands to start.\n\ncd=Change directory, by changing your directory. You are changing your present working directory.\n\nThese are the absolute basic commands that should get you started. Feel free to explore more and ask in the comments below for help."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-0-90f623b291e6",
        "title": "Basic Tutorials Part 0 \u2013 init27 Labs \u2013",
        "text": "We will follow a bunch of libraries in the course and this post intends to provide an overview of the same and justification for using these. If you have a different viewpoint or want to question us on any of these points, please leave a comment below and we\u2019d love to chat about it.\n\nThat said, we will probably stick to these options because after extensive exploration, we have concluded that these are the best options for us. But we\u2019re open to any suggestions and places for improvements!\n\nA version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others. In addition, using version control also makes deploying production websites and web applications much easier.\n\nAt a certain point, you might end up breaking your project and you might want to do a little version control. Git to the rescue!\n\nIt\u2019s a place to brag about repositories by showcasing them and at the same point a place to host the code to allow contributors to add to the Project.\n\nNow many of us here would be beginners and might pick a GUI over a command line, but it turns it that command line can be better than GUI. Some functionalities are just faster done with Command Line, and when you use a cloud service. You will need to use a Command Line to perform actions on your machine.\n\nMost of the commands are run in BASH which is a shell that runs your commands in the background.\n\nA terminal is the interface to the BASH environment on your machine. When you use a terminal, you use the interface to access the BASH environment on your machine\n\nAnaconda is another Open Source project that is the most used amongs the Data Science world. We will chiefly be using Conda and Jupyter Notebooks.\n\nPackage, dependency and environment management for any language \u2014 Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN\n\nConda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in these series.\n\nPython is the intensely used by Deep learning practitioners to cutting edge researchers.\n\nIt\u2019s an Open Source langauge that has gained tremendous fame in the recent years\n\nThis post serves as a basic overview, hence many technical details will be skipped here.\n\nThe reasons why we want to use this are:\n\nThis series will feature an introduction to Python programming and using it\u2019s two most important libraries for Data Science:"
    },
    {
        "url": "https://medium.com/init27-labs/installation-of-opencv-using-anaconda-mac-faded05a4ef6",
        "title": "Installation of OpenCV using Anaconda (Mac) \u2013 init27 Labs \u2013",
        "text": "2. Follow the Installation instructions, should be pretty standard, however Continuum has a guide here.\n\nFor other additional packages: Click here\n\n4. Type the following lines of code"
    },
    {
        "url": "https://medium.com/init27-labs/andrew-ngs-new-course-6e6a4f6c3aef",
        "title": "Andrew NG\u2019s new course \u2013 init27 Labs \u2013",
        "text": "More cool stuff at My Website.\n\nAndrew NG\u2019s new venture features a bunch of courses forming a \u2018DeepLearning specialisation\u2019 on coursera.\n\nAlthough the courses launch on 15th, the content is open to access and the assignments and quizzes are accessible as well.\n\nAs of now, 3 out the 5 courses are available. My experience has been great from these courses. I really feel the gaps that I\u2019ve felt while pursuing the Machine Learning course (and repeating it over several times) have been covered thoroughly. This course feels like a mature version of all coursera courses. It addresses the industry and academia gap, and isn\u2019t theoretical completely. There is plenty of coding too, even though DL is thoroughly Math, Algorithm and statistics (according to my understanding of the field). Yet the course offers enough experience to suffice the gap.\n\nThe three courses make up a perfect weekend task, I really look forward to studying CNN, Sequence models as soon as they are unlocked.\n\nI really loved the (optional) interviews with the Heroes of Deep Learning. Being able to relate to their motivations to the field and path is really motivating.\n\nI\u2019d really love to hear from you about more learning resources related to Deep Learning, AI and I look forward to working on a few projects to gain some skills."
    }
]