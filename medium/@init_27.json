[
    {
        "url": "https://medium.com/init27-labs/readerbot-an-event-driven-chatbot-54e960eecc00?source=user_profile---------1----------------",
        "title": "ReaderBot: An Event Driven ChatBot \u2013 init27 Labs \u2013",
        "text": "Below, is the code for ReaderBot: A EDP based chatbot that interacts with you and opens articles that you\u2019d like to read based on your responses.\n\nFeel free to check the GH repository. Below, is the explanation of the key functions.\n\nFor Example, consider a callback for Self Driving Cars.\n\nThis is a callback that the Bot is expected to execute when provided an input of \u201cSDCs\u201d\n\nWe have to populate a local dictionary for accepted messages for the pre-defined responses, such as the SDC callback shown above.\n\nHere, We\u2019re creating a local dictionary of accepted messages for standard responses.\n\nThis would open in a new tab, a post on Self Driving Cars."
    },
    {
        "url": "https://hackernoon.com/readerbot-an-event-driven-chatbot-for-medium-a8a055ef1f6a?source=user_profile---------2----------------",
        "title": "ReaderBot: An Event Driven ChatBot \u2013",
        "text": "Below, is the code for ReaderBot: A EDP based chatbot that interacts with you and opens articles that you\u2019d like to read based on your responses.\n\nFeel free to check the GH repository. Below, is the explanation of the key functions.\n\nFor Example, consider a callback for Self Driving Cars.\n\nThis is a callback that the Bot is expected to execute when provided an input of \u201cSDCs\u201d\n\nWe have to populate a local dictionary for accepted messages for the pre-defined responses, such as the SDC callback shown above.\n\nHere, We\u2019re creating a local dictionary of accepted messages for standard responses.\n\nThis would open in a new tab, a post on Self Driving Cars."
    },
    {
        "url": "https://hackernoon.com/do-you-trust-this-computer-bc4ce2865b36?source=user_profile---------3----------------",
        "title": "Do you Trust This Computer? \u2013",
        "text": "We\u2019re living in a 2018 with everyone being a fan of Technology.\n\nMost of us are almost unaware of the amount of Digital Interactions we have with our world today.\n\nDoyoutrustthiscomputer is an amazing movie by Chris Paine which takes a critical stance in reminding us that \u2018AI\u2019 is not a scientific fantasy anymore. Infact, some extent of it is already here. It serves a gentle reminder to think and re-think about AI- regulations, controlling and what happens if we\u2019re not careful with the things that we don\u2019t understand.\n\nIf you Follow Elon Musk, you probably would have already watched the movie by now. \n\nIf you haven\u2019t, go check it out at doyoutrustthiscomputer.org\n\nHere are my views from the movie.\n\nThe movie starts with wicked cool references to \u2018AI Sci Fi\u2019 from the 90\u2019s.\n\nNext it discusses the amazing breakthroughs we\u2019ve achieved with Technology.\n\nIt is astonishing that what we even as creative writers and directors imagined would be \u2018Sci-Fi\u2019 is now a common reality.\n\nWe\u2019re hand in hand with Technology. \n\nI\u2019m a college student, and it\u2019s pretty normal to own a cellphone, a Laptop maybe a smartwatch, a tablet?\n\nToday, we\u2019re generating data at a speed that was un imaginable a few years ago.\n\nFacebook itself has 2B users. \n\nCollege students practically live on Instagram. \n\nYou can follow almost any person on earth on Twitter without even knowing them personally.\n\nVarious startups and research in the Domain are mentioned.\n\nYou\u2019re warned about the possible negative impacts of \u2018AI\u2019.\n\nViewpoints from the greatest cutting edge researchers, Entrepreneurs, Practitioners are presented.\n\nWe\u2019ve Boston Robotics robot that are capable of doing mechanical movements like humans.\n\nAffectiva is capable of detecting human emotions from our facial expressions.\n\nSelf Driving Cars are here.\n\nDeepMind is beating Humans at games we thought it would take atleast a 100 years to beat us at.\n\nThroughout the movie, even the animations of the movie itself are have a dark atmosphere.\n\nWe\u2019re constantly reminded what might happen if things go wrong?\n\nTechnology is moving at an unstoppable rate, which is unavoidable.\n\nThe Example of Aircrafts is given: The Wright brothers conducted their first flight in early 1900s- a few years later we have commercial Airplanes.\n\nNow our concern isn\u2019t flying-it\u2019s if we\u2019d get the aisle or window seat.\n\nFlying Cars are about to become common too!\n\nWe know that nations are working on Autonomous weapons.\n\nThe questions asked are very fundamental:\n\nWhat happens when if AI isn\u2019t de-centralized?\n\nUnlike a dictator that can be removed or assassinated, AI will be immortal.\n\nWhat happens when our data is used against us?\n\nEven currently, the researchers don\u2019t understand every bit of the AI systems that they build.\n\nHow do we control a thing that is more powerful, bigger than us, smarter than us?\n\nAI is code. It has no emotions. It has a goal that is needs to achieve. \n\nWhat happens if we\u2019re in it\u2019s path of the goal?\n\n\u201cThe idea isn\u2019t to stop the Killer robots on Street, it\u2019s to prevent them from happening. \n\nIf they\u2019re here, it\u2019s already too late. \u201d\n\n- Elon Musk."
    },
    {
        "url": "https://hackernoon.com/why-every-coder-needs-a-mentor-78d59d21c7c?source=user_profile---------4----------------",
        "title": "Why Every Coder Needs a Mentor \u2013",
        "text": "Growing up, coming from an Indian Parentage- I\u2019ve been really blessed to have my Parents as my Mentors and friends to guide me during every step of my life- Throughout my Childhood and even during my School Life.\n\nMy Parents were there to guide me during every step of my life, To correct me and to show my next path.\n\nI had always this love for \u2018Coding\u2019 in general and I wanted to pick up Programming as a my Career Path, Which I did.\n\n\u2018Coder\u2019 is a very generic Term. Anyone who is interested in working or works on Software already is in the Software industry.\n\nIn 2018, Potentially you don\u2019t even need to go to school for learning. Just google anything that you want to learn. Join an online bootcamp or an online MOOC. Maybe jump on a doctored path such as a Nanodegree.\n\nLast Year, I decided to get a taste of the Deep Learning Nanodegree. Deep Learning back then, wasn't openly taught by any MOOC and the ND appeared to be great.\n\nUdacity-among the many amazing offerings in a ND, connects us with a Mentor who helps us, guides us and keeps us a check on us during our Learning Path. \n\nHowever, once you \u2018graduate\u2019, you\u2019ll have to part ways with your Mentor.\n\nSo, what does a \u2018graduate\u2019 or maybe someone who isn\u2019t on a Udacity learning path do?\n\nAs a learner, or even a Creator- There are multiple paths to mastering or getting started, and you need someone who can guide you, correct you and show the path that is best for you: To help boost your confidence and also allow yourself to keep a reality check. \n\nYou need a Mentor.\n\nAny field in CS has a huge depth to it and you can get lost easily.\n\nConnecting with Mentors is really hard.\n\nMy approach to the same has been brute-force Emailing every connection on my Linkedin that has an amazing profile and could give me pointers.\n\nLuckily enough, I found really great Mentors and friends via the Fast AI Community.\n\nRadek Osmulski has been amazing source of inspiration and help for many of us in the community. Radek has always helped me and guided me whenver I needed correction or I felt intimidated on my Deep Learning path.\n\nTuatini Godard has also been a really good friend and mentor. Even though he is really busy with his freelance projects-whenver I\u2019d contact him on slack or the forums. He will always take the time to help me.\n\nLucas Vazquez an amazing friend and a RL ninja, has always helped me, and very often helped me debug my code too!\n\nI\u2019m grateful to people like them who would take the time and energy to correct and guide a noob on his learning path and always help me correct and refine my articles.\n\nI\u2019ve always been a fan of an open community and open source itself. Here\u2019s how I\u2019m trying to give back to the community:\n\nAI Saturdays: I take much nerdy pride in the Title assigned to me: \u201cAI Geek Leader\u201d- I help mentor the huge global community on the forums and by curating learning paths.\n\nMentorcruise: Mentorcruise is one of the exclusive platforms that allows you to connect with Mentors. I\u2018m a Computer Vision, Deep Learning Mentor and I try to share my little knowledge that I\u2019ve picked up during my Self Taught Path.\n\nAt the same time, I\u2019d like to leave my Email here for anyone who\u2019d like to get in touch: sanyam.bhutani05@gmail.com"
    },
    {
        "url": "https://medium.com/init27-labs/quadcopter-physics-explained-c305da3ec141?source=user_profile---------5----------------",
        "title": "Quadcopter Physics Explained \u2013 init27 Labs \u2013",
        "text": "This articles discusses the physics behind Flights.\n\nThe Rotors act as wings. They generate thrust by rotating at Fast speeds, which pulls the air downwards and keeps the quad in the air.\n\nThe setups for Flying is simple:\n\nA,C spin Clockwise (From our point of view)\n\nPhysics says to be in stability the net forces acting on a body should be zero.\n\nSo if all the rotors were to spin in the same direction, it would result in a net Torque causing the complete Quad to rotate.\n\nThe attitude is defined with analogy from the Naval World.\n\nWe will use these terms to define the motions of our drone.\n\nTo Roll Rightwards (Our Right)\n\nThis creates a net forward force which causes the Drone\u2019s nose to Pitch Downward.\n\nTo Pitch Away from us\n\nWhy?\n\nTo keep the Net upward/downward force zero."
    },
    {
        "url": "https://hackernoon.com/quadcopter-physics-explained-468ee44ba40b?source=user_profile---------6----------------",
        "title": "Quadcopter Physics Explained \u2013",
        "text": "This articles discusses the physics behind Flights.\n\nThe Rotors act as wings. They generate thrust by rotating at Fast speeds, which pulls the air downwards and keeps the quad in the air.\n\nThe setups for Flying is simple:\n\nA,C spin Clockwise (From our point of view)\n\nPhysics says to be in stability the net forces acting on a body should be zero.\n\nSo if all the rotors were to spin in the same direction, it would result in a net Torque causing the complete Quad to rotate.\n\nThe attitude is defined with analogy from the Naval World.\n\nWe will use these terms to define the motions of our drone.\n\nTo Roll Rightwards (Our Right)\n\nThis creates a net forward force which causes the Drone\u2019s nose to Pitch Downward.\n\nTo Pitch Away from us\n\nWhy?\n\nTo keep the Net upward/downward force zero."
    },
    {
        "url": "https://medium.com/init27-labs/flying-car-series-announcement-e0332874575d?source=user_profile---------7----------------",
        "title": "Flying Car Series announcement \u2013 init27 Labs \u2013",
        "text": "The first few posts of Flying Car Series are live on the publication! \n\nLet us know what do you think about them!\n\nThank you for being patient with the release. A lot of things have been moving around and we had to delay the Flying Car Series, for which I apologise.\n\nRest assured, A lot more content will come in a more streamlined manner from now onwards, and weekly Flying Car posts too!\n\nAlso do checkout our YouTube channel for some Flying Car Pre-releases if you haven\u2019t already :)\n\nI\u2019m also happy to announce that we are now open to collaborations. If you\u2019re interested in contributing to our publication, please shoot me an email or tweet.\n\nThank you for subscribing!"
    },
    {
        "url": "https://medium.com/init27-labs/building-a-quadcopter-components-explained-diary-of-a-flying-car-engineer-2-7cb8231534c8?source=user_profile---------8----------------",
        "title": "Building a Quadcopter-Components Explained: Diary of a Flying Car Engineer #2",
        "text": "Note: The two are mentioned are as a combined unit for simplicity However have some significant technical different tasks. Autopilot controls the motors and Flight Controller-Flight execution.\n\nNote: Pitch: The twist of the propellers-is the linear distance moved by the Propellers in one complete rotation."
    },
    {
        "url": "https://medium.com/init27-labs/quadcopter-as-the-flying-car-test-platform-diary-of-a-flying-car-engineer-1-75221c88e148?source=user_profile---------9----------------",
        "title": "QuadCopter as The Flying Car Test Platform: Diary of a Flying Car Engineer #1",
        "text": "This article is aimed at explaining why applying our code to Quadcopters are a good Test Platform for flying Cars.\n\nAn everyday Boeing passenger plane, a F-22 Fighter jet classify as fixed wing aircrafts. These are highly efficient and are the choice for longer travel distances.\n\nThese have rotating propellers to act as wings and keep the aircraft flying. These are capable of VTOL (Vertical TakeOff and Landing) which makes them a better choice for landing in tight environments where we can\u2019t have long runways in place.\n\nI\u2019ll save some interesting Takeoffs for another post in the series.\n\nWe have taken the Crazyflie 2.0 as our flying car test platform, Udacity has generously offered us a discount on the Bundle. Also the kit will allow us to run our projects from the Flying Car Nanodegree, directly on the Nanodrone."
    },
    {
        "url": "https://medium.com/init27-labs/diary-of-a-flying-car-engineer-0-b7e369370686?source=user_profile---------10----------------",
        "title": "Diary of a Flying Car Engineer #0 \u2013 init27 Labs \u2013",
        "text": "Remember when I said My dream has been working on Self Driving Cars? \n\nI Lied.\n\nI\u2019ve always dreamed about Flying Cars after watching Back to the Future movie. I\u2019ve grown up watching the series and have always fantasised about pushing a button and transforming my car into hover mode whenever I\u2019m stuck in traffic and I\u2019ve wasted endless hours thinking how I could fly from my apartment to university.\n\nOfcourse I\u2019m passionate about Self Driving Cars. But Flying Cars have always been a dream. If you don\u2019t feel the same. I refuse to believe you.\n\nSo when Udacity Came out with their Flying Car Nanodegree; I had to apply right away. I was already pursuing the Self Driving Car Nanodegree and I was convinced that this is the best way that I come closer to my dream."
    },
    {
        "url": "https://hackernoon.com/quadcopter-as-the-flying-car-test-platform-diary-of-a-flying-car-engineer-1-d2e735d8e32e?source=user_profile---------11----------------",
        "title": "QuadCopter as The Flying Car Test Platform: Diary of a Flying Car Engineer #1",
        "text": "This article is aimed at explaining why applying our code to Quadcopters are a good Test Platform for flying Cars.\n\nAn everyday Boeing passenger plane, a F-22 Fighter jet classify as fixed wing aircrafts. These are highly efficient and are the choice for longer travel distances.\n\nThese have rotating propellers to act as wings and keep the aircraft flying. These are capable of VTOL (Vertical TakeOff and Landing) which makes them a better choice for landing in tight environments where we can\u2019t have long runways in place.\n\nI\u2019ll save some interesting Takeoffs for another post in the series.\n\nWe have taken the Crazyflie 2.0 as our flying car test platform, Udacity has generously offered us a discount on the Bundle. Also the kit will allow us to run our projects from the Flying Car Nanodegree, directly on the Nanodrone."
    },
    {
        "url": "https://hackernoon.com/building-a-quadcopter-components-explained-diary-of-a-flying-car-engineer-2-c9410b52fe61?source=user_profile---------12----------------",
        "title": "Building a Quadcopter-Components Explained: Diary of a Flying Car Engineer #2",
        "text": "Note: The two are mentioned are as a combined unit for simplicity However have some significant technical different tasks. Autopilot controls the motors and Flight Controller-Flight execution.\n\nNote: Pitch: The twist of the propellers-is the linear distance moved by the Propellers in one complete rotation."
    },
    {
        "url": "https://hackernoon.com/diary-of-a-flying-car-engineer-0-112b0747418a?source=user_profile---------13----------------",
        "title": "Diary of a Flying Car Engineer #0 \u2013",
        "text": "Remember when I said My dream has been working on Self Driving Cars? \n\nI Lied.\n\nI\u2019ve always dreamed about Flying Cars after watching Back to the Future movie. I\u2019ve grown up watching the series and have always fantasised about pushing a button and transforming my car into hover mode whenever I\u2019m stuck in traffic and I\u2019ve wasted endless hours thinking how I could fly from my apartment to university.\n\nOfcourse I\u2019m passionate about Self Driving Cars. But Flying Cars have always been a dream. If you don\u2019t feel the same. I refuse to believe you.\n\nSo when Udacity Came out with their Flying Car Nanodegree; I had to apply right away. I was already pursuing the Self Driving Car Nanodegree and I was convinced that this is the best way that I come closer to my dream."
    },
    {
        "url": "https://hackernoon.com/dear-hackernoon-e53f335085eb?source=user_profile---------14----------------",
        "title": "Dear , \u2013",
        "text": "I started writing with my First Article in Fall \u201917.\n\nI never had the courage to take up blogging seriously until I got into the Fast AI International Fellowship.\n\nThanks to the motivation from the amazing community. I decided to pick it up again.\n\nHere\u2019s my Story: I\u2019m an undergrad from India, my chief interests and dreams lie in the domain of Deep Learning, Self Driving Cars and Flying Cars (Yes, I do like to dream at the cutting edge).\n\nI\u2019m lucky and grateful to be enrolled in one of the best universities of my nation. Still however, my curriculum gets to SVMs at best when it comes to the fields of my interests. To be honest, given my interests- no school offers such curriculum to undergrads.\n\nI wanted to learn and share my ideas and story, so I went to the internet.\n\nEven though I was a noob coder when during my Freshman year in 2015:\n\nA few internships, a Udacity Nanodegree, and countless Coursera and edX MOOCS, a few litres of coffee and graveyard shifts later I was confident enough to start guiding others in my university via the technical clubs and evening meetups.\n\nBut I wanted to reach out to more enthusiasts.\n\nLater in 2017 I got exposed to the best course I had ever come across in my life: Fast AI.\n\nAmongst the cutting edge and kickass Deep learning practises that they encourage, and a major one being: blogging.\n\nThanks to the community, I decided to re-start with my journey of sharing what I learn. I wanted to give to the community-what I had learnt so that anyone who might be stuck in the situation I was yesterday, can learn from the me of today.\n\nI\u2019m no expert, I still would call myself a noob if you would ask me, my only motivation is to help other learners by sharing whatever tiny bits of knowledge I gain as I go across my 5\u20139 daily journeys\n\nOf course there are much better experts sharing their experiences, my aspiration was to help fill the gaps and add to the amazing communities in any way that I could.\n\nEarly this year I started with my Self Driving Car Nanodegree and my article got accepted to Hacker Noon.\n\nI was so excited, I had always been a fan of the publication and I\u2019d daily binge read articles from it.\n\nObviously I submitted my article right away. My main motive had been to write quality articles and not to worry about readership since I wasn\u2019t sure how my posts would get discovered.\n\nMy goal for 2018 was to get a few thousand total reads by the end and continue writing with focus on quality.\n\nBut this time I actually decided to pen down the impact of my article (Before submitting to Hacker Noon).\n\nHacker Noon as a platform \u2014 and even the editors of the publication and David Smooke specially has helped me so much during these few months.\n\nAs of March 24, 2018: I have crossed about 40k+ total hits on all of my articles. The article that was my first submission itself crossed a thousand reads!\n\nThe numbers are the only way I could explain what a change this has been for me.\n\nI was able to reach out to a humungous audience.\n\nToday, I hold the pride of being a Top Writer on Medium in Self Driving Cars.\n\nYes, Me. The plain writer who was almost going to quit blogging if I wasn\u2019t pushed so hard by the Fast AI community.\n\nThank you Hacker Noon for helping me reach to readers from all around the world. For helping me put out my thoughts and my technical tutorials for anyone who might have found them helpful.\n\nI\u2019m grateful to this publication for accepting all of my articles and I promise I will continue writing here. And hopefully get better with every key stroke and every clap.\n\nToday, I start my series of Flying Cars and I will continue writing about Self Driving Cars and Deep Learning."
    },
    {
        "url": "https://hackernoon.com/the-only-undergrad-and-indian-to-be-invited-to-present-at-anaconda-conference-my-deep-learning-d4bde583ffa4?source=user_profile---------15----------------",
        "title": "The only Undergrad and Indian to be invited to present at Anaconda Conference: My Deep Learning\u2026",
        "text": "I had joined an undergrad CS Programme with my goal to become a good coder.\n\nThat\u2019s it. No end goals- I wasn\u2019t sure what UI/UX was, what went into network development, the essence of being app developer.\n\nTL;DR: I was noob freshman who wanted to be a \u2018coder\u2019.\n\nI had taken my High School C, Java courses extremely sincerely-aced every single assessment, I started reading CLRS (Intro To Algorithms: MIT Press). I thought I was on a great start.\n\nUnder the Engineering curriculum in India, the Freshman subjects are aimed at General Engineering subjects: Physics 101, Civil Engineering 101, Electrical Engineering 101, CS 101.\n\nSo with the simple goal of becoming a better coder, I started by joining every single technical club my University had searching to learn about \u2018CS 202\u2019 since I was proud enough to be done with CS 101 during High school.\n\nI went ahead and signed up for every single workshop I could get my hands on.\n\nI signed up for a bunch of Coursera MOOCS.\n\nI wanted to explore every single field that appealed which I did:\n\nBy 2016, I was sure my interests lied in the domains of Deep Learning, Computer Vision and Robotics.\n\nI\u2019m lucky to be from one of Top Universities in my country, still when I had started out with my \u2018AI Endeavours\u2019: The university culture was focussed around Web and kickass App Development.\n\nWhich didn\u2019t appeal to me honestly. And I was the only one who would be digging around MATLAB equations from 5PM-9AM. (Mind you TF was just fresh out during that time).\n\nThere was a constant resistance from my Mentors and friends who would warn me that AI (Yes, The General field) itself is a fairly advanced topic and is something I should worry about when I\u2019m pursuing my Masters or I\u2019m doing my Ph.D.\n\nNeedless to say, Given the rebel I was-I still continued on with my journey. Also, during that time the Online communities were almost non-existent except for the coursera forums where often Andrew Ng would himself answer a few questions- I was lucky to have the best guidance from there. Sadly my undergrad programme didn\u2019t offer any ML/DL courses so that was the only go to.\n\nThere was almost a constant reminder from my friends that I\u2019m picking up an advanced field and I might not get a good job offer.\n\nMy Goal with learning has always been curiosity driven. Ofcourse I want to make money, make a living from doing whatever I do later in life. But My primary motivation is to actually enjoy it.\n\nI started out by applying for Internships at the few startups and the Big Companies that would allow me to work on these \u201cAdvanced\u201d topics. I would explain in every cover letter that why I as an undergrad, want to apply to a intership that requires me to be a M.Tech Student.\n\nI started networking on Linkedin seriously and cold emailing for advice.\n\nBy 2016, I started picking up Tensorflow and the Python & Co open source Libraries.\n\nLuckily, I got accepted into ONGC\u2019s Summer Internship Programme. I was assgined a Project on \u2018Computer Vision Odometry\u2019. My Guides were very impressed by my work.\n\nWith These badges on my Blazer, I marched up knocking at the Doors of IIT-R. I got into the Summer Internship Programme after a rigorous series of interviews and I got to work on Geographical Data Analysis under a Govt Of India Project.\n\nMy work allowed me to revisit IIT-R, This time as a Deep Learning intern: Working with Data to predict Seismic Activity, again on a Govt. Of India Project.\n\nI had constantly taken up MOOCs as they came out which were really helpful. My University had supported my Internship Endeavours by granting me extended vacations to allow me to work for 2\u20133 months every time.\n\nLater, I decided to sign up for Udacity\u2019s Deep Learning Nanodegree which was really helpful and helped me by not just learning about the basics but also working on a few really cool projects of Deep Learning.\n\nI also got into the Fast AI International Fellowship which got me closer to the cutting edge and kickass Deep learning practises. This was by far the best learning experience of my life.\n\nToday I\u2019m enrolled in the Self Driving and The Flying Car Nanodegrees with dreams to bring these tech to the Farms of India, in an affordable manner to further improve the productions.\n\nDuring my International Fellowship i decided to take up blogging seriously and I started sharing tutorials and basic explanations which were very well received thanks to the push from Fast AI community.\n\nLate in 2017, I jumped on the Nurture AI, AI Saturdays Boat as an AI Geek leader where I help the global community by mentoring students.\n\nI\u2019ve always belived in this Philosophy of giving back.\n\nWith The Same Motivation in Mind, I started init27 Labs where I would put out tutorials of Deep learning, Computer Vision, Self Driving and Flying Tech to help anyone who wants to learn about these a good place to start at.\n\nI\u2019m also honoured to be a part of the MentorCruise Boat where I hope to mentor newbies who want to learn more about AI.\n\nBeing Invited to Present at the Conference is the Greatest achievement of my Learning Path. I feel honoured to be acknowledged at a Global Conference, and to be on the Panel of Leaders of my Dream Field.\n\nI\u2019m sharing my Story here so that anyone whose dreams scares them finds the motivation here.\n\nMy Dream is to take up Masters in the field so that I can get to learn about the True Math behind the concepts.\n\nMy Goals are to make a few good first kaggle submissions this year and later take up research in my Life. I want to continue living and breathing in algorithms and geeking out in front of my Computer Screen for my Life."
    },
    {
        "url": "https://hackernoon.com/david-silver-rl-course-lecture-1-notes-2e650270d626?source=user_profile---------16----------------",
        "title": "David Silver RL Course: Lecture 1 Notes \u2013",
        "text": "Reinforcement Learning: It sits at the Intersection of many fields of Science. It\u2019s the science of Decision making, a method to understand optimum decisions.\n\nSo it\u2019s really commo to a lot of branches, and is a general approach to solving the Reward based problems.\n\n(Informal) Reward Hypothesis: All goals can be described by the maximisation of expected cummalative reward.\n\nAll rewards can be weighed out based on the actions after comparisions. Thus all rewards can be decomposed into a scale of comparisions and hence a Scalar reward must be ultimately derived.\n\nBy Definition, Goal may be intermediate or a Final goal or Time Based, etcetra.\n\nFirst step is understanding the Reward Signal.\n\nWe control the brain here-Brain is the agent.\n\nAt every step, the agent receives observations which are generated by the environment and the agent itself influences the environment by making actions.\n\nThe Machine Learning problem of RL is related to the stream of data coming from the trail and error interaction.\n\nThe Stream of Experience, Sequence of Observation, Actions and rewards.\n\nState: It\u2019s a summary of the information to determine the next action. It captures the history to determine all that should happen next.\n\nNote: For a multi-agent problem, an agent can consider other agents as part of the Environment.\n\nAn information systems contains all useful information from History.\n\nMarkov Property: A state is Markov if and only if: Probability of the next state, given your current state is the same as all of the previous states. In other words, only current state is determining the next state and the history is not relavant.\n\nIn other words, If Markov property holds. The Future is independent of the History, given the Present. Since the state characterises everything about the past.\n\nAnother definition: State is a sufficient statistics of the Future.\n\nAnd the entire history is also a Markov state. (Not a useful one)\n\nAn RL Agent may (or may not) include on of these:\n\nIt\u2019s a map from state from action. Determines what the agent will do if it\u2019s in a state.\n\nIt\u2019s a prediction of expected future reward. We chose between actions by deciding to go for the highest rewards, an estimate of this is obtained by the Value function.\n\nValue function depends on the way in which we are behaving, it depends on the policy. It gives the reward if we follow an action, thus helps in optimize our behaviour.\n\nGamma: Discounting. It affects if we care about current/later states. It decides the horizon for evaluating the future. (Horizon-how far along do we need to calculate outcomes of our actions).\n\nIt\u2019s used to learn the environment, predicts what the environment will do next. It isn\u2019t necessary to create a model of the environment. But it\u2019s useful when we do.\n\nIt can be divide into two states:\n\nWe catgorize our agents based on which of the above three concepts, it follows. Say, if we have a value based agent: if it has a value function and a policy is implicit.\n\nPolicy based: maintains a data structure of the every state without storing the value function.\n\nActor Critic: Combines both the policy and also the value function.\n\nSo RL Problems can be categorized as:\n\nThere are two problems when it comes to sequential decision making.\n\nExploration: Chosing to give up some known reward, in order to find more about the environment.\n\nThere is an Exploration Vs Exploitation Tradeoff.\n\nPrediction: An estimate of the future, given the current policy\n\nIn RL, we need to evaluate all our policies to find out the best one."
    },
    {
        "url": "https://hackernoon.com/robotics-series-0-announcement-and-call-for-ideas-e30a58e6023e?source=user_profile---------17----------------",
        "title": "Robotics Series #0 Announcement and Call For Ideas \u2013",
        "text": "Part 0 of the ROS Series, spanning from the Ground Basics of ROS to working on real Projects, with End to End Code Walkthroughs.\n\nI\u2019m really excited to announce a Robotics Tutorial Series to be released very soon.\n\nThis is Part 0 of the Series.\n\nThe series will be in a beginner friendly form. All the links to the GitHub repositories will be provided in the posts. The Posts will be in the form on a theory minima appraoch-where only just the bare amount of theory needed to get you started is required, with in depth discussion of the code. The idea is to get you to speed with working on Robotics in under 10 minutes of every post.\n\nI really want to make this series to be as helpful as I can. I\u2019d love to hear what you\u2019d want to read about.\n\nThe Content decided thus far, based on all the requests is:\n\nI\u2019m actively creating this Tutorial Series to be released on here very soon and would love to hear about your ideas, what you would love to read about.\n\nPlease Drop a Comment below or Shoot me a tweet @bhutanisanyam1"
    },
    {
        "url": "https://medium.com/init27-labs/linear-regression-in-2-minutes-using-pytorch-49d80a9e6528?source=user_profile---------18----------------",
        "title": "Linear Regression in 2 Minutes (using PyTorch) \u2013 init27 Labs \u2013",
        "text": "This is Part 2 of the PyTorch Primer Series.\n\nLinear Regression is linear approach for modeling the relationship between inputs and the predictions\n\nWe find a \u2018Linear fit\u2019 to the data.\n\nFit: We are trying to predict a variable y, by fitting a curve (line here) to the data. The curve in linear regression follows a linear relationship between the scalar (x) and dependent variable.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://medium.com/init27-labs/pytorch-basics-in-4-minutes-c7814fa5f03d?source=user_profile---------19----------------",
        "title": "PyTorch Basics in 4 Minutes \u2013 init27 Labs \u2013",
        "text": "This is Part 1 of the PyTorch Primer Series.\n\nIt\u2019s a Python based package for serving as a replacement of Numpy and to provide flexibility as a Deep Learning Development Platform.\n\nI encourage you to read Fast AI\u2019s blog post for the reason of the course\u2019s switch to PyTorch.\n\nTensors are similar to numpy\u2019s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n\nThis will create a X by Y dimensional Tensor that has been instantiated with random values.\n\nTo Create a 5x3 Tensor with values randomly selected from a Uniform Distribution between -1 and 1,\n\nTensors have a size attribute that can be called to check their size\n\nPyTorch supports various Tensor Functions with different syntax:\n\nInline functions are denoted by an underscore following their name. Note: These have faster execution time (With a higher memory complexity tradeoff)\n\nAll Numpy Indexing, Broadcasting and Reshaping functions are supported\n\nNote: PyTorch doesn\u2019t support a negative hop so [::-1] will result in an error\n\nNote: Be careful when working with different Tensor Types to avoid type errors\n\nConverting a torch Tensor to a numpy array and vice versa is a breeze.\n\nNote: The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n\nMoving the Tensors to GPU can be done as:\n\nCentral to all neural networks in PyTorch is the package. Let\u2019s first briefly visit this, and we will then go to training our first neural network.\n\nThe package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n\nLet us see this in more simple terms with some examples.\n\nis the central class of the package. It wraps a Tensor, and supports nearly all of operations defined on it. Once you finish your computation you can call and have all the gradients computed automatically.\n\nYou can access the raw tensor through the attribute, while the gradient w.r.t. this variable is accumulated into .\n\nAs explained by this Blog Post by Radek, My friend and Mentor from the Fast AI community\n\nFeel free to ask any questions below. \n\nAlso drop us a comment on the tutorials that you\u2019d love to read, I will try to have that up ASAP.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://medium.com/init27-labs/pytorch-primer-series-0-8f38fb09ad2f?source=user_profile---------20----------------",
        "title": "PyTorch Primer Series #0 \u2013 init27 Labs \u2013",
        "text": "This is Part 0 of the Series.\n\nThe series will be in a beginner friendly form. All the links to the GitHub repositories will be provided in the posts. The Posts will be in the form on a theory minima appraoch-where only just the bare amount of theory needed to get you started is required, with in depth discussion of the code.\n\nIf you feel you need a quick refresh of Python, Checkout my Basic Tutorial Series.\n\nFeel Free to contribute and improve the code, I\u2019ll update my posts and Credit you for the contributions as well!\n\nThe topics that will be covered are (Links will be updated as the drafts become public):\n\nPlease drop a comment below if you\u2019d like to read more tutorials and I will try my best to have them up and ready ASAP!\n\nIf you want to chat, ping me in the comments or find me on twitter. I\u2019d love to hear from you!"
    },
    {
        "url": "https://medium.com/init27-labs/robotics-series-0-call-for-proposals-e594fd42b824?source=user_profile---------21----------------",
        "title": "Robotics Series #0 Call for Proposals \u2013 init27 Labs \u2013",
        "text": "Part 0 of the ROS Series, spanning from the Ground Basics of ROS to working on real Projects, with End to End Code Walkthroughs.\n\nI\u2019m really excited to announce a Robotics Tutorial Series to be released very soon.\n\nWe really want to make this series to be as helpful as we can. We\u2019d love to hear what you\u2019d want to read about.\n\nThe Content decided thus far, based on all the requests is:\n\nWe\u2019re actively creating this Tutorial Series to be released on here very soon and would love to hear about your ideas, what you would love to read about.\n\nPlease Drop us a Comment below or Shoot me a tweet @bhutanisanyam1"
    },
    {
        "url": "https://hackernoon.com/a-self-driving-and-flying-new-year-3-30d5ecd375e8?source=user_profile---------22----------------",
        "title": "A Self Driving and Flying (New) Year #3 \u2013",
        "text": "1 Month down the Highway with My Self Driving Car Learning Path and I\u2019m loving the ride. And I have some exciting News to Share.\n\nBut First, here\u2019s what I\u2019ve been upto in my Garage:\n\nHere\u2019s the First (Unedited) Video from the Series:\n\nI have always wanted to work on Deep Learning ideas that would help people at a massive scale.\n\nDeveloping Android/iOS applications would be the ideal path to this.\n\nThanks to Udacity and Google for granting me the Scholarship to Android App Dev.\n\nI certainly hope to release a few ideas of mine (For free of course, by Q3\u20132018).\n\nGiven my belief in Sebestian Thrun\u2019s philosophy of Dreaming Big and chasing ideas fearlessly, I was really looking forward to the Flying Car Nanodegree.\n\nAnd when I received an acceptance mail from Udacity, On the 14th of Feb - I decided to change lanes and Shift Gears for a Flight.\n\nWhat would you expect a Geek to do on Valentine\u2019s?\n\nI decided to invest my Savings for a GPU-Rig to learn about Flying Cars.\n\nI\u2019m definitely up for a Challenge since I\u2019m studying about Flying Cars, Self Driving Cars and Learning from the Scholarship and I\u2019m a \u2018Full Time University Student, Part Time Deep Learning Student\u2019.\n\nBut I certainly will continue sharing in this series, what I\u2019ve learnt via the Nanodegrees. And Share my Path to Driving and Flying Autonomously.\n\nWhat are you geeks upto on Valentine\u2019s?"
    },
    {
        "url": "https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-5-notes-deep-learning-for-human-5cb0f53e4f15?source=user_profile---------23----------------",
        "title": "MIT 6.S094: Deep Learning for Self-Driving Cars 2018 Lecture 5 Notes: Deep Learning for Human\u2026",
        "text": "All Images are from the Lecture Slides.\n\nHow can we use CV to extract useful information from Videos (in Context of Cars)\n\nDeep Learning for Human Sensing:\n\nUsing CV, DL to create systems that operate in the real world.\n\nTakeaway: Data Collection, cleaning is more important than algorithms.\n\nGiven these flaws, and the Two Paths to an Autonomous Future (Human Centred Vs Full Autonomy) discussed in Lecture 1:\n\nIs the Human Centred idea a bad idea?\n\nThe Data collected provides an insight of\n\nSolutions:\n\nThe need is to extract features from raw pixels.\n\nThese networks generate the candidates to be considered instead of a sliding window approach, providing a subset to be considered.\n\nWhy is it important?\n\nAnnotation Tooling:\n\nSemi-automated: Data that the network is not confident about are manually annotated.\n\nFundamental Tradeoff:\n\nWhat is the accuracy we are willing to put up with?\n\nFor increase in accuracy, a human manually iterates and annotates thet data.\n\nFalse Positives:\n\nCan be dealt with by more training data. \n\nSome degree of human annotation fixes some of the problems.\n\nDegree to which a person is mentally busy."
    },
    {
        "url": "https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-4-notes-computer-vision-f591f14b3b99?source=user_profile---------24----------------",
        "title": "MIT 6.S094: Deep Learning for Self-Driving Cars 2018 Lecture 4 Notes: Computer Vision",
        "text": "All Images are from the Lecture Slides.\n\nComputer Vision, as of Today is Deep Learning. Majority of the successes of our understanding of images, utilise Neural Networks.\n\nRaw Sensory data: For the machine, images are in the form of numbers.\n\nThe images in the form of 1 channel or 3 channel numerical arrays, are taken as input by the NN, the output is produced by regressing or by classifying the image into various categories.\n\nWe must be careful about our assumptions for what is easy and hard with Perception.\n\nThere is a bin with different categories inside each class. Those bins have a lot of examples of each. Task: Bin a new image into one of these classes.\n\nWhen the NN is tasked to learning a complex task with large data and large number of objects, CNNs work efficiently.\n\n\u2018Trick-Spatial Invarince\u2019:\n\nAn Object in the top left corner is the same as the object in the bottom right corner of an image. So we learn the same features across the image.\n\nConvolution operation: Instead of the Fully connected layers; Here a 3rd dimension of depth is present. So the block take 3 input volumes and produce 3D output volumes\n\nThey take a slice of the image, \u2018a window\u2019 and slide it through the image. They apply the same weights to slice/window of an image to generate outputs. We can make many such filters.\n\nParameters on each of these filters are shared. (If a feature is useful in one place, it\u2019s useful everywhere) This allows parameter reduction significantly. The re-use of spatial features.\n\nThe methods discussed here, disregard the temporal dynamics, which is relevant in the case of Robotics."
    },
    {
        "url": "https://hackernoon.com/will-ai-take-over-our-jobs-1c6e2ebdb7b0?source=user_profile---------25----------------",
        "title": "Will \u2018AI\u2019 Take over our Jobs? \u2013",
        "text": "An AI and Self Driving Car Enthusiast\u2019s vision of the \u2018Future\u2019\n\nWith the \u2018Deep Learning\u2019, \u2018Machine Learning\u2019, \u2018Data Science\u2019 or \u2018AI Revolution\u2019 hype, there a few common repetitive concerns in our society, that keep appearing in different forms:\n\nI will try to state my viewpoint as an AI enthusiast (Sorry humans \ud83d\ude1c).\n\nFirst, that would require a General and robust Intelligence, which is atleast a few decades away.\n\nAI seems to excel in very specific tasks as of 2018, the systems are extremely brittle and can be, under very limited cases be applied to different domains. The tasks by themselves, are extremely specific to given conditions.\n\nIn the real world, with constraints out of the equations, I\u2019m skeptical if a General Intelligence variable will hold (anytime soon).\n\nHow Far Are We from a Fully Autonomous Driving World?\n\nThis seems to be the biggest concern, since AI can do our tasks better, what would we do?\n\nI firmly disagree with this general opinion, Firstly because such a system is not near for the following reasons:\n\nSecondly, Throughout the history of Humanity, whenever we have always witnessed technology that does our jobs in an efficient manner replacing humans in the field, it has enabled us to worry about greater tasks.\n\nDid Automated Call Routing, replace the workers at Telecommunication Exchange?\n\nYES, They \u2018took\u2019 their jobs (or replaced them). But I\u2019m sure the automation was necessary. I can\u2019t imagine waiting for a few days for an operator to post my Instagram story. With Internet and global connectivity, the task needed to be instant. Hence, Humans were replaced.\n\nThe acceptance curve for every \u2018innovation\u2019. Notice: There was almost no technology before 1900 and the Curves get steeper and closer as years progress.\n\nEverytime we\u2019ve introduced a new \u2018Tech\u2019, it had a tendency to replace certain jobs.\n\nMedium is replacing Newspapers (If I dare say so).\n\nDid all of these things bring job depressions? \n\nI don\u2019t think so. \n\n(The examples are not comprehensive, but I hope you get the idea).\n\nYes, it does. But what about your freedom of commute?\n\nWe spend a significant amount of our life in commute. How about no more traffic jams? Or freedom of doing whatever you want when you are on the road?\n\nWhat about not owning a car and just being able to summon one when you need to commute?\n\nWhat about Solving the issues of car parking, by making it figure that out autonomously?\n\nI think the Pros always outweigh the Cons for every Technology that affects the world on a massive scale. After all, there\u2019s a reason why we call it \u2018innovating\u2019.\n\nSebastian, in his Ted Talk argues that our jobs, for most of our lifetimes include working on variations of the same task. The same \u2018boring\u2019 job.\n\nThe thing about Humans is, we\u2019re extremely competitive. If given the right push, we tend to push the limits of our biological Intelligence.\n\nAI, in general is meant to serve us as a Technology. Any Technology, serves a single purpose: To help us do our tasks better.\n\nOnce we have a competitive mind for innovation, I can\u2019t imagine the wonders that\u2019d happen. If given the push-with AI replacing our jobs. We\u2019d push back and find better problems to solve.\n\nAlphaGo however, pushed Lee-Sedol to innovate. For the 1 game he had won, he played a move that couldn\u2019t be anticipated by AlphaGo itself, experts who reviewed the game believed the same.\n\nThe machine God, pushed the Human God to play better!\n\nAfter the defeat, Lee Sedol went on to win all the matches against (human) players.\n\nOnce you\u2019re at the top, you keep working but tend to lose a competitive sense. Lee Sedol faced a defeating competition from AlphaGo, it pushed him to become a better player.\n\nOur innovations have always helped us improve at innovating.\n\nThat is the Truth about humanity.\n\nHere\u2019s how I\u2019m helping to Bring the World Together with AI.\n\nWhat do you think?"
    },
    {
        "url": "https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-3-notes-deep-reinforcement-learning-fe9a8592e14a?source=user_profile---------26----------------",
        "title": "MIT 6.S094: Deep Learning for Self-Driving Cars 2018 Lecture 3 Notes: Deep Reinforcement Learning",
        "text": "All Images are from the Lecture Slides.\n\nHere is a quick Primer if you want a brief intro to Reinforcement Learning\n\nStack of Tasks an AI System needs to perform\n\nHow Much of the AI Stack can be \u2018Learned\u2019?\n\nWe can learn the representation and knowledge. NN map the data to information, Kernel methods are effective here as well.\n\nMapping the data from right sensor data to knowledge is where DL Shines.\n\nOpen Question: Can We extend this to reasoning and actionable information end-to-end?\n\nQ2, Can we extend this to real world cases of SDC and Robotics?\n\nSupervised Leanring: Memorization of Ground truth data in order to form representations that generalises from the ground truth.\n\nReinforcement Learning: Brute-Force propagate the sparse information through time to assign quality reward to state that does not directly have a reward. To make sense of the world when the data/reward is sparse, but are connected through time. This is equivalent of Reasoning.\n\nConnection through time is modelled as:\n\nThere is an agent, performing an action in the environment, receives a new state and a reward. This process continues over and over.\n\n1 or more of these:\n\nDeterministic approach: Shortest path is to be chosen.\n\nKey Observation: Every single state in the space must have a plan to control the non-deterministic environment.\n\nIf reward function is designed such that every single step is penalised, the optimal policy in this case would be to chose the shortest path.\n\nIf we reduce the penalty, the randomness in movements is allowed.\n\nIf we turn the reward to +ve to movement, there is an increased incentive for staying on the board without finishing.\n\nValue of the Environment state is the reward we are likely to receive in the future. This is determined by discounting the future discount.\n\nA good strategy is maximising the sum of discounted future goals.\n\nWe use any policy to estimate state that maximises the future reward.\n\nThis allows us to consider much larger state space and action space. \n\nWe move about simulation taking actions and updating our estimate of how good actions are.\n\nAs a better estimate is formed of the Q-function, we form a better sense of the the better actions that can be performed. This is still not perfect so there is a value of Exploration. With improvements in estimation, the lesser the value for exploration.\n\nSo Initially we want to explore more and reduce that with time as our estimates become more accurate.\n\nSo the Final System, should operate in a greedy way according to the Q-Fucntion.\n\nThe table is initialised in a random manner and it is updated with the bellman equation, over time the approximation becomes the appropriate table.\n\nProblem: When the Q-Table grows exponentially. Ex: Using Pixel inputs from real world/game. The potential state space, possible combinatorial states are larger than what System memory can hold, larger than what can be estimated using the Bellman Equation.\n\nNN are really good at estimation.\n\nDL: Allows us to approximate values over much larger state space as compared to ML. This allows us to deal with raw values of sensory data, it is much more capable to deal with real world applications; it is generalisable.\n\nThe understanding comes from converting the Raw sensory information to simple useful information based on which action can be taken.\n\nInstead of the Q-function, we plug in a NN. \n\nInput: State space.\n\nOutput: Value of function that each state can take. \n\nDQN: Deep Q-Network.\n\nThe bellman equation inputs the reward and discounts the future rewards.\n\nLoss function for NN: takes the reward received at current state, performs a forward pass through the NN to calculate the value of future state and subtracts it from the Forward pass for the current state of action.\n\nWe take the difference between the Value estimated by Q-Function Estimator (NN) believes the future value and what the possible value will be based on the possible actions.\n\nGiven a transition S, an action a that generates a reward r\u2019 and changes to state S\u2019.\n\nThe update is do a feed forward pass through the Netowork for the current state and do a feed forward pass for all the possible actions in the next state and update the weights using Backpropagation.\n\nExperience Replay:\n\nAs games are played through simulation, the observations are collected into a library of experiences and the training is performed by randomly sampling the previous experiences in batches. So that the system does not overfit a particular evolution of the simulation.\n\nFixed Target Network: \n\nWe use a NN to estimate the value of the current state in action-pair and the next, thereby using it multiple times. As we perform the network, we are updating the network. So the target function inside the loss function changes, which causes problems for stability. So we fix the network and only update it say, every 1,000 steps. \n\nAs we train the network, the Network used to estimate the Target function is kept fixed, resulting in a stable loss function.\n\nReward Clipping:\n\nTrue for systems operating in generalised ways. These simplify the reward functions, to either positive or negative.\n\nCircle: When Technique is used.\n\nCross: Technique not used. \n\nHigher the number, greater the reward received.\n\nNote: The loop is not part of the training, it is the part of saving the observation, state, action, reward and next state into the replay memory.\n\nNext we sample randomly from the memory to train the network based on a loss function. The probablity: Epsilon, is the probability of exploration-which decreases over time.\n\n2015: Atari Breakout\n\nDQN has outperformed on many Atari Games.\n\nNotice: The possible legal board conditions at any point = 2.8x10^(170)\n\nUsed human expert position play to seed in a supervised way, RL approach to beat Human Experts.\n\n(Biased) Opinion: Accomplishment of the decade in AI, AlphaGo Zero (2017):\n\nGiven, a large state space. We start at a board, moves are chosen with some Exploration Vs Exploitation balance, until some conclusion is reached. This information is back-propagated and the we learn the value of board positions in play.\n\nAlphGo used a Neural net for \u2018Intuition\u2019 for estimating the quality of states.\n\nCheckout the Official Tutorial Here\n\nRoad: Grid space, an occupancy grid: When empty, it\u2019s set to ab-Grid value is whatever speed is achievable.\n\nWith other cars in the grid: The value in the grid is the speed of slower-moving cars.\n\nWe can decide on the portion we want to use as input to the Network.\n\nThe Safety System can be considered an equivalent of Basic MPC: Basic Sensors allowing prevention of collision.\n\nTask: To move about the space under the constraints of Safety System.\n\nRed: Non reachable spaces.\n\nGoal: Not get stuck in Traffic.\n\nInput: State space.\n\nOutput: Value of different actions. \n\nBased on Epsilon values and through training, inference evaluation: We choose exploration extent.\n\n\u2018Brain\u2019 takes as an input, the state. The reward performs a forward pass and calculates the reward. \u2018Brain\u2019 is where the NN is contained for both Training and Evaluation.\n\nNew Addition: Number of Agents that can be controlled by the NN, ranging from 1\u201310. The evaluation is performed in the same manner. \n\nNote: The agents are not aware of other agent\u2019s prescence. The actions are greedy for every individual agent and not in an optimised distributed manner.\n\nThese appear in all of the examples when applied to the real world."
    },
    {
        "url": "https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-2-notes-e283b9ec10a0?source=user_profile---------27----------------",
        "title": "MIT 6.S094: Deep Learning for Self-Driving Cars 2018 Lecture 2 Notes",
        "text": "All images are from the Lecture slides.\n\nAn Engineer\u2019s view: We want to find the best possible ways to transform our society and improve lives.\n\nPlot of Technology adoption rate Vs the number of years:\n\nHuman Centred Approach: Criticism: When humans are given the system, they will \u2018overtrust\u2019 the system. The better the system become, the lesser the humans will pay attention.\n\nPublic Perception of What happens inside an Autonomous vehicle:\n\nSource of Raw Data that can be processed.\n\nBeing able to localise itself in space.\n\nAfter understanding the scene, How to get from A to B?\n\nArgument: A1 systems are more favourable in the current years."
    },
    {
        "url": "https://hackernoon.com/how-far-are-we-from-a-fully-autonomous-driving-world-89fde97b5352?source=user_profile---------28----------------",
        "title": "How Far Are We from a Fully Autonomous Driving World?",
        "text": "The MIT Deep Learning for Self-Driving Cars course just released their First lecture video (alternatively Here are the lecture notes if you want a quick read)\n\nThe Lecture is an overview of Deep Learning techniques and has some discussions on the future of Self Driving Tech as well, and a brief warning about the Gaps of current systems.\n\nHere is the take on how far away are we from an Autonomously Driven Future and a brief touch on Ethics:\n\nBy 2017, Computer Vision has reached 97.7%+ accuracies! (ImageNet challenge) Amazing isn\u2019t it?\n\n97.7% sounds good enough. Is it?\n\nAfter all driving involves a lot of Computer Vision and it is indeed better than human high scores-so are we close?\n\nThe ImageNet Challenge involves classifying 14M images into one of 22,000 possible classes.\n\nHow good is this accuracy when its extrapolated to the real world?\n\nNow yes, the classes involved in the challenge wouldn\u2019t all be involved in the SDC scenario but they do point out to one thing, Computer Vision, although it\u2019s more accurate than Humans now, is still not perfect. It isn\u2019t a 100% accurate.\n\nThat coupled with the dynamics of the real world suggest that there is a small chance of the Autonomous systems behaving in unexpected ways. Would you trust the system completely in under all scenarios? To handle every situation better than a Human Driver?\n\nThe argument made in the lecture is that SDCs as of now will work as tools that would help us drive better. They might even drive better than us, but at points, Humans would need to intervene. We have a Semi-Autonomous year as of 2018.\n\nRoughly, in 90% of the Cases, the Car will drive itself better than us, but for the remainder of 10% cases, Human intervention/control would be required.\n\nA 100% accuracy would have a universal approval, which would require a generalisation over all the unexpected cases too, for example: A situation of 1 in a Million, where a Deer would cross the road and the situation has to be handled.\n\nLex Fridman argues in the Lecture that the \u2018perfect system\u2019 would require a lot more research efforts and increase in Efficiency of Deep learning algorithms. Which as of now are highly inefficient as well (Computationally speaking).\n\nBy the perfect case- I\u2019m not referring to the case that a car that can drive itself. The perfect case is where, we\u2019d be so confident about the systems that we would no longer have steering wheels in our vehicles. That human driving would be considered more dangerous than the automated one.\n\nTill then SDCs would definitely appear on the road, we might not have to hold the steering wheels for long durations, no doubt. But there will definitely be moments when Human control would be required. Hence, the term Semi-Autonomous."
    },
    {
        "url": "https://medium.com/init27-labs/init27-labs-3b7a30e54be1?source=user_profile---------29----------------",
        "title": "init27 Labs \u2013 init27 Labs \u2013",
        "text": "init27 is an initiative by Deep Learning and Computer Vision geeks.\n\nPersonally, I\u2019ve had some working experience via internships and and I\u2019ve worked on a few projects by myself. Check them out here. I\u2019ve also completed Udacity\u2019s Deep Learning Nanodegree, and just started with the Self Driving Car Nanodegree as well, completed the FastAIv2 as a part of the International Fellowship. I\u2019ve interned at IIT-Madras, ONGC, IIT-Roorkee. I\u2019ve worked as a Computer Vision Engineer on an Autonomous Underwater Vehicle\u2019s Software suite (AUV) and worked with Embedded Systems.\n\nHowever, as a beginner I had always struggled with learning about Deep Learning or Computer Vision. (TBH, I still consider myself to be a noob. But by beginner, I mean anyone who is standing at the starting line)\n\nHere\u2019s what my learning experiences were like:\n\nSo as init27 \u2018lab\u2019, We\u2019ve decided to start this initiative as a community to help anyone who finds Deep Learning/Computer Vision or even coding in general to be difficult to start with. We hope to do this by putting out resources to for beginners.\n\nNo questions is too silly, neither is any topic too basic.\n\nWell, just leave a comment below or shoot me a tweet @bhutanisanyam1.\n\nAnd We\u2019d be happy to help you with it!\n\nI personally also hope to do weekly or bi-weekly google hangouts to discuss and brainstorm ideas or do walkthroughs as time permits.\n\nWe consider ourselves fortunate enough to be able to pursue paid Courses, Nanodegrees and even be able to purchase the expensive books in some cases.\n\nHowever, since we\u2019re truly Open Source geeks. \n\nWe would love to help others find a way to get started in the field. This is not a monetized attempt neither do we expect profits out of the same. We wish to give back what we have learned, and guide the people that are struggling with applying knowledge or others who might just be getting started.\n\nBy no means are we the experts of the fields and by no means do we even hope to claim that, or call us experts. This is a way to guide others, by creating Tutorials, or curated lists or contributions to their projects too.\n\nWe would also love to share our knowledge by inviting contributors to our Garage Projects.\n\nIf you would like to join us to help the community, you\u2019re very welcome to join us. We\u2019d love to give you the complete credit of contributions that you make.\n\nHere is the little content that we\u2019ve put out:\n\nA lot more coming soon! Later, we\u2019ll be creating detailed walkthroughs of the Projects that we are working on to help you recreate them or maybe extend them to cases better than our abilities."
    },
    {
        "url": "https://hackernoon.com/bringing-the-world-together-with-ai-47b6e1ebd2ab?source=user_profile---------30----------------",
        "title": "Bringing the World Together with AI \u2013",
        "text": "AI Saturdays is a community being built by Nurture.ai, where people across the globe would meet every Saturday in their cities and follow AI Learning courses together.\n\nBeing a Deep learning Geek, I decided to jump on board right away and volunteered to be an Ambassador in one city to organise the meetups and later I volunteered to help mentor the online community with their doubts as an AI Geek Leader.\n\nThe founder of the community, Yap Jia Qing was very humble and welcoming, the courses that they were following (check their website) overlapped my interests. I felt right at my Lab (Or home, whichever you prefer)!\n\nOver the 1 and a half month, AI Saturdays today has grown to a whooping community of 3800+ Members. \n\nPeople from different cities, different cultures and spread across different time zones.\n\nAll united by same thing: A Path to learning AI.\n\nThis was an amazing experience to have: AI Saturday as a community silently united everyone under the AI Banner.\n\nIn the 1 month of hanging out at the community discussions, I have met really awesome people from across the globe. Professionals, hobbyists, Nerds, People having non-technical background, People from different age groups, Different nations, Different cultures. We all speak one common language: Code. We all are attracted like moths to the AI Lightbulb and Thanks to the founders, we all share their help and grow together atitude."
    },
    {
        "url": "https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-1-notes-807be1a50893?source=user_profile---------31----------------",
        "title": "MIT 6.S094:Deep Learning for Self-Driving Cars 2018 Lecture 1 Notes",
        "text": "All images are from the Lecture slides.\n\nDeep learning: Set of techniques that have worked well for AI techniques in recent years due to advancement in research and GPU capabilities. SDC are Systems that can utilize these.\n\nInstructors are working on devoloping cars that understand environment inside and outside the car.\n\nAutonomous vehicle: It\u2019s a Personal robot rather than a Perception-Control. The systems will need assistance from humans via a Transfer of control during situations. A truly Perceptional System having a dynamic nature with human equivalence maybe a few decades away.\n\nCognitive load: A fully connected CNN takes in the raw 3D input to analyse the cognitive load,body pose estimation, drowsiness of the driver.\n\nProposal: Consider human presence in design of every algorithm.\n\nDeep learning Perform really well with huge data. Since human lives are directly dependent on the machines, techniques that learn from real world data are needed.\n\nUnderstanding/Reasoning: Ability to turn complex information into simple and useful information.\n\nDeep learning (Representation Learning or Feature Learning) is able to take raw information without any meaning and is able to construct hierarchical representation to allow insights to be generated.\n\nThe most capable branch of AI that is capable of deriving structure from the data to allow to derivation of insights.\n\nSimiliarity: Both are distributed computation on a large scale.\n\nA basic Neuron is simple, connected units allow much complex use cases.\n\nUniversality: Mutiple Neural nets can learn to approximate any function with just 1 hidden network layer*\n\nLimitation: Not in power of the Networks, but in the methods.\n\nCurrently being used: 1,2\n\nVanishing Gradients: When the output or gradient of the NN is very low and results in slow learning.\n\nLearning Process of the NN. Goal: Update the weights and biases to decrease loss function.\n\nSince the process is modular, it\u2019s parallelizable.\n\nGoal: To minimize the Loss Function by updating weights and biases.\n\nTechniques that help in generalising.\n\nDropout: Randomly Remove some of the nodes (along with the incoming and outgoing nodes)\n\nGoal: To help generalise better.\n\nNeural Network Playground: To play around with techniques and practise\n\nGoal: Input an image and predict an output\n\nSubtle example: DL is still distant from \u2018Human Generalisation Ability\u2019\n\nSame Architecture, Many Applications: We can change the predict layer to make predictions to as many number of classes as per requirements.\n\nEvery pixel is assigned a class and it inputs an image and produces another image as output.\n\nIt\u2019s an oppurtunity to apply techniques to real world problems effectively. (And DL is the most effective at these)."
    },
    {
        "url": "https://hackernoon.com/linear-regression-in-x-minutes-using-pytorch-8eec49f6a0e2?source=user_profile---------32----------------",
        "title": "Linear Regression in 2 Minutes (using PyTorch) \u2013",
        "text": "This is Part 2 of the PyTorch Primer Series.\n\nLinear Regression is linear approach for modeling the relationship between inputs and the predictions\n\nWe find a \u2018Linear fit\u2019 to the data.\n\nFit: We are trying to predict a variable y, by fitting a curve (line here) to the data. The curve in linear regression follows a linear relationship between the scalar (x) and dependent variable.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://hackernoon.com/pytorch-basics-9c1c627cd0d2?source=user_profile---------33----------------",
        "title": "PyTorch Basics in 4 Minutes \u2013",
        "text": "This is Part 1 of the PyTorch Primer Series.\n\nIt\u2019s a Python based package for serving as a replacement of Numpy and to provide flexibility as a Deep Learning Development Platform.\n\nI encourage you to read Fast AI\u2019s blog post for the reason of the course\u2019s switch to PyTorch.\n\nTensors are similar to numpy\u2019s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n\nThis will create a X by Y dimensional Tensor that has been instantiated with random values.\n\nTo Create a 5x3 Tensor with values randomly selected from a Uniform Distribution between -1 and 1,\n\nTensors have a size attribute that can be called to check their size\n\nPyTorch supports various Tensor Functions with different syntax:\n\nInline functions are denoted by an underscore following their name. Note: These have faster execution time (With a higher memory complexity tradeoff)\n\nAll Numpy Indexing, Broadcasting and Reshaping functions are supported\n\nNote: PyTorch doesn\u2019t support a negative hop so [::-1] will result in an error\n\nNote: Be careful when working with different Tensor Types to avoid type errors\n\nConverting a torch Tensor to a numpy array and vice versa is a breeze.\n\nNote: The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n\nMoving the Tensors to GPU can be done as:\n\nCentral to all neural networks in PyTorch is the package. Let\u2019s first briefly visit this, and we will then go to training our first neural network.\n\nThe package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n\nLet us see this in more simple terms with some examples.\n\nis the central class of the package. It wraps a Tensor, and supports nearly all of operations defined on it. Once you finish your computation you can call and have all the gradients computed automatically.\n\nYou can access the raw tensor through the attribute, while the gradient w.r.t. this variable is accumulated into .\n\nAs explained by this Blog Post by Radek, My friend and Mentor from the Fast AI community\n\nFeel free to ask any questions below. \n\nAlso drop us a comment on the tutorials that you\u2019d love to read, I will try to have that up ASAP.\n\nIf you want to read about Week 2 in my Self Driving Journey, here is the blog post\n\nThe Next Part in the Series will discuss about Linear Regression."
    },
    {
        "url": "https://hackernoon.com/a-self-driving-new-year-2-d1bbc5a83570?source=user_profile---------34----------------",
        "title": "A Self Driving (New) Year #2 \u2013",
        "text": "Term 1 Cohort of my Self Driving Car Nanodegree classroom starts on the 19th, meanwhile I have started working on things in my Garage that I want to share:\n\nAs Promised, I would add posts to the series regularly\n\nHere is some news:\n\nI have decided to make a Mini Self Driving Car to apply what I will learn in my Self Driving Car Nanodegree Program:\n\nI have also taken the courage to set 5 bold targets before my Term 1 starts (Roughly a week from now):\n\nLong Term functionality Goals for My Mini Self Driving Car:\n\nPlease note that these aren\u2019t the Pre-requistes, rather are my own personal ventures to my Self Driving Year.\n\nI will share detailed posts of the targets that I have completed.\n\nStay Tuned for updates! I will keep sharing my story, if I make it to the finish line with my Goals or hit the dust!"
    },
    {
        "url": "https://blog.goodaudience.com/a-self-driving-new-year-2-dddd3860dd84?source=user_profile---------35----------------",
        "title": "A Self Driving (New) Year #2 \u2013",
        "text": "Term 1 Cohort of my Self Driving Car Nanodegree classroom starts on the 19th, meanwhile I have started working on things in my Garage that I want to share:\n\nAs Promised, I would add posts to the series regularly\n\nHere is some news:\n\nI have decided to make a Mini Self Driving Car to apply what I will learn in my Self Driving Car Nanodegree Program:\n\nI have also taken the courage to set 5 bold targets before my Term 1 starts (Roughly a week from now):\n\nLong Term functionality Goals for My Mini Self Driving Car:\n\nPlease note that these aren\u2019t the Pre-requistes, rather are my own personal ventures to my Self Driving Year.\n\nI will share detailed posts of the targets that I have completed.\n\nStay Tuned for updates! I will keep sharing my story, if I make it to the finish line with my Goals or hit the dust!"
    },
    {
        "url": "https://hackernoon.com/pytorch-primer-series-0-e2e5df9b31c6?source=user_profile---------36----------------",
        "title": "PyTorch Primer Series #0 \u2013",
        "text": "This is Part 0 of the Series.\n\nThe series will be in a beginner friendly form. All the links to the GitHub repositories will be provided in the posts. The Posts will be in the form on a theory minima appraoch-where only just the bare amount of theory needed to get you started is required, with in depth discussion of the code.\n\nIf you feel you need a quick refresh of Python, Checkout my Basic Tutorial Series.\n\nFeel Free to contribute and improve the code, I\u2019ll update my posts and Credit you for the contributions as well!\n\nThe topics that will be covered are (Links will be updated as the drafts become public):\n\nPlease drop a comment below if you\u2019d like to read more tutorials and I will try my best to have them up and ready ASAP!\n\nIf you want to chat, ping me in the comments or find me on twitter. I\u2019d love to hear from you!"
    },
    {
        "url": "https://medium.com/ai-saturdays/david-silver-rl-course-lecture-1-notes-c7f895ab45b2?source=user_profile---------37----------------",
        "title": "David Silver RL Course: Lecture 1 Notes \u2013 AI Saturdays \u2013",
        "text": "Reinforcement Learning: It sits at the Intersection of many fields of Science. It\u2019s the science of Decision making, a method to understand optimum decisions.\n\nSo it\u2019s really commo to a lot of branches, and is a general approach to solving the Reward based problems.\n\n(Informal) Reward Hypothesis: All goals can be described by the maximisation of expected cummalative reward.\n\nAll rewards can be weighed out based on the actions after comparisions. Thus all rewards can be decomposed into a scale of comparisions and hence a Scalar reward must be ultimately derived.\n\nBy Definition, Goal may be intermediate or a Final goal or Time Based, etcetra.\n\nFirst step is understanding the Reward Signal.\n\nWe control the brain here-Brain is the agent.\n\nAt every step, the agent receives observations which are generated by the environment and the agent itself influences the environment by making actions.\n\nThe Machine Learning problem of RL is related to the stream of data coming from the trail and error interaction.\n\nThe Stream of Experience, Sequence of Observation, Actions and rewards.\n\nState: It\u2019s a summary of the information to determine the next action. It captures the history to determine all that should happen next.\n\nNote: For a multi-agent problem, an agent can consider other agents as part of the Environment.\n\nAn information systems contains all useful information from History.\n\nMarkov Property: A state is Markov if and only if: Probability of the next state, given your current state is the same as all of the previous states. In other words, only current state is determining the next state and the history is not relavant.\n\nIn other words, If Markov property holds. The Future is independent of the History, given the Present. Since the state characterises everything about the past.\n\nAnother definition: State is a sufficient statistics of the Future.\n\nAnd the entire history is also a Markov state. (Not a useful one)\n\nAn RL Agent may (or may not) include on of these:\n\nIt\u2019s a map from state from action. Determines what the agent will do if it\u2019s in a state.\n\nIt\u2019s a prediction of expected future reward. We chose between actions by deciding to go for the highest rewards, an estimate of this is obtained by the Value function.\n\nValue function depends on the way in which we are behaving, it depends on the policy. It gives the reward if we follow an action, thus helps in optimize our behaviour.\n\nGamma: Discounting. It affects if we care about current/later states. It decides the horizon for evaluating the future. (Horizon-how far along do we need to calculate outcomes of our actions).\n\nIt\u2019s used to learn the environment, predicts what the environment will do next. It isn\u2019t necessary to create a model of the environment. But it\u2019s useful when we do.\n\nIt can be divide into two states:\n\nWe catgorize our agents based on which of the above three concepts, it follows. Say, if we have a value based agent: if it has a value function and a policy is implicit.\n\nPolicy based: maintains a data structure of the every state without storing the value function.\n\nActor Critic: Combines both the policy and also the value function.\n\nSo RL Problems can be categorized as:\n\nThere are two problems when it comes to sequential decision making.\n\nExploration: Chosing to give up some known reward, in order to find more about the environment.\n\nThere is an Exploration Vs Exploitation Tradeoff.\n\nPrediction: An estimate of the future, given the current policy\n\nIn RL, we need to evaluate all our policies to find out the best one."
    },
    {
        "url": "https://hackernoon.com/david-silver-rl-course-lecture-1-notes-a42cd1c6f687?source=user_profile---------38----------------",
        "title": "David Silver UCL-RL Course: Lecture 1 Notes \u2013",
        "text": "Reinforcement Learning: It sits at the Intersection of many fields of Science. It\u2019s the science of Decision making, a method to understand optimum decisions.\n\nSo it\u2019s really commo to a lot of branches, and is a general approach to solving the Reward based problems.\n\n(Informal) Reward Hypothesis: All goals can be described by the maximisation of expected cummalative reward.\n\nAll rewards can be weighed out based on the actions after comparisions. Thus all rewards can be decomposed into a scale of comparisions and hence a Scalar reward must be ultimately derived.\n\nBy Definition, Goal may be intermediate or a Final goal or Time Based, etcetra.\n\nFirst step is understanding the Reward Signal.\n\nWe control the brain here-Brain is the agent.\n\nAt every step, the agent receives observations which are generated by the environment and the agent itself influences the environment by making actions.\n\nThe Machine Learning problem of RL is related to the stream of data coming from the trail and error interaction.\n\nThe Stream of Experience, Sequence of Observation, Actions and rewards.\n\nState: It\u2019s a summary of the information to determine the next action. It captures the history to determine all that should happen next.\n\nNote: For a multi-agent problem, an agent can consider other agents as part of the Environment.\n\nAn information systems contains all useful information from History.\n\nMarkov Property: A state is Markov if and only if: Probability of the next state, given your current state is the same as all of the previous states. In other words, only current state is determining the next state and the history is not relavant.\n\nIn other words, If Markov property holds. The Future is independent of the History, given the Present. Since the state characterises everything about the past.\n\nAnother definition: State is a sufficient statistics of the Future.\n\nAnd the entire history is also a Markov state. (Not a useful one)\n\nAn RL Agent may (or may not) include on of these:\n\nIt\u2019s a map from state from action. Determines what the agent will do if it\u2019s in a state.\n\nIt\u2019s a prediction of expected future reward. We chose between actions by deciding to go for the highest rewards, an estimate of this is obtained by the Value function.\n\nValue function depends on the way in which we are behaving, it depends on the policy. It gives the reward if we follow an action, thus helps in optimize our behaviour.\n\nGamma: Discounting. It affects if we care about current/later states. It decides the horizon for evaluating the future. (Horizon-how far along do we need to calculate outcomes of our actions).\n\nIt\u2019s used to learn the environment, predicts what the environment will do next. It isn\u2019t necessary to create a model of the environment. But it\u2019s useful when we do.\n\nIt can be divide into two states:\n\nWe catgorize our agents based on which of the above three concepts, it follows. Say, if we have a value based agent: if it has a value function and a policy is implicit.\n\nPolicy based: maintains a data structure of the every state without storing the value function.\n\nActor Critic: Combines both the policy and also the value function.\n\nSo RL Problems can be categorized as:\n\nThere are two problems when it comes to sequential decision making.\n\nExploration: Chosing to give up some known reward, in order to find more about the environment.\n\nThere is an Exploration Vs Exploitation Tradeoff.\n\nPrediction: An estimate of the future, given the current policy\n\nIn RL, we need to evaluate all our policies to find out the best one."
    },
    {
        "url": "https://hackernoon.com/a-self-driving-new-year-33284e592f35?source=user_profile---------39----------------",
        "title": "A Self Driving New Year #1 \u2013",
        "text": "It\u2019s two days late to wish everyone a new year, but better late then never. Happy New Year World.\n\nI\u2019ve taken the resolution this year, to blog regularly of my findings and learnings. This is a blogpost of Why I chose to take up the Self Driving Car Nanodegree.\n\nFirst off: Here\u2019s a little background how I got to where I am today:\n\nI had always been a tech nerd since school. I had written my First Hello world in my 4th Grade (on BASIC), I got hooked then and there.\n\nFast forward to 2015, I had joined a reputed University in India to pursue my Childhood dream-\u2018To become a Coder\u2019, by Pursuing a CS degree.\n\nOfcourse, I had no idea about the field and no clue as to what I wanted to do for a living, but I was certain about my Love for Programming- I had learnt about Data Structure basics, Linux and C at High School.\n\nIn college-I took up a lot of MOOCs to get a taste of the field, explored a lot-took part in My College\u2019s technical clubs, events: Worked on an Autonomous Underwater Vehicle, worked at a Robotics Team at IIT-Chennai Research Park, worked at various Internships and Projects at IIT-Roorkee, IIT-Madras, ONGC.\n\nBy 2017, I was firm about my interest in pursuing Deep Learning, Computer Vision. In all honesty, I was always fascinated by the word \u2018Artificial Intelligence\u2019 but wasn\u2019t sure if I should take it up as an undergrad, because the General opinion requires me to be a Masters student or a Math Genie. (Not my opionion)\n\nI had already worked on a few Data Science Projects at an Internship at ONGC, and I was working on another one at IIT-Roorkee during Summer, 2017.\n\nSo I finally took the courage and signed up for Udacity\u2019s Deep learning Nanodegree, and voila! I fell in love. 6 Months later, I\u2019ve graduated from the Nanodegree with a lot of new experiences and few \u2018Toy Projects\u2019 (Apart from the ones in the course).\n\nI was lucky enough to get into the Fast AI International Fellowship as well: which was a rollercoaster ride to say the least! (An extremely detailed post on this soon)\n\nAnd work on a few Toy CV Projects.\n\nI\u2019m really, really Thankful to Andrew Trask (I don\u2019t think an introduction is needed-but Andrew is PhD student at Oxford University, funded by the Oxford-DeepMind Graduate Scholarship, where he researches Deep Learning approaches with special emphasis on human language and is currently the lead contributer to OpenMined), Aakash Nain for guiding me (Checkout his review of the SDCND: Aakash\u2019s blog) TL;DR: I made my decision to go with my gut, as Andrew had suggested:\n\nI\u2019ve decided to finally start my Self Driven journey to SDCs (The best New Year Resolution in my Life, I hope): something that has always fascinated me whether in real life, or as a Sci-fi movie when I was a kid (Oh what wouldn\u2019t we give to feel like we\u2019re Tony Starks with J.A.R.V.I.S driving our Orange Audis!) Hence, I\u2019ve signed up for the Udacity Self Driving Car Nanodegree Programme on the 1st of January, 2018.\n\nMy Goal right now is: I hope to learn and apply my knowledge of Deep learning and Computer Vision to this field, while exploring the Depths of Deep learning and gain knowledge of Autonomous Vehicles. Ofcourse, I\u2019d love to be a SDC Engineer, but that\u2019s not the immediate goal, first is enjoying the field.\n\nUnlike David Venturi, I do not want to drop out and create my own Degree- I would like to \u2018take my chances\u2019 in completing my Undergrad studies and then pursue a Masters degree in this field, meet amazing enthusiasts and gain more knowledge, while working on Side Projects to fill the Gaps that I might feel that the curriculum might have. (Lack of Practical aspects, that is-again, this is a Personal Opinion) I\u2019m certainly not the risk it all person.\n\nI will (and I certainly hope that I stick to this plan-another Resolution), regularly share Lessons learnt via Blog posts during 2018: my Experiences from the Nanodegree and from my garage projects as well.\n\nAt the same time, I really hope to do a little Deep Learning and (If I dare say) Kaggling on the side + review my learnings from the DLND, FastAI and Most importantly, contributing to communties-OpenMined, Nurture AI.\n\nHappy New Year Everyone! I\u2019d love to hear about your New Year Resolutions as well!\n\nAnd Stay Tuned for more! I will keep sharing blogs as a part of this series as an accountability of my Learning Path and the experiences.I hope everyone can learn from my experinces and my mistakes as well in that way."
    },
    {
        "url": "https://medium.com/ai-saturdays/reinforcement-learning-part-0-bd755c9cb895?source=user_profile---------40----------------",
        "title": "Reinforcement Learning Part 0 \u2013 AI Saturdays \u2013",
        "text": "We are super excited to announce an upcoming Reinforcement Learning Series!\n\nThe series will be in the form of a deep dive into the code with explanations and walkthroughs along side.\n\nThe series will take you through a few concepts in the most beginner appealing way that we can put up.\n\nYou will receive a full Mathematically and Programmatically sound answer in the series, but here is a fun one to begin with.\n\nImagine you\u2019re in a Bakery and have been told to bake a Delicious cake by your Supervisor.\n\nYour Supervisor is rather a strict person who leaves you to discover the best recipe. However, since the Supervisor hates you, she will thrash you every time you bake a bad cake (Probably not the best place to work at).\n\nNow, you\u2019re a smart kid! You start out an experiment. You keep a track of your Performance and the taste of every attempt.\n\nYour end goal is to impress your Supervisor (maximise your reward). You start out as an inexperienced person. You play around the Bakery (Your environment) and keep trying until you finally impress your Supervisor (Reward)\n\nYou start out by adding Salt, by burning down a few things and get Thrashed every time you do so (Receive a penalty) and since you\u2019re smart, you make sure you don\u2019t do this again (Keep a track of previous moves).\n\nIn the end you finally get \u2018Trained\u2019 once you\u2019ve baked the Best Cake and received your highest goal.\n\nSo this is how RL works."
    },
    {
        "url": "https://hackernoon.com/reinforcement-learning-part-0-8c2c3efe0ad6?source=user_profile---------41----------------",
        "title": "Reinforcement Learning Part 0 \u2013",
        "text": "The series will be in the form of a deep dive into the code with explanations and walkthroughs along side.\n\nNext up will be a series of Posts that will take you through a few concepts in the most beginner appealing way that we can put up.\n\nYou will receive a full Mathematically and Programmatically sound answer in the series, but here is a fun one to begin with.\n\nImagine you\u2019re in a Bakery and have been told to bake a Delicious cake by your Supervisor.\n\nYour Supervisor is rather a strict person who leaves you to discover the best recipe. However, since the Supervisor hates you, she will thrash you every time you bake a bad cake (Probably not the best place to work at).\n\nNow, you\u2019re a smart kid! You start out an experiment. You keep a track of your Performance and the taste of every attempt.\n\nYour end goal is to impress your Supervisor (maximise your reward). You start out as an inexperienced person. You play around the Bakery (Your environment) and keep trying until you finally impress your Supervisor (Reward)\n\nYou start out by adding Salt, by burning down a few things and get Thrashed every time you do so (Receive a penalty) and since you\u2019re smart, you make sure you don\u2019t do this again (Keep a track of previous moves).\n\nIn the end you finally get \u2018Trained\u2019 once you\u2019ve baked the Best Cake and received your highest goal.\n\nSo this is how RL works."
    },
    {
        "url": "https://medium.com/ai-saturdays/geek-board-92f16f87f660?source=user_profile---------42----------------",
        "title": "Geek Board \u2013 AI Saturdays \u2013",
        "text": "This idea as proposed by Sanyam Bhutani and as refined by the AISaturdays Team is:\n\nWe plan to promote Learning to the Max and so we are creating a Geek Leaderboard.\n\nThe idea is to distribute Swag points across various cities to people that do cool stuff. We hope to promote some (actually a lot) friendly competition across the cities.\n\nThe Leaderboard will be updated every Friday, the links will be updated on this post, Sanyam Bhutani will take care of allocating the points to everyone and updating the Leaderboard. The board will feature top 5 Geeks from every city.\n\nThe points will be allocated universally regardless of how \u2018beginner\u2019 your project/work is. We hope to promote equal growth amongs beginners and experts by doing this. That said, if you create something amazing, you will have a special mention in the Leaderboard but points will be the same to keep the beginners motivated.\n\nThe Leaderboard will be Updated weekly and all the submissions from every week will be linked to this post which also will be updated weekly.\n\nNote: All of the Projects, Blogs will be featured in every Weekly Leaderboard.\n\nThe notes will be Prepared by Sanyam Bhutani and will be published on Medium, the MarkDown files will be available in our Official Github account, feel free to contribute there and the Notes will be updated on Medium as well by Sanyam.\n\nSpread the word on Twitter with #AISaturdaysGeek when you make a submission."
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-5-14b177d9bef8?source=user_profile---------43----------------",
        "title": "Basic Tutorials Part 5 \u2013 AI Saturdays \u2013",
        "text": "Follow along with this tutorial using the code\n\nIn this post we discuss the Python Programming basics.\n\nAn overview of why we want to use the langauge has been given in Part 0 of this series.\n\nThis post shall serve as an introductory-crash course to Python.\n\nHere is the accompanying Notebook, the code portions discussed here and in the Notebook will be with bits and pieces left for the reader to figure out. We expect a more active participation in learning. Do leave a comment below if you feel anything is missing or have any doubts.\n\nWe suggest you use Jupyter notebooks (Details were discussed in the early posts)\n\nNotice the indents. Python uses indentation instead of using braces to mark the bodies.\n\nTuples can be created by () braces\n\nLists are created by enclosing within [] braces\n\nLists can be roughly linked to deques in their functionality\n\nDictionaries store values in the form of Key Value Pairs\n\nList comprehensions are a neat trick to collapse several lines of codes into one"
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-4-80723a0aea5d?source=user_profile---------44----------------",
        "title": "Basic Tutorials Part 4 \u2013 AI Saturdays \u2013",
        "text": "Welcome to this tutorial, Part 4 of the series on using Jupyter notebooks.\n\nAs a seasoned practitioner, you might want to demonstrate your code. Your insights and the techniques used.\n\nThe notebook is a web application that allows you to combine explanatory text, math equations, code, and visualizations all in one easily sharable document.\n\nNotebooks have quickly become an essential tool when working with data. You\u2019ll find them being used for data cleaning and exploration, visualization, machine learning, and analysis.\n\nThese support one of my favourite philosophies of Literate programming. To qoute Donald Knuth\n\nJupyter notebooks grew out of the IPython project started by Fernando Perez.\n\nIPython is an interactive shell, similar to the normal Python shell but with great features like syntax highlighting and one of my favourite-code completion (For the note, I\u2019m not lazy, I\u2019m a relaxed typer)\n\nThe central point is the notebook server. You connect to the server through your browser and the notebook works as a web app. The code is sent through the server to the kernel. The kernel runs the code and sends it back to the server, then any output is rendered back in the browser.\n\nThe notebooks are saved as .ipynb files, in a JSON format.\n\nJupyter isn\u2019t Python exclusive! The new name Jupyter comes from the combination of Julia, Python, and R. The basic working is the same for any given language. Just the kernel running everything in the background changes.\n\nNote: Since the Notebooks do not have to be on the same machine, we will use to render notebooks on our machine while using a cloud vendor\u2019s offering.\n\nWhen in the environment\n\nYou\u2019ll see a little box outlined in green. This is called a cell. Cells are where you write and run your code.\n\nJuputer also supports Markdown. In the toolbar, click \u201cCode\u201d to change it to Markdown and back. The little play button runs the cell, and the up and down arrows move cells up and down. Notice, the colour is now Blue.\n\nNow there is a lot of things in the toolbar, feel free to play around a bit and familiarize yourself. Here are a few:\n\nTo activate a cell, press enter when it is highlighted.\n\nNow, in my defence I\u2019m not lazy, the touchpad is just too far down on Macbook. So here are a few commands that I think are common:\n\nThese will often become intuitive and you will find the faster rather than searching for these commands via the GUI\n\nThese are few of the shorcuts that are worthy of a quick mention. There many more mentioned in our Git Repo\n\nTo get a list of all commands,\n\nMarkdown is the widely used format to create web documents. This post is written in Markdown. So it\u2019s worth to mention a few of the Syntaxes that are common.\n\nYou may want to leverage this when you create a notebook for showcasing your models/results.\n\nThis is a basic overview of the funtionalities offered by Jupyter notebooks, this is by no means an exhaustive list."
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-3-4962731e808e?source=user_profile---------45----------------",
        "title": "Basic Tutorials Part 3 \u2013 AI Saturdays \u2013",
        "text": "Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in Part-1 of this series.\n\nPackage managers are used to install libraries and other software on your computer. Pip is the default package manager for Python libraries.\n\nConda is similar to pip except that the available packages are focused around data science while pip is for general use.\n\nHowever, conda is not Python specific like pip is, it can also install non-Python packages but it does include all the Python packages and supports pip.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nConda is the package of Anaconda. If you\u2019ve used virtual env, pip: it includes both of these functionalities along with a few extra.\n\nWe will use conda because we\u2019re geeks. Just kidding, conda will be required when you need to access a cloud instance since you won\u2019t have access to GUI. Plus, it\u2019s easier to type 1 command than click a few buttons (Okay, maybe I wasn\u2019t kidding about the geekiness).\n\nAnaconda navigator which serves as a GUI to the Conda package and includes it is supported on Linux, OS X and Windows.\n\nYou can download the Navigator from Here\n\nSelect your OS and follow the Steps. These are pretty basic and have been omitted. If you\u2019re stuck anywhere or need help, please ask us in the comments below.\n\nThe commands below are to serve as a syntax. We\u2019ve create a Github repository for you to use. Feel free to use the code from there\n\nGithub repository link (Link to be updated soon)\n\nTo use an environment:\n\nNotice that your prompt has a (envname) before it.\n\nTo get out of an environment:\n\nYour project has a certain set of required libraries in order to work. When sharing your project, you share your requirements file so that one can create an environment directly from these.\n\nThis creates a YAML file that contains the list of dependencies of the project.\n\nThis creates a new environment with the name as is \u2014 inside the YAML file.\n\nThis is by no means an exhaustive list of the commands. These are meant to serve for an introductory purposes.\n\nCheckout the Conda user guides if you want to learn more.\n\nHere is another interesting read Common Myths and Misconceptions"
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-2-ee778e5926cf?source=user_profile---------46----------------",
        "title": "Basic Tutorials Part 2 \u2013 AI Saturdays \u2013",
        "text": "A version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others.\n\nThe most common way of using git is via the Command Line interface. We will demonstrate this because we are geeks! (Er, it\u2019s needed when you\u2019re working remotely)\n\nTo get help\n\nIf you get something like\n\nGit Works as shown: Unstage refers to making the file \u2018staged\u2019 from being untracked (In English, the file is added to our repository in the eyes of Git)\n\nUntracked: Changes are not tracked Unstaged: These aren\u2019t a part of Git\u2019s repository.\n\nReturns the status of the Repository\n\nThis adds the File FileName to the staged area\n\nAdds everything in our repository to git\n\nCommit: When you make changes in a repo, these need to be commited. By design, Git requires every commit to include a commit message describing the purpose of the commit. Typically, this takes the form of a single line, usually limited to around 72 characters, with an optional longer message if desired\n\nTo see a record of your commits\n\nWhen you have made changes in your repository, that have not been commited yet.\n\nThis shows the differences between the previous commit and the current one. (For all you Linux geeks, it runs the diff command in the background)\n\nWhen someone wants to submit changes to your repository, they submit a pull request. You review these changes and then \u2018Merge\u2019 the request into your repo.\n\nWell, generally speaking, your Repository will be available for anyone to view once you put it on GitHub. But Collaborators are people that have direct access to the repo. Consider them the administrators.\n\nDifferent collaborators work on the code simultaneously. To avoid hinderence, everyone works on a branch. A branch is the copy made of the code at point of time, which is used to work upon in a manner to keep other branches unaffected.\n\nMaster branch contains the main code for your Project\n\nA site designed to facilitate collaboration with Git repositories and it\u2019s free to use.\n\nSign up for a GitHub account Here.\n\nNow for all purposes of managing a local repository, I recommend you start with Github Desktop which provides a neat GUI to interact with GitHub and has a set of neat tutorials to get you started.\n\nThis is a fairly advanced topics to share amongst complete beginners and is skipped over for a later post in the series. (Or an update)\n\nThis Blog post might feel a little incomplete-that is because it\u2019s been created in a way to force you to explore the Software. Git is a software to be used and explored, hence that part is left out as an intensive excercise to the reader.\n\nThat being said, if you have any doubt: Do leave a comment below and we\u2019d be happy to help resolve it."
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-1-fc384b2327a2?source=user_profile---------47----------------",
        "title": "Basic Tutorials Part 1 \u2013 AI Saturdays \u2013",
        "text": "These terms are usually used to refer to a Black and white window where people (geeks) usually type in code and work with.\n\nBASH: Bourne Again Shell, is what runs your commands when you type them.\n\nTerminal: The windows is called Terminal, is where you type the commands.\n\nGiven these reasons, we chose to use Terminal for our work.\n\nKnow that this is by no means an exhaustive list and is meant to provide an introductory walkthrough.\n\nThere are many more things to be explored. Feel free to ask for more resources or doubts in the comments below.\n\nThe $ is the prompt. Which means that the terminal is ready and is waiting for your commands to start.\n\ncd=Change directory, by changing your directory. You are changing your present working directory.\n\nThese are the absolute basic commands that should get you started. Feel free to explore more and ask in the comments below for help."
    },
    {
        "url": "https://medium.com/ai-saturdays/basic-tutorials-part-0-b84ee51da37f?source=user_profile---------48----------------",
        "title": "Basic Tutorials Part 0 \u2013 AI Saturdays \u2013",
        "text": "We will follow a bunch of libraries in the few courses that we shall follow and this post intends to provide an overview of the same and justification for using these. If you have a different viewpoint or want to question us on any of these points, please leave a comment below and we\u2019d love to chat about it.\n\nThat said, we will probably stick to these options because after extensive exploration, we have concluded that these are the best options for us. But we\u2019re open to any suggestions and places for improvements!\n\nA version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others. In addition, using version control also makes deploying production websites and web applications much easier.\n\nAt a certain point, you might end up breaking your project and you might want to do a little version control. Git to the rescue!\n\nIt\u2019s a place to brag about repositories by showcasing them and at the same point a place to host the code to allow contributors to add to the Project.\n\nNow many of us here would be beginners and might pick a GUI over a command line, but it turns it that command line can be better than GUI. Some functionalities are just faster done with Command Line, and when you use a cloud service. You will need to use a Command Line to perform actions on your machine.\n\nMost of the commands are run in BASH which is a shell that runs your commands in the background.\n\nA terminal is the interface to the BASH environment on your machine. When you use a terminal, you use the interface to access the BASH environment on your machine\n\nAnaconda is another Open Source project that is the most used amongs the Data Science world. We will chiefly be using Conda and Jupyter Notebooks.\n\nPackage, dependency and environment management for any language \u2014 Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN\n\nConda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in these series.\n\nPython is the intensely used by Deep learning practitioners to cutting edge researchers.\n\nIt\u2019s an Open Source langauge that has gained tremendous fame in the recent years\n\nThis post serves as a basic overview, hence many technical details will be skipped here.\n\nThe reasons why we want to use this are:\n\nThis series will feature an introduction to Python programming and using it\u2019s two most important libraries for Data Science:"
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-5-45ee269f98e7?source=user_profile---------49----------------",
        "title": "Basic Tutorials Part 5 \u2013 init27 Labs \u2013",
        "text": "In this post we discuss the Python Programming basics.\n\nAn overview of why we want to use the langauge has been given in Part 0 of this series.\n\nThis post shall serve as an introductory-crash course to Python.\n\nHere is the accompanying Notebook, the code portions discussed here and in the Notebook will be with bits and pieces left for the reader to figure out. We expect a more active participation in learning. Do leave a comment below if you feel anything is missing or have any doubts.\n\nWe suggest you use Jupyter notebooks (Details were discussed in the early posts)\n\nNotice the indents. Python uses indentation instead of using braces to mark the bodies.\n\nTuples can be created by () braces\n\nLists are created by enclosing within [] braces\n\nLists can be roughly linked to deques in their functionality\n\nDictionaries store values in the form of Key Value Pairs\n\nList comprehensions are a neat trick to collapse several lines of codes into one"
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-4-f6ea21045564?source=user_profile---------50----------------",
        "title": "Basic Tutorials Part 4 \u2013 init27 Labs \u2013",
        "text": "Welcome to this tutorial, Part 4 of the series on using Jupyter notebooks.\n\nAs a seasoned practitioner, you might want to demonstrate your code. Your insights and the techniques used.\n\nThe notebook is a web application that allows you to combine explanatory text, math equations, code, and visualizations all in one easily sharable document.\n\nNotebooks have quickly become an essential tool when working with data. You\u2019ll find them being used for data cleaning and exploration, visualization, machine learning, and analysis.\n\nThese support one of my favourite philosophies of Literate programming. To qoute Donald Knuth\n\nJupyter notebooks grew out of the IPython project started by Fernando Perez.\n\nIPython is an interactive shell, similar to the normal Python shell but with great features like syntax highlighting and one of my favourite-code completion (For the note, I\u2019m not lazy, I\u2019m a relaxed typer)\n\nThe central point is the notebook server. You connect to the server through your browser and the notebook works as a web app. The code is sent through the server to the kernel. The kernel runs the code and sends it back to the server, then any output is rendered back in the browser.\n\nThe notebooks are saved as .ipynb files, in a JSON format.\n\nJupyter isn\u2019t Python exclusive! The new name Jupyter comes from the combination of Julia, Python, and R. The basic working is the same for any given language. Just the kernel running everything in the background changes.\n\nNote: Since the Notebooks do not have to be on the same machine, we will use to render notebooks on our machine while using a cloud vendor\u2019s offering.\n\nWhen in the environment\n\nYou\u2019ll see a little box outlined in green. This is called a cell. Cells are where you write and run your code.\n\nJuputer also supports Markdown. In the toolbar, click \u201cCode\u201d to change it to Markdown and back. The little play button runs the cell, and the up and down arrows move cells up and down. Notice, the colour is now Blue.\n\nNow there is a lot of things in the toolbar, feel free to play around a bit and familiarize yourself. Here are a few:\n\nTo activate a cell, press enter when it is highlighted.\n\nNow, in my defence I\u2019m not lazy, the touchpad is just too far down on Macbook. So here are a few commands that I think are common:\n\nThese will often become intuitive and you will find the faster rather than searching for these commands via the GUI\n\nThese are few of the shorcuts that are worthy of a quick mention. There many more mentioned in our Git Repo\n\nTo get a list of all commands,\n\nMarkdown is the widely used format to create web documents. This post is written in Markdown. So it\u2019s worth to mention a few of the Syntaxes that are common.\n\nYou may want to leverage this when you create a notebook for showcasing your models/results.\n\nThis is a basic overview of the funtionalities offered by Jupyter notebooks, this is by no means an exhaustive list."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-3-8ca1bf9627b8?source=user_profile---------51----------------",
        "title": "Basic Tutorials Part 3 \u2013 init27 Labs \u2013",
        "text": "Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in Part-1 of this series.\n\nPackage managers are used to install libraries and other software on your computer. Pip is the default package manager for Python libraries.\n\nConda is similar to pip except that the available packages are focused around data science while pip is for general use.\n\nHowever, conda is not Python specific like pip is, it can also install non-Python packages but it does include all the Python packages and supports pip.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nConda is the package of Anaconda. If you\u2019ve used virtual env, pip: it includes both of these functionalities along with a few extra.\n\nWe will use conda because we\u2019re geeks. Just kidding, conda will be required when you need to access a cloud instance since you won\u2019t have access to GUI. Plus, it\u2019s easier to type 1 command than click a few buttons (Okay, maybe I wasn\u2019t kidding about the geekiness).\n\nAnaconda navigator which serves as a GUI to the Conda package and includes it is supported on Linux, OS X and Windows.\n\nYou can download the Navigator from Here\n\nSelect your OS and follow the Steps. These are pretty basic and have been omitted. If you\u2019re stuck anywhere or need help, please ask us in the comments below.\n\nThe commands below are to serve as a syntax. We\u2019ve create a Github repository for you to use. Feel free to use the code from there\n\nGithub repository link (Link to be updated soon)\n\nTo use an environment:\n\nNotice that your prompt has a (envname) before it.\n\nTo get out of an environment:\n\nYour project has a certain set of required libraries in order to work. When sharing your project, you share your requirements file so that one can create an environment directly from these.\n\nThis creates a YAML file that contains the list of dependencies of the project.\n\nThis creates a new environment with the name as is \u2014 inside the YAML file.\n\nThis is by no means an exhaustive list of the commands. These are meant to serve for an introductory purposes.\n\nCheckout the Conda user guides if you want to learn more.\n\nHere is another interesting read Common Myths and Misconceptions"
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-2-97a6e04b35e8?source=user_profile---------52----------------",
        "title": "Basic Tutorials Part 2 \u2013 init27 Labs \u2013",
        "text": "A version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others.\n\nThe most common way of using git is via the Command Line interface. We will demonstrate this because we are geeks! (Er, it\u2019s needed when you\u2019re working remotely)\n\nTo get help\n\nIf you get something like\n\nGit Works as shown: Unstage refers to making the file \u2018staged\u2019 from being untracked (In English, the file is added to our repository in the eyes of Git)\n\nUntracked: Changes are not tracked Unstaged: These aren\u2019t a part of Git\u2019s repository.\n\nReturns the status of the Repository\n\nThis adds the File FileName to the staged area\n\nAdds everything in our repository to git\n\nCommit: When you make changes in a repo, these need to be commited. By design, Git requires every commit to include a commit message describing the purpose of the commit. Typically, this takes the form of a single line, usually limited to around 72 characters, with an optional longer message if desired\n\nTo see a record of your commits\n\nWhen you have made changes in your repository, that have not been commited yet.\n\nThis shows the differences between the previous commit and the current one. (For all you Linux geeks, it runs the diff command in the background)\n\nWhen someone wants to submit changes to your repository, they submit a pull request. You review these changes and then \u2018Merge\u2019 the request into your repo.\n\nWell, generally speaking, your Repository will be available for anyone to view once you put it on GitHub. But Collaborators are people that have direct access to the repo. Consider them the administrators.\n\nDifferent collaborators work on the code simultaneously. To avoid hinderence, everyone works on a branch. A branch is the copy made of the code at point of time, which is used to work upon in a manner to keep other branches unaffected.\n\nMaster branch contains the main code for your Project\n\nA site designed to facilitate collaboration with Git repositories and it\u2019s free to use.\n\nSign up for a GitHub account Here.\n\nNow for all purposes of managing a local repository, I recommend you start with Github Desktop which provides a neat GUI to interact with GitHub and has a set of neat tutorials to get you started.\n\nThis is a fairly advanced topics to share amongst complete beginners and is skipped over for a later post in the series. (Or an update)\n\nThis Blog post might feel a little incomplete-that is because it\u2019s been created in a way to force you to explore the Software. Git is a software to be used and explored, hence that part is left out as an intensive excercise to the reader.\n\nThat being said, if you have any doubt: Do leave a comment below and we\u2019d be happy to help resolve it."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-1-3ba416f2ba65?source=user_profile---------53----------------",
        "title": "Basic Tutorials Part 1 \u2013 init27 Labs \u2013",
        "text": "These terms are usually used to refer to a Black and white window where people (geeks) usually type in code and work with.\n\nBASH: Bourne Again Shell, is what runs your commands when you type them.\n\nTerminal: The windows is called Terminal, is where you type the commands.\n\nGiven these reasons, we chose to use Terminal for our work.\n\nKnow that this is by no means an exhaustive list and is meant to provide an introductory walkthrough.\n\nThere are many more things to be explored. Feel free to ask for more resources or doubts in the comments below.\n\nThe $ is the prompt. Which means that the terminal is ready and is waiting for your commands to start.\n\ncd=Change directory, by changing your directory. You are changing your present working directory.\n\nThese are the absolute basic commands that should get you started. Feel free to explore more and ask in the comments below for help."
    },
    {
        "url": "https://medium.com/init27-labs/basic-tutorials-part-0-90f623b291e6?source=user_profile---------54----------------",
        "title": "Basic Tutorials Part 0 \u2013 init27 Labs \u2013",
        "text": "We will follow a bunch of libraries in the course and this post intends to provide an overview of the same and justification for using these. If you have a different viewpoint or want to question us on any of these points, please leave a comment below and we\u2019d love to chat about it.\n\nThat said, we will probably stick to these options because after extensive exploration, we have concluded that these are the best options for us. But we\u2019re open to any suggestions and places for improvements!\n\nA version control system (or VCS) provides an automatic way to track changes in software projects, giving creators the power to view previous versions of files and directories, develop speculative features without disrupting the main development, securely back up the project and its history, and collaborate easily and conveniently with others. In addition, using version control also makes deploying production websites and web applications much easier.\n\nAt a certain point, you might end up breaking your project and you might want to do a little version control. Git to the rescue!\n\nIt\u2019s a place to brag about repositories by showcasing them and at the same point a place to host the code to allow contributors to add to the Project.\n\nNow many of us here would be beginners and might pick a GUI over a command line, but it turns it that command line can be better than GUI. Some functionalities are just faster done with Command Line, and when you use a cloud service. You will need to use a Command Line to perform actions on your machine.\n\nMost of the commands are run in BASH which is a shell that runs your commands in the background.\n\nA terminal is the interface to the BASH environment on your machine. When you use a terminal, you use the interface to access the BASH environment on your machine\n\nAnaconda is another Open Source project that is the most used amongs the Data Science world. We will chiefly be using Conda and Jupyter Notebooks.\n\nPackage, dependency and environment management for any language \u2014 Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN\n\nConda is an open source package management system and environment management system that runs on Windows, macOS and Linux.\n\nConda quickly installs, runs and updates packages and their dependencies. Conda easily creates, saves, loads and switches between environments on your local computer. It was created for Python programs, but it can package and distribute software for any language.\n\nWhile creating a Project, you will require various libraries and dependencies. Some projects will require a certain set of libraries which will work only with a given version of a set of other libraries, but at the same point you might want to work on a different set of projects.\n\nTo help with this, Conda creates separate \u2018environments\u2019. A environment X with a set of libraries is independent and unaffected by another environment Y. Thus you can work on your given projects without worrying about \u2018breaking\u2019 the requirements everytime you install something-when you do, conda ensures that the \u2018environment\u2019 works in cohesion by changing other libraries.\n\nAnother point worth mentioning is, Open Source projects share their \u2018source\u2019 code; which needs to be compiled everytime you want to use it. However, compiling a huge library can be tedious and time taking. Conda provides precompiled libraries to be downloaded whenever you need to install something new. So you just have to download it and can dive right in!\n\nA detailed tutorial of using Conda and Jupyter notebooks will be shared in these series.\n\nPython is the intensely used by Deep learning practitioners to cutting edge researchers.\n\nIt\u2019s an Open Source langauge that has gained tremendous fame in the recent years\n\nThis post serves as a basic overview, hence many technical details will be skipped here.\n\nThe reasons why we want to use this are:\n\nThis series will feature an introduction to Python programming and using it\u2019s two most important libraries for Data Science:"
    },
    {
        "url": "https://medium.com/ai-saturdays/cloud-setup-tutorial-part-0-53d42dd4c733?source=user_profile---------55----------------",
        "title": "Cloud Setup Tutorial Part-0 \u2013 AI Saturdays \u2013",
        "text": "Deep Learning is extremely Computation intensive. GPU-Graphic Processing Units seem to perform really well with these computations. Reason: GPUs were orignally devoloped for gaming, which involves a lot of Matrix computations. Deep learning involves a lot of Matrix computations too and recently the GPUs have shown tremendous advances and this has resulted in these being used for Deep Learning.\n\nUsually, GPU resources are not required in our everyday life and we do not have latops or \u2018rigs\u2019 (Desktops) that can leverage this amount of power. So chances are you do not have a GPU at all or have one that would take too long to \u2018train\u2019 or work with Deep learning Models. An easy hassle free alternative is using Cloud Compute for Deep learning.\n\nHassle free? You don\u2019t have to go through the pain of setting every \u2018Library\u2019 and Dependency and you get to jump right in and start out with the lessons.\n\nAnd to start out, it\u2019s pretty cheap. You can get access at 0.6$ an hour (with decent power). Which is way less than buying a \u2018rig\u2019 right away.\n\nThere are a huge number of options that are available now. I will mention a few that I think are good. Know that there are a lot of more options that this blog wouldn\u2019t cover, feel free to discuss about them in the comments below!\n\nThis is roughly in an order of the easiest to setup and in increasing difficulty\n\nCrestle is the simplest interface to play with, once you login you have an option to either start with a GPU or CPU. Then you\u2019re taken directly to the Jupyter notebook\n\nAll of DL libraries installed. No need for any setting up, no using terminals to login (which is initmidating when you start).\n\nThere is access to a terminal still if you want to add/download datasets and install other libraries.\n\nThe pricing doesn\u2019t have many options since you don\u2019t get any. It\u2019s GPU or CPU. The GPUs are Tesla K-80 for you Benchmarking geeks.\n\nPaperspace also offers a clean an intuitive interface along with a few options for the GPU computing. Plus another cool feature is that launching an instance takes you directly to the \u2018Desktop\u2019 view. You get to control the GUI.\n\nYou can always use a terminal to SSH and use the interface.\n\nThat said, the downside of Paperspace is that they have servers in three areas, and the GUI feature might require a good internet connection. (Good is subjective. In my case, I use a 512KBPS connection and can\u2019t use this feature at all, the internet options in your areas ideally would not be this bad)\n\nGoogle Cloud Platform: One of the Big players in the space. The coolest part is, they are offering 300$ for signing up (with a validity of 12 months)\n\nI encourage you to check out our AI Researcher, James Lee\u2019s blog post about it Here\n\nIt\u2019s a walk through of setting up a google cloud computing instance with a 500gb SSD, a 3.75gb ram Broadwell CPU and a Nvidia Tesla K80 GPU. All of this can be done for free at the start, with some details. Repeating these here is unncessary but please feel free to comment below if you to discuss anything.\n\nAWS is arguably the Number 1 cloud service being used right now. Not just in academia, in Industry as well.\n\nThis series will include a walkthrough of setting up and launching instances in the following parts.\n\nAWS offers tonnes of options for all purposes- storage, CPU Power, GPU power, it also hosts the fastest P3 instances in various regions which are really good for huge Deep learning models.\n\nThe costs range from 0.5$ onwards (per hour) for GPU compute. AWS offers some credits to Students as well (If you sign up via a Student ID).\n\nI will skip the details of AWS since we will demonstrate setting up an AWS Instance in this series.\n\nFeel free to ask for help with any other platforms too! Drop a comment below.\n\nThis Blogpost was intended to give a brief intro and has skipped over a lot of details, since many of the Pricing and technical details are highly dynamic. Using a certain vendor is truly a personal choice. I prefer Crestle and AWS, I suggest you should play with all of these options and pick your poison. At a certain point when you are sure you want to pursue the field, a Local server setup will seem to be more viable option. Setting up a Local server will be included in this series.\n\nThis is by no means an exhaustive and complete list. There are many other options to choose from:"
    },
    {
        "url": "https://medium.com/ai-saturdays/aws-tutorial-part-2-61c82f8a5731?source=user_profile---------56----------------",
        "title": "AWS Tutorial Part-2 \u2013 AI Saturdays \u2013",
        "text": "In this post, we explore spot instances. Spot instances are an amazing way to cutting down your AWS bills by upto 90%!\n\nWhy Cheap? Well Amazon tends to leave its free servers around for usage of Spot instances; as a user you place a \u2018bet\u2019 on the pricing that you want for the instance. If someone outbids your price or if the load on AWS goes up. Boof! Your instance is gone!\n\nOne more point, unlike normal instances-spot instances do not let you retain your data after stopping the instance. There is no option of stopping it infact, you can only terminate the instance.\n\nNow assuming we are good with the disclaimers and need to cut our costs, lets proceed:\n\nAssumption: You\u2019ve gone through the Part 1 and have a valid AWS account with a access to GPU Compute permissions (you have applied for increase in compute power and have access to >1 according to the limits)\n\nRequesting: So how this works is, you place a \u2018bet\u2019 on the pricing you want and AWS grants you the access based on availability. Now based on the load on AWS servers and the pricing you have requested, you may have to wait for a while.\n\nKey Pair: We use Secure Shell Login or SSH to login to our instances, the security is ensured by A Key-Pair which gives you access to the instance"
    },
    {
        "url": "https://medium.com/ai-saturdays/aws-setup-tutorial-part-1-f3ee3c77fe3d?source=user_profile---------57----------------",
        "title": "AWS Setup Tutorial: Part 1 \u2013 AI Saturdays \u2013",
        "text": "AWS or Amazon Web Services are a bunch of Cloud services that are provided by Amazon.\n\nThere a bunch of options to choose from for Deep learning, I prefer AWS the most because of the huge number of options that it offers.\n\nNow you might have to wait for a while untill you hear from Amazon, once your limit increase has been approved\n\nAMI is an \u2018Image\u2019 of the OS with everything installed. Consider a snapshot of the states of OS after installing all the software. It can save you the pain of setting it all up, you can dive right into working.\n\nKey Pair: We use Secure Shell Login or SSH to login to our instances, the security is ensured by A Key-Pair which gives you access to the instance"
    },
    {
        "url": "https://hackernoon.com/gradient-clipping-57f04f0adae?source=user_profile---------58----------------",
        "title": "Gradient Clipping \u2013",
        "text": "During \u2018Training\u2019 of a Deep Learning Model, we backpropogate our Gradients through the Network\u2019s layers.\n\nDuring experimentation, once the gradient value grows extremely large, it causes an overflow (i.e. NaN) which is easily detectable at runtime or in a less extreme situation, the Model starts overshooting past our Minima; this issue is called the Gradient Explosion Problem.\n\nThis is when they get exponentially large from being multiplied by numbers larger than 1, consider the example:\n\nGradient clipping will \u2018clip\u2019 the gradients or cap them to a Threshold value to prevent the gradients from getting too large.\n\n\n\nIn the above image, Gradient is clipped from Overshooting and our cost function follows the Dotted values rather than its original trajectory."
    },
    {
        "url": "https://hackernoon.com/imdb-sentiment-analysis-using-a-pre-trained-model-80c3d8343d48?source=user_profile---------59----------------",
        "title": "IMDB Sentiment Analysis using a pre-trained Model \u2013",
        "text": "We must admit the concept of using pretrained Models in NLP is admitedly new.\n\nIn this post I share a method taught in the v2 of FastAI course (to be released publically by next year): to train a Language model on the Large Movie View Dataset which contains 50,000 reviews from IMDB, so that gives us a decent amount of data to test and train our models on, and then use the same model to perform sentiment analysis on IMDB Reviews.\n\nCreating a model that is used to predict/produce a language or to simply predict the next word in a language based on the current set of words.\n\nAnalysing a given set of words to predict the sentiment in the paragraph.\n\nBelow is a walkthrough of the keysteps in our experiment.\n\nIn essence we would be using a pretrained network, but here we shall create the same on our own.\n\nWe preprocess our data using PyTorch\u2019s Torchtext library\n\nWe tokenize our data with spacy and keep it in the lower case.\n\nNext, we create our Model data, which will be fed to the Learning model to perform language modelling.\n\nSince we know that Neural Networks can\u2019t really work with words, we need to map the words to integers. Torch text already does this by mapping our words in\n\nNext up, we create a learner object and call the fit function for the same.\n\nEmbedding matrix: Here is link to a gentle introduction Embeddings.\n\nHere is a sample of text produced by the trained model\n\nSo, thus far we have created a model that can successfully create movie reviews, which started out as being a model that didn\u2019t even understand english. Next we Finetune this to our target task.\n\nSo far, we have trained our Model nicely on Language Modelling. Now we use the same to predict Sentiments of Movie Reviews.\n\nWe freeze the model till the last layer, fit the same after setting our learning rate. We define our metrics for accuracy.\n\nLearned in translation: contextualized word vectors is a paper that has a comparision of all the cutting edge model\u2019s performance on IMDB dataset as a benchmark comparision.\n\nAfter Finetuning the learning rates, tweaking the cycle lengths the accuracy achieved by the model is\n\nWe started with a model that was decent in producing IMBD movie reviews.\n\nThe state of the art of 2017 research is 94.1. So the idea of applying a pretrained language model to actually outperformed the cutting edge research in academia as well.\n\nI\u2019m personally working with my college to generate a model that analysis the sentiment in the Faculty reviews submitted by Students."
    },
    {
        "url": "https://hackernoon.com/convolutional-neural-network-in-5-minutes-8f867eb9ca39?source=user_profile---------60----------------",
        "title": "Convolutional Neural Network in 5 minutes \u2013",
        "text": "Convolution is a set of Dot Products performed by a filter (A mathematical filter like your regular snapchat filter, transforms the data into cooler,more desirable forms).\n\nNow if you like me slept through your Math lectures, all you need to know is that Images are basically represented as Multi-dimensional vectors. A 2-D layout makes sense, but the more dimensions (which is unintuitive) are present to mark the intensity of colours in the image (Remember the cool RGB pallete in MS-Paint?)\n\nThe basic idea behind them is the mathematical function \u2018Convolution\u2019.\n\nThese work on images in a manner similar to the human brain: by finding smaller details- A line, a rectangle, a blob-and then working their way up to more abstract features- Lines arranged in a manner form an oval shape- A certain form of oval with some features is a face.\n\nConvolutional Neural Networks are a category of Neural Networks, which the long bearded geek researchers find to be more promising when working on Image data.\n\nThat was the amount that Facebook paid to acquire Instagram a bunch of years ago. Today the company has grown exponentially to almost every smartphone and even you probably frequent it more than medium.\n\nIf the above line didn\u2019t get you interested, How does a billion dollar sound?\n\nOK, But Why should you care?\n\nConvolutional Neural Networks are the leading architecture in Deep Learning that are used for Image Processing Techniques.\n\nSo we take our Image-which is a huge matrix, Convolve it with a filter-a much smaller matrix, and get an activation map.\n\nActivation map: Each filter is sensitive to certain data, it gets excited when it sees a certain shape/color/form. These are represented as activation maps of the orignal images which are the layers marked as Conv in the image. These are then fed through an activation function then to another bunch of filters which then get \u2018excited\u2019 by further more abstract features.\n\nAs we \u2018go deeper\u2019 into our Neural Networks, we go higher in terms of Human perception, features. We start by detecting features in pixel format and then detecting shapes, then finally objects.\n\nIf you notice closely, Every Conv Layer gets more recognizable. From Pixels to Cars. The first few layers detect something that makes no sense to me. The last layer shows resemblance to our end results.\n\nThese outputs are finally \u2018pooled\u2019 or sent into a fully Connected layer which is used to identify our object from a bunch of options.\n\nWell if you would have noticed, the Neurons of every layer are not fully connected so that means less complications, less number of weights and faster training.\n\nAnother cool thing is that since each layer almost finds a certain set of features in the previous layer. So a trained Network can be used for \u2018transfer learning\u2019. Where you use a trained network- Say one that is good at detecting cars. And then improvise it to differentiate between say Sedans and SUVs.\n\nYou could create a model based on a certain architecture of CNN- say a ResNet34 Model and then use it for identifying dogs and Cats! (Don\u2019t worry the image below is not supposed to make sense. It \u2018s there to makes this essay look more professional)\n\nSo we could effectively do what most engineers do- create a model that is inspired(copied) from another\u2019s Neural network.\n\nYou could use an already award winning Architecture like the VGGNet, AlexNet and leverage their awesomeness in your personal venture.\n\nWhat can CNNs do?\n\nFood for thought: You could create an awesome engine that detects objects in images in real time and finds \u2018A blue car by the beach\u2019. Spoiler alter: My Mentor Jeremy Howard has already showcased this in his amazing Ted Talk.\n\nDon\u2019t worry, approximately 85% of Internet is Pixel Data and we have no techniques to properly analyse it.\n\nIt might take more than an entire life to binge watch it. Even when you say that Instagram with its revolutionary algorithms shows you posts related to your interests, behind the scenses its using your Hastags and Similar user trends to show the data and not real time Image/Video Analysis to conclude that and so does Google. The google Image results are simply a result of finding the text in their website.\n\nEven these giants are yet to devolop their true Image Analysing systems.\n\nThis could be your shot at developing something. A better Self Driving Car? The new Pinterest?"
    },
    {
        "url": "https://medium.com/init27-labs/andrew-ngs-new-course-6e6a4f6c3aef?source=user_profile---------61----------------",
        "title": "Andrew NG\u2019s new course \u2013 init27 Labs \u2013",
        "text": "More cool stuff at My Website.\n\nAndrew NG\u2019s new venture features a bunch of courses forming a \u2018DeepLearning specialisation\u2019 on coursera.\n\nAlthough the courses launch on 15th, the content is open to access and the assignments and quizzes are accessible as well.\n\nAs of now, 3 out the 5 courses are available. My experience has been great from these courses. I really feel the gaps that I\u2019ve felt while pursuing the Machine Learning course (and repeating it over several times) have been covered thoroughly. This course feels like a mature version of all coursera courses. It addresses the industry and academia gap, and isn\u2019t theoretical completely. There is plenty of coding too, even though DL is thoroughly Math, Algorithm and statistics (according to my understanding of the field). Yet the course offers enough experience to suffice the gap.\n\nThe three courses make up a perfect weekend task, I really look forward to studying CNN, Sequence models as soon as they are unlocked.\n\nI really loved the (optional) interviews with the Heroes of Deep Learning. Being able to relate to their motivations to the field and path is really motivating.\n\nI\u2019d really love to hear from you about more learning resources related to Deep Learning, AI and I look forward to working on a few projects to gain some skills."
    }
]